<?xml version="1.0" encoding='UTF-8'?>
<results algorithmName="GS" algorithmVersion="101001" time="9:00" date="2013">
<query content="author:&quot;Sim Khe Chai&quot; NUS" label="" count="22" totalresults="22">
  <result id="0">
    <url>http://dl.acm.org/citation.cfm?id=1390397</url>
    <title status="complete" source="scholar.google.com">A lattice-based approach to query-by-example spoken document retrieval</title>
    <pdf>http://hp-thesis.googlecode.com/svn/trunk/IR/A%20Lattice-Based%20Approach%20to%20Query-by-Example%20Spoken%20Document%20Retrieval.pdf</pdf>
    <author status="complete" source="scholar.google.com">TK Chia, KC Sim, H Li, HT Ng</author>
    <proceeding status="partial" source="scholar.google.com">&#8230; of the 31st annual international ACM &#8230;</proceeding>
    <year>2008</year>
    <source>dl.acm.org</source>
    <snippet status="partial" source="scholar.google.com">Page 1. A Lattice-Based Approach to Query-by-Example Spoken Document Retrieval TeeKiah Chiaâ  Khe Chai Simâ¡ â Department of Computer Science National University of SingaporeLaw Link, Singapore 117590 {chiateek,nght}@comp.nus.edu.sg ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:9GEHrf6jhZsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>17</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=11206543562001310196&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>28</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=11206543562001310196&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="28">
        <result id="0">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5178967</url>
        <title status="complete" source="scholar.google.com">A brief survey of computational approaches in social computing</title>
        <pdf>http://pensivepuffin.com/dwmcphd/syllabi/insc547_wi11/papers/overview/king-overview-socialcomp.sna-IJCNN09.pdf</pdf>
        <author status="complete" source="scholar.google.com">I King, J Li, KT Chan</author>
        <proceeding status="partial" source="scholar.google.com">Neural Networks, 2009. IJCNN 2009. &#8230;</proceeding>
        <year>2009</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Web 2.0 technologies have brought new ways of connecting people in social networks for collaboration in various on-line communities. Social Computing is a novel and emerging computing paradigm that involves a multi-disciplinary approach in analyzing ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:G36fXe5RUosJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10039176603577056795&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>22</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10039176603577056795&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://oai.dtic.mil/oai/oai?verb=getRecord&amp;metadataPrefix=html&amp;identifier=ADA514582</url>
        <title status="complete" source="scholar.google.com">A comparison of query-by-example methods for spoken term detection</title>
        <pdf>http://www.dtic.mil/dtic/tr/fulltext/u2/a514582.pdf</pdf>
        <author status="complete" source="scholar.google.com">W Shen, CM White, TJ Hazen</author>
        <year>2009</year>
        <source>DTIC Document</source>
        <snippet status="partial" source="scholar.google.com">Abstract: In this paper we examine an alternative interface for phonetic search, namely query-by-example, that avoids OOV issues associated with both standard word-based and phonetic search methods. We develop three methods that compare query lattices derived ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:_3eUqOaQ984J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>17</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14913548011405867007&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>17</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14913548011405867007&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4960495</url>
        <title status="complete" source="scholar.google.com">Latent topic modelling of word co-occurence information for spoken document retrieval</title>
        <pdf>http://berlin.csie.ntnu.edu.tw/Berlin_Research/Talks/20090504-ntust-WTM.pdf</pdf>
        <author status="complete" source="scholar.google.com">B Chen</author>
        <proceeding status="partial" source="scholar.google.com">Acoustics, Speech and Signal Processing, 2009. &#8230;</proceeding>
        <year>2009</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract In this paper, we present a word topic model (WTM) approach, discovering the co-occurrence relationship between words as well as the long-span latent topic information, for spoken document retrieval (SDR). A given document as a whole is modeled as a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ctKyMSiww50J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11368123571092247154&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>16</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11368123571092247154&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5373341</url>
        <title status="complete" source="scholar.google.com">Query-by-example spoken term detection for OOV terms</title>
        <pdf>http://old-site.clsp.jhu.edu/~carolinap/papers/qbye_oovs_asru_09.pdf</pdf>
        <author status="partial" source="scholar.google.com">C Parada, A Sethy&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; Speech Recognition &amp; &#8230;</proceeding>
        <year>2009</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract The goal of spoken term detection (STD) technology is to allow open vocabulary search over large collections of speech content. In this paper, we address cases where search term (s) of interest (queries) are acoustic examples. This is provided either by ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Cxu9AzmFDpMJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10596553453171710731&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>16</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10596553453171710731&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <title status="complete" source="scholar.google.com">Improved speech summarization with multiple-hypothesis representations and Kullback-Leibler divergence measures</title>
        <pdf>http://berlin.csie.ntnu.edu.tw/Berlin_Research/manuscripts/2009/p15635.pdf</pdf>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:CKnxajmjhS4J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3352264964649888008&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>16</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3352264964649888008&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.springerlink.com/index/b216521113704351.pdf</url>
        <title status="complete" source="scholar.google.com">Beyond shot retrieval: Searching for broadcast news items using language models of concepts</title>
        <pdf>http://doc.utwente.nl/71235/1/story-event-searching.pdf</pdf>
        <author status="complete" source="scholar.google.com">R Aly, A Doherty, D Hiemstra, A Smeaton</author>
        <proceeding status="partial" source="scholar.google.com">Advances in Information &#8230;</proceeding>
        <year>2010</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. Current video search systems commonly return video shots as results. We believe that users may better relate to longer, semantic video units and propose a retrieval framework for news story items, which consist of multiple shots. The framework is divided ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:k-l_EV2t1ikJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3014787615808285075&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3014787615808285075&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://dl.acm.org/citation.cfm?id=1858005</url>
        <title status="complete" source="scholar.google.com">Using confusion networks for speech summarization</title>
        <pdf>http://www.aclweb.org/anthology-new/N/N10/N10-1006.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Xie, Y Liu</author>
        <proceeding status="partial" source="scholar.google.com">Human Language Technologies: The 2010 Annual &#8230;</proceeding>
        <year>2010</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract For extractive meeting summarization, previous studies have shown performance degradation when using speech recognition transcripts because of the relatively high speech recognition errors on meeting recordings. In this paper we investigated using ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:fHjhIG3K6BAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1218446269255612540&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1218446269255612540&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://dl.acm.org/citation.cfm?id=1871568</url>
        <title status="complete" source="scholar.google.com">Faceted search and browsing of audio content on spoken web</title>
        <author status="partial" source="scholar.google.com">M Diao, S Mukherjea, N Rajput&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the 19th &#8230;</proceeding>
        <year>2010</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Spoken Web is a web of VoiceSites that can be accessed by a phone. The content in a VoiceSite is audio. Therefore Spoken Web provides an alternate to the World Wide Web (WWW) in developing regions where low Internet penetration and low literacy are barriers ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:V6PZb5KHNaEJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11616339876883571543&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5549862</url>
        <title status="complete" source="scholar.google.com">Leveraging KullbackâLeibler Divergence Measures and Information-Rich Cues for Speech Summarization</title>
        <pdf>http://140.122.185.120/Berlin_Research/Manuscripts/2011-/2011-IEEEASLP-Leveraging%20Kullback%E2%80%93Leibler%20Divergence%20Measures%20and%20Information-Rich%20Cues%20for%20Speech%20Summarization%20.pdf</pdf>
        <author status="complete" source="scholar.google.com">SH Lin, YM Yeh, B Chen</author>
        <proceeding status="partial" source="scholar.google.com">Audio, Speech, and Language &#8230;</proceeding>
        <year>2011</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Imperfect speech recognition often leads to degraded performance when exploiting conventional text-based methods for speech summarization. To alleviate this problem, this paper investigates various ways to robustly represent the recognition hypotheses of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:pbBosAIbHOcJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16653215220472787109&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16653215220472787109&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4777895</url>
        <title status="complete" source="scholar.google.com">Phonetic name matching for cross-lingual spoken sentence retrieval</title>
        <pdf>http://www.speech.sri.com/people/wwang/papers/slt2008-clssr.pdf</pdf>
        <author status="complete" source="scholar.google.com">H Ji, R Grishman, W Wang</author>
        <proceeding status="partial" source="scholar.google.com">Spoken Language Technology &#8230;</proceeding>
        <year>2008</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Cross-lingual spoken sentence retrieval (CLSSR) remains a challenge, especially for queries including OOV words such as person names. This paper proposes a simple method of fuzzy matching between query names and phones of candidate audio ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:AhDSzedws8AJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13885566217006223362&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13885566217006223362&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://doc.utwente.nl/72019/1/thesis_R_Aly.pdf</url>
        <title status="complete" source="scholar.google.com">Modeling representation uncertainty in concept-based multimedia retrieval</title>
        <pdf>http://doc.utwente.nl/72019/1/thesis_R_Aly.pdf</pdf>
        <author status="complete" source="scholar.google.com">RBN Aly</author>
        <year>2010</year>
        <source>doc.utwente.nl</source>
        <snippet status="partial" source="scholar.google.com">This thesis considers concept-based multimedia retrieval, where documents are represented by the occurrence of concepts (also referred to as semantic concepts or high-level features). A concept can be thought of as a kind of label, which is attached to (parts ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:gpmjO3XDCdoJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15711303683337853314&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15711303683337853314&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4777899</url>
        <title status="complete" source="scholar.google.com">A similar content retrieval method for podcast episodes</title>
        <pdf>http://cl.naist.jp/~junta-m/slt2008_thesis.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Mizuno, J Ogata, M Goto</author>
        <proceeding status="partial" source="scholar.google.com">Spoken Language Technology &#8230;</proceeding>
        <year>2008</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Given podcasts (audio blogs) that are sets of speech files called episodes, this paper describes a method for retrieving episodes that have similar content. Although most previous retrieval methods were based on bibliographic information, tags, or users&#39; ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:E-cgelwjin0J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9046081681620002579&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9046081681620002579&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5983479</url>
        <title status="complete" source="scholar.google.com">Performance analysis and improvement of Turkish broadcast news retrieval</title>
        <author status="complete" source="scholar.google.com">S Parlak, M Saraclar</author>
        <proceeding status="partial" source="scholar.google.com">Audio, Speech, and Language &#8230;</proceeding>
        <year>2012</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper presents our work on the retrieval of spoken information in Turkish. Traditional speech retrieval systems perform indexing and retrieval over automatic speech recognition (ASR) transcripts, which include errors either because of out-of-vocabulary ( ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:hXB11beKsgwJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=914946196474523781&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=914946196474523781&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="13">
        <url>http://dl.acm.org/citation.cfm?id=1963364</url>
        <title status="complete" source="scholar.google.com">Two-stream indexing for spoken web search</title>
        <pdf>http://wwwconference.org/proceedings/www2011/companion/p503.pdf</pdf>
        <author status="partial" source="scholar.google.com">J Ajmera, A Joshi, S Mukherjea, N Rajput&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the 20th &#8230;</proceeding>
        <year>2011</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper presents two-stream processing of audio to index the audio content for Spoken Web search. The first stream indexes the meta-data associated with a particular audio document. The meta-data is usually very sparse, but accurate. This therefore results ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:sueNDEnHSBMJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1389579601600964530&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1389579601600964530&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="14">
        <url>http://dl.acm.org/citation.cfm?id=1631129</url>
        <title status="complete" source="scholar.google.com">Topic modeling for spoken document retrieval using word-and syllable-level information</title>
        <pdf>http://kusu.comp.nus.edu/proceedings/mm09/sscs/p3.pdf</pdf>
        <author status="complete" source="scholar.google.com">SH Lin, B Chen</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the third workshop on Searching &#8230;</proceeding>
        <year>2009</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Topic modeling for information retrieval (IR) has attracted significant attention and demonstrated good performance in a wide variety of tasks over the years. In this article, we first present a comprehensive comparison among various topic modeling approaches, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FyBocJOpz2QJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7264211174683058199&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7264211174683058199&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="15">
        <url>http://dl.acm.org/citation.cfm?id=2328971</url>
        <title status="complete" source="scholar.google.com">Comparison of methods for language-dependent and language-independent Query-by-Example spoken term detection</title>
        <author status="partial" source="scholar.google.com">J Tejedor, M FapÅ¡o, I SzÃ¶ke, J ÄernockÃ½&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">ACM Transactions on &#8230;</proceeding>
        <year>2012</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract This article investigates query-by-example (QbE) spoken term detection (STD), in which the query is not entered as text, but selected in speech data or spoken. Two feature extractors based on neural networks (NN) are introduced: the first producing phone-state ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:J6VCnDfmiIIJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9406020948282484007&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="16">
        <url>http://www.hlt.utdallas.edu/~shasha/dissertation/dissertation.pdf</url>
        <title status="complete" source="scholar.google.com">Automatic extractive summarization on meeting corpus</title>
        <pdf>http://www.hlt.utdallas.edu/~shasha/dissertation/dissertation.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Xie, Y Liu, JHL Hansen, S Harabagiu, V Ng</author>
        <year>2010</year>
        <source>hlt.utdallas.edu</source>
        <snippet status="partial" source="scholar.google.com">This dissertation (or thesis) was produced in accordance with guidelines which permit the inclusion as part of the dissertation (or thesis) the text of an original paper or papers submitted for publication. The dissertation (or thesis) must still conform to all other ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:wmLhV3iFjasJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:wmLhV3iFjasJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12361683304118837954&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12361683304118837954&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="17">
        <url>http://eprints2008.lib.hokudai.ac.jp/dspace/handle/2115/39702</url>
        <title status="complete" source="scholar.google.com">Query-by-Example Spoken Document Retrieval: The Star Challenge 2008</title>
        <pdf>http://eprints2008.lib.hokudai.ac.jp/dspace/bitstream/2115/39702/1/TA-SS1-1.pdf</pdf>
        <author status="complete" source="scholar.google.com">H Li, KC Sim, V Singh, KM Lye</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; : APSIPA ASC 2009 &#8230;</proceeding>
        <year>2009</year>
        <source>eprints2008.lib.hokudai.ac.jp</source>
        <snippet status="partial" source="scholar.google.com">In this paper, we give an update of recent research activities in HLT department of I2R in query-by-example spoken document retrieval (SDR) and report an evaluation campaign, the Star Challenge 2008, which was organized by A* STAR, Singapore. It is suggested that ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ccf-4HCqDOMJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16360638948118022001&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16360638948118022001&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="18">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5372952</url>
        <title status="complete" source="scholar.google.com">Voice-based information retrievalâhow far are we from the text-based information retrieval?</title>
        <pdf>http://speech.ee.ntu.edu.tw/~RA/lab/html/thesis/Voice-based%20Information%20Retrieval_981016.pdf</pdf>
        <author status="complete" source="scholar.google.com">L Lee, Y Pan</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; &amp; Understanding, 2009. ASRU 2009. IEEE &#8230;</proceeding>
        <year>2009</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Although network content access is primarily text-based today, almost all roles of text can be accomplished by voice. Voice-based information retrieval refers to the situation that the user query and/or the content to be retried are in form of voice. This paper tries to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FcLb6V5FeokJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9906306604307563029&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9906306604307563029&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="19">
        <url>http://filebox.vt.edu/users/skhater/CS5604/hw01.pdf</url>
        <title status="complete" source="scholar.google.com">HW01 for CS5604, Information Storage and Retrieval, Spring 2012</title>
        <pdf>http://filebox.vt.edu/users/skhater/CS5604/hw01.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Khater</author>
        <proceeding status="complete" source="scholar.google.com">Information Storage and Retrieval</proceeding>
        <year>2012</year>
        <source>filebox.vt.edu</source>
        <snippet status="partial" source="scholar.google.com">B. Summary This paper discusses the issue of spoken document retrieval. The paper first described two different ways of document re- trieval. One way is to run 1-best automatic speech recognition (ASR) transcripts of spoken documents for retrieval. However, it was found that 1-best ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2sU4GIsSAwYJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:2sU4GIsSAwYJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="20">
        <url>http://dl.acm.org/citation.cfm?id=2348392</url>
        <title status="complete" source="scholar.google.com">Content-based retrieval for heterogeneous domains: domain adaptation by relative aggregation points</title>
        <pdf>http://www.mpkato.net/wp-content/uploads/2012/08/fp070-kato.pdf</pdf>
        <author status="complete" source="scholar.google.com">MP Kato, H Ohshima, K Tanaka</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; of the 35th international ACM SIGIR &#8230;</proceeding>
        <year>2012</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract We introduce the problem of domain adaptation for content-based retrieval and propose a domain adaptation method based on relative aggregation points (RAPs). Content-based retrieval including image retrieval and spoken document retrieval enables a user to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Udc9IqNUe2cJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7456646667672868689&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="21">
        <url>http://dl.acm.org/citation.cfm?id=2063840</url>
        <title status="complete" source="scholar.google.com">Social ranking for spoken web search</title>
        <author status="complete" source="scholar.google.com">S Sahay, N Rajput, N Pansare</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the 20th ACM &#8230;</proceeding>
        <year>2011</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Spoken Web is an alternative Web for low-literacy users in the developing world. People can create audio content over phone and share on the Spoken Web. This enables easy creation of locally relevant content. Even on the World Wide Web in developed ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2mxtONRMxO8J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17277018544863538394&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="22">
        <url>http://www.springerlink.com/index/301257252827313q.pdf</url>
        <title status="complete" source="scholar.google.com">The uncertain representation ranking framework for concept-based video retrieval</title>
        <pdf>http://doras.dcu.ie/17144/1/urr-framework.pdf</pdf>
        <author status="partial" source="scholar.google.com">R Aly, A Doherty, D Hiemstra, F de Jong&#8230;</author>
        <proceeding status="complete" source="scholar.google.com">Information Retrieval</proceeding>
        <year>2012</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract Concept based video retrieval often relies on imperfect and uncertain concept detectors. We propose a general ranking framework to define effective and robust ranking functions, through explicitly addressing detector uncertainty. It can cope with multiple ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:he5JOv1q-eAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16211105969534004869&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="23">
        <url>http://140.109.19.106/clclp/v17n1/v17n1a4.pdf</url>
        <title status="complete" source="scholar.google.com">A Comparative Study of Methods for Topic Modeling in Spoken Document Retrieval</title>
        <pdf>http://140.109.19.106/clclp/v17n1/v17n1a4.pdf</pdf>
        <author status="complete" source="scholar.google.com">SH Lin, B Chen</author>
        <proceeding status="complete" source="scholar.google.com">ä¸­æè¨ç®èªè¨å­¸æå</proceeding>
        <year>2012</year>
        <source>140.109.19.106</source>
        <snippet status="partial" source="scholar.google.com">Abstract Topic modeling for information retrieval (IR) has attracted significant attention and demonstrated good performance in a wide variety of tasks over the years. In this paper, we first present a comprehensive comparison of various topic modeling approaches, ...</snippet>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:bhOyT1IbowgJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="24">
        <url>http://cs.iupui.edu/~alhasan/papers/fp006-bhuiyan.pdf</url>
        <title status="complete" source="scholar.google.com">Interactive Pattern Mining on Hidden Data: A Sampling-based Solution</title>
        <pdf>http://cs.iupui.edu/~alhasan/papers/fp006-bhuiyan.pdf</pdf>
        <author status="complete" source="scholar.google.com">M Bhuiyan, S Mukhopadhyay, M Al Hasan</author>
        <year>2012</year>
        <source>cs.iupui.edu</source>
        <snippet status="partial" source="scholar.google.com">ABSTRACT Mining frequent patterns from a hidden dataset is an important task with various real-life applications. In this research, we propose a solution to this problem that is based on Markov Chain Monte Carlo (MCMC) sampling of frequent patterns. Instead of returning all ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:sft0XDGicwsJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:sft0XDGicwsJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=825181489627200433&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="25">
        <url>http://www.searchingspeech.org/sscs2008/sscs08_proceedings.pdf#page=6</url>
        <title status="complete" source="scholar.google.com">Query-by-Example Spoken Document Retrieval</title>
        <pdf>http://www.searchingspeech.org/sscs2008/sscs08_proceedings.pdf#page=6</pdf>
        <author status="complete" source="scholar.google.com">H Li</author>
        <proceeding status="partial" source="scholar.google.com">CIP GEGEVENS KONINKLIJKE BIBLIOTHEEK, DEN &#8230;</proceeding>
        <year>2008</year>
        <source>searchingspeech.org</source>
        <snippet status="partial" source="scholar.google.com">Query-by-Example Spoken Document Retrieval Haizhou Li Institute for Infocomm Research (I2R) Agency for Science, Technology and Research (A* STAR), Singapore. hli@ i2r. a-star. edu. sg 1. INTRODUCTION In this presentation, we gave an overview of ongoing ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:kfYvZLN7uOgJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:kfYvZLN7uOgJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16769289222924269201&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="26">
        <url>http://www.ll.mit.edu/mission/communications/publications/publication-files/book_chapter/2011_05_03_Hazen_Speech_Retrieval_FP.pdf</url>
        <title status="complete" source="scholar.google.com">Speech Retrieval</title>
        <pdf>http://www.ll.mit.edu/mission/communications/publications/publication-files/book_chapter/2011_05_03_Hazen_Speech_Retrieval_FP.pdf</pdf>
        <author status="partial" source="scholar.google.com">C Chelba, TJ Hazen, B Ramabhadran&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; : Systems for Extracting &#8230;</proceeding>
        <year>2011</year>
        <source>ll.mit.edu</source>
        <snippet status="partial" source="scholar.google.com">Abstract In this chapter we discuss the retrieval and browsing of spoken audio documents. We focus primarily on the application of document search where a user provides a query and the system returns a set of audio documents that best match the query. The primary ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2CdPl8Mgm0oJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:2CdPl8Mgm0oJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5375926604626077656&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="27">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5593872</url>
        <title status="complete" source="scholar.google.com">Using N-Best Lists and Confusion Networks for Meeting Summarization</title>
        <author status="complete" source="scholar.google.com">S Xie, Y Liu</author>
        <proceeding status="partial" source="scholar.google.com">Audio, Speech, and Language Processing, IEEE &#8230;</proceeding>
        <year>2011</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract The incorrect speech recognition results usually have a negative impact on the speech summarization task, especially on the meeting domain where the word error rate is often higher than other speech genres. In this paper we investigate using rich speech ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:fqPw2q5RoDAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3503890321533608830&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="1">
    <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5372910</url>
    <title status="complete" source="scholar.google.com">Discriminative product-of-expert acoustic mapping for cross-lingual phone recognition</title>
    <pdf>https://wiki.inf.ed.ac.uk/twiki/pub/CSTR/ListenSemester2_2009_10/AS090050.pdf</pdf>
    <author status="complete" source="scholar.google.com">KC Sim</author>
    <proceeding status="partial" source="scholar.google.com">&#8230; Speech Recognition &amp; Understanding, 2009. ASRU &#8230;</proceeding>
    <year>2009</year>
    <source>ieeexplore.ieee.org</source>
    <snippet status="partial" source="scholar.google.com">... Khe Chai Sim #* # National University of Singapore, Singapore Computing 1, 13 ComputingDrive, Singapore 117417 simkc@comp.nus.edu.sg â Institute for Infocomm Research, Singapore1 Fusionopolis Way, #21-01 Connexis, Singapore 138632 kcsim@i2r.a-star.edu.sg ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:WpeAYmCAAX8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>2</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=9151737069251368794&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>5</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=9151737069251368794&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="5">
        <result id="0">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6163959</url>
        <title status="complete" source="scholar.google.com">Regularized subspace Gaussian mixture models for cross-lingual speech recognition</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.221.3757&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">L Lu, A Ghoshal, S Renals</author>
        <proceeding status="partial" source="scholar.google.com">Automatic Speech Recognition &#8230;</proceeding>
        <year>2011</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract We investigate cross-lingual acoustic modelling for low resource languages using the subspace Gaussian mixture model (SGMM). We assume the presence of acoustic models trained on multiple source languages, and use the global subspace parameters ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:_02CfqQ-U3cJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8598284989798436351&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8598284989798436351&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.comp.nus.edu.sg/~li-bo/papers/is10_0526_adapt.pdf</url>
        <title status="complete" source="scholar.google.com">Comparison of Discriminative Input and Output Transformations for Speaker Adaptation in the Hybrid NN/HMM Systems</title>
        <pdf>http://www.comp.nus.edu.sg/~li-bo/papers/is10_0526_adapt.pdf</pdf>
        <author status="complete" source="scholar.google.com">B Li, KC Sim</author>
        <proceeding status="partial" source="scholar.google.com">Eleventh Annual Conference of the International &#8230;</proceeding>
        <year>2010</year>
        <source>comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract Speaker variability is one of the major error sources for ASR systems. Speaker adaptation estimates speaker specific models from the speaker independent ones to minimize the mismatch between the training and testing conditions arisen from speaker ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:mUDhGkSR5g4J:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1073705282869215385&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1073705282869215385&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.comp.nus.edu.sg/~wang86/Joey_files/papers/seq.pdf</url>
        <title status="complete" source="scholar.google.com">Sequential Classification Criteria for NNs in Automatic Speech Recognition</title>
        <pdf>http://www.comp.nus.edu.sg/~wang86/Joey_files/papers/seq.pdf</pdf>
        <author status="complete" source="scholar.google.com">W Guangsen, KC Sim</author>
        <year>2011</year>
        <source>comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract Neural networks (NNs) are discriminative classifiers which have been successfully integrated with hidden Markov models (HMMs), either in the hybrid NN/HMM or tandem connectionist systems. Typically, the NNs are trained with the framebased cross-entropy ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:F3ht8Y8vYMEJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13934189542361626647&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13934189542361626647&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.comp.nus.edu.sg/~wang86/Joey_files/papers/smth.pdf</url>
        <title status="complete" source="scholar.google.com">Comparison of Smoothing Techniques for Robust Context Dependent Acoustic Modelling in Hybrid NN/HMM Systems</title>
        <pdf>http://www.comp.nus.edu.sg/~wang86/Joey_files/papers/smth.pdf</pdf>
        <author status="complete" source="scholar.google.com">W Guangsen, KC Sim</author>
        <year>2011</year>
        <source>comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract Hybrid Neural Network/Hidden Markov Model (NN/HMM) systems have been found to yield high quality phone recognition performance. One issue with modelling the Context Dependent (CD) NN/HMM is the robust estimation of the NN parameters to reliably predict ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:fIHT4FxqRNUJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15367524775636468092&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://homepages.inf.ed.ac.uk/llu/pdf/llu_2nd_year_report.pdf</url>
        <title status="complete" source="scholar.google.com">Robust Estimation and Adaptation of Subspace Gaussian Mixture Models for Automatic Speech Recognition</title>
        <pdf>http://homepages.inf.ed.ac.uk/llu/pdf/llu_2nd_year_report.pdf</pdf>
        <author status="complete" source="scholar.google.com">L Lu</author>
        <year>2011</year>
        <source>homepages.inf.ed.ac.uk</source>
        <snippet status="partial" source="scholar.google.com">Abstract In conventional hidden Markov model (HMM) based speech recognisers, the emitting HMM states are modelled by Gaussian Mixture Models (GMMs), with parameters been estimated directly from the training data. However, in Subspace Gaussian mixture ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:CucG9PBTuEUJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:CucG9PBTuEUJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="2">
    <url>http://www.comp.nus.edu.sg/~wang86/Joey_files/papers/seq.pdf</url>
    <title status="complete" source="scholar.google.com">Sequential Classification Criteria for NNs in Automatic Speech Recognition</title>
    <pdf>http://www.comp.nus.edu.sg/~wang86/Joey_files/papers/seq.pdf</pdf>
    <author status="complete" source="scholar.google.com">W Guangsen, KC Sim</author>
    <year>2011</year>
    <source>comp.nus.edu.sg</source>
    <snippet status="partial" source="scholar.google.com">Sequential Classification Criteria for NNs in Automatic Speech Recognition Guangsen WANG,Khe Chai SIM School of Computing, National University of Singapore COM1, 13 Computing Drive,Singapore 117417 wangguangsen@comp.nus.edu.sg, simkc@comp.nus.edu.sg ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:F3ht8Y8vYMEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>3</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=13934189542361626647&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=13934189542361626647&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://www.kky.zcu.cz/cs/publications/1/JanTrmal_2012_Spatio-temporal.pdf</url>
        <title status="complete" source="scholar.google.com">ZÃ¡padoceskÃ¡ univerzita v Plzni Fakulta aplikovanÃ½ch ved</title>
        <pdf>http://www.kky.zcu.cz/cs/publications/1/JanTrmal_2012_Spatio-temporal.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Trmal</author>
        <proceeding status="complete" source="scholar.google.com">kky.zcu.cz</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstrakt Tato prÃ¡ce se zabÃ½vÃ¡ metodikou adaptace neuronovÃ½ch sÄ±tÄ± a na recnÄ±ku adaptivnÄ±m trÃ©novÃ¡nÄ±m neuronovÃ½ch sÄ±tÄ± pro systÃ©my automatickÃ©ho rozpoznÃ¡vÃ¡nÄ± reci. Obe tyto technologie, tedy jak adaptace, tak na recnÄ±ku adaptivnÄ± trÃ©novÃ¡nÄ± jsou v oboru ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:LH0FJw0F0QYJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:LH0FJw0F0QYJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=491179388407479596&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="3">
    <url>http://dl.acm.org/citation.cfm?id=1658379</url>
    <title status="complete" source="scholar.google.com">Statistical lattice-based spoken document retrieval</title>
    <pdf>http://cmsassets.comp.nus.edu.sg/~nght/pubs/tois10.pdf</pdf>
    <author status="complete" source="scholar.google.com">TK Chia, KC Sim, H Li, HT Ng</author>
    <proceeding status="partial" source="scholar.google.com">ACM Transactions on Information &#8230;</proceeding>
    <year>2010</year>
    <source>dl.acm.org</source>
    <snippet status="partial" source="scholar.google.com">... Authors&#39; addresses: TK Chia and HT Ng, Department of Computer Science, National Universityof Singapore, 13 Computing Drive, Singapore 117417; email: chiateek@comp.nus.edu.sg; KCSim and H. Li, Institute for Infocomm Research, 1 Fusionopolis Way, Singapore 138632 ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:zYmAL7Kz8-cJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>11</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=16713900219984546253&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>9</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=16713900219984546253&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="9">
        <result id="0">
        <url>http://dl.acm.org/citation.cfm?id=2036917</url>
        <title status="complete" source="scholar.google.com">Speech retrieval from unsegmented finnish audio using statistical morpheme-like units for segmentation, recognition, and retrieval</title>
        <author status="complete" source="scholar.google.com">VT Turunen, M Kurimo</author>
        <proceeding status="partial" source="scholar.google.com">ACM Transactions on Speech and Language &#8230;</proceeding>
        <year>2011</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract This article examines the use of statistically discovered morpheme-like units for Spoken Document Retrieval (SDR). The morpheme-like units (morphs) are used both for language modeling in speech recognition and as index terms. Traditional word-based ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:TYuCTpwI6xoJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1939653531938229069&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6163963</url>
        <title status="complete" source="scholar.google.com">Query modeling for spoken document retrieval</title>
        <pdf>http://www.iis.sinica.edu.tw/~kychen/resource/ASRU2011-SDR-Poster.pdf</pdf>
        <author status="complete" source="scholar.google.com">B Chen, PN Chen, KY Chen</author>
        <proceeding status="partial" source="scholar.google.com">Automatic Speech Recognition &#8230;</proceeding>
        <year>2011</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Spoken document retrieval (SDR) has recently become a more interesting research avenue due to increasing volumes of publicly available multimedia associated with speech information. Many efforts have been devoted to developing elaborate indexing and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:xB_tpzEW5G0J:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7918478447350718404&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7918478447350718404&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5684847</url>
        <title status="complete" source="scholar.google.com">Improving the informativeness of verbose queries using summarization techniques for spoken document retrieval</title>
        <author status="complete" source="scholar.google.com">SH Lin, B Chen, EE Jan</author>
        <proceeding status="partial" source="scholar.google.com">Chinese Spoken Language &#8230;</proceeding>
        <year>2010</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Query-by-example information retrieval aims at helping users to find relevant documents accurately when users provide specific query exemplars describing what they are interested in. The query exemplars are usually long and in the form of either a partial ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FtlItvlK-50J:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11383774919474600214&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11383774919474600214&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6065473</url>
        <title status="complete" source="scholar.google.com">A Lattice-Based Method for Keyword Spotting in Online Chinese Handwriting</title>
        <pdf>http://www.icdar2011.org/fileup/PDF/4520b064.pdf</pdf>
        <author status="complete" source="scholar.google.com">H Zhang, CL Liu</author>
        <proceeding status="partial" source="scholar.google.com">Document Analysis and Recognition (ICDAR &#8230;</proceeding>
        <year>2011</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper proposes a lattice-based method for keyword spotting in online Chinese handwriting to improve the trade-off between accuracy and speed, and to overcome the out-of-vocabulary (OOV) problem of lexicon-driven approach. Using a character string ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:zE7kzqcCuZAJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10428369331906957004&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10428369331906957004&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6239571</url>
        <title status="complete" source="scholar.google.com">Spoken Document Retrieval With Unsupervised Query Modeling Techniques</title>
        <author status="partial" source="scholar.google.com">B Chen, KY Chen, PN Chen&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Audio, Speech, and &#8230;</proceeding>
        <year>2012</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Ever-increasing amounts of publicly available multimedia associated with speech information have motivated spoken document retrieval (SDR) to be an active area of intensive research in the speech processing community. Much work has been dedicated ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:0a7KBpuTOQcJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5947617</url>
        <title status="complete" source="scholar.google.com">Handling verbose queries for spoken document retrieval</title>
        <pdf>http://140.124.72.88/lab/ICASSP2011/pdfs/0005552.pdf</pdf>
        <author status="complete" source="scholar.google.com">SH Lin, EE Jan, B Chen</author>
        <proceeding status="partial" source="scholar.google.com">Acoustics, Speech and Signal &#8230;</proceeding>
        <year>2011</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Query-by-example information retrieval provides users a flexible but efficient way to accurately describe their information needs. The query exemplars are usually long and in the form of either a partial or even a full document. However, they may contain extraneous ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1c6pN_z3xGwJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7837661914169200341&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://dx.doi.org/10.1561/1500000020</url>
        <title status="complete" source="scholar.google.com">Automatic Summarization</title>
        <author status="complete" source="scholar.google.com">M Larson</author>
        <proceeding status="complete" source="scholar.google.com">Foundations and TrendsÂ® in Information Retrieval</proceeding>
        <year>2011</year>
        <source>dx.doi.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Speech media, ie, digital audio and video containing spoken content, has blossomed in recent years. Large collections are accruing on the Internet as well as in private and enterprise settings. This growth has motivated extensive research work on ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:W3ZDjicVdc4J:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://search.ieice.org/bin/summary.php?id=e95-d_5_1195</url>
        <title status="complete" source="scholar.google.com">Spoken Document Retrieval Leveraging Unsupervised and Supervised Topic Modeling Techniques</title>
        <pdf>http://www.iis.sinica.edu.tw/papers/whm/13802-F.pdf</pdf>
        <author status="complete" source="scholar.google.com">C Kuan-Yu, W Hsin-Min, C Berlin</author>
        <proceeding status="partial" source="scholar.google.com">IEICE TRANSACTIONS on &#8230;</proceeding>
        <year>2012</year>
        <source>search.ieice.org</source>
        <snippet status="partial" source="scholar.google.com">This paper describes the application of two attractive categories of topic modeling techniques to the problem of spoken document retrieval (SDR), viz. document topic model (DTM) and word topic model (WTM). Apart from using the conventional unsupervised ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:wFe_pjqFa_sJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18116720412980107200&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://doras.dcu.ie/17158/1/1500000020.pdf</url>
        <title status="complete" source="scholar.google.com">Spoken content retrieval: A survey of techniques and technologies</title>
        <pdf>http://doras.dcu.ie/17158/1/1500000020.pdf</pdf>
        <author status="complete" source="scholar.google.com">M Larson, GJF Jones</author>
        <proceeding status="partial" source="scholar.google.com">Foundations and Trends in Information &#8230;</proceeding>
        <year>2012</year>
        <source>doras.dcu.ie</source>
        <snippet status="partial" source="scholar.google.com">Speech media, that is, digital audio and video containing spoken content, has blossomed in recent years. Large collections are accruing on the Internet as well as in private and enterprise settings. This growth has motivated extensive research on techniques and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cwFs6jfv9hMJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:cwFs6jfv9hMJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1438600154426638707&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1438600154426638707&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="4">
    <url>http://www.eee.bham.ac.uk/SLaTE2009/papers/SLaTE2009-05-v2.pdf</url>
    <title status="complete" source="scholar.google.com">Improving phone verification using state-level posterior features and support vector machine for automatic mispronunciation detection</title>
    <pdf>http://www.eee.bham.ac.uk/SLaTE2009/papers/SLaTE2009-05-v2.pdf</pdf>
    <author status="complete" source="scholar.google.com">KC Sim</author>
    <proceeding status="complete" source="scholar.google.com">Proc. SLaTE</proceeding>
    <year>2009</year>
    <source>eee.bham.ac.uk</source>
    <snippet status="partial" source="scholar.google.com">... Machine for Automatic Mispronunciation Detection Khe Chai SIM School of Computing,Department of Computer Science National University of Singapore, Singapore.simkc@comp.nus.edu.sg Abstract An important aspect of a ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:IV2pBS9d6jAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:IV2pBS9d6jAJ:scholar.google.com/+author:%22Sim+Khe+Chai%22+NUS&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <numVersions>3</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=3524732114910666017&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>2</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=3524732114910666017&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="2">
        <result id="0">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5495609</url>
        <title status="complete" source="scholar.google.com">A minimum variance asynchronous Detection Error Trade-off performance analysis for multi-class detection problems</title>
        <author status="complete" source="scholar.google.com">KC Sim</author>
        <proceeding status="partial" source="scholar.google.com">Acoustics Speech and Signal Processing (ICASSP), &#8230;</proceeding>
        <year>2010</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract In a detection problem, the trade-off between the miss and false alarm probabilities are often shown as a Detection Error Trade-off (DET) curve. The DET curve is obtained by adjusting a decision threshold to vary the compromise between these probabilities. For a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:SwkILLZK9NAJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15056741600489638219&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.comp.nus.edu.sg/~li-bo/papers/is10_2614_phnvrf.pdf</url>
        <title status="complete" source="scholar.google.com">Hidden Logistic Linear Regression for Support Vector Machine based Phone Verification</title>
        <pdf>http://www.comp.nus.edu.sg/~li-bo/papers/is10_2614_phnvrf.pdf</pdf>
        <author status="complete" source="scholar.google.com">B Li, KC Sim</author>
        <proceeding status="partial" source="scholar.google.com">Eleventh Annual Conference of the International &#8230;</proceeding>
        <year>2010</year>
        <source>comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract Phone verification approach to mispronunciation detection using a combination of Neural Network (NN) and Support Vector Machine (SVM) has been shown to yield improved verification performance. This approach uses a NN to predict the HMM state posterior ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:5sl5gxTMHekJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16797806573639027174&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="5">
    <url>http://www.comp.nus.edu.sg/~li-bo/papers/is10_0526_adapt.pdf</url>
    <title status="complete" source="scholar.google.com">Comparison of Discriminative Input and Output Transformations for Speaker Adaptation in the Hybrid NN/HMM Systems</title>
    <pdf>http://www.comp.nus.edu.sg/~li-bo/papers/is10_0526_adapt.pdf</pdf>
    <author status="complete" source="scholar.google.com">B Li, KC Sim</author>
    <proceeding status="partial" source="scholar.google.com">Eleventh Annual Conference of the International &#8230;</proceeding>
    <year>2010</year>
    <source>comp.nus.edu.sg</source>
    <snippet status="partial" source="scholar.google.com">... Adaptation in the Hybrid NN/HMM Systems Bo Li, Khe Chai Sim School of Computing,National University of Singapore 1 Computing, 13 Computing Drive, Singapore117417 {li-bo, simkc}@comp.nus.edu.sg Abstract Speaker ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:mUDhGkSR5g4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>3</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=1073705282869215385&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=1073705282869215385&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://www.kky.zcu.cz/cs/publications/1/JanTrmal_2012_Spatio-temporal.pdf</url>
        <title status="complete" source="scholar.google.com">ZÃ¡padoceskÃ¡ univerzita v Plzni Fakulta aplikovanÃ½ch ved</title>
        <pdf>http://www.kky.zcu.cz/cs/publications/1/JanTrmal_2012_Spatio-temporal.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Trmal</author>
        <proceeding status="complete" source="scholar.google.com">kky.zcu.cz</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstrakt Tato prÃ¡ce se zabÃ½vÃ¡ metodikou adaptace neuronovÃ½ch sÄ±tÄ± a na recnÄ±ku adaptivnÄ±m trÃ©novÃ¡nÄ±m neuronovÃ½ch sÄ±tÄ± pro systÃ©my automatickÃ©ho rozpoznÃ¡vÃ¡nÄ± reci. Obe tyto technologie, tedy jak adaptace, tak na recnÄ±ku adaptivnÄ± trÃ©novÃ¡nÄ± jsou v oboru ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:LH0FJw0F0QYJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:LH0FJw0F0QYJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=491179388407479596&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="6">
    <url>http://www.comp.nus.edu.sg/~li-bo/papers/spc2011_deep.pdf</url>
    <title status="complete" source="scholar.google.com">Acoustic spatiotemporal modeling using deep machine learning for robust phoneme recognition</title>
    <pdf>http://www.comp.nus.edu.sg/~li-bo/papers/spc2011_deep.pdf</pdf>
    <author status="partial" source="scholar.google.com">I Arel, S Berant, T Slonim, A Moyal, B Li&#8230;</author>
    <proceeding status="partial" source="scholar.google.com">Afeka-AVIOS Speech &#8230;</proceeding>
    <year>2011</year>
    <source>comp.nus.edu.sg</source>
    <snippet status="partial" source="scholar.google.com">... Palo Alto, CA Email: shay,tsvi@binatix.com Ami Moyal Afeka Academic College of EngineeringTel-Aviv, Israel Email:amim@afeka.ac.il Bo Li, Khe Chai Sim Computional Lingusitics LaboratoryNational University of Singapore Email: li-bo,simkc@comp.nus.edu.sg ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:-h1YPFXQxpgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:-h1YPFXQxpgJ:scholar.google.com/+author:%22Sim+Khe+Chai%22+NUS&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <numVersions>3</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=11008715403656961530&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>2</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=11008715403656961530&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="2">
        <result id="0">
        <url>http://goertzel.org/papers/Uniform_DeSTIN_paper_v2.pdf</url>
        <title status="complete" source="scholar.google.com">Modifying the destin perception architecture to enable representationally transparent deep learning</title>
        <pdf>http://goertzel.org/papers/Uniform_DeSTIN_paper_v2.pdf</pdf>
        <author status="complete" source="scholar.google.com">B Goertzel</author>
        <year>2012</year>
        <source>goertzel.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Bridging the gap between symbolic and subsymbolic representations is aâperhaps theâkey obstacle along the path from the present state of AI technology to human-level artificial general intelligence. A companion paper to this one describes a novel approach ...</snippet>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:X6zdSjZ55kMJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4892731319275859039&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://goertzel.org/Uniform_DeSTIN_paper.pdf</url>
        <title status="complete" source="scholar.google.com">Perception Processing for General Intelligence, Part I: Representationally Transparent Deep Learning</title>
        <pdf>http://goertzel.org/Uniform_DeSTIN_paper.pdf</pdf>
        <author status="complete" source="scholar.google.com">B Goertzel</author>
        <year>2012</year>
        <source>goertzel.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Bridging the gap between symbolic and subsymbolic representations is aâperhaps theâkey obstacle along the path from the present state of AI technology to human-level artificial general intelligence. The companion paper (Part II) describes a novel approach to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Lgq0xbQEtvUJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:Lgq0xbQEtvUJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17705344159511218734&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17705344159511218734&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="7">
    <url>http://www.comp.nus.edu.sg/~yzhou86/fp047.pdf</url>
    <title status="complete" source="scholar.google.com">MOGAT: Mobile Games with Auditory Training for Children with Cochlear Implants</title>
    <pdf>http://www.comp.nus.edu.sg/~yzhou86/fp047.pdf</pdf>
    <author status="complete" source="scholar.google.com">Y Zhou, KC Sim, P Tan, Y Wang</author>
    <proceeding status="complete" source="scholar.google.com">ACM Multimedia</proceeding>
    <year>2012</year>
    <source>comp.nus.edu.sg</source>
    <snippet status="partial" source="scholar.google.com">... Yinsheng Zhou1, Khe Chai Sim1, Patsy Tan2, Ye Wang1 1School of Computing, NationalUniversity of Singapore, 117417, Singapore 2Singapore General Hospital, 169608, Singapore{yzhou86, simkc, wangye}@comp.nus.edu.sg, patsy.tan.lp@sgh.com.sg ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:4KKKkSKeXiAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:4KKKkSKeXiAJ:scholar.google.com/+author:%22Sim+Khe+Chai%22+NUS&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=2332475528332354272&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://www.comp.nus.edu.sg/~yzhou86/mtd015.pdf</url>
        <title status="complete" source="scholar.google.com">MOGAT: A Cloud-based Mobile Game System with Auditory Training for Children with Cochlear Implants</title>
        <pdf>http://www.comp.nus.edu.sg/~yzhou86/mtd015.pdf</pdf>
        <author status="complete" source="scholar.google.com">Y Zhou, TJKP Monserrat, Y Wang</author>
        <proceeding status="complete" source="scholar.google.com">comp.nus.edu.sg</proceeding>
        <snippet status="partial" source="scholar.google.com">ABSTRACT Musical auditory habilitation is an essential process in adapting cochlear implant recipients to the musical hearing context provided by cochlear implants. However, due to the cost and time limitation, it is impossible for hearing healthcare professionals to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:zzFc9vzuqioJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:zzFc9vzuqioJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="8">
    <url>http://dl.acm.org/citation.cfm?id=2388791</url>
    <title status="complete" source="scholar.google.com">Improving mandarin predictive text input by augmenting pinyin initials with speech and tonal information</title>
    <pdf>http://www.comp.nus.edu.sg/~li-bo/papers/icmi12_hvr.pdf</pdf>
    <author status="partial" source="scholar.google.com">G Wang, B Li, S Liu, X Wang, X Wang&#8230;</author>
    <proceeding status="partial" source="scholar.google.com">Proceedings of the 14th &#8230;</proceeding>
    <year>2012</year>
    <source>dl.acm.org</source>
    <snippet status="partial" source="scholar.google.com">... Guangsen Wang guangsen@comp.nus.edu.sg Bo Li libo@nus.edu.sg Shilin Liushilin.liu@comp.nus.edu.sg Xuancong Wang g0801784@nus.edu.sg Xiaoxuan Wangwangxx@comp.nus.edu.sg Khe Chai Sim simkc@comp.nus.edu.sg ...</snippet>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="9">
    <url>http://speech.ddns.comp.nus.edu.sg/hvrgrandchallenge2012/slides/ICMI_HVR_gch103_slides.pdf</url>
    <title status="complete" source="scholar.google.com">Design and implementation of the note-taking style haptic voice recognition for mobile devices</title>
    <pdf>http://speech.ddns.comp.nus.edu.sg/hvrgrandchallenge2012/slides/ICMI_HVR_gch103_slides.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Moon, KC Sim</author>
    <proceeding status="partial" source="scholar.google.com">Proceedings of the 14th ACM &#8230;</proceeding>
    <year>2012</year>
    <source>speech.ddns.comp.nus.edu.sg</source>
    <snippet status="partial" source="scholar.google.com">... Computing 1, 13 Computing Drive Singapore, Singapore 117417 simkc@nus.edu.sg 1 14th ACMInternational Conference on Multimodal Interaction ... Computing 1, 13 Computing Drive Singapore,Singapore 117417 simkc@nus.edu.sg - The End - 21 Page 22. References ...</snippet>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:oIEZFB87ZJgJ:scholar.google.com/+author:%22Sim+Khe+Chai%22+NUS&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="10">
    <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6288972</url>
    <title status="complete" source="scholar.google.com">An investigation of tied-mixture GMM based triphone state clustering</title>
    <pdf>http://www.mirlab.org/conference_papers/International_Conference/ICASSP%202012/pdfs/0004717.pdf</pdf>
    <author status="complete" source="scholar.google.com">G Wang, KC Sim</author>
    <proceeding status="partial" source="scholar.google.com">&#8230; and Signal Processing (ICASSP), 2012 IEEE &#8230;</proceeding>
    <year>2012</year>
    <source>ieeexplore.ieee.org</source>
    <snippet status="partial" source="scholar.google.com">... CLUSTERING Guangsen WANG, Khe Chai SIM School of Computing, NationalUniversity of Singapore COM1, 13 Computing Drive, Singapore 117417wangguangsen@comp.nus.edu.sg, simkc@comp.nus.edu.sg ABSTRACT ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:16N3IPeyJBQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>2</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=1451481754391520215&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="11">
    <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6163914</url>
    <title status="complete" source="scholar.google.com">A Trajectory-based Parallel Model Combination with a unified static and dynamic parameter compensation for noisy speech recognition</title>
    <author status="complete" source="scholar.google.com">KC Sim, MT Luong</author>
    <proceeding status="partial" source="scholar.google.com">Automatic Speech Recognition and &#8230;</proceeding>
    <year>2011</year>
    <source>ieeexplore.ieee.org</source>
    <snippet status="partial" source="scholar.google.com">... Khe Chai SIM #1, Minh-Thang LUONG #2 # Department of Computer Science, Schoolof Computing, National University of Singapore 13 Computing Drive, Singapore 1174171 simkc@comp.nus.edu.sg 2 luongmin@comp.nus.edu.sg ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:cE2tXLUn9rsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=13544056589260770672&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://dl.acm.org/citation.cfm?id=2388791</url>
        <title status="complete" source="scholar.google.com">Improving mandarin predictive text input by augmenting pinyin initials with speech and tonal information</title>
        <pdf>http://www.comp.nus.edu.sg/~li-bo/papers/icmi12_hvr.pdf</pdf>
        <author status="partial" source="scholar.google.com">G Wang, B Li, S Liu, X Wang, X Wang&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the 14th &#8230;</proceeding>
        <year>2012</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Recently, a new technology called Haptic Voice Recognition (HVR) was proposed to enhance the speech recognition efficiency and accuracy for modern mobile devices, which has been successfully applied for robust English voice recognition. As both Pinyin ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="12">
    <url>http://speech.ddns.comp.nus.edu.sg/HVRGrandChallenge2012/data/hvr-grand-challenge-2012-plan.pdf</url>
    <title status="complete" source="scholar.google.com">Haptic Voice Recognition (HVR) Grand Challenge 2012</title>
    <pdf>http://speech.ddns.comp.nus.edu.sg/HVRGrandChallenge2012/data/hvr-grand-challenge-2012-plan.pdf</pdf>
    <author status="complete" source="scholar.google.com">KC SIM, S ZHAO, K YU, H LIAO</author>
    <year>2012</year>
    <source>speech.ddns.comp.nus.edu.sg</source>
    <snippet status="partial" source="scholar.google.com">... comp.nus.edu.sg/HVRGrandChallenge2012/index.php?view=downloads). 5.1 File Formats ... Moredetails about the workshop will be posted on the HVR Grand Challenge 2012 website (http://speech.ddns.comp.nus.edu.sg/HVRGrandChallenge2012/) in due course. 6 Page 7. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:CRNTruN2I7wJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:CRNTruN2I7wJ:scholar.google.com/+author:%22Sim+Khe+Chai%22+NUS&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="13">
    <url>http://dl.acm.org/citation.cfm?id=2388759</url>
    <title status="complete" source="scholar.google.com">ICMI&#39;12 grand challenge: haptic voice recognition</title>
    <author status="complete" source="scholar.google.com">KC Sim, S Zhao, K Yu, H Liao</author>
    <proceeding status="partial" source="scholar.google.com">&#8230; of the 14th ACM international conference &#8230;</proceeding>
    <year>2012</year>
    <source>dl.acm.org</source>
    <snippet status="partial" source="scholar.google.com">... Khe Chai Sim National University of Singapore 13 Computing Drive Singapore 117417simkc@comp.nus.edu.sg Shengdong Zhao National University of Singapore 13Computing Drive Singapore 117417 zhaosd@comp.nus.edu.sg ...</snippet>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="14">
    <url>http://www.comp.nus.edu.sg/~wang86/Joey_files/papers/smth.pdf</url>
    <title status="complete" source="scholar.google.com">Comparison of Smoothing Techniques for Robust Context Dependent Acoustic Modelling in Hybrid NN/HMM Systems</title>
    <pdf>http://www.comp.nus.edu.sg/~wang86/Joey_files/papers/smth.pdf</pdf>
    <author status="complete" source="scholar.google.com">W Guangsen, KC Sim</author>
    <year>2011</year>
    <source>comp.nus.edu.sg</source>
    <snippet status="partial" source="scholar.google.com">... Systems Guangsen WANG, Khe Chai SIM School of Computing, National Universityof Singapore COM1, 13 Computing Drive, Singapore 117417 wangguangsen@comp.nus.edu.sg, simkc@comp.nus.edu.sg Abstract Hybrid ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:fIHT4FxqRNUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>3</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=15367524775636468092&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="15">
    <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5495609</url>
    <title status="complete" source="scholar.google.com">A minimum variance asynchronous Detection Error Trade-off performance analysis for multi-class detection problems</title>
    <author status="complete" source="scholar.google.com">KC Sim</author>
    <proceeding status="partial" source="scholar.google.com">Acoustics Speech and Signal Processing (ICASSP), &#8230;</proceeding>
    <year>2010</year>
    <source>ieeexplore.ieee.org</source>
    <snippet status="partial" source="scholar.google.com">Page 1. A MINIMUM VARIANCE ASYNCHRONOUS DETECTION ERROR TRADE-OFFPERFORMANCE ANALYSIS FOR MULTI-CLASS DETECTION PROBLEMS Khe Chai Sim Schoolof Computing, National University of Singapore simkc@comp.nus.edu.sg ABSTRACT ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:SwkILLZK9NAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>2</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=15056741600489638219&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="16">
    <url>http://www.comp.nus.edu.sg/~li-bo/papers/is10_2614_phnvrf.pdf</url>
    <title status="complete" source="scholar.google.com">Hidden Logistic Linear Regression for Support Vector Machine based Phone Verification</title>
    <pdf>http://www.comp.nus.edu.sg/~li-bo/papers/is10_2614_phnvrf.pdf</pdf>
    <author status="complete" source="scholar.google.com">B Li, KC Sim</author>
    <proceeding status="partial" source="scholar.google.com">Eleventh Annual Conference of the International &#8230;</proceeding>
    <year>2010</year>
    <source>comp.nus.edu.sg</source>
    <snippet status="partial" source="scholar.google.com">Page 1. Hidden Logistic Linear Regression for Support Vector Machine based Phone VerificationBo Li, Khe Chai Sim School of Computing, National University of Singapore. 1 Computing, 13Computing Drive, Singapore 117417 {li-bo, simkc}@comp.nus.edu.sg Abstract ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:5sl5gxTMHekJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>3</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=16797806573639027174&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="17">
    <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6288983</url>
    <title status="complete" source="scholar.google.com">Implicit trajectory modelling using temporally varying weight regression for automatic speech recognition</title>
    <pdf>http://www.mirlab.org/conference_papers/International_Conference/ICASSP%202012/pdfs/0004761.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Liu, KC Sim</author>
    <proceeding status="partial" source="scholar.google.com">&#8230; Speech and Signal Processing (ICASSP), 2012 &#8230;</proceeding>
    <year>2012</year>
    <source>ieeexplore.ieee.org</source>
    <snippet status="partial" source="scholar.google.com">... FOR AUTOMATIC SPEECH RECOGNITION Shilin LIU and Khe Chai SIM Schoolof Computing, National University of Singapore, Singapore {shilin,simkc}@comp.nus.edu.sg ABSTRACT Recently, implicit trajectory modelling ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:kBCDiEw8PsMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>3</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=14068748585357480080&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="18">
    <url>http://www.aclweb.org/anthology/P12-1004</url>
    <title status="complete" source="scholar.google.com">Probabilistic Integration of Partial Lexical Information for Noise Robust Haptic Voice Recognition</title>
    <pdf>http://www.aclweb.org/anthology/P12-1004</pdf>
    <author status="complete" source="scholar.google.com">KC Sim</author>
    <proceeding status="complete" source="scholar.google.com">aclweb.org</proceeding>
    <snippet status="partial" source="scholar.google.com">... Probabilistic Integration of Partial Lexical Information for Noise Robust Haptic Voice RecognitionKhe Chai Sim Department of Computer Science National University of Singapore 13 ComputingDrive, Singapore 117417 simkc@comp.nus.edu.sg Abstract ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:Pja8iFgw5k0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:Pja8iFgw5k0J:scholar.google.com/+author:%22Sim+Khe+Chai%22+NUS&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <numVersions>4</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=5613227142373193278&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>4</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=5613227142373193278&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="4">
        <result id="0">
        <url>http://dl.acm.org/citation.cfm?id=2388791</url>
        <title status="complete" source="scholar.google.com">Improving mandarin predictive text input by augmenting pinyin initials with speech and tonal information</title>
        <pdf>http://www.comp.nus.edu.sg/~li-bo/papers/icmi12_hvr.pdf</pdf>
        <author status="partial" source="scholar.google.com">G Wang, B Li, S Liu, X Wang, X Wang&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the 14th &#8230;</proceeding>
        <year>2012</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Recently, a new technology called Haptic Voice Recognition (HVR) was proposed to enhance the speech recognition efficiency and accuracy for modern mobile devices, which has been successfully applied for robust English voice recognition. As both Pinyin ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://speech.ddns.comp.nus.edu.sg/hvrgrandchallenge2012/slides/ICMI_HVR_gch103_slides.pdf</url>
        <title status="complete" source="scholar.google.com">Design and implementation of the note-taking style haptic voice recognition for mobile devices</title>
        <pdf>http://speech.ddns.comp.nus.edu.sg/hvrgrandchallenge2012/slides/ICMI_HVR_gch103_slides.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Moon, KC Sim</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the 14th ACM &#8230;</proceeding>
        <year>2012</year>
        <source>speech.ddns.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Figure: Simulation results (a) when performed without any additional noise and (b) when performed with artificial noise at SNR= 15dB. xaxis denotes the number of randomly chosen keywords (N), whereas y-axis denotes the word error rate (WER). The red and the blue ...</snippet>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:oIEZFB87ZJgJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://dl.acm.org/citation.cfm?id=2388759</url>
        <title status="complete" source="scholar.google.com">ICMI&#39;12 grand challenge: haptic voice recognition</title>
        <author status="complete" source="scholar.google.com">KC Sim, S Zhao, K Yu, H Liao</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; of the 14th ACM international conference &#8230;</proceeding>
        <year>2012</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper describes the Haptic Voice Recognition (HVR) Grand Challenge 2012 and its datasets. The HVR Grand Challenge 2012 is a research oriented competition designed to bring together researchers across multiple disciplines to work on novel ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://dl.acm.org/citation.cfm?id=2388793</url>
        <title status="complete" source="scholar.google.com">Speak-as-you-swipe (SAYS): a multimodal interface combining speech and gesture keyboard synchronously for continuous mobile text entry</title>
        <pdf>http://speech.ddns.comp.nus.edu.sg/HVRGrandChallenge2012/slides/ICMI_HVR_gch108_slides.pdf</pdf>
        <author status="complete" source="scholar.google.com">KC Sim</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the 14th ACM international conference &#8230;</proceeding>
        <year>2012</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Modern mobile devices, such as the smartphones and tablets, are becoming increasingly popular amongst users of all ages. Text entry is one of the most important modes of interaction between human and their mobile devices. Although typing on a ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="19">
    <url>http://dl.acm.org/citation.cfm?id=2388793</url>
    <title status="complete" source="scholar.google.com">Speak-as-you-swipe (SAYS): a multimodal interface combining speech and gesture keyboard synchronously for continuous mobile text entry</title>
    <pdf>http://speech.ddns.comp.nus.edu.sg/HVRGrandChallenge2012/slides/ICMI_HVR_gch108_slides.pdf</pdf>
    <author status="complete" source="scholar.google.com">KC Sim</author>
    <proceeding status="partial" source="scholar.google.com">Proceedings of the 14th ACM international conference &#8230;</proceeding>
    <year>2012</year>
    <source>dl.acm.org</source>
    <snippet status="partial" source="scholar.google.com">Speak-As-You-Swipe (SAYS): A Multimodal Interface Combining Speech and Gesture KeyboardSynchronously for Continuous Mobile Text Entry Khe Chai Sim National University of SingaporeComputing 1, 13 Computing Drive Singapore 117417 simkc@comp.nus.edu.sg ...</snippet>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="20">
    <url>http://eprints2008.lib.hokudai.ac.jp/dspace/handle/2115/39772</url>
    <title status="complete" source="scholar.google.com">A Phone Verification Approach to Pronunciation Quality Assessment for Spoken Language Learning</title>
    <pdf>http://eprints2008.lib.hokudai.ac.jp/dspace/bitstream/2115/39772/1/TP-P1-1.pdf</pdf>
    <author status="complete" source="scholar.google.com">KC Sim</author>
    <proceeding status="partial" source="scholar.google.com">&#8230; : APSIPA ASC 2009: Asia-Pacific Signal and &#8230;</proceeding>
    <year>2009</year>
    <source>eprints2008.lib.hokudai.ac.jp</source>
    <snippet status="partial" source="scholar.google.com">... Title A Phone Verification Approach to Pronunciation Quality Assessment for Spoken LanguageLearning Author(s) Sim, Khe Chai ... Khe Chai Sim School of Computing, National University ofSingapore, Singapore E-mail: simkc@comp.nus.edu.sg Tel: +65 6516 4813 ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:ryvr3hai0Q4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>6</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=1067812805776452527&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="21">
    <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5545373</url>
    <title status="complete" source="scholar.google.com">Using Discrete Probabilities With Bhattacharyya Measure for SVM-Based Speaker Verification</title>
    <pdf>http://www.cs.joensuu.fi/sipu/pub/Bhattacharyya_kernel.pdf</pdf>
    <author status="partial" source="scholar.google.com">KA Lee, CH You, H Li, T Kinnunen&#8230;</author>
    <proceeding status="partial" source="scholar.google.com">Audio, Speech, and &#8230;</proceeding>
    <year>2011</year>
    <source>ieeexplore.ieee.org</source>
    <snippet status="partial" source="scholar.google.com">... 132129, âCharacterizing individual information in speechâ). Khe Chai Sim is with theSchool of Computing, National University of Singapore, Singapore (e-mail:simkc@comp.nus.edu.sg). Using Discrete Probabilities with Bhattacharyya ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:KQ8AHlCNVCIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>11</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=2473757470573465385&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>4</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=2473757470573465385&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="4">
        <result id="0">
        <url>http://duepublico.uni-duisburg-essen.de/servlets/DerivateServlet/Derivate-31748/Al-Joumaa_Diss.pdf</url>
        <title status="complete" source="scholar.google.com">Development of a Self-Learning Approach Applied to Pattern Recognition and Fuzzy Control</title>
        <pdf>http://duepublico.uni-duisburg-essen.de/servlets/DerivateServlet/Derivate-31748/Al-Joumaa_Diss.pdf</pdf>
        <author status="complete" source="scholar.google.com">H Aljoumaa</author>
        <year>2012</year>
        <source>duepublico.uni-duisburg-essen.de</source>
        <snippet status="partial" source="scholar.google.com">During the twentieth century, important developments in the theoretical and applied sciences have achieved. These developments led to an increase of human desire/greed in an attempt to identify and explain the phenomena, whether simple or complex, in their ...</snippet>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:fTUsuJrPf0sJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www1.i2r.a-star.edu.sg/~kalee/procieee2013_language.pdf</url>
        <title status="complete" source="scholar.google.com">Spoken Language Recognition: from Fundamentals to Practice</title>
        <pdf>http://www1.i2r.a-star.edu.sg/~kalee/procieee2013_language.pdf</pdf>
        <author status="complete" source="scholar.google.com">H Li, B Ma, KA Lee</author>
        <proceeding status="complete" source="scholar.google.com">i2r.a-star.edu.sg</proceeding>
        <snippet status="partial" source="scholar.google.com">AbstractâSpoken language recognition refers to the automatic process through which we determine or verify the identity of the language spoken in a speech sample. We study a computational framework that allows such a decision to be made in a quantitative manner. ...</snippet>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:gIRI8LLZ4-YJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.cas.stc.sh.cn/jsjyup/pdf/2012/10/%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84%CE%B1-GMM%E8%81%9A%E7%B1%BB%E8%AF%B4%E8%AF%9D%E4%BA%BA%E7%A1%AE%E8%AE%A4%E7%AE%97%E6%B3%95.pdf</url>
        <title status="complete" source="scholar.google.com">ä¸ç§æ°ç Î±-GMM èç±»è¯´è¯äººç¡®è®¤ç®æ³</title>
        <pdf>http://www.cas.stc.sh.cn/jsjyup/pdf/2012/10/%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84%CE%B1-GMM%E8%81%9A%E7%B1%BB%E8%AF%B4%E8%AF%9D%E4%BA%BA%E7%A1%AE%E8%AE%A4%E7%AE%97%E6%B3%95.pdf</pdf>
        <author status="complete" source="scholar.google.com">æææ°ï¼ é¢çå¨</author>
        <proceeding status="complete" source="scholar.google.com">è®¡ç®æºåºç¨ä¸è½¯ä»¶</proceeding>
        <year>2012</year>
        <source>cas.stc.sh.cn</source>
        <snippet status="partial" source="scholar.google.com">æè¦éå¯¹åªå£°ç¯å¢ä¸è¯´è¯äººè¯å«çä½çé®é¢, æåºä¸ç§åºäºÎ±î GMM èç±»åSVM çè¯´è¯äººç¡®è®¤ç®æ³. é¦åè®¡ç®æ¯ä½æ³¨åè¯èçÎ±î GMM æ¨¡å, å¹¶è®¡ç®æ¨¡åé´çÎ± æ£åº¦, ç¶åä»¥è¯¥æ£åº¦è®¾è®¡èç±»ç®æ³, å¯¹è¯èçÎ±î GMM æ¨¡åè¿è¡èç±», å¾å°åä¸ªç±»å«çèç±»ä¸­å¿æ¨¡å ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.cas.stc.sh.cn/jsjyup/pdf/2012/10/%E5%9F%BA%E4%BA%8E%E7%89%B9%E5%BE%81%E5%83%8F%E5%88%86%E6%9E%90%E7%9A%84%E5%85%89%E5%AD%A6%E9%95%9C%E5%A4%B4MTF%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95%E7%9A%84%E7%A0%94%E7%A9%B6.pdf</url>
        <title status="complete" source="scholar.google.com">åºäºç¹å¾ååæçåå­¦éå¤´ MTF æµè¯æ¹æ³çç ç©¶</title>
        <pdf>http://www.cas.stc.sh.cn/jsjyup/pdf/2012/10/%E5%9F%BA%E4%BA%8E%E7%89%B9%E5%BE%81%E5%83%8F%E5%88%86%E6%9E%90%E7%9A%84%E5%85%89%E5%AD%A6%E9%95%9C%E5%A4%B4MTF%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95%E7%9A%84%E7%A0%94%E7%A9%B6.pdf</pdf>
        <author status="complete" source="scholar.google.com">å¼ å­¦æï¼ å¾å¤§è¯</author>
        <proceeding status="complete" source="scholar.google.com">è®¡ç®æºåºç¨ä¸è½¯ä»¶</proceeding>
        <year>2012</year>
        <source>cas.stc.sh.cn</source>
        <snippet status="partial" source="scholar.google.com">æè¦åå­¦éå¤´çMTF (ModulationTransferFunction) æ¯ä¸ä¸ªåç¡®, å®¢è§å¹¶ä¸å®éçæåè´¨éè¯ä»·ææ . éç¨åºäºç¹å¾ååæçMTF æµè¯æ¹æ³, éç¹å¯¹åå£æ³è¿è¡æ¹è¿, æåºèªéåºå¹³åè¡æ°ç®æ³åå¾®å¾åå£æ³. éè¿MATLAB è¿è¡å®éªä»¿ç, è·å¾çå¼ä¸IMATEST æ¨¡æä»¿ççå¼å¨ç©ºé´é¢ç ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
</query>
</results>
