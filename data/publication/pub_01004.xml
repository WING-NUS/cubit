<?xml version="1.0" encoding='UTF-8'?>
<results algorithmName="GS" algorithmVersion="101001" time="9:00" date="2013">
<query content="author:&quot;Jain Sanjay&quot; NUS" label="" count="183" totalresults="183">
  <result id="0">
    <url>http://www.sciencedirect.com/science/article/pii/S0022000001917593</url>
    <title status="complete" source="scholar.google.com">Language learning from texts: Degrees of intrinsic complexity and their characterizations</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/rolfintrin.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen</author>
    <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
    <year>2001</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... 305â323. â A preliminary version of this paper was presented at COLT&#39; 2000. f1 E-mail:sanjay@comp.nus.edu.sg. f2 E-mail: kinbere@sacredheart.edu. f3 E-mail: wiehagen@informatik.uni-kl.de. 2 Supported in part by NUS Grant RP3992710. 3 ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:8fj8PkF24gUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>13</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=424031337527965937&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>17</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=424031337527965937&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="17">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397508001503</url>
        <title status="complete" source="scholar.google.com">Learning indexed families of recursive languages from positive data: A survey</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/tcs08lzz.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, T Zeugmann, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In the past 40 years, research on inductive inference has developed along different lines, eg, in the formalizations used, and in the classes of target concepts considered. One common root of many of these formalizations is Gold&#39;s model of identification in the limit. This model ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:kHdpMOKBOpwJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11257453027040786320&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>39</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11257453027040786320&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/TPQLB4Q0AWXYP3CN.pdf</url>
        <title status="complete" source="scholar.google.com">A random sampling technique for training support vector machines</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.7.7311&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J BalcÃ¡zar, Y Dai, O Watanabe</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Random sampling techniques have been developed for combinatorial optimization problems. In this note, we report an application of one of these techniques for training support vector machines (more precisely, primal-form maximal-margin classifiers) that ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:NWZDroniSUAJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>16</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4632482772689315381&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>37</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4632482772689315381&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540106000253</url>
        <title status="complete" source="scholar.google.com">Mind change efficient learning</title>
        <pdf>http://mind-change-bayes-net.googlecode.com/svn/branches/mclc.pdf</pdf>
        <author status="complete" source="scholar.google.com">W Luo, O Schulte</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2006</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper studies efficient learning with respect to mind changes. Our starting point is the idea that a learner that is efficient with respect to mind changes minimizes mind changes not only globally in the entire learning problem, but also locally in subproblems after receiving ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Nc6YcK5juMUJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14247247022051085877&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14247247022051085877&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540109001631</url>
        <title status="complete" source="scholar.google.com">Topological properties of concept spaces (full version)</title>
        <author status="complete" source="scholar.google.com">M Brecht, A Yamamoto</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2010</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Based on the observation that the category of concept spaces with the positive information topology is equivalent to the category of countably based T0 topological spaces, we investigate further connections between the learning in the limit model of inductive ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:yiOA7qSDwy8J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3441739284640441290&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3441739284640441290&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://iospress.metapress.com/index/TRRD110H759Y5W0B.pdf</url>
        <title status="complete" source="scholar.google.com">The intrinsic complexity of learning: A survey</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/intrinsur.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Fundamenta Informaticae</proceeding>
        <year>2003</year>
        <source>IOS Press</source>
        <snippet status="partial" source="scholar.google.com">The theory of learning in the limit has been a focus of study by several researchers over the last three decades. There have been several suggestions on how to measure the complexity or hardness of learning. In this paper we survey the work done in one specific such ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:b9x1IASxyRcJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1714095764473764975&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1714095764473764975&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://epubs.siam.org/doi/abs/10.1137/070700577</url>
        <title status="complete" source="scholar.google.com">Mitotic classes in inductive inference</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.137.6190&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">SIAM Journal on Computing</proceeding>
        <year>2008</year>
        <source>SIAM</source>
        <snippet status="partial" source="scholar.google.com">For the natural notion of splitting classes into two disjoint subclasses via a recursive classifier working on texts, the question of how these splittings can look in the case of learnable classes is addressed. Here the strength of the classes is compared using the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:8Dgog4Yp7VIJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>24</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5975477938293324016&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5975477938293324016&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.springerlink.com/index/QCKQQRTHHQ5K217C.pdf</url>
        <title status="complete" source="scholar.google.com">Intrinsic complexity of uniform learning</title>
        <pdf>http://webdocs.cs.ualberta.ca/~zilles/zilles03uniform.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2003</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Inductive inference is concerned with algorithmic learning of recursive functions. In the model of learning in the limit a learner successful for a class of recursive functions must eventually find a program for any function in the class from a gradually growing sequence ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:HMm4NBIPwV4J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6827755080938735900&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6827755080938735900&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/n3r64276x24l10v0.pdf</url>
        <title status="complete" source="scholar.google.com">Topological Properties of Concept Spaces</title>
        <pdf>http://cs5235.userapi.com/u133638729/docs/e02780dda47c/Yoav_Freund_Algorithmic_Learning_Theory_19_conf.pdf#page=386</pdf>
        <author status="complete" source="scholar.google.com">M de Brecht, A Yamamoto</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Based on the observation that the category of concept spaces with the positive information topology is equivalent to the category of countably based T 0 topological spaces, we investigate further connections between the learning in the limit model of inductive ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:XSbLTj7UvdAJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15041411694562322013&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15041411694562322013&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.springerlink.com/index/u584873247003656.pdf</url>
        <title status="complete" source="scholar.google.com">Mitotic classes</title>
        <pdf>https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2569/1/TRB8-07.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">For the natural notion of splitting classes into two disjoint subclasses via a recursive classifier working on texts, the question is addressed how these splittings can look in the case of learnable classes. Here the strength of the classes is compared using the strong ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:bEfvZa6Aqn8J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9199306675380504428&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9199306675380504428&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.springerlink.com/index/80x7h9xc6ju9crv4.pdf</url>
        <title status="complete" source="scholar.google.com">Intrinsic complexity of learning geometrical concepts from positive data</title>
        <pdf>http://cs5824.userapi.com/u11728334/docs/be3e0641bab1/David_Helmbold_Computational_Learning_Theory_14.pdf#page=185</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Intrinsic complexity is used to measure complexity of learning areas limited by broken-straight lines (called open semi-hulls) 1 and intersections of such areas. Any strategy learning such geometrical concept can be viewed as a sequence of primitive basic ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:UVtfeQ_guscJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14392061916281264977&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14392061916281264977&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www.springerlink.com/index/et9pbxuppma6j9j0.pdf</url>
        <title status="complete" source="scholar.google.com">Learning languages in a union</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/kalapp.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, Y Ng, T Tay</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In inductive inference, a machine is given words in a language and the machine is said to identify the language if it correctly names the language. In this paper we study classes of languages where the unions of up to a fixed number (n say) of languages from the class ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:pFjStsX955MJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10657766068813191332&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10657766068813191332&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>ftp://142.58.111.31/fas-info/ftp/ftp/pub/cs/theses/2007/WeiLuoPhD.pdf</url>
        <title status="complete" source="scholar.google.com">Mind change optimal learning: theory and applications</title>
        <pdf>ftp://142.58.111.31/fas-info/ftp/ftp/pub/cs/theses/2007/WeiLuoPhD.pdf</pdf>
        <author status="complete" source="scholar.google.com">W Luo</author>
        <year>2007</year>
        <source>142.58.111.31</source>
        <snippet status="partial" source="scholar.google.com">Abstract Learning theories play a significant role to machine learning as computability and complexity theories to software engineering. Gold&#39;s language learning paradigm is one cornerstone of modern learning theories. The aim of this thesis is to establish an inductive ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:AdqaxUFSDqAJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:AdqaxUFSDqAJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>34</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11533246138184030721&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11533246138184030721&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000003000679</url>
        <title status="complete" source="scholar.google.com">Intrinsic complexity of learning geometrical concepts from positive data</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/geometry.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Intrinsic complexity is used to measure the complexity of learning areas limited by broken-straight lines (called open semi-hulls) and intersections of such areas. Any strategy learning such geometrical concepts can be viewed as a sequence of primitive basic strategies. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:X_seyV1VkhsJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1986744246918380383&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1986744246918380383&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="13">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397506004890</url>
        <title status="complete" source="scholar.google.com">An approach to intrinsic complexity of uniform learning</title>
        <pdf>http://www2.cs.uregina.ca/~zilles/zilles06intrinsic.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2006</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Inductive inference is concerned with algorithmic learning of recursive functions. In the model of learning in the limit a learner successful for a class of recursive functions must eventually find a program for any function in the class from a gradually growing sequence ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:-afF2fspAVQJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6053165535829796857&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6053165535829796857&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="14">
        <url>http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTR/tcstr_07_31/tcstr_07_31.pdf</url>
        <title status="complete" source="scholar.google.com">TCS Technical Report</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTR/tcstr_07_31/tcstr_07_31.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, T Zeugmann, S Zilles</author>
        <year>2007</year>
        <source>www-alg.ist.hokudai.ac.jp</source>
        <snippet status="partial" source="scholar.google.com">Abstract In the past 40 years, research on inductive inference has developed along different lines, concerning different formalizations of learning models and in particular of target concepts for learning. One common root of many of these is Gold&#39;s model of identification ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:uMhVpfJ4388J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:uMhVpfJ4388J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14978823869208840376&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="15">
        <url>http://dl.comp.nus.edu.sg/dspace/handle/1900.100/1400</url>
        <title status="complete" source="scholar.google.com">On intrinsic complexity of learning geometrical concepts from texts</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1400/1/report.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Sanjay, E KINBER</author>
        <year>1999</year>
        <source>dl.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract: The goal of this paper is to quantify complexity of algorithmic learning of geometrical concepts from growing finite segments. The geometrical concepts we consider are variants of open-hulls. We use intrinsic complexity as our complexity measure. The ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:DAWdzjlgDVIJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5912487687203128588&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="16">
        <url>http://www.springerlink.com/index/K463H6036PH8678U.pdf</url>
        <title status="complete" source="scholar.google.com">Splitting of learnable classes</title>
        <pdf>http://users.dsic.upv.es/workshops/icgi2010/slides/Li.pdf</pdf>
        <author status="complete" source="scholar.google.com">H Li, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">Grammatical Inference: Theoretical Results and &#8230;</proceeding>
        <year>2010</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A class LL is called mitotic if it admits a splitting L 0, L 1 L _0, L _1 such that L, L 0, L 1 L, L _0, L _1 are all equivalent with respect to a certain reducibility. Such a splitting might be called a symmetric splitting. In this paper we investigate the possibility of constructing a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cV405y-RMO8J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>19</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17235435408875347569&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="1">
    <url>http://www.springerlink.com/index/7NDLJGW0PUQ0N9P5.pdf</url>
    <title status="complete" source="scholar.google.com">Non U-shaped vacillatory and team learning</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.127.40&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2005</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... Italy carlucci5@unisi.it 2 Department of Computer and Information Sciences, University ofDelaware, Newark, DE 19716-2586,USA case@cis.udel.edu 3 School of Computing, 3 ScienceDrive 2, National University of Singapore, Singapore 117543 sanjay@comp.nus.edu.sg 4 ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:SiUKzidZXvAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>8</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=17320379244408874314&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>10</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=17320379244408874314&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="10">
        <result id="0">
        <url>http://www.springerlink.com/index/prebbr91cb17uenx.pdf</url>
        <title status="complete" source="scholar.google.com">Unlearning helps</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2205/1/TRA5-06.pdf</pdf>
        <author status="complete" source="scholar.google.com">G Baliga, J Case, W Merkle, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">Automata, Languages and &#8230;</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Overregularization seen in child language learning, re verb tense constructs, involves abandoning correct behaviors for incorrect ones and later reverting to correct behaviors. Quite a number of other child development phenomena also follow this U-shaped form of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Kz0TSnrOJQwJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>24</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=875332727217536299&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>20</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=875332727217536299&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540107000491</url>
        <title status="complete" source="scholar.google.com">Results on memory-limited U-shaped learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.8567&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">U-shaped learning is a learning behaviour in which the learner first learns a given target behaviour, then unlearns it and finally relearns it. Such a behaviour, observed by psychologists, for example, in the learning of past-tenses of English verbs, has been ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:aPOveNlKjhoJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>23</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1913549189572195176&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>21</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1913549189572195176&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540107001095</url>
        <title status="complete" source="scholar.google.com">When unlearning helps</title>
        <author status="partial" source="scholar.google.com">G Baliga, J Case, W Merkle, F Stephan&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Information and &#8230;</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Overregularization seen in child language learning, for example, verb tense constructs, involves abandoning correct behaviours for incorrect ones and later reverting to correct behaviours. Quite a number of other child development phenomena also follow this U- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:4FHwvqlchk8J:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5730369459998183904&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>18</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5730369459998183904&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/1r638k4x8jgt667r.pdf</url>
        <title status="complete" source="scholar.google.com">Memory-limited U-shaped learning</title>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. U-shaped learning is a learning behaviour in which the learner first learns something, then unlearns it and finally relearns it. Such a behaviour, observed by psychologists, for example, in the learning of past-tenses of English verbs, has been ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:HRa3ewNxRzoJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4199449437320713757&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4199449437320713757&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/K6565966X8828563.pdf</url>
        <title status="complete" source="scholar.google.com">U-shaped, iterative, and iterative-with-counter learning</title>
        <pdf>http://www.cis.udel.edu/~moelius/publications/iteqnuit_mlj_preprint.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Moelius</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper solves an important problem left open in the literature by showing that U-shapes are unnecessary in iterative learning. A U-shape occurs when a learner first learns, then unlearns, and, finally, relearns, some target concept. Iterative learning is a Gold-style ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RrqCAV6LybQJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13027096633014401606&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13027096633014401606&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.springerlink.com/index/l5p6329uk2633r03.pdf</url>
        <title status="complete" source="scholar.google.com">Directions for computability theory beyond pure mathematical</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/rft-directions.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Mathematical problems from applied logic II</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper begins by briefly indicating the principal, non-standard motivations of the author for his decades of work in Computability Theory (CT), aka Recursive Function Theory. Then it discusses its proposed, general directions beyond those from pure mathematics for CT. These ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:BWKg2uLmRxMJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1389332872072028677&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1389332872072028677&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.springerlink.com/index/q3u47561122j7n59.pdf</url>
        <title status="complete" source="scholar.google.com">Some recent results in U-shaped learning</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1902/1/TR41-05.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theory and Applications of Models of Computation</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. U-shaped learning deals with a learner first having the correct hypothesis, then changing it to an incorrect hypothesis and then relearning the correct hypothesis. This phenomenon has been observed by psychologists in various studies of children ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:O2n5Ep7n5KgJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>25</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12170106759171107131&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12170106759171107131&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <title status="complete" source="scholar.google.com">U-shaped, iterative, and iterative-with-counter learning (expanded version)</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2fP3wed_a-kJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16819677866713674713&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.springerlink.com/index/12017035066353VR.pdf</url>
        <title status="complete" source="scholar.google.com">Resource Restricted Computability Theoretic Learning: Illustrative Topics and Problems</title>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Computation and Logic in the Real World</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Computability theoretic learning theory (machine inductive inference) typically involves learning programs for languages or functions from a stream of complete data about them and, importantly, allows mind changes as to conjectured programs. This theory takes into ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MIjRDNBNqiIJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2497894499293956144&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397512009310</url>
        <title status="complete" source="scholar.google.com">Memory-limited non-U-shaped learning with solved open problems</title>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Herein we also distinguish between semantic and syntactic U-shapes. We answer a number of open questions in the prior literature as well as provide new results regarding syntactic U-shapes. Importantly for cognitive science, we see more of a previously noticed pattern ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="2">
    <url>http://www.springerlink.com/index/R7605578752701X3.pdf</url>
    <title status="complete" source="scholar.google.com">Learnability of automatic classes</title>
    <author status="complete" source="scholar.google.com">S Jain, Q Luo, F Stephan</author>
    <proceeding status="partial" source="scholar.google.com">Language and Automata Theory and &#8230;</proceeding>
    <year>2010</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 Department of Computer Science, National University of Singapore, Singapore 117417,Republic of Singapore sanjay@comp.nus.edu.sg, luoqingl@comp.nus.edu.sg 2 Departmentof Mathematics and Department of Computer Science, National University of Singapore ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:YRL5i8YQ6qMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>3</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=11811271417670472289&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>9</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=11811271417670472289&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="9">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397510007656</url>
        <title status="complete" source="scholar.google.com">Uncountable automatic classes and learning</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2896/1/TRB1-09.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, Q Luo, P Semukhin, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2011</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In this paper we consider uncountable classes recognizable by Ï-automata and investigate suitable learning paradigms for them. In particular, the counterparts of explanatory, vacillatory and behaviourally correct learning are introduced for this setting. Here the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:A3ovHOqvSVQJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>30</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6073578992515906051&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6073578992515906051&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://dl.comp.nus.edu.sg/dspace/handle/1900.100/3112</url>
        <title status="complete" source="scholar.google.com">On automatic families</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/3112/1/TRB1-10.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, YS Ong, S Pu, F Stephan</author>
        <year>2010</year>
        <source>dl.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract: This paper summarises previous work on automatic families. It then investigates a natural measure which exists inside every automatic family: the size of a regular language in this family is just the length of its index. This measure satisfies various properties similar to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:8apC6ZMa79sJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>20</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15847914836316039921&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15847914836316039921&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/M161142U87M78Q35.pdf</url>
        <title status="complete" source="scholar.google.com">Automatic learning of subclasses of pattern languages</title>
        <author status="partial" source="scholar.google.com">J Case, S Jain, T Le, Y Ong, P Semukhin&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Language and Automata &#8230;</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Automatic classes are classes of languages for which a finite automaton can decide membership question for the languages in the class, in a uniform way, given an index for the language. For alphabet size of at least 4, every automatic class of erasing pattern ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:OKgwDG5SBTsJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4252896055725697080&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4252896055725697080&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/4H6654381W4512X6.pdf</url>
        <title status="complete" source="scholar.google.com">Robust learning of automatic classes of languages</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/3143/1/TRA4-10.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Martin, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper adapts and investigates the paradigm of robust learning, originally defined in the inductive inference literature for classes of recursive functions, to learning languages from positive data. Robustness is a very desirable property, as it captures a form of invariance ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:638p0aK98c4J:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>22</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14911908348191932395&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14911908348191932395&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540112001137</url>
        <title status="complete" source="scholar.google.com">Automatic learning of subclasses of pattern languages</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/autopat.pdf</pdf>
        <author status="partial" source="scholar.google.com">J Case, S Jain, TD Le, YS Ong, P Semukhin&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Information and &#8230;</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Automatic classes are classes of languages for which a finite automaton can decide the membership problem for the languages in the class, in a uniform way, given an index for the language. For alphabet size of at least 4, every automatic class of erasing pattern ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:h4T-C1MLkHMJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>17</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8327168162319467655&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8327168162319467655&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.springerlink.com/index/371821UW3L4225G8.pdf</url>
        <title status="complete" source="scholar.google.com">Automatic learners with feedback queries</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/autofeednew.pdf</pdf>
        <author status="partial" source="scholar.google.com">J Case, S Jain, Y Ong, P Semukhin&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Models of Computation in &#8230;</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Automatic classes are classes of languages for which a finite automaton can decide whether a given element is in a set given by its index. The present work studies the learnability of automatic families by automatic learners which, in each round, output a hypothesis and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RXW6gzjPnq0J:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12510664656516969797&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12510664656516969797&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.springerlink.com/index/V233X697X81081KW.pdf</url>
        <title status="complete" source="scholar.google.com">Automatic learning from positive data and negative counterexamples</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/autoncex.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2012</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We introduce and study a model for learning in the limit by finite automata from positive data and negative counterexamples. The focus is on learning classes of languages with a membership problem computable by finite automata (so-called automatic classes). We ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/D2798548132P7V20.pdf</url>
        <title status="complete" source="scholar.google.com">Automatic functions, linear time and learning</title>
        <pdf>https://www.iscs.nus.edu.sg/~fstephan/autolintime.ps</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, S Seah, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">How the World Computes</proceeding>
        <year>2012</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The present work determines the exact nature of linear time computable notions which characterise automatic functions (those whose graphs are recognised by a finite automaton). The paper also determines which type of linear time notions permit full learnability for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1rUoLH2c-KAJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11599192901718422998&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://hal.archives-ouvertes.fr/hal-00678163/</url>
        <title status="complete" source="scholar.google.com">Mind Change Speed-up for Learning Languages from Positive Data</title>
        <pdf>http://hal.archives-ouvertes.fr/docs/00/67/81/63/PDF/9.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="partial" source="scholar.google.com">Symposium on Theoretical Aspects of &#8230;</proceeding>
        <year>2012</year>
        <source>hal.archives-ouvertes.fr</source>
        <snippet status="partial" source="scholar.google.com">Abstract Within the frameworks of learning in the limit of indexed classes of recursive languages from positive data and automatic learning in the limit of indexed classes of regular languages (with automatically computable sets of indices), we study the problem ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:y8ex7vN-mE8J:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5735473711603107787&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="3">
    <url>http://www.springerlink.com/index/1r638k4x8jgt667r.pdf</url>
    <title status="complete" source="scholar.google.com">Memory-limited U-shaped learning</title>
    <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
    <year>2006</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... it 2 Department of Computer and Information Sciences, University of Delaware, Newark, DE19716-2586, USA case@cis.udel.edu 3 School of Computing, 3 Science Drive 2, NationalUniversity of Singapore, Singapore 117543, Republic of Singapore sanjay@comp.nus.edu.sg ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:HRa3ewNxRzoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>2</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=4199449437320713757&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>8</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=4199449437320713757&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="8">
        <result id="0">
        <url>http://www.springerlink.com/index/prebbr91cb17uenx.pdf</url>
        <title status="complete" source="scholar.google.com">Unlearning helps</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2205/1/TRA5-06.pdf</pdf>
        <author status="complete" source="scholar.google.com">G Baliga, J Case, W Merkle, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">Automata, Languages and &#8230;</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Overregularization seen in child language learning, re verb tense constructs, involves abandoning correct behaviors for incorrect ones and later reverting to correct behaviors. Quite a number of other child development phenomena also follow this U-shaped form of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Kz0TSnrOJQwJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>24</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=875332727217536299&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>20</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=875332727217536299&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540107001095</url>
        <title status="complete" source="scholar.google.com">When unlearning helps</title>
        <author status="partial" source="scholar.google.com">G Baliga, J Case, W Merkle, F Stephan&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Information and &#8230;</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Overregularization seen in child language learning, for example, verb tense constructs, involves abandoning correct behaviours for incorrect ones and later reverting to correct behaviours. Quite a number of other child development phenomena also follow this U- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:4FHwvqlchk8J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5730369459998183904&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>18</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5730369459998183904&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/m13t261w8547g2w7.pdf</url>
        <title status="complete" source="scholar.google.com">Parallelism increases iterative learning power</title>
        <pdf>http://cs5235.userapi.com/u133638729/docs/ceb9e6352614/Marcus_Hutter_Algorithmic_Learning_Theory_18_co.pdf#page=60</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Moelius</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Iterative learning (It It-learning) is a Gold-style learning model in which each of a learner&#39;s output conjectures may depend only upon the learner&#39;s current conjecture and the current input element. Two extensions of the It It-learning model are considered, each of which ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:S-KmCH9zMScJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2824165430781207115&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2824165430781207115&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/K6565966X8828563.pdf</url>
        <title status="complete" source="scholar.google.com">U-shaped, iterative, and iterative-with-counter learning</title>
        <pdf>http://www.cis.udel.edu/~moelius/publications/iteqnuit_mlj_preprint.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Moelius</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper solves an important problem left open in the literature by showing that U-shapes are unnecessary in iterative learning. A U-shape occurs when a learner first learns, then unlearns, and, finally, relearns, some target concept. Iterative learning is a Gold-style ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RrqCAV6LybQJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13027096633014401606&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13027096633014401606&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540107000983</url>
        <title status="complete" source="scholar.google.com">Iterative learning from positive data and negative counterexamples</title>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A model for learning in the limit is defined where a (so-called iterative) learner gets all positive examples from the target language, tests every new conjecture with a teacher (oracle) if it is a subset of the target language (and if it is not, then it receives a negative ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:DfGaZ2CzXhUJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1539865349243728141&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1539865349243728141&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <title status="complete" source="scholar.google.com">U-shaped, iterative, and iterative-with-counter learning (expanded version)</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2fP3wed_a-kJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16819677866713674713&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.springerlink.com/index/RL2050457GU60010.pdf</url>
        <title status="complete" source="scholar.google.com">Iterative learning from positive data and negative counterexamples</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1918/1/TRA3-06.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A model for learning in the limit is defined where a (so-called iterative) learner gets all positive examples from the target language, tests every new conjecture with a teacher (oracle) if it is a subset of the target language (and if it is not, then it receives a negative ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:LnGoLrd_Ie4J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>15</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17159136479996834094&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17159136479996834094&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/12017035066353VR.pdf</url>
        <title status="complete" source="scholar.google.com">Resource Restricted Computability Theoretic Learning: Illustrative Topics and Problems</title>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Computation and Logic in the Real World</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Computability theoretic learning theory (machine inductive inference) typically involves learning programs for languages or functions from a stream of complete data about them and, importantly, allows mind changes as to conjectured programs. This theory takes into ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MIjRDNBNqiIJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2497894499293956144&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="4">
    <url>http://dl.comp.nus.edu.sg/dspace/handle/1900.100/3112</url>
    <title status="complete" source="scholar.google.com">On automatic families</title>
    <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/3112/1/TRB1-10.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, YS Ong, S Pu, F Stephan</author>
    <year>2010</year>
    <source>dl.comp.nus.edu.sg</source>
    <snippet status="partial" source="scholar.google.com">... Sanjay Jain, Yuh Shin Ong, Shi Pu and Frank Stephan S. Jain: School of Computing, NationalUniversity of Singapore Block COM1, 13 Computing Drive, Singapore 117417 Email:sanjay@comp.nus.edu.sg YS Ong: School of Computing, National University of Singapore Block ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:8apC6ZMa79sJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>20</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=15847914836316039921&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>8</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=15847914836316039921&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="8">
        <result id="0">
        <url>http://www.springerlink.com/index/M161142U87M78Q35.pdf</url>
        <title status="complete" source="scholar.google.com">Automatic learning of subclasses of pattern languages</title>
        <author status="partial" source="scholar.google.com">J Case, S Jain, T Le, Y Ong, P Semukhin&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Language and Automata &#8230;</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Automatic classes are classes of languages for which a finite automaton can decide membership question for the languages in the class, in a uniform way, given an index for the language. For alphabet size of at least 4, every automatic class of erasing pattern ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:OKgwDG5SBTsJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4252896055725697080&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4252896055725697080&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/4H6654381W4512X6.pdf</url>
        <title status="complete" source="scholar.google.com">Robust learning of automatic classes of languages</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/3143/1/TRA4-10.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Martin, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper adapts and investigates the paradigm of robust learning, originally defined in the inductive inference literature for classes of recursive functions, to learning languages from positive data. Robustness is a very desirable property, as it captures a form of invariance ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:638p0aK98c4J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>22</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14911908348191932395&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14911908348191932395&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540112001137</url>
        <title status="complete" source="scholar.google.com">Automatic learning of subclasses of pattern languages</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/autopat.pdf</pdf>
        <author status="partial" source="scholar.google.com">J Case, S Jain, TD Le, YS Ong, P Semukhin&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Information and &#8230;</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Automatic classes are classes of languages for which a finite automaton can decide the membership problem for the languages in the class, in a uniform way, given an index for the language. For alphabet size of at least 4, every automatic class of erasing pattern ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:h4T-C1MLkHMJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>17</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8327168162319467655&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8327168162319467655&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/371821UW3L4225G8.pdf</url>
        <title status="complete" source="scholar.google.com">Automatic learners with feedback queries</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/autofeednew.pdf</pdf>
        <author status="partial" source="scholar.google.com">J Case, S Jain, Y Ong, P Semukhin&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Models of Computation in &#8230;</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Automatic classes are classes of languages for which a finite automaton can decide whether a given element is in a set given by its index. The present work studies the learnability of automatic families by automatic learners which, in each round, output a hypothesis and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RXW6gzjPnq0J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12510664656516969797&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12510664656516969797&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/V233X697X81081KW.pdf</url>
        <title status="complete" source="scholar.google.com">Automatic learning from positive data and negative counterexamples</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/autoncex.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2012</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We introduce and study a model for learning in the limit by finite automata from positive data and negative counterexamples. The focus is on learning classes of languages with a membership problem computable by finite automata (so-called automatic classes). We ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.springerlink.com/index/D2798548132P7V20.pdf</url>
        <title status="complete" source="scholar.google.com">Automatic functions, linear time and learning</title>
        <pdf>https://www.iscs.nus.edu.sg/~fstephan/autolintime.ps</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, S Seah, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">How the World Computes</proceeding>
        <year>2012</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The present work determines the exact nature of linear time computable notions which characterise automatic functions (those whose graphs are recognised by a finite automaton). The paper also determines which type of linear time notions permit full learnability for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1rUoLH2c-KAJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11599192901718422998&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://137.132.14.55/handle/10635/22105</url>
        <title status="complete" source="scholar.google.com">Reducibilities between Regular Languages</title>
        <pdf>http://137.132.14.55/bitstream/handle/10635/22105/TanWY.pdf?sequence=1</pdf>
        <author status="complete" source="scholar.google.com">TANWAI YEAN</author>
        <year>2010</year>
        <source>137.132.14.55</source>
        <snippet status="partial" source="scholar.google.com">The topic of this masters thesis is to investigate when a regular set A is reducible to a regular set B in the following sense: A is automaton reducible to B if there is an automatic and injective function f mapping A to B. A is transducer reducible to B if there is a function f ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:hGZELZjtwkkJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5315071748100875908&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.comp.nus.edu.sg/~fstephan/automatatheory-pstopdf.pdf</url>
        <title status="complete" source="scholar.google.com">CS5236âAdvanced Automata Theory</title>
        <pdf>http://www.comp.nus.edu.sg/~fstephan/automatatheory-pstopdf.pdf</pdf>
        <author status="complete" source="scholar.google.com">F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">comp.nus.edu.sg</proceeding>
        <snippet status="partial" source="scholar.google.com">Advanced Automata Theory is a lecture which will first review the basics of formal languages and automata theory and then give insight into specific topics from the theory of automata theory. In computer science, automata are an important tool for many theoretical results ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:oVDhZmpU7vIJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:oVDhZmpU7vIJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17505021617605005473&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="5">
    <url>http://www.springerlink.com/index/KDXC4PGBTGMTD4JL.pdf</url>
    <title status="complete" source="scholar.google.com">Variations on U-shaped learning</title>
    <pdf>https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1862/1/TRA8-05.pdf</pdf>
    <author status="complete" source="scholar.google.com">L Carlucci, S Jain, E Kinber, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
    <year>2005</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... Sciences, University of Delaware, Newark, DE 19716-2586,USA and Dipartimento di Matematica,Universit`a di Siena, Pian dei Mantellini 44, Siena, Italy carlucci5@unisi.it 2 School of Computing,National University of Singapore, Singapore 117543 sanjay@comp.nus.edu.sg 3 ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:_FEflyf2wXMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>31</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=8341218634766438908&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>7</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=8341218634766438908&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="7">
        <result id="0">
        <url>http://www.springerlink.com/index/prebbr91cb17uenx.pdf</url>
        <title status="complete" source="scholar.google.com">Unlearning helps</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2205/1/TRA5-06.pdf</pdf>
        <author status="complete" source="scholar.google.com">G Baliga, J Case, W Merkle, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">Automata, Languages and &#8230;</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Overregularization seen in child language learning, re verb tense constructs, involves abandoning correct behaviors for incorrect ones and later reverting to correct behaviors. Quite a number of other child development phenomena also follow this U-shaped form of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Kz0TSnrOJQwJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>24</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=875332727217536299&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>20</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=875332727217536299&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540107000491</url>
        <title status="complete" source="scholar.google.com">Results on memory-limited U-shaped learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.8567&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">U-shaped learning is a learning behaviour in which the learner first learns a given target behaviour, then unlearns it and finally relearns it. Such a behaviour, observed by psychologists, for example, in the learning of past-tenses of English verbs, has been ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:aPOveNlKjhoJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>23</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1913549189572195176&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>21</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1913549189572195176&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/1r638k4x8jgt667r.pdf</url>
        <title status="complete" source="scholar.google.com">Memory-limited U-shaped learning</title>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. U-shaped learning is a learning behaviour in which the learner first learns something, then unlearns it and finally relearns it. Such a behaviour, observed by psychologists, for example, in the learning of past-tenses of English verbs, has been ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:HRa3ewNxRzoJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4199449437320713757&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4199449437320713757&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540106000320</url>
        <title status="complete" source="scholar.google.com">Variations on U-shaped learning</title>
        <author status="complete" source="scholar.google.com">L Carlucci, S Jain, E Kinber, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2006</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The paper deals with the following problem: is returning to wrong conjectures necessary to achieve full power of algorithmic learning? Returning to wrong conjectures complements the paradigm of U-shaped learning when a learner returns to old correct conjectures. We ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:29Nshv64fAAJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=35106300428604379&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=35106300428604379&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/q3u47561122j7n59.pdf</url>
        <title status="complete" source="scholar.google.com">Some recent results in U-shaped learning</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1902/1/TR41-05.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theory and Applications of Models of Computation</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. U-shaped learning deals with a learner first having the correct hypothesis, then changing it to an incorrect hypothesis and then relearning the correct hypothesis. This phenomenon has been observed by psychologists in various studies of children ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:O2n5Ep7n5KgJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>25</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12170106759171107131&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12170106759171107131&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://dl.comp.nus.edu.sg/dspace/handle/1900.100/1903</url>
        <title status="complete" source="scholar.google.com">Memory-Limited U-Shaped Learning</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1903/1/tr51-05.pdf</pdf>
        <author status="complete" source="scholar.google.com">L CARLUCCI, J CASE, S JAIN, F STEPHAN</author>
        <year>2005</year>
        <source>dl.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract: U-shaped learning is a learning behaviour in which the learner first learns something, then unlearns it and finally relearns it. Such a behaviour, observed by psychologists, for example, in the learning of past-tenses of English verbs, has been ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2QKGOB0_q7AJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12730338166427747033&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12730338166427747033&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://slacellap.pbworks.com/w/file/fetch/45135461/ll07.pdf</url>
        <title status="complete" source="scholar.google.com">SECOND LANGUAGE ACQUISITION</title>
        <pdf>http://slacellap.pbworks.com/w/file/fetch/45135461/ll07.pdf</pdf>
        <author status="complete" source="scholar.google.com">D Pilcher</author>
        <proceeding status="complete" source="scholar.google.com">slacellap.pbworks.com</proceeding>
        <snippet status="partial" source="scholar.google.com">This is a book about second language acquisition. As such, it deals with the ways in which second languages are learned. We take a multidisciplinary approach in that what we have selected to present in this book represents research emanating from other well- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Rp1H2B12Eb4J:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:Rp1H2B12Eb4J:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="6">
    <url>http://www.springerlink.com/index/exe7upbtkll4n7y7.pdf</url>
    <title status="complete" source="scholar.google.com">Learning languages from positive data and negative counterexamples</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.130.6689&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2004</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... Sanjay Jain1â and Efim Kinber2 1 School of Computing, National University of Singapore,Singapore 117543. sanjay@comp.nus.edu.sg 2 Department of Computer Science, Sacred HeartUniversity, Fairfield, CT 06432-1000, USA kinbere@sacredheart.edu Abstract. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:P1H20am1D-AJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>7</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=16145322930123198783&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>9</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=16145322930123198783&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="9">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540105001379</url>
        <title status="complete" source="scholar.google.com">Relations between Gold-style learning and query learning</title>
        <pdf>http://www2.cs.uregina.ca/~zilles/langeZ05queries.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2005</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Different formal learning models address different aspects of human learning. Below we compare Gold-style learningâmodelling learning as a limiting process in which the learner may change its mind arbitrarily often before converging to a correct hypothesisâto ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:rNC7VkEdryUJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2715421266792927404&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>15</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2715421266792927404&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540105001616</url>
        <title status="complete" source="scholar.google.com">Learning languages from positive data and a finite number of queries</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.90.3248&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2006</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A computational model for learning languages in the limit from full positive data and a bounded number of queries to the teacher (oracle) is introduced and explored. Equivalence, superset, and subset queries are considered (for the latter one we consider also a variant ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FzZ78mu49FgJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6409950943424230935&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6409950943424230935&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.tdx.cat/handle/10803/8780</url>
        <title status="complete" source="scholar.google.com">On the learnibility of Mildly Context-Sensitive languages using positive data and correction queries</title>
        <pdf>http://www.tdx.cat/handle/10803/8780</pdf>
        <author status="complete" source="scholar.google.com">L Becerra Bonache</author>
        <year>2006</year>
        <source>tdx.cat</source>
        <snippet status="partial" source="scholar.google.com">Con esta tesis doctoral aproximamos la teorÃ­a de la inferencia gramatical y los estudios de adquisiciÃ³n del lenguaje, en pos de un objetivo final: ahondar en la comprensiÃ³n del modo como los niÃ±os adquieren su primera lengua mediante la explotaciÃ³n de la teorÃ­a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:QhQTLUugOLEJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12770132988148257858&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12770132988148257858&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/x8jvrne9hhf37f3y.pdf</url>
        <title status="complete" source="scholar.google.com">Learning languages from positive data and a finite number of queries</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.104.362&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="partial" source="scholar.google.com">FSTTCS 2004: Foundations of Software Technology &#8230;</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A computational model for learning languages in the limit from full positive data and a bounded number of queries to the teacher (oracle) is introduced and explored. Equivalence, superset, and subset queries are considered. If the answer is negative, the teacher may ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:uaRWKzH8L68J:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12623585568653485241&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12623585568653485241&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540107000983</url>
        <title status="complete" source="scholar.google.com">Iterative learning from positive data and negative counterexamples</title>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A model for learning in the limit is defined where a (so-called iterative) learner gets all positive examples from the target language, tests every new conjecture with a teacher (oracle) if it is a subset of the target language (and if it is not, then it receives a negative ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:DfGaZ2CzXhUJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1539865349243728141&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1539865349243728141&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.sciencedirect.com/science/article/pii/S030439750700549X</url>
        <title status="complete" source="scholar.google.com">A general comparison of language learning from examples and from queries</title>
        <pdf>http://pdf.aminer.org/000/235/383/inductive_learning_of_recurrence_term_languages_from_positive_data.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, S Lange, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In language learning, strong relationships between Gold-style models and query models have recently been observed: in some quite general setting Gold-style learners can be replaced by query learners and vice versa, without loss of learning capabilities. These &#39; ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:KrySs3uRs9AJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15038523541199961130&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15038523541199961130&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.springerlink.com/index/1xtm4b75003x05n2.pdf</url>
        <title status="complete" source="scholar.google.com">Gold-style and query learning under various constraints on the target class</title>
        <pdf>http://webdocs.cs.ualberta.ca/~zilles/jainLZ05queries.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, S Lange, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In language learning, strong relationships between Gold-style models and query models have recently been observed: in some quite general setting Gold-style learners can be replaced by query learners and vice versa, without loss of learning capabilities. These &#39; ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:4j9bAmkZKv0J:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18242421179419410402&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18242421179419410402&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/RL2050457GU60010.pdf</url>
        <title status="complete" source="scholar.google.com">Iterative learning from positive data and negative counterexamples</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1918/1/TRA3-06.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A model for learning in the limit is defined where a (so-called iterative) learner gets all positive examples from the target language, tests every new conjecture with a teacher (oracle) if it is a subset of the target language (and if it is not, then it receives a negative ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:LnGoLrd_Ie4J:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>15</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17159136479996834094&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17159136479996834094&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://grammars.grlmc.com/GRLMC/PersonalPages/leo/DissertationLeonorBecerra.pdf</url>
        <title status="complete" source="scholar.google.com">On the Learnability of Mildly Context-Sensitive Languages using Positive Data and Correction Queries</title>
        <pdf>http://grammars.grlmc.com/GRLMC/PersonalPages/leo/DissertationLeonorBecerra.pdf</pdf>
        <author status="complete" source="scholar.google.com">LB BONACHE</author>
        <proceeding status="complete" source="scholar.google.com">grammars.grlmc.com</proceeding>
        <snippet status="partial" source="scholar.google.com">Thanks also to the âMinisterio de EducaciÃ³n y Cienciaâ(MEC) which provided me the financial support to do this work, granting me a FPU (âFormaciÃ³n de Profesorado Universitarioâ, AP2001-1880) pre-doctoral fellowship. Due to this support, I have had the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:0S0wdgQKLw0J:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:0S0wdgQKLw0J:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=949989060677479889&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="7">
    <url>http://www.sciencedirect.com/science/article/pii/S0022000000917008</url>
    <title status="complete" source="scholar.google.com">Robust learning is rich</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.96.6122&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, C Smith, R Wiehagen</author>
    <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
    <year>2001</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... nus.edu.sgf1; ... 220â227. f1 E-mail: sanjay@comp.nus.edu.sg. f2 E-mail: smith@cs.umd.edu. f3E-mail: wiehagen@informatik.uni-kl.de. Copyright Â© 2001 Academic Press. All rights reserved.Bibliographic information. Citing and related articles. Related articles. No articles found. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:1RLuCKYwPi8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>6</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=3404211858011198165&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>11</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=3404211858011198165&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="11">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397508001400</url>
        <title status="complete" source="scholar.google.com">Learning recursive functions: A survey</title>
        <pdf>http://webdocs.cs.ualberta.ca/~zilles/zeugmannZ08survey.pdf</pdf>
        <author status="complete" source="scholar.google.com">T Zeugmann, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Studying the learnability of classes of recursive functions has attracted considerable interest for at least four decades. Starting with Gold&#39;s (1967) model of learning in the limit, many variations, modifications and extensions have been proposed. These models differ in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2f2VA5VmFfUJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17660134303999589849&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>14</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17660134303999589849&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397501004054</url>
        <title status="complete" source="scholar.google.com">Learning classes of approximations to non-recursive functions</title>
        <pdf>http://www.mat.unisi.it/personalpages/sorbi/public_html/papers/RUSHEAD.pdf#page=53</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2002</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Blum and Blum (Inform. and Control 28 (1975) 125â155) showed that a class B of suitable recursive approximations to the halting problem K is reliably EX-learnable but left it open whether or not B is in NUM. By showing B to be not in NUM we resolve this old problem. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:keLy4mjhzZEJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>33</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10506301346325652113&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10506301346325652113&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000004000212</url>
        <title status="complete" source="scholar.google.com">Robust learningârich and poor</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan, R Wiehagen</author>
        <proceeding status="partial" source="scholar.google.com">Journal of Computer and System &#8230;</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A class C of recursive functions is called robustly learnable in the sense I (where I is any success criterion of learning) if not only C itself but even all transformed classes Î (C), where Î is any general recursive operator, are learnable in the sense I. It was already ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ukImu-_3fDcJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3998343178207249082&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3998343178207249082&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/4H6654381W4512X6.pdf</url>
        <title status="complete" source="scholar.google.com">Robust learning of automatic classes of languages</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/3143/1/TRA4-10.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Martin, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper adapts and investigates the paradigm of robust learning, originally defined in the inductive inference literature for classes of recursive functions, to learning languages from positive data. Robustness is a very desirable property, as it captures a form of invariance ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:638p0aK98c4J:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>22</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14911908348191932395&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14911908348191932395&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540104000550</url>
        <title status="complete" source="scholar.google.com">Learning all subfunctions of a function</title>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Sublearning, a model for learning of subconcepts of a concept, is presented. Sublearning a class of total recursive functions informally means to learn all functions from that class together with all of their subfunctions. While in language learning it is known to be ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:u64grAkFrAEJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=120476829132828347&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=120476829132828347&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.comp.nus.edu.sg/~sanjay/paps/robsur.pdf</url>
        <title status="complete" source="scholar.google.com">A tour of robust learning</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/robsur.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; and Models. Perspectives East and West. &#8230;</proceeding>
        <year>2003</year>
        <source>comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract BarzdinÅ¡ conjectured that only recursively enumerable classes of functions can be learned robustly. This conjecture, which was finally refuted by Fulk, initiated the study of notions of robust learning. The present work surveys research on robust learning and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:OhqoyUDoLugJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:OhqoyUDoLugJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16730565030686759482&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16730565030686759482&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://projecteuclid.org/euclid.jsl/1305810752</url>
        <title status="complete" source="scholar.google.com">Robust separations in inductive inference</title>
        <author status="complete" source="scholar.google.com">M Fulk</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
        <year>2011</year>
        <source>projecteuclid.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Results in recursion-theoretic inductive inference have been criticized as depending on unrealistic self-referential examples. JM BÄrzdiÅÅ¡ proposed a way of ruling out such examples, and conjectured that one of the earliest results of inductive inference ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:VRX6dMGFfUgJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5223478208757372245&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5223478208757372245&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/l5rax18a05jhx5br.pdf</url>
        <title status="complete" source="scholar.google.com">Learning all subfunctions of a function</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/subex.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory and Kernel Machines</proceeding>
        <year>2003</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Sublearning, a model for learning of subconcepts of a concept, is presented. Sublearning a class of total recursive functions informally means to learn all functions from that class together with all of their subfunctions. While in language learning it is known to be ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FXBRXtWXmCoJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3069370088719216661&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=NFu8uP4GqykC&amp;oi=fnd&amp;pg=PA215&amp;ots=-bzu6hOVtL&amp;sig=7nfgPEmXCfb-kkFiQn6bfVPDfYI</url>
        <title status="complete" source="scholar.google.com">A TOUR OF ROBUST LEARNING</title>
        <author status="complete" source="scholar.google.com">F Stephant</author>
        <proceeding status="partial" source="scholar.google.com">Computability and Models: Perspectives East and &#8230;</proceeding>
        <year>2003</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">Abstract BarzdinS conjectured that only recursively enumerable classes of functions can be learned robustly. This conjecture, which was finally refuted by Fulk, initiated the study of notions of robust learning. The present work surveys research on robust learning and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:m5TegYY-cQwJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.eecis.udel.edu/~case/papers/pc10-paper.pdf</url>
        <title status="complete" source="scholar.google.com">Algorithmic Scientific Inference</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/pc10-paper.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">eecis.udel.edu</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract It is argued that, scientific laws, including quantum mechanical ones, can be considered algorithmic, that the expected behavior of the world, if not its exact behavior, is algorithmic, that, then, communities of human scientists over time have algorithmic ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:D5ttjlrBb5sJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:D5ttjlrBb5sJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11200383392974478095&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.6279&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Robust LearningâRich and Poor</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.6279&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">JCS Jainb, F Stephanc, R Wiehagend</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract A class C of recursive functions is called robustly learnable in the sense I (where I is any success criterion of learning) if not only C itself but even all transformed classes Î (C) where Î is any general recursive operator, are learnable in the sense I. It was already ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:F-gF6cXSbSAJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:F-gF6cXSbSAJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2336755529135024151&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="8">
    <url>http://www.springerlink.com/index/D56708146217R601.pdf</url>
    <title status="complete" source="scholar.google.com">Learning in Friedberg numberings</title>
    <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2613/1/TR11-07.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2007</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 Department of Computer Science, National University of Singapore, Singapore 117590,Republic of Singapore sanjay@comp.nus.edu.sg 2 Department of Computer Science andDepartment of Mathematics, National University of Singapore, Singapore 117543, Republic of ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:cLgmLVtjoKkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>26</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=12222878631934212208&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>6</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=12222878631934212208&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="6">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397509000620</url>
        <title status="complete" source="scholar.google.com">Prescribed learning of re classes</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.108.2025&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan, N Ye</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2009</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This work extends studies of Angluin, Lange and Zeugmann on the dependence of learning on the hypothesis space chosen for the language class in the case of learning uniformly recursive language classes. The concepts of class-comprising (where the learner can ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:YdSz3nZgLTsJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>20</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4264170485848462433&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4264170485848462433&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/H18M222XV34JT501.pdf</url>
        <title status="complete" source="scholar.google.com">Learning with temporary memory</title>
        <pdf>http://cs5235.userapi.com/u133638729/docs/e02780dda47c/Yoav_Freund_Algorithmic_Learning_Theory_19_conf.pdf#page=461</pdf>
        <author status="complete" source="scholar.google.com">S Lange, S Moelius, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In the inductive inference framework of learning in the limit, a variation of the bounded example memory (Bem) language learning model is considered. Intuitively, the new model constrains the learner&#39;s memory not only in how much data may be retained, but also in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:3UoB5xip-78J:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13833836604818541277&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13833836604818541277&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/W4537355387873K3.pdf</url>
        <title status="complete" source="scholar.google.com">Prescribed learning of RE classes</title>
        <pdf>https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2576/1/TR10-07.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan, N Ye</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This work extends studies of Angluin, Lange and Zeugmann on the dependence of learning on the hypotheses space chosen for the class. In subsequent investigations, uniformly recursively enumerable hypotheses spaces have been considered. In the present work, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:WtrFAkGimIoJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9986910573797169754&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9986910573797169754&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/Q3641U74N61G1323.pdf</url>
        <title status="complete" source="scholar.google.com">Numberings optimal for learning</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2823/1/TRA8-08+-+Frank+Stephan+and+Sanjay+Jain.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper extends previous studies on learnability in non-acceptable numberings by considering the question: for which criteria which numberings are optimal, that is, for which numberings it holds that one can learn every learnable class using the given numbering ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:IUHpyvyqy04J:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>25</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5677819757943406881&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5677819757943406881&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.146.2248&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Learning with temporary memory (expanded version)</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.146.2248&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, SE Moelius, S Zilles</author>
        <year>2008</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. In the inductive inference framework of learning in the limit, a variation of the bounded example memory (Bem) language learning model is considered. Intuitively, the new model constrains the learner&#39;s memory not only in how much data may be retained, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:7lJI0YadCZkJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:7lJI0YadCZkJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11027518364955726574&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11027518364955726574&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www2.cs.uregina.ca/~zilles/langeMZ08TR.pdf</url>
        <title status="complete" source="scholar.google.com">Incremental Learning with Temporary Memory</title>
        <pdf>http://www2.cs.uregina.ca/~zilles/langeMZ08TR.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Langea, S Zillesc</author>
        <proceeding status="complete" source="scholar.google.com">cs.uregina.ca</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract In the inductive inference framework of learning in the limit, a variation of the bounded example memory (Bem) language learning model is considered. Intuitively, the new model constrains the learner&#39;s memory not only in how much data may be retained, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MRIpRUDfVdEJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:MRIpRUDfVdEJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15084207994078564913&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="9">
    <url>http://www.springerlink.com/index/e654657xu548t251.pdf</url>
    <title status="complete" source="scholar.google.com">Iterative learning of simple external contextual languages</title>
    <pdf>http://cs5235.userapi.com/u133638729/docs/e02780dda47c/Yoav_Freund_Algorithmic_Learning_Theory_19_conf.pdf#page=371</pdf>
    <author status="partial" source="scholar.google.com">L Becerra-Bonache, J Case, S Jain&#8230;</author>
    <proceeding status="partial" source="scholar.google.com">Algorithmic Learning &#8230;</proceeding>
    <year>2008</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... edu 2 Department of Computer and Information Sciences, University of Delaware, Newark, DE19716-2586, USA case@cis.udel.edu 3 Department of Computer Science, National Universityof Singapore, Singapore 117590, Republic of Singapore sanjay@comp.nus.edu.sg 4 ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:scvYnWO_FuQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>25</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=16435534324706102193&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>6</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=16435534324706102193&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="6">
        <result id="0">
        <url>http://www.springerlink.com/index/c648276213130l18.pdf</url>
        <title status="complete" source="scholar.google.com">Learning mildly context-sensitive languages with multidimensional substitutability from positive data</title>
        <author status="complete" source="scholar.google.com">R Yoshinaka</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Recently Clark and Eyraud (2007) have shown that substitutable context-free languages, which capture an aspect of natural language phenomena, are efficiently identifiable in the limit from positive data. Generalizing their work, this paper presents a polynomial-time ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:WhpvrwjkK-8J:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17234119125017500250&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>18</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17234119125017500250&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397510007668</url>
        <title status="complete" source="scholar.google.com">Efficient learning of multiple context-free languages with multidimensional substitutability from positive data</title>
        <author status="complete" source="scholar.google.com">R Yoshinaka</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2011</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Recently Clark and Eyraud (2007)[10] have shown that substitutable context-free languages, which capture an aspect of natural language phenomena, are efficiently identifiable in the limit from positive data. Generalizing their work, this paper presents a polynomial-time ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:R62sBbhv62MJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7199971265441738055&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7199971265441738055&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.socsci.uci.edu/~lpearl/colareadinggroup/readings/Heinz2010Manu_CompLearningDevPsych.pdf</url>
        <title status="complete" source="scholar.google.com">Computational theories of learning and developmental psycholinguistics</title>
        <pdf>http://www.socsci.uci.edu/~lpearl/colareadinggroup/readings/Heinz2010Manu_CompLearningDevPsych.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Heinz</author>
        <proceeding status="partial" source="scholar.google.com">Under review for the The Cambridge Handbook of &#8230;</proceeding>
        <year>2010</year>
        <source>socsci.uci.edu</source>
        <snippet status="partial" source="scholar.google.com">A computer is something that computes, and since humans make computations when pro- cessing information, humans are computers. What kinds of computations do humans make when they learn languages? Answering this question requires the collaborative efforts of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:0YVDFo-F5rUJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:0YVDFo-F5rUJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13107310615108748753&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13107310615108748753&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/195620K685385223.pdf</url>
        <title status="complete" source="scholar.google.com">Bio-inspired grammatical inference</title>
        <pdf>http://hal.archives-ouvertes.fr/docs/00/61/81/06/PDF/IWINAC.pdf</pdf>
        <author status="complete" source="scholar.google.com">L Becerra-Bonache</author>
        <proceeding status="complete" source="scholar.google.com">Foundations on Natural and Artificial Computation</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The field of Grammatical Inference was originally motivated by the problem of natural language acquisition. However, the formal models proposed within this field have left aside this linguistic motivation. In this paper, we propose to improve models and techniques ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ImMRLGzvEbsJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13479818407571448610&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://hal.archives-ouvertes.fr/hal-00618126/</url>
        <title status="complete" source="scholar.google.com">Children as Models for Computers: Natural Language Acquisition for Machine Learning</title>
        <pdf>http://hal.archives-ouvertes.fr/docs/00/61/81/26/PDF/ICAART.pdf</pdf>
        <author status="partial" source="scholar.google.com">L Becerra-Bonache&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the 3rd &#8230;</proceeding>
        <year>2011</year>
        <source>hal.archives-ouvertes.fr</source>
        <snippet status="partial" source="scholar.google.com">Abstract. This paper focuses on a subfield of machine learning, the socalled grammatical inference. Roughly speaking, grammatical inference deals with the problem of inferring a grammar that generates a given set of sample sentences in some manner that is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:EMwobOZWoP8J:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18419818023602408464&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.springerlink.com/index/812361171q2264pu.pdf</url>
        <title status="complete" source="scholar.google.com">Resource Restricted Computability Theoretic Learning: Illustrative Topics and Problems</title>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Theory of Computing Systems</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract Computability theoretic learning theory (machine inductive inference) typically involves learning programs for languages or functions from a stream of complete data about them and, importantly, allows mind changes as to conjectured programs. This theory takes ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cNGIg7j_YKkJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12205036158119891312&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="10">
    <url>http://www.sciencedirect.com/science/article/pii/S0304397510002045</url>
    <title status="complete" source="scholar.google.com">Iterative learning of simple external contextual languages</title>
    <author status="partial" source="scholar.google.com">L Becerra-Bonache, J Case, S Jain&#8230;</author>
    <proceeding status="partial" source="scholar.google.com">Theoretical Computer &#8230;</proceeding>
    <year>2010</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... Correspondingauthor. E-mailaddresses:leonor.becerra-bonache@yale.edu(L.Becerra-Bonache),case@cis.udel.edu(J.Case),sanjay@comp.nus.edu.sg(S.Jain), fstephan@comp.nus.edu.sg(F.Stephan). 0304-3975/$ seefrontmatter&#39;2010ElsevierB.V.Allrightsreserved. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:f8VfCBmn_xMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>10</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=1441054131738363263&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>8</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=1441054131738363263&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="8">
        <result id="0">
        <url>http://www.springerlink.com/index/c648276213130l18.pdf</url>
        <title status="complete" source="scholar.google.com">Learning mildly context-sensitive languages with multidimensional substitutability from positive data</title>
        <author status="complete" source="scholar.google.com">R Yoshinaka</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Recently Clark and Eyraud (2007) have shown that substitutable context-free languages, which capture an aspect of natural language phenomena, are efficiently identifiable in the limit from positive data. Generalizing their work, this paper presents a polynomial-time ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:WhpvrwjkK-8J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17234119125017500250&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>18</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17234119125017500250&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397510007668</url>
        <title status="complete" source="scholar.google.com">Efficient learning of multiple context-free languages with multidimensional substitutability from positive data</title>
        <author status="complete" source="scholar.google.com">R Yoshinaka</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2011</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Recently Clark and Eyraud (2007)[10] have shown that substitutable context-free languages, which capture an aspect of natural language phenomena, are efficiently identifiable in the limit from positive data. Generalizing their work, this paper presents a polynomial-time ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:R62sBbhv62MJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7199971265441738055&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7199971265441738055&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencemag.org/content/333/6040/295.short</url>
        <title status="complete" source="scholar.google.com">Sentence and word complexity</title>
        <author status="complete" source="scholar.google.com">J Heinz, W Idsardi</author>
        <proceeding status="complete" source="scholar.google.com">Science</proceeding>
        <year>2011</year>
        <source>sciencemag.org</source>
        <snippet status="partial" source="scholar.google.com">Summary Our understanding of human learning is increasingly informed by findings from multiple fieldsâpsychology, neuroscience, computer science, linguistics, and education. A convergence of insights is forging a ânew science of learningâ within cognitive science, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:45VpOyQ6gkkJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5296860039031133667&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5296860039031133667&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/74M53LP013269545.pdf</url>
        <title status="complete" source="scholar.google.com">Learning without coding</title>
        <author status="complete" source="scholar.google.com">S Moelius, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2010</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Iterative learning is a model of language learning from positive data, due to Wiehagen. When compared to a learner in Gold&#39;s original model of language learning from positive data, an iterative learner can be thought of as memory-limited. However, an iterative ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:y3d_62hDJLIJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12836458955819415499&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12836458955819415499&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/195620K685385223.pdf</url>
        <title status="complete" source="scholar.google.com">Bio-inspired grammatical inference</title>
        <pdf>http://hal.archives-ouvertes.fr/docs/00/61/81/06/PDF/IWINAC.pdf</pdf>
        <author status="complete" source="scholar.google.com">L Becerra-Bonache</author>
        <proceeding status="complete" source="scholar.google.com">Foundations on Natural and Artificial Computation</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The field of Grammatical Inference was originally motivated by the problem of natural language acquisition. However, the formal models proposed within this field have left aside this linguistic motivation. In this paper, we propose to improve models and techniques ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ImMRLGzvEbsJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13479818407571448610&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=nEBfBghRSgsC&amp;oi=fnd&amp;pg=PA300&amp;ots=42d4reFwFb&amp;sig=KxMF8rATt6_gydu5E36DnDEUWQE</url>
        <title status="complete" source="scholar.google.com">Learning without Coding</title>
        <pdf>http://www.eecis.udel.edu/~moelius/publications/lwoc_tr.pdf</pdf>
        <author status="complete" source="scholar.google.com">SEM Iii, S Zilles</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; , ALT 2010, Canberra, Australia, October 6-8, &#8230;</proceeding>
        <year>2010</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">Abstract. Iterative learning is a model of language learning from positive data, due to Wiehagen. When compared to a learner in Gold&#39;s original model of language learning from positive data, an iterative learner can be thought of as memory-limited. However, an ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:L2vGQFeWA-0J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17078659513412119343&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.eecis.udel.edu/~case/papers/pr2.pdf</url>
        <title status="complete" source="scholar.google.com">On the Necessity of U-Shaped Learning</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/pr2.pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case</author>
        <proceeding status="complete" source="scholar.google.com">eecis.udel.edu</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. A U-shaped curve in a cognitive-developmental trajectory refers to a three-step process: good performance followed by bad performance followed by good performance once again. U-shaped curves have been observed in a wide variety of cognitive- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17336137048815070431&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397512009322</url>
        <title status="complete" source="scholar.google.com">Learning without coding</title>
        <author status="complete" source="scholar.google.com">S Jain, SE Moelius III, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Abstract Iterative learning is a model of language learning from positive data, due to Wiehagen. When compared to a learner in Gold&#39;s original model of language learning from positive data, an iterative learner can be thought of as memory-limited. However, an ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="11">
    <url>http://dl.acm.org/citation.cfm?id=238093</url>
    <title status="complete" source="scholar.google.com">Elementary formal systems, intrinsic complexity, and procrastination</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.96.6124&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
    <proceeding status="partial" source="scholar.google.com">Proceedings of the ninth annual conference on &#8230;</proceeding>
    <year>1996</year>
    <source>dl.acm.org</source>
    <snippet status="partial" source="scholar.google.com">... Department of ISCS School of Computer Science and Engineering National University ofSingapore The University of New South Wales Singapore 119260, Republic of Singapore Sydney,NSW 2052, Australia Email: sanj ayQiscs.nus.sg Email: arun@cse.unsw.edu.au Abstract ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:UjWHaftOaIkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>11</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=9901250622488261970&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>33</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=9901250622488261970&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="33">
        <result id="0">
        <url>http://www.springerlink.com/index/U47706KR760T0Q87.pdf</url>
        <title status="complete" source="scholar.google.com">The logic of reliable and efficient inquiry</title>
        <author status="complete" source="scholar.google.com">O Schulte</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Philosophical Logic</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper pursues a thorough-going instrumentalist, or means-ends, approach to the theory of inductive inference. I consider three epistemic aims: convergence to a correct theory, fast convergence to a correct theory and steady convergence to a correct theory (avoiding ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:9qWtNj2THDUJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3827095674477716982&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>34</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3827095674477716982&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397599000055</url>
        <title status="complete" source="scholar.google.com">Ordinal mind change complexity of language identification</title>
        <author status="complete" source="scholar.google.com">A Ambainis, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>1999</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The approach of ordinal mind change complexity, introduced by Freivalds and Smith, uses (notations for) constructive ordinals to bound the number of mind changes made by a learning machine. This approach provides a measure of the extent to which a learning ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:vR2MAdwEA-MJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16357923614505049533&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>28</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16357923614505049533&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://dl.acm.org/citation.cfm?id=279955</url>
        <title status="complete" source="scholar.google.com">Learnability of a subclass of extended pattern languages</title>
        <author status="complete" source="scholar.google.com">AR Mitchell</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the eleventh annual conference on &#8230;</proceeding>
        <year>1998</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Angluin introduced the class of pattern languages as term languages over strings on a finite alphabet, and showed that the class is identifiable in the limit from texts (positive data). III Angluin&#39;s definition of pattern languages, erasing substitutions are disallowed. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Qr-DkouoqvMJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17558031414669328194&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>21</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17558031414669328194&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://dl.acm.org/citation.cfm?id=267485</url>
        <title status="complete" source="scholar.google.com">Generalized notions of mind change complexity</title>
        <pdf>http://pdf.aminer.org/000/889/421/generalized_notions_of_mind_change_complexity.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Sharma, F Stephan, Y Ventsov</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; of the tenth annual conference on &#8230;</proceeding>
        <year>1997</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Speed of convergence in Gold&#39;s identification in the limit model can be measured by deriving bounds on the number of mind changes made by a learner before the onset of convergence. Two approaches to date are bounds given by constants (referred here as ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:wvC_V1rFm8sJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>31</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14671537202899448002&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>15</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14671537202899448002&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/b41022251g722643.pdf</url>
        <title status="complete" source="scholar.google.com">On learning unions of pattern languages and tree patterns</title>
        <author status="complete" source="scholar.google.com">S Goldman, S Kwek</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We present efficient on-line algorithms for learning unions of a constant number of tree patterns, unions of a constant number of one-variable pattern languages, and unions of a constant number of pattern languages with fixed length substitutions. By fixed length ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:KmR3bf6oVlUJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6149288151932691498&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>14</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6149288151932691498&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://iospress.metapress.com/index/J5TG811UU0055255.pdf</url>
        <title status="complete" source="scholar.google.com">Inductive inference with procrastination: back to definitions</title>
        <author status="complete" source="scholar.google.com">A Ambainis, R Freivalds, CH Smith</author>
        <proceeding status="complete" source="scholar.google.com">Fundamenta Informaticae</proceeding>
        <year>1999</year>
        <source>IOS Press</source>
        <snippet status="partial" source="scholar.google.com">In this paper, we reconsider the definition of procrastinating learning machines. In the original definition of Freivalds and Smith [FS93], constructive ordinals are used to bound mindchanges. We investigate possibility of using arbitrary linearly ordered sets to bound ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:TWbMAAm7UeQJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16452136561103627853&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16452136561103627853&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397502004176</url>
        <title status="complete" source="scholar.google.com">Learning elementary formal systems with queries</title>
        <pdf>https://ds.lib.kyutech.ac.jp/dspace/bitstream/10228/370/1/Learning_Elementary_Formal_Systems_with_Queries.pdf</pdf>
        <author status="complete" source="scholar.google.com">H Sakamoto, K Hirata, H Arimura</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The elementary formal system (EFS) is a kind of logic programs which directly manipulates strings, and the learnability of the subclass called hereditary EFSs (HEFSs) has been investigated in the frameworks of the PAC-learning, query-learning, and inductive ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ctf2jw3aQZwJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>19</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11259520295187699570&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11259520295187699570&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/a81263786620675p.pdf</url>
        <title status="complete" source="scholar.google.com">Ordinal mind change complexity of language identification</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.150.7815&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">A Ambainis, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
        <year>1997</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The approach of ordinal mind change complexity, introduced by Freivalds and Smith, uses constructive ordinals to bound the number of mind changes made by a learning machine. This approach provides a measure of the extent to which a learning machine has to keep ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:L3MXwPUbmY4J:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10275274767126197039&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10275274767126197039&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://projecteuclid.org/euclid.jsl/1080938842</url>
        <title status="complete" source="scholar.google.com">Parsimony hierarchies for inductive inference</title>
        <pdf>http://pdf.aminer.org/002/865/517/parsimony_hierarchies_for_inductive_inference.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Ambainis, J Case, S Jain, M Suraj</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
        <year>2004</year>
        <source>projecteuclid.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Freivalds defined an acceptable programming system independent criterion for learning programs for functions in which the final programs were required to be both correct and ânearlyâ minimal size, ie, within a computable function of being purely minimal size. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:PPOiazrZf9IJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15168080914944291644&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15168080914944291644&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.springerlink.com/index/M10332H915246783.pdf</url>
        <title status="complete" source="scholar.google.com">On the classification of computable languages</title>
        <pdf>http://www.cis.udel.edu/~case/papers/classif.ps</pdf>
        <author status="complete" source="scholar.google.com">J Case, E Kinber, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">STACS 97</proceeding>
        <year>1997</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A one-sided classifier for a given class of languages converges to 1 on every language from the class and outputs 0 infinitely often on languages outside the class. A two-sided classifier, on the other hand, converges to 1 on languages from the class and converges to 0 on ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RuRE4B4a4IgJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9862911903855338566&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9862911903855338566&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397501000846</url>
        <title status="complete" source="scholar.google.com">Mind change complexity of learning logic programs</title>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2002</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present paper motivates the study of mind change complexity for learning minimal models of length-bounded logic programs. It establishes ordinal mind change complexity bounds for learnability of these classes both from positive facts and from positive and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:jJz4Dy_hBmEJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6991523063786937484&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6991523063786937484&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://www.sciencedirect.com/science/article/pii/S030439750200422X</url>
        <title status="complete" source="scholar.google.com">Refuting learning revisited</title>
        <author status="complete" source="scholar.google.com">W Merkle, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We consider, within the framework of inductive inference, the concept of refuting learning as introduced by Mukouchi and Arikawa, where the learner is not only required to learn all concepts in a given class but also has to explicitly refute concepts outside the class. In the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RVIbTNh5upMJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10644954639140344389&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10644954639140344389&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540103002438</url>
        <title status="complete" source="scholar.google.com">Generalized notions of mind change complexity</title>
        <pdf>http://www.math.uni-heidelberg.de/logic/fstephan/ssv-mathpreprints-com.ps</pdf>
        <author status="complete" source="scholar.google.com">A Sharma, F Stephan, Y Ventsov</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Gold introduced the notion of learning in the limit where a class S is learnable iff there is a recursive machine M which reads the course of values of a function f and converges to a program for f whenever f is in S. An important measure for the speed of convergence in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cA20SaS7b8gJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14442968844286037360&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14442968844286037360&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="13">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397500001316</url>
        <title status="complete" source="scholar.google.com">On the learnability of recursively enumerable languages from good examples</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/good.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, S Lange, J Nessel</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present paper investigates identification of indexed families L of recursively enumerable languages from good examples. We distinguish class-preserving learning from good examples (the good examples have to be generated with respect to a hypothesis space ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:pT5ZV88QH0cJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5124833383680655013&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5124833383680655013&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="14">
        <url>http://dl.acm.org/citation.cfm?id=307465</url>
        <title status="complete" source="scholar.google.com">On the intrinsic complexity of learning recursive functions</title>
        <author status="partial" source="scholar.google.com">E Kinber, C Papazian, C Smith&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the twelfth &#8230;</proceeding>
        <year>1999</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract The intrinsic complexity of learning compares the difficulty of learning classes of objects by using some reducibility notion. For several types of learning recursive functions (learning in the limit, learning with a bounded number of mind changes, learning with ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:7vprogRmWLwJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13571709647171877614&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13571709647171877614&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="15">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397505006456</url>
        <title status="complete" source="scholar.google.com">Unifying logic, topology and learning in parametric logic</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.8.1793&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2006</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Many connections have been established between learning and logic, or learning and topology, or logic and topology. Still, the connections are not at the heart of these fields. Each of them is fairly independent of the others when attention is restricted to basic ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:BNnirbyUR9YJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>29</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15440473385555122436&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15440473385555122436&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="16">
        <url>http://www.springerlink.com/index/tpxvht2u27uhrbtf.pdf</url>
        <title status="complete" source="scholar.google.com">Learning, logic, and topology in a common framework</title>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2002</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Many connections have been established between learning and logic, or learning and topology, or logic and topology. Still, the connections are not at the heart of these fields. Each of them is fairly independent of the others when attention is restricted to basic ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:NXIp5aKFsQcJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=554371163819176501&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=554371163819176501&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="17">
        <url>http://www.springerlink.com/index/L23CUU7HRC4JU3UV.pdf</url>
        <title status="complete" source="scholar.google.com">Refuting learning revisited</title>
        <pdf>http://pdf.aminer.org/001/093/440/refuting_learning_revisited.pdf</pdf>
        <author status="complete" source="scholar.google.com">W Merkle, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We consider, within the framework of inductive inference, the concept of refuting learning as introduced by Mukouchi and Arikawa, where the learner is not only required to learn all concepts in a given class but also has to explicitly refute concepts outside the class. In the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:KuoyBNoKaj4J:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4497419109372455466&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4497419109372455466&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="18">
        <url>http://espace.library.uq.edu.au/view/UQ:10431</url>
        <title status="complete" source="scholar.google.com">How About Tomorrow? Optimal Procrastination and the Implications for Delay in Submitting to Conferences</title>
        <pdf>http://espace.library.uq.edu.au/eserv.php?pid=UQ:10431&amp;dsID=econ_dp_280_00.pdf</pdf>
        <author status="complete" source="scholar.google.com">S McDonald, R Beard, T Purcell</author>
        <year>2000</year>
        <source>espace.library.uq.edu.au</source>
        <snippet status="partial" source="scholar.google.com">In these times of academic stress in which one&#39;s time budget is a binding constraint, procrastination and delay may be an optimal response to deadlines imposed by conference organizers. We formulate a model of optimal procrastination using optimal stopping theory ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Kl-NLib5qN4J:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16044347614892482346&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16044347614892482346&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="19">
        <url>http://www.springerlink.com/index/1p9a8e58kgtl7mwk.pdf</url>
        <title status="complete" source="scholar.google.com">Mind change complexity of learning logic programs</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.105.2902&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The present paper motivates the study of mind change complexity for learning minimal models of length-bounded logic programs. It establishes ordinal mind change complexity bounds for learnability of these classes both from positive facts and from positive and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1GrxM06Kkp0J:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11354289679037983444&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11354289679037983444&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="20">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540103000592</url>
        <title status="complete" source="scholar.google.com">On the intrinsic complexity of learning recursive functions</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.105.5266&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="partial" source="scholar.google.com">S Jain, E Kinber, C Papazian, C Smith&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Information and &#8230;</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The intrinsic complexity of learning compares the difficulty of learning classes of objects by using some reducibility notion. For several types of learning recursive functions, both natural complete classes are exhibited and necessary and sufficient conditions for completeness ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1E4tVz7znzUJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3864074454383283924&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3864074454383283924&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="21">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397509007981</url>
        <title status="complete" source="scholar.google.com">Mind change complexity of inferring unbounded unions of restricted pattern languages from positive data</title>
        <author status="complete" source="scholar.google.com">M de Brecht, A Yamamoto</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2010</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper shows that the mind change complexity of inferring from positive data the class of unbounded unions of languages of regular patterns with constant segment length bound is of the form [Formula: see text], assuming that the patterns are defined over a finite ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:S_0At17bfksJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5440026599753841995&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5440026599753841995&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="22">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397501004029</url>
        <title status="complete" source="scholar.google.com">On learning unions of pattern languages and tree patterns in the mistake bound model</title>
        <author status="complete" source="scholar.google.com">SA Goldman, SS Kwek</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2002</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We present efficient on-line algorithms for learning unions of a constant number of tree patterns, unions of a constant number of one-variable pattern languages, and unions of a constant number of pattern languages with fixed length substitutions. By fixed length ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:PL_cHq5MJb0J:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13629384158032478012&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13629384158032478012&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="23">
        <url>http://www.springerlink.com/index/953nl87770n8u582.pdf</url>
        <title status="complete" source="scholar.google.com">Mind change complexity of inferring unbounded unions of pattern languages from positive data</title>
        <pdf>http://fs1.bib.tiera.ru/content/dvd52/Balcazar%20J.%20L.%20(Ed),%20Long%20Ph.%20M.%20(Ed),%20Stephan%20F.%20(Ed)%20-%20Algorithmic%20Learning%20Theory.%2017th%20International%20Conference,%20ALT%202006,%20Barcelona,%20Spain,%20October%207-10,%202006,%20Proceedings(2006)(393).pdf#page=135</pdf>
        <author status="complete" source="scholar.google.com">M de Brecht, A Yamamoto</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper gives a proof that the class of unbounded unions of languages of regular patterns with constant segment length bound is inferable from positive data with mind change bound between Ï Ï and www Ï^ Ï^ Ï. We give a very tight bound on the mind change ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:s5QaNydO4G4J:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7989471669290439859&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7989471669290439859&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="24">
        <url>http://iospress.metapress.com/index/TRRD110H759Y5W0B.pdf</url>
        <title status="complete" source="scholar.google.com">The intrinsic complexity of learning: A survey</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/intrinsur.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Fundamenta Informaticae</proceeding>
        <year>2003</year>
        <source>IOS Press</source>
        <snippet status="partial" source="scholar.google.com">The theory of learning in the limit has been a focus of study by several researchers over the last three decades. There have been several suggestions on how to measure the complexity or hardness of learning. In this paper we survey the work done in one specific such ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:b9x1IASxyRcJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1714095764473764975&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1714095764473764975&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="25">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540104000392</url>
        <title status="complete" source="scholar.google.com">On the classification of recursive languages</title>
        <author status="complete" source="scholar.google.com">J Case, E Kinber, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A one-sided classifier for a given class of languages converges to 1 on every language from the class and outputs 0 infinitely often on languages outside the class. A two-sided classifier, on the other hand, converges to 1 on languages from the class and converges to 0 on ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:PVNAR5fT1ogJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9860301080863200061&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9860301080863200061&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="26">
        <url>http://dl.acm.org/citation.cfm?id=307450</url>
        <title status="complete" source="scholar.google.com">On a generalized notion of mistake bounds</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.115.8551&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the twelfth annual conference on &#8230;</proceeding>
        <year>1999</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract The present paper proposes the use of constructive ordinals as mistake bounds in the online learning model. This approach elegantly generalizes the applicability of the on-line mistake bound model to learnability analysis of very expressive concept classes like ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MyqL-H2ICScJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2812929516891744819&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2812929516891744819&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=33</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="27">
        <url>http://www.springerlink.com/index/12017035066353VR.pdf</url>
        <title status="complete" source="scholar.google.com">Resource Restricted Computability Theoretic Learning: Illustrative Topics and Problems</title>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Computation and Logic in the Real World</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Computability theoretic learning theory (machine inductive inference) typically involves learning programs for languages or functions from a stream of complete data about them and, importantly, allows mind changes as to conjectured programs. This theory takes into ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MIjRDNBNqiIJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2497894499293956144&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="28">
        <url>http://www.springerlink.com/index/H4H25161Q638L4N4.pdf</url>
        <title status="complete" source="scholar.google.com">Learning figures with the Hausdorff metric by fractalsâtowards computable binary classification</title>
        <pdf>http://mahito.info/Files/Sugiyama_MLJ01.pdf</pdf>
        <author status="complete" source="scholar.google.com">M Sugiyama, E Hirowatari, H Tsuiki, A Yamamoto</author>
        <proceeding status="complete" source="scholar.google.com">Machine Learning</proceeding>
        <year>2012</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract We present learning of figures, nonempty compact sets in Euclidean space, based on Gold&#39;s learning model aiming at a computable foundation for binary classification of multivariate data. Encoding real vectors with no numerical error requires infinite ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FAyQDaL5NyQJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2609828983492054036&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="29">
        <url>http://www.springerlink.com/index/812361171q2264pu.pdf</url>
        <title status="complete" source="scholar.google.com">Resource Restricted Computability Theoretic Learning: Illustrative Topics and Problems</title>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Theory of Computing Systems</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract Computability theoretic learning theory (machine inductive inference) typically involves learning programs for languages or functions from a stream of complete data about them and, importantly, allows mind changes as to conjectured programs. This theory takes ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cNGIg7j_YKkJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12205036158119891312&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="30">
        <url>http://cs5824.userapi.com/u11728334/docs/d1adaec0a5be/Osamu_Watanabe_Algorithmic_Learning_Theory_10_c.pdf#page=357</url>
        <title status="complete" source="scholar.google.com">On Learnin Unions of Pattern Lan ua es and Tree Patterns</title>
        <pdf>http://cs5824.userapi.com/u11728334/docs/d1adaec0a5be/Osamu_Watanabe_Algorithmic_Learning_Theory_10_c.pdf#page=357</pdf>
        <author status="complete" source="scholar.google.com">SA Goldman, SS Kwek</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <source>cs5824.userapi.com</source>
        <snippet status="partial" source="scholar.google.com">Abs rac. We present e cient on-line al orithms for learnin unions of a constant number of tree patterns, unions of a constant number of onevariable pattern lan ua es, and unions of a constant number of pattern lan ua es with xed len th substitutions. By xed len th ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:tfgGkboi0G8J:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:tfgGkboi0G8J:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8056977918058231989&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="31">
        <title status="complete" source="scholar.google.com">Inductive inference: theories and techniques</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:lKSmli8IdK8J:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="32">
        <title status="complete" source="scholar.google.com">Mathematisches Institut, Universitat Heidelberg 69120 Heidelberg, Germany, EU</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:OnDXsF3WybQJ:scholar.google.com/&amp;hl=en&amp;num=33&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="12">
    <url>http://www.springerlink.com/index/2781772065028428.pdf</url>
    <title status="complete" source="scholar.google.com">Towards a better understanding of incremental learning</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.114.3889&amp;rep=rep1&amp;type=pdf#page=180</pdf>
    <author status="complete" source="scholar.google.com">S Jain, S Lange, S Zilles</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2006</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 School of Computing, National University of Singapore, Singapore 117543sanjay@comp.nus.edu.sg 2 FB Informatik, Hochschule Darmstadt, Haardtring 100,Dâ64295 Darmstadt slange@fbi.h-da.de 3 DFKI GmbH, Erwin-SchrÃ¶dinger-Str. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:yMOath6NN_QJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>12</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=17597689232025633736&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>7</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=17597689232025633736&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="7">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397508001503</url>
        <title status="complete" source="scholar.google.com">Learning indexed families of recursive languages from positive data: A survey</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/tcs08lzz.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, T Zeugmann, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In the past 40 years, research on inductive inference has developed along different lines, eg, in the formalizations used, and in the classes of target concepts considered. One common root of many of these formalizations is Gold&#39;s model of identification in the limit. This model ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:kHdpMOKBOpwJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11257453027040786320&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>39</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11257453027040786320&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/0528274385H23010.pdf</url>
        <title status="complete" source="scholar.google.com">An incremental class boundary preserving hypersphere classifier</title>
        <author status="complete" source="scholar.google.com">N Lopes, B Ribeiro</author>
        <proceeding status="complete" source="scholar.google.com">Neural Information Processing</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Recent progress in sensing, networking and data management has led to a wealth of valuable information. The challenge is to extract meaningful knowledge from such data produced at an astonishing rate. Unlike batch learning algorithms designed under the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:crPH3O0L9YkJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9940864868729467762&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9940864868729467762&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6270399</url>
        <title status="complete" source="scholar.google.com">A GPU-accelerated Approximate Algorithm for Incremental Learning of Gaussian Mixture Model</title>
        <author status="complete" source="scholar.google.com">C Chen, D Mu, H Zhang, B Hong</author>
        <proceeding status="partial" source="scholar.google.com">Parallel and Distributed &#8230;</proceeding>
        <year>2012</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract The Gaussian mixture model (GMM) is a widely used probabilistic clustering model. The incremental learning algorithm of GMM is the basis of a variety of complex incremental learning algorithms. It is typically applied to real-time or massive data problems where the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ihA5GIL3fy8J:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3422726379949068426&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://hss.ulb.uni-bonn.de/2012/3009/3009.pdf</url>
        <title status="complete" source="scholar.google.com">Sequential Learning Using Incremental Import Vector Machines for Semantic Segmentation</title>
        <pdf>http://hss.ulb.uni-bonn.de/2012/3009/3009.pdf</pdf>
        <author status="complete" source="scholar.google.com">R Roscher</author>
        <year>2012</year>
        <source>hss.ulb.uni-bonn.de</source>
        <snippet status="partial" source="scholar.google.com">We propose an innovative machine learning algorithm called incremental import vector machines that is used for classification purposes. The classifier is specifically designed for the task of sequential learning, in which the data samples are successively presented to ...</snippet>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:_XsnMlFq2xsJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.eecis.udel.edu/~case/papers/pr2.pdf</url>
        <title status="complete" source="scholar.google.com">On the Necessity of U-Shaped Learning</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/pr2.pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case</author>
        <proceeding status="complete" source="scholar.google.com">eecis.udel.edu</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. A U-shaped curve in a cognitive-developmental trajectory refers to a three-step process: good performance followed by bad performance followed by good performance once again. U-shaped curves have been observed in a wide variety of cognitive- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17336137048815070431&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTR/tcstr_07_31/tcstr_07_31.pdf</url>
        <title status="complete" source="scholar.google.com">TCS Technical Report</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTR/tcstr_07_31/tcstr_07_31.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, T Zeugmann, S Zilles</author>
        <year>2007</year>
        <source>www-alg.ist.hokudai.ac.jp</source>
        <snippet status="partial" source="scholar.google.com">Abstract In the past 40 years, research on inductive inference has developed along different lines, concerning different formalizations of learning models and in particular of target concepts for learning. One common root of many of these is Gold&#39;s model of identification ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:uMhVpfJ4388J:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:uMhVpfJ4388J:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14978823869208840376&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://dl.acm.org/citation.cfm?id=2398425</url>
        <title status="complete" source="scholar.google.com">A novel local patch framework for fixing supervised learning models</title>
        <pdf>http://www.cs.ucsb.edu/~yileiwang/papers/Local%20Patch.pdf</pdf>
        <author status="partial" source="scholar.google.com">Y Wang, B Wei, J Yan, Y Hu, ZH Deng&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the 21st &#8230;</proceeding>
        <year>2012</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract In the past decades, machine learning models, especially supervised learning algorithms, have been widely used in various real world applications. However, no matter how strong a learning model is, it will suffer from the prediction errors when it is applied to ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="13">
    <url>http://www.springerlink.com/index/5fvlvahq3bcmcvmh.pdf</url>
    <title status="complete" source="scholar.google.com">Learning recursive functions refutably</title>
    <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/alt01jkwz.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen, T Zeugmann</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2001</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 School of Computing, National University of Singapore, Singapore 119260 sanjay@comp.nus.edu.sg 2 Department of Computer Science, Sacred Heart University, Fairfield, CT 06432-1000,USA kinbere@sacredheart.edu 3 Department of Computer Science, University of ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:odjl50e9rvgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>10</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=17919468083884710049&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>5</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=17919468083884710049&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="5">
        <result id="0">
        <url>http://japanlinkcenter.org/JST.JSTAGE/ipsjdc/1.141?from=Google</url>
        <title status="complete" source="scholar.google.com">Refutability and reliability for inductive inference of recursive real-valued functions</title>
        <author status="complete" source="scholar.google.com">E Hirowatari, K Hirata, T Miyahara, S Arikawa</author>
        <proceeding status="complete" source="scholar.google.com">IPSJ Digital Courier</proceeding>
        <year>2005</year>
        <source>J-STAGE</source>
        <snippet status="partial" source="scholar.google.com">Inductive inference gives us a theoretical model of concept learning from examples. In this paper, we study refutably and reliably inductive inference of recursive real-valued functions. First we introduce the new criteria RealRefEx for refutable inference and RealRelEx for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Bj5YkSkJ59QJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15341240729797672454&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15341240729797672454&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/vbxrhekl7drt3k7p.pdf</url>
        <title status="complete" source="scholar.google.com">Reflective inductive inference of recursive functions</title>
        <author status="complete" source="scholar.google.com">G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2002</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In this paper, we investigate reflective inductive inference of recursive functions. A reflective IIM is a learning machine that is additionally able to assess its own competence. First, we formalize reflective learning from arbitrary example sequences. Here, we arrive at four ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:sbmGyIHhwVYJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6251525705298262449&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6251525705298262449&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/H4H25161Q638L4N4.pdf</url>
        <title status="complete" source="scholar.google.com">Learning figures with the Hausdorff metric by fractalsâtowards computable binary classification</title>
        <pdf>http://mahito.info/Files/Sugiyama_MLJ01.pdf</pdf>
        <author status="complete" source="scholar.google.com">M Sugiyama, E Hirowatari, H Tsuiki, A Yamamoto</author>
        <proceeding status="complete" source="scholar.google.com">Machine Learning</proceeding>
        <year>2012</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract We present learning of figures, nonempty compact sets in Euclidean space, based on Gold&#39;s learning model aiming at a computable foundation for binary classification of multivariate data. Encoding real vectors with no numerical error requires infinite ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FAyQDaL5NyQJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2609828983492054036&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://mahito.info/Files/Sugiyama_PhDthesis.pdf</url>
        <title status="complete" source="scholar.google.com">Studies on Computational Learning via Discretization</title>
        <pdf>http://mahito.info/Files/Sugiyama_PhDthesis.pdf</pdf>
        <author status="complete" source="scholar.google.com">M Sugiyama</author>
        <year>2012</year>
        <source>mahito.info</source>
        <snippet status="partial" source="scholar.google.com">Abstract Thisthesispresentscutting-edgestudiesoncomputationallearning. Thekeyissue throughout the thesis is amalgamation of two processes; discretization of continuous objects and learning from such objects provided by data. Machine learning, or data mining and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:QKRXZUBQR78J:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:QKRXZUBQR78J:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13783073422099063872&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://japanlinkcenter.org/JST.JSTAGE/imt/1.33?from=Google</url>
        <title status="complete" source="scholar.google.com">Refutability and Reliability for Inductive Inference of Recursive Real-Valued Functions</title>
        <author status="partial" source="scholar.google.com">E Hirowatari, K Hirata, T Miyahara&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Information and Media &#8230;</proceeding>
        <year>2006</year>
        <source>J-STAGE</source>
        <snippet status="partial" source="scholar.google.com">Inductive inference gives us a theoretical model of concept learning from examples. In this paper, we study refutably and reliably inductive inference of recursive real-valued functions. First we introduce the new criteria RealRefEx for refutable inference and RealRelEx for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:hcYinlfmXMUJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14221494987318806149&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="14">
    <url>http://books.google.com.sg/books?hl=en&amp;lr=&amp;id=iG2gZJHCNH0C&amp;oi=fnd&amp;pg=PR9&amp;dq=%22Jain+Sanjay%22+NUS&amp;ots=O8eqQw8InE&amp;sig=_t3eKJk5r6VofyDgmF11jrGmemg</url>
    <title status="complete" source="scholar.google.com">Systems that learn: An introduction to learning theory</title>
    <pdf>http://www.cis.syr.edu/people/royer/stl2e/upthruChap1.ps</pdf>
    <author status="complete" source="scholar.google.com">S Jain, DN Osherson, JS Royer, A Sharma</author>
    <year>1999</year>
    <source>books.google.com</source>
    <snippet status="partial" source="scholar.google.com">... 3. Human information processingâMathematical models. I. Jain, Sanjay, 1965 Feb. ... We wouldbe pleased to hear from our readership, for better or for worse. To contact us, try:sanjay@iscs.nus.edu.sg, osherson@rice.edu, royer@top.cis.syr.edu, or arun@cse unsw edu ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:CBR0n2k50uUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>7</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=16560361905604269064&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>383</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=16560361905604269064&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="383">
        <result id="0">
        <url>http://www.degruyter.com/view/j/tlir.2002.19.issue-1-2/tlir.19.1-2.9/tlir.19.1-2.9.xml</url>
        <title status="complete" source="scholar.google.com">Empirical assessment of stimulus poverty arguments</title>
        <pdf>http://www.ucd.ie/artspgs/research/pullum.pdf</pdf>
        <author status="complete" source="scholar.google.com">GK Pullum, BC Scholz</author>
        <proceeding status="complete" source="scholar.google.com">The Linguistic Review</proceeding>
        <year>2002</year>
        <source>degruyter.com</source>
        <snippet status="partial" source="scholar.google.com">Abstract This article examines a type of argument for linguistic nativism that takes the following form:(i) a fact about some natural language is exhibited that allegedly could not be learned from experience without access to a certain kind of (positive) data;(ii) it is claimed ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:DJo_CxyQHnMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>15</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8295226013785233932&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>359</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8295226013785233932&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://journals.cambridge.org/abstract_s0140525x08004998</url>
        <title status="complete" source="scholar.google.com">Language as shaped by the brain</title>
        <pdf>http://sites.google.com/site/andrewdmsmith/publications/papers/2008_thebrainplustheculturaltransmissionmechanismdeterminethenatureoflanguage.pdf</pdf>
        <author status="complete" source="scholar.google.com">MH Christiansen, N Chater</author>
        <proceeding status="complete" source="scholar.google.com">Behavioral and Brain Sciences</proceeding>
        <year>2008</year>
        <source>Cambridge Univ Press</source>
        <snippet status="partial" source="scholar.google.com">Abstract It is widely assumed that human learning and the structure of human languages are intimately related. This relationship is frequently suggested to derive from a language-specific biological endowment, which encodes universal, but communicatively arbitrary, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Xd0wfVCDgYsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>43</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10052460224988634461&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>269</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10052460224988634461&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <title status="complete" source="scholar.google.com">Language evolution</title>
        <pdf>http://www.lel.ed.ac.uk/~simon/Papers/Christiansen/Language%20Evolution%20The%20Hardest%20Problem%20in%20Science%3F.pdf</pdf>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:-4LAOaCECVgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>19</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6343747373826605819&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>239</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6343747373826605819&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://journals.cambridge.org/abstract_S0305000904006336</url>
        <title status="complete" source="scholar.google.com">A multiple process solution to the logical problem of language acquisition</title>
        <pdf>http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1876779/</pdf>
        <author status="complete" source="scholar.google.com">B MacWhinney</author>
        <proceeding status="complete" source="scholar.google.com">Journal of child language</proceeding>
        <year>2004</year>
        <source>Cambridge Univ Press</source>
        <snippet status="partial" source="scholar.google.com">Abstract Many researchers believe that there is a logical problem at the centre of language acquisition theory. According to this analysis, the input to the learner is too inconsistent and incomplete to determine the acquisition of grammar. Moreover, when corrective feedback ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:hOOeJcfjqRMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1416914002253898628&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>144</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1416914002253898628&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.sciencedirect.com/science/article/pii/S0364021304000060</url>
        <title status="complete" source="scholar.google.com">Artificial syntactic violations activate Broca&#39;s region</title>
        <pdf>http://csjarchive.cogsci.rpi.edu/2004v28/i03/p0383p0407/00000164.PDF</pdf>
        <author status="complete" source="scholar.google.com">KM Petersson, C Forkstam, M Ingvar</author>
        <proceeding status="complete" source="scholar.google.com">Cognitive science</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In the present study, using event-related functional magnetic resonance imaging, we investigated a group of participants on a grammaticality classification task after they had been exposed to well-formed consonant strings generated from an artificial regular ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:lsNMTSDfihwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2056701509676876694&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>87</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2056701509676876694&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=XAOE5V9B4dUC&amp;oi=fnd&amp;pg=PR9&amp;ots=ray8snPGbK&amp;sig=Zvmeo9teN2XHZo92pPysqeLLKpU</url>
        <title status="complete" source="scholar.google.com">Grammatical inference: learning automata and grammars</title>
        <pdf>http://carbon.ijs.si/site/normal_dl/tag=71561/bootcamp2010_higuera_gi_01.pdf</pdf>
        <author status="complete" source="scholar.google.com">C De la Higuera</author>
        <year>2010</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">The problem of inducing, learning or inferring grammars has been studied for decades, but only in recent years has grammatical inference emerged as an independent field with connections to many scientific disciplines, including bio-informatics, computational ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:8k75NW0x-QgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=646602366631104242&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>94</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=646602366631104242&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://dspace.ou.nl/handle/1820/65</url>
        <title status="complete" source="scholar.google.com">Learning Networks: connecting people, organizations, autonomous agents and learning resources to establish the emergence of effective lifelong learning</title>
        <pdf>http://dspace.ou.nl/bitstream/1820/65/1/progplan%20Learning%20Networks.pdf</pdf>
        <author status="complete" source="scholar.google.com">R Koper, P Sloep</author>
        <year>2002</year>
        <source>dspace.ou.nl</source>
        <snippet status="partial" source="scholar.google.com">Page 1. Learning Networks connecting people, organizations, autonomous agents andlearning resources to establish the emergence of effective lifelong learning LearningTechnology Development Programme 2003 - 2008 More is different â¦ ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:5Uo-UlZrEwwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=870157171503811301&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>71</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=870157171503811301&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.degruyter.com/view/j/tlir.2002.19.issue-1-2/tlir.19.1-2.185/tlir.19.1-2.185.xml</url>
        <title status="complete" source="scholar.google.com">Searching for arguments to support linguistic nativism</title>
        <pdf>http://www.ling.uni-potsdam.de/~rvogel/grundlagen/sp02.pdf</pdf>
        <author status="complete" source="scholar.google.com">BC Scholz, GK Pullum</author>
        <proceeding status="complete" source="scholar.google.com">The Linguistic Review</proceeding>
        <year>2002</year>
        <source>degruyter.com</source>
        <snippet status="partial" source="scholar.google.com">Abstract This article is a reply to the foregoing responses to our âEmpirical assessment of stimulus poverty argumentsâ(Pullum and Scholz, this special volume, here-after EASPA). We first address certain philosophical themes that cut across all six responses. We correct the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:eP3RhbOIXEQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4925962397062135160&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>63</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4925962397062135160&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.sciencedirect.com/science/article/pii/S0022249606001209</url>
        <title status="complete" source="scholar.google.com">&#39;Ideal learning&#39;of natural language: Positive results about learning from positive evidence</title>
        <pdf>http://eprints.pascal-network.org/archive/00002798/01/jmp06.pdf</pdf>
        <author status="complete" source="scholar.google.com">N Chater, P VitÃ¡nyi</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Mathematical Psychology</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Gold&#39;s [1967. Language identification in the limit. Information and Control, 16, 447â474] celebrated work on learning in the limit has been taken, by many cognitive scientists, to have powerful negative implications for the learnability of language from positive data (ie, from ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:mQ3ZK_kC2X0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9068282593892961689&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>60</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9068282593892961689&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397508001503</url>
        <title status="complete" source="scholar.google.com">Learning indexed families of recursive languages from positive data: A survey</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/tcs08lzz.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, T Zeugmann, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In the past 40 years, research on inductive inference has developed along different lines, eg, in the formalizations used, and in the classes of target concepts considered. One common root of many of these formalizations is Gold&#39;s model of identification in the limit. This model ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:kHdpMOKBOpwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11257453027040786320&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>39</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11257453027040786320&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://repository.cmu.edu/cgi/viewcontent.cgi?article=1382&amp;context=philosophy</url>
        <title status="complete" source="scholar.google.com">Why probability does not capture the logic of scientific justification</title>
        <pdf>http://repository.cmu.edu/cgi/viewcontent.cgi?article=1382&amp;context=philosophy</pdf>
        <author status="complete" source="scholar.google.com">KT Kelly, C Glymour</author>
        <year>2004</year>
        <source>repository.cmu.edu</source>
        <snippet status="partial" source="scholar.google.com">Here is the usual way philosophers think about science and induction. Scientists do many thingsâaspire, probe, theorize, conclude, retract, and refineâbut successful research culminates in a published research report that presents an argument for some empirical ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:v6vd7OFqc3MJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8319110455257574335&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>35</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8319110455257574335&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://www.ling.uni-potsdam.de/~rvogel/grundlagen/SP05.pdf</url>
        <title status="complete" source="scholar.google.com">Irrational nativist exuberance</title>
        <pdf>http://www.ling.uni-potsdam.de/~rvogel/grundlagen/SP05.pdf</pdf>
        <author status="complete" source="scholar.google.com">BC Scholz, GK Pullum</author>
        <proceeding status="partial" source="scholar.google.com">Contemporary debates in cognitive &#8230;</proceeding>
        <year>2006</year>
        <source>ling.uni-potsdam.de</source>
        <snippet status="partial" source="scholar.google.com">The protracted dispute over the degree of independence of language acquisition from sensory experience often degenerates into an unsavory cavalcade of exaggerated claims, tendentious rhetoric, and absurd parodies of opposing views. In this chapter, however, we ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:SVvbzH0buisJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:SVvbzH0buisJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3150861116420873033&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>32</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3150861116420873033&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <url>http://www.mitpressjournals.org/doi/abs/10.1162/LING_a_00015</url>
        <title status="complete" source="scholar.google.com">Learning long-distance phonotactics</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.180.3043&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Heinz</author>
        <proceeding status="complete" source="scholar.google.com">Linguistic Inquiry</proceeding>
        <year>2010</year>
        <source>MIT Press</source>
        <snippet status="partial" source="scholar.google.com">This article shows that specific properties of long-distance phonotactic patterns derived from consonantal harmony patterns (Hansson 2001, Rose and Walker 2004) follow from a learner that generalizes only on the basis of the order of sounds, not the distance between ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:d3LEEnz3WhkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1827044711115027063&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>31</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1827044711115027063&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="13">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397502000750</url>
        <title status="complete" source="scholar.google.com">Identification of function distinguishable languages</title>
        <author status="complete" source="scholar.google.com">H Fernau</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We show how appropriately chosen functions f which we call distinguishing can be used to make deterministic finite automata backward deterministic. This idea can be exploited to design regular language classes called f-distinguishable which are identifiable in the limit ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:gKIb9zEsYfQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17609404611106153088&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>29</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17609404611106153088&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="14">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397501004042</url>
        <title status="complete" source="scholar.google.com">On the power of incremental learning</title>
        <author status="complete" source="scholar.google.com">S Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2002</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper provides a systematic study of incremental learning from noise-free and from noisy data. As usual, we distinguish between learning from positive data and learning from positive and negative data, synonymously called learning from text and learning from ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:9XQsOKjr0GIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7120450118602224885&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>27</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7120450118602224885&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="15">
        <url>http://www.springerlink.com/index/A7GT969GQYX97XY5.pdf</url>
        <title status="complete" source="scholar.google.com">Consistent Identification in the Limit of Any of the Classes k-Valued Is NP-hard</title>
        <author status="complete" source="scholar.google.com">C FlorÃªncio</author>
        <proceeding status="complete" source="scholar.google.com">Logical Aspects of Computational Linguistics</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In [Bus87],[BP90]&#39;discovery procedures&#39; for CCGs were defined that accept a sequence of structures as input and yield a set of grammars. In [Kan98] it was shown that some of the classes based on these procedures are learnable (in the technical sense of [Gol67]). In [ ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:VnjEySzcjnUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8470950034052249686&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>26</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8470950034052249686&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="16">
        <url>http://www.springerlink.com/index/U775M8U16Q7472J3.pdf</url>
        <title status="complete" source="scholar.google.com">Justification as truth-finding efficiency: how Ockham&#39;s Razor works</title>
        <pdf>http://repository.cmu.edu/cgi/viewcontent.cgi?article=1380&amp;context=philosophy</pdf>
        <author status="complete" source="scholar.google.com">KT Kelly</author>
        <proceeding status="complete" source="scholar.google.com">Minds and Machines</proceeding>
        <year>2004</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">I propose that empirical procedures, like computational procedures, are justified in terms of truth-finding efficiency. I contrast the idea with more standard philosophies of science and illustrate it by deriving Ockham&#39;s razor from the aim of minimizing dramatic changes of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:75jowYcIOfAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17309876021942065391&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>25</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17309876021942065391&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="17">
        <url>http://www.springerlink.com/index/R45G1727V6G57789.pdf</url>
        <title status="complete" source="scholar.google.com">On abstract computer virology from a recursion theoretic perspective</title>
        <pdf>http://hal.archives-ouvertes.fr/docs/00/11/51/99/PDF/jcv06.pdf</pdf>
        <author status="complete" source="scholar.google.com">G Bonfante, M Kaczmarek, JY Marion</author>
        <proceeding status="complete" source="scholar.google.com">Journal in computer virology</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract We are concerned with theoretical aspects of computer viruses. For this, we suggest a new definition of viruses which is clearly based on the iteration theorem and above all on Kleene&#39;s recursion theorem. We in this study capture in a natural way previous definitions, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:5G9YFBdv4OAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>21</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16204073604195315684&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>25</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16204073604195315684&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="18">
        <url>http://www.jstor.org/stable/10.1086/423752</url>
        <title status="complete" source="scholar.google.com">Gold&#39;s Theorem and Cognitive Science*</title>
        <pdf>http://www.afhalifax.ca/magazine/wp-content/sciences/for-emgold/Johnson.GoldsTheorem.pdf</pdf>
        <author status="complete" source="scholar.google.com">K Johnson</author>
        <proceeding status="complete" source="scholar.google.com">Philosophy of Science</proceeding>
        <year>2004</year>
        <source>JSTOR</source>
        <snippet status="partial" source="scholar.google.com">A variety of inaccurate claims about Gold&#39;s Theorem have appeared in the cognitive science literature. I begin by characterizing the logic of this theorem and its proof. I then examine several claims about Gold&#39;s Theorem, and I show why they are false. Finally, I assess the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:XejiLDKGagYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>27</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=462329461818452061&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>26</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=462329461818452061&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="19">
        <url>http://www.springerlink.com/index/03BNCPWMGPE9TWHU.pdf</url>
        <title status="complete" source="scholar.google.com">Identification of function distinguishable languages</title>
        <pdf>http://cs5824.userapi.com/u11728334/docs/45c43340f2ae/Hiroki_Arimura_Algorithmic_Learning_Theory_11_c.pdf#page=126</pdf>
        <author status="complete" source="scholar.google.com">H Fernau</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We show how appropriately chosen functions which we call distinguishing can be used to make deterministic finite automata backward deterministic. These ideas can be exploited to design regular language classes identifiable in the limit from positive samples. Special ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:pUiw2UwyKTIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3614475481592645797&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>25</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3614475481592645797&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="20">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397508001497</url>
        <title status="complete" source="scholar.google.com">Discontinuities in pattern inference</title>
        <pdf>https://dspace.lboro.ac.uk/dspace/bitstream/2134/3469/3/Reidenbach_TCS_Discontinuities_Pattern_Inference.pdf</pdf>
        <author status="complete" source="scholar.google.com">D Reidenbach</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper deals with the inferrability of classes of E-pattern languagesâalso referred to as extended or erasing pattern languagesâfrom positive data in Gold&#39;s model of identification in the limit. The first main part of the paper shows that the recently presented negative result ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:j-9N_GCa18kJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14544263262956810127&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>24</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14544263262956810127&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="21">
        <url>http://journals.cambridge.org/production/action/cjoGetFulltext?fulltextid=350696</url>
        <title status="complete" source="scholar.google.com">The Subset Principle in syntax: Costs of compliance</title>
        <pdf>http://www.colag.cs.hunter.cuny.edu/pub/Fodor_Sakas_SP_2005.pdf</pdf>
        <author status="complete" source="scholar.google.com">JD Fodor, WG Sakas</author>
        <proceeding status="partial" source="scholar.google.com">JOURNAL OF LINGUISTICS- &#8230;</proceeding>
        <year>2005</year>
        <source>Cambridge Univ Press</source>
        <snippet status="partial" source="scholar.google.com">Following Hale &amp; Reiss&#39; paper on the Subset Principle (SP) in phonology, we draw attention here to some unsolved problems in the application of SP to syntax acquisition. While noting connections to formal results in computational linguistics, our focus is on how SP could be ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ws8JLxrCepgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10987307658637856706&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>24</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10987307658637856706&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="22">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=Tr8V5M1W0LYC&amp;oi=fnd&amp;pg=PA11&amp;ots=ET2nqGOrWg&amp;sig=IKLEaDxSbxuMpfMlTGwGFbInMj0</url>
        <title status="complete" source="scholar.google.com">The logic of success</title>
        <pdf>http://repository.cmu.edu/cgi/viewcontent.cgi?article=1384&amp;context=philosophy</pdf>
        <author status="complete" source="scholar.google.com">KT Kelly</author>
        <proceeding status="complete" source="scholar.google.com">Philosophy of science today</proceeding>
        <year>2000</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">The problem of induction reminds us that science cannot wait for empirical hypotheses to be verified and Duhem&#39;s problem reminds us that we cannot expect full refutations either. We must settle for something less. The shape of this something less depends on which ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:eCLrHoB3SpEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10469311675934384760&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>21</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10469311675934384760&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="23">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397507003222</url>
        <title status="complete" source="scholar.google.com">Ockham&#39;s razor, empirical complexity, and truth-finding efficiency</title>
        <pdf>http://repository.cmu.edu/cgi/viewcontent.cgi?article=1376&amp;context=philosophy</pdf>
        <author status="complete" source="scholar.google.com">KT Kelly</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The nature of empirical simplicity and its relationship to scientific truth are long-standing puzzles. In this paper, empirical simplicity is explicated in terms of empirical effects, which are defined in terms of the structure of the inference problem addressed. Problem ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:-KjAOR7aYosJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10043829942342428920&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>21</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10043829942342428920&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="24">
        <url>http://dl.acm.org/citation.cfm?id=1654531</url>
        <title status="complete" source="scholar.google.com">Item-based constructions and the logical problem</title>
        <pdf>http://acl.ldc.upenn.edu/W/W05/W05-05.pdf#page=61</pdf>
        <author status="complete" source="scholar.google.com">B MacWhinney</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the Workshop on Psychocomputational &#8230;</proceeding>
        <year>2005</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract The logical problem of language is grounded on arguments from poverty of positive evidence and arguments from poverty of negative evidence. Careful analysis of child language corpora shows that, if one assumes that children learn through item-based ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:6r4xWLqnetkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>32</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15671022272174472938&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>22</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15671022272174472938&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="25">
        <url>http://www.springerlink.com/index/prebbr91cb17uenx.pdf</url>
        <title status="complete" source="scholar.google.com">Unlearning helps</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2205/1/TRA5-06.pdf</pdf>
        <author status="complete" source="scholar.google.com">G Baliga, J Case, W Merkle, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">Automata, Languages and &#8230;</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Overregularization seen in child language learning, re verb tense constructs, involves abandoning correct behaviors for incorrect ones and later reverting to correct behaviors. Quite a number of other child development phenomena also follow this U-shaped form of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Kz0TSnrOJQwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>24</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=875332727217536299&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>20</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=875332727217536299&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="26">
        <url>http://journals.cambridge.org/production/action/cjoGetFulltext?fulltextid=6095808</url>
        <title status="complete" source="scholar.google.com">On the role of locality in learning stress patterns</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.149.6123&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Heinz</author>
        <proceeding status="complete" source="scholar.google.com">Phonology</proceeding>
        <year>2009</year>
        <source>Cambridge Univ Press</source>
        <snippet status="partial" source="scholar.google.com">This paper presents a previously unnoticed universal property of stress patterns in the world&#39;s languages: they are, for small neighbourhoods, neighbourhooddistinct. Neighbourhood-distinctness is a locality condition defined in automatatheoretic terms. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:vITnvfLaBGkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7567414009992283324&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>22</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7567414009992283324&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="27">
        <url>http://repository.cmu.edu/philosophy/384/</url>
        <title status="complete" source="scholar.google.com">Ockham&#39;s razor, truth, and information</title>
        <pdf>http://repository.cmu.edu/cgi/viewcontent.cgi?article=1375&amp;context=philosophy</pdf>
        <author status="complete" source="scholar.google.com">KT Kelly</author>
        <year>2007</year>
        <source>repository.cmu.edu</source>
        <snippet status="partial" source="scholar.google.com">Abstract In science, one faces the problem of selecting the true theory from a range of alternative theories. The typical response is to select the simplest theory compatible with available evidence, on the authority of âOckham&#39;s Razorâ. But how can a fixed bias toward ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:aqNZAX8gP2wJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7799988809484575594&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>19</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7799988809484575594&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="28">
        <url>http://www.colag.cs.hunter.cuny.edu/pub/FodorSakasBUCLD28.pdf</url>
        <title status="complete" source="scholar.google.com">Evaluating models of parameter setting</title>
        <pdf>http://www.colag.cs.hunter.cuny.edu/pub/FodorSakasBUCLD28.pdf</pdf>
        <author status="complete" source="scholar.google.com">JD Fodor, WG Sakas</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the 28th Annual &#8230;</proceeding>
        <year>2004</year>
        <source>colag.cs.hunter.cuny.edu</source>
        <snippet status="partial" source="scholar.google.com">Our research group has built a research environment for testing models of syntactic parameter setting. We have created a domain of 3,072 languages with up to 1,432 sentences in each, defined by a set of Universal Grammar (UG) rules and 13 (so far) ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:aYb5X-NWO98J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:aYb5X-NWO98J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numCite>21</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16085546028651611753&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="29">
        <url>http://www.springerlink.com/index/dhnm8ddvum0w11lk.pdf</url>
        <title status="complete" source="scholar.google.com">Supporting increment and decrement operations in balancing networks</title>
        <pdf>http://bit.csc.lsu.edu/~busch/papers/journal/2000-CJTCS-antitokens.pdf</pdf>
        <author status="partial" source="scholar.google.com">W Aiello, C Busch, M Herlihy, M Mavronicolas, N Shavit&#8230;</author>
        <proceeding status="complete" source="scholar.google.com">STACS 99</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Counting networks are a class of distributed data structures that support highly concurrent implementations of shared Fetch&amp;Increment counters. Applications of these counters include shared pools and stacks, load balancing, and software barriers [4, 12, 13, 18]. A ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:AD1qFSokE5gJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>24</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10958142081489059072&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>18</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10958142081489059072&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="30">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.25.5007&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">A limiting rst order realizability interpretation</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.25.5007&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">M Nakata, S Hayashi</author>
        <proceeding status="complete" source="scholar.google.com">SCMJ Online</proceeding>
        <year>2001</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. Constructive Mathematics might be regarded as a fragment of classical mathematics in which any proof of an existence theorem is equipped with a computable function giving the solution of the theorem. Limit Computable Mathematics (LCM) ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:fxCSabkZe8YJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:fxCSabkZe8YJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14302053325775966335&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>19</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14302053325775966335&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="31">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540107000491</url>
        <title status="complete" source="scholar.google.com">Results on memory-limited U-shaped learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.8567&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">U-shaped learning is a learning behaviour in which the learner first learns a given target behaviour, then unlearns it and finally relearns it. Such a behaviour, observed by psychologists, for example, in the learning of past-tenses of English verbs, has been ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:aPOveNlKjhoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>23</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1913549189572195176&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>21</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1913549189572195176&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="32">
        <url>http://repository.cmu.edu/philosophy/390/</url>
        <title status="complete" source="scholar.google.com">Efficient convergence implies Ockham&#39;s Razor</title>
        <pdf>http://repository.cmu.edu/cgi/viewcontent.cgi?article=1385&amp;context=philosophy</pdf>
        <author status="complete" source="scholar.google.com">KT Kelly</author>
        <year>2005</year>
        <source>repository.cmu.edu</source>
        <snippet status="partial" source="scholar.google.com">Abstract A finite data set is consistent with infinitely many alternative theories. Scientific realists recommend that we prefer the simplest one. Anti-realists ask how a fixed simplicity bias could track the truth when the truth might be complex. It is no solution to impose a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:QzdAp4dIkW4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7967228963258906435&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>18</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7967228963258906435&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="33">
        <url>http://www.springerlink.com/index/vwb843xljvqtaaeb.pdf</url>
        <title status="complete" source="scholar.google.com">Consistent Identification in the Limit of Rigid Grammars from Strings is NP-hard</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.11.4640&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">C FlorÃªncio</author>
        <proceeding status="complete" source="scholar.google.com">Grammatical Inference: Algorithms and Applications</proceeding>
        <year>2002</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In [Bus87] and [BP90] some &#39;discovery procedures&#39; for classical categorial grammars were defined. These procedures take a set of structures (strings labeled with derivational information) as input and yield a set of hypotheses in the form of grammars. In [Kan98] ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:sDVZ0LK8qIoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9991443249507153328&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>18</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9991443249507153328&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="34">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000001917593</url>
        <title status="complete" source="scholar.google.com">Language learning from texts: Degrees of intrinsic complexity and their characterizations</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/rolfintrin.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper deals with two problems:(1) what makes languages learnable in the limit by natural strategies of varying hardness, and (2) what makes classes of languages the hardest ones to learn. To quantify hardness of learning, we use intrinsic complexity based on ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:8fj8PkF24gUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=424031337527965937&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>17</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=424031337527965937&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="35">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540107001095</url>
        <title status="complete" source="scholar.google.com">When unlearning helps</title>
        <author status="partial" source="scholar.google.com">G Baliga, J Case, W Merkle, F Stephan&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Information and &#8230;</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Overregularization seen in child language learning, for example, verb tense constructs, involves abandoning correct behaviours for incorrect ones and later reverting to correct behaviours. Quite a number of other child development phenomena also follow this U- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:4FHwvqlchk8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5730369459998183904&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>18</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5730369459998183904&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="36">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397503006406</url>
        <title status="complete" source="scholar.google.com">Uncomputability: the problem of induction internalized</title>
        <pdf>http://repository.cmu.edu/cgi/viewcontent.cgi?article=1381&amp;context=philosophy</pdf>
        <author status="complete" source="scholar.google.com">KT Kelly</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">I argue that uncomputable formal problems are intuitively, mathematically, and methodologically analogous to empirical problems in which Hume&#39;s problem of induction arises. In particular, I show that a version of Ockham&#39;s razor (a preference for simple ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:0I6WLUvn5McJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14403891818311093968&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>18</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14403891818311093968&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="37">
        <url>http://www.springerlink.com/index/P8T30NK152182338.pdf</url>
        <title status="partial" source="scholar.google.com">Computing Machines Can&#39;t Be Intelligent (... and Turing Said So)</title>
        <pdf>http://research.cs.queensu.ca/home/akl/cisc879/papers/PAPERS_FROM_MINDS_AND_MACHINES/VOLUME_12_NO_4/P8T30NK152182338.pdf</pdf>
        <author status="complete" source="scholar.google.com">P Kugel</author>
        <proceeding status="complete" source="scholar.google.com">Minds and Machines</proceeding>
        <year>2002</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">According to the conventional wisdom, Turing (1950) said that computing machines can be intelligent. I don&#39;t believe it. I think that what Turing really said was that computing machinesâ-computers limited to computingâ-can only fake intelligence. If we want computers to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:KsMPkx9YLssJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14640736331262575402&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>16</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14640736331262575402&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="38">
        <url>http://stanford.library.usyd.edu.au/entries/learning-formal/</url>
        <title status="complete" source="scholar.google.com">Formal learning theory</title>
        <pdf>http://stanford.library.usyd.edu.au/entries/learning-formal/</pdf>
        <author status="complete" source="scholar.google.com">O Schulte</author>
        <year>2008</year>
        <source>stanford.library.usyd.edu.au</source>
        <snippet status="partial" source="scholar.google.com">Formal learning theory is the mathematical embodiment of a normative epistemology. It deals with the question of how an agent should use observations about her environment to arrive at correct and informative conclusions. Philosophers such as Putnam, Glymour and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:sw_02_yLsXgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8696886273567362995&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>15</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8696886273567362995&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="39">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397508001400</url>
        <title status="complete" source="scholar.google.com">Learning recursive functions: A survey</title>
        <pdf>http://webdocs.cs.ualberta.ca/~zilles/zeugmannZ08survey.pdf</pdf>
        <author status="complete" source="scholar.google.com">T Zeugmann, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Studying the learnability of classes of recursive functions has attracted considerable interest for at least four decades. Starting with Gold&#39;s (1967) model of learning in the limit, many variations, modifications and extensions have been proposed. These models differ in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2f2VA5VmFfUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17660134303999589849&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>14</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17660134303999589849&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="40">
        <url>http://www.illc.uva.nl/~seop/archives/sum2010/entries/innateness-language/</url>
        <title status="complete" source="scholar.google.com">Innateness and language</title>
        <pdf>http://www.illc.uva.nl/~seop/archives/sum2010/entries/innateness-language/</pdf>
        <author status="complete" source="scholar.google.com">F Cowie</author>
        <proceeding status="complete" source="scholar.google.com">Stanford Encyclopedia of Philosophy</proceeding>
        <year>2010</year>
        <source>illc.uva.nl</source>
        <snippet status="partial" source="scholar.google.com">The philosophical debate over innate ideas and their role in the acquisition of knowledge has a venerable history. It is thus surprising that very little attention was paid until early last century to the questions of how linguistic knowledge is acquired and what role, if any, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GpA62hukXdwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15879028300710580250&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>16</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15879028300710580250&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="41">
        <url>http://onlinelibrary.wiley.com/doi/10.1002/9780470147658.chpsy0214/full</url>
        <title status="complete" source="scholar.google.com">Cognitive science and cognitive development</title>
        <author status="complete" source="scholar.google.com">F Keil</author>
        <proceeding status="complete" source="scholar.google.com">Handbook of child psychology</proceeding>
        <year>2007</year>
        <source>Wiley Online Library</source>
        <snippet status="partial" source="scholar.google.com">The interdisciplinary field of cognitive science represents an important way to study cognitive development. It offers insights on the mind in development that are not always apparent when considering cognitive development more narrowly from the perspectives of one of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Fuiu-hpU3iQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2656653305046820886&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>16</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2656653305046820886&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="42">
        <url>http://diss.kib.ki.se/2005/91-7140-304-3/thesis.pdf</url>
        <title status="complete" source="scholar.google.com">Learning and memory in the human brain</title>
        <pdf>http://diss.kib.ki.se/2005/91-7140-304-3/thesis.pdf</pdf>
        <author status="complete" source="scholar.google.com">KM Petersson</author>
        <year>2005</year>
        <source>diss.kib.ki.se</source>
        <snippet status="partial" source="scholar.google.com">Page 1. From the Department of Clinical Neuroscience Cognitive Neurophysiology ResearchGroup Karolinska Institutet 171 76 Stockholm Sweden LEARNING AND MEMORY IN THE HUMANBRAIN Karl Magnus Petersson Stockholm 2005 ISBN 91-7140-304-3 Page 2. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2y4mCq0I_wkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=720304004695207643&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=720304004695207643&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="43">
        <url>http://www.springerlink.com/index/0G9NMQXG2TJYL0N0.pdf</url>
        <title status="complete" source="scholar.google.com">Permutations and control sets for learning non-regular language families</title>
        <author status="complete" source="scholar.google.com">H Fernau, J Sempere</author>
        <proceeding status="partial" source="scholar.google.com">Grammatical Inference: Algorithms and &#8230;</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="complete" source="scholar.google.com">We discuss two versatile methods which can be used to transfer learnability results from one language class to another. We apply these methodologies to three learning paradigms:(1) Learning in the limit,(2) Morphic generator grammar inference, and (3) Query learning.</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:oGMaDyVvzeUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16559013609869042592&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16559013609869042592&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="44">
        <url>http://www.springerlink.com/index/94W6377H22714315.pdf</url>
        <title status="complete" source="scholar.google.com">Bridging learning theory and dynamic epistemic logic</title>
        <pdf>http://dare.uva.nl/document/170255</pdf>
        <author status="complete" source="scholar.google.com">N Gierasimczuk</author>
        <proceeding status="complete" source="scholar.google.com">Synthese</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper discusses the possibility of modelling inductive inference (Gold 1967) in dynamic epistemic logic (see eg van Ditmarsch et al. 2007). The general purpose is to propose a semantic basis for designing a modal logic for learning in the limit. First, we ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:e-a2AGVslUEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4725802565054686843&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4725802565054686843&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="45">
        <url>http://www.springerlink.com/index/jw5445p387l860p6.pdf</url>
        <title status="complete" source="scholar.google.com">Inferability of closed set systems from positive data</title>
        <pdf>http://cs5128.userapi.com/u11728334/docs/1293ed13081f/Takashi_Washio_New_Frontiers_in_Artificial_Inte.pdf#page=267</pdf>
        <author status="partial" source="scholar.google.com">M de Brecht, M Kobayashi, H Tokunaga&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">New Frontiers in Artificial &#8230;</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In this paper, we generalize previous results showing connections between inductive inference from positive data and algebraic structures by using tools from universal algebra. In particular, we investigate the inferability from positive data of language classes defined ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:woe9YiaC4SwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3234009108805683138&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3234009108805683138&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="46">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397502004188</url>
        <title status="complete" source="scholar.google.com">Advanced elementary formal systems</title>
        <pdf>http://lia.ufc.br/~wladimir/mestrado/%5BLange%5DAdvanced%20elementary%20formal%20systems,%20Theoretical%20Computer%20Science,%20Volume%20298,%20Issue%201.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, G Grieser, KP Jantke</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">An elementary formal system (EFS) is a logic program such as a Prolog program, for instance, that directly manipulates strings. Arikawa and his co-workers proposed elementary formal systems as a unifying framework for formal language learning. In the present paper, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:zgpXZQ3BLzwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4336897229460015822&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4336897229460015822&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="47">
        <url>http://www.springerlink.com/index/b3377t73n174233v.pdf</url>
        <title status="complete" source="scholar.google.com">Mind change optimal learning of bayes net structure</title>
        <pdf>http://mind-change-bayes-net.googlecode.com/svn-history/r47/trunk/mcbayes-journal.pdf</pdf>
        <author status="complete" source="scholar.google.com">O Schulte, W Luo, R Greiner</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper analyzes the problem of learning the structure of a Bayes net (BN) in the theoretical framework of Gold&#39;s learning paradigm. Bayes nets are one of the most prominent formalisms for knowledge representation and probabilistic and causal ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:BQzlZsbEb8cJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>25</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14370921292371397637&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14370921292371397637&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="48">
        <url>http://projecteuclid.org/euclid.jsl/1080938842</url>
        <title status="complete" source="scholar.google.com">Parsimony hierarchies for inductive inference</title>
        <pdf>http://pdf.aminer.org/002/865/517/parsimony_hierarchies_for_inductive_inference.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Ambainis, J Case, S Jain, M Suraj</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
        <year>2004</year>
        <source>projecteuclid.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Freivalds defined an acceptable programming system independent criterion for learning programs for functions in which the final programs were required to be both correct and ânearlyâ minimal size, ie, within a computable function of being purely minimal size. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:PPOiazrZf9IJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15168080914944291644&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15168080914944291644&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="49">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540106000253</url>
        <title status="complete" source="scholar.google.com">Mind change efficient learning</title>
        <pdf>http://mind-change-bayes-net.googlecode.com/svn/branches/mclc.pdf</pdf>
        <author status="complete" source="scholar.google.com">W Luo, O Schulte</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2006</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper studies efficient learning with respect to mind changes. Our starting point is the idea that a learner that is efficient with respect to mind changes minimizes mind changes not only globally in the entire learning problem, but also locally in subproblems after receiving ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Nc6YcK5juMUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14247247022051085877&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14247247022051085877&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="50">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000000917008</url>
        <title status="complete" source="scholar.google.com">Robust learning is rich</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.96.6122&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, C Smith, R Wiehagen</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Intuitively, a class of objects is robustly learnable if not only this class itself is learnable but all of its computable transformations remain learnable as well. In that sense, being learnable robustly seems to be a desirable property in all fields of learning. We will study this ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1RLuCKYwPi8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3404211858011198165&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3404211858011198165&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="51">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000007000797</url>
        <title status="complete" source="scholar.google.com">Non-U-shaped vacillatory and team learning</title>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">Journal of Computer and System &#8230;</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">U-shaped learning behaviour in cognitive development involves learning, unlearning and relearning. It occurs, for example, in learning irregular verbs. The prior cognitive science literature is occupied with how humans do it, for example, general rules versus tables of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:EQmrDMaxldIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15174229983668930833&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15174229983668930833&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="52">
        <url>http://www.springerlink.com/index/FFUUH184HP1XJ6KG.pdf</url>
        <title status="complete" source="scholar.google.com">Learning in logic with richprolog</title>
        <pdf>http://www.cs.toronto.edu/~ntp/studies/ICLP2002.pdf</pdf>
        <author status="complete" source="scholar.google.com">E Martin, P Nguyen, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Logic Programming</proceeding>
        <year>2002</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Deduction and induction are unified on the basis of a generalized notion of logical consequence, having classical first-order logic as a particular case. RichProlog is a natural extension of Prolog rooted in this generalized logic, in the same way as Prolog is rooted in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:NIbVO3dNaKwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>33</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12423264746601809460&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12423264746601809460&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="53">
        <url>http://www.jstor.org/stable/10.1086/525604</url>
        <title status="complete" source="scholar.google.com">A new solution to the puzzle of simplicity</title>
        <pdf>http://philsci-archive.pitt.edu/2984/1/psa2006b.pdf</pdf>
        <author status="complete" source="scholar.google.com">KT Kelly</author>
        <proceeding status="complete" source="scholar.google.com">Philosophy of Science</proceeding>
        <year>2007</year>
        <source>JSTOR</source>
        <snippet status="partial" source="scholar.google.com">Explaining the connection, if any, between simplicity and truth is among the deepest problems facing the philosophy of science, statistics, and machine learning. Say that an efficient truth finding method minimizes worst case costs en route to converging to the true ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:KQLWU0pqLlMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5993845021543367209&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5993845021543367209&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="54">
        <url>http://www.springerlink.com/index/T0Q50184P25H2248.pdf</url>
        <title status="complete" source="scholar.google.com">Learning to coordinate; A recursion theoretic perspective</title>
        <pdf>http://www.princeton.edu/~osherson/papers/coop28.pdf</pdf>
        <author status="complete" source="scholar.google.com">F Montagna, D Osherson</author>
        <proceeding status="complete" source="scholar.google.com">Synthese</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract We consider two players each of whom attempts to predict the behavior of the other, using no more than the history of earlier predictions. Behaviors are limited to a pair of options, conventionally denoted by 0, 1. Such players face the problem of learning to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:CE6yVd567EUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5038537178459819528&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5038537178459819528&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="55">
        <url>http://164.8.231.2/razno/icl2004/pdf/jantke1.pdf</url>
        <title status="complete" source="scholar.google.com">Adaptation to the learners&#39; needs and desires by induction and negotiation of hypotheses</title>
        <pdf>http://164.8.231.2/razno/icl2004/pdf/jantke1.pdf</pdf>
        <author status="complete" source="scholar.google.com">KP Jantke, G Grieser, S Lange</author>
        <proceeding status="partial" source="scholar.google.com">International conference on interactive &#8230;</proceeding>
        <year>2004</year>
        <source>164.8.231.2</source>
        <snippet status="partial" source="scholar.google.com">Abstract: The present paper has a quite narrow scope: High adaptivity to the learners&#39; needs and desires, even in case those are only vaguely and incompletely known and may be, in addition, subject to a certain drift over time. Adaptation is implemented by hypothesizing ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:bXw8qBQzsR8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:bXw8qBQzsR8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2283662649868450925&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2283662649868450925&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="56">
        <url>http://dl.acm.org/citation.cfm?id=1075149</url>
        <title status="complete" source="scholar.google.com">A word-order database for testing computational models of language acquisition</title>
        <pdf>http://acl.ldc.upenn.edu/acl2003/main/pdfs/Sakas.pdf</pdf>
        <author status="complete" source="scholar.google.com">WG Sakas</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the 41st Annual Meeting on Association &#8230;</proceeding>
        <year>2003</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract An investment of effort over the last two years has begun to produce a wealth of data concerning computational psycholinguistic models of syntax acquisition. The data is generated by running simulations on a recently completed database of word order ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:zLF5zHjvs6MJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>24</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11796035151119102412&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11796035151119102412&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="57">
        <url>http://www.springerlink.com/index/DAK95EXC6BDRXL6V.pdf</url>
        <title status="complete" source="scholar.google.com">A general theory of deduction, induction, and learning</title>
        <pdf>http://cs5594.userapi.com/u11728334/docs/5bd09dd62f02/Klaus_P_Jantke_Discovery_Science_318857.pdf#page=170</pdf>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Discovery Science</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Deduction, induction, learning, are various aspects of a more general scientific activity: the discovery of truth. We propose to embed them in a common, logical framework. First, we define a generalized notion of âlogical consequence.â lternating compact and âweakly ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:tf931vs0ZDEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3559027861769158581&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3559027861769158581&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="58">
        <url>http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9922.2010.00606.x/full</url>
        <title status="complete" source="scholar.google.com">Artificial language learning in adults and children</title>
        <pdf>http://pubman.mpdl.mpg.de/pubman/item/escidoc:541621:6/component/escidoc:541620/Folia-LanguageLearning10.pdf</pdf>
        <author status="partial" source="scholar.google.com">V Folia, J UddÃ©n, M De Vries, C Forkstam&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Language &#8230;</proceeding>
        <year>2010</year>
        <source>Wiley Online Library</source>
        <snippet status="partial" source="scholar.google.com">This article briefly reviews some recent work on artificial language learning in children and adults. The final part of the article is devoted to a theoretical formulation of the language learning problem from a mechanistic neurobiological viewpoint and we show that it is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:7zO-1wS3qkoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5380313936274797551&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5380313936274797551&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="59">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397500003856</url>
        <title status="complete" source="scholar.google.com">Control structures in hypothesis spaces: The influence on learning</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain, M Suraj</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2002</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In any learnability setting, hypotheses are conjectured from some hypothesis space. Studied herein are the influence on learnability of the presence or absence of certain control structures in the hypothesis space. First presented are control structure characterizations ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:mk1c8QhJiGwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7820581055686790554&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7820581055686790554&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="60">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540105001616</url>
        <title status="complete" source="scholar.google.com">Learning languages from positive data and a finite number of queries</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.90.3248&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2006</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A computational model for learning languages in the limit from full positive data and a bounded number of queries to the teacher (oracle) is introduced and explored. Equivalence, superset, and subset queries are considered (for the latter one we consider also a variant ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FzZ78mu49FgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6409950943424230935&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6409950943424230935&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="61">
        <url>http://www.springerlink.com/index/AM7558R84445558T.pdf</url>
        <title status="complete" source="scholar.google.com">U-shaped, iterative, and iterative-with-counter learning</title>
        <author status="complete" source="scholar.google.com">J Case, SE Moelius</author>
        <proceeding status="complete" source="scholar.google.com">Machine Learning</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper solves an important problem left open in the literature by showing that U-shapes are unnecessary in iterative learning from positive data. A U-shape occurs when a learner first learns, then unlearns, and, finally, relearns, some target concept. Iterative ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:sZ5F-vPpsDUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3868849313996447409&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3868849313996447409&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="62">
        <url>http://www.springerlink.com/index/BN4WUBDWE0233BPV.pdf</url>
        <title status="complete" source="scholar.google.com">Synthesizing learners tolerating computable noisy data</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/nrec.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1998</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">An index for an re class of languages (by definition) generates a sequence of grammars defining the class. An index for an indexed family of languages (by definition) generates a sequence of decision procedures defining the family. F. Stephan&#39;s model of noisy data is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:NQuQP4PCMXcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8588859833335155509&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8588859833335155509&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="63">
        <url>http://www.springerlink.com/index/q2137520m7713386.pdf</url>
        <title status="complete" source="scholar.google.com">How simplicity helps you find the truth without pointing at it</title>
        <pdf>http://repository.cmu.edu/cgi/viewcontent.cgi?article=1378&amp;context=philosophy</pdf>
        <author status="complete" source="scholar.google.com">K Kelly</author>
        <proceeding status="partial" source="scholar.google.com">Induction, Algorithmic Learning Theory, and &#8230;</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">It seems that a fixed bias toward simplicity should help one find the truth, since scientific theorizing is guided by such a bias. But it also seems that a fixed bias toward simplicity cannot indicate or point at the truth, since an indicator has to be sensitive to what it ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:5u8YrrNMkJQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10705140648863395814&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10705140648863395814&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="64">
        <url>http://dare.uva.nl/record/363483</url>
        <title status="complete" source="scholar.google.com">Knowing one&#39;s limits: logical analysis of inductive inference</title>
        <pdf>http://dare.uva.nl/document/200643</pdf>
        <author status="complete" source="scholar.google.com">N Gierasimczuk</author>
        <year>2010</year>
        <source>dare.uva.nl</source>
        <snippet status="partial" source="scholar.google.com">This book is about change. Change of mind, revision of beliefs, formation of conjectures, and strategies for learning. We compare two major paradigms of formal epistemology that deal with the dynamics of informational states: formal learning theory and dynamic epistemic ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:0XobFzY4lzYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3933674604498483921&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3933674604498483921&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="65">
        <url>http://www.springerlink.com/index/etmf66y31mk7etmj.pdf</url>
        <title status="complete" source="scholar.google.com">Advertising games for web services</title>
        <pdf>http://pdf.aminer.org/000/115/692/advertising_games_for_web_services.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Agostini, P Avesani</author>
        <proceeding status="partial" source="scholar.google.com">On The Move to Meaningful Internet Systems 2003: &#8230;</proceeding>
        <year>2003</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We advance and discuss a framework suitable to study theoretical implications and practical impact of language evolution and lexicon sharing in an open distributed multi-agent system. In our approach, the assumption of autonomy plays a key role to preserve the opportunity ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:3RHtUlpbdwUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=393883935914660317&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=393883935914660317&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="66">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397500002188</url>
        <title status="complete" source="scholar.google.com">Probabilistic inductive inference: a survey</title>
        <pdf>http://arxiv.org/pdf/cs.LG/9902026</pdf>
        <author status="complete" source="scholar.google.com">A Ambainis</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="complete" source="scholar.google.com">This paper surveys developments in probabilistic inductive inference (learning) of recursive (computable) functions. We mainly focus on finite learning, since this simple paradigm has produced the most interesting (and most complex) results.</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:0IvCr0ZYyFgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6397460331299507152&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6397460331299507152&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="67">
        <url>http://www-uilots.let.uu.nl/publications/clin1999/Pap/costa.pdf</url>
        <title status="complete" source="scholar.google.com">Consistent identification in the limit of some Penn and Buszkowski&#39;s classes is NP-hard</title>
        <pdf>http://www-uilots.let.uu.nl/publications/clin1999/Pap/costa.pdf</pdf>
        <author status="complete" source="scholar.google.com">CC FlorÃªncio</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the International Conference on &#8230;</proceeding>
        <year>1999</year>
        <source>www-uilots.let.uu.nl</source>
        <snippet status="partial" source="scholar.google.com">Abstract In (Buszkowski, 1987) and (Buszkowski and Penn, 1990) certain&#39;discovery procedures&#39; for classical categorial grammars were defined. These procedures accept a sequence of structures (strings labeled with derivational information) as input and yield a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:rFiyxADcrY4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10281115420214843564&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10281115420214843564&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="68">
        <url>http://www.springerlink.com/index/7NDLJGW0PUQ0N9P5.pdf</url>
        <title status="complete" source="scholar.google.com">Non U-shaped vacillatory and team learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.127.40&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">U-shaped learning behaviour in cognitive development involves learning, unlearning and relearning. It occurs, for example, in learning irregular verbs. The prior cognitive science literature is occupied with how humans do it, for example, general rules versus tables of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:SiUKzidZXvAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17320379244408874314&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17320379244408874314&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="69">
        <url>http://www.springerlink.com/index/exe7upbtkll4n7y7.pdf</url>
        <title status="complete" source="scholar.google.com">Learning languages from positive data and negative counterexamples</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.130.6689&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2004</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In this paper we introduce a paradigm for learning in the limit of potentially infinite languages from all positive data and negative counterexamples provided in response to the conjectures made by the learner. Several variants of this paradigm are considered that reflect different ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:P1H20am1D-AJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16145322930123198783&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16145322930123198783&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="70">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540108000266</url>
        <title status="complete" source="scholar.google.com">Learning in Friedberg numberings</title>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In this paper we consider learnability in some special numberings, such as Friedberg numberings, which contain all the recursively enumerable languages, but have simpler grammar equivalence problem compared to acceptable numberings. We show that every ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Hq2mBjhdYAMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=243296875089145118&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=243296875089145118&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="71">
        <url>http://www.springerlink.com/index/13h4133733706187.pdf</url>
        <title status="complete" source="scholar.google.com">Learning and teaching as a game: A sabotage approach</title>
        <pdf>http://staff.science.uva.nl/~lkurzen/publications/GKV-Sabotage-2009.pdf</pdf>
        <author status="partial" source="scholar.google.com">N Gierasimczuk, L Kurzen&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Logic, Rationality, and &#8230;</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. In formal approaches to inductive learning, the ability to learn is understood as the ability to single out a correct hypothesis from a range of possibilities. Although most of the existing research focuses on the characteristics of the learner, in many paradigms the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ggYqEZEDb68J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12641326600645379714&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12641326600645379714&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="72">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.111.1902&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">U-shaped learning may be necessary 3</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.111.1902&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carluccia, J Caseb, S Jainc, F Stephand</author>
        <year>2005</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract U-shaped learning behaviour in cognitive development involves learning, unlearning and relearning. It occurs, for example, in learning irregular verbs. The prior cognitive science literature is occupied with how humans do it, for example, general rules ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:TF-JIATWghcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:TF-JIATWghcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>20</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1694151723058814796&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1694151723058814796&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="73">
        <url>http://www.springerlink.com/index/Y1537725320743Q1.pdf</url>
        <title status="complete" source="scholar.google.com">Dynamically delayed postdictive completeness and consistency in learning</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/PcpPcsDelayTR.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In computational function learning in the limit, an algorithmic learner tries to find a program for a computable function g given successively more values of g, each time outputting a conjectured program for g. A learner is called postdictively complete iff all available data is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:7IuxNDCJ05gJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11012296353986481132&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11012296353986481132&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="74">
        <url>http://www.springerlink.com/index/1r638k4x8jgt667r.pdf</url>
        <title status="complete" source="scholar.google.com">Memory-limited U-shaped learning</title>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. U-shaped learning is a learning behaviour in which the learner first learns something, then unlearns it and finally relearns it. Such a behaviour, observed by psychologists, for example, in the learning of past-tenses of English verbs, has been ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:HRa3ewNxRzoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4199449437320713757&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4199449437320713757&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="75">
        <url>http://www.springerlink.com/index/xfv2m69u824kufh1.pdf</url>
        <title status="complete" source="scholar.google.com">The learning and emergence of mildly context sensitive languages</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.86.4409&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="partial" source="scholar.google.com">E Stabler, T Collier, G Kobele, Y Lee, Y Lin&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Advances in Artificial &#8230;</proceeding>
        <year>2003</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper describes a framework for studies of the adaptive acquisition and evolution of language, with the following components: language learning begins by associating words with cognitively salient representations (âgroundingâ); the sentences of each language are ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FzKPf_fL3rIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>24</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12888963447438389783&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12888963447438389783&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="76">
        <url>http://www.springerlink.com/index/q2249g17m13j7637.pdf</url>
        <title status="complete" source="scholar.google.com">Learning left-to-right and right-to-left iterative languages</title>
        <pdf>http://carbon.ijs.si/site/normal_dl/tag=28354/icgi08_heinz_lrlil_01.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Heinz</author>
        <proceeding status="complete" source="scholar.google.com">Grammatical Inference: Algorithms and Applications</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The left-to-right and right-to-left iterative languages are previously unnoticed subclasses of the regular languages of infinite size that are identifiable in the limit from positive data. Essentially, these language classes are the ones obtained by merging final states in a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:m0CSmX4aJiIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2460683377449255067&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2460683377449255067&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="77">
        <url>http://www.springerlink.com/index/Y15138N500786355.pdf</url>
        <title status="complete" source="scholar.google.com">Towards understanding meme media knowledge evolution</title>
        <pdf>http://km.meme.hokudai.ac.jp/people/jantke/Publications/2006/2006_KaschekJantkeNebel.pdf</pdf>
        <author status="complete" source="scholar.google.com">R Kaschek, K Jantke, IT Nebel</author>
        <proceeding status="complete" source="scholar.google.com">Federation over the Web</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Successful communication involves the individual utterances being interpreted within a suitable context. Systems that fail to acquire and share the context required for some topic are likely to fail to communicate successfully about that topic. Software systems populating ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:EjetoBFpzYIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9425305119587383058&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9425305119587383058&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="78">
        <url>http://cs.unb.ca/~goldfarb/Theses/John&#39;s_Thesis.pdf</url>
        <title status="complete" source="scholar.google.com">ETS Learning of Kernel Languages</title>
        <pdf>http://cs.unb.ca/~goldfarb/Theses/John&#39;s_Thesis.pdf</pdf>
        <author status="complete" source="scholar.google.com">JM Abela</author>
        <year>2002</year>
        <source>cs.unb.ca</source>
        <snippet status="partial" source="scholar.google.com">Abstract The Evolving Transformations Systems (ETS) model is a new inductive learning model proposed by Goldfarb in 1990. The development of the ETS model was motivated by need for the unification of the two competing approaches that model learningânumeric ( ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:TP6fsr4X6eoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:TP6fsr4X6eoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16927086782256774732&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16927086782256774732&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="79">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397501004054</url>
        <title status="complete" source="scholar.google.com">Learning classes of approximations to non-recursive functions</title>
        <pdf>http://www.mat.unisi.it/personalpages/sorbi/public_html/papers/RUSHEAD.pdf#page=53</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2002</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Blum and Blum (Inform. and Control 28 (1975) 125â155) showed that a class B of suitable recursive approximations to the halting problem K is reliably EX-learnable but left it open whether or not B is in NUM. By showing B to be not in NUM we resolve this old problem. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:keLy4mjhzZEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>33</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10506301346325652113&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10506301346325652113&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="80">
        <url>http://biolinguistics.eu/index.php/biolinguistics/article/view/167</url>
        <title status="complete" source="scholar.google.com">Implicit artificial syntax processing: genes, preference, and bounded recursion</title>
        <pdf>http://biolinguistics.eu/index.php/biolinguistics/article/download/167/200</pdf>
        <author status="complete" source="scholar.google.com">V Folia, C Forkstam, M Ingvar, KM Petersson</author>
        <proceeding status="complete" source="scholar.google.com">Biolinguistics</proceeding>
        <year>2011</year>
        <source>biolinguistics.eu</source>
        <snippet status="partial" source="scholar.google.com">Abstract The first objective of this study was to compare the brain network engaged by preference classification and the standard grammaticality classification after implicit artificial syntax acquisition by re-analyzing previously reported event-related fMRI data. The results ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ecA6A54ru84J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14896548150117056633&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14896548150117056633&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="81">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397510002045</url>
        <title status="complete" source="scholar.google.com">Iterative learning of simple external contextual languages</title>
        <author status="partial" source="scholar.google.com">L Becerra-Bonache, J Case, S Jain&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Theoretical Computer &#8230;</proceeding>
        <year>2010</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">It is investigated for which choice of a parameter q, denoting the number of contexts, the class of simple external contextual languages is iteratively learnable. On the one hand, the class admits, for all values of q, polynomial time learnability provided an adequate choice ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:f8VfCBmn_xMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1441054131738363263&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1441054131738363263&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="82">
        <url>http://www.springerlink.com/index/lwppl43dfva4ulg5.pdf</url>
        <title status="complete" source="scholar.google.com">Mind change efficient learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.72.7998&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">W Luo, O Schulte</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper studies efficient learning with respect to mind changes. Our starting point is the idea that a learner that is efficient with respect to mind changes minimizes mind changes not only globally in the entire learning problem, but also locally in subproblems after receiving ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Tr_ZFZkwJUUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4982441996810043214&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4982441996810043214&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="83">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.77.8582&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Computational models of language universals: Expressiveness, learnability and consequences</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.77.8582&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">EP Stabler</author>
        <proceeding status="complete" source="scholar.google.com">Language universals</proceeding>
        <year>2009</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Every linguist is struck by similarities among even the most different and most culturally isolated human languages. It is natural to assume that some of these common properties, these language universals, might reflect something about the way people can learn and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Sks_gUHpP6YJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:Sks_gUHpP6YJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11979550001379363658&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11979550001379363658&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="84">
        <url>http://www.sciencedirect.com/science/article/pii/S1355219807001037</url>
        <title status="complete" source="scholar.google.com">The co-discovery of conservation laws and particle families</title>
        <pdf>http://phil-sci07.googlecode.com/svn-history/r47/trunk/published-SHPMP517.pdf</pdf>
        <author status="complete" source="scholar.google.com">O Schulte</author>
        <proceeding status="partial" source="scholar.google.com">Studies In History and Philosophy of Science Part B: &#8230;</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper presents an epistemological analysis of the search for new conservation laws in particle physics that was especially prominent in the 1950s and 1960s. Discovering conservation laws has posed various challenges concerning the underdetermination of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:fTxrhydZjusJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16973602071916526717&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16973602071916526717&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="85">
        <url>http://colt2010.haifa.il.ibm.com/presentation/COLT10Talk-NUTechniques.pdf</url>
        <title status="complete" source="scholar.google.com">Strongly non-U-shaped learning results by general techniques</title>
        <pdf>http://colt2010.haifa.il.ibm.com/presentation/COLT10Talk-NUTechniques.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of COLT (Conference on &#8230;</proceeding>
        <year>2010</year>
        <source>colt2010.haifa.il.ibm.com</source>
        <snippet status="partial" source="scholar.google.com">Let N={0, 1, 2,...}, the set of all natural numbers. A language is a set Lâ N. A presentation for L is essentially an (infinite) listing T of all and only the elements of L. Such a T is called a text for L. We numerically name programs or grammars in some standard general hypothesis ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:t15I2yZe0eEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:t15I2yZe0eEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16271890449647034039&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16271890449647034039&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="86">
        <url>http://dl.comp.nus.edu.sg/dspace/handle/1900.100/3112</url>
        <title status="complete" source="scholar.google.com">On automatic families</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/3112/1/TRB1-10.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, YS Ong, S Pu, F Stephan</author>
        <year>2010</year>
        <source>dl.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract: This paper summarises previous work on automatic families. It then investigates a natural measure which exists inside every automatic family: the size of a regular language in this family is just the length of its index. This measure satisfies various properties similar to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:8apC6ZMa79sJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>20</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15847914836316039921&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15847914836316039921&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="87">
        <url>http://www.springerlink.com/index/m13t261w8547g2w7.pdf</url>
        <title status="complete" source="scholar.google.com">Parallelism increases iterative learning power</title>
        <pdf>http://cs5235.userapi.com/u133638729/docs/ceb9e6352614/Marcus_Hutter_Algorithmic_Learning_Theory_18_co.pdf#page=60</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Moelius</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Iterative learning (It It-learning) is a Gold-style learning model in which each of a learner&#39;s output conjectures may depend only upon the learner&#39;s current conjecture and the current input element. Two extensions of the It It-learning model are considered, each of which ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:S-KmCH9zMScJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2824165430781207115&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2824165430781207115&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="88">
        <url>http://www.springerlink.com/index/426358m7702847h2.pdf</url>
        <title status="complete" source="scholar.google.com">Difficulties in forcing fairness of polynomial time inductive inference</title>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">There are difficulties obtaining fair feasibility from polynomial time updated language learning in the limit from positive data. Pitt 1989 noted that unfair delaying tricks can achieve polynomial time updates but with no feasibility constraint on the whole learning process. In ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:bIREIdSBRukJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16809265407298143340&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16809265407298143340&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="89">
        <url>http://www.springerlink.com/index/D56708146217R601.pdf</url>
        <title status="complete" source="scholar.google.com">Learning in Friedberg numberings</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2613/1/TR11-07.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In this paper we consider learnability in some special numberings, such as Friedberg numberings, which contain all the recursively enumerable languages, but have simpler grammar equivalence problem compared to acceptable numberings. We show that every ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cLgmLVtjoKkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>26</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12222878631934212208&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12222878631934212208&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="90">
        <url>http://www.springerlink.com/index/61px2eqgnaf9ugv1.pdf</url>
        <title status="complete" source="scholar.google.com">Can learning in the limit be done efficiently?</title>
        <pdf>http://cs5235.userapi.com/u133638729/docs/0b3b37a51a80/Ricard_Gavald_Algorithmic_Learning_Theory_14_co.pdf#page=17</pdf>
        <author status="complete" source="scholar.google.com">T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2003</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Inductive inference can be considered as one of the fundamental paradigms of algorithmic learning theory. We survey results recently obtained and show their impact to potential applications. Since the main focus is put on the efficiency of learning, we also deal with ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:QwnJTXIvDKQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11820875289918507331&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11820875289918507331&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="91">
        <url>http://www.springerlink.com/index/622mq05067241241.pdf</url>
        <title status="complete" source="scholar.google.com">Identification through inductive verification</title>
        <pdf>http://cs5824.userapi.com/u11728334/docs/0e8ded319f9b/Peter_Bosch_Logic_Language_and_Computation_2007.pdf#page=204</pdf>
        <author status="complete" source="scholar.google.com">N Gierasimczuk</author>
        <proceeding status="complete" source="scholar.google.com">Logic, Language, and Computation</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. In this paper we are concerned with some general properties of scientific hypotheses. We investigate the relationship between the situation when the task is to verify a given hypothesis, and when a scientist has to pick a correct hypothesis from an arbitrary ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:fGSSaZJBlUUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>20</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5013985857239147644&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5013985857239147644&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="92">
        <url>http://pubs.doc.ic.ac.uk/atf-ilp-comparison-etai/atf-ilp-comparison-etai.pdf</url>
        <title status="complete" source="scholar.google.com">An application-based comparison of automated theory formation and inductive logic programming</title>
        <pdf>http://pubs.doc.ic.ac.uk/atf-ilp-comparison-etai/atf-ilp-comparison-etai.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Colton</author>
        <proceeding status="complete" source="scholar.google.com">Electron. Trans. Artif. Intell.</proceeding>
        <year>2000</year>
        <source>pubs.doc.ic.ac.uk</source>
        <snippet status="partial" source="scholar.google.com">Abstract Automated theory formation involves the production of examples, concepts and hypotheses. The HR program performs automated theory formation and has been used to form theories in mathematical domains. In addition to providing a plausible model for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:QEyjgPxrJ-QJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:QEyjgPxrJ-QJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16440227696973401152&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16440227696973401152&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="93">
        <url>http://www.springerlink.com/index/q82730772215r617.pdf</url>
        <title status="complete" source="scholar.google.com">Learning by erasing in dynamic epistemic logic</title>
        <pdf>http://www.ninagierasimczuk.com/lata_slidesNG.pdf</pdf>
        <author status="complete" source="scholar.google.com">N Gierasimczuk</author>
        <proceeding status="complete" source="scholar.google.com">Language and Automata Theory and Applications</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. This work provides a comparison of learning by erasing [1] and iterated epistemic update [2] as analyzed in dynamic epistemic logic (see eg [3]). We show that finite identification can be modelled in dynamic epistemic logic and that the elimination process ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:3dk4ivtUg30J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9044165916022594013&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9044165916022594013&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="94">
        <url>http://www.springerlink.com/index/e654657xu548t251.pdf</url>
        <title status="complete" source="scholar.google.com">Iterative learning of simple external contextual languages</title>
        <pdf>http://cs5235.userapi.com/u133638729/docs/e02780dda47c/Yoav_Freund_Algorithmic_Learning_Theory_19_conf.pdf#page=371</pdf>
        <author status="partial" source="scholar.google.com">L Becerra-Bonache, J Case, S Jain&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Algorithmic Learning &#8230;</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">It is investigated for which choice of a parameter q, denoting the number of contexts, the class of simple external contextual languages is iteratively learnable. On one hand, the class admits, for all values of q, polynomial time learnability provided an adequate choice of the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:scvYnWO_FuQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>25</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16435534324706102193&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16435534324706102193&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="95">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397502004218</url>
        <title status="complete" source="scholar.google.com">On learning of functions refutably</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.100.9346&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Learning of recursive functions refutably informally means that for every recursive function, the learning machine has either to learn this function or to refute it, that is to signal that it is not able to learn it. Three modi of making precise the notion of refuting are considered. We ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:p7s2pvsnODgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4051031826598640551&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4051031826598640551&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="96">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000004000212</url>
        <title status="complete" source="scholar.google.com">Robust learningârich and poor</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan, R Wiehagen</author>
        <proceeding status="partial" source="scholar.google.com">Journal of Computer and System &#8230;</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A class C of recursive functions is called robustly learnable in the sense I (where I is any success criterion of learning) if not only C itself but even all transformed classes Î (C), where Î is any general recursive operator, are learnable in the sense I. It was already ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ukImu-_3fDcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3998343178207249082&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3998343178207249082&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="97">
        <url>http://repository.cmu.edu/cgi/viewcontent.cgi?article=1377&amp;context=philosophy</url>
        <title status="complete" source="scholar.google.com">Simplicity, truth, and the unending game of science</title>
        <pdf>http://repository.cmu.edu/cgi/viewcontent.cgi?article=1377&amp;context=philosophy</pdf>
        <author status="complete" source="scholar.google.com">KT Kelly</author>
        <year>2007</year>
        <source>repository.cmu.edu</source>
        <snippet status="partial" source="scholar.google.com">Carnegie Mellon University Department of Philosophy Baker Hall 135 Pittsburgh, PA 15213-3890, USA kk3n@ andrew. cmu. edu abstract. This paper presents a new explanation of how preferring the simplest theory compatible with experience assists one in finding the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:jLCHwwesXqoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>16</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12276438783603749004&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12276438783603749004&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="98">
        <url>http://www.polkfolk.com/docs/Ref-Library/Floridi/The%20Blackwell%20Guide%20to%20the%20Philosophy%20of%20Computing%20and%20Information_Luciano%20Floridi%20(Blackwell%202004%20376s).pdf#page=312</url>
        <title status="complete" source="scholar.google.com">Computing in the Philosophy of Science</title>
        <pdf>http://www.polkfolk.com/docs/Ref-Library/Floridi/The%20Blackwell%20Guide%20to%20the%20Philosophy%20of%20Computing%20and%20Information_Luciano%20Floridi%20(Blackwell%202004%20376s).pdf#page=312</pdf>
        <author status="complete" source="scholar.google.com">P Thagard</author>
        <proceeding status="partial" source="scholar.google.com">The Blackwell guide to the philosophy of computing &#8230;</proceeding>
        <year>2004</year>
        <source>polkfolk.com</source>
        <snippet status="partial" source="scholar.google.com">What do philosophers do? Twenty or thirty years ago, one might have been told âanalyze conceptsâ or âevaluate arguments.â The answer âwrite computer programsâ would have inspired a blank stare and computational philosophy of science might have sounded like ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:EbxN0mhlAQEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:EbxN0mhlAQEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=72450569893952529&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=72450569893952529&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="99">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=THPXrGmQCtEC&amp;oi=fnd&amp;pg=PA113&amp;ots=u8qInevttv&amp;sig=OzYMurtD_vPlevmJJjvODwaTg9Y</url>
        <title status="complete" source="scholar.google.com">Linguistic models</title>
        <author status="complete" source="scholar.google.com">GK Pullum, BC Scholz</author>
        <proceeding status="partial" source="scholar.google.com">Mind, Brain, and Language: &#8230;</proceeding>
        <year>2003</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">This chapter is about natural languages, their structure, and their grammars. The concentration is entirely on syntax (the structure of sentences, clauses, and phrases), setting aside phonology (sound structure) and morphology (word structure), as well as issues of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:afxP8kCV-G4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7996305244572089449&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7996305244572089449&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="100">
        <url>http://www.springerlink.com/index/K6565966X8828563.pdf</url>
        <title status="complete" source="scholar.google.com">U-shaped, iterative, and iterative-with-counter learning</title>
        <pdf>http://www.cis.udel.edu/~moelius/publications/iteqnuit_mlj_preprint.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Moelius</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper solves an important problem left open in the literature by showing that U-shapes are unnecessary in iterative learning. A U-shape occurs when a learner first learns, then unlearns, and, finally, relearns, some target concept. Iterative learning is a Gold-style ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RrqCAV6LybQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13027096633014401606&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13027096633014401606&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="101">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397506004919</url>
        <title status="complete" source="scholar.google.com">From learning in the limit to stochastic finite learning</title>
        <pdf>http://eprints.lib.hokudai.ac.jp/dspace/bitstream/2115/17137/1/TCS364-1-77.pdf</pdf>
        <author status="complete" source="scholar.google.com">T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2006</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Inductive inference can be considered as one of the fundamental paradigms of algorithmic learning theory. We survey results recently obtained and show their impact to potential applications. Since the main focus is put on the efficiency of learning, we also deal with ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:jvVcGqZe3pkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11087403400132621710&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11087403400132621710&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="102">
        <url>http://www.springerlink.com/index/1N4582H1226U0066.pdf</url>
        <title status="complete" source="scholar.google.com">Optimal language learning</title>
        <pdf>http://cs5235.userapi.com/u133638729/docs/e02780dda47c/Yoav_Freund_Algorithmic_Learning_Theory_19_conf.pdf#page=431</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Moelius</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Gold&#39;s original paper on inductive inference introduced a notion of an optimal learner. Intuitively, a learner identifies a class of objects optimally iff there is no other learner that: requires as little of each presentation of each object in the class in order to identify that ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:IPVBINypfzwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4359389727217022240&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4359389727217022240&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="103">
        <url>http://www.itk.ilstu.edu/faculty/chungli/mypapers/li-thesis.ps</url>
        <title status="complete" source="scholar.google.com">Type-2 complexity theory</title>
        <pdf>http://www.itk.ilstu.edu/faculty/chungli/mypapers/li-thesis.ps</pdf>
        <author status="complete" source="scholar.google.com">CC Li</author>
        <year>2001</year>
        <source>itk.ilstu.edu</source>
        <snippet status="partial" source="scholar.google.com">OTMs based on a class of computable functions called Type-2 Time Bounds (T2TB). With the tools we developed, each type-2 time bound Î²â T2TB determines a type-2 complexity class C (Î²). We also define a type-2 big-O notationâO (Î²)âwhich would be a useful tool for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RHTxVXGtQcUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:RHTxVXGtQcUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14213832601242793028&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14213832601242793028&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="104">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540103000592</url>
        <title status="complete" source="scholar.google.com">On the intrinsic complexity of learning recursive functions</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.105.5266&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="partial" source="scholar.google.com">S Jain, E Kinber, C Papazian, C Smith&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Information and &#8230;</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The intrinsic complexity of learning compares the difficulty of learning classes of objects by using some reducibility notion. For several types of learning recursive functions, both natural complete classes are exhibited and necessary and sufficient conditions for completeness ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1E4tVz7znzUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3864074454383283924&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3864074454383283924&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="105">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540103000828</url>
        <title status="complete" source="scholar.google.com">Learning by switching type of information</title>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present work is dedicated to the study of modes of data-presentation in the range between text and informant within the framework of inductive inference. In this study, the learner alternatingly requests sequences of positive and negative data. We define various ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:T69CcuOiZkMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4856748345923907407&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4856748345923907407&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="106">
        <url>http://www.springerlink.com/index/1GAC95CTA52GAPQY.pdf</url>
        <title status="complete" source="scholar.google.com">On variants of iterative learning</title>
        <pdf>http://www.ke.tu-darmstadt.de/m/lehre/archiv/ss06/alg-lernen/incremental-fattext-initialhyp.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Discovey Science</proceeding>
        <year>1998</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Within the present paper, we investigate the principal learning capabilities of iterative learners in some more details. The general scenario of iterative learning is as follows. An iterative learner successively takes as input one element of a text (an informant) of a target ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:dXOMcjDsZLoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13431119681550054261&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13431119681550054261&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="107">
        <url>http://www.springerlink.com/index/at77777731851m48.pdf</url>
        <title status="complete" source="scholar.google.com">Inductive inference and language learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.136.9978&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Theory and Applications of Models of Computation</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. The present paper is a short reflection concerning the role which inductive inference played and can play in language learning. We shortly recall some major insights obtained and outline some new directions based on own work and results recently ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:rBwPkSnW5R4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2226421064820268204&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2226421064820268204&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="108">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397509007981</url>
        <title status="complete" source="scholar.google.com">Mind change complexity of inferring unbounded unions of restricted pattern languages from positive data</title>
        <author status="complete" source="scholar.google.com">M de Brecht, A Yamamoto</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2010</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper shows that the mind change complexity of inferring from positive data the class of unbounded unions of languages of regular patterns with constant segment length bound is of the form [Formula: see text], assuming that the patterns are defined over a finite ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:S_0At17bfksJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5440026599753841995&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5440026599753841995&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="109">
        <url>http://www.springerlink.com/index/EKX087X862286207.pdf</url>
        <title status="complete" source="scholar.google.com">On the uniform learnability of approximations to non-recursive functions</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/alt99sz.pdf</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Blum and Blum (1975) showed that a class BB of suitable recursive approximations to the halting problem is reliably EX-learnable. These investigations are carried on by showing that BB is neither in NUM nor robustly EX-learnable. Since the definition of the class BB is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:LOx7t0gGJBoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>15</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1883637453533473836&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1883637453533473836&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="110">
        <url>http://www.springerlink.com/index/L69637G3780M3J8U.pdf</url>
        <title status="complete" source="scholar.google.com">String extension learning using lattices</title>
        <author status="complete" source="scholar.google.com">A Kasprzik, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Language and Automata Theory and Applications</proceeding>
        <year>2010</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. The class of regular languages is not identifiable from positive data in Gold&#39;s language learning model. Many attempts have been made to define interesting classes that are learnable in this model, preferably with the associated learner having certain ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:0betva7fEvgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17875595812586502097&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17875595812586502097&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="111">
        <url>http://search.ieice.org/bin/summary.php?id=e86-d_2_219</url>
        <title status="complete" source="scholar.google.com">Criteria for inductive inference with mind changes and anomalies of recursive real-valued functions</title>
        <author status="partial" source="scholar.google.com">E Hirowatari, K Hirata, T Miyahara&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; on Information and &#8230;</proceeding>
        <year>2003</year>
        <source>search.ieice.org</source>
        <snippet status="partial" source="scholar.google.com">This paper investigates the interaction of&lt; I&gt; mind changes&lt;/I&gt; and&lt; I&gt; anomalies&lt;/I&gt; for inductive inference of recursive real-valued functions. We show that the criteria for inductive inference of recursive real-valued functions by bounding the number of mind changes and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:rFwCx_sXAPUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17654136909435395244&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17654136909435395244&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="112">
        <url>http://www.springerlink.com/index/5fvlvahq3bcmcvmh.pdf</url>
        <title status="complete" source="scholar.google.com">Learning recursive functions refutably</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/alt01jkwz.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Learning of recursive functions refutably means that for every recursive function, the learning machine has either to learn this function or to refute it, ie, to signal that it is not able to learn it. Three modi of making precise the notion of refuting are considered. We show that the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:odjl50e9rvgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17919468083884710049&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17919468083884710049&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="113">
        <url>http://www.springerlink.com/index/k01lgxl984yxvt7k.pdf</url>
        <title status="complete" source="scholar.google.com">Notes on formalizing coordination?</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.21.9153&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">A Agostini</author>
        <proceeding status="complete" source="scholar.google.com">AI* IA 99: Advances in Artificial Intelligence</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper concerns with 2-agents coordination gamesâwe call them paradigms of coordination. To coordinate, agents&#39; behaviour must eventually stabilize to a set of basic formulas that express a suitable part of agents&#39;ânatureâ. Four paradigms are advanced and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:aMhm_8za3ecJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16707750766607517800&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16707750766607517800&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="114">
        <url>http://www.tdx.cat/handle/10803/8780</url>
        <title status="complete" source="scholar.google.com">On the learnibility of Mildly Context-Sensitive languages using positive data and correction queries</title>
        <pdf>http://www.tdx.cat/handle/10803/8780</pdf>
        <author status="complete" source="scholar.google.com">L Becerra Bonache</author>
        <year>2006</year>
        <source>tdx.cat</source>
        <snippet status="partial" source="scholar.google.com">Con esta tesis doctoral aproximamos la teorÃ­a de la inferencia gramatical y los estudios de adquisiciÃ³n del lenguaje, en pos de un objetivo final: ahondar en la comprensiÃ³n del modo como los niÃ±os adquieren su primera lengua mediante la explotaciÃ³n de la teorÃ­a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:QhQTLUugOLEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12770132988148257858&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12770132988148257858&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="115">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1223992</url>
        <title status="complete" source="scholar.google.com">Formal models of incremental learning and their analysis</title>
        <pdf>http://www2.cs.uregina.ca/~zilles/langeZ03incremental.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, S Zilles</author>
        <proceeding status="partial" source="scholar.google.com">Neural Networks, 2003. Proceedings of the &#8230;</proceeding>
        <year>2003</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract We consider concept learning from examples. The learner receives-step by step-larger and larger initial segments of a sequence of examples describing an unknown target concept, processes these examples, and computes hypotheses. The learner is successful, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:7CcjAdlpBmgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7495795010552670188&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7495795010552670188&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="116">
        <url>http://www.springerlink.com/index/jgfwc5rdf2fq2cq3.pdf</url>
        <title status="complete" source="scholar.google.com">On the complexity of consistent identification of some classes of structure languages</title>
        <author status="complete" source="scholar.google.com">C Costa FlorÃªncio</author>
        <proceeding status="complete" source="scholar.google.com">Grammatical Inference: Algorithms and Applications</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In [5, 7]&#39;discovery procedures&#39; for CCGs were defined that accept a sequence of structures as input and yield a set of grammars. In [11] it was shown that some of the classes based on these procedures are learnable. The complexity of learning them was still left open. In this ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:X29yCLL-Eq4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12543367952779603807&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12543367952779603807&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="117">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540108000783</url>
        <title status="complete" source="scholar.google.com">Consistent and coherent learning with&lt; i&gt; Î´&lt;/i&gt;-delay</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/ic08az.pdf</pdf>
        <author status="complete" source="scholar.google.com">Y Akama, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A consistent learner is required to correctly and completely reflect in its actual hypothesis all data received so far. Though this demand sounds quite plausible, it may lead to the unsolvability of the learning problem. Therefore, in the present paper several variations of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:TBROCzQlYzoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4207247382352368716&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4207247382352368716&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="118">
        <url>http://elkedagopendag.nl/Docs/Expertise/OTEC/Onderzoek/LTD%20Programme%20Learning%20Networks%202003-2008%20U2003-1608%20MMO.doc</url>
        <title status="complete" source="scholar.google.com">Learning Networks</title>
        <pdf>http://elkedagopendag.nl/Docs/Expertise/OTEC/Onderzoek/LTD%20Programme%20Learning%20Networks%202003-2008%20U2003-1608%20MMO.doc</pdf>
        <author status="complete" source="scholar.google.com">R Koper, P Sloep</author>
        <proceeding status="partial" source="scholar.google.com">Learning Technology Development &#8230;</proceeding>
        <year>2003</year>
        <source>elkedagopendag.nl</source>
        <snippet status="partial" source="scholar.google.com">This document contains the description of the Learning Technology Development Programme that will start in January 2003 and will run for a regular period of five years. It provides the general framework for the development and execution of a series of concrete ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:D94cDWmW3ysJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:D94cDWmW3ysJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>29</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3161410841373105679&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3161410841373105679&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="119">
        <url>http://www.springerlink.com/index/EE2QJHXWMLEGMXXN.pdf</url>
        <title status="complete" source="scholar.google.com">Inferring unions of the pattern languages by the most fitting covers</title>
        <pdf>http://www.geocities.ws/kalngyk/pub/alt2005j.ps.gz</pdf>
        <author status="complete" source="scholar.google.com">Y Ng, T Shinohara</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We are interested in learning unions of the pattern languages in the limit from positive data using strategies that guarantee some form of minimality during the learning process. It is known that for any class of languages with so-called finite elasticity, any learning strategy ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:6_r6HWBNdTkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4140300507652225771&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4140300507652225771&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="120">
        <url>http://www.springerlink.com/index/n8rfuueg4ytgbeg5.pdf</url>
        <title status="complete" source="scholar.google.com">On the comparison of inductive inference criteria for uniform learning of finite classes</title>
        <pdf>http://cs5824.userapi.com/u11728334/docs/20e8cf4a8295/Naoki_Abe_Algorithmic_Learning_Theory_12_conf_A.pdf#page=260</pdf>
        <author status="complete" source="scholar.google.com">S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We consider a learning model in which each element of a class of recursive functions is to be identified in the limit by a computable strategy. Given gradually growing initial segments of the graph of a function, the learner is supposed to generate a sequence of hypotheses ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:-wk6JIpicNgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15596073855036819963&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15596073855036819963&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="121">
        <url>http://www.springerlink.com/index/x8jvrne9hhf37f3y.pdf</url>
        <title status="complete" source="scholar.google.com">Learning languages from positive data and a finite number of queries</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.104.362&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="partial" source="scholar.google.com">FSTTCS 2004: Foundations of Software Technology &#8230;</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A computational model for learning languages in the limit from full positive data and a bounded number of queries to the teacher (oracle) is introduced and explored. Equivalence, superset, and subset queries are considered. If the answer is negative, the teacher may ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:uaRWKzH8L68J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12623585568653485241&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12623585568653485241&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="122">
        <url>http://www.springerlink.com/index/5n75eb1v97fxh6qq.pdf</url>
        <title status="complete" source="scholar.google.com">Robust LearningâRich and Poor</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.36.2906&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan, R Wiehagen</author>
        <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Aclass C of recursive functions is called robustly learnable in the sense I (where I is any success criterion of learning) if not only C itself but even all transformed classes T (C) where T is any general recursive operator, are learnable in the sense I. It was already shown ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:6-x8KxzTtaYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>21</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12012739699022818539&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12012739699022818539&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="123">
        <url>http://iospress.metapress.com/index/PK2XCKMT5U2YNC8D.pdf</url>
        <title status="complete" source="scholar.google.com">Optimal unification of infinite sets of types</title>
        <author status="complete" source="scholar.google.com">J Marciniec</author>
        <proceeding status="complete" source="scholar.google.com">Fundamenta Informaticae</proceeding>
        <year>2004</year>
        <source>IOS Press</source>
        <snippet status="partial" source="scholar.google.com">In this paper we focus on the properties of infinite sets of types that have finite substitutional images. Since the number of such images may be infinite, we provide the way of its reduction. Having this done, we apply the new methods in the field of learnability of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:zTVIVwRQGn8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9158720771785766349&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9158720771785766349&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="124">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540107000983</url>
        <title status="complete" source="scholar.google.com">Iterative learning from positive data and negative counterexamples</title>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A model for learning in the limit is defined where a (so-called iterative) learner gets all positive examples from the target language, tests every new conjecture with a teacher (oracle) if it is a subset of the target language (and if it is not, then it receives a negative ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:DfGaZ2CzXhUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1539865349243728141&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1539865349243728141&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="125">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540110002026</url>
        <title status="complete" source="scholar.google.com">Hypothesis spaces for learning</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/hypdep.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2011</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In this paper we survey some results in inductive inference showing how learnability of a class of languages may depend on the hypothesis space chosen. Additionally, optimal hypothesis spaces, usable for every learnable class, are considered. We also discuss ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:nE03dzw6FbIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12832226744634658204&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12832226744634658204&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="126">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=HmkZLRXC7_oC&amp;oi=fnd&amp;pg=PT40&amp;ots=bW3-qifDZ-&amp;sig=eTeOCX2BU1dcHegPfYcwbB3qD3Q</url>
        <title status="complete" source="scholar.google.com">Assistance and Induction: The Therapy Planning Case</title>
        <pdf>http://km.meme.hokudai.ac.jp/people/jantke/Publications/2007/PISA_Book_JantkeLamonova_Final.pdf</pdf>
        <author status="complete" source="scholar.google.com">K Jantke, N Lamonova</author>
        <proceeding status="partial" source="scholar.google.com">Intelligent Assistant Systems: Concepts, &#8230;</proceeding>
        <year>2007</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">Abstract Software systems on their way from tools to assistants have to be equipped with learnability. This does apply in complex problem solving environments, in particular. Planning in complex and dynamic environments is learning. Plans are hypotheses ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:X0ekfqlJUCQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2616672375825254239&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2616672375825254239&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="127">
        <url>http://www.springerlink.com/index/WW86604W658G5101.pdf</url>
        <title status="complete" source="scholar.google.com">Solutions to open questions for non-U-shaped learning with memory limitations</title>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2010</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A U-shape occurs when a learner first learns, then unlearns, and, finally, relearns, some target concept. Within the framework of Inductive Inference, previous results have shown, for example, that U-shapes are unnecessary for explanatory learning, but are necessary for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ibyShxgPJ6sJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12332842702605565065&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12332842702605565065&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="128">
        <url>http://www.springerlink.com/index/L1727613M2806111.pdf</url>
        <title status="complete" source="scholar.google.com">Scientific discovery on positive data via belief revision</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.3130&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">E Martin, D Osherson</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Philosophical Logic</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A model of inductive inquiry is defined within a first-order context. Intuitively, the model pictures inquiry as a game between Nature and a scientist. To begin the game, a nonlogical vocabulary is agreed upon by the two players along with a partition of a class of structures ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:bFqKmico9RYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1654272588690119276&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1654272588690119276&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="129">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.67.7979&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Inductive versus approximative learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.67.7979&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">W Menzel, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">Perspectives of Adaptivity and learning, edited by R. &#8230;</proceeding>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">A central and crucial point in any mathematical model of learning is the notion of âconvergenceâ used to express the success of the process being studied. In the wide variety of approaches to learning, mainly two types of convergence concepts appear to be used, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:JFpgrY1teusJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:JFpgrY1teusJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>21</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16967995001338354212&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16967995001338354212&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="130">
        <url>http://www.springerlink.com/index/51R88P473336HU02.pdf</url>
        <title status="complete" source="scholar.google.com">Feasible iteration of feasible learning functionals</title>
        <pdf>http://cs5235.userapi.com/u133638729/docs/ceb9e6352614/Marcus_Hutter_Algorithmic_Learning_Theory_18_co.pdf#page=45</pdf>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing, T Paddock</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">For learning functions in the limit, an algorithmic learner obtains successively more data about a function and calculates trials each resulting in the output of a corresponding program, where, hopefully, these programs eventually converge to a correct program for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:4nPXyisn9PIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17506660720536155106&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17506660720536155106&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="131">
        <url>http://www.springerlink.com/index/g28v15q1q8132l83.pdf</url>
        <title status="complete" source="scholar.google.com">Prediction of recursive real-valued functions from finite examples</title>
        <author status="complete" source="scholar.google.com">E Hirowatari, K Hirata, T Miyahara</author>
        <proceeding status="complete" source="scholar.google.com">New Frontiers in Artificial Intelligence</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In this paper, we investigate prediction of recursive real-valued functions from finite examples by extending the framework of inductive inference of recursive real-valued functions to be a more realistic one. First, we propose a finite prediction machine, which is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ooaT2aPbnAwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=908842721598473890&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=908842721598473890&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="132">
        <url>http://www.springerlink.com/index/l5p6329uk2633r03.pdf</url>
        <title status="complete" source="scholar.google.com">Directions for computability theory beyond pure mathematical</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/rft-directions.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Mathematical problems from applied logic II</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper begins by briefly indicating the principal, non-standard motivations of the author for his decades of work in Computability Theory (CT), aka Recursive Function Theory. Then it discusses its proposed, general directions beyond those from pure mathematics for CT. These ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:BWKg2uLmRxMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1389332872072028677&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1389332872072028677&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="133">
        <url>http://www.springerlink.com/index/3u7121w65176281t.pdf</url>
        <title status="complete" source="scholar.google.com">Learning correction grammars</title>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We investigate a new paradigm in the context of learning in the limit: learning correction grammars for classes of re languages. Knowing a language may feature a representation of the target language in terms of two sets of rules (two grammars). The second grammar is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:WspX_CCq1PEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17425739916852578906&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17425739916852578906&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="134">
        <url>http://arxiv.org/abs/cs/0608033</url>
        <title status="complete" source="scholar.google.com">A Study on Learnability for Rigid Lambek Grammars</title>
        <pdf>http://arxiv.org/pdf/cs/0608033</pdf>
        <author status="complete" source="scholar.google.com">R Bonato</author>
        <proceeding status="complete" source="scholar.google.com">arXiv preprint cs/0608033</proceeding>
        <year>2006</year>
        <source>arxiv.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract: We present basic notions of Gold&#39;s&quot; learnability in the limit&quot; paradigm, first presented in 1967, a formalization of the cognitive process by which a native speaker gets to grasp the underlying grammar of his/her own native language by being exposed to well ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Znm9x4eB5QwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=929291318293526886&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=929291318293526886&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="135">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5632238</url>
        <title status="complete" source="scholar.google.com">The reach of dynamic plan generation for enterprise planning Web services</title>
        <author status="partial" source="scholar.google.com">O Arnold, KP Jantke, C Vogler, HR Beick&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Frontier Computing. &#8230;</proceeding>
        <year>2010</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract There is a trend in information and communication technology services from fat client installations to customizable Web services. The authors are engaged in the development of some planning service for small and medium size enterprizes. For this ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:QpOHAce8URkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1824446886971937602&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1824446886971937602&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="136">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397502001767</url>
        <title status="complete" source="scholar.google.com">Variants of iterative learning</title>
        <author status="complete" source="scholar.google.com">S Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We investigate the principal learning capabilities of iterative learners in some more details. Thereby, we confine ourselves to study the learnability of indexable concept classes. The general scenario of iterative learning is as follows. An iterative learner successively takes ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:bvw9BCIGZGgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7522144020785396846&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7522144020785396846&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="137">
        <url>http://colt2009.cs.mcgill.ca/papers/014.pdf</url>
        <title status="complete" source="scholar.google.com">Consistent partial identification</title>
        <pdf>http://colt2009.cs.mcgill.ca/papers/014.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <year>2009</year>
        <source>colt2009.cs.mcgill.ca</source>
        <snippet status="partial" source="scholar.google.com">Abstract This study contrasts consistent partial identification with learning in the limit. Here partial identification means that the learner outputs an infinite sequence of conjectures in which one correct hypothesis occurs infinitely often and all other hypotheses occur only ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:xzayBPkFv3MJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:xzayBPkFv3MJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>21</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8340391601997231815&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8340391601997231815&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="138">
        <url>http://hal.inria.fr/hal-00573633/</url>
        <title status="complete" source="scholar.google.com">Measuring learning complexity with criteria epitomizers</title>
        <pdf>http://hal.inria.fr/docs/00/57/36/33/PDF/31.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="partial" source="scholar.google.com">Leibniz International Proceedings in Informatics ( &#8230;</proceeding>
        <year>2011</year>
        <source>hal.inria.fr</source>
        <snippet status="partial" source="scholar.google.com">RÃ©sumÃ©: In prior papers, beginning with the seminal work by Freivalds et~ al.~ 1995, the notion of\ emph {intrinsic complexity} is used to analyze the learning complexity of sets of functions in a Gold-style learning setting. Herein are pointed out some weaknesses of this ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:BnuuDxP3ocUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14240935157961751302&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14240935157961751302&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="139">
        <url>http://www.springerlink.com/index/q3u47561122j7n59.pdf</url>
        <title status="complete" source="scholar.google.com">Some recent results in U-shaped learning</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1902/1/TR41-05.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theory and Applications of Models of Computation</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. U-shaped learning deals with a learner first having the correct hypothesis, then changing it to an incorrect hypothesis and then relearning the correct hypothesis. This phenomenon has been observed by psychologists in various studies of children ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:O2n5Ep7n5KgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>25</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12170106759171107131&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12170106759171107131&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="140">
        <url>http://www.springerlink.com/index/7J55687H719706J1.pdf</url>
        <title status="complete" source="scholar.google.com">Mechanisms of knowledge evolution for web information extraction</title>
        <author status="complete" source="scholar.google.com">C MÃ¼ller</author>
        <proceeding status="complete" source="scholar.google.com">Federation over the Web</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. The knowledge that is needed in Web information extraction can, under certain assumptions, be characterized as the knowledge held by wrappers that are used to extract the semantics of documents. The evolution of this knowledge can be divided into the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:foNSGpOrU1UJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6148446564581016446&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6148446564581016446&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="141">
        <url>http://www.springerlink.com/index/953nl87770n8u582.pdf</url>
        <title status="complete" source="scholar.google.com">Mind change complexity of inferring unbounded unions of pattern languages from positive data</title>
        <pdf>http://fs1.bib.tiera.ru/content/dvd52/Balcazar%20J.%20L.%20(Ed),%20Long%20Ph.%20M.%20(Ed),%20Stephan%20F.%20(Ed)%20-%20Algorithmic%20Learning%20Theory.%2017th%20International%20Conference,%20ALT%202006,%20Barcelona,%20Spain,%20October%207-10,%202006,%20Proceedings(2006)(393).pdf#page=135</pdf>
        <author status="complete" source="scholar.google.com">M de Brecht, A Yamamoto</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper gives a proof that the class of unbounded unions of languages of regular patterns with constant segment length bound is inferable from positive data with mind change bound between Ï Ï and www Ï^ Ï^ Ï. We give a very tight bound on the mind change ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:s5QaNydO4G4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7989471669290439859&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7989471669290439859&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="142">
        <url>http://www.springerlink.com/index/77telyrg3pmm7cnc.pdf</url>
        <title status="complete" source="scholar.google.com">Counting extensional differences in BC-learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.8062&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, S Terwijn</author>
        <proceeding status="partial" source="scholar.google.com">Grammatical Inference: Algorithms and &#8230;</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Let BC be the model of behaviourally correct function learning as introduced by Barzdins [4] and Case and Smith [8]. We introduce a mind change hierarchy for BC, counting the number of extensional differences in the hypotheses of a learner. We compare the resulting ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:aUlyOc03SogJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9820723292006402409&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9820723292006402409&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="143">
        <url>http://www.springerlink.com/index/RK67V5644693N33P.pdf</url>
        <title status="complete" source="scholar.google.com">Learning families of closed sets in matroids</title>
        <pdf>http://carlossicoli.free.fr/D/Dinneen_M.J.,_Khoussainov_B.,_Nies_A.-Computation,_Physics_and_Beyond-Springer(2012).pdf#page=130</pdf>
        <author status="complete" source="scholar.google.com">Z Gao, F Stephan, G Wu, A Yamamoto</author>
        <proceeding status="partial" source="scholar.google.com">Computation, Physics and &#8230;</proceeding>
        <year>2012</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In this paper it is studied for which oracles A and which types of A-re matroids the class of all A-re closed sets in the matroid is learnable by an unrelativised learner. The learning criteria considered comprise in particular criteria more general than behaviourally correct ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:imU_RCcj09AJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>21</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15047409431530661258&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15047409431530661258&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="144">
        <url>http://www.sciencedirect.com/science/article/pii/S0168007205000941</url>
        <title status="complete" source="scholar.google.com">Generality&#39;s price: Inescapable deficiencies in machine-learned programs</title>
        <pdf>http://www.cis.syr.edu/~royer/archive/gen.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, KJ Chen, S Jain, W Merkle, JS Royer</author>
        <proceeding status="partial" source="scholar.google.com">Annals of Pure and Applied &#8230;</proceeding>
        <year>2006</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper investigates some delicate tradeoffs between the generality of an algorithmic learning device and the quality of the programs it learns successfully. There are results to the effect that, thanks to small increases in generality of a learning device, the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:JENiSWTOK-AJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16153231418617643812&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16153231418617643812&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="145">
        <url>http://www.springerlink.com/index/1233111895g360t7.pdf</url>
        <title status="complete" source="scholar.google.com">Learning real polynomials with a Turing machine</title>
        <author status="complete" source="scholar.google.com">D Cheung</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We provide an algorithm to PAC learn multivariate polynomials with real coefficients. The instance space from which labeled samples are drawn is IR N but the coordinates of such samples are known only approximately. The algorithm is iterative and the main ingredient ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:9j_KUzUkmQwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=907796611349495798&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=907796611349495798&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="146">
        <url>http://www.springerlink.com/index/BP37665N54TJ3522.pdf</url>
        <title status="complete" source="scholar.google.com">Computing characteristic sets of bounded unions of polynomial ideals</title>
        <author status="partial" source="scholar.google.com">I Takamatsu, M Kobayashi, H Tokunaga&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">New Frontiers in Artificial &#8230;</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The surprising fact that Hilbert&#39;s basis theorem in algebra shows identifiabilty of ideals of polynomials in the limit from positive data is derived by the correspondence between ideals and languages in the context of machine learning. This correspondence also reveals the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:nNWVVGvbUp4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11408422060109976988&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11408422060109976988&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="147">
        <url>http://www.springerlink.com/index/P142346471G1117R.pdf</url>
        <title status="complete" source="scholar.google.com">Learning figures with the hausdorff metric by fractals</title>
        <pdf>http://mahito.info/Files/Sugiyama_ALT2010.pdf</pdf>
        <author status="partial" source="scholar.google.com">M Sugiyama, E Hirowatari, H Tsuiki&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Algorithmic Learning &#8230;</proceeding>
        <year>2010</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Discretization is a fundamental process for machine learning from analog data such as continuous signals. For example, the discrete Fourier analysis is one of the most essential signal processing methods for learning or recognition from continuous signals. However, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:sWX3XHtrfVsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6592543607125140913&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6592543607125140913&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="148">
        <url>http://cmsassets.comp.nus.edu.sg/~fstephan/recursiontheory-pstopdf.pdf</url>
        <title status="complete" source="scholar.google.com">Recursion theory</title>
        <pdf>http://cmsassets.comp.nus.edu.sg/~fstephan/recursiontheory-pstopdf.pdf</pdf>
        <author status="complete" source="scholar.google.com">F Stephan</author>
        <year>2009</year>
        <source>cmsassets.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Recursion theory deals with the fundamental concepts on what subsets of natural numbers (or other famous countable domains) could be defined effectively and how complex the so defined sets are. The basic concept are the recursive and recursively enumerable sets, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:xNz4ZeWWl9QJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:xNz4ZeWWl9QJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>27</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15318878569526516932&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15318878569526516932&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="149">
        <url>http://www.springerlink.com/index/kwux465b2brhh1qq.pdf</url>
        <title status="complete" source="scholar.google.com">Limiting resolution: From foundations to implementation</title>
        <author status="complete" source="scholar.google.com">P Caldon, E Martin</author>
        <proceeding status="complete" source="scholar.google.com">Logic Programming</proceeding>
        <year>2004</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We present a generalization of SLD-resolution, Limiting Resolution (LR) which embeds concepts from the field of inductive inference into logic programming. This paper describes the development of LR from theoretical underpinnings through to demonstrating a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:VvU4ekvWHK4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12546138281608803670&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12546138281608803670&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="150">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397502008149</url>
        <title status="complete" source="scholar.google.com">Learning power and language expressiveness</title>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The topic of the present work is to study the relationship between the power of the learning algorithms on the one hand, and the expressive power of the logical language which is used to represent the problems to be learned on the other hand. The central question is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:houbhlhcZq0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12494775751471238022&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12494775751471238022&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="151">
        <url>http://rstb.royalsocietypublishing.org/content/367/1598/1971.short</url>
        <title status="complete" source="scholar.google.com">The neurobiology of syntax: beyond string sets</title>
        <pdf>http://pubman.mpdl.mpg.de/pubman/item/escidoc:1451131:4/component/escidoc:1479593/Petersson_Phil_Trans_R_Soc_B_2012.pdf</pdf>
        <author status="complete" source="scholar.google.com">KM Petersson, P Hagoort</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; of the Royal &#8230;</proceeding>
        <year>2012</year>
        <source>rstb.royalsocietypublishing.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract The human capacity to acquire language is an outstanding scientific challenge to understand. Somehow our language capacities arise from the way the human brain processes, develops and learns in interaction with its environment. To set the stage, we ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:lnGYiK5GFRgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1735370946851139990&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1735370946851139990&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="152">
        <url>http://japanlinkcenter.org/JST.JSTAGE/ipsjdc/1.141?from=Google</url>
        <title status="complete" source="scholar.google.com">Refutability and reliability for inductive inference of recursive real-valued functions</title>
        <author status="complete" source="scholar.google.com">E Hirowatari, K Hirata, T Miyahara, S Arikawa</author>
        <proceeding status="complete" source="scholar.google.com">IPSJ Digital Courier</proceeding>
        <year>2005</year>
        <source>J-STAGE</source>
        <snippet status="partial" source="scholar.google.com">Inductive inference gives us a theoretical model of concept learning from examples. In this paper, we study refutably and reliably inductive inference of recursive real-valued functions. First we introduce the new criteria RealRefEx for refutable inference and RealRelEx for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Bj5YkSkJ59QJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15341240729797672454&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15341240729797672454&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="153">
        <url>http://www2.units.it/episteme/L&amp;PS_Vol3No1/datteri-hosni-tamburrini/datteri-hosni-tamburrini-html/datteri-hosni-tamburrini_L&amp;PS_Vol3No1.html</url>
        <title status="complete" source="scholar.google.com">Machine learning from examples: A non-inductivist analysis</title>
        <pdf>http://www2.units.it/episteme/L&amp;PS_Vol3No1/datteri-hosni-tamburrini/datteri-hosni-tamburrini-html/datteri-hosni-tamburrini_L&amp;PS_Vol3No1.html</pdf>
        <author status="complete" source="scholar.google.com">E Datteri, H Hosni, G Tamburrini</author>
        <proceeding status="complete" source="scholar.google.com">Logic and Philosophy of Science</proceeding>
        <year>2005</year>
        <source>units.it</source>
        <snippet status="partial" source="scholar.google.com">ABSTRACT. It has been suggested that AI investigations of mechanical learning undermine sweeping anti-inductivist views in the theory of knowledge and the philosophy of science. In particular, it is claimed that some mechanical learning systems perform epistemically ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:F01Nyi6xPLkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13347738210139983127&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13347738210139983127&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="154">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397509000668</url>
        <title status="complete" source="scholar.google.com">Parallelism increases iterative learning power</title>
        <author status="complete" source="scholar.google.com">J Case, SE Moelius III</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2009</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Iterative learning (It-learning) is a Gold-style learning model in which each of a learner&#39;s output conjectures may depend only upon the learner&#39;s current conjecture and the current input element. Two extensions of the It-learning model are considered, each of which ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:AmR2ykO8WnsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8888623813914682370&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8888623813914682370&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="155">
        <url>http://projecteuclid.org/euclid.jsl/1243948324</url>
        <title status="complete" source="scholar.google.com">Learning correction grammars</title>
        <pdf>https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2307/1/TR12-06.pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
        <year>2009</year>
        <source>projecteuclid.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract We investigate a new paradigm in the context of learning in the limit, namely, learning correction grammars for classes of computably enumerable (ce) languages. Knowing a language may feature a representation of it in terms of two grammars. The ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:0zSN0GENz58J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11515437485971551443&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11515437485971551443&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="156">
        <url>http://www.springerlink.com/index/4H6654381W4512X6.pdf</url>
        <title status="complete" source="scholar.google.com">Robust learning of automatic classes of languages</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/3143/1/TRA4-10.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Martin, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper adapts and investigates the paradigm of robust learning, originally defined in the inductive inference literature for classes of recursive functions, to learning languages from positive data. Robustness is a very desirable property, as it captures a form of invariance ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:638p0aK98c4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>22</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14911908348191932395&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14911908348191932395&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="157">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397509000620</url>
        <title status="complete" source="scholar.google.com">Prescribed learning of re classes</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.108.2025&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan, N Ye</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2009</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This work extends studies of Angluin, Lange and Zeugmann on the dependence of learning on the hypothesis space chosen for the language class in the case of learning uniformly recursive language classes. The concepts of class-comprising (where the learner can ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:YdSz3nZgLTsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>20</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4264170485848462433&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4264170485848462433&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="158">
        <url>http://www.springerlink.com/index/uhq0emr1dtqgjrkx.pdf</url>
        <title status="complete" source="scholar.google.com">Learning recursive concepts with anomalies</title>
        <pdf>http://cs5824.userapi.com/u11728334/docs/a70c63d88f80/Hiroki_Arimura_Algorithmic_Learning_Theory_11_c.pdf#page=111</pdf>
        <author status="complete" source="scholar.google.com">G Grieser, S Lange, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper provides a systematic study of inductive inference of indexable concept classes in learning scenarios in which the learner is successful if its final hypothesis describes a finite variant of the target concept-henceforth called learning with anomalies. As usual, we ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:aWrK9G-Cpf4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>17</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18349215674150840937&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18349215674150840937&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="159">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000006000304</url>
        <title status="complete" source="scholar.google.com">Learning languages in a union</title>
        <author status="complete" source="scholar.google.com">S Jain, YK Ng, TS Tay</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In inductive inference, a machine is given words of a language (a recursively enumerable set in our setting) and the machine is said to identify the language if it correctly names the language. In this paper we study identifiability of classes of languages where the unions of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GHk691m3r34J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9128716566731061528&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9128716566731061528&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="160">
        <url>http://www.iidia.com.ar/rgm/comunicaciones/JIISIC-08-179-187.pdf</url>
        <title status="complete" source="scholar.google.com">Un modelo de arquitectura para el aprendizaje y comparticiÃ³n de conocimiento entre sistemas inteligentes autÃ³nomos distribuidos</title>
        <pdf>http://www.iidia.com.ar/rgm/comunicaciones/JIISIC-08-179-187.pdf</pdf>
        <author status="partial" source="scholar.google.com">J Ierache, M Naiouf, R GarcÃ­a MartÃ­nez&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; de IngenierÃ­a de &#8230;</proceeding>
        <year>2008</year>
        <source>iidia.com.ar</source>
        <snippet status="partial" source="scholar.google.com">Resumen Se presenta un modelo de arquitecturas para sistemas inteligentes autÃ³nomos distribuidos con comparticiÃ³n de conocimiento. Este se enfoca en plantear un modelo para que sistemas autÃ³nomos inteligentes interoperen en entornos distribuidos enfocando su ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:fPrsy8oZ3AoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:fPrsy8oZ3AoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=782528794051017340&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=782528794051017340&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="161">
        <url>http://www.springerlink.com/index/W4537355387873K3.pdf</url>
        <title status="complete" source="scholar.google.com">Prescribed learning of RE classes</title>
        <pdf>https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2576/1/TR10-07.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan, N Ye</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This work extends studies of Angluin, Lange and Zeugmann on the dependence of learning on the hypotheses space chosen for the class. In subsequent investigations, uniformly recursively enumerable hypotheses spaces have been considered. In the present work, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:WtrFAkGimIoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9986910573797169754&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9986910573797169754&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="162">
        <url>http://www.aaai.org/Papers/Symposia/Spring/2007/SS-07-05/SS07-05-006.pdf</url>
        <title status="complete" source="scholar.google.com">Learning a Plan in the Limit</title>
        <pdf>http://aaaipress.org/Papers/Symposia/Spring/2007/SS-07-05/SS07-05-006.pdf</pdf>
        <author status="complete" source="scholar.google.com">P Caldon, E Martin</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the AAAI Spring Symposium on &#8230;</proceeding>
        <year>2007</year>
        <source>aaai.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Induction is one of the major forms of reasoning; it is therefore essential to include it in a commonsense reasoning framework. This paper examines a class of induction-based planning problems. These problems can be solved, but not in the classical sense, where ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:osV1GuTuDnoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8795229785765037474&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8795229785765037474&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="163">
        <url>http://www.sciencedirect.com/science/article/pii/S030439750200419X</url>
        <title status="complete" source="scholar.google.com">Decision lists over regular patterns</title>
        <author status="complete" source="scholar.google.com">S Lange, J Nessel</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The paper introduces the notion of decision lists over regular patterns. This formalism provides a strict extension of regular erasing pattern languages and of containment decision lists. Formal properties of the resulting language class, a subclass of the regular ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:4cLDHBLA8YoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10011994630645859041&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10011994630645859041&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="164">
        <url>http://iospress.metapress.com/index/TRRD110H759Y5W0B.pdf</url>
        <title status="complete" source="scholar.google.com">The intrinsic complexity of learning: A survey</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/intrinsur.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Fundamenta Informaticae</proceeding>
        <year>2003</year>
        <source>IOS Press</source>
        <snippet status="partial" source="scholar.google.com">The theory of learning in the limit has been a focus of study by several researchers over the last three decades. There have been several suggestions on how to measure the complexity or hardness of learning. In this paper we survey the work done in one specific such ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:b9x1IASxyRcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1714095764473764975&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1714095764473764975&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="165">
        <url>http://www.springerlink.com/index/2ekr0vuphnl0253x.pdf</url>
        <title status="complete" source="scholar.google.com">On computability of pattern recognition problems</title>
        <pdf>http://www.idsia.ch/idsiareport/IDSIA-17-05.pdf</pdf>
        <author status="complete" source="scholar.google.com">D Ryabko</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In statistical setting of the pattern recognition problem the number of examples required to approximate an unknown labelling function is linear in the VC dimension of the target learning class. In this work we consider the question whether such bounds exist if ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GKJUJOfx5-sJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16998821293582492184&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16998821293582492184&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="166">
        <url>http://www.springerlink.com/index/m447337826676k75.pdf</url>
        <title status="complete" source="scholar.google.com">Deduction, Induction, and beyond in Parametric Logic</title>
        <pdf>http://sites.google.com/site/omundodalogica/livros-de-introducao-a-logica/Logic,Epistemology,andtheUnityofScienceVol.9-Induction,AlgorithmicLearningTheory,andPhilosophy.pdf#page=68</pdf>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">Induction, Algorithmic Learning Theory, &#8230;</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">With parametric logic, we propose a unified approach to deduction and induction, both viewed as particular instances of a generalized notion of logical consequence. This generalized notion of logical consequence is Tarskian, in the sense that if a sentence Ï is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MsBcJUWaGjUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3826540455174914098&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3826540455174914098&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="167">
        <url>http://www.springerlink.com/index/85nxf8jer9dfw3aw.pdf</url>
        <title status="complete" source="scholar.google.com">Explanation as contextual</title>
        <author status="complete" source="scholar.google.com">R Young</author>
        <proceeding status="complete" source="scholar.google.com">Modeling and Using Context</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">There is a view that all explanation is contextual. An explanation answers questions that are relevant in a context and that are open to solution in that context. In another context, there might be no such questions, or they might not be open to solution. Van Fraassen has used ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FEI-NRwhuTMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3727046571661869588&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3727046571661869588&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="168">
        <url>http://www.springerlink.com/index/ch8pj94nfknw32c8.pdf</url>
        <title status="complete" source="scholar.google.com">Generalized logical consequence: Making room for induction in the logic of science</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.7.388&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Chopra, E Martin</author>
        <proceeding status="complete" source="scholar.google.com">Journal of philosophical logic</proceeding>
        <year>2002</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We present a framework that provides a logic for science by generalizing the notion of logical (Tarskian) consequence. This framework will introduce hierarchies of logical consequences, the first level of each of which is identified with deduction. We argue for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MbV8NjJ-dIYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9688507452508386609&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9688507452508386609&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="169">
        <url>http://www.informatik.uni-trier.de/~kasprzik/KasprzikDiss.pdf</url>
        <title status="complete" source="scholar.google.com">Formal tree languages and their algorithmic learnability</title>
        <pdf>http://www.informatik.uni-trier.de/~kasprzik/KasprzikDiss.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Kasprzik</author>
        <year>2011</year>
        <source>informatik.uni-trier.de</source>
        <snippet status="partial" source="scholar.google.com">Abstract This thesis centers on formal tree languages and on their learnability by algorithmic methods in abstractions of several learning settings. After a general introduction (Chapter 1), we present a survey of relevant definitions for the formal tree concept as well as special ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:XUrGPQUipE4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:XUrGPQUipE4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5666691637045512797&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5666691637045512797&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="170">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.72.5245&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Discovering and Debugging Algebraic Specifications for Java Classes</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.72.5245&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Henkel</author>
        <year>2004</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">This thesis presents a system for reducing the cost of developing algebraic specifications for Java classes. The system consists of two components: an algebraic specification discovery tool and an algebraic interpreter. The first tool automatically discovers algebraic ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:zdy8Pk2s4GUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:zdy8Pk2s4GUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7341056840378932429&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7341056840378932429&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="171">
        <url>http://jmlr.csail.mit.edu/proceedings/papers/v13/sugiyama10b/sugiyama10b.pdf</url>
        <title status="complete" source="scholar.google.com">The coding divergence for measuring the complexity of separating two sets</title>
        <pdf>http://jmlr.csail.mit.edu/proceedings/papers/v13/sugiyama10b/sugiyama10b.pdf</pdf>
        <author status="complete" source="scholar.google.com">M Sugiyama, A Yamamoto</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; of 2nd Asian Conference on Machine &#8230;</proceeding>
        <year>2010</year>
        <source>jmlr.csail.mit.edu</source>
        <snippet status="partial" source="scholar.google.com">Abstract In this paper we integrate two essential processes, discretization of continuous data and learning of a model that explains them, towards fully computational machine learning from continuous data. Discretization is fundamental for machine learning and data mining, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:mQ7PSXE8qKMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:mQ7PSXE8qKMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11792742081536921241&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="172">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=SE2dQKpbHL4C&amp;oi=fnd&amp;pg=PA3&amp;ots=TB3gbK2uzP&amp;sig=lSaN-QBZrFmVL_7sH3g4HRFzZ1s</url>
        <title status="complete" source="scholar.google.com">Designing for Mutability in Information Systems Artifacts</title>
        <pdf>http://epress.anu.edu.au/info_systems02/pdf/whole_book.pdf#page=13</pdf>
        <author status="complete" source="scholar.google.com">S Gregor, J Iivari</author>
        <year>2007</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper aims to extend understanding of the nature of information systems and technology (IS/IT) artifacts and the manner in which information systems design theories address the mutable nature of these artifacts. The term &#39;semizoa&#39;is introduced to refer to IS/ ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:xeM3ZZRPDdoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15712302173737444293&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15712302173737444293&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="173">
        <url>http://www.jstor.org/stable/10.1086/341856</url>
        <title status="complete" source="scholar.google.com">Scientific discovery from the perspective of hypothesis acceptance</title>
        <pdf>http://mail.philsci.org/archives/psa2000/scientific-discovery.pdf</pdf>
        <author status="complete" source="scholar.google.com">E Martin, D Osherson</author>
        <proceeding status="complete" source="scholar.google.com">Philosophy of Science</proceeding>
        <year>2002</year>
        <source>JSTOR</source>
        <snippet status="partial" source="scholar.google.com">Abstract A model of inductive inquiry is defined within the context of first-order logic. The model conceives of inquiry as a game between Nature and a scientist. To begin the game, a nonlogical vocabulary is agreed upon by the two players, along with a partition of a class ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:r7xhiNf4uR0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>25</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2142016702381145263&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2142016702381145263&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="174">
        <url>http://www.illc.uva.nl/HPI/Draft_Learning.pdf</url>
        <title status="complete" source="scholar.google.com">Learning, Simplicity, Truth, and Misinformation</title>
        <pdf>http://www.illc.uva.nl/HPI/Draft_Learning.pdf</pdf>
        <author status="complete" source="scholar.google.com">K Kelly</author>
        <year>2005</year>
        <source>illc.uva.nl</source>
        <snippet status="partial" source="scholar.google.com">Abstract Both in learning and in natural science, one faces the problem of selecting among a range of theories, all of which are compatible with the available evidence. The traditional response to this problem has been to select the simplest such theory on the basis of â ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:st0aibOPT1wJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:st0aibOPT1wJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6651693175911669170&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6651693175911669170&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="175">
        <url>http://www.springerlink.com/index/6ERU0RJGACY7NH57.pdf</url>
        <title status="complete" source="scholar.google.com">Classes with easily learnable subclasses</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.69.7892&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, W Menzel, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2002</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Let Ex denote the explanatory model of learning [3],[5]. Various more restrictive models have been studied in the literature, an example is finite identification [5]. The topic of the present paper are the natural variants (a) and (b) below of the classical question whether a given ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Wa_BkvHgXHMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8312766340373000025&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8312766340373000025&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="176">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.51.1603&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Learning Strategies for Infinite Games</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.51.1603&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">M Ott</author>
        <year>1998</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">The aim of computational learning theory is to model learning problems from a computability or complexity theoretical point of view, and to provide| in the developed models| rigorous mathematical proofs for phenomena which occur in real world problems. Within ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:6d77nA6DcKAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:6d77nA6DcKAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11560884342246596329&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11560884342246596329&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="177">
        <url>http://www.springerlink.com/index/KUY6NRGG7E72T9R4.pdf</url>
        <title status="complete" source="scholar.google.com">Learning by switching type of information</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.8.2370&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The present work is dedicated to the study of modes of datapresentation between text and informant within the framework of inductive inference. The model is such that the learner requests sequences of positive andnegativ e data andthe relations between the various ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RIi4rBN__vcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17869860093931587652&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17869860093931587652&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="178">
        <url>http://etd.lsu.edu/docs/available/etd-02152007-190320/</url>
        <title status="complete" source="scholar.google.com">Using time-lapse and stroboscopic photography to enhance student understanding of plant growth, structure, and pollination: An inquiry-based study</title>
        <pdf>http://etd.lsu.edu/docs/available/etd-02152007-190320/unrestricted/LJSDissertation.pdf</pdf>
        <author status="complete" source="scholar.google.com">LJ Schultz Sr</author>
        <year>2007</year>
        <source>etd.lsu.edu</source>
        <snippet status="partial" source="scholar.google.com">Abstract This study was designed to evaluate the effects of allowing students to generate their own images in a science class as opposed to using pre-existing images. The participants in the study were 7th grade science students enrolled in a small, rural, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:tWkEr9vYl9wJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15895411847873194421&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15895411847873194421&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="179">
        <url>http://www.springerlink.com/index/a5q146m5w688qr30.pdf</url>
        <title status="complete" source="scholar.google.com">Consistency conditions for inductive inference of recursive functions</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/cons_cond_07az.pdf</pdf>
        <author status="complete" source="scholar.google.com">Y Akama, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">New Frontiers in Artificial Intelligence</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A consistent learner is required to correctly and completely reflect in its actual hypothesis all data received so far. Though this demand sounds quite plausible, it may lead to the unsolvability of the learning problem. Therefore, in the present paper several variations of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:7hVztLILKRwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2029165969266644462&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2029165969266644462&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="180">
        <title status="complete" source="scholar.google.com">U-shaped, iterative, and iterative-with-counter learning (expanded version)</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2fP3wed_a-kJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16819677866713674713&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="181">
        <url>http://www.springerlink.com/index/tfnvaubgr6letkab.pdf</url>
        <title status="complete" source="scholar.google.com">On a syntactic characterization of classification with a mind change bound</title>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Most learning paradigms impose a particular syntax on the class of concepts to be learned; the chosen syntax can dramatically affect whether the class is learnable or not. For classification paradigms, where the task is to determine whether the underlying world ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ok69y5G1ZLgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13286944438442872482&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13286944438442872482&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="182">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=HmkZLRXC7_oC&amp;oi=fnd&amp;pg=PT60&amp;ots=bW3-qifDZ-&amp;sig=hLTGRtJQjA5ehZzjWNJpFSCFfN8</url>
        <title status="complete" source="scholar.google.com">Wrapper induction programs as information extraction assistants</title>
        <pdf>http://km.meme.hokudai.ac.jp/people/jantke/Publications/2005/2005_JantkeMueller_PISA.pdf</pdf>
        <author status="complete" source="scholar.google.com">K Jantke, C MÃ¼ller</author>
        <proceeding status="partial" source="scholar.google.com">Intelligent Assistant Systems: Concepts, &#8230;</proceeding>
        <year>2007</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">Abstract These days, search engines are useful tools relying on quite elaborated technologies which, albeit their enormous frequency of usage and the sophistication of the technologies invoked, continuously frustrate thousands of users. They are simply tools not ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:0OQNzNK8CWEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6992327510022022352&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6992327510022022352&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="183">
        <title status="complete" source="scholar.google.com">Investigating learning models for language acquisition</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:zbCP0rT7Ud8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16091919697616810189&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16091919697616810189&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="184">
        <url>http://bib.informatik.uni-tuebingen.de/files/wsi-berichte/wsi-00-13.pdf</url>
        <title status="complete" source="scholar.google.com">On learning function distinguishable languages</title>
        <pdf>http://bib.informatik.uni-tuebingen.de/files/wsi-berichte/wsi-00-13.pdf</pdf>
        <author status="complete" source="scholar.google.com">H Fernau</author>
        <year>2000</year>
        <source>bib.informatik.uni-tuebingen.de</source>
        <snippet status="partial" source="scholar.google.com">Abstract We show how appropriately chosen functions which we call distinguishing can be used to make deterministic finite automata backward deterministic. These ideas can be exploited to design regular language classes identifiable in the limit from positive samples ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MdDB4Zo2jgAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=40029485533351985&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=40029485533351985&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="185">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540101929220</url>
        <title status="complete" source="scholar.google.com">Learning by the process of elimination</title>
        <author status="partial" source="scholar.google.com">R Freivalds, M Karpinski, CH Smith&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Information and &#8230;</proceeding>
        <year>2002</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Elimination of potential hypotheses is a fundamental component of many learning processes. In order to understand the nature of elimination, herein we study the following model of learning recursive functions from examples. On any target function, the learning ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GP3h4Rz_L6sJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12335358403904929048&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12335358403904929048&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="186">
        <url>http://neuro.bstu.by/ai/To-dom/My_research/failed%201%20subitem/For-research/Needle/2-Quantom-c/proc-200205xx-yy_riga%5B1%5D.pdf#page=114</url>
        <title status="complete" source="scholar.google.com">A survey of quantum learning</title>
        <pdf>http://neuro.bstu.by/ai/To-dom/My_research/failed%201%20subitem/For-research/Needle/2-Quantom-c/proc-200205xx-yy_riga%5B1%5D.pdf#page=114</pdf>
        <author status="complete" source="scholar.google.com">R Bonner, R Freivalds</author>
        <proceeding status="complete" source="scholar.google.com">Quantum Computation and Learning</proceeding>
        <year>2003</year>
        <source>neuro.bstu.by</source>
        <snippet status="partial" source="scholar.google.com">Abstract. We survey papers on problems of learning by quantum computers. The quest of quantum learning, as that of quantum computation, is to produce tractable quantum algorithms in situations, where tractable classical algorithms do not exist, or are not known ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:TEAF4-0qwm8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:TEAF4-0qwm8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8053046284896256076&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8053046284896256076&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="187">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540110002099</url>
        <title status="complete" source="scholar.google.com">The efficiency of identifying timed automata and the power of clocks</title>
        <author status="complete" source="scholar.google.com">S Verwer, M Weerdt, C Witteveen</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2011</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We develop theory on the efficiency of identifying (learning) timed automata. In particular, we show that:(i) deterministic timed automata cannot be identified efficiently in the limit from labeled data and (ii) that one-clock deterministic timed automata can be identified ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:XD4o7Xs3ohoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1919157396612595292&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1919157396612595292&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="188">
        <url>http://www.springerlink.com/index/B827045M7662102M.pdf</url>
        <title status="complete" source="scholar.google.com">Iterative learning from positive data and counters</title>
        <author status="complete" source="scholar.google.com">T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We analyze iterative learning in the limit from positive data with the additional information provided by a counter. The simplest type of counter provides the current iteration number (counting up from 0 to infinity), which is known to improve learning power over plain ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:R2qx8w66hzAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3496968209057278535&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3496968209057278535&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="189">
        <url>http://ww.raai.org/about/persons/finn/pages/ArFinn.doc</url>
        <title status="complete" source="scholar.google.com">ÐÑÐ¸Ð½ÑÐ¸Ð¿Ñ ÐºÐ¾Ð½ÑÑÑÑÐ¸ÑÐ¾Ð²Ð°Ð½Ð¸Ñ Ð¸Ð½ÑÐµÐ»Ð»ÐµÐºÑÑÐ°Ð»ÑÐ½ÑÑ ÑÐ¸ÑÑÐµÐ¼</title>
        <pdf>http://ww.raai.org/about/persons/finn/pages/ArFinn.doc</pdf>
        <author status="complete" source="scholar.google.com">Ð®Ð ÐÑÑÐºÐ¸Ð¹, ÐÐ Ð¤Ð¸Ð½Ð½</author>
        <proceeding status="partial" source="scholar.google.com">ÐÐ½ÑÐ¾ÑÐ¼Ð°ÑÐ¸Ð¾Ð½Ð½ÑÐµ ÑÐµÑÐ½Ð¾Ð»Ð¾Ð³Ð¸Ð¸ Ð¸ &#8230;</proceeding>
        <year>2008</year>
        <source>ww.raai.org</source>
        <snippet status="partial" source="scholar.google.com">ÐÐ½Ð½Ð¾ÑÐ°ÑÐ¸Ñ. Ð ÑÑÐ°ÑÑÐµ ÑÑÐ¾ÑÐ¼ÑÐ»Ð¸ÑÐ¾Ð²Ð°Ð½Ñ Ð¿ÑÐ¸Ð½ÑÐ¸Ð¿Ñ Ð¸Ð½ÑÐµÐ»Ð»ÐµÐºÑÑÐ°Ð»ÑÐ½Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð´Ð°Ð½Ð½ÑÑ Ð¸ ÑÐ°ÑÑÐ¼Ð¾ÑÑÐµÐ½ ÐÐ¡Ð-Ð¼ÐµÑÐ¾Ð´ Ð°Ð²ÑÐ¾Ð¼Ð°ÑÐ¸ÑÐµÑÐºÐ¾Ð³Ð¾ Ð¿Ð¾ÑÐ¾Ð¶Ð´ÐµÐ½Ð¸Ñ Ð³Ð¸Ð¿Ð¾ÑÐµÐ·, ÑÐ¾Ð´ÐµÑÐ¶Ð°ÑÐ¸Ð¹ ÐÐÐ­-ÑÐ°ÑÑÑÐ¶Ð´ÐµÐ½Ð¸Ñ. ÐÑÐ°ÐºÑÐ¸ÐºÐ° Ð¿ÑÐ¸Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ ÐÐÐ­-ÑÐ°ÑÑÑÐ¶Ð´ÐµÐ½Ð¸Ð¹ (Ð² Ð²Ð¸Ð´Ðµ ÐÐ¡Ð-ÑÐ°ÑÑÑÐ¶Ð´ÐµÐ½Ð¸Ð¹) ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:inoNRmnBErAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:inoNRmnBErAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12687415758147123850&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12687415758147123850&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="190">
        <url>http://www.freidok.uni-freiburg.de/volltexte/3301/</url>
        <title status="complete" source="scholar.google.com">Three-dimensional perception for mobile robots</title>
        <pdf>http://www.freidok.uni-freiburg.de/volltexte/3301/</pdf>
        <author status="complete" source="scholar.google.com">R Triebel</author>
        <year>2007</year>
        <source>freidok.uni-freiburg.de</source>
        <snippet status="partial" source="scholar.google.com">Diese Arbeit befasst sich mit dem Problem der dreidimensionalen Wahrnehmung von mobilen Robotern, wobei die Wahrnehmung aus den Teilaspekten Datenaufnahme, konsistente und effiziente DatenreprÃ¤sentation, sowie der Klassifikation der vorhandenen ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:q37Hcb8WWe4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17174783665457561259&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17174783665457561259&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="191">
        <url>http://sedici.unlp.edu.ar/handle/10915/20476</url>
        <title status="complete" source="scholar.google.com">Un modelo de interoperabilidad para sistemas autÃ³nomos en entornos distribuidos</title>
        <pdf>http://sedici.unlp.edu.ar/bitstream/handle/10915/20476/Documento_completo.pdf?sequence=1</pdf>
        <author status="partial" source="scholar.google.com">J Ierache, M Naiouf, R GarcÃ­a MartÃ­nez&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">IX Workshop de &#8230;</proceeding>
        <year>2007</year>
        <source>sedici.unlp.edu.ar</source>
        <snippet status="partial" source="scholar.google.com">La lÃ­nea orienta su investigaciÃ³n a Arquitecturas de Sistemas DistribuÃ­dos, Sistemas Inteligentes AutÃ³nomos, Modelos de IntegraciÃ³n de Arquitecturas, Modelos de Interoperabilidad SemÃ¡ntica, ComparticiÃ³n de Conocimiento. Esta se enfoca en plantear ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:vEfrcGDySqMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11766483472484091836&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11766483472484091836&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="192">
        <title status="complete" source="scholar.google.com">LExIKONâSystemarchitekturen zur Extraktion von Information aus dem Internet</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:oOubvUarJ6oJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12260956830856637344&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12260956830856637344&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="193">
        <title status="complete" source="scholar.google.com">LExIKONâLernszenarios fÃ¼r die Extraktion von Information aus dem Internet</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:4Ejj4ofHZ6QJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11846656731262437600&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11846656731262437600&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="194">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540112001137</url>
        <title status="complete" source="scholar.google.com">Automatic learning of subclasses of pattern languages</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/autopat.pdf</pdf>
        <author status="partial" source="scholar.google.com">J Case, S Jain, TD Le, YS Ong, P Semukhin&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Information and &#8230;</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Automatic classes are classes of languages for which a finite automaton can decide the membership problem for the languages in the class, in a uniform way, given an index for the language. For alphabet size of at least 4, every automatic class of erasing pattern ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:h4T-C1MLkHMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>17</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8327168162319467655&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8327168162319467655&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="195">
        <url>http://www.springerlink.com/index/858g336205826854.pdf</url>
        <title status="complete" source="scholar.google.com">On a question of Frank Stephan</title>
        <author status="complete" source="scholar.google.com">K Ambos-Spies, S Badaev, S Goncharov</author>
        <proceeding status="partial" source="scholar.google.com">Theory and Applications of &#8230;</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">For many TxtEX-learnable computable families of recursively enumerable sets, all their computable numberings are equivalent with respect to the reduction via the functions recursive in the halting problem. We show that this holds for every TxtEX-learnable ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:XRuiFdSyZFgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6369412396974480221&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6369412396974480221&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="196">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.114.9567&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Inductive Simplicity and the Matrix</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.114.9567&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">G Harman, S Kulkarni</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the 25th Annual Meeting of the &#8230;</proceeding>
        <year>2003</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract In certain statistical learning problems, a policy of choosing simpler rules that account fairly well for data is likely to have less error on new cases than a policy of choosing complex rules that have less error on the data. The relevant kind of simplicity is not to be ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:9G39F-VetsoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:9G39F-VetsoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14606966779465788916&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14606966779465788916&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="197">
        <url>http://www.springerlink.com/index/w25m257233680458.pdf</url>
        <title status="complete" source="scholar.google.com">How to do things with an infinite regress</title>
        <pdf>http://repository.cmu.edu/cgi/viewcontent.cgi?article=1379&amp;context=philosophy</pdf>
        <author status="complete" source="scholar.google.com">K Kelly</author>
        <proceeding status="partial" source="scholar.google.com">Induction, Algorithmic Learning Theory, and &#8230;</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Scientific methods may be viewed as procedures for converging to the true answer to a given empirical question. Typically, such methods converge to the truth only if certain empirical presuppositions are satisfied, which raises the question whether the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MkF0G34A8KUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>33</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11957057552295149874&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11957057552295149874&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="198">
        <url>http://dare.uva.nl/record/114462</url>
        <title status="complete" source="scholar.google.com">Coordination of 01-agents vs. coordination of worlds-based agents</title>
        <pdf>http://dare.uva.nl/document/1249</pdf>
        <author status="complete" source="scholar.google.com">A Agostini, D De Jongh, F Montagna</author>
        <year>2000</year>
        <source>dare.uva.nl</source>
        <snippet status="partial" source="scholar.google.com">Abstract As far as we know, a learning to coordinate paradigm was rst introduced in Learning Theory JORS99] by using the tools of recursion theory MOss]. In this paper, we present a rst-order paradigm of coordination| we call this paradigm of sf-coordination. The ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:znR1JmCsYZYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10836131707392193742&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10836131707392193742&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="199">
        <url>http://www.springerlink.com/index/RL2050457GU60010.pdf</url>
        <title status="complete" source="scholar.google.com">Iterative learning from positive data and negative counterexamples</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1918/1/TRA3-06.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A model for learning in the limit is defined where a (so-called iterative) learner gets all positive examples from the target language, tests every new conjecture with a teacher (oracle) if it is a subset of the target language (and if it is not, then it receives a negative ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:LnGoLrd_Ie4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>15</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17159136479996834094&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17159136479996834094&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="200">
        <url>http://www.springerlink.com/index/E51164H268835618.pdf</url>
        <title status="complete" source="scholar.google.com">On the amount of nonconstructivity in learning recursive functions</title>
        <pdf>http://www.lu.lv/fileadmin/user_upload/lu_portal/projekti/datorzinatnes_pielietojumi/publikacijas/Freivalds_6_1.pdf</pdf>
        <author status="complete" source="scholar.google.com">R Freivalds, T Zeugmann</author>
        <proceeding status="partial" source="scholar.google.com">Theory and Applications of Models of &#8230;</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Nonconstructive proofs are a powerful mechanism in mathematics. Furthermore, nonconstructive computations by various types of machines and automata have been considered by eg, Karp and Lipton [] and Freivalds []. They allow to regard more ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:p9S5NJ9fEk4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5625664021928203431&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5625664021928203431&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="201">
        <url>http://www.springerlink.com/index/U24442P28136J242.pdf</url>
        <title status="complete" source="scholar.google.com">Software model synthesis using satisfiability solvers</title>
        <author status="complete" source="scholar.google.com">MJH Heule, S Verwer</author>
        <proceeding status="complete" source="scholar.google.com">Empirical Software Engineering</proceeding>
        <year>2012</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract We introduce a novel approach for synthesis of software models based on identifying deterministic finite state automata. Our approach consists of three important contributions. First, we argue that in order to model software, one should focus mainly on ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:uq76NAVtyU0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5605131080370400954&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="202">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397507006585</url>
        <title status="complete" source="scholar.google.com">Learning languages from positive data and a limited number of short counterexamples</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1899/1/TR21-05.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We consider two variants of a model for learning languages in the limit from positive data and a limited number of short negative counterexamples (counterexamples are considered to be short if they are smaller than the largest element of input seen so far). Negative ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:oTUPOOVeFnkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8725265666657957281&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8725265666657957281&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="203">
        <url>http://dl.comp.nus.edu.sg/dspace/handle/1900.100/1903</url>
        <title status="complete" source="scholar.google.com">Memory-Limited U-Shaped Learning</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1903/1/tr51-05.pdf</pdf>
        <author status="complete" source="scholar.google.com">L CARLUCCI, J CASE, S JAIN, F STEPHAN</author>
        <year>2005</year>
        <source>dl.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract: U-shaped learning is a learning behaviour in which the learner first learns something, then unlearns it and finally relearns it. Such a behaviour, observed by psychologists, for example, in the learning of past-tenses of English verbs, has been ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2QKGOB0_q7AJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12730338166427747033&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12730338166427747033&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="204">
        <url>http://www.springerlink.com/index/JHAKX6HT87VUU10B.pdf</url>
        <title status="complete" source="scholar.google.com">Changing the Inference TypeâKeeping the Hypothesis Space</title>
        <pdf>http://cs5235.userapi.com/u133638729/docs/0b3b37a51a80/Ricard_Gavald_Algorithmic_Learning_Theory_14_co.pdf#page=84</pdf>
        <author status="complete" source="scholar.google.com">F Balbach</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2003</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In inductive inference all learning takes place in hypothesis spaces. We investigate for which classes of recursive functions learnability according to an inference type II implies learnability according to a different inference type JJ within the same hypothesis space. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:iEBLTLJoq84J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14892111707824144520&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14892111707824144520&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="205">
        <url>http://repository.cmu.edu/cgi/viewcontent.cgi?article=1144&amp;context=philosophy</url>
        <title status="complete" source="scholar.google.com">A Close Shave with Realism: How Ockham&#39;s Razor Helps Us Find the Truth</title>
        <pdf>http://repository.cmu.edu/cgi/viewcontent.cgi?article=1144&amp;context=philosophy</pdf>
        <author status="complete" source="scholar.google.com">KT Kelly</author>
        <year>2002</year>
        <source>repository.cmu.edu</source>
        <snippet status="partial" source="scholar.google.com">Abstract Many distinct theories are compatible with current experience. Scientific realists recommend that we choose the simplest. Anti-realists object that such appeals to&quot; Ockham&#39;s razor&quot; cannot be truth-conducive, since they lead us astray in complex worlds. I argue, on ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2-z1TjuA8W8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8066369399813434587&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8066369399813434587&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="206">
        <url>http://www.springerlink.com/index/p471j41484409222.pdf</url>
        <title status="complete" source="scholar.google.com">Logically reliable inductive inference</title>
        <pdf>http://www.cs.sfu.ca/~oschulte/files/pubs/vnorma.pdf</pdf>
        <author status="complete" source="scholar.google.com">O Schulte</author>
        <proceeding status="partial" source="scholar.google.com">Induction, Algorithmic Learning Theory, and &#8230;</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper is an overview of formal learning theory that emphasizes the philosophical motivation for the mathematical definitions. I introduce key concepts at a slow pace, comparing and contrasting with other approaches to inductive inference such as ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:vh8XVq1rZroJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>16</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13431541330896953278&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13431541330896953278&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="207">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.145.8803&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Optimal language learning (expanded version)</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.145.8803&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, SE Moelius</author>
        <year>2008</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. Gold&#39;s original paper on inductive inference introduced a notion of an optimal learner. Intuitively, a learner identifies a class of objects optimally iff there is no other learner that: requires as little of each presentation of each object in the class in order to identify ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:d7PuVqTQuiMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:d7PuVqTQuiMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2574599541247357815&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2574599541247357815&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="208">
        <url>http://ethos.bl.uk/OrderDetails.do?uin=uk.bl.ethos.408657</url>
        <title status="complete" source="scholar.google.com">Modelling optional infinitive phenomena in children&#39;s speech</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:suFoeOZkI3wJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8945104225913332146&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8945104225913332146&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="209">
        <url>http://www.springerlink.com/index/371821UW3L4225G8.pdf</url>
        <title status="complete" source="scholar.google.com">Automatic learners with feedback queries</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/autofeednew.pdf</pdf>
        <author status="partial" source="scholar.google.com">J Case, S Jain, Y Ong, P Semukhin&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Models of Computation in &#8230;</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Automatic classes are classes of languages for which a finite automaton can decide whether a given element is in a set given by its index. The present work studies the learnability of automatic families by automatic learners which, in each round, output a hypothesis and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RXW6gzjPnq0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12510664656516969797&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12510664656516969797&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="210">
        <url>http://www.scholarbank.nus.edu.sg/handle/10635/16035</url>
        <title status="complete" source="scholar.google.com">Specification mining: Methodologies, theories and applications</title>
        <pdf>http://www.scholarbank.nus.edu.sg/bitstream/handle/10635/16035/LoD.pdf?sequence=1</pdf>
        <author status="complete" source="scholar.google.com">D Lo</author>
        <year>2008</year>
        <source>scholarbank.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">In this dissertation, we describe theories, methodologies and applications of mining expressive software specifications from program execution traces. By observing program execution traces, specifications in the formats of automata, frequent behavioral patterns, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ED_riljR9zMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3744691793399856912&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3744691793399856912&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="211">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.113.356&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Models for Algorithmic Teaching</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.113.356&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">F Balbach</author>
        <year>2007</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract Learning theory focuses almost entirely on the learner and its efficient realization, but neglects other parts of the learning process, most importantly the teacher, which is merely modeled as a passive data source. In this thesis, however, we study models in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:H2UalNYLs50J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:H2UalNYLs50J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11363439301021558047&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11363439301021558047&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="212">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.36.1360&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">On learning formulas in the limit and with assurance</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.36.1360&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">A Ambainis</author>
        <proceeding status="complete" source="scholar.google.com">Information processing letters</proceeding>
        <year>2001</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">B arzdi ns, Freivalds and Smith 2] introduced a learning model for inferring formulas of rst order predicate logic from elementary facts. In their model, the learner receives an enumeration of elementary facts that are true in some model. The task of the learner is to synthesize ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:YQCYn-GffsoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:YQCYn-GffsoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14591275634120982625&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14591275634120982625&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="213">
        <url>http://frontiersinai.com/ecai/ecai2000/pdf/p0333.pdf</url>
        <title status="complete" source="scholar.google.com">Team-solvability: A model-theoretic perspective</title>
        <pdf>http://frontiersinai.com/ecai/ecai2000/pdf/p0333.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Agostini</author>
        <proceeding status="complete" source="scholar.google.com">ECAI</proceeding>
        <year>2000</year>
        <source>frontiersinai.com</source>
        <snippet status="partial" source="scholar.google.com">Abstract. At present, the extension of formal learning theory to the multi-agent case considers âteamsâ of agents sharing a common end. Success is achieved if one or more of the agents is successful, and cooperation is not involved in the team formation. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Mj7NokerSWcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:Mj7NokerSWcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7442668183368842802&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7442668183368842802&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="214">
        <url>http://www.springerlink.com/index/2567642l84087416.pdf</url>
        <title status="complete" source="scholar.google.com">Control structures in hypothesis spaces: The influence on learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.100.9732&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, M Suraj</author>
        <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
        <year>1997</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In any learnability setting, hypotheses are conjectured from some hypothesis space. Studied herein are the effects on learnability of the presence or absence of certain control structures in the hypothesis space. First presented are control structure characterizations of some ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:k0PPox92zbIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12884083987241190291&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12884083987241190291&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="215">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540101929104</url>
        <title status="complete" source="scholar.google.com">Induction by enumeration</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.35.5739&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">E Martin, D Osherson</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Induction by enumeration has a clear interpretation within the numerical paradigm of inductive discovery (ie, the one pioneered by EM Gold (1967, Inform. and Control10, 447â474)). The concept is less easily interpreted within the first-order paradigm discussed by ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:685CqakMUSUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2688944375345630955&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2688944375345630955&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="216">
        <url>http://www.springerlink.com/index/2e9yk3herkaudm15.pdf</url>
        <title status="complete" source="scholar.google.com">On Learning to Coordinate</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Montagna, G Simi, A Sorbi</author>
        <proceeding status="partial" source="scholar.google.com">Learning Theory and Kernel &#8230;</proceeding>
        <year>2003</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A mere bounded number of random bits judiciously employed by a probabilistically correct algorithmic coordinator is shown to increase the power of learning to coordinate compared to deterministic algorithmic coordinators. Furthermore, these probabilistic algorithmic ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:5qBDtcPhVL8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13786892589963911398&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13786892589963911398&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="217">
        <url>http://www.springerlink.com/index/e260l7477q204851.pdf</url>
        <title status="complete" source="scholar.google.com">Incremental learning with ordinal bounded example memory</title>
        <author status="complete" source="scholar.google.com">L Carlucci</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A Bounded Example Memory learner is a learner that operates incrementally and maintains a memory of finitely many data items. The paradigm is well-studied and known to coincide with set-driven learning. A hierarchy of stronger and stronger learning criteria is obtained ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:IH0StlGWmHwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8978091134854266144&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8978091134854266144&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="218">
        <url>http://www.springerlink.com/index/et9pbxuppma6j9j0.pdf</url>
        <title status="complete" source="scholar.google.com">Learning languages in a union</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/kalapp.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, Y Ng, T Tay</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In inductive inference, a machine is given words in a language and the machine is said to identify the language if it correctly names the language. In this paper we study classes of languages where the unions of up to a fixed number (n say) of languages from the class ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:pFjStsX955MJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10657766068813191332&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10657766068813191332&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="219">
        <url>http://www.princeton.edu/~osherson/papers/histPublishedVersion.pdf</url>
        <title status="complete" source="scholar.google.com">Formal learning theory in context</title>
        <pdf>http://www.princeton.edu/~osherson/papers/histPublishedVersion.pdf</pdf>
        <author status="complete" source="scholar.google.com">D Osherson, S Weinstein</author>
        <proceeding status="partial" source="scholar.google.com">Handbook of the History of Logic: Induction &#8230;</proceeding>
        <year>2011</year>
        <source>princeton.edu</source>
        <snippet status="partial" source="scholar.google.com">One version of the problem of induction is how to justify hypotheses in the face of data. Why advance hypothesis A rather than Bâor in a probabilistic context, why attach greater probability to A than B? If the data arrive as a stream of observations (distributed through ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:XQFpu9UtF6AJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:XQFpu9UtF6AJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11535739366528319837&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11535739366528319837&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="220">
        <url>http://www.springerlink.com/index/0F9V180D4H1PDFK4.pdf</url>
        <title status="complete" source="scholar.google.com">Learning how to separate</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/resep.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The main question addressed in the present work is how to find effectively a recursive function separating two sets drawn arbitrarily from a given collection of disjoint sets. In particular, it is investigated in which cases it is possible to satisfy the following additional ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:SdXNvUSIHnoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>19</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8799620550752064841&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8799620550752064841&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="221">
        <url>http://www.springerlink.com/index/R7711XV044066355.pdf</url>
        <title status="complete" source="scholar.google.com">Inductive logic programming: yet another application of logic</title>
        <author status="complete" source="scholar.google.com">A Yamamoto</author>
        <proceeding status="complete" source="scholar.google.com">Declarative Programming for Knowledge Management</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper presents a brief introduction of the relation between logic programming and machine learning. The area researching the relation is usually called Inductive Logic Programming (ILP, for short). In this paper we will give the details of neither ILP systems ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Z1DyvhWNsaQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11867421617635348583&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11867421617635348583&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="222">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000004001400</url>
        <title status="complete" source="scholar.google.com">On learning to coordinate: random bits help, insightful normal forms, and competency isomorphisms</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Montagna, G Simi, A Sorbi</author>
        <proceeding status="partial" source="scholar.google.com">Journal of Computer and &#8230;</proceeding>
        <year>2005</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A mere bounded number of random bits judiciously employed by a probabilistically correct algorithmic coordinator is shown to increase the power of learning to coordinate compared to deterministic algorithmic coordinators. Furthermore, these probabilistic algorithmic ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:5cDXwvb-EUUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4977039399005438181&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4977039399005438181&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="223">
        <url>ftp://142.58.111.31/fas-info/ftp/ftp/pub/cs/theses/2007/WeiLuoPhD.pdf</url>
        <title status="complete" source="scholar.google.com">Mind change optimal learning: theory and applications</title>
        <pdf>ftp://142.58.111.31/fas-info/ftp/ftp/pub/cs/theses/2007/WeiLuoPhD.pdf</pdf>
        <author status="complete" source="scholar.google.com">W Luo</author>
        <year>2007</year>
        <source>142.58.111.31</source>
        <snippet status="partial" source="scholar.google.com">Abstract Learning theories play a significant role to machine learning as computability and complexity theories to software engineering. Gold&#39;s language learning paradigm is one cornerstone of modern learning theories. The aim of this thesis is to establish an inductive ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:AdqaxUFSDqAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:AdqaxUFSDqAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>34</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11533246138184030721&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11533246138184030721&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="224">
        <url>http://philsci-archive.pitt.edu/2558/</url>
        <title status="complete" source="scholar.google.com">Understanding science of the new millennium</title>
        <pdf>http://philsci-archive.pitt.edu/2558/1/Usnm.pdf</pdf>
        <author status="complete" source="scholar.google.com">P Kawalec</author>
        <year>2005</year>
        <source>philsci-archive.pitt.edu</source>
        <snippet status="partial" source="scholar.google.com">Any serious attempt to give an account of the cognitive aspect of scienceâas contrasted with eg its social or cultural aspectsâcannot ignore the automation revolution. In the conception presented in this paper the results of computer science are taken seriously and integrated ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Tq2zxsWlnX0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9051573094945369422&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9051573094945369422&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="225">
        <url>http://www.springerlink.com/index/Q3641U74N61G1323.pdf</url>
        <title status="complete" source="scholar.google.com">Numberings optimal for learning</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2823/1/TRA8-08+-+Frank+Stephan+and+Sanjay+Jain.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper extends previous studies on learnability in non-acceptable numberings by considering the question: for which criteria which numberings are optimal, that is, for which numberings it holds that one can learn every learnable class using the given numbering ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:IUHpyvyqy04J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>25</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5677819757943406881&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5677819757943406881&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="226">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397503006108</url>
        <title status="complete" source="scholar.google.com">Learning how to separate</title>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The main question addressed in the present work is how to find effectively a recursive function separating two sets drawn arbitrarily from a given collection of disjoint sets. In particular, it is investigated when one can find better learners which satisfy additional ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:nF9d1Ps158kJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14548656476959629212&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14548656476959629212&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="227">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540103001743</url>
        <title status="complete" source="scholar.google.com">Counting extensional differences in BC-learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.97.1000&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan, SA Terwijn</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Let BC be the model of behaviourally correct function learning as introduced by Ba Ì rzdins [Theory of Algorithms and Programs, vol. 1, Latvian State University, 1974, p. 82â88] and Case and Smith [Theoret. Comput. Sci. 25 (1983) 193â220]. We introduce a mind change ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:7Abr25fIqYAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>15</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9271161862474106604&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9271161862474106604&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="228">
        <url>http://www.springerlink.com/index/N857344206464K67.pdf</url>
        <title status="complete" source="scholar.google.com">Two Ways of Thinking about Induction</title>
        <pdf>http://fs1.bib.tiera.ru/content/dvd57/Friend%20M.%20(ed.),%20Harizanov%20V.S.%20(ed.)%20-%20Induction,%20Algorithmic%20Learning%20Theory,%20and%20Philosophy(2007)(304).pdf#page=242</pdf>
        <author status="complete" source="scholar.google.com">N Goethe</author>
        <proceeding status="partial" source="scholar.google.com">Induction, Algorithmic Learning Theory, and &#8230;</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Inductive inference has always been a major concern in philosophy. This paper considers two different ways of thinking about induction: the classical way and the new, learning-theoretic way. After a brief introduction, I discuss the classical style of thinking about ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ZGjH3adwimcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7460899598975330404&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7460899598975330404&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="229">
        <url>http://www.springerlink.com/index/97285WVT37N48810.pdf</url>
        <title status="complete" source="scholar.google.com">On learning languages from positive data and a limited number of short counterexamples</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/bncfull.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. We consider two variants of a model for learning languages in the limit from positive data and a limited number of short negative counterexamples (counterexamples are considered to be short if they are smaller that the largest element of input seen so far). ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:y-Vc4Y2Mb7QJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13001765190241150411&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13001765190241150411&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="230">
        <url>http://www.springerlink.com/index/r62632k383117627.pdf</url>
        <title status="complete" source="scholar.google.com">Sample Complexity for Computational Classification Problems</title>
        <pdf>http://daniil.ryabko.net/comp.pdf</pdf>
        <author status="complete" source="scholar.google.com">D Ryabko</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmica</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract In a statistical setting of the classification (pattern recognition) problem the number of examples required to approximate an unknown labelling function is linear in the VC dimension of the target learning class. In this work we consider the question of whether ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Ekvn5tAbCWoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7640668826851822354&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7640668826851822354&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="231">
        <url>http://rsta.royalsocietypublishing.org/content/370/1971/3570.short</url>
        <title status="complete" source="scholar.google.com">Computability-theoretic learning complexity</title>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="partial" source="scholar.google.com">Philosophical Transactions of the &#8230;</proceeding>
        <year>2012</year>
        <source>rsta.royalsocietypublishing.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Initially discussed are some of Alan Turing&#39;s wonderfully profound and influential ideas about mind and mechanismâincluding regarding their connection to the main topic of the present study, which is within the field of computability-theoretic learning theory. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:A4Qc6wulYm8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8026158956535383043&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8026158956535383043&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="232">
        <url>http://arxiv.org/abs/1210.0697</url>
        <title status="complete" source="scholar.google.com">Inside the Muchnik Degrees: Discontinuity, Learnability, and Constructivism</title>
        <pdf>http://arxiv.org/pdf/1210.0697</pdf>
        <author status="complete" source="scholar.google.com">K Higuchi, T Kihara</author>
        <proceeding status="complete" source="scholar.google.com">arXiv preprint arXiv:1210.0697</proceeding>
        <year>2012</year>
        <source>arxiv.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract: It is known that infinitely many Medvedev degrees exist inside the Muchnik degree of any nontrivial\ Pi_1 subset of Cantor space. We shed light on the fine structures inside these Muchnik degrees related to Learning Theory, Constructive Mathematics, and ...</snippet>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9729118854065778010&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="233">
        <url>http://japanlinkcenter.org/JST.JSTAGE/jssst/21.409?from=Google</url>
        <title status="complete" source="scholar.google.com">ç²¾å¯åæ¼ç®å­ãç¨ããå¸°ç´ã¡ã¿è«çãã­ã°ã©ãã³ã°</title>
        <author status="complete" source="scholar.google.com">å±±æ¬ç« å</author>
        <proceeding status="complete" source="scholar.google.com">ã³ã³ãã¥ã¼ã¿ ã½ããã¦ã§ã¢</proceeding>
        <year>2004</year>
        <source>J-STAGE</source>
        <snippet status="partial" source="scholar.google.com">å¸°ç´ã¡ã¿è«çãã­ã°ã©ãã³ã°ã¨ã¯, ã¡ã¿è«çãã­ã°ã©ãã³ã°ãç¨ããå¸°ç´æ¨è«ã®å®å¼åã§ãã. è¨ç·´ä¾ããã¼ã¿ãããããèª¬æããä»®èª¬ãè«çãã­ã°ã©ã ã®å½¢ã§çæããå¸°ç´æ¨è«ã¯å¸°ç´è«çãã­ã°ã©ãã³ã°ã¨ãã°ãã¦ãã. å¸°ç´ã¡ã¿è«çãã­ã°ã©ãã³ã°ã§ã¯, ãã®ä»®èª¬ã®çææä½ãè«çã§ ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:P7B3fmi9-1IJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5979581186760486975&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5979581186760486975&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="234">
        <url>http://japanlinkcenter.org/JST.JSTAGE/jssst/23.2_29?from=Google</url>
        <title status="complete" source="scholar.google.com">å¸°ç´è«çãã­ã°ã©ãã³ã°ã®åºç¤çè«ã¨ãã®å±é</title>
        <author status="complete" source="scholar.google.com">å±±æ¬ç« å</author>
        <proceeding status="complete" source="scholar.google.com">ã³ã³ãã¥ã¼ã¿ ã½ããã¦ã§ã¢</proceeding>
        <year>2006</year>
        <source>J-STAGE</source>
        <snippet status="partial" source="scholar.google.com">å¸°ç´è«çãã­ã°ã©ãã³ã°ã¨ã¯, è«çãã­ã°ã©ã ãç¨ããæ©æ¢°å­¦ç¿ææ³ã§ãã, æ§é åãã¼ã¿ããã®ãã¼ã¿åæã¨ç¥è­ç²å¾ã¸ã®å¿ç¨ãé²ãããã¦ãã. æ¬ç¨¿ã§ã¯, è¨ç®ã®ç«å ´ããå­¦ç¿ã¨ããè¡çºãæããä¸ã§, ãã©ã¡ã¼ã¿æ¨å®ã¨æ¯è¼ãã¤ã¤, è«çãã­ã°ã©ãã³ã°ã®çè«ã¨è¨ç®è«çå­¦ç¿çè«ãåºç¤ ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RJF9rNFSziYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2796263479139209540&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2796263479139209540&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="235">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6266254</url>
        <title status="complete" source="scholar.google.com">Job Shop Scheduling at Your Fingertips Planning Alternatives Off the Cloud</title>
        <pdf>http://www.cmlab.csie.ntu.edu.tw/~zenic/Download/ICME2012/Workshops/data/4729a193.pdf</pdf>
        <author status="partial" source="scholar.google.com">C Vogler, HR Beick, J Opfermann&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Multimedia and Expo &#8230;</proceeding>
        <year>2012</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract The algorithmic generation of detailed manufacturing plans close to an optimal solution is computationally unfeasible due to the enormous size of the space of potential solutions which makes searching a process of exponential time complexity. Human- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:SGZMAwHEgpIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10557215985139213896&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="236">
        <url>http://www.springerlink.com/index/N525J247J5PU4534.pdf</url>
        <title status="complete" source="scholar.google.com">Introduction to the Philosophy and Mathematics of Algorithmic Learning Theory</title>
        <pdf>http://sites.google.com/site/omundodalogica/livros-de-introducao-a-logica/Logic,Epistemology,andtheUnityofScienceVol.9-Induction,AlgorithmicLearningTheory,andPhilosophy.pdf#page=15</pdf>
        <author status="complete" source="scholar.google.com">V Harizanov, N Goethe, M Friend</author>
        <proceeding status="partial" source="scholar.google.com">Induction, Algorithmic Learning Theory, &#8230;</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Algorithmic learning theory is a mathematically precise, general framework for studying the existence of computational strategies for converging to the truth in empirical questions. As such, algorithmic learning theory has immediate implications for the philosophy of science ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:HtxJBnGArxcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1706724006721870878&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="237">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.2.3033&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">38050 Povo (Trento), Italy Tel.:+ 39 0461 314312 Fax:+ 39 0461 302040 eâ mail: prdoc@ itc. itâ url: http://www. itc. it</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.2.3033&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">A Agostini, P Avesani</author>
        <year>2004</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">This report has been submitted for publication outside of ITC and will probably be copyrighted if accepted for publication. It has been issued as a Technical Report for early dissemination of its contents. In view of the transfert of copy right to the outside publisher, its distribution ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:5F8GB2SVmboJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:5F8GB2SVmboJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13445942419338452964&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="238">
        <url>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/doitr166sz.ps.gz</url>
        <title status="complete" source="scholar.google.com">DOI Technical Report</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/doitr166sz.ps.gz</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, T Zeugmann</author>
        <year>1999</year>
        <source>www-alg.ist.hokudai.ac.jp</source>
        <snippet status="complete" source="scholar.google.com">Abstract Blum and Blum (1975) showed that a class B of suitable recursive approximations to the halting problem K is reliably EX-learnable but left it open whether or not B is in NUM. By showing B to be not in NUM we resolve this old problem.</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ypBkC6zAZg8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:ypBkC6zAZg8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="239">
        <url>http://www.springerlink.com/index/12017035066353VR.pdf</url>
        <title status="complete" source="scholar.google.com">Resource Restricted Computability Theoretic Learning: Illustrative Topics and Problems</title>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Computation and Logic in the Real World</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Computability theoretic learning theory (machine inductive inference) typically involves learning programs for languages or functions from a stream of complete data about them and, importantly, allows mind changes as to conjectured programs. This theory takes into ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MIjRDNBNqiIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2497894499293956144&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="240">
        <url>http://www.springerlink.com/index/H4H25161Q638L4N4.pdf</url>
        <title status="complete" source="scholar.google.com">Learning figures with the Hausdorff metric by fractalsâtowards computable binary classification</title>
        <pdf>http://mahito.info/Files/Sugiyama_MLJ01.pdf</pdf>
        <author status="complete" source="scholar.google.com">M Sugiyama, E Hirowatari, H Tsuiki, A Yamamoto</author>
        <proceeding status="complete" source="scholar.google.com">Machine Learning</proceeding>
        <year>2012</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract We present learning of figures, nonempty compact sets in Euclidean space, based on Gold&#39;s learning model aiming at a computable foundation for binary classification of multivariate data. Encoding real vectors with no numerical error requires infinite ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FAyQDaL5NyQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2609828983492054036&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="241">
        <url>http://hypercomputation.org/download/2001a_kugel.pdf</url>
        <title status="complete" source="scholar.google.com">Can Computers Be Genuinely Intelligent?</title>
        <pdf>http://hypercomputation.org/download/2001a_kugel.pdf</pdf>
        <author status="complete" source="scholar.google.com">P Kugel</author>
        <proceeding status="complete" source="scholar.google.com">hypercomputation.org</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract The conventional wisdom has it that Turing (1950) argued that computing machines can become genuinely intelligent. I don&#39;t believe it. I think that what he really tried to say was that computing machines Å computers limited to computing Å can only fake intelligence. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:VNiIECKJQYYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:VNiIECKJQYYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9674164253967833172&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="242">
        <url>http://www.cis.udel.edu/~case/papers/lncs_paper.ps</url>
        <title status="complete" source="scholar.google.com">Ð§Ð² Ð¤ Ð¶Ð² Ð² Ð¬Ð³ Ð³Ð³Ð¶ Ð² Ð¸</title>
        <pdf>http://www.cis.udel.edu/~case/papers/lncs_paper.ps</pdf>
        <author status="complete" source="scholar.google.com">C Isomorphisms</author>
        <proceeding status="complete" source="scholar.google.com">cis.udel.edu</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. A mere bounded number of random bits judiciously employed by a probabilistically correct algorithmic coordinator is shown to increase the power of learning to coordinate compared to deterministic algorithmic coordinators. Furthermore, these probabilistic ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:H2iyE0DjcmQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:H2iyE0DjcmQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7238097415485679647&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="243">
        <title status="complete" source="scholar.google.com">LEARNING MODELS FOR LANGUAGE ACQUISITION</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:TVkuFRYuE3MJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="244">
        <url>http://www.comp.nus.edu.sg/~fstephan/conservative.ps</url>
        <title status="complete" source="scholar.google.com">On Conservative Learning of Re Languages</title>
        <pdf>http://www.comp.nus.edu.sg/~fstephan/conservative.ps</pdf>
        <author status="complete" source="scholar.google.com">Z Gao, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">comp.nus.edu.sg</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract Partially conservative learning is a variant of partial learning whereby the learner, on a text for a target language L, outputs one index e with L= We infinitely often and every further hypothesis d is output only finitely often and satisfies Lâ Wd. The present paper ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GhE8Fjp-QkoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:GhE8Fjp-QkoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="245">
        <url>http://www.kul.pl/files/137/public/Kawalec_Automated_Science.doc</url>
        <title status="complete" source="scholar.google.com">PaweÅ Kawalec</title>
        <pdf>http://www.kul.pl/files/137/public/Kawalec_Automated_Science.doc</pdf>
        <author status="complete" source="scholar.google.com">W Filozofii, J PawÅa II</author>
        <proceeding status="complete" source="scholar.google.com">kul.pl</proceeding>
        <snippet status="partial" source="scholar.google.com">Any serious attempt to give an account of the cognitive aspect of scienceâas contrasted with eg its economic, social or cultural aspectsâcannot ignore the automation revolution. In the conception presented in this paper the results of computer science are taken seriously ...</snippet>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:jcJyFgAYsEwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="246">
        <url>http://my.ilstu.edu/~sfcroke/files/Croker_Symbols_Without_Rules.pdf</url>
        <title status="complete" source="scholar.google.com">Symbols Without Rules</title>
        <pdf>http://my.ilstu.edu/~sfcroke/files/Croker_Symbols_Without_Rules.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Croker</author>
        <proceeding status="partial" source="scholar.google.com">The mind, the body, and the world: psychology after &#8230;</proceeding>
        <year>2007</year>
        <source>my.ilstu.edu</source>
        <snippet status="partial" source="scholar.google.com">There has been much debate over the ability of computational models to explain various aspects of cognition. Such discussions have tended to focus on connectionist or subsymbolic models. Symbolic models, typically characterised as production systems with ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:bwD6GQrXBuAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:bwD6GQrXBuAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16142826352741580911&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="247">
        <url>https://dl.comp.nus.edu.sg/dspace/handle/1900.100/1510</url>
        <title status="complete" source="scholar.google.com">U-shaped leaning may be necessary</title>
        <pdf>https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1510/1/upload.pdf</pdf>
        <author status="complete" source="scholar.google.com">C Lorenzo, C John, J Sanjay, S Frank</author>
        <year>2004</year>
        <source>dl.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract: U-shaped learning behaviour in cognitive development involves learning, unlearning and relearning. It occurs, for example, in learning irregular verbs. The prior cognitive science literature is occupied with how humans do it, for example, general rules ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:aN5UGzEe8gMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=284322922738540136&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="248">
        <url>http://dissertations.ub.rug.nl/FILES/faculties/arts/2011/c.coltekin/completethesisColteginC..pdf</url>
        <title status="complete" source="scholar.google.com">Catching Words in a Stream of Speech</title>
        <pdf>http://dissertations.ub.rug.nl/FILES/faculties/arts/2011/c.coltekin/completethesisColteginC..pdf</pdf>
        <author status="complete" source="scholar.google.com">STCD Speech, Ã ÃÃ¶ltekin</author>
        <proceeding status="complete" source="scholar.google.com">dissertations.ub.rug.nl</proceeding>
        <snippet status="partial" source="scholar.google.com">I started my PhD project with a more ambitious goal than what might have been achieved in this dissertation. I wanted to touch most issues of language acquisition, developing computational models for a wider range of phenomena. In particular, I wanted to focus on ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:5JmrHh1OKREJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:5JmrHh1OKREJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1236605459665492452&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="249">
        <url>http://kryten.mm.rpi.edu/Univ_of_Turku_Hypercomputation_AI.pdf</url>
        <title status="complete" source="scholar.google.com">Computational Socialism vs. Free-Market Capitalism</title>
        <pdf>http://kryten.mm.rpi.edu/Univ_of_Turku_Hypercomputation_AI.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Bringsjord, JJIN Sunder</author>
        <year>2011</year>
        <source>kryten.mm.rpi.edu</source>
        <snippet status="partial" source="scholar.google.com">Abstract When imagining alternative futures for the ï¬eld of economics, it&#39;s standard to ignore even the most sophisticated forms of socialism; eg, even modern computational socialist economic calculation (MCSEC), as propounded by Cockshott et al. For example, in his ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:OHFFHx-THwYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="250">
        <url>http://ml-submission07.googlecode.com/svn-history/r14/trunk/ml-conserve.pdf</url>
        <title status="complete" source="scholar.google.com">Discovery of Conservation Laws and Hidden Particles in Particle Physics</title>
        <pdf>http://ml-submission07.googlecode.com/svn-history/r14/trunk/ml-conserve.pdf</pdf>
        <author status="complete" source="scholar.google.com">O Schulte</author>
        <year>2007</year>
        <source>ml-submission07.googlecode.com</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper describes algorithms for two learning tasks in particle physics: From given observations of reactions among elementary particles,(1) find conservation laws that correctly classify particle reactions as âpossibleâ orâ impossibleâ, and (2) infer the presence ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:nkt1Ibzhf64J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:nkt1Ibzhf64J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12574016882773150622&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="251">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6040879</url>
        <title status="complete" source="scholar.google.com">The MovieOracle-Content Based Movie Recommendations</title>
        <author status="complete" source="scholar.google.com">J Nessel, B Cimpa</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; and Intelligent Agent Technology (WI-IAT), &#8230;</proceeding>
        <year>2011</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract&quot; What movies do you like?&quot; Everyone has had to answer this question at least once. And the answer is often given by means of examples:&quot; I like Star Wars.&quot; Often an examples explains a lot more than trying to characterize movies by other means, like giving a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:UcuYId4MiEsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5442614297863179089&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5442614297863179089&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="252">
        <title status="complete" source="scholar.google.com">Noise, Efficiency, and Stability in Modeling Language Acquisition</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:leo7JuxbH_MJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17518822145306389141&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="253">
        <url>http://www.linguistics.ucla.edu/people/Stabler/212-08.pdf</url>
        <title status="complete" source="scholar.google.com">Language Learning</title>
        <pdf>http://www.linguistics.ucla.edu/people/Stabler/212-08.pdf</pdf>
        <author status="complete" source="scholar.google.com">EP Stabler</author>
        <proceeding status="complete" source="scholar.google.com">linguistics.ucla.edu</proceeding>
        <snippet status="partial" source="scholar.google.com">Questions like these generate heated disputes, but they are typically posed in these vague terms that obscure the real issues. We will introduce some ways of thinking about learning that will allow much clearer and more interesting questions to be formulated and (some of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:-6qbJ9zrAKEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:-6qbJ9zrAKEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11601531970896243451&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="254">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000003001491</url>
        <title status="complete" source="scholar.google.com">Trees and learning</title>
        <author status="complete" source="scholar.google.com">W Merkle, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We characterize FIN-, EX-and BC-learning, as well as the corresponding notions of team learning, in terms of isolated branches on effectively given sequences of trees. The more restrictive models of FIN-learning and strong-monotonic BC-learning are characterized in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:hQkNKCpTD28J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8002706503386335621&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="255">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.134.9282&amp;rep=rep1&amp;type=pdf#page=23</url>
        <title status="complete" source="scholar.google.com">Allocation of computational resource in economic search</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.134.9282&amp;rep=rep1&amp;type=pdf#page=23</pdf>
        <author status="complete" source="scholar.google.com">RF BONNER, V GALANT</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; on Mathematical and Statistical Applications in &#8230;</proceeding>
        <year>2001</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">It is hard to dispute that a poorly informed decision is unlikely to be as good as a well-informed one. A process of improving the information base for a decision, in so far it consumes non-negligible economic resources, is called economic search. The cost of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1XJsKK24kT0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:1XJsKK24kT0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4436530161783698133&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="256">
        <url>http://www.springerlink.com/index/D2798548132P7V20.pdf</url>
        <title status="complete" source="scholar.google.com">Automatic functions, linear time and learning</title>
        <pdf>https://www.iscs.nus.edu.sg/~fstephan/autolintime.ps</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, S Seah, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">How the World Computes</proceeding>
        <year>2012</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The present work determines the exact nature of linear time computable notions which characterise automatic functions (those whose graphs are recognised by a finite automaton). The paper also determines which type of linear time notions permit full learnability for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1rUoLH2c-KAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11599192901718422998&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="257">
        <url>http://ml-submission07.googlecode.com/svn-history/r43/trunk/ml-conserve.pdf</url>
        <title status="complete" source="scholar.google.com">Machine Discovery of Conserved Quantities and Hidden Particles in Particle Physics</title>
        <pdf>http://ml-submission07.googlecode.com/svn-history/r43/trunk/ml-conserve.pdf</pdf>
        <author status="complete" source="scholar.google.com">O Schulte</author>
        <year>2008</year>
        <source>ml-submission07.googlecode.com</source>
        <snippet status="partial" source="scholar.google.com">Abstract An important problem for scientific discovery in several domains is constructing a model of physical or chemical reactions. We introduce a new principle for learning reaction models: models should be maximally strict, ie, they should rule out as many unobserved ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:9FaULA3ZnyIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:9FaULA3ZnyIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2494951369192265460&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="258">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.112.4849&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Belief-desire coherence</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.112.4849&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Petersen</author>
        <year>2003</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Tradition compels me to write dissertation acknowledgements that are long, effusive, and unprofessional. Fortunately for me, I heartily endorse that tradition. First, of course, I want to thank my chair, Eric Lormand. If our marathon advising meetings (of up to six hours) hadn&#39;t ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:HfxFLwN1pR8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:HfxFLwN1pR8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2280357442871491613&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="259">
        <url>ftp://193.170.37.138/pub/techreports/2002/02-60.pdf.gz#page=172</url>
        <title status="complete" source="scholar.google.com">Two Paradigms of Learning</title>
        <pdf>ftp://193.170.37.138/pub/techreports/2002/02-60.pdf.gz#page=172</pdf>
        <author status="complete" source="scholar.google.com">W Menzel, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">Symposium in Honor of Bruno Buchberger&#39;s &#8230;</proceeding>
        <year>2002</year>
        <source>193.170.37.138</source>
        <snippet status="partial" source="scholar.google.com">Abstract Two approaches to model learning phenomena are related to each other, the statistical and the inductive one. A central point where they differ is the used notion of convergence. We investigate whether and to which extent, in the world of computable ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MFMiNuQanhMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:MFMiNuQanhMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1413596900503999280&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="260">
        <url>http://www.springerlink.com/index/3122181185068285.pdf</url>
        <title status="complete" source="scholar.google.com">Invariance properties of quantifiers and multiagent information exchange</title>
        <pdf>http://www.jakubszymanik.com/papers/muddy.pdf</pdf>
        <author status="complete" source="scholar.google.com">N Gierasimczuk, J Szymanik</author>
        <proceeding status="complete" source="scholar.google.com">The Mathematics of Language</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The paper presents two case studies of multi-agent information exchange involving generalized quantifiers. We focus on scenarios in which agents successfully converge to knowledge on the basis of the information about the knowledge of others, so-called ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:L8tqOwBgj0AJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4652042494210132783&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4652042494210132783&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="261">
        <url>http://www.psy.cmu.edu/~rakison/macwhinney.doc</url>
        <title status="complete" source="scholar.google.com">The Poverty of the Linguistic Input</title>
        <pdf>http://www.psy.cmu.edu/~rakison/macwhinney.doc</pdf>
        <author status="complete" source="scholar.google.com">B MacWhinney</author>
        <proceeding status="complete" source="scholar.google.com">psy.cmu.edu</proceeding>
        <snippet status="partial" source="scholar.google.com">Chomsky (1980) argued that the child&#39;s acquisition of grammar is &#39;hopelessly underdetermined by the fragmentary evidence available.&#39;He attributed this indeterminacy to two major sources. The first is the degenerate nature of the input. According to Chomsky, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:rV7rOzXmG74J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:rV7rOzXmG74J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="262">
        <url>http://dspace.ou.nl/handle/1820/66</url>
        <title status="complete" source="scholar.google.com">Learning Networks: a first elaboration</title>
        <pdf>http://dspace.ou.nl/bitstream/1820/66/2/framework-TDprogramme-internalUse.pdf</pdf>
        <author status="complete" source="scholar.google.com">R Koper, P Sloep</author>
        <year>2002</year>
        <source>dspace.ou.nl</source>
        <snippet status="complete" source="scholar.google.com">The document contains the initial theoretical framework for learning networks. It has been elaborated in several follow-up publications. It presents an overview of theory, general use-case and graph representation of a learning network.</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RjeBPFPap8QJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14170534803576796998&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="263">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.3.7987&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Advanced elementary formal systems</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.3.7987&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S en Langea, G Grieserb, KP Jantkec</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract An elementary formal system (EFS) is a logic program such as a Prolog program, for instance, that directly manipulates strings. Arikawa and his co-workers proposed elementary formal systems as a unifying framework for formal language learning. In the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:sdrUPLR1-4IJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:sdrUPLR1-4IJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9438266861060151985&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="264">
        <url>http://www.math.uni-hamburg.de/home/loewe/Publ/BookFotFSV.pdf#page=231</url>
        <title status="complete" source="scholar.google.com">Simplicity, Truth, and the Unending Game of Science</title>
        <pdf>http://www.math.uni-hamburg.de/home/loewe/Publ/BookFotFSV.pdf#page=231</pdf>
        <author status="partial" source="scholar.google.com">S Bold, B LÃ¶we, T RÃ¤sch&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">ALESSANDRO &#8230;</proceeding>
        <year>2007</year>
        <source>math.uni-hamburg.de</source>
        <snippet status="partial" source="scholar.google.com">Department of Philosophy Carnegie Mellon University Baker Hall 135 Pittsburgh, PA 15213-3890, USA kk3n@ andrew. cmu. edu abstract. This paper presents a new explanation of how preferring the simplest theory compatible with experience assists one in finding the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:k2FvPa-EZhsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:k2FvPa-EZhsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1974411374833394067&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="265">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540111001088</url>
        <title status="complete" source="scholar.google.com">Optimal language learning from positive data</title>
        <author status="complete" source="scholar.google.com">J Case, SE Moelius</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2011</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">GoldÊ¼s original paper on inductive inference introduced a notion of an optimal learner. Intuitively, a learner identifies a class of objects optimally iff there is no other learner that: requires as little of each presentation of each object in the class in order to identify that ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Lka8Q86r5ysJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3163686165639087662&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="266">
        <title status="complete" source="scholar.google.com">U-shaped learning may be necessary 3</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:9zFARK7e_V8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="267">
        <url>http://www.cs.rpi.edu/~govinn/econ_hypernet.pdf</url>
        <title status="complete" source="scholar.google.com">Might the Rigorous Modeling of Economic Phenomena Require Hypercomputation?</title>
        <pdf>http://www.cs.rpi.edu/~govinn/econ_hypernet.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Bringsjord, E Eberbach, Y Yang</author>
        <year>2010</year>
        <source>cs.rpi.edu</source>
        <snippet status="partial" source="scholar.google.com">Mathematical logic was born from the rigorous formalization and study of mathematics using computation and formal logic, and includes such seminal results as GÃ¶del&#39;s incompleteness theorems and Turing&#39;s halting-problem result, proved at the dawn of computer science. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ckvURPWxwhgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:ckvURPWxwhgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="268">
        <url>http://dare.uva.nl/en/record/308774</url>
        <title status="complete" source="scholar.google.com">Games for Learning-A Sabotage Approach</title>
        <pdf>http://dare.uva.nl/document/138289</pdf>
        <author status="complete" source="scholar.google.com">N Gierasimczuk, L Kurzen, FR Velazquez-Quesada</author>
        <year>2009</year>
        <source>dare.uva.nl</source>
        <snippet status="partial" source="scholar.google.com">Abstract In formal approaches to inductive learning, the ability to learn is understood as the ability to single out a correct hypothesis from a range of possibilities. Although most of the existing research focuses on the characteristics of the learner, in many paradigms the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:tjZgR-rMYp0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>15</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11340852118264231606&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="269">
        <url>http://www.eecis.udel.edu/~case/siena/batch3.pdf</url>
        <title status="complete" source="scholar.google.com">Batch 3, the Final Batch of Final HW Problems</title>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">eecis.udel.edu</proceeding>
        <snippet status="complete" source="scholar.google.com">Hint: Suppose the hypothesis awb F. Showing L is re is easy. Employ some result say which one from class to obtain a modified F which is b-ary order independent2 and, then, apply the Fundamental Lemma3 to L to show L is also re</snippet>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:_a1oSt_zJgIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="270">
        <url>http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTR/tcstr_08_34/tcstr_08_34.pdf</url>
        <title status="complete" source="scholar.google.com">TCS Technical Report</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTR/tcstr_08_34/tcstr_08_34.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Legg, J Poland, T Zeugmann</author>
        <year>2008</year>
        <source>www-alg.ist.hokudai.ac.jp</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper provides a short discussion concerning the state of the art in Bayesian learning theory with an emphasis on performance guarantees. In the second part of the paper, we outline some negative results indicating that there is no hope for a general ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:o3oLTWgxShMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:o3oLTWgxShMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1389977759036177059&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="271">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.5172&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">On the power of incremental learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.5172&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S en Langea, G Grieserb</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract This paper provides a systematic study of incremental learning from noise-free and from noisy data. As usual, we distinguish between learning from positive data and learning from positive and negative data, synonymously called learning from text and learning from ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:xOBQUupPq0AJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:xOBQUupPq0AJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4659906107266883780&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="272">
        <url>http://www.springerlink.com/index/8hkxd64aqlcbl09v.pdf</url>
        <title status="complete" source="scholar.google.com">Generality&#39;s Price</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.7086&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, KJ Chen, S Jain, W Merkle, J Royer</author>
        <proceeding status="partial" source="scholar.google.com">Learning Theory and Kernel &#8230;</proceeding>
        <year>2003</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper investigates some delicate tradeoffs between the generality of an algorithmic learning device and the quality of the programs it learns successfully. There are results to the effect that, thanks to small increases in generality of a learning device, the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:8r24VLwPns4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14888354719683100146&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="273">
        <title status="partial" source="scholar.google.com">Deutsches Forschungszentrum f ur K unstliche Intelligenz, Stuhlsatzenhausweg 3, 66123 Saarbr ucken, Germany, Email: lange@ dfki. de b Technische &#8230;</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:3xgNVk77AAMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="274">
        <title status="complete" source="scholar.google.com">The panels: proceedings from the panels of the fortieth annual meeting of the Chicago Linguistic Society</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:5t7MWM4MEqYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="275">
        <url>http://www.springerlink.com/index/X2874731U074220J.pdf</url>
        <title status="complete" source="scholar.google.com">Computable scientists, uncomputable world</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.165.9096&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Costa</author>
        <proceeding status="complete" source="scholar.google.com">Unconventional Computation</proceeding>
        <year>2010</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Consider the classical model of a Turing machine with an oracle. The classical oracle is a one step external consultation device. The oracle may contain either non-computable information, or computable information provided just to speed up the computations of the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:IjkwWzx2nzQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3791879412869249314&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="276">
        <url>http://arxiv.org/abs/cs/0502074</url>
        <title status="complete" source="scholar.google.com">On sample complexity for computational pattern recognition</title>
        <pdf>http://arxiv.org/pdf/cs/0502074</pdf>
        <author status="complete" source="scholar.google.com">D Ryabko</author>
        <proceeding status="complete" source="scholar.google.com">arXiv preprint cs/0502074</proceeding>
        <year>2005</year>
        <source>arxiv.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract: In statistical setting of the pattern recognition problem the number of examples required to approximate an unknown labelling function is linear in the VC dimension of the target learning class. In this work we consider the question whether such bounds exist if ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:-fwSXIOmTWIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7083500872039333113&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="277">
        <title status="complete" source="scholar.google.com">LinkÃ¶ping Electronic Articles in Computer and Information Science Vol.(2000): nr</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:EC3GXGyW_u4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="278">
        <url>http://people.umass.edu/kmyu/output/yu-uclawpl-2011.pdf</url>
        <title status="complete" source="scholar.google.com">Representational Maps from the Speech Signal to Phonological Categories: a Case Study with Lexical Tones</title>
        <pdf>http://people.umass.edu/kmyu/output/yu-uclawpl-2011.pdf</pdf>
        <author status="complete" source="scholar.google.com">MY Kristine</author>
        <proceeding status="complete" source="scholar.google.com">people.umass.edu</proceeding>
        <snippet status="partial" source="scholar.google.com">As the initial step in studying the acquisition of phonological categories from the speech signal, we describe representational issues for the target of learning, a probabilistic distribution of phonological categories over a phonetic parameter space. Our model ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:h4UCXZ7LNjMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:h4UCXZ7LNjMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3690360825702417799&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="279">
        <title status="complete" source="scholar.google.com">Knowledge as Reliably Inferred Stable True Belief</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ftFXXW2IKSIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="280">
        <url>http://phil-sci07.googlecode.com/svn-history/r7/trunk/phil-sci07.pdf</url>
        <title status="complete" source="scholar.google.com">How Particle Physics Cuts Nature At Its Joints</title>
        <pdf>http://phil-sci07.googlecode.com/svn-history/r7/trunk/phil-sci07.pdf</pdf>
        <author status="complete" source="scholar.google.com">O Schulte</author>
        <year>2008</year>
        <source>phil-sci07.googlecode.com</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper studies the search for new conservation laws in particle physics. This search has posed various challenges concerning the underdetermination of theory by evidence, to which physicists have found various responses. These responses include an ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Q4f7XvxLtsYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:Q4f7XvxLtsYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14318715612568454979&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="281">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000012000876</url>
        <title status="complete" source="scholar.google.com">Learning with ordinal-bounded memory from positive data</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/bemord.pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A bounded example memory learner operates incrementally and maintains a memory of finitely many data items. The paradigm is well-studied and known to coincide with set-driven learning. A hierarchy of stronger and stronger learning criteria had earlier been obtained ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:SO2jYG0s_0kJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5332029332114369864&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="282">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.138.3697&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Perspectives on contexts</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.138.3697&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">P Bouquet, L Serafini, RH Thomason</author>
        <year>2008</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">March 22, 2006 Contents Introduction: Perspectives on Context vii Paolo Bouquet, Luciano Serafini, Richmond Thomason 1 On the dimensions of context dependence 1 Massimo Benerecetti, Paolo Bouquet, Chiara Ghidini 2 What is Local Models Semantics? 19 ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:nhFnYmNU1xUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:nhFnYmNU1xUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1573819380618695070&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="283">
        <url>http://www.comp.nus.edu.sg/~sanjay/paps/robsur-c.pdf</url>
        <title status="complete" source="scholar.google.com">A Survey of Robust Learning</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/robsur-c.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <year>2008</year>
        <source>comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract. A class of objects is said to be robustly learnable if not only this class itself is learnable but all of its computable âtransformationsâ are also learnable. We study robust learning within the framework of inductive inference. A class of recursive functions is said ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:td7IYjEIaMwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:td7IYjEIaMwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14729031589518958261&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="284">
        <url>http://mahito.info/Files/Sugiyama_PhDthesis.pdf</url>
        <title status="complete" source="scholar.google.com">Studies on Computational Learning via Discretization</title>
        <pdf>http://mahito.info/Files/Sugiyama_PhDthesis.pdf</pdf>
        <author status="complete" source="scholar.google.com">M Sugiyama</author>
        <year>2012</year>
        <source>mahito.info</source>
        <snippet status="partial" source="scholar.google.com">Abstract Thisthesispresentscutting-edgestudiesoncomputationallearning. Thekeyissue throughout the thesis is amalgamation of two processes; discretization of continuous objects and learning from such objects provided by data. Machine learning, or data mining and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:QKRXZUBQR78J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:QKRXZUBQR78J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13783073422099063872&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="285">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.113.5874&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Notes on learnability and human languages</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.113.5874&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">E Stabler</author>
        <proceeding status="complete" source="scholar.google.com">Journal of the Association for Computing Machinery</proceeding>
        <year>1999</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">We are interested in how people learn language, and there are lots of things to learn about how children (or second language learners) acquire and use vocabulary and syntactic structures of various kinds. But it can be illuminating to tackle a simpler problem first. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FNK2ZVldD4cJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:FNK2ZVldD4cJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9732099958310883860&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="286">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.187.4822&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">TCS Technical Report</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.187.4822&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">R Freivalds, T Zeugmann</author>
        <year>2010</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract Nonconstructive proofs are a powerful mechanism in mathematics. Furthermore, nonconstructive computations by various types of machines and automata have been considered by eg, Karp and Lipton [15] and Freivalds [10]. They allow to regard more ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:fekPbDTTq9gJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:fekPbDTTq9gJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15612804755314698621&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="287">
        <url>http://cls.metapress.com/index/967480g7x2232005.pdf</url>
        <title status="complete" source="scholar.google.com">What does Gold&#39;s Theorem show about language acquisition?</title>
        <author status="complete" source="scholar.google.com">K Johnson</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings from the Annual Meeting of the Chicago &#8230;</proceeding>
        <year>2004</year>
        <source>Chic Ling Society</source>
        <snippet status="partial" source="scholar.google.com">It is often thought that children lack negative evidence when they acquire their native language and that this fact supports a rationalist view of the mind over an empiricist view. One argument from &#39;No negative evidence&#39;to rationalism centers on the &#39;Logical Problem ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:qVvWcD-ZfvoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="288">
        <url>http://www.abstracta.pro.br/revista/Special%20Issue%20III/SI_3_full.pdf#page=48</url>
        <title status="complete" source="scholar.google.com">RESPONSE TO SHAFER, THAGARD, STREVENS, AND HANSON</title>
        <pdf>http://www.abstracta.pro.br/revista/Special%20Issue%20III/SI_3_full.pdf#page=48</pdf>
        <author status="complete" source="scholar.google.com">G Harman, S Kulkarni</author>
        <proceeding status="complete" source="scholar.google.com">Special Issue III 2009</proceeding>
        <source>abstracta.pro.br</source>
        <snippet status="partial" source="scholar.google.com">Like Glenn Shafer, we are nostalgic for the time when âphilosophers, mathematicians, and scientists interested in probability, induction, and scientific methodology talked with each other more than they do nowâ,[p. 10]. 1 Shafer goes on to mention other relevant ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:BbMAcjFPWmIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:BbMAcjFPWmIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7087064037405537029&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="289">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.20.8500&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">SIIM Technical Report</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.20.8500&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen, T Zeugmann</author>
        <year>2001</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract Learning of recursive functions refutably informally means that for every recursive function, the learning machine has either to learn this function or to refute it, that is to signal that it is not able to learn it. Three modi of making precise the notion of refuting are ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:jT4EcmddjbEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:jT4EcmddjbEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12793984815305342605&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="290">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000009000749</url>
        <title status="complete" source="scholar.google.com">Numberings optimal for learning</title>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2010</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper extends previous studies on learnability in non-acceptable numberings by considering the question: for which criteria which numberings are optimal, that is, for which numberings it holds that one can learn every learnable class using the given numbering ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:41DjdY4aypgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11009641438226108643&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11009641438226108643&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="291">
        <url>http://grammars.grlmc.com/GRLMC/PersonalPages/leo/DissertationLeonorBecerra.pdf</url>
        <title status="complete" source="scholar.google.com">On the Learnability of Mildly Context-Sensitive Languages using Positive Data and Correction Queries</title>
        <pdf>http://grammars.grlmc.com/GRLMC/PersonalPages/leo/DissertationLeonorBecerra.pdf</pdf>
        <author status="complete" source="scholar.google.com">LB BONACHE</author>
        <proceeding status="complete" source="scholar.google.com">grammars.grlmc.com</proceeding>
        <snippet status="partial" source="scholar.google.com">Thanks also to the âMinisterio de EducaciÃ³n y Cienciaâ(MEC) which provided me the financial support to do this work, granting me a FPU (âFormaciÃ³n de Profesorado Universitarioâ, AP2001-1880) pre-doctoral fellowship. Due to this support, I have had the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:0S0wdgQKLw0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:0S0wdgQKLw0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=949989060677479889&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="292">
        <title status="complete" source="scholar.google.com">SPATIAL ANALYSIS OF CHINESE GARDEN DESIGNS WITH MACHINE LEARNING</title>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="293">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397507002277</url>
        <title status="complete" source="scholar.google.com">On the data consumption benefits of accepting increased uncertainty</title>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In the context of learning paradigms of identification in the limit, we address the question: why is uncertainty sometimes desirable? We use mind change bounds on the output hypotheses as a measure of uncertainty and interpret &#39;desirable&#39;as reduction in data ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:YN_1eqwpL5wJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11254259814596206432&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="294">
        <url>http://www.springerlink.com/index/2TFVJ5FR0PY9BTGF.pdf</url>
        <title status="complete" source="scholar.google.com">Costs of general purpose learning</title>
        <pdf>http://pdf.aminer.org/000/620/043/costs_of_general_purpose_learning.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, KJ Chen, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">STACS 99</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Leo Harrington surprisingly constructed a machine which can learn any computable function f according to the following criterion (called Be*-identification). His machine, on the successive graph points of f, outputs a corresponding infinite sequence of programs p 0, p ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:mYn4ergsVsAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13859314074127993241&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="295">
        <url>http://cslipublications.stanford.edu/FG/2005/marciniec.pdf</url>
        <title status="complete" source="scholar.google.com">Learnability of Some Classes of Optimal Categorial Grammars</title>
        <pdf>http://cslipublications.stanford.edu/FG/2005/marciniec.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Marciniec</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of FG-MoL 2005: The 10th &#8230;</proceeding>
        <year>2009</year>
        <source>cslipublications.stanford.edu</source>
        <snippet status="partial" source="scholar.google.com">Abstract In this paper we characterize a learnable class of classical categorial grammars, which lies inbetween (learnable) class of rigid grammars and (not learnable) class of optimal grammars. The learning function we provide is based on guided optimal unification, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1VECfUtE7QMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:1VECfUtE7QMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=282957442604749269&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="296">
        <url>http://hal-ujm.ccsd.cnrs.fr/hal-00168677/</url>
        <title status="complete" source="scholar.google.com">Learning Balls of Strings: A Horizontal Analysis</title>
        <pdf>http://hal-ujm.ccsd.cnrs.fr/docs/00/16/86/77/PDF/hjt07.pdf</pdf>
        <author status="complete" source="scholar.google.com">C De La Higuera, JC Janodet, F Tantini</author>
        <year>2007</year>
        <source>hal-ujm.ccsd.cnrs.fr</source>
        <snippet status="partial" source="scholar.google.com">Abstract. There are a number of established paradigms to study the learnability of classes of functions or languages: Query learning, Identification in the limit, Probably Approximately Correct learning. Comparison between these paradigms is hard. Moreover, when to the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:sixyft_WvRgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1782817282896047282&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="297">
        <url>http://cs.swan.ac.uk/reports/yr2006/CSR7-2006.pdf#page=151</url>
        <title status="complete" source="scholar.google.com">Finite Prediction of Recursive Real-Valued Functions</title>
        <pdf>http://cs.swan.ac.uk/reports/yr2006/CSR7-2006.pdf#page=151</pdf>
        <author status="complete" source="scholar.google.com">E Hirowatari, K Hirata, T Miyahara</author>
        <proceeding status="complete" source="scholar.google.com">12345efghi</proceeding>
        <source>cs.swan.ac.uk</source>
        <snippet status="partial" source="scholar.google.com">Abstract. This paper concerns learning theory of recursive real-valued functions that are one of the formulations for the computable real function. Hirowatari et al.(2005) have introduced the finite prediction of recursive real-valued functions, which is based on a finite prediction ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:mrbQfjOvUPEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:mrbQfjOvUPEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17388590796983285402&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="298">
        <url>http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTRB/tcstr_08_4/tcstr_08_4.pdf</url>
        <title status="complete" source="scholar.google.com">TCS Technical Report</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTRB/tcstr_08_4/tcstr_08_4.pdf</pdf>
        <author status="complete" source="scholar.google.com">T Zeugmann, S Zilles</author>
        <year>2007</year>
        <source>www-alg.ist.hokudai.ac.jp</source>
        <snippet status="partial" source="scholar.google.com">AESYAISLAGFAKEGJWAEHGJLSFLLZSFC... epuv ep his le tures m inly l rifies the su je t of cryptologyF qener lly spe kingD ryptology is out communication in the presence of adversariesF gryptology ne diveded into two m jor p rtsD iFeFD cryptography nd ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:N39igYssHS0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:N39igYssHS0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3250803483714158391&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="299">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540103002657</url>
        <title status="complete" source="scholar.google.com">Classes with easily learnable subclasses</title>
        <pdf>http://www.math.uni-heidelberg.de/logic/postscripts/tr59.ps</pdf>
        <author status="complete" source="scholar.google.com">S Jain, W Menzel, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In this paper we study the question of whether identifiable classes have subclasses which are identifiable under a more restrictive criterion. The chosen framework is inductive inference, in particular the criterion of explanatory learning (Ex) of recursive functions as ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2l6PgklSSt8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16089763094411042522&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="300">
        <url>http://www.springerlink.com/index/812361171q2264pu.pdf</url>
        <title status="complete" source="scholar.google.com">Resource Restricted Computability Theoretic Learning: Illustrative Topics and Problems</title>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Theory of Computing Systems</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract Computability theoretic learning theory (machine inductive inference) typically involves learning programs for languages or functions from a stream of complete data about them and, importantly, allows mind changes as to conjectured programs. This theory takes ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cNGIg7j_YKkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12205036158119891312&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="301">
        <url>http://www.iip.ist.i.kyoto-u.ac.jp/member/matthew/Sigma2_full_version.pdf</url>
        <title status="complete" source="scholar.google.com">Interpreting Learners as Realizers for Î£0</title>
        <pdf>http://www.iip.ist.i.kyoto-u.ac.jp/member/matthew/Sigma2_full_version.pdf</pdf>
        <author status="complete" source="scholar.google.com">M de Brecht, A Yamamoto</author>
        <proceeding status="complete" source="scholar.google.com">iip.ist.i.kyoto-u.ac.jp</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. We introduce the concept of a Î£0 2-admissible representation, which we then use to interpret some basic Gold-style models of inductive inference within the field of computable analysis. We interpret inductive inference problems as functions between ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:icHOhA4simwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:icHOhA4simwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="302">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397505005220</url>
        <title status="complete" source="scholar.google.com">Inductive inference of approximations for recursive concepts</title>
        <pdf>http://eprints.lib.hokudai.ac.jp/dspace/bitstream/2115/17147/1/TCS348-1.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, G Grieser, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2005</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper provides a systematic study of inductive inference of indexable concept classes in learning scenarios where the learner is successful if its final hypothesis describes a finite variant of the target concept, ie, learning with anomalies. Learning from positive data only ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:f-x_hcXi3wMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=279191039896448127&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="303">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397512004604</url>
        <title status="complete" source="scholar.google.com">On families of categorial grammars of bounded value, their learnability and related complexity questions</title>
        <pdf>https://lirias.kuleuven.be/bitstream/123456789/342848/1/CostaFernauTCS_CR3.pdf</pdf>
        <author status="complete" source="scholar.google.com">C Costa FlorÃªncio, H Fernau</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In Kanazawa (1998)[1], the learnability of several parameterized families of categorial grammar classes was studied. These classes were shown to be learnable in the technical sense of identifiability in the limit from positive data. They are defined in terms of bounds ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ZA2WhrM4Xf0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18256810808138141028&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18256810808138141028&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="304">
        <url>http://www.springerlink.com/index/6LYLFEKMFX7KTYQ4.pdf</url>
        <title status="complete" source="scholar.google.com">On the data consumption benefits of accepting increased uncertainty</title>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2004</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In the context of learning paradigms of identification in the limit, we address the question: why is uncertainty sometimes desirable? We use mind change bounds on the output hypotheses as a measure of uncertainty, and interpret &#39;desirable&#39;as reduction in data ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:vahgiAbccK4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12569788480607004861&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="305">
        <url>http://www.eecis.udel.edu/~case/papers/pr2.pdf</url>
        <title status="complete" source="scholar.google.com">On the Necessity of U-Shaped Learning</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/pr2.pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case</author>
        <proceeding status="complete" source="scholar.google.com">eecis.udel.edu</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. A U-shaped curve in a cognitive-developmental trajectory refers to a three-step process: good performance followed by bad performance followed by good performance once again. U-shaped curves have been observed in a wide variety of cognitive- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17336137048815070431&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="306">
        <url>http://fs1.bib.tiera.ru/content/dvd57/Friend%20M.%20(ed.),%20Harizanov%20V.S.%20(ed.)%20-%20Induction,%20Algorithmic%20Learning%20Theory,%20and%20Philosophy(2007)(304).pdf#page=14</url>
        <title status="complete" source="scholar.google.com">INTRODUCTION TO THE PHILOSOPHY AND MATHEMATICS OF ALGORITHMIC LEARNING THEORY</title>
        <author status="complete" source="scholar.google.com">H Putnam</author>
        <proceeding status="partial" source="scholar.google.com">LOGIC, EPISTEMOLOGY, AND THE UNITY OF &#8230;</proceeding>
        <year>2007</year>
        <source>fs1.bib.tiera.ru</source>
        <snippet status="partial" source="scholar.google.com">Algorithmic learning theory is a mathematically precise, general framework for studying the existence of computational strategies for converging to the truth in empirical questions. As such, algorithmic learning theory has immediate implications for the philosophy of science ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GZZ7jcGSvDUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:GZZ7jcGSvDUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3872131139631814169&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="307">
        <url>http://www.springerlink.com/index/1150U7548UU28L74.pdf</url>
        <title status="complete" source="scholar.google.com">Guest editorial: Learning theory</title>
        <author status="complete" source="scholar.google.com">O Bousquet, A Elisseeff</author>
        <proceeding status="complete" source="scholar.google.com">Machine Learning</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The theoretical study of the learning ability of machines was initiated in the sixties with the works of Gold, Solomonoff, Vapnik and Chervonenkis among a few others. In almost half a century, this discipline has developed into various directions and several sub-areas have ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:VfZUjgI-kKQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11858045999565305429&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="308">
        <url>http://www.fitelson.org/few/few_07/kelly.pdf</url>
        <title status="complete" source="scholar.google.com">Simplicity and Truth Conduciveness</title>
        <pdf>http://www.fitelson.org/few/few_07/kelly.pdf</pdf>
        <author status="complete" source="scholar.google.com">KT Kelly</author>
        <proceeding status="complete" source="scholar.google.com">fitelson.org</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract There is a long-standing puzzle concerning the connection of simplicity to truth in scientific inference. It is proposed that simplicity does not point at or indicate the truth but nonetheless keeps science on the straightest or most direct route thereto. A theorem to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:wczwjmFcaKIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:wczwjmFcaKIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11702705205801962689&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="309">
        <url>http://kalngyk.zymichost.com/pub/alt2005j.pdf</url>
        <title status="complete" source="scholar.google.com">Inferring Unions of Pattern Languages By Most Fitting Covers From Positive Examples</title>
        <pdf>http://kalngyk.zymichost.com/pub/alt2005j.pdf</pdf>
        <author status="complete" source="scholar.google.com">YK Nga, T Shinohara</author>
        <proceeding status="complete" source="scholar.google.com">kalngyk.zymichost.com</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract We are interested in the inductive inference of classes of unions, of the pattern languages and their subclasses, from positive examples using strategies that guarantee some form of minimality in the intermediate hypotheses. It is known that a strategy based ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Ow6NkCWum3IJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:Ow6NkCWum3IJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="310">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.98.2477&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Inductive inference of approximations for recursive</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.98.2477&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Langea, G Grieserb, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper provides a systematic study of inductive inference of indexable concept classes in learning scenarios where the learner is successful if its final hypothesis describes a finite variant of the target concept, ie, learning with anomalies. Learning from positive ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MWKAkpxb010J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="311">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=Eu6dg98YC4sC&amp;oi=fnd&amp;pg=PA175&amp;ots=D_NAMniaER&amp;sig=BMcbsaj7B2JgzmYxf6eSR3CB7wY</url>
        <title status="complete" source="scholar.google.com">Coordination through Inductive Meaning Negotiation</title>
        <pdf>https://www.haiti.cs.uni-potsdam.de/proceedings/ECAI-06/Proceedings/ecai/papers/ECAI06_037.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Agostini, I Trento</author>
        <proceeding status="partial" source="scholar.google.com">FRONTIERS IN ARTIFICIAL &#8230;</proceeding>
        <year>2006</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">Abstract. This paper is on negotiation, precisely on the negotiation of meaning. We advance and discuss a formal paradigm of coordination and variants thereof, wherein meaning negotiation plays a major role in the process of convergence to a common agreement. Our ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:J-x4lSP5ye4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17206557782572592167&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="312">
        <title status="complete" source="scholar.google.com">Inductive inference: theories and techniques</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:lKSmli8IdK8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="313">
        <url>http://www.springerlink.com/index/fbhv3m16mb69v8lf.pdf</url>
        <title status="complete" source="scholar.google.com">Web Searching and Î£ 2 Queries</title>
        <author status="complete" source="scholar.google.com">A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Advanced Web Technologies and Applications</proceeding>
        <year>2004</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In the terminology of Logic programming, current search engines answer Î£ 1 queries (formulas of the form `(x)j(`(x))âxÏ(x)wherej(`(x))Ï(x)isabooleancombinationofattributes).Suchaqueryisdeterminedbyaparticularsequ....Inordertogivemorecontroltousers,searchengineswillhavetotacklemoreexpress...,namely, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:QZnCl2GV0u8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17281038966564493633&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="314">
        <url>http://faculty.sacredheart.edu/kinbere/jkw_JCSS.ps</url>
        <title status="complete" source="scholar.google.com">Language Learning from Texts: Degrees of Intrinsic Complexity and Their Characterizations</title>
        <pdf>http://faculty.sacredheart.edu/kinbere/jkw_JCSS.ps</pdf>
        <author status="complete" source="scholar.google.com">R Wiehagen</author>
        <year>2001</year>
        <source>faculty.sacredheart.edu</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper deals with two problems: 1) what makes languages to be learnable in the limit by natural strategies of varying hardness; 2) what makes classes of languages to be the hardest ones to learn. To quantify hardness of learning, we use intrinsic complexity ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:r6APmnQoog8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:r6APmnQoog8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1126507338062078127&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="315">
        <url>http://arxiv.org/abs/1208.5003</url>
        <title status="complete" source="scholar.google.com">Identification of Probabilities of Languages</title>
        <pdf>http://arxiv.org/pdf/1208.5003</pdf>
        <author status="complete" source="scholar.google.com">P Vitanyi, N Chater</author>
        <proceeding status="complete" source="scholar.google.com">arXiv preprint arXiv:1208.5003</proceeding>
        <year>2012</year>
        <source>arxiv.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract: We consider the problem of inferring the probability distribution associated with a language, given data consisting of an infinite sequence of elements of the languge. We do this under two assumptions on the algorithms concerned:(i) like a real-life algorothm it has ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:0Z6qmk2OeRoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1907712381126614737&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="316">
        <url>http://ml-submission07.googlecode.com/svn/branches/compcomm1-16.pdf</url>
        <title status="complete" source="scholar.google.com">Automated Discovery of Phenomenological Conservation Laws and Particle Families</title>
        <pdf>http://ml-submission07.googlecode.com/svn/branches/compcomm1-16.pdf</pdf>
        <author status="complete" source="scholar.google.com">O Schulte, MS Drew</author>
        <proceeding status="complete" source="scholar.google.com">ml-submission07.googlecode.com</proceeding>
        <snippet status="partial" source="scholar.google.com">One of the important problems of particle physics is to find a theory that pre- dicts which interactions among elementary particles are possible and which are not. Selection rules in the form of conservation laws, governing which processes are permitted and which are forbidden, have turned out ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:uc2Xm40OWIEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:uc2Xm40OWIEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9320215430206836153&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="317">
        <url>http://scholarbank.nus.edu/handle/10635/34660</url>
        <title status="complete" source="scholar.google.com">Variants of Partial Learning in Inductive Inference</title>
        <pdf>http://scholarbank.nus.edu/bitstream/handle/10635/34660/test.pdf?sequence=1</pdf>
        <author status="complete" source="scholar.google.com">GAO ZIYUAN</author>
        <year>2012</year>
        <source>scholarbank.nus.edu</source>
        <snippet status="partial" source="scholar.google.com">This thesis studies several variants of partial learning under the framework of inductive inference. In particular, the following learning criteria are examined: con fident partial learning, partially conservative learning, essentially class consistent partial learning, and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:82yGne6LC9AJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14991229641594137843&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="318">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397512009310</url>
        <title status="complete" source="scholar.google.com">Memory-limited non-U-shaped learning with solved open problems</title>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Herein we also distinguish between semantic and syntactic U-shapes. We answer a number of open questions in the prior literature as well as provide new results regarding syntactic U-shapes. Importantly for cognitive science, we see more of a previously noticed pattern ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="319">
        <url>http://japanlinkcenter.org/JST.JSTAGE/imt/1.33?from=Google</url>
        <title status="complete" source="scholar.google.com">Refutability and Reliability for Inductive Inference of Recursive Real-Valued Functions</title>
        <author status="partial" source="scholar.google.com">E Hirowatari, K Hirata, T Miyahara&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Information and Media &#8230;</proceeding>
        <year>2006</year>
        <source>J-STAGE</source>
        <snippet status="partial" source="scholar.google.com">Inductive inference gives us a theoretical model of concept learning from examples. In this paper, we study refutably and reliably inductive inference of recursive real-valued functions. First we introduce the new criteria RealRefEx for refutable inference and RealRelEx for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:hcYinlfmXMUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14221494987318806149&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="320">
        <url>http://phil-sci07.googlecode.com/svn-history/r11/trunk/phil-sci07.pdf</url>
        <title status="complete" source="scholar.google.com">Co-Discovery of Conservation Laws and Particle Families in Particle Physics</title>
        <pdf>http://phil-sci07.googlecode.com/svn-history/r11/trunk/phil-sci07.pdf</pdf>
        <author status="complete" source="scholar.google.com">O Schulte</author>
        <year>2007</year>
        <source>phil-sci07.googlecode.com</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper presents an epistemological analysis of the search for new conservation laws in particle physics. This search has posed various challenges concerning the underdetermination of theory by evidence, to which physicists have found various ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ejgAop3cU0gJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:ejgAop3cU0gJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5211751763383695482&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="321">
        <url>http://www.physics.ox.ac.uk/systems/agarwal/oldweb/games.pdf</url>
        <title status="complete" source="scholar.google.com">Games With Dynamic Payoffs</title>
        <pdf>http://www.physics.ox.ac.uk/systems/agarwal/oldweb/games.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Mittal, S Agarwal</author>
        <year>2005</year>
        <source>physics.ox.ac.uk</source>
        <snippet status="partial" source="scholar.google.com">Abstract In this paper, we present a study on games in which the payoffs are dynamic, that is the payoffs change with time, or are dependent on the strategy profiles of the players. We investigate two such games: a Language acquisition game, and the Spatial prisoner&#39;s ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:H93woiyWvFMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:H93woiyWvFMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6033862719226043679&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="322">
        <url>http://onlinelibrary.wiley.com/doi/10.1111/tops.12001/full</url>
        <title status="complete" source="scholar.google.com">Complexity in language acquisition</title>
        <pdf>http://www.dcs.kcl.ac.uk/staff/lappin/papers/clark-lappin_tics13_proofs.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Clark, S Lappin</author>
        <proceeding status="complete" source="scholar.google.com">Topics in Cognitive Science</proceeding>
        <year>2013</year>
        <source>Wiley Online Library</source>
        <snippet status="partial" source="scholar.google.com">Abstract Learning theory has frequently been applied to language acquisition, but discussion has largely focused on information theoretic problemsâin particular on the absence of direct negative evidence. Such arguments typically neglect the probabilistic ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="323">
        <url>http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTR/tcstr_07_31/tcstr_07_31.pdf</url>
        <title status="complete" source="scholar.google.com">TCS Technical Report</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTR/tcstr_07_31/tcstr_07_31.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, T Zeugmann, S Zilles</author>
        <year>2007</year>
        <source>www-alg.ist.hokudai.ac.jp</source>
        <snippet status="partial" source="scholar.google.com">Abstract In the past 40 years, research on inductive inference has developed along different lines, concerning different formalizations of learning models and in particular of target concepts for learning. One common root of many of these is Gold&#39;s model of identification ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:uMhVpfJ4388J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:uMhVpfJ4388J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14978823869208840376&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="324">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.140.3835&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">TCS Technical Report</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.140.3835&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">Y Akama, T Zeugmann</author>
        <year>2007</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract A consistent learner is required to correctly and completely reflect in its actual hypothesis all data received so far. Though this demand sounds quite plausible, it may lead to the unsolvability of the learning problem. Therefore, in the present paper several ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:d2vXpn3b0ZAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:d2vXpn3b0ZAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10435363144310680439&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="325">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=3_Sp1g_QziwC&amp;oi=fnd&amp;pg=PA54&amp;ots=2Wjq1vOxH8&amp;sig=8McZnwRTx0ZVAZCVymxkwI9eRnU</url>
        <title status="complete" source="scholar.google.com">3 Learnability</title>
        <author status="complete" source="scholar.google.com">J Heinz, J Riggle</author>
        <proceeding status="complete" source="scholar.google.com">The Blackwell Companion to Phonology</proceeding>
        <year>2011</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">How can anything (such as a child or any other computing device) automatically acquire (any aspect of) a phonological grammar on the basis of its experience? This is the fundamental (and unresolved) question of phonological learnability, and it is essentially ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:_VafqOJLtUsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5455349960492930813&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="326">
        <url>http://www.sciencedirect.com/science/article/pii/S0020019008003104</url>
        <title status="complete" source="scholar.google.com">On some open problems in reflective inductive inference</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.150.8614&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Information Processing Letters</proceeding>
        <year>2009</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In this paper we show that there exist classes of functions which can be learnt by a finite learner which reflects on its capability, but not learnable by a consistent learner which optimistically reflects on its capability. This solves the two mentioned open problems from [ ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:StJGq90VtMwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14750438721350718026&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="327">
        <title status="complete" source="scholar.google.com">A Close Shave with Realism: Ockham&#39;s Razor Deduced from Efficient Convergence</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:j4BdrfcXItQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15285806437781831823&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="328">
        <url>http://km.meme.hokudai.ac.jp/people/jantke/Publications/2006/JantkeGrieser-KEV-2006.pdf</url>
        <title status="complete" source="scholar.google.com">Aspects of Knowledge Evolution in Algorithmic Learning</title>
        <pdf>http://km.meme.hokudai.ac.jp/people/jantke/Publications/2006/JantkeGrieser-KEV-2006.pdf</pdf>
        <author status="complete" source="scholar.google.com">KP Jantke, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">km.meme.hokudai.ac.jp</proceeding>
        <snippet status="partial" source="scholar.google.com">ABSTRACT It seems nowadays widely accepted that learning means the acquisiton of knowledge and/or skills, whereby some specialists prefer to relate the development of skills more to training than to learning. However, a closer look reveals severe difficulties of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:t6p8rvM3j4UJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:t6p8rvM3j4UJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9623972448458025655&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="329">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.136.484&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Learning agents need no induction</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.136.484&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">E Datteri, H Hosni, G Tamburrini</author>
        <year>2009</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract It has been suggested that AI investigations of mechanical learning undermine sweeping anti-inductivist views in the theory of knowledge and the philosophy of science. In particular, it is claimed that some mechanical learning systems perform epistemically ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Uf2JsV99RSMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:Uf2JsV99RSMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2541575414674488657&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="330">
        <url>http://eprints.pascal-network.org/archive/00007224/</url>
        <title status="complete" source="scholar.google.com">Grammatical Inference&#39;s Adventures in Machine Learning Land</title>
        <pdf>http://eprints.pascal-network.org/archive/00007224/01/hdrjcj.pdf</pdf>
        <author status="complete" source="scholar.google.com">JC Janodet</author>
        <year>2010</year>
        <source>eprints.pascal-network.org</source>
        <snippet status="complete" source="scholar.google.com">Abstract This manuscript (in french) was written for my habilitation. Using the research results I got during the last decade, I study the differences and convergences between both Machine Leaning and Grammatical Inference, seen as independent research fields.</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:WVvcs0G-4kcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="331">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.138.3697&amp;rep=rep1&amp;type=pdf#page=260</url>
        <title status="complete" source="scholar.google.com">Context and Philosophy of Science</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.138.3697&amp;rep=rep1&amp;type=pdf#page=260</pdf>
        <author status="complete" source="scholar.google.com">RA Young</author>
        <proceeding status="complete" source="scholar.google.com">Perspectives on contexts</proceeding>
        <year>2006</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">This paper aims to define a concept of context of justification close to Reichenbach&#39;s (section 11.1). For him, the context of justification of a theory is the context of its rational discovery. To prepare for a definition of context, we review the relationship between context in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:LxgrtIqXECcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:LxgrtIqXECcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2814916389090564143&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="332">
        <url>http://ijens.org/Vol%2011%20I%2001/111201-8585%20IJET-IJENS.pdf</url>
        <title status="complete" source="scholar.google.com">DETERMINATION OF OPTIMAL CENTERS FOR SCANNING OF REGULAR FIGURES&#39;IMAGES WHEN RECOGNITHIZING THEM</title>
        <pdf>http://ijens.org/Vol%2011%20I%2001/111201-8585%20IJET-IJENS.pdf</pdf>
        <author status="complete" source="scholar.google.com">MM Al-Hiyari</author>
        <year>2005</year>
        <source>ijens.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract There has been proposed method for recognition of images of flat regular figures using their resolution from the internal spot of scanning. new forms of images representation are considered. An algorithm on search of optimal scanning center has been proponed. A ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:XLcVtwIv5DIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:XLcVtwIv5DIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3667107685294520156&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="333">
        <url>http://cocosci.berkeley.edu/annehsu/papers/languagereview.pdf</url>
        <title status="complete" source="scholar.google.com">Language learning from positive evidence, reconsidered: A simplicity-based approach</title>
        <pdf>http://cocosci.berkeley.edu/annehsu/papers/languagereview.pdf</pdf>
        <author status="complete" source="scholar.google.com">AS Hsu, N Chater, P VitÃ¡nyi</author>
        <proceeding status="complete" source="scholar.google.com">cocosci.berkeley.edu</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract Children appear to be able to learn their native language by exposure to their linguistic and communicative environment, but without requiring that their mistakes are corrected. Such learning from âpositive evidenceâ has been viewed as raising âlogicalâ ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FmZStzAfpxUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:FmZStzAfpxUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1560250090001688086&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="334">
        <url>http://www.springerlink.com/index/J0W128K65840063R.pdf</url>
        <title status="complete" source="scholar.google.com">Learning via finitely many queries</title>
        <pdf>http://rutcor.rutgers.edu/~amai/aimath04/AcceptedPapers/Lee-aimath04.pdf</pdf>
        <author status="complete" source="scholar.google.com">AC Lee</author>
        <proceeding status="complete" source="scholar.google.com">Annals of Mathematics and Artificial Intelligence</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This work introduces a new query inference model that can access data and communicate with the teacher by asking finitely many Boolean queries in a language L. In this model the parameters of interest are the number of queries used and the expressive power of L. We ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:j_c9uEG18zwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4392053355484936079&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="335">
        <url>http://km.meme.hokudai.ac.jp/people/jantke/Publications/2005/2005_Jantke_Sapporo-Keynote.pdf</url>
        <title status="complete" source="scholar.google.com">Principles, Potentials and Problems of Inductive Reasoning in Meme Media Technology Applications</title>
        <pdf>http://km.meme.hokudai.ac.jp/people/jantke/Publications/2005/2005_Jantke_Sapporo-Keynote.pdf</pdf>
        <author status="complete" source="scholar.google.com">KP Jantke</author>
        <proceeding status="complete" source="scholar.google.com">km.meme.hokudai.ac.jp</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract Meme Media have been invented to allow for the study and further development towards revolutionary applications of externalized knowledge evolution. Meme media technologies like IntelligentPad and IntelligentBox have been further on investigated and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:qnMKuQgmu3sJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:qnMKuQgmu3sJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="336">
        <url>http://www.morganclaypool.com/doi/abs/10.2200/S00304ED1V01Y201010HLT011</url>
        <title status="complete" source="scholar.google.com">Computational modeling of human language acquisition</title>
        <pdf>http://www.aclweb.org/anthology/J/J11/J11-3009.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Alishahi</author>
        <proceeding status="partial" source="scholar.google.com">Synthesis Lectures on Human Language &#8230;</proceeding>
        <year>2010</year>
        <source>morganclaypool.com</source>
        <snippet status="partial" source="scholar.google.com">Abstract Human language acquisition has been studied for centuries, but using computational modeling for such studies is a relatively recent trend. However, computational approaches to language learning have become increasingly popular, mainly due to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:7oGEujTqqHcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>16</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8622398998789259758&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8622398998789259758&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="337">
        <url>http://www.springerlink.com/index/rx7nvg4b11vwk6dl.pdf</url>
        <title status="complete" source="scholar.google.com">A probabilistic identification result</title>
        <pdf>http://cs.anu.edu.au/people/Eric.McCreath/papers/limit2000.pdf</pdf>
        <author status="complete" source="scholar.google.com">E McCreath</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The approach used to assess a learning algorithm should reect the type of environment we place the algorithm within. Often learners are given examples that both contain noise and are governed by a particular distribution. Hence, probabilistic identification in the limit is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:TuKQuqPuzWcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7479896943109399118&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="338">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.104.3021&amp;rep=rep1&amp;type=pdf#page=198</url>
        <title status="complete" source="scholar.google.com">Learnability of Recursively Enumerable Sets of Recursive Real-Valued Functions</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.104.3021&amp;rep=rep1&amp;type=pdf#page=198</pdf>
        <author status="complete" source="scholar.google.com">E Hirowatari, K Hirata, T Miyahara</author>
        <proceeding status="complete" source="scholar.google.com">Computation and Logic in the Real World</proceeding>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. In this paper, we investigate the learnability of recursively enumerable (re, for short) sets of recursive real-valued functions. Unfortunately, as shown by Hirowatari and Arikawa (1997), there exists an re set of recursive real-valued functions that is not learnable in the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1uicui4CQr4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:1uicui4CQr4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13709522615391807702&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="339">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.26.7011&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">SIIM Technical Report</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.26.7011&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, G Grieser, T Zeugmann</author>
        <year>2001</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper provides a systematic study of inductive inference of indexable concept classes in learning scenarios where the learner is successful if its nal hypothesis describes a nite variant of the target concept, ie, learning with anomalies. Learning from positive ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:XFunvZj2iAQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:XFunvZj2iAQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=326782108861684572&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="340">
        <url>http://www.linguistics.ucla.edu/people/stabler/Stabler09-HEL.pdf</url>
        <title status="complete" source="scholar.google.com">Mathematics of language learning</title>
        <pdf>http://www.linguistics.ucla.edu/people/stabler/Stabler09-HEL.pdf</pdf>
        <author status="complete" source="scholar.google.com">EP Stabler</author>
        <proceeding status="complete" source="scholar.google.com">Histoire, ÃpistÃ©mologie, Langage</proceeding>
        <year>2009</year>
        <source>linguistics.ucla.edu</source>
        <snippet status="partial" source="scholar.google.com">Abstract. This paper surveys prominent mathematical approaches to language learning, with an emphasis on the common fundamental assumptions of various approaches. All approaches adopt some restrictive assumption about the nature of relevant causal ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:pCZ8w9dLKh8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:pCZ8w9dLKh8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2245690754267358884&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="341">
        <url>https://www1.comp.nus.edu.sg/~fstephan/alt2004.ps</url>
        <title status="complete" source="scholar.google.com">On the Data Consumption Beneï¬ts of Accepting Increased Uncertainty</title>
        <pdf>https://www1.comp.nus.edu.sg/~fstephan/alt2004.ps</pdf>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">comp.nus.edu.sg</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract In the context of learning paradigms of identification in the limit, We address the question: Why is uncertainty sometimes desirable? VVe use mind change bounds on the output hypotheses a measure of uncertainty, and interpret &#39;desirable&#39;as reduction i11 data ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Er3nw-LMkmMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7175022430676040978&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="342">
        <url>http://www.springerlink.com/index/U07211K470R73N12.pdf</url>
        <title status="complete" source="scholar.google.com">Learning and classifying</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/classifylearn.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Martin, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We define and study a learning paradigm that sits between identification in the limit and classification. More precisely, we expect that a learner be able to identify in the limit which members of a set D of n possible data belong to a target language, where n and D are ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:dAVDyGPzGgMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=223758741395408244&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="343">
        <url>http://www.contrib.andrew.cmu.edu/~kk3n/ockham/bijoy3.pdf</url>
        <title status="complete" source="scholar.google.com">Argument, Inquiry, and the Unity of Science</title>
        <pdf>http://www.contrib.andrew.cmu.edu/~kk3n/ockham/bijoy3.pdf</pdf>
        <author status="complete" source="scholar.google.com">KT Kelly</author>
        <year>2008</year>
        <source>contrib.andrew.cmu.edu</source>
        <snippet status="partial" source="scholar.google.com">Abstract Ockham&#39;s razor impels scientists to seek ever greater unity in nature. That seems to saddle science with a metaphysical presupposition of simplicity that might be false. The objection is apt if scientific method is understood as a system of inductive logic or proof, for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:osWKyfEM0GMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:osWKyfEM0GMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7192262837518648738&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="344">
        <url>http://www.illc.uva.nl/ESSLLI2008/Materials/vanBenthemPacuit/vanBenthemPacuit.pdf#page=11</url>
        <title status="complete" source="scholar.google.com">Identification through Inductive Verification</title>
        <pdf>http://www.illc.uva.nl/ESSLLI2008/Materials/vanBenthemPacuit/vanBenthemPacuit.pdf#page=11</pdf>
        <author status="complete" source="scholar.google.com">N Gierasimczuk</author>
        <proceeding status="partial" source="scholar.google.com">Logic and intelligent interaction: charting the technical &#8230;</proceeding>
        <source>illc.uva.nl</source>
        <snippet status="partial" source="scholar.google.com">Abstract In this paper we are concerned with some general properties of scientific hypotheses. We investigate the relationship between the situation when the task is to verify a given hypothesis, and when a scientist has to pick a correct hypothesis from an arbitrary ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:yCG3ymXEe8YJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:yCG3ymXEe8YJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14302240983116882376&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="345">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6223491</url>
        <title status="complete" source="scholar.google.com">Monotonic plan generation assistance: Challenges, open problems &amp; solutions</title>
        <author status="complete" source="scholar.google.com">O Arnold, KP Jantke</author>
        <proceeding status="partial" source="scholar.google.com">Systems and Informatics (ICSAI), 2012 &#8230;</proceeding>
        <year>2012</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Plan generation is essentially a process of reasoning about the future. In complex application conditions, humans need computerized support by planning assistant systems that manage the complexity of data and the dynamics of targeted processes. In practice, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Bc_KyjeevJIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="346">
        <title status="complete" source="scholar.google.com">Forschungsinstitut fÃ¼r Informationstechnologien</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:CvJvyyWq8rgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="347">
        <url>http://www.springerlink.com/index/R244418312565362.pdf</url>
        <title status="complete" source="scholar.google.com">On the amount of nonconstructivity in learning formal languages from positive data</title>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan, T Zeugmann</author>
        <proceeding status="partial" source="scholar.google.com">Theory and Applications of Models of &#8230;</proceeding>
        <year>2012</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Nonconstructive computations by various types of machines and automata have been considered by eg, Karp and Lipton [18] and Freivalds [9, 10]. They allow to regard more complicated algorithms from the viewpoint of more primitive computational devices. The ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:PTqhzkyLOnIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8231044430973450813&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="348">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.93.9830&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Lecture Notes: Language and Evolution</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.93.9830&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">E Stabler</author>
        <year>2007</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">The study of evolution and language provides a unique opportunity for carefully examining basic and important questions about evolution, language, and the kinds of explanations available for sources of order in physical, biological, cognitive and cultural domains. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:SboB0FdYrB4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:SboB0FdYrB4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2210238651307244105&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="349">
        <url>http://unsworks.unsw.edu.au/fapi/datastream/unsworks:2490/SOURCE2</url>
        <title status="complete" source="scholar.google.com">Limiting Programs for Induction in Artificial Intelligence</title>
        <pdf>http://unsworks.unsw.edu.au/fapi/datastream/unsworks:2490/SOURCE2</pdf>
        <author status="complete" source="scholar.google.com">P Caldon</author>
        <proceeding status="complete" source="scholar.google.com">unsworks.unsw.edu.au</proceeding>
        <snippet status="partial" source="scholar.google.com">ABSTRACT. This thesis examines a novel induction-based framework for logic programming. Limiting programs are logic programs distinguished by two features, in general they contain an infinite data stream over which induction will be performed, and in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:iAv-0VdveX4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:iAv-0VdveX4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9113437743936834440&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="350">
        <url>http://www.mpi-inf.mpg.de/~scheffer/publications/thesis.pdf</url>
        <title status="complete" source="scholar.google.com">Error Estimation AND Model Selection</title>
        <pdf>http://www.mpi-inf.mpg.de/~scheffer/publications/thesis.pdf</pdf>
        <author status="complete" source="scholar.google.com">T Scheffer</author>
        <proceeding status="complete" source="scholar.google.com">mpi-inf.mpg.de</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract Machine learning algorithms search a space of possible hypotheses and estimate the error of each hypotheses using a sample. Most often, the goal of classification tasks is to find a hypothesis with a low true (or generalization) misclassification probability (or error ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:XniZ0qwSMLQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>15</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12983898259186088030&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="351">
        <url>http://www.mpi-inf.mpg.de/departments/d1/teaching/ss12/learning/ScriptSS12.pdf</url>
        <title status="complete" source="scholar.google.com">Limits of Computational Learning</title>
        <pdf>http://www.mpi-inf.mpg.de/departments/d1/teaching/ss12/learning/ScriptSS12.pdf</pdf>
        <author status="complete" source="scholar.google.com">T KÃ¶tzing</author>
        <year>2012</year>
        <source>mpi-inf.mpg.de</source>
        <snippet status="partial" source="scholar.google.com">15? Maybe all odd numbers that are not squares? In this course we will study learning (identification) of infinite objects (such as infinite sequences) from finite data (such as initial pieces of the sequence), also known as Inductive Inference. What (collections of) ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:K97o0me1JA0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:K97o0me1JA0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=947081279179382315&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="352">
        <url>http://www.tech.plymouth.ac.uk/socce/evolang6/mittal_karnick.pdf</url>
        <title status="complete" source="scholar.google.com">LEARNING MODELS FOR LANGUAGE ACQUISITION</title>
        <pdf>http://www.tech.plymouth.ac.uk/socce/evolang6/mittal_karnick.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Mittal, H Karnick</author>
        <proceeding status="complete" source="scholar.google.com">Relation</proceeding>
        <year>2008</year>
        <source>tech.plymouth.ac.uk</source>
        <snippet status="partial" source="scholar.google.com">In this paper, we present a model of language acquisition which can be used to explain how children learn a grammar by interacting with their surroundings. We build upon the model proposed by Komarova et al in the context of evolution of grammars. We test our model for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:F9Gj2EvObqEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:F9Gj2EvObqEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11632461712697053463&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="353">
        <url>http://ml-submission07.googlecode.com/svn-history/r25/trunk/ml-conserve.pdf</url>
        <title status="complete" source="scholar.google.com">Machine Discovery of Conservation Laws and Hidden Particles in Particle Physics</title>
        <pdf>http://ml-submission07.googlecode.com/svn-history/r25/trunk/ml-conserve.pdf</pdf>
        <author status="complete" source="scholar.google.com">O Schulte</author>
        <year>2007</year>
        <source>ml-submission07.googlecode.com</source>
        <snippet status="partial" source="scholar.google.com">Abstract An important problem for scientific discovery in several domains is constructing a model of physical or chemical reactions. We introduce a new principle for learning reaction models: models should be maximally strict, ie, they should rule out as many unobserved ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Osh22WqsvngJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:Osh22WqsvngJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="354">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540109000741</url>
        <title status="complete" source="scholar.google.com">Mind change optimal learning of Bayes net structure from dependency and independency data</title>
        <pdf>http://mind-change-bayes-net.googlecode.com/svn/trunk/YINCO_3648.pdf</pdf>
        <author status="complete" source="scholar.google.com">O Schulte, W Luo, R Greiner</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2010</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper analyzes the problem of learning the structure of a Bayes net in the theoretical framework of Gold&#39;s learning paradigm. Bayes nets are one of the most prominent formalisms for knowledge representation and probabilistic and causal reasoning. We ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ccaV24KQB1QJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6054967115727095409&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="355">
        <url>http://dmyers.us/F99%20classes/Myers_FormsofRules_6500.doc</url>
        <title status="complete" source="scholar.google.com">Forms of rules of games of forms</title>
        <pdf>http://dmyers.us/F99%20classes/Myers_FormsofRules_6500.doc</pdf>
        <author status="complete" source="scholar.google.com">D Myers</author>
        <proceeding status="partial" source="scholar.google.com">ErzÃ¤hlformen im computerspiel: Zur &#8230;</proceeding>
        <year>2009</year>
        <source>dmyers.us</source>
        <snippet status="partial" source="scholar.google.com">The use of formalist techniques in the humanities is rare these days, almost passÃ©. Formalism has been largely absorbed and, indeed, almost eliminated, by variants of structuralism, which have proven more appealing to those who would situate the study of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:KpcF3H-1mQYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:KpcF3H-1mQYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=475610796421125930&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="356">
        <url>http://www.springerlink.com/index/63mdygem6382h1gf.pdf</url>
        <title status="complete" source="scholar.google.com">Identifying clusters from positive data</title>
        <author status="partial" source="scholar.google.com">J Case, S Jain, E Martin, A Sharma&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; Inference: Algorithms and &#8230;</proceeding>
        <year>2004</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The present work studies clustering from an abstract point of view and investigates its properties in the framework of inductive inference. Any class S considered is given by a numbering A 0, A 1,... of nonempty subsets of â or â k which is also used as a hypothesis ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:0HVe3V8fkkIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4796931049699309008&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="357">
        <title status="complete" source="scholar.google.com">Program self-reference</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.156.5672&amp;rep=rep1&amp;type=pdf</pdf>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:YxqD3ZnzbpwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11272214759526832739&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="358">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.118.7824&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">NEGATIVE DATA IN LEARNING LANGUAGES</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.118.7824&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S JAIN, E KINBER</author>
        <proceeding status="partial" source="scholar.google.com">Mathematical Logic in Asia: Proceedings of the 9th &#8230;</proceeding>
        <year>2006</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">The paper is a survey of recent results on algorithmic learning (inductive inference) of languages from full collection of positive examples and some negative data. Different types of negative data are considered. We primarily concentrate on learning using (1) carefully ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:xhc83r1kuQwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:xhc83r1kuQwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=916874765786683334&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="359">
        <url>http://www.springerlink.com/index/g654385j7014634v.pdf</url>
        <title status="complete" source="scholar.google.com">Inductive Inference Systems for Learning Classes of Algorithmically Generated Sets and Structures</title>
        <pdf>http://fs1.bib.tiera.ru/content/dvd57/Friend%20M.%20(ed.),%20Harizanov%20V.S.%20(ed.)%20-%20Induction,%20Algorithmic%20Learning%20Theory,%20and%20Philosophy(2007)(304).pdf#page=40</pdf>
        <author status="complete" source="scholar.google.com">V Harizanov</author>
        <proceeding status="partial" source="scholar.google.com">Induction, Algorithmic Learning Theory, and &#8230;</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Computability theorists have extensively studied sets A the elements of which can be enumerated by Turing machines. These sets, also called computably enumerable sets, can be identified with their G del codes. Although each Turing machine has a unique G del ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:dLv33n0UvL8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13815940287710083956&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="360">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397512009322</url>
        <title status="complete" source="scholar.google.com">Learning without coding</title>
        <author status="complete" source="scholar.google.com">S Jain, SE Moelius III, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Abstract Iterative learning is a model of language learning from positive data, due to Wiehagen. When compared to a learner in Gold&#39;s original model of language learning from positive data, an iterative learner can be thought of as memory-limited. However, an ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="361">
        <url>http://www.springerlink.com/index/5KE83L9WF92MT3C8.pdf</url>
        <title status="complete" source="scholar.google.com">Extending elementary formal systems</title>
        <pdf>http://cs5824.userapi.com/u11728334/docs/20e8cf4a8295/Naoki_Abe_Algorithmic_Learning_Theory_12_conf_A.pdf#page=341</pdf>
        <author status="complete" source="scholar.google.com">S Lange, G Grieser, K Jantke</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">An elementary formal system (EFS) is a logic program such as a Prolog program, for instance, that directly manipulates strings. Arikawa and his co-workers proposed elementary formal systems as a unifying framework for formal language learning. In the present paper, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:N3_B4WZo4XkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8782415539432685367&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="362">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397512007128</url>
        <title status="complete" source="scholar.google.com">Learning in the limit with lattice-structured hypothesis spaces</title>
        <author status="complete" source="scholar.google.com">J Heinz, A Kasprzik, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We define a collection of language classes which are TxtEx-learnable (learnable in the limit from positive data). The learners map any data input to an element of a fixed lattice, and keep the least upper bound of all lattice elements thus obtained as the current hypothesis. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ZwsP5kjqVmoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7662569414835768167&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="363">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.6279&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Robust LearningâRich and Poor</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.6279&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">JCS Jainb, F Stephanc, R Wiehagend</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract A class C of recursive functions is called robustly learnable in the sense I (where I is any success criterion of learning) if not only C itself but even all transformed classes Î (C) where Î is any general recursive operator, are learnable in the sense I. It was already ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:F-gF6cXSbSAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:F-gF6cXSbSAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2336755529135024151&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="364">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.190.8253&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Learning as Interaction</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.190.8253&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">N Gierasimczuk, L Kurzen, FR VelÃ¡zquez-Quesada</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract In formal approaches to inductive learning, the ability to learn is understood as the ability to single out a correct hypothesis from a range of possibilities. Although most of the existing research focuses on the characteristics of the learner, in many paradigms the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:twON6cT75-YJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:twON6cT75-YJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16638544171494081463&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="365">
        <url>https://www.comp.nus.edu.sg/~fstephan/confcons.ps</url>
        <title status="complete" source="scholar.google.com">Confident and Consistent Partial Learning of Recursive Functions</title>
        <pdf>https://www.comp.nus.edu.sg/~fstephan/confcons.ps</pdf>
        <author status="complete" source="scholar.google.com">Z Gao, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">comp.nus.edu.sg</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. Partial learning is a criterion where the learner infinitely often outputs one correct conjecture while every other hypothesis is issued only finitely often. This paper addresses two variants of partial learning in the setting of inductive inference of functions: first, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Av888G6XhQIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:Av888G6XhQIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=181717862711099138&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="366">
        <url>http://phil-sci07.googlecode.com/svn/branches/beijing/sg_B2_Schulte.pdf</url>
        <title status="complete" source="scholar.google.com">Logic, Methodology and Philosophy of Science</title>
        <pdf>http://phil-sci07.googlecode.com/svn/branches/beijing/sg_B2_Schulte.pdf</pdf>
        <author status="complete" source="scholar.google.com">C Glymour, W Wei, D WesterstÃ¥hl</author>
        <proceeding status="complete" source="scholar.google.com">phil-sci07.googlecode.com</proceeding>
        <snippet status="partial" source="scholar.google.com">ABSTRACT. This paper presents an epistemological analysis of the search for new conservation laws in particle physics. Discovering conservation laws has posed various challenges concerning the underdetermination of theory by evidence, to which physicists ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:i8Mg8ywceZAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:i8Mg8ywceZAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10410382993026761611&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="367">
        <url>http://epubs.siam.org/doi/abs/10.1137/050629112</url>
        <title status="complete" source="scholar.google.com">Identifying Clusters from Positive Data</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/cluster.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, E Martin, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">SIAM Journal on Computing</proceeding>
        <year>2006</year>
        <source>SIAM</source>
        <snippet status="partial" source="scholar.google.com">The present work studies clustering from an abstract point of view and investigates its properties in the framework of inductive inference. Any class S considered is given by a hypothesis space, ie, numbering, A_0,A_1,... of nonempty recursively enumerable (re) ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:J3Yj85UdkaEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>30</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11642119041595962919&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="368">
        <url>http://www.comp.nus.edu.sg/~sanjay/paps/coord.pdf</url>
        <title status="complete" source="scholar.google.com">On Learning To Coordinate: Random Bits Help, Insightful Normal Forms, and Competency Isomorphisms</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/coord.pdf</pdf>
        <author status="complete" source="scholar.google.com">JCSJF Montagnac, G Simic, A Sorbic</author>
        <proceeding status="complete" source="scholar.google.com">comp.nus.edu.sg</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract A mere bounded number of random bits judiciously employed by a probabilistically correct algorithmic coordinator is shown to increase the power of learning to coordinate compared to deterministic algorithmic coordinators. Furthermore, these probabilistic ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:hy1_83_8liEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:hy1_83_8liEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2420399476234464647&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="369">
        <url>http://www.springerlink.com/index/D891256047178X85.pdf</url>
        <title status="complete" source="scholar.google.com">Learning from streams</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.157.1225&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan, N Ye</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Learning from streams is a process in which a group of learners separately obtain information about the target to be learned, but they can communicate with each other in order to learn the target. We are interested in machine models for learning from streams ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1jKd9b4XsWYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>22</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7399721771678380758&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="370">
        <url>http://www.worldscientific.com/doi/abs/10.1142/S0129626412400129</url>
        <title status="complete" source="scholar.google.com">THE MYTH OF&#39;THE MYTH OF HYPERCOMPUTATION&#39;</title>
        <author status="partial" source="scholar.google.com">NS GOVINDARAJULU&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Parallel Processing &#8230;</proceeding>
        <year>2012</year>
        <source>World Scientific</source>
        <snippet status="partial" source="scholar.google.com">A myth has unfortunately arisen in connection with Martin Davis&#39;s rather aggressively titled paper&quot; The Myth of Hypercomputation.&quot; The myth is that Davis is profoundly and decisively right therein, and that hypercomputation is indeed therefore a myth. We show herein that ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:xcyL-EJQIiQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2603731783141543109&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="371">
        <title status="complete" source="scholar.google.com">53100 SIENA Italy agostini@ unisi. it</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ROz6-I0TExMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="372">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6252552</url>
        <title status="complete" source="scholar.google.com">Reasoning with heuristics and induction: An account based on the CLARION cognitive architecture</title>
        <pdf>http://ccn.psych.purdue.edu/papers/PID2235401.pdf</pdf>
        <author status="complete" source="scholar.google.com">R Sun, S Helie</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; ), The 2012 International Joint Conference on</proceeding>
        <year>2012</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Some psychologists have criticized computational cognitive architectures on the basis of model complexity and parameter tweaking. This paper addresses these criticisms by using a well established cognitive architecture, CLARION, and extracting its core theory ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:jZNO_kBuxhYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1641120339646649229&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="373">
        <url>http://www.princeton.edu/~osherson/IL/essay4.pdf</url>
        <title status="complete" source="scholar.google.com">Advanced Topics in Inductive Logic1</title>
        <pdf>http://www.princeton.edu/~osherson/IL/essay4.pdf</pdf>
        <author status="complete" source="scholar.google.com">E Martin, D Osherson</author>
        <year>2003</year>
        <source>princeton.edu</source>
        <snippet status="partial" source="scholar.google.com">1This work was supported by Australian Research Council Grant# A49803051 to Martin and by NSF Grant# IIS-9978135 to Osherson. We thank Scott Weinstein for generously checking proofs and offering improvements to several arguments. Thanks also to Sebastian Rahtz ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:IneW_kNr_wUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:IneW_kNr_wUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=432182029029111586&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="374">
        <url>http://ubt.opus.hbz-nrw.de/volltexte/2012/737/</url>
        <title status="partial" source="scholar.google.com">Formal tree languages and their algorithmic learnability Formal tree languages and their algorithmic learnability Formale Baumsprachen und ihre Lernbarkeit mittels &#8230;</title>
        <pdf>http://ubt.opus.hbz-nrw.de/volltexte/2012/737/pdf/KasprzikDiss.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Kasprzik</author>
        <year>2011</year>
        <source>ubt.opus.hbz-nrw.de</source>
        <snippet status="partial" source="scholar.google.com">Abstract This thesis centers on formal tree languages and on their learnability by algorithmic methods in abstractions of several learning settings. After a general introduction (Chapter 1), we present a survey of relevant definitions for the formal tree concept as well as special ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RVo3_2YrNw8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="375">
        <title status="complete" source="scholar.google.com">Neue TechnologienâPotentiale und Probleme illustriert an Anwendungen des e-Learning</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:QzNmTp72XCwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="376">
        <title status="complete" source="scholar.google.com">LExIKON {Lernszenarios f ur die Extraktion von Information aus dem Internet</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:w0R6YGVUio8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10343172288596821187&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="377">
        <url>http://raai.org/about/persons/finn/pages/finn_kdd.doc</url>
        <title status="partial" source="scholar.google.com">Ð ÐµÑÐ°ÑÐµÐ»Ñ Ð·Ð°Ð´Ð°Ñ= Ð Ð°ÑÑÑÐ¶Ð´Ð°ÑÐµÐ»Ñ+ ÐÑÑÐ¸ÑÐ»Ð¸ÑÐµÐ»Ñ+ Ð¡Ð¸Ð½ÑÐµÐ·Ð°ÑÐ¾Ñ, ÐÐ½ÑÐ¾ÑÐ¼Ð°ÑÐ¸Ð¾Ð½Ð½Ð°Ñ ÑÑÐµÐ´Ð°= ÐÐ¤+ ÐÐ, ÐÐ½ÑÐµÐ»Ð»ÐµÐºÑÑÐ°Ð»ÑÐ½ÑÐ¹ Ð¸Ð½ÑÐµÑÑÐµÐ¹Ñ= Ð´Ð¸Ð°Ð»Ð¾Ð³+ &#8230;</title>
        <pdf>http://raai.org/about/persons/finn/pages/finn_kdd.doc</pdf>
        <author status="complete" source="scholar.google.com">ÐÐ Ð¤Ð¸Ð½Ð½</author>
        <proceeding status="complete" source="scholar.google.com">raai.org</proceeding>
        <snippet status="partial" source="scholar.google.com">Ð Ð°ÑÑÑÐ¶Ð´Ð°ÑÐµÐ»Ñ ÐµÑÑÑ Ð¿Ð¾Ð´ÑÐ¸ÑÑÐµÐ¼Ð°, ÑÐµÐ°Ð»Ð¸Ð·ÑÑÑÐ°Ñ Ð»Ð¾Ð³Ð¸ÑÐµÑÐºÐ¸Ðµ ÑÑÐµÐ´ÑÑÐ²Ð° ÑÐµÑÐµÐ½Ð¸Ñ Ð·Ð°Ð´Ð°Ñ, Ð¿Ð¾ÑÑÐµÐ´ÑÑÐ²Ð¾Ð¼ ÐºÐ¾ÑÐ¾ÑÑÑ ÑÐ¾ÑÐ¼Ð°Ð»Ð¸Ð·ÑÐµÑÑÑ ÑÐ¾Ð¾ÑÐ²ÐµÑÑÑÐ²ÑÑÑÐ°Ñ ÑÐ²ÑÐ¸ÑÑÐ¸ÐºÐ°. Ð ÐµÐ·ÑÐ»ÑÑÐ°ÑÐ¾Ð¼ ÑÐ°ÐºÐ¾Ð¹ ÑÐ¾ÑÐ¼Ð°Ð»Ð¸Ð·Ð°ÑÐ¸Ð¸ ÑÐ²Ð»ÑÑÑÑÑ ÑÐ°Ð·Ð»Ð¸ÑÐ½ÑÐµ ÑÐ¸Ð¿Ñ ÑÐ°ÑÑÑÐ¶Ð´ÐµÐ½Ð¸Ð¹, Ð½Ð°Ð¿ÑÐ¸Ð¼ÐµÑ, Ð¿ÑÐ¸Ð±Ð»Ð¸Ð¶ÐµÐ½Ð½ÑÐµ ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:tqjvYW2eha0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:tqjvYW2eha0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12503574133095770294&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="378">
        <url>http://www.ke.tu-darmstadt.de/lehre/arbeiten/diplom/2006/Degen_Mathias.pdf</url>
        <title status="complete" source="scholar.google.com">STALKER: Lerntheoretische Modellierung und Untersuchung</title>
        <pdf>http://www.ke.tu-darmstadt.de/lehre/arbeiten/diplom/2006/Degen_Mathias.pdf</pdf>
        <author status="complete" source="scholar.google.com">M Degen</author>
        <proceeding status="complete" source="scholar.google.com">ke.tu-darmstadt.de</proceeding>
        <snippet status="partial" source="scholar.google.com">Hiermit versichere ich, die vorliegende Diplomarbeit ohne Hilfe Dritter und nur mit den angegebenen Quellen und Hilfsmitteln angefertigt zu haben. Alle Stellen, die aus den Quellen entnommen wurden, sind als solche kenntlich gemacht worden. Diese Arbeit hat ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:CTA1lDMFs3sJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:CTA1lDMFs3sJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8913473806584328201&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="379">
        <title status="complete" source="scholar.google.com">Maschinelles Lernen und Automatische Reflexion</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:UuVdx_1KBdwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15854160517059700050&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="380">
        <url>http://tel.archives-ouvertes.fr/tel-00659482/</url>
        <title status="complete" source="scholar.google.com">L&#39;InfÃ©rence Grammaticale au pays des Apprentissages Automatiques: Discussions sur la coexistence de deux disciplines</title>
        <pdf>http://tel.archives-ouvertes.fr/docs/00/65/94/82/PDF/report.pdf</pdf>
        <author status="complete" source="scholar.google.com">JC Janodet</author>
        <year>2010</year>
        <source>tel.archives-ouvertes.fr</source>
        <snippet status="partial" source="scholar.google.com">J&#39;ai dÃ©couvert l&#39;InfÃ©rence Grammaticale en lisant le Journal Officiel. Il ya des lectures plus divertissantes, mais quand on postulaita la maÄ±trise de confÃ©rences en 2000, Galaxie n&#39;existait pas encore: on tÃ©lÃ©chargeait un long fichier publiÃ© au JO par le Ministere, et c&#39;est ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:5r508tHv95QJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10734311921855807206&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="381">
        <title status="complete" source="scholar.google.com">Reflexive Induktive Inferenz</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:arZY9pLbFEAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4617556942206318186&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="382">
        <url>http://hal.inria.fr/inria-00549416/</url>
        <title status="complete" source="scholar.google.com">DÃ©cidabilitÃ© et ComplexitÃ©</title>
        <pdf>http://hal.inria.fr/docs/00/54/94/16/PDF/Chapitre_DecidabiliteComplexite.pdf</pdf>
        <author status="partial" source="scholar.google.com">O Bournez, G Dowek, R Gilleron, S Grigorieff&#8230;</author>
        <proceeding status="complete" source="scholar.google.com">IA Handbook</proceeding>
        <year>2010</year>
        <source>hal.inria.fr</source>
        <snippet status="partial" source="scholar.google.com">RÃ©sumÃ©: L&#39;informatique fondamentale est un vaste sujet, comme en tÃ©moignent les 2 283 et 3 176 pages des&quot; Handbooks&quot;(228; 1). Couvrir en quelques dizaines de pages, l&#39;ensemble de l&#39;in-formatique nous a semblÃ© une entreprise hors de notre portÃ©e. De ce fait, nous ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:9Ndi-1X6vZMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10645940341370443764&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="15">
    <url>http://www.springerlink.com/index/M161142U87M78Q35.pdf</url>
    <title status="complete" source="scholar.google.com">Automatic learning of subclasses of pattern languages</title>
    <author status="partial" source="scholar.google.com">J Case, S Jain, T Le, Y Ong, P Semukhin&#8230;</author>
    <proceeding status="partial" source="scholar.google.com">Language and Automata &#8230;</proceeding>
    <year>2011</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 Department of Computer and Information Sciences, University of Delaware, Newark, DE19716-2586, USA case@cis.udel.edu 2 Department of Computer Science, National Universityof Singapore, Singapore 117417, Republic of Singapore sanjay@comp.nus.edu.sg, daole ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:OKgwDG5SBTsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>3</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=4252896055725697080&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>4</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=4252896055725697080&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="4">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000011001565</url>
        <title status="complete" source="scholar.google.com">Learnability of automatic classes</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2895/1/TRA1-09.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, Q Luo, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2011</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present work initiates the study of the learnability of automatic indexable classes which are classes of regular languages of a certain form. AngluinÊ¼s tell-tale condition characterises when these classes are explanatorily learnable. Therefore, the more ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:YFpXlQRP4YwJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>19</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10151481916173802080&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10151481916173802080&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/371821UW3L4225G8.pdf</url>
        <title status="complete" source="scholar.google.com">Automatic learners with feedback queries</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/autofeednew.pdf</pdf>
        <author status="partial" source="scholar.google.com">J Case, S Jain, Y Ong, P Semukhin&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Models of Computation in &#8230;</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Automatic classes are classes of languages for which a finite automaton can decide whether a given element is in a set given by its index. The present work studies the learnability of automatic families by automatic learners which, in each round, output a hypothesis and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RXW6gzjPnq0J:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12510664656516969797&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12510664656516969797&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/D2798548132P7V20.pdf</url>
        <title status="complete" source="scholar.google.com">Automatic functions, linear time and learning</title>
        <pdf>https://www.iscs.nus.edu.sg/~fstephan/autolintime.ps</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, S Seah, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">How the World Computes</proceeding>
        <year>2012</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The present work determines the exact nature of linear time computable notions which characterise automatic functions (those whose graphs are recognised by a finite automaton). The paper also determines which type of linear time notions permit full learnability for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1rUoLH2c-KAJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11599192901718422998&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www-test.comp.nus.edu.sg/~fstephan/autolearn.ps</url>
        <title status="complete" source="scholar.google.com">Learnability of automatic classes</title>
        <pdf>http://www-test.comp.nus.edu.sg/~fstephan/autolearn.ps</pdf>
        <author status="complete" source="scholar.google.com">S Jaina, Q Luob, F Stephanc</author>
        <year>2012</year>
        <source>www-test.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract The present work initiates the study of the learnability of automatic indexable classes which are classes of regular languages of a certain form. Angluin&#39;s tell-tale condition characterises when these classes are explanatorily learnable. Therefore, the more ...</snippet>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:JuK-zNs-g04J:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="16">
    <url>http://www.sciencedirect.com/science/article/pii/S0304397599000055</url>
    <title status="complete" source="scholar.google.com">Ordinal mind change complexity of language identification</title>
    <author status="complete" source="scholar.google.com">A Ambainis, S Jain, A Sharma</author>
    <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
    <year>1999</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... 1999 Eisevier Science BV All rights reserved. Keywords: Inductive inference; Mind changecomplexity; Ordinals * Corresponding author. E-mail addresses&#39;, ambainis@cs.berkeley.edu(A. Ambainis), sanjay@iscs.nus.edu. sg (S. Jain), arun@cse.unsw.edu.au (A. Sharma). ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:vR2MAdwEA-MJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>9</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=16357923614505049533&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>28</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=16357923614505049533&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="28">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397500002723</url>
        <title status="complete" source="scholar.google.com">Learning algebraic structures from text</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.41.615&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, Y Ventsov</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present work investigates the learnability of classes of substructures of some algebraic structures: submonoids and subgroups of given groups, ideals of given commutative rings, subfields of given vector spaces. The learner sees all positive data but no negative one ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:pOAgDmnQfi8J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3422401916475334820&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>23</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3422401916475334820&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://projecteuclid.org/euclid.jsl/1080938842</url>
        <title status="complete" source="scholar.google.com">Parsimony hierarchies for inductive inference</title>
        <pdf>http://pdf.aminer.org/002/865/517/parsimony_hierarchies_for_inductive_inference.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Ambainis, J Case, S Jain, M Suraj</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
        <year>2004</year>
        <source>projecteuclid.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Freivalds defined an acceptable programming system independent criterion for learning programs for functions in which the final programs were required to be both correct and ânearlyâ minimal size, ie, within a computable function of being purely minimal size. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:PPOiazrZf9IJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15168080914944291644&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15168080914944291644&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540106000253</url>
        <title status="complete" source="scholar.google.com">Mind change efficient learning</title>
        <pdf>http://mind-change-bayes-net.googlecode.com/svn/branches/mclc.pdf</pdf>
        <author status="complete" source="scholar.google.com">W Luo, O Schulte</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2006</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper studies efficient learning with respect to mind changes. Our starting point is the idea that a learner that is efficient with respect to mind changes minimizes mind changes not only globally in the entire learning problem, but also locally in subproblems after receiving ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Nc6YcK5juMUJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14247247022051085877&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14247247022051085877&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540103002438</url>
        <title status="complete" source="scholar.google.com">Generalized notions of mind change complexity</title>
        <pdf>http://www.math.uni-heidelberg.de/logic/fstephan/ssv-mathpreprints-com.ps</pdf>
        <author status="complete" source="scholar.google.com">A Sharma, F Stephan, Y Ventsov</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Gold introduced the notion of learning in the limit where a class S is learnable iff there is a recursive machine M which reads the course of values of a function f and converges to a program for f whenever f is in S. An important measure for the speed of convergence in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cA20SaS7b8gJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14442968844286037360&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14442968844286037360&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/lwppl43dfva4ulg5.pdf</url>
        <title status="complete" source="scholar.google.com">Mind change efficient learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.72.7998&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">W Luo, O Schulte</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper studies efficient learning with respect to mind changes. Our starting point is the idea that a learner that is efficient with respect to mind changes minimizes mind changes not only globally in the entire learning problem, but also locally in subproblems after receiving ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Tr_ZFZkwJUUJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4982441996810043214&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4982441996810043214&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397505006456</url>
        <title status="complete" source="scholar.google.com">Unifying logic, topology and learning in parametric logic</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.8.1793&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2006</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Many connections have been established between learning and logic, or learning and topology, or logic and topology. Still, the connections are not at the heart of these fields. Each of them is fairly independent of the others when attention is restricted to basic ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:BNnirbyUR9YJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>29</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15440473385555122436&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15440473385555122436&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.springerlink.com/index/tpxvht2u27uhrbtf.pdf</url>
        <title status="complete" source="scholar.google.com">Learning, logic, and topology in a common framework</title>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2002</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Many connections have been established between learning and logic, or learning and topology, or logic and topology. Still, the connections are not at the heart of these fields. Each of them is fairly independent of the others when attention is restricted to basic ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:NXIp5aKFsQcJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=554371163819176501&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=554371163819176501&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/1p9a8e58kgtl7mwk.pdf</url>
        <title status="complete" source="scholar.google.com">Mind change complexity of learning logic programs</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.105.2902&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The present paper motivates the study of mind change complexity for learning minimal models of length-bounded logic programs. It establishes ordinal mind change complexity bounds for learnability of these classes both from positive facts and from positive and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1GrxM06Kkp0J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11354289679037983444&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11354289679037983444&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540103000592</url>
        <title status="complete" source="scholar.google.com">On the intrinsic complexity of learning recursive functions</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.105.5266&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="partial" source="scholar.google.com">S Jain, E Kinber, C Papazian, C Smith&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Information and &#8230;</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The intrinsic complexity of learning compares the difficulty of learning classes of objects by using some reducibility notion. For several types of learning recursive functions, both natural complete classes are exhibited and necessary and sufficient conditions for completeness ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1E4tVz7znzUJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3864074454383283924&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3864074454383283924&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.springerlink.com/index/w7a5t1fc79t023u9.pdf</url>
        <title status="complete" source="scholar.google.com">Compute inclusion depth of a pattern</title>
        <author status="complete" source="scholar.google.com">W Luo</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We define a concept of inclusion depth (see Definition 1) to capture mind-change complexity [3, 1] of pattern identification problems [2]. Our basic question is whether the inclusion depth for any pattern is computable. We conjecture a combinatorial characterization that, if true, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MKf7hSaqxc4J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14899502024658495280&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14899502024658495280&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397509007981</url>
        <title status="complete" source="scholar.google.com">Mind change complexity of inferring unbounded unions of restricted pattern languages from positive data</title>
        <author status="complete" source="scholar.google.com">M de Brecht, A Yamamoto</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2010</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper shows that the mind change complexity of inferring from positive data the class of unbounded unions of languages of regular patterns with constant segment length bound is of the form [Formula: see text], assuming that the patterns are defined over a finite ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:S_0At17bfksJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5440026599753841995&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5440026599753841995&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://search.ieice.org/bin/summary.php?id=e86-d_2_219</url>
        <title status="complete" source="scholar.google.com">Criteria for inductive inference with mind changes and anomalies of recursive real-valued functions</title>
        <author status="partial" source="scholar.google.com">E Hirowatari, K Hirata, T Miyahara&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; on Information and &#8230;</proceeding>
        <year>2003</year>
        <source>search.ieice.org</source>
        <snippet status="partial" source="scholar.google.com">This paper investigates the interaction of&lt; I&gt; mind changes&lt;/I&gt; and&lt; I&gt; anomalies&lt;/I&gt; for inductive inference of recursive real-valued functions. We show that the criteria for inductive inference of recursive real-valued functions by bounding the number of mind changes and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:rFwCx_sXAPUJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17654136909435395244&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17654136909435395244&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397501004029</url>
        <title status="complete" source="scholar.google.com">On learning unions of pattern languages and tree patterns in the mistake bound model</title>
        <author status="complete" source="scholar.google.com">SA Goldman, SS Kwek</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2002</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We present efficient on-line algorithms for learning unions of a constant number of tree patterns, unions of a constant number of one-variable pattern languages, and unions of a constant number of pattern languages with fixed length substitutions. By fixed length ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:PL_cHq5MJb0J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13629384158032478012&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13629384158032478012&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="13">
        <url>http://www.springerlink.com/index/953nl87770n8u582.pdf</url>
        <title status="complete" source="scholar.google.com">Mind change complexity of inferring unbounded unions of pattern languages from positive data</title>
        <pdf>http://fs1.bib.tiera.ru/content/dvd52/Balcazar%20J.%20L.%20(Ed),%20Long%20Ph.%20M.%20(Ed),%20Stephan%20F.%20(Ed)%20-%20Algorithmic%20Learning%20Theory.%2017th%20International%20Conference,%20ALT%202006,%20Barcelona,%20Spain,%20October%207-10,%202006,%20Proceedings(2006)(393).pdf#page=135</pdf>
        <author status="complete" source="scholar.google.com">M de Brecht, A Yamamoto</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper gives a proof that the class of unbounded unions of languages of regular patterns with constant segment length bound is inferable from positive data with mind change bound between Ï Ï and www Ï^ Ï^ Ï. We give a very tight bound on the mind change ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:s5QaNydO4G4J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7989471669290439859&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7989471669290439859&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="14">
        <url>http://www.springerlink.com/index/QTAUAWTR9PFWEC4K.pdf</url>
        <title status="complete" source="scholar.google.com">On ordinal VC-dimension and some notions of complexity</title>
        <pdf>http://cs5235.userapi.com/u133638729/docs/0b3b37a51a80/Ricard_Gavald_Algorithmic_Learning_Theory_14_co.pdf#page=54</pdf>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2003</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We generalize the classical notion of VC-dimension to ordinal VC-dimension, in the context of logical learning paradigms. Logical learning paradigms encompass the numerical learning paradigms commonly studied in Inductive inference. A logical learning paradigm ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:DXua8Q4n9aAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>24</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11598219360499038989&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11598219360499038989&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="15">
        <url>http://www.springerlink.com/index/m447337826676k75.pdf</url>
        <title status="complete" source="scholar.google.com">Deduction, Induction, and beyond in Parametric Logic</title>
        <pdf>http://sites.google.com/site/omundodalogica/livros-de-introducao-a-logica/Logic,Epistemology,andtheUnityofScienceVol.9-Induction,AlgorithmicLearningTheory,andPhilosophy.pdf#page=68</pdf>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">Induction, Algorithmic Learning Theory, &#8230;</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">With parametric logic, we propose a unified approach to deduction and induction, both viewed as particular instances of a generalized notion of logical consequence. This generalized notion of logical consequence is Tarskian, in the sense that if a sentence Ï is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MsBcJUWaGjUJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3826540455174914098&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3826540455174914098&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="16">
        <url>http://www.springerlink.com/index/Q4H243321323V6K8.pdf</url>
        <title status="complete" source="scholar.google.com">The complexity of learning SUBSEQ (A)</title>
        <pdf>http://fs1.bib.tiera.ru/content/dvd52/Balcazar%20J.%20L.%20(Ed),%20Long%20Ph.%20M.%20(Ed),%20Stephan%20F.%20(Ed)%20-%20Algorithmic%20Learning%20Theory.%2017th%20International%20Conference,%20ALT%202006,%20Barcelona,%20Spain,%20October%207-10,%202006,%20Proceedings(2006)(393).pdf#page=120</pdf>
        <author status="complete" source="scholar.google.com">S Fenner, W Gasarch</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Higman showed that if A is any language then SUBSEQ (A) is regular, where SUBSEQ (A) is the language of all subsequences of strings in A. We consider the following inductive inference problem: given A (Îµ), A (0), A (1), A (00),... learn, in the limit, a DFA for SUBSEQ ( ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Jza4kQkTdmMJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>36</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7166936788827125287&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7166936788827125287&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="17">
        <url>http://www.springerlink.com/index/tfnvaubgr6letkab.pdf</url>
        <title status="complete" source="scholar.google.com">On a syntactic characterization of classification with a mind change bound</title>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Most learning paradigms impose a particular syntax on the class of concepts to be learned; the chosen syntax can dramatically affect whether the class is learnable or not. For classification paradigms, where the task is to determine whether the underlying world ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ok69y5G1ZLgJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13286944438442872482&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13286944438442872482&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="18">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540104000392</url>
        <title status="complete" source="scholar.google.com">On the classification of recursive languages</title>
        <author status="complete" source="scholar.google.com">J Case, E Kinber, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A one-sided classifier for a given class of languages converges to 1 on every language from the class and outputs 0 infinitely often on languages outside the class. A two-sided classifier, on the other hand, converges to 1 on languages from the class and converges to 0 on ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:PVNAR5fT1ogJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9860301080863200061&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9860301080863200061&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="19">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397506004907</url>
        <title status="complete" source="scholar.google.com">On ordinal VC-dimension and some notions of complexity</title>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2006</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We generalize the classical notion of VapnikâChernovenkis (VC) dimension to ordinal VC-dimension, in the context of logical learning paradigms. Logical learning paradigms encompass the numerical learning paradigms commonly studied in Inductive Inference. A ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:L7PJYay5n-wJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17050550864274109231&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17050550864274109231&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="20">
        <url>http://www.springerlink.com/index/0F9V180D4H1PDFK4.pdf</url>
        <title status="complete" source="scholar.google.com">Learning how to separate</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/resep.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The main question addressed in the present work is how to find effectively a recursive function separating two sets drawn arbitrarily from a given collection of disjoint sets. In particular, it is investigated in which cases it is possible to satisfy the following additional ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:SdXNvUSIHnoJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>19</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8799620550752064841&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8799620550752064841&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="21">
        <url>ftp://142.58.111.31/fas-info/ftp/ftp/pub/cs/theses/2007/WeiLuoPhD.pdf</url>
        <title status="complete" source="scholar.google.com">Mind change optimal learning: theory and applications</title>
        <pdf>ftp://142.58.111.31/fas-info/ftp/ftp/pub/cs/theses/2007/WeiLuoPhD.pdf</pdf>
        <author status="complete" source="scholar.google.com">W Luo</author>
        <year>2007</year>
        <source>142.58.111.31</source>
        <snippet status="partial" source="scholar.google.com">Abstract Learning theories play a significant role to machine learning as computability and complexity theories to software engineering. Gold&#39;s language learning paradigm is one cornerstone of modern learning theories. The aim of this thesis is to establish an inductive ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:AdqaxUFSDqAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:AdqaxUFSDqAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>34</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11533246138184030721&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11533246138184030721&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="22">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540103001743</url>
        <title status="complete" source="scholar.google.com">Counting extensional differences in BC-learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.97.1000&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan, SA Terwijn</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Let BC be the model of behaviourally correct function learning as introduced by Ba Ì rzdins [Theory of Algorithms and Programs, vol. 1, Latvian State University, 1974, p. 82â88] and Case and Smith [Theoret. Comput. Sci. 25 (1983) 193â220]. We introduce a mind change ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:7Abr25fIqYAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>15</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9271161862474106604&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9271161862474106604&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="23">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397511006712</url>
        <title status="complete" source="scholar.google.com">Set systems: Order types, continuous nondeterministic deformations, and quasi-orders</title>
        <pdf>http://arxiv.org/pdf/1106.5294</pdf>
        <author status="complete" source="scholar.google.com">Y Akama</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2011</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">By reformulating a learning process of a set system L as a game between Teacher and Learner, we define the order type of L to be the order type of the game tree, if the tree is well-founded. The features of the order type of L (dimL in symbol) are (1) we can represent any ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:o4rl3y2pdkQJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4933316456325941923&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4933316456325941923&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="24">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000012000876</url>
        <title status="complete" source="scholar.google.com">Learning with ordinal-bounded memory from positive data</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/bemord.pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A bounded example memory learner operates incrementally and maintains a memory of finitely many data items. The paradigm is well-studied and known to coincide with set-driven learning. A hierarchy of stronger and stronger learning criteria had earlier been obtained ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:SO2jYG0s_0kJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5332029332114369864&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="25">
        <url>http://www.iip.ist.i.kyoto-u.ac.jp/member/matthew/Sigma2_full_version.pdf</url>
        <title status="complete" source="scholar.google.com">Interpreting Learners as Realizers for Î£0</title>
        <pdf>http://www.iip.ist.i.kyoto-u.ac.jp/member/matthew/Sigma2_full_version.pdf</pdf>
        <author status="complete" source="scholar.google.com">M de Brecht, A Yamamoto</author>
        <proceeding status="complete" source="scholar.google.com">iip.ist.i.kyoto-u.ac.jp</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. We introduce the concept of a Î£0 2-admissible representation, which we then use to interpret some basic Gold-style models of inductive inference within the field of computable analysis. We interpret inductive inference problems as functions between ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:icHOhA4simwJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:icHOhA4simwJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="26">
        <url>http://unsworks.unsw.edu.au/fapi/datastream/unsworks:2490/SOURCE2</url>
        <title status="complete" source="scholar.google.com">Limiting Programs for Induction in Artificial Intelligence</title>
        <pdf>http://unsworks.unsw.edu.au/fapi/datastream/unsworks:2490/SOURCE2</pdf>
        <author status="complete" source="scholar.google.com">P Caldon</author>
        <proceeding status="complete" source="scholar.google.com">unsworks.unsw.edu.au</proceeding>
        <snippet status="partial" source="scholar.google.com">ABSTRACT. This thesis examines a novel induction-based framework for logic programming. Limiting programs are logic programs distinguished by two features, in general they contain an infinite data stream over which induction will be performed, and in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:iAv-0VdveX4J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:iAv-0VdveX4J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9113437743936834440&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="27">
        <url>http://projecteuclid.org/euclid.jsl/1245158093</url>
        <title status="complete" source="scholar.google.com">The complexity of learning SUBSEQ (A)</title>
        <author status="complete" source="scholar.google.com">S Fenner, W Gasarch, B Postow</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
        <year>2009</year>
        <source>projecteuclid.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Higman essentially showed that if A is any language then SUBSEQ (A) is regular, where SUBSEQ (A) is the language of all subsequences of strings in A. Let sâ, sâ, sâ,â¦ be the standard lexicographic enumeration of all strings over some finite alphabet. We ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:g5V9744bXBUJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1539135473371157891&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="17">
    <url>http://colt2009.cs.mcgill.ca/papers/014.pdf</url>
    <title status="complete" source="scholar.google.com">Consistent partial identification</title>
    <pdf>http://colt2009.cs.mcgill.ca/papers/014.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
    <year>2009</year>
    <source>colt2009.cs.mcgill.ca</source>
    <snippet status="partial" source="scholar.google.com">... Sanjay Jainâ and Frank Stephanâ  Department of Computer Science, National University ofSingapore, Singapore 117417 Email: sanjay@comp.nus.edu.sg and fstephan@comp.nus.edu.sg Abstract ... One âSupported in part by NUS grant number R252-000-308-112. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:xzayBPkFv3MJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:xzayBPkFv3MJ:scholar.google.com/+author:%22Jain+Sanjay%22+NUS&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <numVersions>21</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=8340391601997231815&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>3</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=8340391601997231815&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="3">
        <result id="0">
        <url>http://www.comp.nus.edu.sg/~fstephan/conservative.ps</url>
        <title status="complete" source="scholar.google.com">On Conservative Learning of Re Languages</title>
        <pdf>http://www.comp.nus.edu.sg/~fstephan/conservative.ps</pdf>
        <author status="complete" source="scholar.google.com">Z Gao, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">comp.nus.edu.sg</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract Partially conservative learning is a variant of partial learning whereby the learner, on a text for a target language L, outputs one index e with L= We infinitely often and every further hypothesis d is output only finitely often and satisfies Lâ Wd. The present paper ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GhE8Fjp-QkoJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:GhE8Fjp-QkoJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://scholarbank.nus.edu/handle/10635/34660</url>
        <title status="complete" source="scholar.google.com">Variants of Partial Learning in Inductive Inference</title>
        <pdf>http://scholarbank.nus.edu/bitstream/handle/10635/34660/test.pdf?sequence=1</pdf>
        <author status="complete" source="scholar.google.com">GAO ZIYUAN</author>
        <year>2012</year>
        <source>scholarbank.nus.edu</source>
        <snippet status="partial" source="scholar.google.com">This thesis studies several variants of partial learning under the framework of inductive inference. In particular, the following learning criteria are examined: con fident partial learning, partially conservative learning, essentially class consistent partial learning, and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:82yGne6LC9AJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14991229641594137843&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>https://www.comp.nus.edu.sg/~fstephan/confcons.ps</url>
        <title status="complete" source="scholar.google.com">Confident and Consistent Partial Learning of Recursive Functions</title>
        <pdf>https://www.comp.nus.edu.sg/~fstephan/confcons.ps</pdf>
        <author status="complete" source="scholar.google.com">Z Gao, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">comp.nus.edu.sg</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. Partial learning is a criterion where the learner infinitely often outputs one correct conjecture while every other hypothesis is issued only finitely often. This paper addresses two variants of partial learning in the setting of inductive inference of functions: first, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Av888G6XhQIJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:Av888G6XhQIJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=181717862711099138&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="18">
    <url>http://www.springerlink.com/index/q3u47561122j7n59.pdf</url>
    <title status="complete" source="scholar.google.com">Some recent results in U-shaped learning</title>
    <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1902/1/TR41-05.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Theory and Applications of Models of Computation</proceeding>
    <year>2006</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 Department of Computer Science, National University of Singapore, Singapore 117543,Republic of Singapore sanjay@comp.nus.edu.sg 2 Department of Computer Science andDepartment of Mathematics, National University of Singapore, Singapore 117543, Republic of ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:O2n5Ep7n5KgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>25</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=12170106759171107131&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>3</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=12170106759171107131&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="3">
        <result id="0">
        <url>http://www.springerlink.com/index/prebbr91cb17uenx.pdf</url>
        <title status="complete" source="scholar.google.com">Unlearning helps</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2205/1/TRA5-06.pdf</pdf>
        <author status="complete" source="scholar.google.com">G Baliga, J Case, W Merkle, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">Automata, Languages and &#8230;</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Overregularization seen in child language learning, re verb tense constructs, involves abandoning correct behaviors for incorrect ones and later reverting to correct behaviors. Quite a number of other child development phenomena also follow this U-shaped form of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Kz0TSnrOJQwJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>24</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=875332727217536299&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>20</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=875332727217536299&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540107001095</url>
        <title status="complete" source="scholar.google.com">When unlearning helps</title>
        <author status="partial" source="scholar.google.com">G Baliga, J Case, W Merkle, F Stephan&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Information and &#8230;</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Overregularization seen in child language learning, for example, verb tense constructs, involves abandoning correct behaviours for incorrect ones and later reverting to correct behaviours. Quite a number of other child development phenomena also follow this U- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:4FHwvqlchk8J:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5730369459998183904&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>18</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5730369459998183904&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <title status="complete" source="scholar.google.com">Inductive inference: theories and techniques</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:lKSmli8IdK8J:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="19">
    <url>http://www.springerlink.com/index/4H6654381W4512X6.pdf</url>
    <title status="complete" source="scholar.google.com">Robust learning of automatic classes of languages</title>
    <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/3143/1/TRA4-10.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, E Martin, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2011</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 School of Computing, National University of Singapore, Singapore 117417, Republic ofSingapore sanjay@comp.nus.edu.sg 2 School of Computer Science and Engineering, Universityof New South Wales, Sydney 2052, Australia emartin@cse.unsw.edu.au 3 Department of ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:638p0aK98c4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>22</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=14911908348191932395&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>3</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=14911908348191932395&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="3">
        <result id="0">
        <url>http://dl.comp.nus.edu.sg/dspace/handle/1900.100/3112</url>
        <title status="complete" source="scholar.google.com">On automatic families</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/3112/1/TRB1-10.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, YS Ong, S Pu, F Stephan</author>
        <year>2010</year>
        <source>dl.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract: This paper summarises previous work on automatic families. It then investigates a natural measure which exists inside every automatic family: the size of a regular language in this family is just the length of its index. This measure satisfies various properties similar to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:8apC6ZMa79sJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>20</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15847914836316039921&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15847914836316039921&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540112001137</url>
        <title status="complete" source="scholar.google.com">Automatic learning of subclasses of pattern languages</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/autopat.pdf</pdf>
        <author status="partial" source="scholar.google.com">J Case, S Jain, TD Le, YS Ong, P Semukhin&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Information and &#8230;</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Automatic classes are classes of languages for which a finite automaton can decide the membership problem for the languages in the class, in a uniform way, given an index for the language. For alphabet size of at least 4, every automatic class of erasing pattern ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:h4T-C1MLkHMJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>17</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8327168162319467655&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8327168162319467655&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/371821UW3L4225G8.pdf</url>
        <title status="complete" source="scholar.google.com">Automatic learners with feedback queries</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/autofeednew.pdf</pdf>
        <author status="partial" source="scholar.google.com">J Case, S Jain, Y Ong, P Semukhin&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Models of Computation in &#8230;</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Automatic classes are classes of languages for which a finite automaton can decide whether a given element is in a set given by its index. The present work studies the learnability of automatic families by automatic learners which, in each round, output a hypothesis and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RXW6gzjPnq0J:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12510664656516969797&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12510664656516969797&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="20">
    <url>http://www.springerlink.com/index/82329846173M8772.pdf</url>
    <title status="complete" source="scholar.google.com">One-shot learners using negative counterexamples and nearest positive examples</title>
    <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2315/1/tra3-07.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2007</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... Sanjay Jain1,â and Efim Kinber2 1 School of Computing, National University of Singapore,Singapore 117590 sanjay@comp.nus.edu.sg 2 Department of Computer Science, Sacred HeartUniversity, Fairfield, CT 06432-1000, USA kinbere@sacredheart.edu Abstract. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:70f8Jtnk5nEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>12</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=8207498992242411503&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>5</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=8207498992242411503&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="5">
        <result id="0">
        <url>http://www.springerlink.com/index/448m288387u11551.pdf</url>
        <title status="complete" source="scholar.google.com">A note on the relationship between different types of correction queries</title>
        <pdf>http://grammars.grlmc.com/grlmc/PersonalPages/cristina/Articles/A%20Note%20on%20the%20Relationship%20between%20Different%20Types%20of%20Correction%20Queries.pdf</pdf>
        <author status="complete" source="scholar.google.com">C TÃ®rnÄucÄ</author>
        <proceeding status="complete" source="scholar.google.com">Grammatical Inference: Algorithms and Applications</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The adult-child interaction which takes place during the child&#39;s language acquisition process has been the inspiration for Angluin&#39;s teacher-learner model [1], the forerunner of today&#39;s active learning field. But the initial types of queries have some drawbacks: equivalence ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:4uwNyDOPq3kJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8767258552169262306&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>16</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8767258552169262306&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.tesisenred.net/bitstream/handle/10803/8792/Thesis.pdf</url>
        <title status="complete" source="scholar.google.com">Language Learning with Correction Queries</title>
        <pdf>http://www.tesisenred.net/bitstream/handle/10803/8792/Thesis.pdf</pdf>
        <author status="complete" source="scholar.google.com">C TËÄ±rnauca</author>
        <year>2009</year>
        <source>tesisenred.net</source>
        <snippet status="partial" source="scholar.google.com">I would not be here today if it was not for my dear friend and colleague Mihai Ionescu, who persuaded me to continue my studies and to enroll in a PhD program in Tarragona. Also, I would like to address my gratitude to my mother, first of all, for raising me the way she did, ...</snippet>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:kvw1EEn1D8AJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13839549874086214802&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397509006318</url>
        <title status="complete" source="scholar.google.com">Necessary and sufficient conditions for learning with correction queries</title>
        <author status="complete" source="scholar.google.com">C TÃ®rnÄucÄ, S Kobayashi</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2009</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We investigate the newly introduced model of learning with correction queries in the context of query learning. We present necessary and sufficient conditions for a class of languages to be inferable within this setting. We also offer a complete picture of how is the model of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:KfPGJVWwbwoJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=752013542546666281&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=752013542546666281&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.tdx.cat/handle/10803/8792</url>
        <title status="complete" source="scholar.google.com">Language learning with correction queries</title>
        <pdf>http://www.tdx.cat/bitstream/handle/10803/8792/Thesis.pdf.txt?sequence=2</pdf>
        <author status="complete" source="scholar.google.com">C Tirnauca</author>
        <year>2009</year>
        <source>tdx.cat</source>
        <snippet status="partial" source="scholar.google.com">In the field of grammatical inference, the goal of any learning algorithm is to identify a target concept from a given class by having access to a specific type of information. The main learning settings are Gold&#39;s model of learning in the limit and Angluin&#39;s query learning. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:vPYbLipk9tIJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15201447724560676540&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15201447724560676540&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397509001674</url>
        <title status="complete" source="scholar.google.com">One-shot learners using negative counterexamples and nearest positive examples</title>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2009</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">As some cognitive research suggests, in the process of learning languages, in addition to overt explicit negative evidence, a child often receives covert explicit evidence in form of corrected or rephrased sentences. In this paper, we suggest one approach to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:r9OMYh_KopUJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10782402694024582063&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="21">
    <url>http://www.springerlink.com/index/x8jvrne9hhf37f3y.pdf</url>
    <title status="complete" source="scholar.google.com">Learning languages from positive data and a finite number of queries</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.104.362&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
    <proceeding status="partial" source="scholar.google.com">FSTTCS 2004: Foundations of Software Technology &#8230;</proceeding>
    <year>2005</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... Sanjay Jain1,â and Efim Kinber2 1 School of Computing, National University of Singapore,Singapore 117543 sanjay@comp.nus.edu.sg 2 Department of Computer Science, Sacred HeartUniversity, Fairfield, CT 06432-1000 USA kinbere@sacredheart.edu Abstract. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:uaRWKzH8L68J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>11</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=12623585568653485241&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>4</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=12623585568653485241&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="4">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540105001379</url>
        <title status="complete" source="scholar.google.com">Relations between Gold-style learning and query learning</title>
        <pdf>http://www2.cs.uregina.ca/~zilles/langeZ05queries.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2005</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Different formal learning models address different aspects of human learning. Below we compare Gold-style learningâmodelling learning as a limiting process in which the learner may change its mind arbitrarily often before converging to a correct hypothesisâto ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:rNC7VkEdryUJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2715421266792927404&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>15</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2715421266792927404&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S030439750700549X</url>
        <title status="complete" source="scholar.google.com">A general comparison of language learning from examples and from queries</title>
        <pdf>http://pdf.aminer.org/000/235/383/inductive_learning_of_recurrence_term_languages_from_positive_data.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, S Lange, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In language learning, strong relationships between Gold-style models and query models have recently been observed: in some quite general setting Gold-style learners can be replaced by query learners and vice versa, without loss of learning capabilities. These &#39; ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:KrySs3uRs9AJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15038523541199961130&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15038523541199961130&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/1xtm4b75003x05n2.pdf</url>
        <title status="complete" source="scholar.google.com">Gold-style and query learning under various constraints on the target class</title>
        <pdf>http://webdocs.cs.ualberta.ca/~zilles/jainLZ05queries.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, S Lange, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In language learning, strong relationships between Gold-style models and query models have recently been observed: in some quite general setting Gold-style learners can be replaced by query learners and vice versa, without loss of learning capabilities. These &#39; ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:4j9bAmkZKv0J:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18242421179419410402&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18242421179419410402&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.118.7824&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">NEGATIVE DATA IN LEARNING LANGUAGES</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.118.7824&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S JAIN, E KINBER</author>
        <proceeding status="partial" source="scholar.google.com">Mathematical Logic in Asia: Proceedings of the 9th &#8230;</proceeding>
        <year>2006</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">The paper is a survey of recent results on algorithmic learning (inductive inference) of languages from full collection of positive examples and some negative data. Different types of negative data are considered. We primarily concentrate on learning using (1) carefully ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:xhc83r1kuQwJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:xhc83r1kuQwJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=916874765786683334&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="22">
    <url>http://www.springerlink.com/index/5n75eb1v97fxh6qq.pdf</url>
    <title status="complete" source="scholar.google.com">Robust LearningâRich and Poor</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.36.2906&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan, R Wiehagen</author>
    <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
    <year>2001</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 Computer and Information Sciences Department, University of Delaware, Newark, DE 19716,USA, case@cis.udel.edu 2 School of Computing, National University of Singapore, Singapore119260, sanjay@comp.nus.edu.sg 3 Mathematisches Institut, Im Neuenheimer Feld ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:6-x8KxzTtaYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>21</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=12012739699022818539&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>4</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=12012739699022818539&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="4">
        <result id="0">
        <url>http://www.comp.nus.edu.sg/~sanjay/paps/robsur.pdf</url>
        <title status="complete" source="scholar.google.com">A tour of robust learning</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/robsur.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; and Models. Perspectives East and West. &#8230;</proceeding>
        <year>2003</year>
        <source>comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract BarzdinÅ¡ conjectured that only recursively enumerable classes of functions can be learned robustly. This conjecture, which was finally refuted by Fulk, initiated the study of notions of robust learning. The present work surveys research on robust learning and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:OhqoyUDoLugJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:OhqoyUDoLugJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16730565030686759482&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16730565030686759482&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/l5rax18a05jhx5br.pdf</url>
        <title status="complete" source="scholar.google.com">Learning all subfunctions of a function</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/subex.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory and Kernel Machines</proceeding>
        <year>2003</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Sublearning, a model for learning of subconcepts of a concept, is presented. Sublearning a class of total recursive functions informally means to learn all functions from that class together with all of their subfunctions. While in language learning it is known to be ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FXBRXtWXmCoJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3069370088719216661&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.comp.nus.edu.sg/~sanjay/paps/robsur-c.pdf</url>
        <title status="complete" source="scholar.google.com">A Survey of Robust Learning</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/robsur-c.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <year>2008</year>
        <source>comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract. A class of objects is said to be robustly learnable if not only this class itself is learnable but all of its computable âtransformationsâ are also learnable. We study robust learning within the framework of inductive inference. A class of recursive functions is said ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:td7IYjEIaMwJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:td7IYjEIaMwJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14729031589518958261&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=NFu8uP4GqykC&amp;oi=fnd&amp;pg=PA215&amp;ots=-bzu6hPTwH&amp;sig=so6hkByE0Ata3Og_03Dn8nSrePI</url>
        <title status="complete" source="scholar.google.com">A TOUR OF ROBUST LEARNING</title>
        <author status="complete" source="scholar.google.com">F Stephant</author>
        <proceeding status="partial" source="scholar.google.com">Computability and Models: Perspectives East and &#8230;</proceeding>
        <year>2003</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">Abstract BarzdinS conjectured that only recursively enumerable classes of functions can be learned robustly. This conjecture, which was finally refuted by Fulk, initiated the study of notions of robust learning. The present work surveys research on robust learning and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:m5TegYY-cQwJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="23">
    <url>http://www.springerlink.com/index/4b58j4ktgql69ylf.pdf</url>
    <title status="complete" source="scholar.google.com">Learning a subclass of regular patterns in polynomial time</title>
    <pdf>http://cs5235.userapi.com/u133638729/docs/0b3b37a51a80/Ricard_Gavald_Algorithmic_Learning_Theory_14_co.pdf#page=234</pdf>
    <author status="partial" source="scholar.google.com">J Case, S Jain, R Reischuk, F Stephan&#8230;</author>
    <proceeding status="partial" source="scholar.google.com">Algorithmic Learning &#8230;</proceeding>
    <year>2003</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... of Computer and Information Sciences, University of Delaware, Newark, DE 19716-2586, USAcase@cis.udel.edu 2 School of Computing, National University of Singapore, Singapore 117543sanjay@comp.nus.edu.sg 3 Institute for Theoretical Informatics, University at LÃ¼beck ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:5fXE9S8QnLgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>6</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=13302525197518435813&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>5</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=13302525197518435813&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="5">
        <result id="0">
        <url>http://www.springerlink.com/index/K60N8248P560R675.pdf</url>
        <title status="complete" source="scholar.google.com">An experiment with association rules and classification: Post-bagging and conviction</title>
        <pdf>http://repositorium.sdum.uminho.pt/bitstream/1822/4295/1/ds05_final.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Jorge, P Azevedo</author>
        <proceeding status="complete" source="scholar.google.com">Discovery science</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. In this paper we study a new technique we call post-bagging, which consists in resampling parts of a classification model rather then the data. We do this with a particular kind of model: large sets of classification association rules, and in combination with ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:owHsaZD6amoJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7668216813710999971&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>16</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7668216813710999971&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/F0315154612W2R02.pdf</url>
        <title status="complete" source="scholar.google.com">Measuring over-generalization in the minimal multiple generalizations of biosequences</title>
        <pdf>http://kalngyk.zymichost.com/pub/ds2005.pdf</pdf>
        <author status="complete" source="scholar.google.com">Y Ng, H Ono, T Shinohara</author>
        <proceeding status="complete" source="scholar.google.com">Discovery Science</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. We consider the problem of finding a set of patterns that best characterizes a set of strings. To this end, Arimura et. al.[3] considered the use of minimal multiple generalizations (mmg) for such characterizations. Given any sample set, the mmgs are, roughly speaking, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:gFQhOgA9fH4J:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9114226817075598464&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9114226817075598464&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.tesisenred.net/bitstream/handle/10803/8792/Thesis.pdf</url>
        <title status="complete" source="scholar.google.com">Language Learning with Correction Queries</title>
        <pdf>http://www.tesisenred.net/bitstream/handle/10803/8792/Thesis.pdf</pdf>
        <author status="complete" source="scholar.google.com">C TËÄ±rnauca</author>
        <year>2009</year>
        <source>tesisenred.net</source>
        <snippet status="partial" source="scholar.google.com">I would not be here today if it was not for my dear friend and colleague Mihai Ionescu, who persuaded me to continue my studies and to enroll in a PhD program in Tarragona. Also, I would like to address my gratitude to my mother, first of all, for raising me the way she did, ...</snippet>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:kvw1EEn1D8AJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13839549874086214802&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.tdx.cat/handle/10803/8792</url>
        <title status="complete" source="scholar.google.com">Language learning with correction queries</title>
        <pdf>http://www.tdx.cat/bitstream/handle/10803/8792/Thesis.pdf.txt?sequence=2</pdf>
        <author status="complete" source="scholar.google.com">C Tirnauca</author>
        <year>2009</year>
        <source>tdx.cat</source>
        <snippet status="partial" source="scholar.google.com">In the field of grammatical inference, the goal of any learning algorithm is to identify a target concept from a given class by having access to a specific type of information. The main learning settings are Gold&#39;s model of learning in the limit and Angluin&#39;s query learning. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:vPYbLipk9tIJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15201447724560676540&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15201447724560676540&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://wwwhome.math.utwente.nl/~mantheyb/misc/FocusMUL_TCS_MantheyEA.pdf</url>
        <title status="complete" source="scholar.google.com">Institut fur Theoretische Informatik: Theoretische Informatik und das Problem des Handlungsreisenden</title>
        <pdf>http://wwwhome.math.utwente.nl/~mantheyb/misc/FocusMUL_TCS_MantheyEA.pdf</pdf>
        <author status="complete" source="scholar.google.com">B Manthey, J Arpe, A Jakoby, R Reischuk</author>
        <proceeding status="complete" source="scholar.google.com">wwwhome.math.utwente.nl</proceeding>
        <snippet status="partial" source="scholar.google.com">KomplexitÃ¤tstheorie Die KomplexitÃ¤tstheorie beschÃ¤ftigt sich mit der Frage, wie viel Ressourcen, wie z. B. Rechenzeit oder Speicherplatz, notwendig sind, um ein bestimmtes Problem zu lÃ¶sen. Ziel sind einerseits positive Aussagen, dass ein Problem schnell oder ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:OaY26Ix8nDEJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:OaY26Ix8nDEJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3574869148858492473&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="24">
    <url>http://www.springerlink.com/index/3u7121w65176281t.pdf</url>
    <title status="complete" source="scholar.google.com">Learning correction grammars</title>
    <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain</author>
    <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
    <year>2007</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... unisi.it 2 Department of Computer and Information Sciences, University of Delaware, Newark,DE 19716-2586, USA case@cis.udel.edu 3 Department of Computer Science, National Universityof Singapore, Singapore 117543, Republic of Singapore sanjay@comp.nus.edu.sg ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:WspX_CCq1PEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>3</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=17425739916852578906&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>4</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=17425739916852578906&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="4">
        <result id="0">
        <url>http://dl.comp.nus.edu.sg/dspace/handle/1900.100/3042</url>
        <title status="complete" source="scholar.google.com">Turing degrees and the Ershov hierarchy</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/3042/1/TRC6-09.pdf</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, Y Yang, L Yu</author>
        <year>2009</year>
        <source>dl.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract: An nr. e. set can be defined as the symmetric difference of n recursively enumerable sets. The classes of these sets form a natural hierarchy which became a well-studied topic in recursion theory. In a series of ground-breaking papers, Ershov ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:dsqImiE0SQYJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>22</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=452950556458666614&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=452950556458666614&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://projecteuclid.org/euclid.jsl/1243948324</url>
        <title status="complete" source="scholar.google.com">Learning correction grammars</title>
        <pdf>https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2307/1/TR12-06.pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
        <year>2009</year>
        <source>projecteuclid.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract We investigate a new paradigm in the context of learning in the limit, namely, learning correction grammars for classes of computably enumerable (ce) languages. Knowing a language may feature a representation of it in terms of two grammars. The ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:0zSN0GENz58J:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11515437485971551443&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11515437485971551443&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/e260l7477q204851.pdf</url>
        <title status="complete" source="scholar.google.com">Incremental learning with ordinal bounded example memory</title>
        <author status="complete" source="scholar.google.com">L Carlucci</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A Bounded Example Memory learner is a learner that operates incrementally and maintains a memory of finitely many data items. The paradigm is well-studied and known to coincide with set-driven learning. A hierarchy of stronger and stronger learning criteria is obtained ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:IH0StlGWmHwJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8978091134854266144&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8978091134854266144&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://scholarbank.nus.edu/handle/10635/34660</url>
        <title status="complete" source="scholar.google.com">Variants of Partial Learning in Inductive Inference</title>
        <pdf>http://scholarbank.nus.edu/bitstream/handle/10635/34660/test.pdf?sequence=1</pdf>
        <author status="complete" source="scholar.google.com">GAO ZIYUAN</author>
        <year>2012</year>
        <source>scholarbank.nus.edu</source>
        <snippet status="partial" source="scholar.google.com">This thesis studies several variants of partial learning under the framework of inductive inference. In particular, the following learning criteria are examined: con fident partial learning, partially conservative learning, essentially class consistent partial learning, and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:82yGne6LC9AJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14991229641594137843&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="25">
    <url>http://www.sciencedirect.com/science/article/pii/0020019093902293</url>
    <title status="complete" source="scholar.google.com">On the non-existence of maximal inference degrees for language identification</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/querylang.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
    <proceeding status="complete" source="scholar.google.com">Information Processing Letters</proceeding>
    <year>1993</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... Science, National University of Singapore, Heng Miu Keng Terrace, Kent Ridge,Singapore 0511, Singapore. Email: sanjay@iss.nus.sg. 0020-0190/93/$06.00 (01993 - Elsevier Science Publishers BV All rights reserved 81 ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:bkBrH4fYB0oJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>8</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=5334470358502948974&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>19</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=5334470358502948974&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="19">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/0168007294900353</url>
        <title status="complete" source="scholar.google.com">Extremes in the degrees of inferability</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.97.4123&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="partial" source="scholar.google.com">L Fortnow, W Gasarch, S Jain, E Kinber&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Annals of pure and &#8230;</proceeding>
        <year>1994</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Abstract Most theories of learning consider inferring a function f from either (1) observations about f or,(2) questions about f. We consider a scenario whereby the learner observes f and asks queries to some set A. If I is a notion of learning then I [A] is the set of concept classes ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ySVA1E3gAEIJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>43</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4756047831381321161&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>52</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4756047831381321161&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://dl.acm.org/citation.cfm?id=168319</url>
        <title status="complete" source="scholar.google.com">On the structure of degrees of inferability</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.1414&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">M Kummer, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the sixth annual conference on &#8230;</proceeding>
        <year>1993</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">We consider learning of classes of recursive functions within the framework of inductive inference[17]. A recent theme M the study of inductive inference machines with oracles [6, 8, 9, 10, 1.5. 18] The basic questllon is how the Information content of the oracle (technically: ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:YS3k5FN4VhwJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>35</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2041951782776876385&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>47</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2041951782776876385&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540107000491</url>
        <title status="complete" source="scholar.google.com">Results on memory-limited U-shaped learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.8567&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">U-shaped learning is a learning behaviour in which the learner first learns a given target behaviour, then unlearns it and finally relearns it. Such a behaviour, observed by psychologists, for example, in the learning of past-tenses of English verbs, has been ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:aPOveNlKjhoJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>23</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1913549189572195176&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>21</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1913549189572195176&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/78867137810P8066.pdf</url>
        <title status="complete" source="scholar.google.com">Learning with higher order additional information</title>
        <author status="complete" source="scholar.google.com">G Baliga, J Case</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1994</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">[Go167] studied, among other things, algorithmic learning (in the limit) of deci- sion procedures for languages given informants, ie, given enumerations of the characteristic functions of the languages. [FW79] shows that learning power is increased if, in addition to the informants, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:eFGnga8zZ4AJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9252420788343492984&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9252420788343492984&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <title status="complete" source="scholar.google.com">A survey of inductive inference with an emphasis on queries</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.33.5664&amp;rep=rep1&amp;type=pdf</pdf>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GnKgfqPifP0J:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18265723380539879962&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18265723380539879962&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://dl.acm.org/citation.cfm?id=168318</url>
        <title status="complete" source="scholar.google.com">On probably correct classification of concepts</title>
        <pdf>http://www.princeton.edu/~kulkarni/Papers/Conferences/c1993_kz_colt.pdf</pdf>
        <author status="complete" source="scholar.google.com">SR Kulkarni, O Zeitouni</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the sixth annual conference on &#8230;</proceeding>
        <year>1993</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract We consider the problem of classifying an unknown concept into one of two subclasses of concepts. Specifically, if C is a concept class and Co and Cl are two disjoint subsets of C, given an unknown c E Co U Cl we wish to decide whether cc Co or c E Cl ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:U3Zggq0wGmQJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7213131274962105939&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7213131274962105939&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540103000828</url>
        <title status="complete" source="scholar.google.com">Learning by switching type of information</title>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present work is dedicated to the study of modes of data-presentation in the range between text and informant within the framework of inductive inference. In this study, the learner alternatingly requests sequences of positive and negative data. We define various ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:T69CcuOiZkMJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4856748345923907407&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4856748345923907407&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000006000912</url>
        <title status="complete" source="scholar.google.com">On the learnability of vector spaces</title>
        <pdf>http://home.gwu.edu/~harizanv/LearningVectorSpaces.pdf</pdf>
        <author status="complete" source="scholar.google.com">VS Harizanov, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The central topic of the paper is the learnability of the recursively enumerable subspaces of Vâ/V, where Vâ is the standard recursive vector space over the rationals with (countably) infinite dimension and V is a given recursively enumerable subspace of Vâ. It is shown ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:vAJdKbhcpJQJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10710787759831581372&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10710787759831581372&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://cmsassets.comp.nus.edu.sg/~fstephan/recursiontheory-pstopdf.pdf</url>
        <title status="complete" source="scholar.google.com">Recursion theory</title>
        <pdf>http://cmsassets.comp.nus.edu.sg/~fstephan/recursiontheory-pstopdf.pdf</pdf>
        <author status="complete" source="scholar.google.com">F Stephan</author>
        <year>2009</year>
        <source>cmsassets.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Recursion theory deals with the fundamental concepts on what subsets of natural numbers (or other famous countable domains) could be defined effectively and how complex the so defined sets are. The basic concept are the recursive and recursively enumerable sets, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:xNz4ZeWWl9QJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:xNz4ZeWWl9QJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>27</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15318878569526516932&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15318878569526516932&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.springerlink.com/index/vg7tbegp60j98yac.pdf</url>
        <title status="complete" source="scholar.google.com">On the learnability of vector spaces</title>
        <pdf>http://home.gwu.edu/~harizanv/LearningWithStephanJournal.pdf</pdf>
        <author status="complete" source="scholar.google.com">V Harizanov, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2002</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The central topic of the paper is the learnability of the recursively enumerable subspaces of Vâ/V, where Vâ is the standard recursive vector space over the rationals with countably infinite dimension, and V is a given recursively enumerable subspace of Vâ. It is shown ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:fNrxctUkabMJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12927904704518806140&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12927904704518806140&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397502008149</url>
        <title status="complete" source="scholar.google.com">Learning power and language expressiveness</title>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The topic of the present work is to study the relationship between the power of the learning algorithms on the one hand, and the expressive power of the logical language which is used to represent the problems to be learned on the other hand. The central question is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:houbhlhcZq0J:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12494775751471238022&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12494775751471238022&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://www.springerlink.com/index/M27215M428216111.pdf</url>
        <title status="complete" source="scholar.google.com">The complexity of universal text-learners</title>
        <author status="complete" source="scholar.google.com">F Stephan, S Terwijn</author>
        <proceeding status="complete" source="scholar.google.com">Fundamentals of Computation Theory</proceeding>
        <year>1997</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The present work deals with language learning from text. It considers universal learners for classes of languages in models of additional information and analyzes their complexity in terms of Turing degrees. The following is shown: If the additional information is given by a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:wMeB2r6meDkJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4141243196007106496&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4141243196007106496&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <url>http://www.springerlink.com/index/KUY6NRGG7E72T9R4.pdf</url>
        <title status="complete" source="scholar.google.com">Learning by switching type of information</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.8.2370&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The present work is dedicated to the study of modes of datapresentation between text and informant within the framework of inductive inference. The model is such that the learner requests sequences of positive andnegativ e data andthe relations between the various ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RIi4rBN__vcJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17869860093931587652&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17869860093931587652&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="13">
        <url>http://dl.comp.nus.edu.sg/dspace/handle/1900.100/1903</url>
        <title status="complete" source="scholar.google.com">Memory-Limited U-Shaped Learning</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1903/1/tr51-05.pdf</pdf>
        <author status="complete" source="scholar.google.com">L CARLUCCI, J CASE, S JAIN, F STEPHAN</author>
        <year>2005</year>
        <source>dl.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract: U-shaped learning is a learning behaviour in which the learner first learns something, then unlearns it and finally relearns it. Such a behaviour, observed by psychologists, for example, in the learning of past-tenses of English verbs, has been ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2QKGOB0_q7AJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12730338166427747033&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12730338166427747033&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="14">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540199928043</url>
        <title status="complete" source="scholar.google.com">The complexity of universal text-learners</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.40.8223&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, SA Terwijn</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>1999</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present work deals with language learning from text. It considers universal learners for classes of languages in models of additional information and analyzes their complexity in terms of Turing degrees. The following is shown: If the additional information is given by a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:HcrHXJzLv5AJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10430279134445292061&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10430279134445292061&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="15">
        <url>http://www.springerlink.com/index/T448G2083421512J.pdf</url>
        <title status="complete" source="scholar.google.com">Input-Dependence in Function-Learning</title>
        <author status="complete" source="scholar.google.com">S Jain, E Martin, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theory of Computing Systems</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract In the standard model of inductive inference, a learner gets as input the graph of a function, and has to discover (in the limit) a program for the function. In this paper, we consider besides the graph also other modes of input such as the complement of the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:f-T8tNbGjGkJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7605672496183698559&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="16">
        <url>http://www.springerlink.com/index/63mdygem6382h1gf.pdf</url>
        <title status="complete" source="scholar.google.com">Identifying clusters from positive data</title>
        <author status="partial" source="scholar.google.com">J Case, S Jain, E Martin, A Sharma&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; Inference: Algorithms and &#8230;</proceeding>
        <year>2004</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The present work studies clustering from an abstract point of view and investigates its properties in the framework of inductive inference. Any class S considered is given by a numbering A 0, A 1,... of nonempty subsets of â or â k which is also used as a hypothesis ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:0HVe3V8fkkIJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4796931049699309008&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="17">
        <url>http://epubs.siam.org/doi/abs/10.1137/050629112</url>
        <title status="complete" source="scholar.google.com">Identifying Clusters from Positive Data</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/cluster.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, E Martin, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">SIAM Journal on Computing</proceeding>
        <year>2006</year>
        <source>SIAM</source>
        <snippet status="partial" source="scholar.google.com">The present work studies clustering from an abstract point of view and investigates its properties in the framework of inductive inference. Any class S considered is given by a hypothesis space, ie, numbering, A_0,A_1,... of nonempty recursively enumerable (re) ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:J3Yj85UdkaEJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>30</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11642119041595962919&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="18">
        <url>http://www.springerlink.com/index/66PQ885G78N0K742.pdf</url>
        <title status="complete" source="scholar.google.com">Input-Dependence in Function-Learning</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/cie.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Martin, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Computation and Logic in the Real World</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In the standard literature on inductive inference, a learner sees as input the course of values of the function to be learned. In the present work, it is investigated how reasonable this choice is and how sensitive the model is with respect to variations like the overgraph or ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2SOO9izoryMJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2571529192064558041&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="26">
    <url>http://dl.acm.org/citation.cfm?id=279952</url>
    <title status="complete" source="scholar.google.com">Robust learning aided by context</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/context.pdf</pdf>
    <author status="partial" source="scholar.google.com">J Case, S Jain, M Ott, A Sharma&#8230;</author>
    <proceeding status="partial" source="scholar.google.com">Proceedings of the &#8230;</proceeding>
    <year>1998</year>
    <source>dl.acm.org</source>
    <snippet status="partial" source="scholar.google.com">... Universitat Karlsruhe Singapore 119260, Republic of Singapore 76128 Karlsruhe, Germanysanjay@iscs.nus.edu.sg m-ott@ira.uka.de Arun Sharmat School of Computer Science andEngineering Frank Stephans Mathematisches Institut University of New South Wales ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:ihOGY9NnPVMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>34</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=5998064436332860298&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>19</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=5998064436332860298&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="19">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397508001400</url>
        <title status="complete" source="scholar.google.com">Learning recursive functions: A survey</title>
        <pdf>http://webdocs.cs.ualberta.ca/~zilles/zeugmannZ08survey.pdf</pdf>
        <author status="complete" source="scholar.google.com">T Zeugmann, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Studying the learnability of classes of recursive functions has attracted considerable interest for at least four decades. Starting with Gold&#39;s (1967) model of learning in the limit, many variations, modifications and extensions have been proposed. These models differ in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2f2VA5VmFfUJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17660134303999589849&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>14</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17660134303999589849&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/30508hpk5cedmc48.pdf</url>
        <title status="complete" source="scholar.google.com">Avoiding coding tricks by hyperrobust learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.133.1424&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">M Ott, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The present work introduces and justifies the notion of hyperrobust learning where one fixed learner has to learn all functions in a given class plus their images under primitive recursive operators. The following is shown: This notion of learnability does not change if the class ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:hh7HHpYQ31EJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>31</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5899452273826143878&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5899452273826143878&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000000917008</url>
        <title status="complete" source="scholar.google.com">Robust learning is rich</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.96.6122&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, C Smith, R Wiehagen</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Intuitively, a class of objects is robustly learnable if not only this class itself is learnable but all of its computable transformations remain learnable as well. In that sense, being learnable robustly seems to be a desirable property in all fields of learning. We will study this ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1RLuCKYwPi8J:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3404211858011198165&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3404211858011198165&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397501004054</url>
        <title status="complete" source="scholar.google.com">Learning classes of approximations to non-recursive functions</title>
        <pdf>http://www.mat.unisi.it/personalpages/sorbi/public_html/papers/RUSHEAD.pdf#page=53</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2002</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Blum and Blum (Inform. and Control 28 (1975) 125â155) showed that a class B of suitable recursive approximations to the halting problem K is reliably EX-learnable but left it open whether or not B is in NUM. By showing B to be not in NUM we resolve this old problem. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:keLy4mjhzZEJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>33</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10506301346325652113&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10506301346325652113&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.sciencedirect.com/science/article/pii/S030439750100086X</url>
        <title status="complete" source="scholar.google.com">Avoiding coding tricks by hyperrobust learning</title>
        <author status="complete" source="scholar.google.com">M Ott, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2002</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present work introduces and justifies the notion of hyperrobust learning where one fixed learner has to learn all functions in a given class plus their images under primitive recursive operators. The following are shown: The notion of learnability does not change if the class ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:6dr-DNkEbLMJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12928713960546294505&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12928713960546294505&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.springerlink.com/index/pn5cud3da5rgr59d.pdf</url>
        <title status="complete" source="scholar.google.com">Divide and Conquer Machine Learning for a Genomics Analogy Problem</title>
        <pdf>http://cs5594.userapi.com/u11728334/docs/5bd09dd62f02/Klaus_P_Jantke_Discovery_Science_318857.pdf#page=109</pdf>
        <author status="complete" source="scholar.google.com">M Ouyang, J Case, J Burnside</author>
        <proceeding status="complete" source="scholar.google.com">Discovery Science</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Genomic strings are not of fixed length, but provide one-dimensional spatial data that do not divide for conquering by machine learning into manageable. xed size chunks obeying Dietterich independent and identically distributed assumption. We nonetheless need to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:iRrMM52biPoJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18052850205795818121&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18052850205795818121&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000004000212</url>
        <title status="complete" source="scholar.google.com">Robust learningârich and poor</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan, R Wiehagen</author>
        <proceeding status="partial" source="scholar.google.com">Journal of Computer and System &#8230;</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A class C of recursive functions is called robustly learnable in the sense I (where I is any success criterion of learning) if not only C itself but even all transformed classes Î (C), where Î is any general recursive operator, are learnable in the sense I. It was already ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ukImu-_3fDcJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3998343178207249082&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3998343178207249082&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/EKX087X862286207.pdf</url>
        <title status="complete" source="scholar.google.com">On the uniform learnability of approximations to non-recursive functions</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/alt99sz.pdf</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Blum and Blum (1975) showed that a class BB of suitable recursive approximations to the halting problem is reliably EX-learnable. These investigations are carried on by showing that BB is neither in NUM nor robustly EX-learnable. Since the definition of the class BB is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:LOx7t0gGJBoJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>15</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1883637453533473836&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1883637453533473836&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.springerlink.com/index/5n75eb1v97fxh6qq.pdf</url>
        <title status="complete" source="scholar.google.com">Robust LearningâRich and Poor</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.36.2906&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan, R Wiehagen</author>
        <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Aclass C of recursive functions is called robustly learnable in the sense I (where I is any success criterion of learning) if not only C itself but even all transformed classes T (C) where T is any general recursive operator, are learnable in the sense I. It was already shown ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:6-x8KxzTtaYJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>21</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12012739699022818539&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12012739699022818539&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.springerlink.com/index/l5p6329uk2633r03.pdf</url>
        <title status="complete" source="scholar.google.com">Directions for computability theory beyond pure mathematical</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/rft-directions.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Mathematical problems from applied logic II</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper begins by briefly indicating the principal, non-standard motivations of the author for his decades of work in Computability Theory (CT), aka Recursive Function Theory. Then it discusses its proposed, general directions beyond those from pure mathematics for CT. These ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:BWKg2uLmRxMJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1389332872072028677&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1389332872072028677&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www.springerlink.com/index/1233111895g360t7.pdf</url>
        <title status="complete" source="scholar.google.com">Learning real polynomials with a Turing machine</title>
        <author status="complete" source="scholar.google.com">D Cheung</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We provide an algorithm to PAC learn multivariate polynomials with real coefficients. The instance space from which labeled samples are drawn is IR N but the coordinates of such samples are known only approximately. The algorithm is iterative and the main ingredient ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:9j_KUzUkmQwJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=907796611349495798&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=907796611349495798&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540104000550</url>
        <title status="complete" source="scholar.google.com">Learning all subfunctions of a function</title>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Sublearning, a model for learning of subconcepts of a concept, is presented. Sublearning a class of total recursive functions informally means to learn all functions from that class together with all of their subfunctions. While in language learning it is known to be ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:u64grAkFrAEJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=120476829132828347&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=120476829132828347&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <url>http://www.comp.nus.edu.sg/~sanjay/paps/robsur.pdf</url>
        <title status="complete" source="scholar.google.com">A tour of robust learning</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/robsur.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; and Models. Perspectives East and West. &#8230;</proceeding>
        <year>2003</year>
        <source>comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract BarzdinÅ¡ conjectured that only recursively enumerable classes of functions can be learned robustly. This conjecture, which was finally refuted by Fulk, initiated the study of notions of robust learning. The present work surveys research on robust learning and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:OhqoyUDoLugJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:OhqoyUDoLugJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16730565030686759482&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16730565030686759482&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="13">
        <url>http://projecteuclid.org/euclid.jsl/1305810752</url>
        <title status="complete" source="scholar.google.com">Robust separations in inductive inference</title>
        <author status="complete" source="scholar.google.com">M Fulk</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
        <year>2011</year>
        <source>projecteuclid.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Results in recursion-theoretic inductive inference have been criticized as depending on unrealistic self-referential examples. JM BÄrzdiÅÅ¡ proposed a way of ruling out such examples, and conjectured that one of the earliest results of inductive inference ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:VRX6dMGFfUgJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5223478208757372245&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5223478208757372245&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="14">
        <url>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/doitr166sz.ps.gz</url>
        <title status="complete" source="scholar.google.com">DOI Technical Report</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/doitr166sz.ps.gz</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, T Zeugmann</author>
        <year>1999</year>
        <source>www-alg.ist.hokudai.ac.jp</source>
        <snippet status="complete" source="scholar.google.com">Abstract Blum and Blum (1975) showed that a class B of suitable recursive approximations to the halting problem K is reliably EX-learnable but left it open whether or not B is in NUM. By showing B to be not in NUM we resolve this old problem.</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ypBkC6zAZg8J:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:ypBkC6zAZg8J:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="15">
        <url>http://www.springerlink.com/index/l5rax18a05jhx5br.pdf</url>
        <title status="complete" source="scholar.google.com">Learning all subfunctions of a function</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/subex.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory and Kernel Machines</proceeding>
        <year>2003</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Sublearning, a model for learning of subconcepts of a concept, is presented. Sublearning a class of total recursive functions informally means to learn all functions from that class together with all of their subfunctions. While in language learning it is known to be ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FXBRXtWXmCoJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3069370088719216661&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="16">
        <url>http://www.comp.nus.edu.sg/~sanjay/paps/robsur-c.pdf</url>
        <title status="complete" source="scholar.google.com">A Survey of Robust Learning</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/robsur-c.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <year>2008</year>
        <source>comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract. A class of objects is said to be robustly learnable if not only this class itself is learnable but all of its computable âtransformationsâ are also learnable. We study robust learning within the framework of inductive inference. A class of recursive functions is said ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:td7IYjEIaMwJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:td7IYjEIaMwJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14729031589518958261&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="17">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=NFu8uP4GqykC&amp;oi=fnd&amp;pg=PA215&amp;ots=-bzu6hPVuK&amp;sig=jP0ZdYARDw6R7i-_teu6Qow8kJ4</url>
        <title status="complete" source="scholar.google.com">A TOUR OF ROBUST LEARNING</title>
        <author status="complete" source="scholar.google.com">F Stephant</author>
        <proceeding status="partial" source="scholar.google.com">Computability and Models: Perspectives East and &#8230;</proceeding>
        <year>2003</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">Abstract BarzdinS conjectured that only recursively enumerable classes of functions can be learned robustly. This conjecture, which was finally refuted by Fulk, initiated the study of notions of robust learning. The present work surveys research on robust learning and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:m5TegYY-cQwJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="18">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.6279&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Robust LearningâRich and Poor</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.6279&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">JCS Jainb, F Stephanc, R Wiehagend</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract A class C of recursive functions is called robustly learnable in the sense I (where I is any success criterion of learning) if not only C itself but even all transformed classes Î (C) where Î is any general recursive operator, are learnable in the sense I. It was already ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:F-gF6cXSbSAJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:F-gF6cXSbSAJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2336755529135024151&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="27">
    <url>http://dl.acm.org/citation.cfm?id=238061.238090</url>
    <title status="complete" source="scholar.google.com">Synthesizing enumeration techniques for language learning</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.54.6728&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">GR Baliga, J Case, S Jain</author>
    <proceeding status="partial" source="scholar.google.com">Proceedings of the ninth annual conference &#8230;</proceeding>
    <year>1996</year>
    <source>dl.acm.org</source>
    <snippet status="partial" source="scholar.google.com">... Rowan College of New Jersey University of Delaware National University of Singapore MullicaHill, NJ 08024, USA Newark, DE 19716, USA Singapore (Email: baliga@gboro,rowan. edu)(Email: case@ cis,udel.edu) (Email: sanjay@iscs.nus. sg) Abstract ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:9SeZaVkkkuUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>17</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=16542324347727587317&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>19</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=16542324347727587317&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="19">
        <result id="0">
        <url>http://epubs.siam.org/doi/pdf/10.1137/S0097539793249694</url>
        <title status="complete" source="scholar.google.com">The power of vacillation in language learning</title>
        <pdf>http://dare.uva.nl/document/1137</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">SIAM Journal on Computing</proceeding>
        <year>1999</year>
        <source>SIAM</source>
        <snippet status="partial" source="scholar.google.com">Some extensions are considered of Gold&#39;s influential model of language learning by machine from positive data. Studied are criteria of successful learning featuring convergence in the limit to vacillation between several alternative correct grammars. The ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:iB0Rc-7Qrq0J:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>23</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12515170137060482440&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>82</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12515170137060482440&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540198927821</url>
        <title status="complete" source="scholar.google.com">The synthesis of language learners</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.2144&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">GR Baliga, J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>1999</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">An index for an re class of languages (by definition) is a procedure which generates a sequence of grammars defining the class. An index for an indexed family of languages (by definition) is a procedure which generates a sequence of decision procedures defining ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Bgc6-PuulWUJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7319949166585186054&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>28</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7319949166585186054&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397500002723</url>
        <title status="complete" source="scholar.google.com">Learning algebraic structures from text</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.41.615&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, Y Ventsov</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present work investigates the learnability of classes of substructures of some algebraic structures: submonoids and subgroups of given groups, ideals of given commutative rings, subfields of given vector spaces. The learner sees all positive data but no negative one ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:pOAgDmnQfi8J:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3422401916475334820&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>23</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3422401916475334820&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/NYRGBXAELWDDY9C7.pdf</url>
        <title status="complete" source="scholar.google.com">A negative result on inductive inference of extended pattern languages</title>
        <pdf>https://dspace.lboro.ac.uk/dspace-jspui/bitstream/2134/3471/1/reidenbach_alt02.pdf</pdf>
        <author status="complete" source="scholar.google.com">D Reidenbach</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2002</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The question of learnability of the class of extended pattern languages is considered to be one of the eldest and outstanding open problems in inductive inference of formal languages. This paper provides an appropriate answer presenting a subclass-the terminal-free ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:yBulyWkO2EwJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5537191589369420744&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>23</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5537191589369420744&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/BN4WUBDWE0233BPV.pdf</url>
        <title status="complete" source="scholar.google.com">Synthesizing learners tolerating computable noisy data</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/nrec.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1998</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">An index for an re class of languages (by definition) generates a sequence of grammars defining the class. An index for an indexed family of languages (by definition) generates a sequence of decision procedures defining the family. F. Stephan&#39;s model of noisy data is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:NQuQP4PCMXcJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8588859833335155509&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8588859833335155509&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.springerlink.com/index/746143G84P1761X0.pdf</url>
        <title status="complete" source="scholar.google.com">Vacillatory and BC learning on noisy data</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.1104&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1996</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In an earlier paper, Frank Stephan introduced a form of noisy data which nonetheless uniquely determines the true data: correct information occurs infinitely often while incorrect information occurs only finitely often. The present paper considers the effects of this form ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:DwzAHopQyuMJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16414020346056805391&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16414020346056805391&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.springerlink.com/index/037l58m020020m31.pdf</url>
        <title status="complete" source="scholar.google.com">Synthesizing noise-tolerant language learners</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.114.3595&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1997</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">An index for an re class of languages (by definition) generates a sequence of grammars defining the class. An index for an indexed family of languages (by definition) generates a sequence of decision procedures defining the family. F. Stephan&#39;s model of noisy data is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:87KSL3z6TQYJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=454294548715320051&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=454294548715320051&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.tandfonline.com/doi/abs/10.1080/09528130119716</url>
        <title status="complete" source="scholar.google.com">On the role of search for learning from examples</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.36.230&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">SA Kurtz, CH Smith, R Wiehagen</author>
        <proceeding status="partial" source="scholar.google.com">Journal of Experimental &amp; &#8230;</proceeding>
        <year>2001</year>
        <source>Taylor &amp; Francis</source>
        <snippet status="partial" source="scholar.google.com">Gold (1967) discovered a fundamental enumeration technique, the socalled identification-by-enumeration, a simple but powerful class of algorithms for learning from examples (inductive inference). We introduce a variety of more sophisticated (and more powerful) enumeration ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:7826UNEm518J:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6910534833667755503&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6910534833667755503&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397500001328</url>
        <title status="complete" source="scholar.google.com">Synthesizing noise-tolerant language learners</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">An index for an re class of languages (by definition) generates a sequence of grammars defining the class. An index for an indexed family of languages (by definition) generates a sequence of decision procedures defining the family. F. Stephan&#39;s model of noisy data is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:kQjLOj-Cp0IJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4802950735694858385&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4802950735694858385&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.springerlink.com/index/19159n6c37lb7fn9.pdf</url>
        <title status="complete" source="scholar.google.com">On the synthesis of strategies identifying recursive functions</title>
        <pdf>http://www2.cs.uregina.ca/~zilles/zilles01colt.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A classical learning problem in Inductive Inference consists of identifying each function of a given class of recursive functions from a finite number of its output values. Uniform learning is concerned with the design of single programs solving infinitely many classical learning ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:VMY0UNoA_msJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7781658143791302228&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7781658143791302228&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397599002686</url>
        <title status="complete" source="scholar.google.com">Vacillatory and BC learning on noisy data</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2000</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present work employs a model of noise introduced earlier by the third author. In this model noisy data nonetheless uniquely determines the true data: correct information occurs infinitely often while incorrect information occurs only finitely often. The present paper ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:f2xw58_6_98J:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16140895360367225983&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16140895360367225983&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://www.springerlink.com/index/n8rfuueg4ytgbeg5.pdf</url>
        <title status="complete" source="scholar.google.com">On the comparison of inductive inference criteria for uniform learning of finite classes</title>
        <pdf>http://cs5824.userapi.com/u11728334/docs/20e8cf4a8295/Naoki_Abe_Algorithmic_Learning_Theory_12_conf_A.pdf#page=260</pdf>
        <author status="complete" source="scholar.google.com">S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We consider a learning model in which each element of a class of recursive functions is to be identified in the limit by a computable strategy. Given gradually growing initial segments of the graph of a function, the learner is supposed to generate a sequence of hypotheses ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:-wk6JIpicNgJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15596073855036819963&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15596073855036819963&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <url>http://webdocs.cs.ualberta.ca/~zilles/zilles00TRuniform.pdf</url>
        <title status="complete" source="scholar.google.com">On Uniform Learning of Classes of Recursive Functions</title>
        <pdf>http://webdocs.cs.ualberta.ca/~zilles/zilles00TRuniform.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Zilles</author>
        <year>2000</year>
        <source>webdocs.cs.ualberta.ca</source>
        <snippet status="partial" source="scholar.google.com">Abstract A classical learning problem in inductive inference consists of identifying each function of a given class of recursive functions from a finite number of its output values. Uniform learning is concerned with the design of single programs solving infinitely many ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:xRybFOmxhVMJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:xRybFOmxhVMJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6018412091681742021&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6018412091681742021&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="13">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397599002698</url>
        <title status="complete" source="scholar.google.com">Learning languages and functions by erasing</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.33.6746&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="partial" source="scholar.google.com">S Jain, E Kinber, S Lange, R Wiehagen&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Theoretical computer &#8230;</proceeding>
        <year>2000</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Learning by erasing means the process of eliminating potential hypotheses from further consideration thereby converging to the least hypothesis never eliminated. This hypothesis must be a solution to the actual learning problem. The capabilities of learning by erasing ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:HTriKiOK64cJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>16</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9794073698295233053&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9794073698295233053&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="14">
        <url>http://dl.acm.org/citation.cfm?id=307448</url>
        <title status="complete" source="scholar.google.com">Extensional set learning</title>
        <pdf>http://www.math.ru.nl/~terwijn/publications/recBC.pdf</pdf>
        <author status="complete" source="scholar.google.com">SA Terwijn</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the twelfth annual conference on &#8230;</proceeding>
        <year>1999</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract We investigate the model recBC of learning of re sets, where changes in hypotheses only count when there is an extensional difference. We study the learnability of collections that are uniformly re We prove that, in contrast with the case of uniformly ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:DVq2DXEt7X4J:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9146016381843954189&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9146016381843954189&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="15">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540199928043</url>
        <title status="complete" source="scholar.google.com">The complexity of universal text-learners</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.40.8223&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, SA Terwijn</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>1999</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present work deals with language learning from text. It considers universal learners for classes of languages in models of additional information and analyzes their complexity in terms of Turing degrees. The following is shown: If the additional information is given by a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:HcrHXJzLv5AJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10430279134445292061&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10430279134445292061&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=19</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="16">
        <url>http://webdocs.cs.ualberta.ca/~zilles/zilles01TRuniform.pdf</url>
        <title status="complete" source="scholar.google.com">Identification Criteria in Uniform Inductive Inference</title>
        <pdf>http://webdocs.cs.ualberta.ca/~zilles/zilles01TRuniform.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">webdocs.cs.ualberta.ca</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract Uniform Inductive Inference is concerned with the existence and the learning behaviour of strategies identifying infinitely many classes of recursive functions. The success of such strategies depends on the hypothesis spaces they use, as well as on the chosen ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:-F5RpHdsLmIJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:-F5RpHdsLmIJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7074711325759332088&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="17">
        <title status="complete" source="scholar.google.com">Department of Computer and Information Sciences University of Delaware Newark, DE 19716, USA</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RLkDr-qUHr8J:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13771608446225070404&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="18">
        <title status="complete" source="scholar.google.com">Univ. of Delaware Sanjay Jain</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:rB0c-snhTMYJ:scholar.google.com/&amp;hl=en&amp;num=19&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="28">
    <url>http://www.sciencedirect.com/science/article/pii/S0304397509000620</url>
    <title status="complete" source="scholar.google.com">Prescribed learning of re classes</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.108.2025&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, F Stephan, N Ye</author>
    <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
    <year>2009</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... whataretheclassesofconceptsthatcanbelearnedusing Correspondingauthor. E-mailaddresses:sanjay@comp.nus.edu.sg(S.Jain),fstephan@comp.nus.edu.sg(F.Stephan),g0701171@nus.edu.sg(N.Ye). 0304-3975/$ seefrontmatter&#39;2009ElsevierB.V.Allrightsreserved. doi ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:YdSz3nZgLTsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>20</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=4264170485848462433&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>3</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=4264170485848462433&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="3">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540110002026</url>
        <title status="complete" source="scholar.google.com">Hypothesis spaces for learning</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/hypdep.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2011</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In this paper we survey some results in inductive inference showing how learnability of a class of languages may depend on the hypothesis space chosen. Additionally, optimal hypothesis spaces, usable for every learnable class, are considered. We also discuss ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:nE03dzw6FbIJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12832226744634658204&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12832226744634658204&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.comp.nus.edu.sg/~fstephan/conservative.ps</url>
        <title status="complete" source="scholar.google.com">On Conservative Learning of Re Languages</title>
        <pdf>http://www.comp.nus.edu.sg/~fstephan/conservative.ps</pdf>
        <author status="complete" source="scholar.google.com">Z Gao, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">comp.nus.edu.sg</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract Partially conservative learning is a variant of partial learning whereby the learner, on a text for a target language L, outputs one index e with L= We infinitely often and every further hypothesis d is output only finitely often and satisfies Lâ Wd. The present paper ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GhE8Fjp-QkoJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:GhE8Fjp-QkoJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/U2V8151P2N16110H.pdf</url>
        <title status="complete" source="scholar.google.com">Learnability of co-re classes</title>
        <pdf>http://www.comp.nus.edu.sg/~fstephan/corelearn.ps</pdf>
        <author status="complete" source="scholar.google.com">Z Gao, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Language and Automata Theory and Applications</proceeding>
        <year>2012</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The object of investigation in this paper is the learnability of co-recursively enumerable (co-re) languages based on Gold&#39;s [11] original model of inductive inference. In particular, the following learning models are studied: finite learning, explanatory learning, vacillatory ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:aenPm2LFsxAJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1203522552749615465&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="29">
    <url>http://www.springerlink.com/index/y7784576255hxt23.pdf</url>
    <title status="complete" source="scholar.google.com">Not-so-nearly-minimal-size program inference (preliminary report)</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.122.3355&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">J Case, M Suraj, S Jain</author>
    <proceeding status="partial" source="scholar.google.com">Algorithmic learning for knowledge-based &#8230;</proceeding>
    <year>1995</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... Mandayam Suraj Department of Computer and Information Sciences University of DelawareNewark, DE 19716 USA {case, suraj}@cis.udel.edu Sanjay Jain Institute of Systems ScienceNational University of Singapore Singapore 0511 Republic of Singapore sanjay~iss.nus.sg ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:uyIvn6CkzdYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>8</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=15478208504114651835&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>17</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=15478208504114651835&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="17">
        <result id="0">
        <url>http://dl.acm.org/citation.cfm?id=238093</url>
        <title status="complete" source="scholar.google.com">Elementary formal systems, intrinsic complexity, and procrastination</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.96.6124&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the ninth annual conference on &#8230;</proceeding>
        <year>1996</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Recently, rich subclasses of elementary formal systems(EFS) have been shown to be identifiable in the limit from only positive data. Examples of these classes are Angluin&#39;s pattern languages, unions of pattern languages by Wright and Shinohara, and classes of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:UjWHaftOaIkJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9901250622488261970&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>33</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9901250622488261970&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397599000055</url>
        <title status="complete" source="scholar.google.com">Ordinal mind change complexity of language identification</title>
        <author status="complete" source="scholar.google.com">A Ambainis, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>1999</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The approach of ordinal mind change complexity, introduced by Freivalds and Smith, uses (notations for) constructive ordinals to bound the number of mind changes made by a learning machine. This approach provides a measure of the extent to which a learning ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:vR2MAdwEA-MJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16357923614505049533&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>28</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16357923614505049533&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://iospress.metapress.com/index/J5TG811UU0055255.pdf</url>
        <title status="complete" source="scholar.google.com">Inductive inference with procrastination: back to definitions</title>
        <author status="complete" source="scholar.google.com">A Ambainis, R Freivalds, CH Smith</author>
        <proceeding status="complete" source="scholar.google.com">Fundamenta Informaticae</proceeding>
        <year>1999</year>
        <source>IOS Press</source>
        <snippet status="partial" source="scholar.google.com">In this paper, we reconsider the definition of procrastinating learning machines. In the original definition of Freivalds and Smith [FS93], constructive ordinals are used to bound mindchanges. We investigate possibility of using arbitrary linearly ordered sets to bound ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:TWbMAAm7UeQJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16452136561103627853&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16452136561103627853&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/t6pj8f6l9ubx4leq.pdf</url>
        <title status="complete" source="scholar.google.com">A guided tour of minimal indices and shortest descriptions</title>
        <pdf>http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ADA354440#page=81</pdf>
        <author status="complete" source="scholar.google.com">M Schaefer</author>
        <proceeding status="complete" source="scholar.google.com">Archive for Mathematical Logic</proceeding>
        <year>1998</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. The set of minimal indices of a Gdel numbering is defined as. It has been known since 1972 that, but beyond this has remained mostly uninvestigated. This paper collects the scarce results on from the literature and adds some new observations including that is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:OFKtozT9A1IJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5909845538566394424&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5909845538566394424&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/a81263786620675p.pdf</url>
        <title status="complete" source="scholar.google.com">Ordinal mind change complexity of language identification</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.150.7815&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">A Ambainis, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
        <year>1997</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The approach of ordinal mind change complexity, introduced by Freivalds and Smith, uses constructive ordinals to bound the number of mind changes made by a learning machine. This approach provides a measure of the extent to which a learning machine has to keep ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:L3MXwPUbmY4J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10275274767126197039&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10275274767126197039&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://projecteuclid.org/euclid.jsl/1080938842</url>
        <title status="complete" source="scholar.google.com">Parsimony hierarchies for inductive inference</title>
        <pdf>http://pdf.aminer.org/002/865/517/parsimony_hierarchies_for_inductive_inference.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Ambainis, J Case, S Jain, M Suraj</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
        <year>2004</year>
        <source>projecteuclid.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Freivalds defined an acceptable programming system independent criterion for learning programs for functions in which the final programs were required to be both correct and ânearlyâ minimal size, ie, within a computable function of being purely minimal size. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:PPOiazrZf9IJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15168080914944291644&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15168080914944291644&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397501000846</url>
        <title status="complete" source="scholar.google.com">Mind change complexity of learning logic programs</title>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2002</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present paper motivates the study of mind change complexity for learning minimal models of length-bounded logic programs. It establishes ordinal mind change complexity bounds for learnability of these classes both from positive facts and from positive and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:jJz4Dy_hBmEJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6991523063786937484&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6991523063786937484&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/FJ27LV202965N48R.pdf</url>
        <title status="complete" source="scholar.google.com">General inductive inference types based on linearly-ordered sets</title>
        <author status="complete" source="scholar.google.com">A Ambainis, R Freivalds, C Smith</author>
        <proceeding status="complete" source="scholar.google.com">STACS 96</proceeding>
        <year>1996</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In this paper, we reconsider the definitions of procrastinating learning machines. In the original definition of Freivalds and Smith [FS93], constructive ordinals are used to bound mindchanges. We investigate the possibility of using arbitrary linearly ordered sets to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:a7WJaokzy2wJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7839416241659426155&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7839416241659426155&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.springerlink.com/index/1p9a8e58kgtl7mwk.pdf</url>
        <title status="complete" source="scholar.google.com">Mind change complexity of learning logic programs</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.105.2902&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The present paper motivates the study of mind change complexity for learning minimal models of length-bounded logic programs. It establishes ordinal mind change complexity bounds for learnability of these classes both from positive facts and from positive and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1GrxM06Kkp0J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11354289679037983444&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11354289679037983444&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540103000828</url>
        <title status="complete" source="scholar.google.com">Learning by switching type of information</title>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present work is dedicated to the study of modes of data-presentation in the range between text and informant within the framework of inductive inference. In this study, the learner alternatingly requests sequences of positive and negative data. We define various ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:T69CcuOiZkMJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4856748345923907407&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4856748345923907407&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www.comp.nus.edu.sg/~sanjay/paps/parsh.pdf</url>
        <title status="complete" source="scholar.google.com">Machine induction without revolutionary changes in hypothesis size</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/parsh.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>1996</year>
        <source>comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper provides a beginning study of the effects on inductive inference of paradigm shifts whose absence is approximately modeled by various formal approaches to forbidding large changes in the size of programs conjectured. One approach, called ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:UBoOOrjlzAYJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:UBoOOrjlzAYJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=490019038887287376&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=490019038887287376&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://www.sciencedirect.com/science/article/pii/0304397595001549</url>
        <title status="complete" source="scholar.google.com">Anomalous learning helps succinctness</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/mininacc.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>1996</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">It is shown that allowing a bounded number of anomalies (mistakes) in the final programs learned by an algorithmic procedure can considerably âsuccinctifyâ those final programs. Naturally, only those contexts are investigated in which the presence of anomalies is not ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FxGlgxLXFioJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3032847873598624023&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3032847873598624023&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <url>http://www.springerlink.com/index/KUY6NRGG7E72T9R4.pdf</url>
        <title status="complete" source="scholar.google.com">Learning by switching type of information</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.8.2370&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The present work is dedicated to the study of modes of datapresentation between text and informant within the framework of inductive inference. The model is such that the learner requests sequences of positive andnegativ e data andthe relations between the various ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RIi4rBN__vcJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17869860093931587652&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17869860093931587652&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="13">
        <url>http://dl.acm.org/citation.cfm?id=307450</url>
        <title status="complete" source="scholar.google.com">On a generalized notion of mistake bounds</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.115.8551&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the twelfth annual conference on &#8230;</proceeding>
        <year>1999</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract The present paper proposes the use of constructive ordinals as mistake bounds in the online learning model. This approach elegantly generalizes the applicability of the on-line mistake bound model to learnability analysis of very expressive concept classes like ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MyqL-H2ICScJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2812929516891744819&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2812929516891744819&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="14">
        <url>http://www.cs.uchicago.edu/files/tr_authentic/TR-97-15.ps</url>
        <title status="complete" source="scholar.google.com">Submitted as a Master&#39;s Thesis at the University of Chicago</title>
        <pdf>http://www.cs.uchicago.edu/files/tr_authentic/TR-97-15.ps</pdf>
        <author status="complete" source="scholar.google.com">M Schaefer</author>
        <year>1997</year>
        <source>cs.uchicago.edu</source>
        <snippet status="partial" source="scholar.google.com">Abstract The set of minimal indices of a G del numbering&#39;is de ned as MIN&#39;= fe:(8i&lt; e)&#39;i 6=&#39;e] g. It has been known since 1972 that MIN&#39;T; 00, but beyond this MIN&#39;has remained mostly uninvestigated. This thesis collects the scarce results on MIN&#39;from the literature and adds ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:3OPhFtCAt5oJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:3OPhFtCAt5oJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11148521033804407772&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="15">
        <url>http://www.springerlink.com/index/P10132MM72722530.pdf</url>
        <title status="complete" source="scholar.google.com">Machine induction without revolutionary paradigm shifts</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1995</year>
        <source>Springer</source>
        <snippet status="complete" source="scholar.google.com">This paper provides a beginning study of the effects on inductive inference of paradigm shifts whose absence is approximately modeled by various formal approaches to forbidding large changes in the size of programs conjectured.</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:xSMXOf0nWRcJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1682419904337617861&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="16">
        <title status="complete" source="scholar.google.com">Department of Computer and Information Sciences University of Delaware Newark, DE 19716, USA Email: case@ cis. udel. edu</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:XViiPr1RB8kJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="30">
    <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.53.9905&amp;rep=rep1&amp;type=pdf</url>
    <title status="complete" source="scholar.google.com">Computational limits on team identification of languages</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.53.9905&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
    <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
    <year>1996</year>
    <source>Citeseer</source>
    <snippet status="partial" source="scholar.google.com">... His present address: Institute of Systems Science, National University of Sin- gapore, Singapore0511, Republic of Singapore, Email: sanjay@iss.nus.sg At the same time, Arun Sharma wasa liated with the Department of Computer Science, SUNY at Bu alo, Department of ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:gZGqzDA4sGYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:gZGqzDA4sGYJ:scholar.google.com/+author:%22Jain+Sanjay%22+NUS&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <numVersions>15</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=7399475970013041025&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>17</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=7399475970013041025&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="17">
        <result id="0">
        <url>http://www.springerlink.com/index/W476041228312557.pdf</url>
        <title status="complete" source="scholar.google.com">The communication of inductive inferences</title>
        <pdf>http://www.wdavies.org/papers/Thesis-Proposal-final-V1.ps</pdf>
        <author status="complete" source="scholar.google.com">W Davies, P Edwards</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; Intelligence Meets Machine Learning Learning in &#8230;</proceeding>
        <year>1997</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We propose a new approach to communication between agents that perform inductive inference. Consider a community of agents where each agent has a limited view of the overall world. When an agent in this community induces a hypothesis about the world, it ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:tGLL3Mf874MJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>21</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9507095273735414452&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>18</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9507095273735414452&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/030439759400162C</url>
        <title status="complete" source="scholar.google.com">On aggregating teams of learning machines</title>
        <pdf>http://pdf.aminer.org/000/039/386/on_aggregating_teams_of_learning_machines.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>1995</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A team of learning machines is a multiset of learning machines. A team is said to be successful just in case each member of some nonempty subset of the team is successful. The ratio of the number of machines required to be successful to the size of the team is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:9BaHDhhKKvYJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>20</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17738071549535524596&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17738071549535524596&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/7275u31884w23584.pdf</url>
        <title status="complete" source="scholar.google.com">On identification by teams and probabilistic machines</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.119.8736&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning for Knowledge-Based Systems</proceeding>
        <year>1995</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Inductive inference in the scientific domain is seldom an individual enterprise. Many a scientific breakthrough are result of the efforts of several scientists investigating a problem; scientific success is achieved if any one or more of members of the scientific community are successful. This ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:KIRo8csh0vMJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17569142256137962536&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17569142256137962536&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397500002188</url>
        <title status="complete" source="scholar.google.com">Probabilistic inductive inference: a survey</title>
        <pdf>http://arxiv.org/pdf/cs.LG/9902026</pdf>
        <author status="complete" source="scholar.google.com">A Ambainis</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="complete" source="scholar.google.com">This paper surveys developments in probabilistic inductive inference (learning) of recursive (computable) functions. We mainly focus on finite learning, since this simple paradigm has produced the most interesting (and most complex) results.</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:0IvCr0ZYyFgJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6397460331299507152&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6397460331299507152&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://arxiv.org/abs/cs/0504001</url>
        <title status="complete" source="scholar.google.com">Probabilistic and team PFIN-type learning: general properties</title>
        <pdf>http://arxiv.org/pdf/cs.LG/0504001</pdf>
        <author status="complete" source="scholar.google.com">A Ambainis</author>
        <proceeding status="complete" source="scholar.google.com">arXiv preprint cs/0504001</proceeding>
        <year>2005</year>
        <source>arxiv.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract: We consider the probability hierarchy for Popperian FINite learning and study the general properties of this hierarchy. We prove that the probability hierarchy is decidable, ie there exists an algorithm that receives p_1 and p_2 and answers whether PFIN-type ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:CfbPRuKfTEgJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5209714663160280585&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5209714663160280585&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://pdf.aminer.org/000/311/008/unions_of_identifiable_families_of_languages.pdf</url>
        <title status="complete" source="scholar.google.com">Team learning of formal languages</title>
        <pdf>http://pdf.aminer.org/000/311/008/unions_of_identifiable_families_of_languages.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">WSIMLC95</proceeding>
        <year>1995</year>
        <source>pdf.aminer.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract A team of learning machines is a multiset of learning machines. A team is said to successfully learn a concept just in case each member of some nonempty subset, of predetermined size, of the team learns the concept. Team learning of computer programs ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:VMXWutYixfwJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:VMXWutYixfwJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>21</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18214002573622822228&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18214002573622822228&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.springerlink.com/index/Q4H243321323V6K8.pdf</url>
        <title status="complete" source="scholar.google.com">The complexity of learning SUBSEQ (A)</title>
        <pdf>http://fs1.bib.tiera.ru/content/dvd52/Balcazar%20J.%20L.%20(Ed),%20Long%20Ph.%20M.%20(Ed),%20Stephan%20F.%20(Ed)%20-%20Algorithmic%20Learning%20Theory.%2017th%20International%20Conference,%20ALT%202006,%20Barcelona,%20Spain,%20October%207-10,%202006,%20Proceedings(2006)(393).pdf#page=120</pdf>
        <author status="complete" source="scholar.google.com">S Fenner, W Gasarch</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Higman showed that if A is any language then SUBSEQ (A) is regular, where SUBSEQ (A) is the language of all subsequences of strings in A. We consider the following inductive inference problem: given A (Îµ), A (0), A (1), A (00),... learn, in the limit, a DFA for SUBSEQ ( ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Jza4kQkTdmMJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>36</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7166936788827125287&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7166936788827125287&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/N06E3108MYXKV600.pdf</url>
        <title status="complete" source="scholar.google.com">Team learning of computable languages</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.108.396&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Theory of Computing Systems</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. A team of learning machines is a multiset of learning machines. A team is said to learn a concept successfully if each member of some nonempty subset, of predetermined size, of the team learns the concept. Team learning of languages may be viewed as a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:o5szlboYGy4J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3322276339762043811&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3322276339762043811&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.springerlink.com/index/f581mp71128658l0.pdf</url>
        <title status="complete" source="scholar.google.com">Team learning of recursive languages</title>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">PRICAI&#39;96: Topics in Artificial Intelligence</proceeding>
        <year>1996</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A team of learning machines is a multiset of learning machines. A team is said to successfully learn a concept just in case each member of some nonempty subset, of predetermined size, of the team learns the concept. Team learning of languages turns out ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Q2WHuIBNz38J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9209664978242987331&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9209664978242987331&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.40.744&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Ph. D. Thesis Proposal: The Communication of Inductive Inferences</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.40.744&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">W Davies</author>
        <year>2007</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract We propose a new approach to communication between agents that perform inductive inference. Previous systems have used methods based on voting strategies or theory refinement to integrate multiple learned models. Our approach uses version spaces ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:LBXHPJ9e1oQJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:LBXHPJ9e1oQJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9571942096035058988&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www.eccc.hpi-web.de/resources/pdf/ambaifi.pdf</url>
        <title status="complete" source="scholar.google.com">Randomization in Learning Theory</title>
        <pdf>http://www.eccc.hpi-web.de/resources/pdf/ambaifi.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Ambainis</author>
        <year>2007</year>
        <source>eccc.hpi-web.de</source>
        <snippet status="partial" source="scholar.google.com">Abstract We consider inductive inference (learning) of recursive (computable) functions. Here, the power of probabilistic algorithms increases as the probability of success decrease. The pattern of this increase depends on the exact requirements about learning algorithm. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:3zD5XGBnM1wJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:3zD5XGBnM1wJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6643767538875969759&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000007000773</url>
        <title status="complete" source="scholar.google.com">Probabilistic and team PFIN-type learning: General properties</title>
        <author status="complete" source="scholar.google.com">A Ambainis</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We consider the probability hierarchy for Popperian FINite learning and study the general properties of this hierarchy. We prove that the probability hierarchy is decidable, ie there exists an algorithm that receives p1 and p2 and answers whether PFIN-type learning with ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:YPa8ZEjXEuIJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16290319508080227936&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.98.3940&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Finite identification of functions by teams with success ratio</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.98.3940&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma, M Velauthapillai</author>
        <year>2007</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract Consider a scenario in which an algorithmic machine, M, is being fed the graph of a computable function f. M is said to finitely identify f just in case after inspecting a finite portion of the graph of f it emits its first conjecture which is a program for f, and it never abandons ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:P24AmYe9XGQJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:P24AmYe9XGQJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7231863491735350847&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="13">
        <url>http://www.springerlink.com/index/T448G2083421512J.pdf</url>
        <title status="complete" source="scholar.google.com">Input-Dependence in Function-Learning</title>
        <author status="complete" source="scholar.google.com">S Jain, E Martin, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theory of Computing Systems</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract In the standard model of inductive inference, a learner gets as input the graph of a function, and has to discover (in the limit) a program for the function. In this paper, we consider besides the graph also other modes of input such as the complement of the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:f-T8tNbGjGkJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7605672496183698559&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="14">
        <url>http://projecteuclid.org/euclid.jsl/1245158093</url>
        <title status="complete" source="scholar.google.com">The complexity of learning SUBSEQ (A)</title>
        <author status="complete" source="scholar.google.com">S Fenner, W Gasarch, B Postow</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
        <year>2009</year>
        <source>projecteuclid.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Higman essentially showed that if A is any language then SUBSEQ (A) is regular, where SUBSEQ (A) is the language of all subsequences of strings in A. Let sâ, sâ, sâ,â¦ be the standard lexicographic enumeration of all strings over some finite alphabet. We ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:g5V9744bXBUJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1539135473371157891&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="15">
        <url>http://www.springerlink.com/index/D891256047178X85.pdf</url>
        <title status="complete" source="scholar.google.com">Learning from streams</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.157.1225&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan, N Ye</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Learning from streams is a process in which a group of learners separately obtain information about the target to be learned, but they can communicate with each other in order to learn the target. We are interested in machine models for learning from streams ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1jKd9b4XsWYJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>22</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7399721771678380758&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="16">
        <url>http://www.springerlink.com/index/66PQ885G78N0K742.pdf</url>
        <title status="complete" source="scholar.google.com">Input-Dependence in Function-Learning</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/cie.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Martin, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Computation and Logic in the Real World</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In the standard literature on inductive inference, a learner sees as input the course of values of the function to be learned. In the present work, it is investigated how reasonable this choice is and how sensitive the model is with respect to variations like the overgraph or ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2SOO9izoryMJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2571529192064558041&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="31">
    <url>http://www.comp.nus.edu.sg/~sanjay/paps/fexmind.pdf</url>
    <title status="complete" source="scholar.google.com">Complexity issues for vacillatory function identification</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/fexmind.pdf</pdf>
    <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
    <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
    <year>1995</year>
    <source>comp.nus.edu.sg</source>
    <snippet status="partial" source="scholar.google.com">... 19716, USA Email: case@cis.udel.edu Sanjay Jain Institute of Systems ScienceNational University of Singapore Singapore 0511 Republic of Singapore Email:sanjay@iss.nus.sg Arun Sharma School of Computer Science ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:_dBwCJU23woJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:_dBwCJU23woJ:scholar.google.com/+author:%22Jain+Sanjay%22+NUS&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <numVersions>13</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=783404873905393917&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>16</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=783404873905393917&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="16">
        <result id="0">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=StUzu3bjlEIC&amp;oi=fnd&amp;pg=PR1&amp;ots=x4bgN1yAxo&amp;sig=c6rRcrF12xvGmqpiQzkYpxzillY</url>
        <title status="complete" source="scholar.google.com">Elements of scientific inquiry</title>
        <author status="complete" source="scholar.google.com">E Martin, DN Osherson</author>
        <year>1998</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">One influential view of science focuses on the credibility that scientists attach to alternative theories and on the evolution of these credibilities under the impact of data. Interpreting credibility as probability leads to the Bayesian analysis of inquiry, which has helped us to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:5uRXANb3dl4J:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6806900385317905638&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>96</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6806900385317905638&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://epubs.siam.org/doi/pdf/10.1137/S0097539793249694</url>
        <title status="complete" source="scholar.google.com">The power of vacillation in language learning</title>
        <pdf>http://dare.uva.nl/document/1137</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">SIAM Journal on Computing</proceeding>
        <year>1999</year>
        <source>SIAM</source>
        <snippet status="partial" source="scholar.google.com">Some extensions are considered of Gold&#39;s influential model of language learning by machine from positive data. Studied are criteria of successful learning featuring convergence in the limit to vacillation between several alternative correct grammars. The ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:iB0Rc-7Qrq0J:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>23</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12515170137060482440&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>82</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12515170137060482440&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.tandfonline.com/doi/abs/10.1080/09528139408953778</url>
        <title status="complete" source="scholar.google.com">Infinitary self-reference in learning theory</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.47.5822&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="partial" source="scholar.google.com">Journal of Experimental &amp; Theoretical Artificial &#8230;</proceeding>
        <year>1994</year>
        <source>Taylor &amp; Francis</source>
        <snippet status="partial" source="scholar.google.com">Abstract Kleene&#39;s second recursion theorem provides a means for transforming any program p into a program e (p) which first creates a quiescent self-copy and then runs p on that self-copy together with any externally given input. e (p), in effect, has complete (low level), self- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:W3Ho86D-EPAJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17298606135970394459&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>47</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17298606135970394459&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000007000797</url>
        <title status="complete" source="scholar.google.com">Non-U-shaped vacillatory and team learning</title>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">Journal of Computer and System &#8230;</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">U-shaped learning behaviour in cognitive development involves learning, unlearning and relearning. It occurs, for example, in learning irregular verbs. The prior cognitive science literature is occupied with how humans do it, for example, general rules versus tables of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:EQmrDMaxldIJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15174229983668930833&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15174229983668930833&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/746143G84P1761X0.pdf</url>
        <title status="complete" source="scholar.google.com">Vacillatory and BC learning on noisy data</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.1104&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1996</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In an earlier paper, Frank Stephan introduced a form of noisy data which nonetheless uniquely determines the true data: correct information occurs infinitely often while incorrect information occurs only finitely often. The present paper considers the effects of this form ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:DwzAHopQyuMJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16414020346056805391&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16414020346056805391&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.springerlink.com/index/7NDLJGW0PUQ0N9P5.pdf</url>
        <title status="complete" source="scholar.google.com">Non U-shaped vacillatory and team learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.127.40&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">U-shaped learning behaviour in cognitive development involves learning, unlearning and relearning. It occurs, for example, in learning irregular verbs. The prior cognitive science literature is occupied with how humans do it, for example, general rules versus tables of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:SiUKzidZXvAJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17320379244408874314&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17320379244408874314&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.111.1902&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">U-shaped learning may be necessary 3</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.111.1902&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carluccia, J Caseb, S Jainc, F Stephand</author>
        <year>2005</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract U-shaped learning behaviour in cognitive development involves learning, unlearning and relearning. It occurs, for example, in learning irregular verbs. The prior cognitive science literature is occupied with how humans do it, for example, general rules ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:TF-JIATWghcJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:TF-JIATWghcJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>20</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1694151723058814796&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1694151723058814796&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397599002686</url>
        <title status="complete" source="scholar.google.com">Vacillatory and BC learning on noisy data</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2000</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present work employs a model of noise introduced earlier by the third author. In this model noisy data nonetheless uniquely determines the true data: correct information occurs infinitely often while incorrect information occurs only finitely often. The present paper ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:f2xw58_6_98J:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16140895360367225983&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16140895360367225983&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.springerlink.com/index/77telyrg3pmm7cnc.pdf</url>
        <title status="complete" source="scholar.google.com">Counting extensional differences in BC-learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.8062&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, S Terwijn</author>
        <proceeding status="partial" source="scholar.google.com">Grammatical Inference: Algorithms and &#8230;</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Let BC be the model of behaviourally correct function learning as introduced by Barzdins [4] and Case and Smith [8]. We introduce a mind change hierarchy for BC, counting the number of extensional differences in the hypotheses of a learner. We compare the resulting ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:aUlyOc03SogJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9820723292006402409&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9820723292006402409&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.sciencedirect.com/science/article/pii/0304397595001549</url>
        <title status="complete" source="scholar.google.com">Anomalous learning helps succinctness</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/mininacc.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>1996</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">It is shown that allowing a bounded number of anomalies (mistakes) in the final programs learned by an algorithmic procedure can considerably âsuccinctifyâ those final programs. Naturally, only those contexts are investigated in which the presence of anomalies is not ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FxGlgxLXFioJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3032847873598624023&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3032847873598624023&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540103001743</url>
        <title status="complete" source="scholar.google.com">Counting extensional differences in BC-learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.97.1000&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan, SA Terwijn</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Let BC be the model of behaviourally correct function learning as introduced by Ba Ì rzdins [Theory of Algorithms and Programs, vol. 1, Latvian State University, 1974, p. 82â88] and Case and Smith [Theoret. Comput. Sci. 25 (1983) 193â220]. We introduce a mind change ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:7Abr25fIqYAJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>15</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9271161862474106604&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9271161862474106604&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>https://dl.comp.nus.edu.sg/dspace/handle/1900.100/1510</url>
        <title status="complete" source="scholar.google.com">U-shaped leaning may be necessary</title>
        <pdf>https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1510/1/upload.pdf</pdf>
        <author status="complete" source="scholar.google.com">C Lorenzo, C John, J Sanjay, S Frank</author>
        <year>2004</year>
        <source>dl.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract: U-shaped learning behaviour in cognitive development involves learning, unlearning and relearning. It occurs, for example, in learning irregular verbs. The prior cognitive science literature is occupied with how humans do it, for example, general rules ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:aN5UGzEe8gMJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=284322922738540136&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.88.1495&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Some Results on U-shaped, Vacillatory and Team Learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.88.1495&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
        <year>2008</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. U-shaped learning behaviour in cognitive development involves learning, unlearning and relearning. It occurs, for example, in learning irregular verbs. The prior cognitive science literature is occupied with how humans do it, for example, general rules ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:mMyKHdGlAbYJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:mMyKHdGlAbYJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13114945907441978520&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="13">
        <title status="complete" source="scholar.google.com">U-shaped learning may be necessary 3</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:9zFARK7e_V8J:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="14">
        <title status="complete" source="scholar.google.com">Department of Computer and Information Sciences University of Delaware Newark, DE 19716, USA</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RLkDr-qUHr8J:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13771608446225070404&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="15">
        <title status="complete" source="scholar.google.com">Univ. of Delaware Sanjay Jain</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:rB0c-snhTMYJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="32">
    <url>http://www.springerlink.com/index/najyku8tm4xhhpdl.pdf</url>
    <title status="complete" source="scholar.google.com">Learning with refutation</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.137.7727&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>1998</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">Page 1. Learning with Refutation Sanjay Jain1 Department of ISCS National Universityof Singapore Singapore 119260 Email: sanjay@iscs.nus.edu.sg Abstract. In theirpioneering work, Mukouchi and Arikawa modeled a learning ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:L2zSWvne_uYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>19</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=16644986435359894575&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>15</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=16644986435359894575&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="15">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S030439750200422X</url>
        <title status="complete" source="scholar.google.com">Refuting learning revisited</title>
        <author status="complete" source="scholar.google.com">W Merkle, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We consider, within the framework of inductive inference, the concept of refuting learning as introduced by Mukouchi and Arikawa, where the learner is not only required to learn all concepts in a given class but also has to explicitly refute concepts outside the class. In the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RVIbTNh5upMJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10644954639140344389&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10644954639140344389&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/L23CUU7HRC4JU3UV.pdf</url>
        <title status="complete" source="scholar.google.com">Refuting learning revisited</title>
        <pdf>http://pdf.aminer.org/001/093/440/refuting_learning_revisited.pdf</pdf>
        <author status="complete" source="scholar.google.com">W Merkle, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We consider, within the framework of inductive inference, the concept of refuting learning as introduced by Mukouchi and Arikawa, where the learner is not only required to learn all concepts in a given class but also has to explicitly refute concepts outside the class. In the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:KuoyBNoKaj4J:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4497419109372455466&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4497419109372455466&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397502004218</url>
        <title status="complete" source="scholar.google.com">On learning of functions refutably</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.100.9346&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Learning of recursive functions refutably informally means that for every recursive function, the learning machine has either to learn this function or to refute it, that is to signal that it is not able to learn it. Three modi of making precise the notion of refuting are considered. We ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:p7s2pvsnODgJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4051031826598640551&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4051031826598640551&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397508001412</url>
        <title status="complete" source="scholar.google.com">Reflective inductive inference of recursive functions</title>
        <author status="complete" source="scholar.google.com">G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In this paper, we investigate reflective inductive inference of recursive functions. A reflective IIM is a learning machine that is additionally able to assess its own competence. First, we formalize reflective learning from arbitrary, and from canonical, example sequences. Here, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:NX7O4wMNs5oJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11147267813030133301&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11147267813030133301&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/5fvlvahq3bcmcvmh.pdf</url>
        <title status="complete" source="scholar.google.com">Learning recursive functions refutably</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/alt01jkwz.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Learning of recursive functions refutably means that for every recursive function, the learning machine has either to learn this function or to refute it, ie, to signal that it is not able to learn it. Three modi of making precise the notion of refuting are considered. We show that the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:odjl50e9rvgJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17919468083884710049&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17919468083884710049&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.springerlink.com/index/n8rfuueg4ytgbeg5.pdf</url>
        <title status="complete" source="scholar.google.com">On the comparison of inductive inference criteria for uniform learning of finite classes</title>
        <pdf>http://cs5824.userapi.com/u11728334/docs/20e8cf4a8295/Naoki_Abe_Algorithmic_Learning_Theory_12_conf_A.pdf#page=260</pdf>
        <author status="complete" source="scholar.google.com">S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We consider a learning model in which each element of a class of recursive functions is to be identified in the limit by a computable strategy. Given gradually growing initial segments of the graph of a function, the learner is supposed to generate a sequence of hypotheses ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:-wk6JIpicNgJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15596073855036819963&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15596073855036819963&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.springerlink.com/index/mbhav1ap8ga0pu01.pdf</url>
        <title status="complete" source="scholar.google.com">Language learning with a neighbor system</title>
        <author status="complete" source="scholar.google.com">Y Mukouchi, M Sato</author>
        <proceeding status="complete" source="scholar.google.com">Discovery Science</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We consider inductive language learning from positive examples, some of which may be incorrect. In the present paper, the error or incorrectness we consider is the one described uniformly in terms of a distance over strings. Firstly, we introduce a notion of a recursively ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cOdYf8F5xJoJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11152172449248372592&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11152172449248372592&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397502004206</url>
        <title status="complete" source="scholar.google.com">Refutable language learning with a neighbor system</title>
        <author status="complete" source="scholar.google.com">Y Mukouchi, M Sato</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We consider inductive language learning and machine discovery from examples with some errors. In the present paper, the error or incorrectness we consider is the one described uniformly in terms of a distance over strings. Firstly, we introduce a notion of a recursively ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:UOGaqoDgODwJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4339465084194185552&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4339465084194185552&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.springerlink.com/index/6HW6VLPJ7XJ22BAH.pdf</url>
        <title status="complete" source="scholar.google.com">Refutable language learning with a neighbor system</title>
        <pdf>http://cs5824.userapi.com/u11728334/docs/20e8cf4a8295/Naoki_Abe_Algorithmic_Learning_Theory_12_conf_A.pdf#page=276</pdf>
        <author status="complete" source="scholar.google.com">Y Mukouchi, M Sato</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We consider inductive language learning and machine discovery from examples with some errors. In the present paper, the error or incorrectness we consider is the one described uniformly in terms of a distance over strings. Firstly, we introduce a notion of a recursively ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:i9aaqcCduzsJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4304207319687419531&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4304207319687419531&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.springerlink.com/index/vbxrhekl7drt3k7p.pdf</url>
        <title status="complete" source="scholar.google.com">Reflective inductive inference of recursive functions</title>
        <author status="complete" source="scholar.google.com">G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2002</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In this paper, we investigate reflective inductive inference of recursive functions. A reflective IIM is a learning machine that is additionally able to assess its own competence. First, we formalize reflective learning from arbitrary example sequences. Here, we arrive at four ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:sbmGyIHhwVYJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6251525705298262449&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6251525705298262449&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www.tandfonline.com/doi/abs/10.1080/09528130010029802</url>
        <title status="complete" source="scholar.google.com">On an open problem in classification of languages</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.100.6827&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <proceeding status="partial" source="scholar.google.com">Journal of Experimental &amp; Theoretical Artificial &#8230;</proceeding>
        <year>2001</year>
        <source>Taylor &amp; Francis</source>
        <snippet status="partial" source="scholar.google.com">Smith, Wichagen and Zeugmann (1997) showed an interesting connection between learning with bounded number of mind changes from informants and classification from informant. They showed that if an indexed family of languages L is learnable via ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:WX04j3ypwhIJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1351829190608452953&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1351829190608452953&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.20.8500&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">SIIM Technical Report</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.20.8500&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen, T Zeugmann</author>
        <year>2001</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract Learning of recursive functions refutably informally means that for every recursive function, the learning machine has either to learn this function or to refute it, that is to signal that it is not able to learn it. Three modi of making precise the notion of refuting are ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:jT4EcmddjbEJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:jT4EcmddjbEJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12793984815305342605&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <url>http://www.springerlink.com/index/5RDJV0QCC3FKK17K.pdf</url>
        <title status="complete" source="scholar.google.com">Refutable/inductive learning from neighbor examples and its application to decision trees over patterns</title>
        <author status="complete" source="scholar.google.com">M Sato, Y Mukouchi, M Terada</author>
        <proceeding status="complete" source="scholar.google.com">Progress in Discovery Science</proceeding>
        <year>2002</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The paper develops the theory of refutable/inductive learning as a foundation of discovery science from examples. We consider refutable/inductive language learning from positive examples, some of which may be incorrect. The error or incorrectness we consider is the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:zWgPdk1OTTQJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3768754557779142861&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="13">
        <title status="complete" source="scholar.google.com">Mathematisches Institut, Universitat Heidelberg 69120 Heidelberg, Germany, EU</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:OnDXsF3WybQJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="14">
        <title status="complete" source="scholar.google.com">Reflexive Induktive Inferenz</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:arZY9pLbFEAJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4617556942206318186&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="33">
    <url>http://www.springerlink.com/index/YQ258NX138521621.pdf</url>
    <title status="complete" source="scholar.google.com">On monotonic strategies for learning re languages</title>
    <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>1994</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">On monotonic strategies for learning re languages Sanjay Jain x and Arun Sharma 2 ] Departmentof Information Systems and Computer Science Lower Kent Ridge Road National Univers/ty ofSingapore Singapore 0511, Republic of Singapore Emai]: sanjayQiscs.nus.sg 2 ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:ynb3tsk_p7wJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>3</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=13593904135831779018&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>15</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=13593904135831779018&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="15">
        <result id="0">
        <url>http://dl.acm.org/authorize?1704</url>
        <title status="complete" source="scholar.google.com">Discovering models of software processes from event-based data</title>
        <pdf>http://www.dtic.mil/dtic/tr/fulltext/u2/a446147.pdf</pdf>
        <author status="complete" source="scholar.google.com">JE Cook, AL Wolf</author>
        <proceeding status="partial" source="scholar.google.com">ACM Transactions on Software Engineering and &#8230;</proceeding>
        <year>1998</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Many software process methods and tools presuppose the existence of a formal model of a process. Unfortunately, developing a formal model for an on-going, complex process can be difficult, costly, and error prone. This presents a practical barrier to the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:hoGqqdn7KJgJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>31</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10964290205106471302&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>613</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10964290205106471302&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540198927845</url>
        <title status="complete" source="scholar.google.com">Incremental concept learning for bounded data mining</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.7157&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, S Lange, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>1999</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Important refinements of concept learning in the limit from positive data considerably restricting the accessibility of input data are studied. Let c be any concept; every infinite sequence of elements exhausting c is called positive presentation of c. In all learning ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:KMSqppsxSO8J:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>19</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17242085717973845032&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>88</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17242085717973845032&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://dl.acm.org/citation.cfm?id=225320</url>
        <title status="complete" source="scholar.google.com">Language learning from texts (extended abstract): mind changes, limited memory and monotonicity</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.9010&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">E Kinber, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the eighth annual conference on &#8230;</proceeding>
        <year>1995</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract The paper explores language learning in the limit under various constraints on the number of mind-Chmges, memory, and monotonicity. We define language learning with limited (long term) memory and prove that learning with limited memory is exactly the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:XZJ_OM0KCaEJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>33</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11603817791429251677&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>71</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11603817791429251677&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.sciencedirect.com/science/article/pii/S0166361503001982</url>
        <title status="complete" source="scholar.google.com">Discovering models of behavior for concurrent workflows</title>
        <pdf>http://www.cs.nmsu.edu/~cliu/publications/compind.pdf</pdf>
        <author status="complete" source="scholar.google.com">JE Cook, Z Du, C Liu, AL Wolf</author>
        <proceeding status="complete" source="scholar.google.com">Computers in Industry</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Understanding the dynamic behavior of a workflow is crucial for being able to modify, maintain, and improve it. A particularly difficult aspect of some behavior is concurrency. Automated techniques which seek to mine workflow data logs to discover information ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:yPSrKZRPdtsJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>15</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15813914639330964680&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>64</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15813914639330964680&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://dl.acm.org/citation.cfm?id=238095</url>
        <title status="complete" source="scholar.google.com">Angluin&#39;s theorem for indexed families of re sets and applications</title>
        <pdf>http://research.nii.ac.jp/~kanazawa/publications/LP-96-05.text.pdf</pdf>
        <author status="complete" source="scholar.google.com">D De Jongh, M Kanazawa</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the ninth annual conference &#8230;</proceeding>
        <year>1996</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract We extend Angluin&#39;s(1980) theorem to characterize identifiability of indexed families of re languages, as opposed to indexed families of recursive languages. We also prove some variants characterizing conservativity and two other similar restrictions, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:OzVu-cMMVRIJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>25</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1320976101546014011&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>34</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1320976101546014011&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397597000182</url>
        <title status="complete" source="scholar.google.com">Noisy inference and oracles</title>
        <author status="complete" source="scholar.google.com">F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>1997</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present paper deals with several variants of inductive inference from noisy data. The notion of noise is based on the idea that the learner recieves a sequence of data elements such that each correct element appears infinitely often and each incorrect element ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GMtxMtHdCqsJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12324907220817005336&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>22</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12324907220817005336&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.sciencedirect.com/science/article/pii/S0164121204002080</url>
        <title status="complete" source="scholar.google.com">Discovering thread interactions in a concurrent system</title>
        <author status="complete" source="scholar.google.com">JE Cook, Z Du</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Systems and Software</proceeding>
        <year>2005</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Understanding the behavior of a system is a central reverse engineering task, and is crucial for being able to modify, maintain, and improve the system. An often difficult aspect of some system behaviors is concurrency, in particular identifying those areas that exhibit mutual ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:BdNaPgbvdkkJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5293681222115578629&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>17</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5293681222115578629&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/74u9j8083154t170.pdf</url>
        <title status="complete" source="scholar.google.com">Monotonicity versus efficiency for learning languages from texts</title>
        <author status="complete" source="scholar.google.com">E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1994</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">One of the central, problems of learning languages from texts is: how various restrictions on the behaviour of a learner limit the learning abilities. We consider restrictions of two types. Restrictions of the first type concern monotonicity of learning. Monotonicity means actually ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:bFcqWNGam_4J:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18346427730941859692&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>14</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18346427730941859692&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.springerlink.com/index/F7357P1580T1575G.pdf</url>
        <title status="complete" source="scholar.google.com">Noisy inference and oracles</title>
        <author status="complete" source="scholar.google.com">F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1995</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A learner noisily infers a function or set, if every correct item is presented infinitely often while in addition some incorrect data (noise) is presented a finite number of times. It is shown that learning from a noisy informant is equal to finite learning with K-oracle from a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:tBlBkmyH02YJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7409414712334555572&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7409414712334555572&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397597000170</url>
        <title status="complete" source="scholar.google.com">Probabilistic language learning under monotonicity constraints</title>
        <author status="complete" source="scholar.google.com">L Meyer</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>1997</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present paper deals with probabilistic identification of indexed families of uniformly recursive languages from positive data under monotonicity constraints. Thereby, we consider conservative, strong-monotonic and monotonic probabilistic learning of indexed ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:6Ol8yeF8qvoJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18062386564712688104&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18062386564712688104&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www.springerlink.com/index/5n5knxgfmm120bf6.pdf</url>
        <title status="complete" source="scholar.google.com">Comparing the power of probabilistic learning and oracle identification under monotonicity constraints</title>
        <pdf>http://cs5824.userapi.com/u11728334/docs/9e67ff61eb70/Michael_M_Richter_Algorithmic_Learning_Theory_9.pdf#page=316</pdf>
        <author status="complete" source="scholar.google.com">L Meyer</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1998</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In the setting of learning indexed families, probabilistic learning under monotonicity constraints is more powerful than deterministic learning under monotonicity constraints even if the probability is close to 1 provided the learning machines are restricted to proper or ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:UPd0HgnUU9MJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15227747900700555088&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15227747900700555088&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://www.tandfonline.com/doi/abs/10.1080/095281397147275</url>
        <title status="complete" source="scholar.google.com">Strong monotonic and set-driven inductive inference</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1392/1/report.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <proceeding status="partial" source="scholar.google.com">Journal of Experimental &amp; Theoretical Artificial &#8230;</proceeding>
        <year>1997</year>
        <source>Taylor &amp; Francis</source>
        <snippet status="partial" source="scholar.google.com">Abstract. In an earlier paper, Kinber and Stephan posed an open problem about whether every class of languages, which can be identified strong monotonically, can also be identified by a set-driven machine. This question is solved in this paper. The answer to the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:oUu_DHYm4S8J:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3450081078004370337&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397507002277</url>
        <title status="complete" source="scholar.google.com">On the data consumption benefits of accepting increased uncertainty</title>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In the context of learning paradigms of identification in the limit, we address the question: why is uncertainty sometimes desirable? We use mind change bounds on the output hypotheses as a measure of uncertainty and interpret &#39;desirable&#39;as reduction in data ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:YN_1eqwpL5wJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11254259814596206432&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="13">
        <url>http://www.springerlink.com/index/6LYLFEKMFX7KTYQ4.pdf</url>
        <title status="complete" source="scholar.google.com">On the data consumption benefits of accepting increased uncertainty</title>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2004</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In the context of learning paradigms of identification in the limit, we address the question: why is uncertainty sometimes desirable? We use mind change bounds on the output hypotheses as a measure of uncertainty, and interpret &#39;desirable&#39;as reduction in data ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:vahgiAbccK4J:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12569788480607004861&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="14">
        <url>https://www1.comp.nus.edu.sg/~fstephan/alt2004.ps</url>
        <title status="complete" source="scholar.google.com">On the Data Consumption Beneï¬ts of Accepting Increased Uncertainty</title>
        <pdf>https://www1.comp.nus.edu.sg/~fstephan/alt2004.ps</pdf>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">comp.nus.edu.sg</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract In the context of learning paradigms of identification in the limit, We address the question: Why is uncertainty sometimes desirable? VVe use mind change bounds on the output hypotheses a measure of uncertainty, and interpret &#39;desirable&#39;as reduction i11 data ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Er3nw-LMkmMJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7175022430676040978&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="34">
    <url>http://dl.acm.org/citation.cfm?id=168331</url>
    <title status="complete" source="scholar.google.com">Probability is more powerful than team for language identification from positive data</title>
    <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
    <proceeding status="partial" source="scholar.google.com">Proceedings of the sixth annual conference on &#8230;</proceeding>
    <year>1993</year>
    <source>dl.acm.org</source>
    <snippet status="partial" source="scholar.google.com">... Engineering I&#39;Jational University of Singapore The University of New South WalesSingapore 0511, Republic of Singapore Sydney, NSW 2033, Australia Email:sanjay@isa.nus.sg Email: arun@cse.unsw.edu .au Abstract A ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:jJh_bx5H9kMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>3</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=4897179840857217164&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>14</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=4897179840857217164&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="14">
        <result id="0">
        <url>http://www.springerlink.com/index/P811426W6266L1MX.pdf</url>
        <title status="complete" source="scholar.google.com">Three decades of team learning</title>
        <author status="complete" source="scholar.google.com">C Smith</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1994</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The philosophers of science were the first group to apply formal methods to the process of discovery [Bur58, Car52, ResT0]. They developed models of the scien- tific method that entailed .alternating phases of data acquisition and hypothesis formation. The linguists used amazingly similar ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:HYNoroo8D0kJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5264493055748637469&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>30</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5264493055748637469&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.53.9905&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Computational limits on team identification of languages</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.53.9905&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>1996</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract A team of learning machines is essentially a multiset of learning machines. A team is said to successfully identify a concept just in case each member of some nonempty subset of the team identi es the concept. Team identi cation of programs for computable functions ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:gZGqzDA4sGYJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:gZGqzDA4sGYJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>15</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7399475970013041025&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>17</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7399475970013041025&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/030439759400162C</url>
        <title status="complete" source="scholar.google.com">On aggregating teams of learning machines</title>
        <pdf>http://pdf.aminer.org/000/039/386/on_aggregating_teams_of_learning_machines.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>1995</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A team of learning machines is a multiset of learning machines. A team is said to be successful just in case each member of some nonempty subset of the team is successful. The ratio of the number of machines required to be successful to the size of the team is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:9BaHDhhKKvYJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>20</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17738071549535524596&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17738071549535524596&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/7275u31884w23584.pdf</url>
        <title status="complete" source="scholar.google.com">On identification by teams and probabilistic machines</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.119.8736&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning for Knowledge-Based Systems</proceeding>
        <year>1995</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Inductive inference in the scientific domain is seldom an individual enterprise. Many a scientific breakthrough are result of the efforts of several scientists investigating a problem; scientific success is achieved if any one or more of members of the scientific community are successful. This ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:KIRo8csh0vMJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17569142256137962536&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17569142256137962536&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/7017211543565117.pdf</url>
        <title status="complete" source="scholar.google.com">Probabilistic language learning under monotonicity constraints</title>
        <author status="complete" source="scholar.google.com">L Meyer</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1995</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The present paper deals with probabilistic identification of indexed families of uniformly recursive languages from positive data under various monotonicity constraints. Thereby, we consider strong-monotonic, monotonic and weak-monotonic probabilistic learning of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:XHD8qg9bqFQJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6100225818124644444&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6100225818124644444&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://arxiv.org/abs/cs/0504001</url>
        <title status="complete" source="scholar.google.com">Probabilistic and team PFIN-type learning: general properties</title>
        <pdf>http://arxiv.org/pdf/cs.LG/0504001</pdf>
        <author status="complete" source="scholar.google.com">A Ambainis</author>
        <proceeding status="complete" source="scholar.google.com">arXiv preprint cs/0504001</proceeding>
        <year>2005</year>
        <source>arxiv.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract: We consider the probability hierarchy for Popperian FINite learning and study the general properties of this hierarchy. We prove that the probability hierarchy is decidable, ie there exists an algorithm that receives p_1 and p_2 and answers whether PFIN-type ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:CfbPRuKfTEgJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5209714663160280585&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5209714663160280585&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <title status="complete" source="scholar.google.com">A survey of inductive inference with an emphasis on queries</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.33.5664&amp;rep=rep1&amp;type=pdf</pdf>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GnKgfqPifP0J:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18265723380539879962&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18265723380539879962&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397597000170</url>
        <title status="complete" source="scholar.google.com">Probabilistic language learning under monotonicity constraints</title>
        <author status="complete" source="scholar.google.com">L Meyer</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>1997</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present paper deals with probabilistic identification of indexed families of uniformly recursive languages from positive data under monotonicity constraints. Thereby, we consider conservative, strong-monotonic and monotonic probabilistic learning of indexed ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:6Ol8yeF8qvoJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18062386564712688104&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18062386564712688104&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.springerlink.com/index/U101472218233264.pdf</url>
        <title status="complete" source="scholar.google.com">Monotonic and dual-monotonic probabilistic language learning of indexed families with high probability</title>
        <author status="complete" source="scholar.google.com">L Meyer</author>
        <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
        <year>1997</year>
        <source>Springer</source>
        <snippet status="complete" source="scholar.google.com">The present paper deals with monotonic and dual-monotonic probabilistic identification of indexed families of uniformly recursive languages from positive data. In particular, we consider the special case where the probability is equal to 1.</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:7QZ1D7HClgEJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=114492906268853997&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=114492906268853997&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://pdf.aminer.org/000/311/008/unions_of_identifiable_families_of_languages.pdf</url>
        <title status="complete" source="scholar.google.com">Team learning of formal languages</title>
        <pdf>http://pdf.aminer.org/000/311/008/unions_of_identifiable_families_of_languages.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">WSIMLC95</proceeding>
        <year>1995</year>
        <source>pdf.aminer.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract A team of learning machines is a multiset of learning machines. A team is said to successfully learn a concept just in case each member of some nonempty subset, of predetermined size, of the team learns the concept. Team learning of computer programs ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:VMXWutYixfwJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:VMXWutYixfwJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>21</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18214002573622822228&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18214002573622822228&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www.springerlink.com/index/N06E3108MYXKV600.pdf</url>
        <title status="complete" source="scholar.google.com">Team learning of computable languages</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.108.396&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Theory of Computing Systems</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. A team of learning machines is a multiset of learning machines. A team is said to learn a concept successfully if each member of some nonempty subset, of predetermined size, of the team learns the concept. Team learning of languages may be viewed as a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:o5szlboYGy4J:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3322276339762043811&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3322276339762043811&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://www.springerlink.com/index/5n5knxgfmm120bf6.pdf</url>
        <title status="complete" source="scholar.google.com">Comparing the power of probabilistic learning and oracle identification under monotonicity constraints</title>
        <pdf>http://cs5824.userapi.com/u11728334/docs/9e67ff61eb70/Michael_M_Richter_Algorithmic_Learning_Theory_9.pdf#page=316</pdf>
        <author status="complete" source="scholar.google.com">L Meyer</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1998</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In the setting of learning indexed families, probabilistic learning under monotonicity constraints is more powerful than deterministic learning under monotonicity constraints even if the probability is close to 1 provided the learning machines are restricted to proper or ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:UPd0HgnUU9MJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15227747900700555088&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15227747900700555088&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <url>http://www.springerlink.com/index/f581mp71128658l0.pdf</url>
        <title status="complete" source="scholar.google.com">Team learning of recursive languages</title>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">PRICAI&#39;96: Topics in Artificial Intelligence</proceeding>
        <year>1996</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A team of learning machines is a multiset of learning machines. A team is said to successfully learn a concept just in case each member of some nonempty subset, of predetermined size, of the team learns the concept. Team learning of languages turns out ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Q2WHuIBNz38J:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9209664978242987331&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9209664978242987331&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="13">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.98.3940&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Finite identification of functions by teams with success ratio</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.98.3940&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma, M Velauthapillai</author>
        <year>2007</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract Consider a scenario in which an algorithmic machine, M, is being fed the graph of a computable function f. M is said to finitely identify f just in case after inspecting a finite portion of the graph of f it emits its first conjecture which is a program for f, and it never abandons ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:P24AmYe9XGQJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:P24AmYe9XGQJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7231863491735350847&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="35">
    <url>http://www.sciencedirect.com/science/article/pii/S0890540199928055</url>
    <title status="complete" source="scholar.google.com">Robust behaviorally correct learning</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/robbc.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain</author>
    <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
    <year>1999</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... Verlag, New York/Berlin (1986), pp. 220â227. f1 E-mail: sanjay@comp.nus.edu.sg.Copyright Â© 1999 Academic Press. All rights reserved. Information and ComputationVolume 153, Issue 2, 15 September 1999, Pages 238-248. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:zRgar4gEM3QJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>9</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=8373041117311670477&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>14</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=8373041117311670477&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="14">
        <result id="0">
        <url>http://dl.acm.org/citation.cfm?id=279952</url>
        <title status="complete" source="scholar.google.com">Robust learning aided by context</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/context.pdf</pdf>
        <author status="partial" source="scholar.google.com">J Case, S Jain, M Ott, A Sharma&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the &#8230;</proceeding>
        <year>1998</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Empirical st, udies of multitask learning provide some evidence that the performance of a learning system on its intended targets improves by presenting to the learning system related tasks, also called contexts, as additional input. Angluin, Gasarch, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ihOGY9NnPVMJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>34</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5998064436332860298&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>19</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5998064436332860298&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397508001400</url>
        <title status="complete" source="scholar.google.com">Learning recursive functions: A survey</title>
        <pdf>http://webdocs.cs.ualberta.ca/~zilles/zeugmannZ08survey.pdf</pdf>
        <author status="complete" source="scholar.google.com">T Zeugmann, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Studying the learnability of classes of recursive functions has attracted considerable interest for at least four decades. Starting with Gold&#39;s (1967) model of learning in the limit, many variations, modifications and extensions have been proposed. These models differ in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2f2VA5VmFfUJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17660134303999589849&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>14</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17660134303999589849&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397501004054</url>
        <title status="complete" source="scholar.google.com">Learning classes of approximations to non-recursive functions</title>
        <pdf>http://www.mat.unisi.it/personalpages/sorbi/public_html/papers/RUSHEAD.pdf#page=53</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2002</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Blum and Blum (Inform. and Control 28 (1975) 125â155) showed that a class B of suitable recursive approximations to the halting problem K is reliably EX-learnable but left it open whether or not B is in NUM. By showing B to be not in NUM we resolve this old problem. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:keLy4mjhzZEJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>33</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10506301346325652113&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10506301346325652113&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.sciencedirect.com/science/article/pii/S030439750100086X</url>
        <title status="complete" source="scholar.google.com">Avoiding coding tricks by hyperrobust learning</title>
        <author status="complete" source="scholar.google.com">M Ott, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2002</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present work introduces and justifies the notion of hyperrobust learning where one fixed learner has to learn all functions in a given class plus their images under primitive recursive operators. The following are shown: The notion of learnability does not change if the class ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:6dr-DNkEbLMJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12928713960546294505&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12928713960546294505&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000004000212</url>
        <title status="complete" source="scholar.google.com">Robust learningârich and poor</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan, R Wiehagen</author>
        <proceeding status="partial" source="scholar.google.com">Journal of Computer and System &#8230;</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A class C of recursive functions is called robustly learnable in the sense I (where I is any success criterion of learning) if not only C itself but even all transformed classes Î (C), where Î is any general recursive operator, are learnable in the sense I. It was already ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ukImu-_3fDcJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3998343178207249082&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3998343178207249082&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.springerlink.com/index/EKX087X862286207.pdf</url>
        <title status="complete" source="scholar.google.com">On the uniform learnability of approximations to non-recursive functions</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/alt99sz.pdf</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Blum and Blum (1975) showed that a class BB of suitable recursive approximations to the halting problem is reliably EX-learnable. These investigations are carried on by showing that BB is neither in NUM nor robustly EX-learnable. Since the definition of the class BB is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:LOx7t0gGJBoJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>15</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1883637453533473836&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1883637453533473836&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.springerlink.com/index/5n75eb1v97fxh6qq.pdf</url>
        <title status="complete" source="scholar.google.com">Robust LearningâRich and Poor</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.36.2906&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan, R Wiehagen</author>
        <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Aclass C of recursive functions is called robustly learnable in the sense I (where I is any success criterion of learning) if not only C itself but even all transformed classes T (C) where T is any general recursive operator, are learnable in the sense I. It was already shown ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:6-x8KxzTtaYJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>21</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12012739699022818539&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12012739699022818539&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/1233111895g360t7.pdf</url>
        <title status="complete" source="scholar.google.com">Learning real polynomials with a Turing machine</title>
        <author status="complete" source="scholar.google.com">D Cheung</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We provide an algorithm to PAC learn multivariate polynomials with real coefficients. The instance space from which labeled samples are drawn is IR N but the coordinates of such samples are known only approximately. The algorithm is iterative and the main ingredient ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:9j_KUzUkmQwJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=907796611349495798&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=907796611349495798&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.comp.nus.edu.sg/~sanjay/paps/robsur.pdf</url>
        <title status="complete" source="scholar.google.com">A tour of robust learning</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/robsur.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; and Models. Perspectives East and West. &#8230;</proceeding>
        <year>2003</year>
        <source>comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract BarzdinÅ¡ conjectured that only recursively enumerable classes of functions can be learned robustly. This conjecture, which was finally refuted by Fulk, initiated the study of notions of robust learning. The present work surveys research on robust learning and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:OhqoyUDoLugJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:OhqoyUDoLugJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16730565030686759482&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16730565030686759482&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://projecteuclid.org/euclid.jsl/1305810752</url>
        <title status="complete" source="scholar.google.com">Robust separations in inductive inference</title>
        <author status="complete" source="scholar.google.com">M Fulk</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
        <year>2011</year>
        <source>projecteuclid.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Results in recursion-theoretic inductive inference have been criticized as depending on unrealistic self-referential examples. JM BÄrzdiÅÅ¡ proposed a way of ruling out such examples, and conjectured that one of the earliest results of inductive inference ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:VRX6dMGFfUgJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5223478208757372245&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5223478208757372245&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/doitr166sz.ps.gz</url>
        <title status="complete" source="scholar.google.com">DOI Technical Report</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/doitr166sz.ps.gz</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, T Zeugmann</author>
        <year>1999</year>
        <source>www-alg.ist.hokudai.ac.jp</source>
        <snippet status="complete" source="scholar.google.com">Abstract Blum and Blum (1975) showed that a class B of suitable recursive approximations to the halting problem K is reliably EX-learnable but left it open whether or not B is in NUM. By showing B to be not in NUM we resolve this old problem.</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ypBkC6zAZg8J:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:ypBkC6zAZg8J:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://www.comp.nus.edu.sg/~sanjay/paps/robsur-c.pdf</url>
        <title status="complete" source="scholar.google.com">A Survey of Robust Learning</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/robsur-c.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <year>2008</year>
        <source>comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract. A class of objects is said to be robustly learnable if not only this class itself is learnable but all of its computable âtransformationsâ are also learnable. We study robust learning within the framework of inductive inference. A class of recursive functions is said ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:td7IYjEIaMwJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:td7IYjEIaMwJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14729031589518958261&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=NFu8uP4GqykC&amp;oi=fnd&amp;pg=PA215&amp;ots=-bzu6hPZuL&amp;sig=P_fx-z5PzYNUEgaspe4Jzn80Al4</url>
        <title status="complete" source="scholar.google.com">A TOUR OF ROBUST LEARNING</title>
        <author status="complete" source="scholar.google.com">F Stephant</author>
        <proceeding status="partial" source="scholar.google.com">Computability and Models: Perspectives East and &#8230;</proceeding>
        <year>2003</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">Abstract BarzdinS conjectured that only recursively enumerable classes of functions can be learned robustly. This conjecture, which was finally refuted by Fulk, initiated the study of notions of robust learning. The present work surveys research on robust learning and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:m5TegYY-cQwJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="13">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.6279&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Robust LearningâRich and Poor</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.6279&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">JCS Jainb, F Stephanc, R Wiehagend</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract A class C of recursive functions is called robustly learnable in the sense I (where I is any success criterion of learning) if not only C itself but even all transformed classes Î (C) where Î is any general recursive operator, are learnable in the sense I. It was already ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:F-gF6cXSbSAJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:F-gF6cXSbSAJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2336755529135024151&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="36">
    <url>http://pdf.aminer.org/000/108/909/learning_in_the_presence_of_inaccurate_information.pdf</url>
    <title status="complete" source="scholar.google.com">Learning in the presence of inaccurate information</title>
    <pdf>http://pdf.aminer.org/000/108/909/learning_in_the_presence_of_inaccurate_information.pdf</pdf>
    <author status="complete" source="scholar.google.com">M Fulk, S Jain</author>
    <proceeding status="partial" source="scholar.google.com">Annual Workshop on Computational Learning Theory &#8230;</proceeding>
    <year>1989</year>
    <source>pdf.aminer.org</source>
    <snippet status="partial" source="scholar.google.com">... Genesee Valley Software, 92 Monteroy Road, Brighton, NY 14618, USA â Department ofInformation Systems and Computer Science, National University of Singapore, Singapore0511, Republic of Singapore. Email: sanjay@iscs.nus.sg 1 Page 2. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:9v-M3AEjHTIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:9v-M3AEjHTIJ:scholar.google.com/+author:%22Jain+Sanjay%22+NUS&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <numVersions>11</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=3611080967123173366&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>14</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=3611080967123173366&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="14">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000005800728</url>
        <title status="complete" source="scholar.google.com">Open problems in âsystems that learnâ</title>
        <author status="complete" source="scholar.google.com">M Fulk, S Jain, DN Osherson</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>1994</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In this paper we solve some of the open problems in D. Osherson, M. Stob, and S. Weinstein (âSystems That Learn,â MIT Press, Cambridge, MA, 1986). We also give partial solutions to some other open problems in the book. In particular we show that the collection of classes ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:HrUYB7tOQMgJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14429619771279979806&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>57</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14429619771279979806&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.tandfonline.com/doi/abs/10.1080/09528139408953778</url>
        <title status="complete" source="scholar.google.com">Infinitary self-reference in learning theory</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.47.5822&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="partial" source="scholar.google.com">Journal of Experimental &amp; Theoretical Artificial &#8230;</proceeding>
        <year>1994</year>
        <source>Taylor &amp; Francis</source>
        <snippet status="partial" source="scholar.google.com">Abstract Kleene&#39;s second recursion theorem provides a means for transforming any program p into a program e (p) which first creates a quiescent self-copy and then runs p on that self-copy together with any externally given input. e (p), in effect, has complete (low level), self- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:W3Ho86D-EPAJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17298606135970394459&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>47</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17298606135970394459&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397597000182</url>
        <title status="complete" source="scholar.google.com">Noisy inference and oracles</title>
        <author status="complete" source="scholar.google.com">F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>1997</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present paper deals with several variants of inductive inference from noisy data. The notion of noise is based on the idea that the learner recieves a sequence of data elements such that each correct element appears infinitely often and each incorrect element ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GMtxMtHdCqsJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12324907220817005336&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>22</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12324907220817005336&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/F7357P1580T1575G.pdf</url>
        <title status="complete" source="scholar.google.com">Noisy inference and oracles</title>
        <author status="complete" source="scholar.google.com">F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1995</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A learner noisily infers a function or set, if every correct item is presented infinitely often while in addition some incorrect data (noise) is presented a finite number of times. It is shown that learning from a noisy informant is equal to finite learning with K-oracle from a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:tBlBkmyH02YJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7409414712334555572&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7409414712334555572&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/744gl6106742726h.pdf</url>
        <title status="complete" source="scholar.google.com">Program synthesis in the presence of infinite number of inaccuracies</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1391/1/report.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1994</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Most studies modeling inaccurate data in Gold style learning consider cases in which the number of inaccuracies is finite. The present paper argues that this approach is not reasonable for modeling inaccuracies in concepts that are infinite in nature (for example, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:mDnNbDEJntsJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15825096248509938072&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15825096248509938072&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.sciencedirect.com/science/article/pii/0304397595001352</url>
        <title status="complete" source="scholar.google.com">Learning in the presence of inaccurate information</title>
        <author status="complete" source="scholar.google.com">M Fulk, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>1996</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present paper considers the effects of introducing inaccuracies in a learner&#39;s environment in Gold&#39;s learning model of identification in the limit. Three kinds of inaccuracies are considered: presence of spurious data is modeled as learning from a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:06FfqX7UAvoJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18015195099907989971&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18015195099907989971&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.springerlink.com/index/746143G84P1761X0.pdf</url>
        <title status="complete" source="scholar.google.com">Vacillatory and BC learning on noisy data</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.1104&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1996</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In an earlier paper, Frank Stephan introduced a form of noisy data which nonetheless uniquely determines the true data: correct information occurs infinitely often while incorrect information occurs only finitely often. The present paper considers the effects of this form ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:DwzAHopQyuMJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16414020346056805391&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16414020346056805391&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/Y883313L70NM1731.pdf</url>
        <title status="complete" source="scholar.google.com">Learning from multiple sources of inaccurate data</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/mulj.pdf</pdf>
        <author status="complete" source="scholar.google.com">G Baliga, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Analogical and Inductive Inference</proceeding>
        <year>1992</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Most theoretical studies of inductive inference model a situation involving a machine M learning its environment E on following lines. M, placed in E, receives data about E, and simultaneously conjectures a sequence of hypotheses. M is said to learn E just in case the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:8-_nijoirs8J:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14964936246632640499&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14964936246632640499&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <title status="complete" source="scholar.google.com">A survey of inductive inference with an emphasis on queries</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.33.5664&amp;rep=rep1&amp;type=pdf</pdf>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GnKgfqPifP0J:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18265723380539879962&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18265723380539879962&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://epubs.siam.org/doi/pdf/10.1137/S0097539792239461</url>
        <title status="complete" source="scholar.google.com">Learning from multiple sources of inaccurate data</title>
        <author status="complete" source="scholar.google.com">G Baliga, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">SIAM Journal on Computing</proceeding>
        <year>1997</year>
        <source>SIAM</source>
        <snippet status="partial" source="scholar.google.com">Most theoretical models of inductive inference make the idealized assumption that the data available to a learner is from a single and accurate source. The subject of inaccuracies in data emanating from a single source has been addressed by several authors. The present ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2bqtl92062sJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7776508045410810585&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7776508045410810585&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www.comp.nus.edu.sg/~sanjay/paps/osw.pdf</url>
        <title status="complete" source="scholar.google.com">Open problems in systems that learn</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/osw.pdf</pdf>
        <author status="complete" source="scholar.google.com">MA Fulk, S Jain, DN Osherson</author>
        <year>1989</year>
        <source>comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract In this paper we solve some of the open problems in [19]. We also give partial solutions to some other open problems in the book. In particular we show that the collection of classes of languages that can be identified on ânoisyâ text (ie a text which may contain ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:rprN2zL2qk4J:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:rprN2zL2qk4J:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5668613779295673006&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5668613779295673006&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <title status="complete" source="scholar.google.com">Department of Computer and Information Sciences University of Delaware Newark, DE 19716, USA</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RLkDr-qUHr8J:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13771608446225070404&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <title status="complete" source="scholar.google.com">Univ. of Delaware Sanjay Jain</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:rB0c-snhTMYJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="13">
        <title status="complete" source="scholar.google.com">Reflexive Induktive Inferenz</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:arZY9pLbFEAJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4617556942206318186&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="37">
    <url>http://www.springerlink.com/index/a81263786620675p.pdf</url>
    <title status="complete" source="scholar.google.com">Ordinal mind change complexity of language identification</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.150.7815&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">A Ambainis, S Jain, A Sharma</author>
    <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
    <year>1997</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 29, Riga, Latvia Emaih ambainis~cclu.lv 2 Department of Information Systems and ComputerScience National University of Singapore Singapore 119260, Republic of Singapore Email:sanjay@iscs.nus.sg 3 School of Computer Science and Engineering The University of New ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:L3MXwPUbmY4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>7</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=10275274767126197039&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>13</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=10275274767126197039&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="13">
        <result id="0">
        <url>http://dl.acm.org/citation.cfm?id=279955</url>
        <title status="complete" source="scholar.google.com">Learnability of a subclass of extended pattern languages</title>
        <author status="complete" source="scholar.google.com">AR Mitchell</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the eleventh annual conference on &#8230;</proceeding>
        <year>1998</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Angluin introduced the class of pattern languages as term languages over strings on a finite alphabet, and showed that the class is identifiable in the limit from texts (positive data). III Angluin&#39;s definition of pattern languages, erasing substitutions are disallowed. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Qr-DkouoqvMJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17558031414669328194&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>21</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17558031414669328194&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://dl.acm.org/citation.cfm?id=267485</url>
        <title status="complete" source="scholar.google.com">Generalized notions of mind change complexity</title>
        <pdf>http://pdf.aminer.org/000/889/421/generalized_notions_of_mind_change_complexity.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Sharma, F Stephan, Y Ventsov</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; of the tenth annual conference on &#8230;</proceeding>
        <year>1997</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Speed of convergence in Gold&#39;s identification in the limit model can be measured by deriving bounds on the number of mind changes made by a learner before the onset of convergence. Two approaches to date are bounds given by constants (referred here as ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:wvC_V1rFm8sJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>31</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14671537202899448002&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>15</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14671537202899448002&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/b41022251g722643.pdf</url>
        <title status="complete" source="scholar.google.com">On learning unions of pattern languages and tree patterns</title>
        <author status="complete" source="scholar.google.com">S Goldman, S Kwek</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We present efficient on-line algorithms for learning unions of a constant number of tree patterns, unions of a constant number of one-variable pattern languages, and unions of a constant number of pattern languages with fixed length substitutions. By fixed length ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:KmR3bf6oVlUJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6149288151932691498&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>14</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6149288151932691498&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/M10332H915246783.pdf</url>
        <title status="complete" source="scholar.google.com">On the classification of computable languages</title>
        <pdf>http://www.cis.udel.edu/~case/papers/classif.ps</pdf>
        <author status="complete" source="scholar.google.com">J Case, E Kinber, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">STACS 97</proceeding>
        <year>1997</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A one-sided classifier for a given class of languages converges to 1 on every language from the class and outputs 0 infinitely often on languages outside the class. A two-sided classifier, on the other hand, converges to 1 on languages from the class and converges to 0 on ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RuRE4B4a4IgJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9862911903855338566&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9862911903855338566&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397501000846</url>
        <title status="complete" source="scholar.google.com">Mind change complexity of learning logic programs</title>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2002</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present paper motivates the study of mind change complexity for learning minimal models of length-bounded logic programs. It establishes ordinal mind change complexity bounds for learnability of these classes both from positive facts and from positive and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:jJz4Dy_hBmEJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6991523063786937484&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6991523063786937484&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.springerlink.com/index/1p9a8e58kgtl7mwk.pdf</url>
        <title status="complete" source="scholar.google.com">Mind change complexity of learning logic programs</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.105.2902&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The present paper motivates the study of mind change complexity for learning minimal models of length-bounded logic programs. It establishes ordinal mind change complexity bounds for learnability of these classes both from positive facts and from positive and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1GrxM06Kkp0J:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11354289679037983444&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11354289679037983444&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.11.3502&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Learning generalized quantifiers</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.11.3502&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">CC FlorÃªncio</author>
        <proceeding status="complete" source="scholar.google.com">Proceedings of Seventh ESSLLI Student Session</proceeding>
        <year>2002</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. This paper addresses the question of the learnability of generalized quantifiers. This topic was first taken up in (van Benthem 1986a) but has received little attention since then. There are a few results: in (Clark 1996) it was shown that first-order generalized ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RGIjT1spj6cJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:RGIjT1spj6cJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12073914598150070852&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12073914598150070852&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/77telyrg3pmm7cnc.pdf</url>
        <title status="complete" source="scholar.google.com">Counting extensional differences in BC-learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.8062&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, S Terwijn</author>
        <proceeding status="partial" source="scholar.google.com">Grammatical Inference: Algorithms and &#8230;</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Let BC be the model of behaviourally correct function learning as introduced by Barzdins [4] and Case and Smith [8]. We introduce a mind change hierarchy for BC, counting the number of extensional differences in the hypotheses of a learner. We compare the resulting ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:aUlyOc03SogJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9820723292006402409&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9820723292006402409&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.springerlink.com/index/amayby2r5wn99wrj.pdf</url>
        <title status="complete" source="scholar.google.com">Learning algebraic structures from text using semantical knowledge</title>
        <pdf>http://cs5824.userapi.com/u11728334/docs/9e67ff61eb70/Michael_M_Richter_Algorithmic_Learning_Theory_9.pdf#page=331</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, Y Ventsov</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1998</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The present work investigates to which extent semantical knowledge can support the learning of basic mathematical concepts. The considered learning criteria are learning characteristic or enumerable indices for languages from positive data where the learner ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:-xRmirstl1YJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6239506092249191675&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6239506092249191675&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://dl.acm.org/citation.cfm?id=307450</url>
        <title status="complete" source="scholar.google.com">On a generalized notion of mistake bounds</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.115.8551&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the twelfth annual conference on &#8230;</proceeding>
        <year>1999</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract The present paper proposes the use of constructive ordinals as mistake bounds in the online learning model. This approach elegantly generalizes the applicability of the on-line mistake bound model to learnability analysis of very expressive concept classes like ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MyqL-H2ICScJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2812929516891744819&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2812929516891744819&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397507002277</url>
        <title status="complete" source="scholar.google.com">On the data consumption benefits of accepting increased uncertainty</title>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In the context of learning paradigms of identification in the limit, we address the question: why is uncertainty sometimes desirable? We use mind change bounds on the output hypotheses as a measure of uncertainty and interpret &#39;desirable&#39;as reduction in data ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:YN_1eqwpL5wJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11254259814596206432&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://www.springerlink.com/index/6LYLFEKMFX7KTYQ4.pdf</url>
        <title status="complete" source="scholar.google.com">On the data consumption benefits of accepting increased uncertainty</title>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2004</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In the context of learning paradigms of identification in the limit, we address the question: why is uncertainty sometimes desirable? We use mind change bounds on the output hypotheses as a measure of uncertainty, and interpret &#39;desirable&#39;as reduction in data ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:vahgiAbccK4J:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12569788480607004861&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <url>https://www1.comp.nus.edu.sg/~fstephan/alt2004.ps</url>
        <title status="complete" source="scholar.google.com">On the Data Consumption Beneï¬ts of Accepting Increased Uncertainty</title>
        <pdf>https://www1.comp.nus.edu.sg/~fstephan/alt2004.ps</pdf>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">comp.nus.edu.sg</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract In the context of learning paradigms of identification in the limit, We address the question: Why is uncertainty sometimes desirable? VVe use mind change bounds on the output hypotheses a measure of uncertainty, and interpret &#39;desirable&#39;as reduction i11 data ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Er3nw-LMkmMJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7175022430676040978&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="38">
    <url>http://www.springerlink.com/index/1xtm4b75003x05n2.pdf</url>
    <title status="complete" source="scholar.google.com">Gold-style and query learning under various constraints on the target class</title>
    <pdf>http://webdocs.cs.ualberta.ca/~zilles/jainLZ05queries.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, S Lange, S Zilles</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2005</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 School of Computing, National University of Singapore, Singapore 117543 sanjay@comp.nus.edu.sg 2 Fachhochschule Darmstadt, FB Informatik, Haardtring 100, 64295 Darmstadt, Germanys.lange@fbi.fh-darmstadt.de 3 DFKI GmbH, Erwin-SchrÃ¶dinger-StraÃe, 67663 ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:4j9bAmkZKv0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>11</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=18242421179419410402&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>4</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=18242421179419410402&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="4">
        <result id="0">
        <url>http://www.springerlink.com/index/82329846173M8772.pdf</url>
        <title status="complete" source="scholar.google.com">One-shot learners using negative counterexamples and nearest positive examples</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2315/1/tra3-07.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">As some cognitive research suggests, in the process of learning languages, in addition to overt explicit negative evidence, a child often receives covert explicit evidence in form of corrected or rephrased sentences. In this paper, we suggest one approach to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:70f8Jtnk5nEJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8207498992242411503&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8207498992242411503&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S030439750700549X</url>
        <title status="complete" source="scholar.google.com">A general comparison of language learning from examples and from queries</title>
        <pdf>http://pdf.aminer.org/000/235/383/inductive_learning_of_recurrence_term_languages_from_positive_data.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, S Lange, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In language learning, strong relationships between Gold-style models and query models have recently been observed: in some quite general setting Gold-style learners can be replaced by query learners and vice versa, without loss of learning capabilities. These &#39; ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:KrySs3uRs9AJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15038523541199961130&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15038523541199961130&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.tesisenred.net/bitstream/handle/10803/8792/Thesis.pdf</url>
        <title status="complete" source="scholar.google.com">Language Learning with Correction Queries</title>
        <pdf>http://www.tesisenred.net/bitstream/handle/10803/8792/Thesis.pdf</pdf>
        <author status="complete" source="scholar.google.com">C TËÄ±rnauca</author>
        <year>2009</year>
        <source>tesisenred.net</source>
        <snippet status="partial" source="scholar.google.com">I would not be here today if it was not for my dear friend and colleague Mihai Ionescu, who persuaded me to continue my studies and to enroll in a PhD program in Tarragona. Also, I would like to address my gratitude to my mother, first of all, for raising me the way she did, ...</snippet>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:kvw1EEn1D8AJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13839549874086214802&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.tdx.cat/handle/10803/8792</url>
        <title status="complete" source="scholar.google.com">Language learning with correction queries</title>
        <pdf>http://www.tdx.cat/bitstream/handle/10803/8792/Thesis.pdf.txt?sequence=2</pdf>
        <author status="complete" source="scholar.google.com">C Tirnauca</author>
        <year>2009</year>
        <source>tdx.cat</source>
        <snippet status="partial" source="scholar.google.com">In the field of grammatical inference, the goal of any learning algorithm is to identify a target concept from a given class by having access to a specific type of information. The main learning settings are Gold&#39;s model of learning in the limit and Angluin&#39;s query learning. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:vPYbLipk9tIJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15201447724560676540&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15201447724560676540&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="39">
    <url>http://www.springerlink.com/index/X42R7787R321T705.pdf</url>
    <title status="complete" source="scholar.google.com">Generalization and specialization strategies for learning re languages</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/mon.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
    <proceeding status="complete" source="scholar.google.com">Annals of Mathematics and Artificial Intelligence</proceeding>
    <year>1998</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... a Department of Information Systems and Computer Science, National University of Singapore,Singapore 119260, Republic of Singapore E-mail: sanjay@iscs.nus.edu.sg b School of ComputerScience and Engineering, The University of New South Wales, Sydney, NSW 2052 ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:vGf5KkQAIYkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>7</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=9881179350206343100&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>12</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=9881179350206343100&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="12">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397508001503</url>
        <title status="complete" source="scholar.google.com">Learning indexed families of recursive languages from positive data: A survey</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/tcs08lzz.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, T Zeugmann, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In the past 40 years, research on inductive inference has developed along different lines, eg, in the formalizations used, and in the classes of target concepts considered. One common root of many of these formalizations is Gold&#39;s model of identification in the limit. This model ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:kHdpMOKBOpwJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11257453027040786320&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>39</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11257453027040786320&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/prebbr91cb17uenx.pdf</url>
        <title status="complete" source="scholar.google.com">Unlearning helps</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2205/1/TRA5-06.pdf</pdf>
        <author status="complete" source="scholar.google.com">G Baliga, J Case, W Merkle, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">Automata, Languages and &#8230;</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Overregularization seen in child language learning, re verb tense constructs, involves abandoning correct behaviors for incorrect ones and later reverting to correct behaviors. Quite a number of other child development phenomena also follow this U-shaped form of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Kz0TSnrOJQwJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>24</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=875332727217536299&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>20</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=875332727217536299&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540107001095</url>
        <title status="complete" source="scholar.google.com">When unlearning helps</title>
        <author status="partial" source="scholar.google.com">G Baliga, J Case, W Merkle, F Stephan&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Information and &#8230;</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Overregularization seen in child language learning, for example, verb tense constructs, involves abandoning correct behaviours for incorrect ones and later reverting to correct behaviours. Quite a number of other child development phenomena also follow this U- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:4FHwvqlchk8J:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5730369459998183904&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>18</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5730369459998183904&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000007000797</url>
        <title status="complete" source="scholar.google.com">Non-U-shaped vacillatory and team learning</title>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">Journal of Computer and System &#8230;</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">U-shaped learning behaviour in cognitive development involves learning, unlearning and relearning. It occurs, for example, in learning irregular verbs. The prior cognitive science literature is occupied with how humans do it, for example, general rules versus tables of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:EQmrDMaxldIJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15174229983668930833&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15174229983668930833&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/7NDLJGW0PUQ0N9P5.pdf</url>
        <title status="complete" source="scholar.google.com">Non U-shaped vacillatory and team learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.127.40&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">U-shaped learning behaviour in cognitive development involves learning, unlearning and relearning. It occurs, for example, in learning irregular verbs. The prior cognitive science literature is occupied with how humans do it, for example, general rules versus tables of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:SiUKzidZXvAJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17320379244408874314&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17320379244408874314&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.111.1902&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">U-shaped learning may be necessary 3</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.111.1902&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carluccia, J Caseb, S Jainc, F Stephand</author>
        <year>2005</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract U-shaped learning behaviour in cognitive development involves learning, unlearning and relearning. It occurs, for example, in learning irregular verbs. The prior cognitive science literature is occupied with how humans do it, for example, general rules ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:TF-JIATWghcJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:TF-JIATWghcJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>20</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1694151723058814796&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1694151723058814796&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397508001515</url>
        <title status="complete" source="scholar.google.com">Learning and extending sublanguages</title>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A number of natural models for learning in the limit are introduced to deal with the situation when a learner is required to provide a grammar covering the input even if only a part of the target language is available. Examples of language families are exhibited that are ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:eK38qPkm9ZIJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10589412952555433336&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10589412952555433336&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/H2112615PHQ60P40.pdf</url>
        <title status="complete" source="scholar.google.com">Learning and extending sublanguages</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.114.3889&amp;rep=rep1&amp;type=pdf#page=150</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A number of natural models for learning in the limit is introduced to deal with the situation when a learner is required to provide a grammar covering the input even if only a part of the target language is available. Examples of language families are exhibited that are ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:keIkDRy3wyUJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2721219930969399953&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2721219930969399953&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>https://dl.comp.nus.edu.sg/dspace/handle/1900.100/1510</url>
        <title status="complete" source="scholar.google.com">U-shaped leaning may be necessary</title>
        <pdf>https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1510/1/upload.pdf</pdf>
        <author status="complete" source="scholar.google.com">C Lorenzo, C John, J Sanjay, S Frank</author>
        <year>2004</year>
        <source>dl.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract: U-shaped learning behaviour in cognitive development involves learning, unlearning and relearning. It occurs, for example, in learning irregular verbs. The prior cognitive science literature is occupied with how humans do it, for example, general rules ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:aN5UGzEe8gMJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=284322922738540136&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397500002735</url>
        <title status="complete" source="scholar.google.com">Aspects of complexity of probabilistic learning under monotonicity constraints</title>
        <author status="complete" source="scholar.google.com">L Meyer</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In the setting of learning indexed families, probabilistic learning under monotonicity constraints is more powerful than deterministic learning under monotonicity constraints, even if the probability is close to 1, provided the learning machines are restricted to proper ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:zIyqQdyBJ_0J:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18241691598681967820&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <title status="complete" source="scholar.google.com">U-shaped learning may be necessary 3</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:9zFARK7e_V8J:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTR/tcstr_07_31/tcstr_07_31.pdf</url>
        <title status="complete" source="scholar.google.com">TCS Technical Report</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTR/tcstr_07_31/tcstr_07_31.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, T Zeugmann, S Zilles</author>
        <year>2007</year>
        <source>www-alg.ist.hokudai.ac.jp</source>
        <snippet status="partial" source="scholar.google.com">Abstract In the past 40 years, research on inductive inference has developed along different lines, concerning different formalizations of learning models and in particular of target concepts for learning. One common root of many of these is Gold&#39;s model of identification ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:uMhVpfJ4388J:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:uMhVpfJ4388J:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14978823869208840376&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="40">
    <url>http://www.sciencedirect.com/science/article/pii/030439759400162C</url>
    <title status="complete" source="scholar.google.com">On aggregating teams of learning machines</title>
    <pdf>http://pdf.aminer.org/000/039/386/on_aggregating_teams_of_learning_machines.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
    <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
    <year>1995</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... 1. Introduction The present paper investigates the problem of aggregating a team oflearning machines into a single learning machine. In other words, we are interestedin finding * Corresponding author. E-mail: sanjay@iscs.nus.sg. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:9BaHDhhKKvYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>20</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=17738071549535524596&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>13</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=17738071549535524596&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="13">
        <result id="0">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=JYcznFCN3xcC&amp;oi=fnd&amp;pg=PA259&amp;ots=IG3ZrHMt1x&amp;sig=pl_AOa8-kUH-zzH9mPEHkT9dX0c</url>
        <title status="complete" source="scholar.google.com">6 Learning in Multiagent Systems</title>
        <pdf>http://wwwbrauer.informatik.tu-muenchen.de/~weissg/Docs/sen-weiss-MAL99.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Sen, G Weiss</author>
        <proceeding status="partial" source="scholar.google.com">Multiagent Systems: A Modern Approach to &#8230;</proceeding>
        <year>2000</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">Learning and intelligence are intimately related to each other. It is usually agreed that a system capable of learning deserves to be called intelligent; and conversely, a system being considered as intelligent is, among other things, usually expected to be able to learn. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:To0bwrCWoekJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16834902568002620750&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>168</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16834902568002620750&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/P811426W6266L1MX.pdf</url>
        <title status="complete" source="scholar.google.com">Three decades of team learning</title>
        <author status="complete" source="scholar.google.com">C Smith</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1994</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The philosophers of science were the first group to apply formal methods to the process of discovery [Bur58, Car52, ResT0]. They developed models of the scien- tific method that entailed .alternating phases of data acquisition and hypothesis formation. The linguists used amazingly similar ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:HYNoroo8D0kJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5264493055748637469&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>30</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5264493055748637469&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.53.9905&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Computational limits on team identification of languages</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.53.9905&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>1996</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract A team of learning machines is essentially a multiset of learning machines. A team is said to successfully identify a concept just in case each member of some nonempty subset of the team identi es the concept. Team identi cation of programs for computable functions ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:gZGqzDA4sGYJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:gZGqzDA4sGYJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>15</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7399475970013041025&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>17</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7399475970013041025&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/7275u31884w23584.pdf</url>
        <title status="complete" source="scholar.google.com">On identification by teams and probabilistic machines</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.119.8736&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning for Knowledge-Based Systems</proceeding>
        <year>1995</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Inductive inference in the scientific domain is seldom an individual enterprise. Many a scientific breakthrough are result of the efforts of several scientists investigating a problem; scientific success is achieved if any one or more of members of the scientific community are successful. This ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:KIRo8csh0vMJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17569142256137962536&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17569142256137962536&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <title status="complete" source="scholar.google.com">A survey of inductive inference with an emphasis on queries</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.33.5664&amp;rep=rep1&amp;type=pdf</pdf>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GnKgfqPifP0J:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18265723380539879962&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18265723380539879962&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397597000170</url>
        <title status="complete" source="scholar.google.com">Probabilistic language learning under monotonicity constraints</title>
        <author status="complete" source="scholar.google.com">L Meyer</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>1997</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present paper deals with probabilistic identification of indexed families of uniformly recursive languages from positive data under monotonicity constraints. Thereby, we consider conservative, strong-monotonic and monotonic probabilistic learning of indexed ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:6Ol8yeF8qvoJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18062386564712688104&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18062386564712688104&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://pdf.aminer.org/000/311/008/unions_of_identifiable_families_of_languages.pdf</url>
        <title status="complete" source="scholar.google.com">Team learning of formal languages</title>
        <pdf>http://pdf.aminer.org/000/311/008/unions_of_identifiable_families_of_languages.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">WSIMLC95</proceeding>
        <year>1995</year>
        <source>pdf.aminer.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract A team of learning machines is a multiset of learning machines. A team is said to successfully learn a concept just in case each member of some nonempty subset, of predetermined size, of the team learns the concept. Team learning of computer programs ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:VMXWutYixfwJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:VMXWutYixfwJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>21</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18214002573622822228&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18214002573622822228&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/N06E3108MYXKV600.pdf</url>
        <title status="complete" source="scholar.google.com">Team learning of computable languages</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.108.396&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Theory of Computing Systems</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. A team of learning machines is a multiset of learning machines. A team is said to learn a concept successfully if each member of some nonempty subset, of predetermined size, of the team learns the concept. Team learning of languages may be viewed as a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:o5szlboYGy4J:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3322276339762043811&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3322276339762043811&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.springerlink.com/index/f581mp71128658l0.pdf</url>
        <title status="complete" source="scholar.google.com">Team learning of recursive languages</title>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">PRICAI&#39;96: Topics in Artificial Intelligence</proceeding>
        <year>1996</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A team of learning machines is a multiset of learning machines. A team is said to successfully learn a concept just in case each member of some nonempty subset, of predetermined size, of the team learns the concept. Team learning of languages turns out ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Q2WHuIBNz38J:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9209664978242987331&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9209664978242987331&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.cs.rochester.edu/users/faculty/dana/zhu-dissertation.pdf</url>
        <title status="complete" source="scholar.google.com">Learning to Cooperate</title>
        <pdf>http://www.cs.rochester.edu/users/faculty/dana/zhu-dissertation.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Zhu</author>
        <year>2003</year>
        <source>cs.rochester.edu</source>
        <snippet status="partial" source="scholar.google.com">Abstract Game theory is not only useful to understand the performance of human and autonomous game players, but it is also widely employed to solve resource allocation problems in distributed decision making systems. These distributed systems are mostly ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:fOUmaO9zNBoJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:fOUmaO9zNBoJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1888261615856838012&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www.springerlink.com/index/J8584730L3R17371.pdf</url>
        <title status="complete" source="scholar.google.com">The job assignment problem: A study in parallel and distributed machine learning</title>
        <pdf>http://www.personeel.unimaas.nl/gerhard-weiss/publications/BB10.pdf</pdf>
        <author status="complete" source="scholar.google.com">G WeiÃ</author>
        <proceeding status="complete" source="scholar.google.com">Foundations of Computer Science</proceeding>
        <year>1997</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This article describes a parallel and distributed machine learning approach to a basic variant of the job assignment problem. The approach is in the line of the multiagent learning paradigm as investigated in distributed artificial intelligence. The job assignment problem ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:581XeTTCNlsJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>17</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6572654236823703015&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.98.3940&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Finite identification of functions by teams with success ratio</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.98.3940&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma, M Velauthapillai</author>
        <year>2007</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract Consider a scenario in which an algorithmic machine, M, is being fed the graph of a computable function f. M is said to finitely identify f just in case after inspecting a finite portion of the graph of f it emits its first conjecture which is a program for f, and it never abandons ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:P24AmYe9XGQJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:P24AmYe9XGQJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7231863491735350847&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <title status="complete" source="scholar.google.com">An Introduction to Learning Systems/Eine Einf uhrung in Lernende Systeme Version 2.1</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:NcuvxM70QroJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13421559008417794869&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="41">
    <url>http://dl.acm.org/citation.cfm?id=279982</url>
    <title status="complete" source="scholar.google.com">On the power of learning robustly</title>
    <author status="complete" source="scholar.google.com">S Jain, C Smith, R Wiehagen</author>
    <proceeding status="partial" source="scholar.google.com">&#8230; of the eleventh annual conference on &#8230;</proceeding>
    <year>1998</year>
    <source>dl.acm.org</source>
    <snippet status="partial" source="scholar.google.com">Page 1. On the Power of Learning Robustly Sanjay Jain Department of ISCS NationalUniversity of Singapore Singapore 119260 sanjay@iscs.nus.edu.sg Carl Smith RolfWiehagen Department of Computer Science Department ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:ORkvWqtuUjIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>4</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=3626082332218169657&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>11</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=3626082332218169657&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="11">
        <result id="0">
        <url>http://dl.acm.org/citation.cfm?id=279952</url>
        <title status="complete" source="scholar.google.com">Robust learning aided by context</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/context.pdf</pdf>
        <author status="partial" source="scholar.google.com">J Case, S Jain, M Ott, A Sharma&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the &#8230;</proceeding>
        <year>1998</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Empirical st, udies of multitask learning provide some evidence that the performance of a learning system on its intended targets improves by presenting to the learning system related tasks, also called contexts, as additional input. Angluin, Gasarch, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ihOGY9NnPVMJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>34</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5998064436332860298&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>19</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5998064436332860298&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540199928055</url>
        <title status="complete" source="scholar.google.com">Robust behaviorally correct learning</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/robbc.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>1999</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Intuitively, a class of functions is robustly learnable if not only the class itself, but also all of the transformations of the class under natural transformations (such as via general recursive operators) are learnable. Fulk showed the existence of a nontrivial class which is robustly ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:zRgar4gEM3QJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8373041117311670477&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>14</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8373041117311670477&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/30508hpk5cedmc48.pdf</url>
        <title status="complete" source="scholar.google.com">Avoiding coding tricks by hyperrobust learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.133.1424&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">M Ott, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The present work introduces and justifies the notion of hyperrobust learning where one fixed learner has to learn all functions in a given class plus their images under primitive recursive operators. The following is shown: This notion of learnability does not change if the class ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:hh7HHpYQ31EJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>31</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5899452273826143878&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5899452273826143878&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000000917008</url>
        <title status="complete" source="scholar.google.com">Robust learning is rich</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.96.6122&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, C Smith, R Wiehagen</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Intuitively, a class of objects is robustly learnable if not only this class itself is learnable but all of its computable transformations remain learnable as well. In that sense, being learnable robustly seems to be a desirable property in all fields of learning. We will study this ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1RLuCKYwPi8J:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3404211858011198165&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3404211858011198165&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.sciencedirect.com/science/article/pii/S030439750100086X</url>
        <title status="complete" source="scholar.google.com">Avoiding coding tricks by hyperrobust learning</title>
        <author status="complete" source="scholar.google.com">M Ott, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2002</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present work introduces and justifies the notion of hyperrobust learning where one fixed learner has to learn all functions in a given class plus their images under primitive recursive operators. The following are shown: The notion of learnability does not change if the class ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:6dr-DNkEbLMJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12928713960546294505&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12928713960546294505&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.springerlink.com/index/EKX087X862286207.pdf</url>
        <title status="complete" source="scholar.google.com">On the uniform learnability of approximations to non-recursive functions</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/alt99sz.pdf</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Blum and Blum (1975) showed that a class BB of suitable recursive approximations to the halting problem is reliably EX-learnable. These investigations are carried on by showing that BB is neither in NUM nor robustly EX-learnable. Since the definition of the class BB is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:LOx7t0gGJBoJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>15</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1883637453533473836&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1883637453533473836&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.springerlink.com/index/5n75eb1v97fxh6qq.pdf</url>
        <title status="complete" source="scholar.google.com">Robust LearningâRich and Poor</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.36.2906&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan, R Wiehagen</author>
        <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Aclass C of recursive functions is called robustly learnable in the sense I (where I is any success criterion of learning) if not only C itself but even all transformed classes T (C) where T is any general recursive operator, are learnable in the sense I. It was already shown ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:6-x8KxzTtaYJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>21</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12012739699022818539&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12012739699022818539&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/1233111895g360t7.pdf</url>
        <title status="complete" source="scholar.google.com">Learning real polynomials with a Turing machine</title>
        <author status="complete" source="scholar.google.com">D Cheung</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We provide an algorithm to PAC learn multivariate polynomials with real coefficients. The instance space from which labeled samples are drawn is IR N but the coordinates of such samples are known only approximately. The algorithm is iterative and the main ingredient ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:9j_KUzUkmQwJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=907796611349495798&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=907796611349495798&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/doitr166sz.ps.gz</url>
        <title status="complete" source="scholar.google.com">DOI Technical Report</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/doitr166sz.ps.gz</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, T Zeugmann</author>
        <year>1999</year>
        <source>www-alg.ist.hokudai.ac.jp</source>
        <snippet status="complete" source="scholar.google.com">Abstract Blum and Blum (1975) showed that a class B of suitable recursive approximations to the halting problem K is reliably EX-learnable but left it open whether or not B is in NUM. By showing B to be not in NUM we resolve this old problem.</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ypBkC6zAZg8J:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:ypBkC6zAZg8J:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.comp.nus.edu.sg/~sanjay/paps/robsur-c.pdf</url>
        <title status="complete" source="scholar.google.com">A Survey of Robust Learning</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/robsur-c.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <year>2008</year>
        <source>comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract. A class of objects is said to be robustly learnable if not only this class itself is learnable but all of its computable âtransformationsâ are also learnable. We study robust learning within the framework of inductive inference. A class of recursive functions is said ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:td7IYjEIaMwJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:td7IYjEIaMwJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14729031589518958261&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <title status="complete" source="scholar.google.com">John Case Sanjay Jain Matthias Ott</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:4pic7DzOdwkJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="42">
    <url>http://www.springerlink.com/index/W4537355387873K3.pdf</url>
    <title status="complete" source="scholar.google.com">Prescribed learning of RE classes</title>
    <pdf>https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2576/1/TR10-07.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, F Stephan, N Ye</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2007</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 Department of Computer Science, National University of Singapore, Singapore 117590,Republic of Singapore sanjay@comp.nus.edu.sg 2 Department of Computer Science andDepartment of Mathematics, National University of Singapore, Singapore 117543, Republic of ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:WtrFAkGimIoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>9</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=9986910573797169754&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>2</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=9986910573797169754&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="2">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540110002026</url>
        <title status="complete" source="scholar.google.com">Hypothesis spaces for learning</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/hypdep.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2011</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In this paper we survey some results in inductive inference showing how learnability of a class of languages may depend on the hypothesis space chosen. Additionally, optimal hypothesis spaces, usable for every learnable class, are considered. We also discuss ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:nE03dzw6FbIJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12832226744634658204&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12832226744634658204&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://iospress.metapress.com/index/506U32192564M0H5.pdf</url>
        <title status="complete" source="scholar.google.com">Prescribed learning of indexed families</title>
        <pdf>https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2573/1/TRB9-07.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan, Y Nan</author>
        <proceeding status="complete" source="scholar.google.com">Fundamenta Informaticae</proceeding>
        <year>2008</year>
        <source>IOS Press</source>
        <snippet status="partial" source="scholar.google.com">This work extends studies of Angluin, Lange and Zeugmann on how learnability of a language class depends on the hypothesis space used by the learner. While previous studies mainly focused on the case where the learner chooses a particular hypothesis ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:L0BIVfdJrrIJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>29</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12875309711335374895&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12875309711335374895&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="43">
    <url>http://www.springerlink.com/index/BN4WUBDWE0233BPV.pdf</url>
    <title status="complete" source="scholar.google.com">Synthesizing learners tolerating computable noisy data</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/nrec.pdf</pdf>
    <author status="complete" source="scholar.google.com">J Case, S Jain</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>1998</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... Noisy Data John Case1 and Sanjay Jain2 1 Department of CIS University of Delaware Newark,DE 19716, USA Email: case@cis.udel.edu 2 Sanjay Jain Department of ISCS National Universityof Singapore Singapore 119260 Email: sanjay@iscs.nus.edu.sg Abstract. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:NQuQP4PCMXcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>18</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=8588859833335155509&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>10</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=8588859833335155509&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="10">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397501004042</url>
        <title status="complete" source="scholar.google.com">On the power of incremental learning</title>
        <author status="complete" source="scholar.google.com">S Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2002</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper provides a systematic study of incremental learning from noise-free and from noisy data. As usual, we distinguish between learning from positive data and learning from positive and negative data, synonymously called learning from text and learning from ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:9XQsOKjr0GIJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7120450118602224885&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>27</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7120450118602224885&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397500002723</url>
        <title status="complete" source="scholar.google.com">Learning algebraic structures from text</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.41.615&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, Y Ventsov</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present work investigates the learnability of classes of substructures of some algebraic structures: submonoids and subgroups of given groups, ideals of given commutative rings, subfields of given vector spaces. The learner sees all positive data but no negative one ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:pOAgDmnQfi8J:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3422401916475334820&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>23</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3422401916475334820&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/F7Q6184682RG6200.pdf</url>
        <title status="complete" source="scholar.google.com">On the strength of incremental learning</title>
        <author status="complete" source="scholar.google.com">S Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper provides a systematic study of incremental learning from noise-free and from noisy data, thereby distinguishing between learning from only positive data and from both positive and negative data. Our study relies on the notion of noisy data introduced in [22]. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:oCAsckbuppkJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11071798720267559072&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11071798720267559072&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/mbhav1ap8ga0pu01.pdf</url>
        <title status="complete" source="scholar.google.com">Language learning with a neighbor system</title>
        <author status="complete" source="scholar.google.com">Y Mukouchi, M Sato</author>
        <proceeding status="complete" source="scholar.google.com">Discovery Science</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We consider inductive language learning from positive examples, some of which may be incorrect. In the present paper, the error or incorrectness we consider is the one described uniformly in terms of a distance over strings. Firstly, we introduce a notion of a recursively ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cOdYf8F5xJoJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11152172449248372592&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11152172449248372592&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397502004206</url>
        <title status="complete" source="scholar.google.com">Refutable language learning with a neighbor system</title>
        <author status="complete" source="scholar.google.com">Y Mukouchi, M Sato</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We consider inductive language learning and machine discovery from examples with some errors. In the present paper, the error or incorrectness we consider is the one described uniformly in terms of a distance over strings. Firstly, we introduce a notion of a recursively ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:UOGaqoDgODwJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4339465084194185552&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4339465084194185552&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.springerlink.com/index/6HW6VLPJ7XJ22BAH.pdf</url>
        <title status="complete" source="scholar.google.com">Refutable language learning with a neighbor system</title>
        <pdf>http://cs5824.userapi.com/u11728334/docs/20e8cf4a8295/Naoki_Abe_Algorithmic_Learning_Theory_12_conf_A.pdf#page=276</pdf>
        <author status="complete" source="scholar.google.com">Y Mukouchi, M Sato</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We consider inductive language learning and machine discovery from examples with some errors. In the present paper, the error or incorrectness we consider is the one described uniformly in terms of a distance over strings. Firstly, we introduce a notion of a recursively ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:i9aaqcCduzsJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4304207319687419531&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4304207319687419531&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.5444&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Iterative concept learning from noisy data</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.5444&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S en Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract In the present paper, we study iterative learning of indexable concept classes from noisy data. We distinguish between learning from positive data only and learning from positive and negative data; synonymously, learning from text and informant, respectively. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:hovRSwK6TgMJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:hovRSwK6TgMJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=238332349321939846&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.5172&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">On the power of incremental learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.5172&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S en Langea, G Grieserb</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract This paper provides a systematic study of incremental learning from noise-free and from noisy data. As usual, we distinguish between learning from positive data and learning from positive and negative data, synonymously called learning from text and learning from ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:xOBQUupPq0AJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:xOBQUupPq0AJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4659906107266883780&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.springerlink.com/index/5RDJV0QCC3FKK17K.pdf</url>
        <title status="complete" source="scholar.google.com">Refutable/inductive learning from neighbor examples and its application to decision trees over patterns</title>
        <author status="complete" source="scholar.google.com">M Sato, Y Mukouchi, M Terada</author>
        <proceeding status="complete" source="scholar.google.com">Progress in Discovery Science</proceeding>
        <year>2002</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The paper develops the theory of refutable/inductive learning as a foundation of discovery science from examples. We consider refutable/inductive language learning from positive examples, some of which may be incorrect. The error or incorrectness we consider is the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:zWgPdk1OTTQJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3768754557779142861&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.6756&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">On the strength of incremental learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.6756&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S en Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. This paper provides a systematic study of incremental learning from noise-free and from noisy data, thereby distinguishing between learning from only positive data and from both positive and negative data. Our study relies on the notion of noisy data introduced in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:wMdDg89ZrbwJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:wMdDg89ZrbwJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13595621597896755136&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="44">
    <url>http://www.springerlink.com/index/744gl6106742726h.pdf</url>
    <title status="complete" source="scholar.google.com">Program synthesis in the presence of infinite number of inaccuracies</title>
    <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1391/1/report.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>1994</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... Inaccuracies Sanjay Jain 1 Department of Information Systems and Computer ScienceLower Kent Ridge Road National University of Singapore Singapore 0511, Republicof Singapore Email: sanjay~iscs.nus.sg Abstract. Most ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:mDnNbDEJntsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>10</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=15825096248509938072&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>10</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=15825096248509938072&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="10">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397597000182</url>
        <title status="complete" source="scholar.google.com">Noisy inference and oracles</title>
        <author status="complete" source="scholar.google.com">F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>1997</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present paper deals with several variants of inductive inference from noisy data. The notion of noise is based on the idea that the learner recieves a sequence of data elements such that each correct element appears infinitely often and each incorrect element ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GMtxMtHdCqsJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12324907220817005336&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>22</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12324907220817005336&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/F7357P1580T1575G.pdf</url>
        <title status="complete" source="scholar.google.com">Noisy inference and oracles</title>
        <author status="complete" source="scholar.google.com">F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1995</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A learner noisily infers a function or set, if every correct item is presented infinitely often while in addition some incorrect data (noise) is presented a finite number of times. It is shown that learning from a noisy informant is equal to finite learning with K-oracle from a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:tBlBkmyH02YJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7409414712334555572&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7409414712334555572&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/Y883313L70NM1731.pdf</url>
        <title status="complete" source="scholar.google.com">Learning from multiple sources of inaccurate data</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/mulj.pdf</pdf>
        <author status="complete" source="scholar.google.com">G Baliga, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Analogical and Inductive Inference</proceeding>
        <year>1992</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Most theoretical studies of inductive inference model a situation involving a machine M learning its environment E on following lines. M, placed in E, receives data about E, and simultaneously conjectures a sequence of hypotheses. M is said to learn E just in case the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:8-_nijoirs8J:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14964936246632640499&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14964936246632640499&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <title status="complete" source="scholar.google.com">A survey of inductive inference with an emphasis on queries</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.33.5664&amp;rep=rep1&amp;type=pdf</pdf>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GnKgfqPifP0J:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18265723380539879962&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18265723380539879962&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/F7Q6184682RG6200.pdf</url>
        <title status="complete" source="scholar.google.com">On the strength of incremental learning</title>
        <author status="complete" source="scholar.google.com">S Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper provides a systematic study of incremental learning from noise-free and from noisy data, thereby distinguishing between learning from only positive data and from both positive and negative data. Our study relies on the notion of noisy data introduced in [22]. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:oCAsckbuppkJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11071798720267559072&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11071798720267559072&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://epubs.siam.org/doi/pdf/10.1137/S0097539792239461</url>
        <title status="complete" source="scholar.google.com">Learning from multiple sources of inaccurate data</title>
        <author status="complete" source="scholar.google.com">G Baliga, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">SIAM Journal on Computing</proceeding>
        <year>1997</year>
        <source>SIAM</source>
        <snippet status="partial" source="scholar.google.com">Most theoretical models of inductive inference make the idealized assumption that the data available to a learner is from a single and accurate source. The subject of inaccuracies in data emanating from a single source has been addressed by several authors. The present ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2bqtl92062sJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7776508045410810585&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7776508045410810585&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.springerlink.com/index/mbhav1ap8ga0pu01.pdf</url>
        <title status="complete" source="scholar.google.com">Language learning with a neighbor system</title>
        <author status="complete" source="scholar.google.com">Y Mukouchi, M Sato</author>
        <proceeding status="complete" source="scholar.google.com">Discovery Science</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We consider inductive language learning from positive examples, some of which may be incorrect. In the present paper, the error or incorrectness we consider is the one described uniformly in terms of a distance over strings. Firstly, we introduce a notion of a recursively ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cOdYf8F5xJoJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11152172449248372592&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11152172449248372592&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.5444&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Iterative concept learning from noisy data</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.5444&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S en Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract In the present paper, we study iterative learning of indexable concept classes from noisy data. We distinguish between learning from positive data only and learning from positive and negative data; synonymously, learning from text and informant, respectively. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:hovRSwK6TgMJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:hovRSwK6TgMJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=238332349321939846&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.springerlink.com/index/5RDJV0QCC3FKK17K.pdf</url>
        <title status="complete" source="scholar.google.com">Refutable/inductive learning from neighbor examples and its application to decision trees over patterns</title>
        <author status="complete" source="scholar.google.com">M Sato, Y Mukouchi, M Terada</author>
        <proceeding status="complete" source="scholar.google.com">Progress in Discovery Science</proceeding>
        <year>2002</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The paper develops the theory of refutable/inductive learning as a foundation of discovery science from examples. We consider refutable/inductive language learning from positive examples, some of which may be incorrect. The error or incorrectness we consider is the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:zWgPdk1OTTQJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3768754557779142861&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.6756&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">On the strength of incremental learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.6756&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S en Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. This paper provides a systematic study of incremental learning from noise-free and from noisy data, thereby distinguishing between learning from only positive data and from both positive and negative data. Our study relies on the notion of noisy data introduced in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:wMdDg89ZrbwJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:wMdDg89ZrbwJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13595621597896755136&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="45">
    <url>http://www.sciencedirect.com/science/article/pii/0304397595001352</url>
    <title status="complete" source="scholar.google.com">Learning in the presence of inaccurate information</title>
    <author status="complete" source="scholar.google.com">M Fulk, S Jain</author>
    <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
    <year>1996</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... The above model of learning is based on the work initiated by Gold [14] and has been used ininductive inference of both functions and languages. We refer the reader to [1,4,9,19,15] forbackground material in this field. &#39;&quot;Corresponding author, e-mail: sanjay@iscs.nus.sg. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:06FfqX7UAvoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>6</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=18015195099907989971&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>10</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=18015195099907989971&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="10">
        <result id="0">
        <url>http://www.springerlink.com/index/BN4WUBDWE0233BPV.pdf</url>
        <title status="complete" source="scholar.google.com">Synthesizing learners tolerating computable noisy data</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/nrec.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1998</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">An index for an re class of languages (by definition) generates a sequence of grammars defining the class. An index for an indexed family of languages (by definition) generates a sequence of decision procedures defining the family. F. Stephan&#39;s model of noisy data is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:NQuQP4PCMXcJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8588859833335155509&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8588859833335155509&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/744gl6106742726h.pdf</url>
        <title status="complete" source="scholar.google.com">Program synthesis in the presence of infinite number of inaccuracies</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1391/1/report.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1994</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Most studies modeling inaccurate data in Gold style learning consider cases in which the number of inaccuracies is finite. The present paper argues that this approach is not reasonable for modeling inaccuracies in concepts that are infinite in nature (for example, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:mDnNbDEJntsJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15825096248509938072&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15825096248509938072&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/746143G84P1761X0.pdf</url>
        <title status="complete" source="scholar.google.com">Vacillatory and BC learning on noisy data</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.1104&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1996</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In an earlier paper, Frank Stephan introduced a form of noisy data which nonetheless uniquely determines the true data: correct information occurs infinitely often while incorrect information occurs only finitely often. The present paper considers the effects of this form ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:DwzAHopQyuMJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16414020346056805391&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16414020346056805391&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397599002686</url>
        <title status="complete" source="scholar.google.com">Vacillatory and BC learning on noisy data</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2000</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present work employs a model of noise introduced earlier by the third author. In this model noisy data nonetheless uniquely determines the true data: correct information occurs infinitely often while incorrect information occurs only finitely often. The present paper ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:f2xw58_6_98J:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16140895360367225983&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16140895360367225983&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397508001515</url>
        <title status="complete" source="scholar.google.com">Learning and extending sublanguages</title>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A number of natural models for learning in the limit are introduced to deal with the situation when a learner is required to provide a grammar covering the input even if only a part of the target language is available. Examples of language families are exhibited that are ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:eK38qPkm9ZIJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10589412952555433336&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10589412952555433336&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000000917367</url>
        <title status="complete" source="scholar.google.com">Synthesizing learners tolerating computable noisy data</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">An index for an re class of languages (by definition) generates a sequence of grammars defining the class. An index for an indexed family of recursive languages (by definition) generates a sequence of decision procedures defining the family. F. Stephan&#39;s model of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:I11qjU5RhmMJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7171508854455950627&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7171508854455950627&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>https://dspace.lboro.ac.uk/dspace/handle/2134/6458</url>
        <title status="complete" source="scholar.google.com">Inferring descriptive generalisations of formal languages</title>
        <pdf>https://dspace.lboro.ac.uk/dspace-jspui/bitstream/2134/6458/3/Freydenberger_Reidenbach_COLT_2010[1].pdf</pdf>
        <author status="complete" source="scholar.google.com">DD Freydenberger, D Reidenbach</author>
        <year>2010</year>
        <source>dspace.lboro.ac.uk</source>
        <snippet status="partial" source="scholar.google.com">In the present paper, we introduce a variant of Gold-style learners that is not required to infer precise descriptions of the languages in a class, but that must find descriptive patterns, ie, optimal generalisations within a class of pattern languages. Our first main result ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:y89Prha3ZOIJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16313365058284408779&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16313365058284408779&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/H2112615PHQ60P40.pdf</url>
        <title status="complete" source="scholar.google.com">Learning and extending sublanguages</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.114.3889&amp;rep=rep1&amp;type=pdf#page=150</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A number of natural models for learning in the limit is introduced to deal with the situation when a learner is required to provide a grammar covering the input even if only a part of the target language is available. Examples of language families are exhibited that are ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:keIkDRy3wyUJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2721219930969399953&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2721219930969399953&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=PZjcvI3LWWoC&amp;oi=fnd&amp;pg=PA1&amp;ots=RujHEJgCuG&amp;sig=rWQ6-k42hYRgSJqgtHDdsRDRU-Y</url>
        <title status="complete" source="scholar.google.com">Inclusion of pattern languages and related problems</title>
        <pdf>http://publikationen.ub.uni-frankfurt.de/frontdoor/deliver/index/docId/22351/file/dissertation.pdf</pdf>
        <author status="complete" source="scholar.google.com">DD Freydenberger</author>
        <year>2011</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">Pattern, dh endliche WÃ¶rter aus Variablen und Terminalsymbolen, stellen eine kompakte, elegante und natÃ¼rliche Methode dar, gewisse kontextsensitive Sprachen zu reprÃ¤sentieren. Ein Pattern erzeugt ein Wort durch eine Substitution, die alle Variablen im Pattern durch ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2qmJCHCGK18J:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6857722673339410906&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.springerlink.com/index/D891256047178X85.pdf</url>
        <title status="complete" source="scholar.google.com">Learning from streams</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.157.1225&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan, N Ye</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Learning from streams is a process in which a group of learners separately obtain information about the target to be learned, but they can communicate with each other in order to learn the target. We are interested in machine models for learning from streams ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1jKd9b4XsWYJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>22</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7399721771678380758&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="46">
    <url>http://www.springerlink.com/index/7275u31884w23584.pdf</url>
    <title status="complete" source="scholar.google.com">On identification by teams and probabilistic machines</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.119.8736&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning for Knowledge-Based Systems</proceeding>
    <year>1995</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">Page 1. On Identification by Teams and Probabilistic Machines Sanjay Jain Instituteof Systems Science National University of Singapore Singapore 0511, Republic ofSingapore sanjay@iss.nus.sg Arun Sharma School of Computer ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:KIRo8csh0vMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>7</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=17569142256137962536&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>10</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=17569142256137962536&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="10">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540198927845</url>
        <title status="complete" source="scholar.google.com">Incremental concept learning for bounded data mining</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.7157&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, S Lange, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>1999</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Important refinements of concept learning in the limit from positive data considerably restricting the accessibility of input data are studied. Let c be any concept; every infinite sequence of elements exhausting c is called positive presentation of c. In all learning ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:KMSqppsxSO8J:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>19</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17242085717973845032&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>88</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17242085717973845032&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397500002188</url>
        <title status="complete" source="scholar.google.com">Probabilistic inductive inference: a survey</title>
        <pdf>http://arxiv.org/pdf/cs.LG/9902026</pdf>
        <author status="complete" source="scholar.google.com">A Ambainis</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="complete" source="scholar.google.com">This paper surveys developments in probabilistic inductive inference (learning) of recursive (computable) functions. We mainly focus on finite learning, since this simple paradigm has produced the most interesting (and most complex) results.</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:0IvCr0ZYyFgJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6397460331299507152&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6397460331299507152&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://arxiv.org/abs/cs/0504001</url>
        <title status="complete" source="scholar.google.com">Probabilistic and team PFIN-type learning: general properties</title>
        <pdf>http://arxiv.org/pdf/cs.LG/0504001</pdf>
        <author status="complete" source="scholar.google.com">A Ambainis</author>
        <proceeding status="complete" source="scholar.google.com">arXiv preprint cs/0504001</proceeding>
        <year>2005</year>
        <source>arxiv.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract: We consider the probability hierarchy for Popperian FINite learning and study the general properties of this hierarchy. We prove that the probability hierarchy is decidable, ie there exists an algorithm that receives p_1 and p_2 and answers whether PFIN-type ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:CfbPRuKfTEgJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5209714663160280585&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5209714663160280585&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/m271548vv0n55723.pdf</url>
        <title status="complete" source="scholar.google.com">Unions of identifiable families of languages</title>
        <author status="partial" source="scholar.google.com">K ApsÄ«tis, R Freivalds, R Simanovskis&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; : Learning Syntax from &#8230;</proceeding>
        <year>1996</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper deals with the satisfiability of requirements put on the identifiability of unions of language families. We consider identification in the limit from a text with bounds on mindchanges and anomalies. We show that, though these identification types are not ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Tp0C3Y7dMmcJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7436249540405140814&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7436249540405140814&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397500002760</url>
        <title status="complete" source="scholar.google.com">Closedness properties in ex-identification</title>
        <author status="partial" source="scholar.google.com">K ApsÄ±Ìtis, R Freivalds, R Simanovskis&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Theoretical computer &#8230;</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In this paper we investigate in which cases unions of identifiable classes are also necessarily identifiable. We consider identification in the limit with bounds on mindchanges and anomalies. Though not closed under the set union, these identification types still have ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ccnDb2_tXgoJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=747295651062335857&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=747295651062335857&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>https://qir.kyushu-u.ac.jp/dspace/handle/2324/3005</url>
        <title status="complete" source="scholar.google.com">Incremental concept learning for bounded data mining</title>
        <pdf>https://qir.kyushu-u.ac.jp/dspace/bitstream/2324/3005/1/trcs136.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, S Lange, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">136</proceeding>
        <year>1997</year>
        <source>qir.kyushu-u.ac.jp</source>
        <snippet status="partial" source="scholar.google.com">Important refinements of concept learning in the limit from positive data considerably restricting the accessibility of input data are studied. Let c be any concept; every infinite sequence of elements exhausting c is called positive presentation of c. In all learning ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:WfNv0upB4Q0J:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1000153069061665625&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1000153069061665625&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <title status="complete" source="scholar.google.com">DE 19716, USA case@ cis. udel. edu</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:H_NSPGhiO_oJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.eccc.hpi-web.de/resources/pdf/ambaifi.pdf</url>
        <title status="complete" source="scholar.google.com">Randomization in Learning Theory</title>
        <pdf>http://www.eccc.hpi-web.de/resources/pdf/ambaifi.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Ambainis</author>
        <year>2007</year>
        <source>eccc.hpi-web.de</source>
        <snippet status="partial" source="scholar.google.com">Abstract We consider inductive inference (learning) of recursive (computable) functions. Here, the power of probabilistic algorithms increases as the probability of success decrease. The pattern of this increase depends on the exact requirements about learning algorithm. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:3zD5XGBnM1wJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:3zD5XGBnM1wJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6643767538875969759&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000007000773</url>
        <title status="complete" source="scholar.google.com">Probabilistic and team PFIN-type learning: General properties</title>
        <author status="complete" source="scholar.google.com">A Ambainis</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We consider the probability hierarchy for Popperian FINite learning and study the general properties of this hierarchy. We prove that the probability hierarchy is decidable, ie there exists an algorithm that receives p1 and p2 and answers whether PFIN-type learning with ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:YPa8ZEjXEuIJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16290319508080227936&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.opengrey.eu/item/display/10068/340061</url>
        <title status="complete" source="scholar.google.com">Closedness properties in inductive inference</title>
        <pdf>https://dspace.lu.lv/dspace/bitstream/7/225/1/Smotrovs_J_Slegtibas_tipa_ipasibas_1999.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Smotrovs</author>
        <year>1999</year>
        <source>opengrey.eu</source>
        <snippet status="partial" source="scholar.google.com">RÃ©sumÃ©: This work investigates properties resembling closedness that are characteristic to some well known identification types in inductive inference of total recursive functions and in language learning. The properties can be formulated as follows: if every union of n-1 ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:oYp-GImFkUwJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5517337842373528225&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="47">
    <url>http://www.springerlink.com/index/C2L6T112K5453454.pdf</url>
    <title status="complete" source="scholar.google.com">Index Sets and Universal Numberings</title>
    <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2901/1/TRA3-09.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, F Stephan, J Teutsch</author>
    <proceeding status="partial" source="scholar.google.com">Mathematical Theory and Computational &#8230;</proceeding>
    <year>2009</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 Department of Computer Science, National University of Singapore, Singapore 117417,Republic of Singapore sanjay@comp.nus.edu.sg 2 Department of Computer Science andDepartment of Mathematics, National University of Singapore, Singapore 117543, Republic of ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:EbB0IReDymEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>9</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=7046588702343344145&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>2</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=7046588702343344145&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="2">
        <result id="0">
        <url>http://projecteuclid.org/euclid.jsl/1327068704</url>
        <title status="complete" source="scholar.google.com">An incomplete set of shortest descriptions</title>
        <pdf>http://people.cs.uchicago.edu/~teutsch/papers/sd.pdf</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, J Teutsch</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
        <year>2012</year>
        <source>projecteuclid.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract The truth-table degree of the set of shortest programs remains an outstanding problem in recursion theory. We examine two related sets, the set of shortest descriptions and the set of domain-random strings, and show that the truth-table degrees of these sets ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:hmy4ooGINGEJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>19</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7004373410830118022&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7004373410830118022&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/u73305676038hm5m.pdf</url>
        <title status="complete" source="scholar.google.com">Program self-reference in constructive Scott subdomains</title>
        <pdf>http://www.eecis.udel.edu/~moelius/publications/krt_css_tr.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Moelius</author>
        <proceeding status="complete" source="scholar.google.com">Mathematical Theory and Computational Practice</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Intuitively, a recursion theorem asserts the existence of self-referential programs. Two well-known recursion theorems are Kleene&#39;s Recursion Theorem (krt) and Rogers&#39; Fixpoint Recursion Theorem (fprt). Does one of these two theorems better capture the notion of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:nLFvFHsS3igJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2944811526180024732&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2944811526180024732&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="48">
    <url>http://www.springerlink.com/index/746143G84P1761X0.pdf</url>
    <title status="complete" source="scholar.google.com">Vacillatory and BC learning on noisy data</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.1104&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>1996</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 Computer and Information Sciences Department University of Delaware Newark, DE 19716,USA case@cis.udel.edu 2 Department of Information Systems and Computer Science NationalUniversity of Singapore Singapore 119260 Republic of Singapore sanjay@iscs.nus.sg. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:DwzAHopQyuMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>18</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=16414020346056805391&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>9</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=16414020346056805391&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="9">
        <result id="0">
        <url>http://epubs.siam.org/doi/pdf/10.1137/S0097539793249694</url>
        <title status="complete" source="scholar.google.com">The power of vacillation in language learning</title>
        <pdf>http://dare.uva.nl/document/1137</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">SIAM Journal on Computing</proceeding>
        <year>1999</year>
        <source>SIAM</source>
        <snippet status="partial" source="scholar.google.com">Some extensions are considered of Gold&#39;s influential model of language learning by machine from positive data. Studied are criteria of successful learning featuring convergence in the limit to vacillation between several alternative correct grammars. The ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:iB0Rc-7Qrq0J:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>23</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12515170137060482440&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>82</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12515170137060482440&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540198927821</url>
        <title status="complete" source="scholar.google.com">The synthesis of language learners</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.2144&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">GR Baliga, J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>1999</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">An index for an re class of languages (by definition) is a procedure which generates a sequence of grammars defining the class. An index for an indexed family of languages (by definition) is a procedure which generates a sequence of decision procedures defining ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Bgc6-PuulWUJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7319949166585186054&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>28</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7319949166585186054&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/BN4WUBDWE0233BPV.pdf</url>
        <title status="complete" source="scholar.google.com">Synthesizing learners tolerating computable noisy data</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/nrec.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1998</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">An index for an re class of languages (by definition) generates a sequence of grammars defining the class. An index for an indexed family of languages (by definition) generates a sequence of decision procedures defining the family. F. Stephan&#39;s model of noisy data is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:NQuQP4PCMXcJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8588859833335155509&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8588859833335155509&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/037l58m020020m31.pdf</url>
        <title status="complete" source="scholar.google.com">Synthesizing noise-tolerant language learners</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.114.3595&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1997</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">An index for an re class of languages (by definition) generates a sequence of grammars defining the class. An index for an indexed family of languages (by definition) generates a sequence of decision procedures defining the family. F. Stephan&#39;s model of noisy data is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:87KSL3z6TQYJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=454294548715320051&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=454294548715320051&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/F7Q6184682RG6200.pdf</url>
        <title status="complete" source="scholar.google.com">On the strength of incremental learning</title>
        <author status="complete" source="scholar.google.com">S Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper provides a systematic study of incremental learning from noise-free and from noisy data, thereby distinguishing between learning from only positive data and from both positive and negative data. Our study relies on the notion of noisy data introduced in [22]. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:oCAsckbuppkJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11071798720267559072&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11071798720267559072&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397500001328</url>
        <title status="complete" source="scholar.google.com">Synthesizing noise-tolerant language learners</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">An index for an re class of languages (by definition) generates a sequence of grammars defining the class. An index for an indexed family of languages (by definition) generates a sequence of decision procedures defining the family. F. Stephan&#39;s model of noisy data is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:kQjLOj-Cp0IJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4802950735694858385&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4802950735694858385&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.5444&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Iterative concept learning from noisy data</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.5444&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S en Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract In the present paper, we study iterative learning of indexable concept classes from noisy data. We distinguish between learning from positive data only and learning from positive and negative data; synonymously, learning from text and informant, respectively. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:hovRSwK6TgMJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:hovRSwK6TgMJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=238332349321939846&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.6756&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">On the strength of incremental learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.6756&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S en Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. This paper provides a systematic study of incremental learning from noise-free and from noisy data, thereby distinguishing between learning from only positive data and from both positive and negative data. Our study relies on the notion of noisy data introduced in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:wMdDg89ZrbwJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:wMdDg89ZrbwJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13595621597896755136&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <title status="complete" source="scholar.google.com">Department of Computer and Information Sciences University of Delaware Newark, DE 19716, USA</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RLkDr-qUHr8J:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13771608446225070404&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="49">
    <url>http://www.springerlink.com/index/46v14h8287161651.pdf</url>
    <title status="complete" source="scholar.google.com">Learning of re languages from good examples</title>
    <author status="complete" source="scholar.google.com">S Jain, S Lange, J Nessel</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>1997</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... of Singapore (Emaih sanjay@iscs.nus.edu.sg) 2 Universit~it Leipzig FakultÂ£tf/Jr Mathematik undInformatik Institut f&#39;dr Informatik Augustusplatz 10-11 04109 Leipzig, Germany (Emaihslange@informatik.uni-leipzig.de) UtfiversitÂ£t Kaiserslautern FB Informatik PF 3049 67653 ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:vFHmh7_N4KAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>5</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=11592491663354122684&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>8</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=11592491663354122684&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="8">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397508001448</url>
        <title status="complete" source="scholar.google.com">Measuring teachability using variants of the teaching dimension</title>
        <author status="complete" source="scholar.google.com">FJ Balbach</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In a typical algorithmic learning model, a learner has to identify a target object from partial information. Conversely, in a teaching model a teacher has to give information that allows the learners to identify a target object. We devise two variants of the classical teaching ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:JP_2s7lLLqsJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12334879690374709028&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12334879690374709028&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/G7HTYWYLBQX4P6LD.pdf</url>
        <title status="complete" source="scholar.google.com">Teaching classes with high teaching dimension using few examples</title>
        <author status="complete" source="scholar.google.com">F Balbach</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We consider the Boolean concept classes of 2-term DNF and 1-decision lists which both have a teaching dimension exponential in the number n of variables. It is shown that both classes have an average teaching dimension linear in n. We also consider learners that ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ArxECpI3LTsJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4264125522566757378&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4264125522566757378&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/g812l25483611877.pdf</url>
        <title status="complete" source="scholar.google.com">Teaching randomized learners</title>
        <pdf>http://www.dagstuhl.de/Materials/Files/06/06111/06111.ZeugmannThomas1.Slides.pdf</pdf>
        <author status="complete" source="scholar.google.com">F Balbach, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. The present paper introduces a new model for teaching randomized learners. Our new model, though based on the classical teaching dimension model, allows to study the influence of various parameters such as the learner&#39;s memory size, its ability to provide or ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:jCQpG9zhNfoJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18029565018712384652&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18029565018712384652&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/6MCR39U3DKULF2LL.pdf</url>
        <title status="complete" source="scholar.google.com">Teaching learners with restricted mind changes</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/alt05bz.pdf</pdf>
        <author status="complete" source="scholar.google.com">F Balbach, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Within learning theory teaching has been studied in various ways. In a common variant the teacher has to teach all learners that are restricted to output only consistent hypotheses. The complexity of teaching is then measured by the maximum number of mistakes a consistent ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:tICQAdyappEJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10495246251343249588&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10495246251343249588&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/R1360773437P3450.pdf</url>
        <title status="complete" source="scholar.google.com">Learnability of enumerable classes of recursive functions from âtypicalâ examples</title>
        <pdf>http://cs5824.userapi.com/u11728334/docs/d1adaec0a5be/Osamu_Watanabe_Algorithmic_Learning_Theory_10_c.pdf#page=274</pdf>
        <author status="complete" source="scholar.google.com">J Nessel</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The paper investigates whether it is possible to learn every enumerable classes of recursive functions from âtypicalâ examples.âTypicalâ means, there is a computable family of finite sets, such that for each function in the class there is one set of examples that can be used in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GlN0koXYVhMJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1393539202917094170&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1393539202917094170&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://d-nb.info/991297032/34</url>
        <title status="complete" source="scholar.google.com">TCS Technical Report</title>
        <pdf>http://d-nb.info/991297032/34</pdf>
        <author status="complete" source="scholar.google.com">FJ Balbach, T Zeugmann</author>
        <year>2006</year>
        <source>d-nb.info</source>
        <snippet status="partial" source="scholar.google.com">Abstract The present paper introduces a new model for teaching randomized learners. Our new model, though based on the classical teaching dimension model, allows to study the influence of various parameters such as the learner&#39;s memory size, its ability to provide or ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:vMZDOOljn7AJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:vMZDOOljn7AJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12727000925294806716&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTR/tcstr_05_5/tcstr_05_5.pdf</url>
        <title status="complete" source="scholar.google.com">TCS Technical Report</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTR/tcstr_05_5/tcstr_05_5.pdf</pdf>
        <author status="complete" source="scholar.google.com">FJ Balbach, T Zeugmann</author>
        <year>2005</year>
        <source>www-alg.ist.hokudai.ac.jp</source>
        <snippet status="partial" source="scholar.google.com">Abstract Within algorithmic learning theory teaching has been studied in various ways. In a common variant the teacher has to teach all learners that are restricted to output only consistent hypotheses. The complexity of teaching is then measured by the maximum ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:dkYUyk0cyAIJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:dkYUyk0cyAIJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=200441303846372982&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <title status="complete" source="scholar.google.com">An Introduction to Learning Systems/Eine Einf uhrung in Lernende Systeme Version 2.1</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:NcuvxM70QroJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13421559008417794869&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="50">
    <url>http://www.springerlink.com/index/K762R164N01M8397.pdf</url>
    <title status="complete" source="scholar.google.com">Prudence in vacillatory language identification</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/prud.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
    <proceeding status="complete" source="scholar.google.com">Theory of Computing Systems</proceeding>
    <year>1995</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 Department of Information Systems and Computer Science, National University of Singapore,Singapore 0511, Republic of Singapore sanjay@iscs.nus.sg 2 School of Computer Science andEngineering, The University of New South Wales, Sydney, NSW 2052, Australia arun ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:GhqTljfSxR4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>7</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=2217409527741094426&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>8</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=2217409527741094426&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="8">
        <result id="0">
        <url>http://epubs.siam.org/doi/pdf/10.1137/S0097539793249694</url>
        <title status="complete" source="scholar.google.com">The power of vacillation in language learning</title>
        <pdf>http://dare.uva.nl/document/1137</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">SIAM Journal on Computing</proceeding>
        <year>1999</year>
        <source>SIAM</source>
        <snippet status="partial" source="scholar.google.com">Some extensions are considered of Gold&#39;s influential model of language learning by machine from positive data. Studied are criteria of successful learning featuring convergence in the limit to vacillation between several alternative correct grammars. The ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:iB0Rc-7Qrq0J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>23</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12515170137060482440&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>82</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12515170137060482440&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S016800729500064X</url>
        <title status="complete" source="scholar.google.com">Characterizing language identification in terms of computable numberings</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.100.4696&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Annals of Pure and Applied Logic</proceeding>
        <year>1997</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Identification of programs for computable functions from their graphs and identification of grammars (re indices) for recursively enumerable languages from positive data are two extensively studied problems in the recursion theoretic framework of inductive inference. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:rVGICIY2FScJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2816217091286782381&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2816217091286782381&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.comp.nus.edu.sg/~sanjay/paps/parsh.pdf</url>
        <title status="complete" source="scholar.google.com">Machine induction without revolutionary changes in hypothesis size</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/parsh.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>1996</year>
        <source>comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper provides a beginning study of the effects on inductive inference of paradigm shifts whose absence is approximately modeled by various formal approaches to forbidding large changes in the size of programs conjectured. One approach, called ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:UBoOOrjlzAYJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:UBoOOrjlzAYJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=490019038887287376&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=490019038887287376&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397509000620</url>
        <title status="complete" source="scholar.google.com">Prescribed learning of re classes</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.108.2025&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan, N Ye</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2009</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This work extends studies of Angluin, Lange and Zeugmann on the dependence of learning on the hypothesis space chosen for the language class in the case of learning uniformly recursive language classes. The concepts of class-comprising (where the learner can ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:YdSz3nZgLTsJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>20</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4264170485848462433&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4264170485848462433&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/W4537355387873K3.pdf</url>
        <title status="complete" source="scholar.google.com">Prescribed learning of RE classes</title>
        <pdf>https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2576/1/TR10-07.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan, N Ye</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This work extends studies of Angluin, Lange and Zeugmann on the dependence of learning on the hypotheses space chosen for the class. In subsequent investigations, uniformly recursively enumerable hypotheses spaces have been considered. In the present work, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:WtrFAkGimIoJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9986910573797169754&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9986910573797169754&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.springerlink.com/index/P10132MM72722530.pdf</url>
        <title status="complete" source="scholar.google.com">Machine induction without revolutionary paradigm shifts</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1995</year>
        <source>Springer</source>
        <snippet status="complete" source="scholar.google.com">This paper provides a beginning study of the effects on inductive inference of paradigm shifts whose absence is approximately modeled by various formal approaches to forbidding large changes in the size of programs conjectured.</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:xSMXOf0nWRcJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1682419904337617861&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <title status="complete" source="scholar.google.com">Department of Computer and Information Sciences University of Delaware Newark, DE 19716, USA Email: case@ cis. udel. edu</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:XViiPr1RB8kJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <title status="complete" source="scholar.google.com">Department of Computer and Information Sciences University of Delaware Newark, DE 19716, USA</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RLkDr-qUHr8J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13771608446225070404&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="51">
    <url>http://www.springerlink.com/index/7uh287708126834n.pdf</url>
    <title status="complete" source="scholar.google.com">The structure of intrinsic complexity of learning</title>
    <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
    <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
    <year>1995</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 Department of Information Systems and Computer Science National University of SingaporeSingapore 0511, Republic of Singapore EInail: sanjay@iscs.nus.sg 2 School of Computer Scienceand Engineering The University of New South Wales Sydney, NSW 2052, Australia ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:1FzGzGwQXB4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>4</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=2187641578473282772&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>8</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=2187641578473282772&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="8">
        <result id="0">
        <url>http://www.springerlink.com/index/F9U07Q1178H5U425.pdf</url>
        <title status="complete" source="scholar.google.com">On the intrinsic complexity of learning</title>
        <author status="complete" source="scholar.google.com">R Freivalds, E Kinber, C Smith</author>
        <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
        <year>1995</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A new view of learning is presented. The basis of this view is a natural notion of reduction. We prove completeness and relative difficulty results. An infinite hierarchy of intrinsically more and more difficult to learn concepts is presented. Our results indicate that the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:7HHM9ZpaVwMJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=240760726682890732&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>59</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=240760726682890732&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://dl.acm.org/citation.cfm?id=181150</url>
        <title status="complete" source="scholar.google.com">On the intrinsic complexity of language identification</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/reduc.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the seventh annual conference on &#8230;</proceeding>
        <year>1994</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract A new investigation of the complexity of language identification is undertaken using the notion of reduction from recursion theory and complexity theory. The approach, referred to as the intrinsic complexity of language identification, employs notions of âweakâ and â ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:vwGS9j2SBcEJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>19</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13908683819031069119&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>39</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13908683819031069119&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://dl.acm.org/citation.cfm?id=238093</url>
        <title status="complete" source="scholar.google.com">Elementary formal systems, intrinsic complexity, and procrastination</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.96.6124&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the ninth annual conference on &#8230;</proceeding>
        <year>1996</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Recently, rich subclasses of elementary formal systems(EFS) have been shown to be identifiable in the limit from only positive data. Examples of these classes are Angluin&#39;s pattern languages, unions of pattern languages by Wright and Shinohara, and classes of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:UjWHaftOaIkJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9901250622488261970&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>33</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9901250622488261970&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/ENM087H739QTKHWB.pdf</url>
        <title status="complete" source="scholar.google.com">Consistent polynomial identification in the limit</title>
        <pdf>http://cs5824.userapi.com/u11728334/docs/9e67ff61eb70/Michael_M_Richter_Algorithmic_Learning_Theory_9.pdf#page=434</pdf>
        <author status="complete" source="scholar.google.com">W Stein</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1998</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper aims to extend well known results about polynomial update-time bounded learning strategies in a recursion theoretic setting. We generalize the update-time complexity using the approach of Blum&#39;s computational complexity measures. It will turn ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:3sU5QB2MkvkJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17983590319303280094&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17983590319303280094&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/y261x5nh13x214nw.pdf</url>
        <title status="complete" source="scholar.google.com">Transformations that preserve learnability</title>
        <author status="complete" source="scholar.google.com">A Ambainis, R Freivalds</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1996</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We consider transformations (performed by general recursive operators) mapping recursive functions into recursive functions. These transformations can be considered as mapping sets of recursive functions into sets of recursive functions. A transformation is said to be ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cVbn5QorK_gJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17882434071211497073&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17882434071211497073&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <title status="complete" source="scholar.google.com">A survey of inductive inference with an emphasis on queries</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.33.5664&amp;rep=rep1&amp;type=pdf</pdf>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GnKgfqPifP0J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18265723380539879962&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18265723380539879962&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.8201&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">On the Intrinsic Complexity of Learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.8201&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">R usi ns Freivalds, E m Kinbery, CH Smithz</author>
        <year>1995</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract A new view of learning is presented. The basis of this view is a natural notion of reduction. We prove completeness and relative difculty results. An in nite hierarchy of intrinsically more and more di cult to learn concepts is presented. Our results indicate that ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:XeYDBpiIq9wJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:XeYDBpiIq9wJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15900953095878993501&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <title status="complete" source="scholar.google.com">Inductive inference: theories and techniques</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:lKSmli8IdK8J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="52">
    <url>http://www.springerlink.com/index/6ERU0RJGACY7NH57.pdf</url>
    <title status="complete" source="scholar.google.com">Classes with easily learnable subclasses</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.69.7892&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, W Menzel, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2002</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 National University of Singapore, Singapore 119260, sanjay@comp.nus.edu.sg 2 Institut fÃ¼rLogik, KomplexitÃ¤t und Deduktionssysteme, UniversitÃ¤t Karlsruhe, 76128 Karlsruhe, Germany,EU, menzel@ira.uka.de 3 Mathematisches Institut, UniversitÃ¤t Heidelberg, Im ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:Wa_BkvHgXHMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>14</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=8312766340373000025&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>2</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=8312766340373000025&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="2">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540103000828</url>
        <title status="complete" source="scholar.google.com">Learning by switching type of information</title>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present work is dedicated to the study of modes of data-presentation in the range between text and informant within the framework of inductive inference. In this study, the learner alternatingly requests sequences of positive and negative data. We define various ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:T69CcuOiZkMJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4856748345923907407&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4856748345923907407&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/KUY6NRGG7E72T9R4.pdf</url>
        <title status="complete" source="scholar.google.com">Learning by switching type of information</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.8.2370&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The present work is dedicated to the study of modes of datapresentation between text and informant within the framework of inductive inference. The model is such that the learner requests sequences of positive andnegativ e data andthe relations between the various ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RIi4rBN__vcJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17869860093931587652&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17869860093931587652&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="53">
    <url>http://www.springerlink.com/index/6813w3k86555t79h.pdf</url>
    <title status="complete" source="scholar.google.com">Iterative learning from texts and counterexamples using additional information</title>
    <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2937/1/TRB4-09.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2009</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 School of Computing, National University of Singapore, Singapore 117417, Republic ofSingapore sanjay@comp.nus.edu.sg 2 Department of Computer Science, Sacred HeartUniversity, Fairfield, CT 06825-1000, USA kinbere@sacredheart.edu Abstract. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:m0uIqOprI_kJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>9</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=17952311195222952859&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>3</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=17952311195222952859&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="3">
        <result id="0">
        <url>http://www.springerlink.com/index/WW86604W658G5101.pdf</url>
        <title status="complete" source="scholar.google.com">Solutions to open questions for non-U-shaped learning with memory limitations</title>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2010</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A U-shape occurs when a learner first learns, then unlearns, and, finally, relearns, some target concept. Within the framework of Inductive Inference, previous results have shown, for example, that U-shapes are unnecessary for explanatory learning, but are necessary for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ibyShxgPJ6sJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12332842702605565065&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12332842702605565065&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/X524068561K52072.pdf</url>
        <title status="complete" source="scholar.google.com">Iterative learning from texts and counterexamples using additional information</title>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Machine learning</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract A variant of iterative learning in the limit (cf. Lange and Zeugmann 1996) is studied when a learner gets negative examples refuting conjectures containing data in excess of the target language and uses additional information of the following four types:(a) memorizing ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:3qdCfFnTLTgJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4048124021366237150&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397512009310</url>
        <title status="complete" source="scholar.google.com">Memory-limited non-U-shaped learning with solved open problems</title>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Herein we also distinguish between semantic and syntactic U-shapes. We answer a number of open questions in the prior literature as well as provide new results regarding syntactic U-shapes. Importantly for cognitive science, we see more of a previously noticed pattern ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="54">
    <url>http://www.springerlink.com/index/KUY6NRGG7E72T9R4.pdf</url>
    <title status="complete" source="scholar.google.com">Learning by switching type of information</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.8.2370&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2001</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 School of Computing, National University of Singapore, Singapore 119260, sanjay@comp.nus.edu.sg 2 Mathematisches Institut, Im Neuenheimer Feld 294, Ruprecht-Karls-UniversitÃ¤tHeidelberg, 69120 Heidelberg, Germany, fstephan@math.uni-heidelberg.de Abstract. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:RIi4rBN__vcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>13</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=17869860093931587652&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>2</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=17869860093931587652&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="2">
        <result id="0">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=p-W5c6H2ne0C&amp;oi=fnd&amp;pg=PA1&amp;ots=Od3xl1JyQe&amp;sig=hIgHh7BlptohQu-WaSr5mWC8eYM</url>
        <title status="complete" source="scholar.google.com">Information and Knowledge: A Constructive Type-theoretical Approach</title>
        <author status="complete" source="scholar.google.com">G Primiero</author>
        <year>2007</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">This book develops a philosophical and logical interpretation of the concept of information within the formal structure of Constructive Type Theory (CTT), in a manner concurrent with a diverse range of contemporary perspectives on the philosophy of information. On the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:lEusuOBzGaMJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11752552111608187796&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11752552111608187796&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/vg7tbegp60j98yac.pdf</url>
        <title status="complete" source="scholar.google.com">On the learnability of vector spaces</title>
        <pdf>http://home.gwu.edu/~harizanv/LearningWithStephanJournal.pdf</pdf>
        <author status="complete" source="scholar.google.com">V Harizanov, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2002</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The central topic of the paper is the learnability of the recursively enumerable subspaces of Vâ/V, where Vâ is the standard recursive vector space over the rationals with countably infinite dimension, and V is a given recursively enumerable subspace of Vâ. It is shown ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:fNrxctUkabMJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12927904704518806140&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12927904704518806140&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="55">
    <url>http://www.sciencedirect.com/science/article/pii/S0022000096900896</url>
    <title status="complete" source="scholar.google.com">Program synthesis in the presence of infinite number of inaccuracies</title>
    <author status="complete" source="scholar.google.com">S Jain</author>
    <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
    <year>1996</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... input data. Several results establishing trade-offs between the density and type ofinaccuracies are also derived. * E-mail: sanjay@uscs.nus.sg. Copyright Â© 1996Academic Press. All rights reserved. Supplementary content. 1 2 ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:XLf2CsymMvUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>5</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=17668367683415357276&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>7</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=17668367683415357276&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="7">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397501004042</url>
        <title status="complete" source="scholar.google.com">On the power of incremental learning</title>
        <author status="complete" source="scholar.google.com">S Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2002</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper provides a systematic study of incremental learning from noise-free and from noisy data. As usual, we distinguish between learning from positive data and learning from positive and negative data, synonymously called learning from text and learning from ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:9XQsOKjr0GIJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7120450118602224885&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>27</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7120450118602224885&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/BN4WUBDWE0233BPV.pdf</url>
        <title status="complete" source="scholar.google.com">Synthesizing learners tolerating computable noisy data</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/nrec.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1998</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">An index for an re class of languages (by definition) generates a sequence of grammars defining the class. An index for an indexed family of languages (by definition) generates a sequence of decision procedures defining the family. F. Stephan&#39;s model of noisy data is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:NQuQP4PCMXcJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8588859833335155509&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8588859833335155509&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397502004206</url>
        <title status="complete" source="scholar.google.com">Refutable language learning with a neighbor system</title>
        <author status="complete" source="scholar.google.com">Y Mukouchi, M Sato</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We consider inductive language learning and machine discovery from examples with some errors. In the present paper, the error or incorrectness we consider is the one described uniformly in terms of a distance over strings. Firstly, we introduce a notion of a recursively ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:UOGaqoDgODwJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4339465084194185552&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4339465084194185552&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/6HW6VLPJ7XJ22BAH.pdf</url>
        <title status="complete" source="scholar.google.com">Refutable language learning with a neighbor system</title>
        <pdf>http://cs5824.userapi.com/u11728334/docs/20e8cf4a8295/Naoki_Abe_Algorithmic_Learning_Theory_12_conf_A.pdf#page=276</pdf>
        <author status="complete" source="scholar.google.com">Y Mukouchi, M Sato</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We consider inductive language learning and machine discovery from examples with some errors. In the present paper, the error or incorrectness we consider is the one described uniformly in terms of a distance over strings. Firstly, we introduce a notion of a recursively ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:i9aaqcCduzsJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4304207319687419531&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4304207319687419531&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000000917367</url>
        <title status="complete" source="scholar.google.com">Synthesizing learners tolerating computable noisy data</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">An index for an re class of languages (by definition) generates a sequence of grammars defining the class. An index for an indexed family of recursive languages (by definition) generates a sequence of decision procedures defining the family. F. Stephan&#39;s model of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:I11qjU5RhmMJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7171508854455950627&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7171508854455950627&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.5172&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">On the power of incremental learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.5172&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S en Langea, G Grieserb</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract This paper provides a systematic study of incremental learning from noise-free and from noisy data. As usual, we distinguish between learning from positive data and learning from positive and negative data, synonymously called learning from text and learning from ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:xOBQUupPq0AJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:xOBQUupPq0AJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4659906107266883780&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <title status="complete" source="scholar.google.com">Reflexive Induktive Inferenz</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:arZY9pLbFEAJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4617556942206318186&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="56">
    <url>http://www.springerlink.com/index/037l58m020020m31.pdf</url>
    <title status="complete" source="scholar.google.com">Synthesizing noise-tolerant language learners</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.114.3595&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>1997</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 Department of CIS University of Delaware Newark, DE 19716, USA Emall: case@cis.udel.edu2 Department of ISCS National University of Singapore Singapore 119260 Email:sanjay@iscs.nus.edu.sg 3 The University of New South Wales Sydney, NSW 2052, Australia ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:87KSL3z6TQYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>12</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=454294548715320051&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>7</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=454294548715320051&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="7">
        <result id="0">
        <url>http://epubs.siam.org/doi/pdf/10.1137/S0097539793249694</url>
        <title status="complete" source="scholar.google.com">The power of vacillation in language learning</title>
        <pdf>http://dare.uva.nl/document/1137</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">SIAM Journal on Computing</proceeding>
        <year>1999</year>
        <source>SIAM</source>
        <snippet status="partial" source="scholar.google.com">Some extensions are considered of Gold&#39;s influential model of language learning by machine from positive data. Studied are criteria of successful learning featuring convergence in the limit to vacillation between several alternative correct grammars. The ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:iB0Rc-7Qrq0J:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>23</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12515170137060482440&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>82</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12515170137060482440&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540198927821</url>
        <title status="complete" source="scholar.google.com">The synthesis of language learners</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.2144&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">GR Baliga, J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>1999</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">An index for an re class of languages (by definition) is a procedure which generates a sequence of grammars defining the class. An index for an indexed family of languages (by definition) is a procedure which generates a sequence of decision procedures defining ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Bgc6-PuulWUJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7319949166585186054&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>28</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7319949166585186054&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397501004042</url>
        <title status="complete" source="scholar.google.com">On the power of incremental learning</title>
        <author status="complete" source="scholar.google.com">S Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2002</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper provides a systematic study of incremental learning from noise-free and from noisy data. As usual, we distinguish between learning from positive data and learning from positive and negative data, synonymously called learning from text and learning from ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:9XQsOKjr0GIJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7120450118602224885&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>27</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7120450118602224885&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/F7Q6184682RG6200.pdf</url>
        <title status="complete" source="scholar.google.com">On the strength of incremental learning</title>
        <author status="complete" source="scholar.google.com">S Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper provides a systematic study of incremental learning from noise-free and from noisy data, thereby distinguishing between learning from only positive data and from both positive and negative data. Our study relies on the notion of noisy data introduced in [22]. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:oCAsckbuppkJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11071798720267559072&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11071798720267559072&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.5444&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Iterative concept learning from noisy data</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.5444&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S en Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract In the present paper, we study iterative learning of indexable concept classes from noisy data. We distinguish between learning from positive data only and learning from positive and negative data; synonymously, learning from text and informant, respectively. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:hovRSwK6TgMJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:hovRSwK6TgMJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=238332349321939846&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.5172&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">On the power of incremental learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.5172&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S en Langea, G Grieserb</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract This paper provides a systematic study of incremental learning from noise-free and from noisy data. As usual, we distinguish between learning from positive data and learning from positive and negative data, synonymously called learning from text and learning from ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:xOBQUupPq0AJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:xOBQUupPq0AJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4659906107266883780&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.6756&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">On the strength of incremental learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.6756&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S en Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. This paper provides a systematic study of incremental learning from noise-free and from noisy data, thereby distinguishing between learning from only positive data and from both positive and negative data. Our study relies on the notion of noisy data introduced in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:wMdDg89ZrbwJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:wMdDg89ZrbwJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13595621597896755136&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="57">
    <url>http://www.sciencedirect.com/science/article/pii/0304397594900477</url>
    <title status="complete" source="scholar.google.com">Program size restrictions in computational learning</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/minimal.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
    <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
    <year>1994</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... a hypothesis. Correspondence to: S. Jain, Institute of Systems Science, NationalUniversity of Singapore, Singapore 0511, Singapore. Email addresses of the authors:sanjay@iss.nus.sg and arun@es.unsw.oz.au. 0304-3975 ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:cXCNt227MpIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>8</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=10534688558278340721&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>7</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=10534688558278340721&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="7">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000005800467</url>
        <title status="complete" source="scholar.google.com">Vacillatory learning of nearly minimal size grammars</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.5328&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>1994</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In Gold&#39;s influential language learning paradigm a learning machine converges in the limit to one correct grammar. In an attempt to generalize Gold&#39;s paradigm, Case considered the question whether people might converge to vacillating between up to (some integer) n&gt; 1 ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Y758Y4keMBoJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1887041819296710243&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1887041819296710243&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <title status="complete" source="scholar.google.com">A survey of inductive inference with an emphasis on queries</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.33.5664&amp;rep=rep1&amp;type=pdf</pdf>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GnKgfqPifP0J:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18265723380539879962&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18265723380539879962&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/3u7121w65176281t.pdf</url>
        <title status="complete" source="scholar.google.com">Learning correction grammars</title>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We investigate a new paradigm in the context of learning in the limit: learning correction grammars for classes of re languages. Knowing a language may feature a representation of the target language in terms of two sets of rules (two grammars). The second grammar is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:WspX_CCq1PEJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17425739916852578906&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17425739916852578906&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.comp.nus.edu.sg/~sanjay/paps/parsh.pdf</url>
        <title status="complete" source="scholar.google.com">Machine induction without revolutionary changes in hypothesis size</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/parsh.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>1996</year>
        <source>comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper provides a beginning study of the effects on inductive inference of paradigm shifts whose absence is approximately modeled by various formal approaches to forbidding large changes in the size of programs conjectured. One approach, called ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:UBoOOrjlzAYJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:UBoOOrjlzAYJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=490019038887287376&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=490019038887287376&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.sciencedirect.com/science/article/pii/0304397595001549</url>
        <title status="complete" source="scholar.google.com">Anomalous learning helps succinctness</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/mininacc.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>1996</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">It is shown that allowing a bounded number of anomalies (mistakes) in the final programs learned by an algorithmic procedure can considerably âsuccinctifyâ those final programs. Naturally, only those contexts are investigated in which the presence of anomalies is not ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FxGlgxLXFioJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3032847873598624023&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3032847873598624023&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://projecteuclid.org/euclid.jsl/1243948324</url>
        <title status="complete" source="scholar.google.com">Learning correction grammars</title>
        <pdf>https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2307/1/TR12-06.pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
        <year>2009</year>
        <source>projecteuclid.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract We investigate a new paradigm in the context of learning in the limit, namely, learning correction grammars for classes of computably enumerable (ce) languages. Knowing a language may feature a representation of it in terms of two grammars. The ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:0zSN0GENz58J:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11515437485971551443&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11515437485971551443&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <title status="complete" source="scholar.google.com">Department of Computer and Information Sciences University of Delaware Newark, DE 19716, USA Email: case@ cis. udel. edu</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:XViiPr1RB8kJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="58">
    <url>http://www.sciencedirect.com/science/article/pii/S0890540198927845</url>
    <title status="complete" source="scholar.google.com">Incremental concept learning for bounded data mining</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.7157&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">J Case, S Jain, S Lange, T Zeugmann</author>
    <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
    <year>1999</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... Inform. and Comput., 120 (1995), pp. 155â173. * Corresponding author. f1 E-mail:case@cis.udel.edu. f2 E-mail: sanjay@iscs.nus.edu.sg. f3 E-mail: slange@informatik.uni-leipzig.de. f4 E-mail: thomas@i.kyushu-u.ac.jp. Copyright Â© 1999 Academic Press. All rights reserved. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:KMSqppsxSO8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>19</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=17242085717973845032&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>88</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=17242085717973845032&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="88">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397508001503</url>
        <title status="complete" source="scholar.google.com">Learning indexed families of recursive languages from positive data: A survey</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/tcs08lzz.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, T Zeugmann, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In the past 40 years, research on inductive inference has developed along different lines, eg, in the formalizations used, and in the classes of target concepts considered. One common root of many of these formalizations is Gold&#39;s model of identification in the limit. This model ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:kHdpMOKBOpwJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11257453027040786320&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>39</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11257453027040786320&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397501004042</url>
        <title status="complete" source="scholar.google.com">On the power of incremental learning</title>
        <author status="complete" source="scholar.google.com">S Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2002</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper provides a systematic study of incremental learning from noise-free and from noisy data. As usual, we distinguish between learning from positive data and learning from positive and negative data, synonymously called learning from text and learning from ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:9XQsOKjr0GIJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7120450118602224885&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>27</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7120450118602224885&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000099916690</url>
        <title status="complete" source="scholar.google.com">An average-case optimal one-variable pattern language learner</title>
        <author status="complete" source="scholar.google.com">R Reischuk, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2000</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A new algorithm for learning one-variable pattern languages from positive data is proposed and analyzed with respect to its average-case behavior. We consider the total learning time that takes into account all operations till convergence to a correct hypothesis is achieved. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:NLKyK_OMwKYJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>21</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12015758781862556212&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>21</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12015758781862556212&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540107000491</url>
        <title status="complete" source="scholar.google.com">Results on memory-limited U-shaped learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.8567&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">U-shaped learning is a learning behaviour in which the learner first learns a given target behaviour, then unlearns it and finally relearns it. Such a behaviour, observed by psychologists, for example, in the learning of past-tenses of English verbs, has been ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:aPOveNlKjhoJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>23</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1913549189572195176&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>21</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1913549189572195176&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://pdf.aminer.org/000/311/170/a_unified_algorithm_for_extending_classes_of_languages_identifiable_in.pdf</url>
        <title status="complete" source="scholar.google.com">String extension learning</title>
        <pdf>http://pdf.aminer.org/000/311/170/a_unified_algorithm_for_extending_classes_of_languages_identifiable_in.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Heinz</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the 48th annual meeting of the &#8230;</proceeding>
        <year>2010</year>
        <source>pdf.aminer.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper defines a collection of functions which define classes of languages, which have the property that they are identifiable in the limit from positive data from a very simple kind of learner. Furthermore these learners are always incremental, maximally ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:YxW_ul8db8sJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:YxW_ul8db8sJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14658967609106437475&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>19</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14658967609106437475&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397508001400</url>
        <title status="complete" source="scholar.google.com">Learning recursive functions: A survey</title>
        <pdf>http://webdocs.cs.ualberta.ca/~zilles/zeugmannZ08survey.pdf</pdf>
        <author status="complete" source="scholar.google.com">T Zeugmann, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Studying the learnability of classes of recursive functions has attracted considerable interest for at least four decades. Starting with Gold&#39;s (1967) model of learning in the limit, many variations, modifications and extensions have been proposed. These models differ in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2f2VA5VmFfUJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17660134303999589849&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>14</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17660134303999589849&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://projecteuclid.org/euclid.jsl/1080938842</url>
        <title status="complete" source="scholar.google.com">Parsimony hierarchies for inductive inference</title>
        <pdf>http://pdf.aminer.org/002/865/517/parsimony_hierarchies_for_inductive_inference.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Ambainis, J Case, S Jain, M Suraj</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
        <year>2004</year>
        <source>projecteuclid.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Freivalds defined an acceptable programming system independent criterion for learning programs for functions in which the final programs were required to be both correct and ânearlyâ minimal size, ie, within a computable function of being purely minimal size. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:PPOiazrZf9IJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15168080914944291644&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15168080914944291644&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/8xvpk1x6ce61vyqv.pdf</url>
        <title status="complete" source="scholar.google.com">A complete and tight average-case analysis of learning monomials</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.106.2291&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">R Reischuk, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">STACS 99</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We advocate to analyze the average complexity of learning problems. An appropriate framework for this purpose is introduced. Based on it we consider the problem of learning monomials and the special case of learning monotone monomials in the limit and for on- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:KkmT1xChH3UJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>15</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8439641320423901482&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8439641320423901482&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000007000797</url>
        <title status="complete" source="scholar.google.com">Non-U-shaped vacillatory and team learning</title>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">Journal of Computer and System &#8230;</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">U-shaped learning behaviour in cognitive development involves learning, unlearning and relearning. It occurs, for example, in learning irregular verbs. The prior cognitive science literature is occupied with how humans do it, for example, general rules versus tables of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:EQmrDMaxldIJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15174229983668930833&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15174229983668930833&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.springerlink.com/index/AM7558R84445558T.pdf</url>
        <title status="complete" source="scholar.google.com">U-shaped, iterative, and iterative-with-counter learning</title>
        <author status="complete" source="scholar.google.com">J Case, SE Moelius</author>
        <proceeding status="complete" source="scholar.google.com">Machine Learning</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper solves an important problem left open in the literature by showing that U-shapes are unnecessary in iterative learning from positive data. A U-shape occurs when a learner first learns, then unlearns, and, finally, relearns, some target concept. Iterative ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:sZ5F-vPpsDUJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3868849313996447409&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3868849313996447409&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www.springerlink.com/index/BN4WUBDWE0233BPV.pdf</url>
        <title status="complete" source="scholar.google.com">Synthesizing learners tolerating computable noisy data</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/nrec.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1998</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">An index for an re class of languages (by definition) generates a sequence of grammars defining the class. An index for an indexed family of languages (by definition) generates a sequence of decision procedures defining the family. F. Stephan&#39;s model of noisy data is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:NQuQP4PCMXcJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8588859833335155509&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8588859833335155509&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://www.springerlink.com/index/7NDLJGW0PUQ0N9P5.pdf</url>
        <title status="complete" source="scholar.google.com">Non U-shaped vacillatory and team learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.127.40&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">U-shaped learning behaviour in cognitive development involves learning, unlearning and relearning. It occurs, for example, in learning irregular verbs. The prior cognitive science literature is occupied with how humans do it, for example, general rules versus tables of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:SiUKzidZXvAJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17320379244408874314&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17320379244408874314&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.111.1902&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">U-shaped learning may be necessary 3</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.111.1902&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carluccia, J Caseb, S Jainc, F Stephand</author>
        <year>2005</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract U-shaped learning behaviour in cognitive development involves learning, unlearning and relearning. It occurs, for example, in learning irregular verbs. The prior cognitive science literature is occupied with how humans do it, for example, general rules ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:TF-JIATWghcJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:TF-JIATWghcJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>20</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1694151723058814796&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1694151723058814796&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="13">
        <url>http://www.springerlink.com/index/1r638k4x8jgt667r.pdf</url>
        <title status="complete" source="scholar.google.com">Memory-limited U-shaped learning</title>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. U-shaped learning is a learning behaviour in which the learner first learns something, then unlearns it and finally relearns it. Such a behaviour, observed by psychologists, for example, in the learning of past-tenses of English verbs, has been ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:HRa3ewNxRzoJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4199449437320713757&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4199449437320713757&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="14">
        <url>http://its.lnpu.edu.ua/edocs1/new_doc/en/Bunke%20H.%20(ed.),%20Kandel%20A.%20(ed.),%20Last%20M.%20(ed.)%20-%20Data%20Mining%20In%20Time%20Series%20Databases%20(2004)(en).pdf#page=114</url>
        <title status="complete" source="scholar.google.com">Change detection in classification models induced from time series data</title>
        <pdf>http://its.lnpu.edu.ua/edocs1/new_doc/en/Bunke%20H.%20(ed.),%20Kandel%20A.%20(ed.),%20Last%20M.%20(ed.)%20-%20Data%20Mining%20In%20Time%20Series%20Databases%20(2004)(en).pdf#page=114</pdf>
        <author status="complete" source="scholar.google.com">G Zeira, O Maimon, M Last, L Rokach</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; â, M. Last, A. Kandel, and H. &#8230;</proceeding>
        <year>2004</year>
        <source>its.lnpu.edu.ua</source>
        <snippet status="partial" source="scholar.google.com">Most classification methods are based on the assumption that the historic data involved in building and verifying the model is the best estimator of what will happen in the future. One important factor that must not be set aside is the time factor. As more data is accumulated ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:rpI6jqR6zlMJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:rpI6jqR6zlMJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6038898997529842350&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6038898997529842350&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="15">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397510002045</url>
        <title status="complete" source="scholar.google.com">Iterative learning of simple external contextual languages</title>
        <author status="partial" source="scholar.google.com">L Becerra-Bonache, J Case, S Jain&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Theoretical Computer &#8230;</proceeding>
        <year>2010</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">It is investigated for which choice of a parameter q, denoting the number of contexts, the class of simple external contextual languages is iteratively learnable. On the one hand, the class admits, for all values of q, polynomial time learnability provided an adequate choice ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:f8VfCBmn_xMJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1441054131738363263&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1441054131738363263&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="16">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397500001316</url>
        <title status="complete" source="scholar.google.com">On the learnability of recursively enumerable languages from good examples</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/good.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, S Lange, J Nessel</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present paper investigates identification of indexed families L of recursively enumerable languages from good examples. We distinguish class-preserving learning from good examples (the good examples have to be generated with respect to a hypothesis space ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:pT5ZV88QH0cJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5124833383680655013&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5124833383680655013&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="17">
        <url>http://colt2010.haifa.il.ibm.com/presentation/COLT10Talk-NUTechniques.pdf</url>
        <title status="complete" source="scholar.google.com">Strongly non-U-shaped learning results by general techniques</title>
        <pdf>http://colt2010.haifa.il.ibm.com/presentation/COLT10Talk-NUTechniques.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of COLT (Conference on &#8230;</proceeding>
        <year>2010</year>
        <source>colt2010.haifa.il.ibm.com</source>
        <snippet status="partial" source="scholar.google.com">Let N={0, 1, 2,...}, the set of all natural numbers. A language is a set Lâ N. A presentation for L is essentially an (infinite) listing T of all and only the elements of L. Such a T is called a text for L. We numerically name programs or grammars in some standard general hypothesis ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:t15I2yZe0eEJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:t15I2yZe0eEJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16271890449647034039&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16271890449647034039&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="18">
        <url>http://www.springerlink.com/index/m13t261w8547g2w7.pdf</url>
        <title status="complete" source="scholar.google.com">Parallelism increases iterative learning power</title>
        <pdf>http://cs5235.userapi.com/u133638729/docs/ceb9e6352614/Marcus_Hutter_Algorithmic_Learning_Theory_18_co.pdf#page=60</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Moelius</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Iterative learning (It It-learning) is a Gold-style learning model in which each of a learner&#39;s output conjectures may depend only upon the learner&#39;s current conjecture and the current input element. Two extensions of the It It-learning model are considered, each of which ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:S-KmCH9zMScJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2824165430781207115&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2824165430781207115&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="19">
        <url>http://www.springerlink.com/index/61px2eqgnaf9ugv1.pdf</url>
        <title status="complete" source="scholar.google.com">Can learning in the limit be done efficiently?</title>
        <pdf>http://cs5235.userapi.com/u133638729/docs/0b3b37a51a80/Ricard_Gavald_Algorithmic_Learning_Theory_14_co.pdf#page=17</pdf>
        <author status="complete" source="scholar.google.com">T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2003</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Inductive inference can be considered as one of the fundamental paradigms of algorithmic learning theory. We survey results recently obtained and show their impact to potential applications. Since the main focus is put on the efficiency of learning, we also deal with ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:QwnJTXIvDKQJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11820875289918507331&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11820875289918507331&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="20">
        <url>http://www.springerlink.com/index/F7Q6184682RG6200.pdf</url>
        <title status="complete" source="scholar.google.com">On the strength of incremental learning</title>
        <author status="complete" source="scholar.google.com">S Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper provides a systematic study of incremental learning from noise-free and from noisy data, thereby distinguishing between learning from only positive data and from both positive and negative data. Our study relies on the notion of noisy data introduced in [22]. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:oCAsckbuppkJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11071798720267559072&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11071798720267559072&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="21">
        <url>http://www.springerlink.com/index/e654657xu548t251.pdf</url>
        <title status="complete" source="scholar.google.com">Iterative learning of simple external contextual languages</title>
        <pdf>http://cs5235.userapi.com/u133638729/docs/e02780dda47c/Yoav_Freund_Algorithmic_Learning_Theory_19_conf.pdf#page=371</pdf>
        <author status="partial" source="scholar.google.com">L Becerra-Bonache, J Case, S Jain&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Algorithmic Learning &#8230;</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">It is investigated for which choice of a parameter q, denoting the number of contexts, the class of simple external contextual languages is iteratively learnable. On one hand, the class admits, for all values of q, polynomial time learnability provided an adequate choice of the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:scvYnWO_FuQJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>25</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16435534324706102193&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16435534324706102193&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="22">
        <url>http://www.springerlink.com/index/K6565966X8828563.pdf</url>
        <title status="complete" source="scholar.google.com">U-shaped, iterative, and iterative-with-counter learning</title>
        <pdf>http://www.cis.udel.edu/~moelius/publications/iteqnuit_mlj_preprint.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Moelius</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper solves an important problem left open in the literature by showing that U-shapes are unnecessary in iterative learning. A U-shape occurs when a learner first learns, then unlearns, and, finally, relearns, some target concept. Iterative learning is a Gold-style ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RrqCAV6LybQJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13027096633014401606&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13027096633014401606&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="23">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397506004919</url>
        <title status="complete" source="scholar.google.com">From learning in the limit to stochastic finite learning</title>
        <pdf>http://eprints.lib.hokudai.ac.jp/dspace/bitstream/2115/17137/1/TCS364-1-77.pdf</pdf>
        <author status="complete" source="scholar.google.com">T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2006</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Inductive inference can be considered as one of the fundamental paradigms of algorithmic learning theory. We survey results recently obtained and show their impact to potential applications. Since the main focus is put on the efficiency of learning, we also deal with ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:jvVcGqZe3pkJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11087403400132621710&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11087403400132621710&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="24">
        <url>http://www.springerlink.com/index/1GAC95CTA52GAPQY.pdf</url>
        <title status="complete" source="scholar.google.com">On variants of iterative learning</title>
        <pdf>http://www.ke.tu-darmstadt.de/m/lehre/archiv/ss06/alg-lernen/incremental-fattext-initialhyp.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Discovey Science</proceeding>
        <year>1998</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Within the present paper, we investigate the principal learning capabilities of iterative learners in some more details. The general scenario of iterative learning is as follows. An iterative learner successively takes as input one element of a text (an informant) of a target ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:dXOMcjDsZLoJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13431119681550054261&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13431119681550054261&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="25">
        <url>http://www.springerlink.com/index/2781772065028428.pdf</url>
        <title status="complete" source="scholar.google.com">Towards a better understanding of incremental learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.114.3889&amp;rep=rep1&amp;type=pdf#page=180</pdf>
        <author status="complete" source="scholar.google.com">S Jain, S Lange, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The present study aims at insights into the nature of incremental learning in the context of Gold&#39;s model of identification in the limit. With a focus on natural requirements such as consistency and conservativeness, incremental learning is analysed both for learning from ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:yMOath6NN_QJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17597689232025633736&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17597689232025633736&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="26">
        <url>http://www.springerlink.com/index/L69637G3780M3J8U.pdf</url>
        <title status="complete" source="scholar.google.com">String extension learning using lattices</title>
        <author status="complete" source="scholar.google.com">A Kasprzik, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Language and Automata Theory and Applications</proceeding>
        <year>2010</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. The class of regular languages is not identifiable from positive data in Gold&#39;s language learning model. Many attempts have been made to define interesting classes that are learnable in this model, preferably with the associated learner having certain ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:0betva7fEvgJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17875595812586502097&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17875595812586502097&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="27">
        <url>http://www.springerlink.com/index/WW86604W658G5101.pdf</url>
        <title status="complete" source="scholar.google.com">Solutions to open questions for non-U-shaped learning with memory limitations</title>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2010</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A U-shape occurs when a learner first learns, then unlearns, and, finally, relearns, some target concept. Within the framework of Inductive Inference, previous results have shown, for example, that U-shapes are unnecessary for explanatory learning, but are necessary for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ibyShxgPJ6sJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12332842702605565065&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12332842702605565065&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="28">
        <url>http://www.springerlink.com/index/4b58j4ktgql69ylf.pdf</url>
        <title status="complete" source="scholar.google.com">Learning a subclass of regular patterns in polynomial time</title>
        <pdf>http://cs5235.userapi.com/u133638729/docs/0b3b37a51a80/Ricard_Gavald_Algorithmic_Learning_Theory_14_co.pdf#page=234</pdf>
        <author status="partial" source="scholar.google.com">J Case, S Jain, R Reischuk, F Stephan&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Algorithmic Learning &#8230;</proceeding>
        <year>2003</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Presented is an algorithm (for learning a subclass of erasing regular pattern languages) which can be made to run with arbitrarily high probability of success on extended regular languages generated by patterns Ï of the form x 0 Î± 1 x 1... Î± mxm for unknown m but ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:5fXE9S8QnLgJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13302525197518435813&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13302525197518435813&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="29">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397502001767</url>
        <title status="complete" source="scholar.google.com">Variants of iterative learning</title>
        <author status="complete" source="scholar.google.com">S Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We investigate the principal learning capabilities of iterative learners in some more details. Thereby, we confine ourselves to study the learnability of indexable concept classes. The general scenario of iterative learning is as follows. An iterative learner successively takes ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:bvw9BCIGZGgJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7522144020785396846&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7522144020785396846&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="30">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397510002057</url>
        <title status="complete" source="scholar.google.com">Incremental learning with temporary memory</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/tem.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, S Lange, SE Moelius, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2010</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In the inductive inference framework of learning in the limit, a variation of the bounded example memory (Bem) language learning model is considered. Intuitively, the new model constrains the learner&#39;s memory not only in how much data may be stored, but also in how ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:3nbCH_5_qskJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14531567877095585502&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14531567877095585502&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="31">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397509000668</url>
        <title status="complete" source="scholar.google.com">Parallelism increases iterative learning power</title>
        <author status="complete" source="scholar.google.com">J Case, SE Moelius III</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2009</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Iterative learning (It-learning) is a Gold-style learning model in which each of a learner&#39;s output conjectures may depend only upon the learner&#39;s current conjecture and the current input element. Two extensions of the It-learning model are considered, each of which ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:AmR2ykO8WnsJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8888623813914682370&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8888623813914682370&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="32">
        <url>http://www.springerlink.com/index/H18M222XV34JT501.pdf</url>
        <title status="complete" source="scholar.google.com">Learning with temporary memory</title>
        <pdf>http://cs5235.userapi.com/u133638729/docs/e02780dda47c/Yoav_Freund_Algorithmic_Learning_Theory_19_conf.pdf#page=461</pdf>
        <author status="complete" source="scholar.google.com">S Lange, S Moelius, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In the inductive inference framework of learning in the limit, a variation of the bounded example memory (Bem) language learning model is considered. Intuitively, the new model constrains the learner&#39;s memory not only in how much data may be retained, but also in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:3UoB5xip-78J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13833836604818541277&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13833836604818541277&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="33">
        <url>http://www.springerlink.com/index/uhq0emr1dtqgjrkx.pdf</url>
        <title status="complete" source="scholar.google.com">Learning recursive concepts with anomalies</title>
        <pdf>http://cs5824.userapi.com/u11728334/docs/a70c63d88f80/Hiroki_Arimura_Algorithmic_Learning_Theory_11_c.pdf#page=111</pdf>
        <author status="complete" source="scholar.google.com">G Grieser, S Lange, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper provides a systematic study of inductive inference of indexable concept classes in learning scenarios in which the learner is successful if its final hypothesis describes a finite variant of the target concept-henceforth called learning with anomalies. As usual, we ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:aWrK9G-Cpf4J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>17</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18349215674150840937&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18349215674150840937&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="34">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397506004932</url>
        <title status="complete" source="scholar.google.com">Learning a subclass of regular patterns in polynomial time</title>
        <pdf>http://eprints2008.lib.hokudai.ac.jp/dspace/bitstream/2115/17138/1/TCS364-1-115.pdf</pdf>
        <author status="partial" source="scholar.google.com">J Case, S Jain, R Reischuk, F Stephan&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Theoretical computer &#8230;</proceeding>
        <year>2006</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">An algorithm for learning a subclass of erasing regular pattern languages is presented. On extended regular pattern languages generated by patterns Ï of the form x0Î±1x1â¦ Î±mxm, where x0,â¦, xm are variables and Î±1,..., Î±m strings of terminals of length c each, it runs ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:l0-OdtlbjkwJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>15</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5516447583130505111&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5516447583130505111&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="35">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000000917367</url>
        <title status="complete" source="scholar.google.com">Synthesizing learners tolerating computable noisy data</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">An index for an re class of languages (by definition) generates a sequence of grammars defining the class. An index for an indexed family of recursive languages (by definition) generates a sequence of decision procedures defining the family. F. Stephan&#39;s model of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:I11qjU5RhmMJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7171508854455950627&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7171508854455950627&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="36">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540107000740</url>
        <title status="complete" source="scholar.google.com">Some natural conditions on incremental learning</title>
        <pdf>http://www2.cs.uregina.ca/~zilles/jainLZ07incremental.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, S Lange, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present study aims at insights into the nature of incremental learning in the context of Gold&#39;s model of identification in the limit. With a focus on natural requirements such as consistency and conservativeness, incremental learning is analysed both for learning from ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:fy0ckG0INFYJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6211599052712979839&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6211599052712979839&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="37">
        <url>http://www.springerlink.com/index/6813w3k86555t79h.pdf</url>
        <title status="complete" source="scholar.google.com">Iterative learning from texts and counterexamples using additional information</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2937/1/TRB4-09.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A variant of iterative learning in the limit (cf.[LZ96]) is studied when a learner gets negative examples refuting conjectures containing data in excess of the target language and uses additional information of the following four types: a) memorizing up to n input elements ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:m0uIqOprI_kJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17952311195222952859&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17952311195222952859&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="38">
        <title status="complete" source="scholar.google.com">U-shaped, iterative, and iterative-with-counter learning (expanded version)</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2fP3wed_a-kJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16819677866713674713&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="39">
        <url>http://www.springerlink.com/index/4APV7JEF2FUUCKV3.pdf</url>
        <title status="complete" source="scholar.google.com">Stochastic finite learning</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/saga01z.ps.gz</pdf>
        <author status="complete" source="scholar.google.com">T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Stochastic Algorithms: Foundations and Applications</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Recently, we have developed a learning model, called stochastic finite learning, that makes a connection between concepts from PAC learning and inductive inference learning models. The motivation for this work is as follows. Within Gold&#39;s (1967) model of learning in the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:C5VCw3bISTYJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3911878163755603211&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3911878163755603211&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="40">
        <url>http://www.springerlink.com/index/B827045M7662102M.pdf</url>
        <title status="complete" source="scholar.google.com">Iterative learning from positive data and counters</title>
        <author status="complete" source="scholar.google.com">T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We analyze iterative learning in the limit from positive data with the additional information provided by a counter. The simplest type of counter provides the current iteration number (counting up from 0 to infinity), which is known to improve learning power over plain ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:R2qx8w66hzAJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3496968209057278535&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3496968209057278535&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="41">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.15.9807&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">HOMO LUDENS: ON THE PLAYâ ELEMENT IN INDUCTIVE LOGIC</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.15.9807&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">A Agostini, DS Itc-irst</author>
        <year>2001</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">This report has been submitted forpublication outside of ITC and will probably be copyrighted if accepted for publication. It has been issued as a Technical Report forearly dissemination of its contents. In view of the transfert of copy right tothe outside publisher, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:oxiU2zBaoBsJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:oxiU2zBaoBsJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1990690201186605219&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1990690201186605219&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="42">
        <url>http://www.springerlink.com/index/K9T4732U26W2U651.pdf</url>
        <title status="complete" source="scholar.google.com">Segmentation of Continuous Data Streams Based on a Change Detection Methodology</title>
        <author status="complete" source="scholar.google.com">G Zeira, M Last, O Maimon</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; in Knowledge Discovery and Data Mining</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Most data mining algorithms assume that the historic data are the best estimator of what will happen in the future. As more data are accumulated in a database, one should examine whether the new data agrees with the model induced from previous instances. The ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:8yvLJUo7OMYJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14283231407853218803&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14283231407853218803&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="43">
        <url>http://dl.comp.nus.edu.sg/dspace/handle/1900.100/1903</url>
        <title status="complete" source="scholar.google.com">Memory-Limited U-Shaped Learning</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1903/1/tr51-05.pdf</pdf>
        <author status="complete" source="scholar.google.com">L CARLUCCI, J CASE, S JAIN, F STEPHAN</author>
        <year>2005</year>
        <source>dl.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract: U-shaped learning is a learning behaviour in which the learner first learns something, then unlearns it and finally relearns it. Such a behaviour, observed by psychologists, for example, in the learning of past-tenses of English verbs, has been ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2QKGOB0_q7AJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12730338166427747033&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12730338166427747033&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="44">
        <url>http://www.springerlink.com/index/371821UW3L4225G8.pdf</url>
        <title status="complete" source="scholar.google.com">Automatic learners with feedback queries</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/autofeednew.pdf</pdf>
        <author status="partial" source="scholar.google.com">J Case, S Jain, Y Ong, P Semukhin&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Models of Computation in &#8230;</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Automatic classes are classes of languages for which a finite automaton can decide whether a given element is in a set given by its index. The present work studies the learnability of automatic families by automatic learners which, in each round, output a hypothesis and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RXW6gzjPnq0J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12510664656516969797&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12510664656516969797&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="45">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.113.356&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Models for Algorithmic Teaching</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.113.356&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">F Balbach</author>
        <year>2007</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract Learning theory focuses almost entirely on the learner and its efficient realization, but neglects other parts of the learning process, most importantly the teacher, which is merely modeled as a passive data source. In this thesis, however, we study models in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:H2UalNYLs50J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:H2UalNYLs50J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11363439301021558047&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11363439301021558047&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="46">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.72.3587&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">A Polynomial Time Learner for a Subclass of Regular Patterns</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.72.3587&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="partial" source="scholar.google.com">J Case, S Jain, R Reischuk, F Stephan&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Electronic Colloquium on &#8230;</proceeding>
        <year>2004</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract Presented is an algorithm (for learning a subclass of erasing regular pattern languages) which can be made to run with arbitrarily high probability of success on extended regular languages generated by patterns Ï of the form x0Î±1x1... Î±mxm for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:n2qisYftnREJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:n2qisYftnREJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>32</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1269431837044927135&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1269431837044927135&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="47">
        <url>http://www.springerlink.com/index/2e9yk3herkaudm15.pdf</url>
        <title status="complete" source="scholar.google.com">On Learning to Coordinate</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Montagna, G Simi, A Sorbi</author>
        <proceeding status="partial" source="scholar.google.com">Learning Theory and Kernel &#8230;</proceeding>
        <year>2003</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A mere bounded number of random bits judiciously employed by a probabilistically correct algorithmic coordinator is shown to increase the power of learning to coordinate compared to deterministic algorithmic coordinators. Furthermore, these probabilistic algorithmic ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:5qBDtcPhVL8J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13786892589963911398&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13786892589963911398&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="48">
        <url>http://www.springerlink.com/index/e260l7477q204851.pdf</url>
        <title status="complete" source="scholar.google.com">Incremental learning with ordinal bounded example memory</title>
        <author status="complete" source="scholar.google.com">L Carlucci</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A Bounded Example Memory learner is a learner that operates incrementally and maintains a memory of finitely many data items. The paradigm is well-studied and known to coincide with set-driven learning. A hierarchy of stronger and stronger learning criteria is obtained ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:IH0StlGWmHwJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8978091134854266144&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8978091134854266144&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="49">
        <url>https://qir.kyushu-u.ac.jp/dspace/handle/2324/3021</url>
        <title status="complete" source="scholar.google.com">Analyzing the average-case behavior of conjunctive learning algorithms</title>
        <pdf>https://qir.kyushu-u.ac.jp/dspace/bitstream/2324/3021/5/trcs153.pdf</pdf>
        <author status="complete" source="scholar.google.com">R Reischuk, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">153</proceeding>
        <year>1998</year>
        <source>qir.kyushu-u.ac.jp</source>
        <snippet status="partial" source="scholar.google.com">We advocate to analyze the average complexity of learning problems. An appropriate framework for this purpose is introduced. Based on it we consider the problem of learning monomials and the special case of learning monotone monomials in the limit and for on- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:b-_UvEVGSjQJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3767901303583600495&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3767901303583600495&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="50">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000004001400</url>
        <title status="complete" source="scholar.google.com">On learning to coordinate: random bits help, insightful normal forms, and competency isomorphisms</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Montagna, G Simi, A Sorbi</author>
        <proceeding status="partial" source="scholar.google.com">Journal of Computer and &#8230;</proceeding>
        <year>2005</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A mere bounded number of random bits judiciously employed by a probabilistically correct algorithmic coordinator is shown to increase the power of learning to coordinate compared to deterministic algorithmic coordinators. Furthermore, these probabilistic algorithmic ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:5cDXwvb-EUUJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4977039399005438181&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4977039399005438181&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="51">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.146.2248&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Learning with temporary memory (expanded version)</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.146.2248&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, SE Moelius, S Zilles</author>
        <year>2008</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. In the inductive inference framework of learning in the limit, a variation of the bounded example memory (Bem) language learning model is considered. Intuitively, the new model constrains the learner&#39;s memory not only in how much data may be retained, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:7lJI0YadCZkJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:7lJI0YadCZkJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11027518364955726574&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11027518364955726574&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="52">
        <url>http://www.sciencedirect.com/science/article/pii/S0020019003004459</url>
        <title status="complete" source="scholar.google.com">Incremental learning of approximations from positive data</title>
        <author status="complete" source="scholar.google.com">G Grieser, S Lange</author>
        <proceeding status="complete" source="scholar.google.com">Information processing letters</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Three different types of incremental learning are systematically studied: iterative learning, feedback inference, and bounded example-memory learning. In contrast to exact learning, where a learner is required to stabilize on a correct description of the target concept, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:DeVd1rMEuQYJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=484423605361173773&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=484423605361173773&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="53">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.5284&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Hypothesis assessments as guidance for incremental and meta-learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.5284&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">G Grieser</author>
        <proceeding status="partial" source="scholar.google.com">Proc. 11th European Conference on Machine Learning &#8230;</proceeding>
        <year>2000</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. In this paper, a new decision tree learning algorithm (INCDT) is proposed: an incremental one based on hypotheses assessments. INC-DT uses only a xed amount of instance memory during the whole learning process. It bases its hypotheses exclusively ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Ynq8-GyJ030J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:Ynq8-GyJ030J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9066741575949515362&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9066741575949515362&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="54">
        <title status="partial" source="scholar.google.com">19716-2586, USA caseQcis. udel. edu 2 School of Computing, National University of Singapore, Singapore 117543 sanj ayOcomp. nus. edu. sg 3 Institute &#8230;</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:8o0GCrQ1Q-0J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="55">
        <url>http://www.springerlink.com/index/12017035066353VR.pdf</url>
        <title status="complete" source="scholar.google.com">Resource Restricted Computability Theoretic Learning: Illustrative Topics and Problems</title>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Computation and Logic in the Real World</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Computability theoretic learning theory (machine inductive inference) typically involves learning programs for languages or functions from a stream of complete data about them and, importantly, allows mind changes as to conjectured programs. This theory takes into ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MIjRDNBNqiIJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2497894499293956144&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="56">
        <url>http://www.cis.udel.edu/~case/papers/lncs_paper.ps</url>
        <title status="complete" source="scholar.google.com">Ð§Ð² Ð¤ Ð¶Ð² Ð² Ð¬Ð³ Ð³Ð³Ð¶ Ð² Ð¸</title>
        <pdf>http://www.cis.udel.edu/~case/papers/lncs_paper.ps</pdf>
        <author status="complete" source="scholar.google.com">C Isomorphisms</author>
        <proceeding status="complete" source="scholar.google.com">cis.udel.edu</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. A mere bounded number of random bits judiciously employed by a probabilistically correct algorithmic coordinator is shown to increase the power of learning to coordinate compared to deterministic algorithmic coordinators. Furthermore, these probabilistic ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:H2iyE0DjcmQJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:H2iyE0DjcmQJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7238097415485679647&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="57">
        <url>https://dl.comp.nus.edu.sg/dspace/handle/1900.100/1510</url>
        <title status="complete" source="scholar.google.com">U-shaped leaning may be necessary</title>
        <pdf>https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1510/1/upload.pdf</pdf>
        <author status="complete" source="scholar.google.com">C Lorenzo, C John, J Sanjay, S Frank</author>
        <year>2004</year>
        <source>dl.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract: U-shaped learning behaviour in cognitive development involves learning, unlearning and relearning. It occurs, for example, in learning irregular verbs. The prior cognitive science literature is occupied with how humans do it, for example, general rules ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:aN5UGzEe8gMJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=284322922738540136&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="58">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.88.1495&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Some Results on U-shaped, Vacillatory and Team Learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.88.1495&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
        <year>2008</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. U-shaped learning behaviour in cognitive development involves learning, unlearning and relearning. It occurs, for example, in learning irregular verbs. The prior cognitive science literature is occupied with how humans do it, for example, general rules ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:mMyKHdGlAbYJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:mMyKHdGlAbYJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13114945907441978520&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="59">
        <title status="complete" source="scholar.google.com">U-shaped learning may be necessary 3</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:9zFARK7e_V8J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="60">
        <url>http://www2.cs.uregina.ca/~zilles/langeMZ08TR.pdf</url>
        <title status="complete" source="scholar.google.com">Incremental Learning with Temporary Memory</title>
        <pdf>http://www2.cs.uregina.ca/~zilles/langeMZ08TR.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Langea, S Zillesc</author>
        <proceeding status="complete" source="scholar.google.com">cs.uregina.ca</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract In the inductive inference framework of learning in the limit, a variation of the bounded example memory (Bem) language learning model is considered. Intuitively, the new model constrains the learner&#39;s memory not only in how much data may be retained, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MRIpRUDfVdEJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:MRIpRUDfVdEJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15084207994078564913&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="61">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.5444&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Iterative concept learning from noisy data</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.5444&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S en Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract In the present paper, we study iterative learning of indexable concept classes from noisy data. We distinguish between learning from positive data only and learning from positive and negative data; synonymously, learning from text and informant, respectively. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:hovRSwK6TgMJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:hovRSwK6TgMJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=238332349321939846&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="62">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.5172&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">On the power of incremental learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.5172&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S en Langea, G Grieserb</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract This paper provides a systematic study of incremental learning from noise-free and from noisy data. As usual, we distinguish between learning from positive data and learning from positive and negative data, synonymously called learning from text and learning from ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:xOBQUupPq0AJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:xOBQUupPq0AJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4659906107266883780&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="63">
        <title status="partial" source="scholar.google.com">Deutsches Forschungszentrum f ur K unstliche Intelligenz, Stuhlsatzenhausweg 3, 66123 Saarbr ucken, Germany, Email: lange@ dfki. de b Technische &#8230;</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:3xgNVk77AAMJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="64">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000012000876</url>
        <title status="complete" source="scholar.google.com">Learning with ordinal-bounded memory from positive data</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/bemord.pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A bounded example memory learner operates incrementally and maintains a memory of finitely many data items. The paradigm is well-studied and known to coincide with set-driven learning. A hierarchy of stronger and stronger learning criteria had earlier been obtained ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:SO2jYG0s_0kJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5332029332114369864&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="65">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.4578&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">An Average-Case Optimal One-Variable Pattern Language Learner</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.4578&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">R udiger Reischuk, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract A new algorithm for learning one-variable pattern languages from positive data is proposed and analyzed with respect to its average-case behavior. We consider the total learning time that takes into account all operations till convergence to a correct hypothesis ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:XAlbcQ9MadwJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:XAlbcQ9MadwJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15882309190108776796&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="66">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397507002277</url>
        <title status="complete" source="scholar.google.com">On the data consumption benefits of accepting increased uncertainty</title>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In the context of learning paradigms of identification in the limit, we address the question: why is uncertainty sometimes desirable? We use mind change bounds on the output hypotheses as a measure of uncertainty and interpret &#39;desirable&#39;as reduction in data ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:YN_1eqwpL5wJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11254259814596206432&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="67">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.49.9565&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">A Complete and Tight Average-Case Analysis of Learning Monomials</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.49.9565&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">R udiger Reischuk, T Zeugmanny</author>
        <year>1998</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract We advocate to analyze the average complexity of learning problems. An appropriate framework for this purpose is introduced. Based on it we consider the problem of learning monomials and the special case of learning monotone monomials in the limit and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:nZDJexayAAgJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:nZDJexayAAgJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=576656561939255453&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="68">
        <url>http://www.springerlink.com/index/X524068561K52072.pdf</url>
        <title status="complete" source="scholar.google.com">Iterative learning from texts and counterexamples using additional information</title>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Machine learning</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract A variant of iterative learning in the limit (cf. Lange and Zeugmann 1996) is studied when a learner gets negative examples refuting conjectures containing data in excess of the target language and uses additional information of the following four types:(a) memorizing ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:3qdCfFnTLTgJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4048124021366237150&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="69">
        <url>http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTRB/tcstr_08_4/tcstr_08_4.pdf</url>
        <title status="complete" source="scholar.google.com">TCS Technical Report</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTRB/tcstr_08_4/tcstr_08_4.pdf</pdf>
        <author status="complete" source="scholar.google.com">T Zeugmann, S Zilles</author>
        <year>2007</year>
        <source>www-alg.ist.hokudai.ac.jp</source>
        <snippet status="partial" source="scholar.google.com">AESYAISLAGFAKEGJWAEHGJLSFLLZSFC... epuv ep his le tures m inly l rifies the su je t of cryptologyF qener lly spe kingD ryptology is out communication in the presence of adversariesF gryptology ne diveded into two m jor p rtsD iFeFD cryptography nd ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:N39igYssHS0J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:N39igYssHS0J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3250803483714158391&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="70">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.6756&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">On the strength of incremental learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.6756&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S en Lange, G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. This paper provides a systematic study of incremental learning from noise-free and from noisy data, thereby distinguishing between learning from only positive data and from both positive and negative data. Our study relies on the notion of noisy data introduced in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:wMdDg89ZrbwJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:wMdDg89ZrbwJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13595621597896755136&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="71">
        <url>http://www.springerlink.com/index/812361171q2264pu.pdf</url>
        <title status="complete" source="scholar.google.com">Resource Restricted Computability Theoretic Learning: Illustrative Topics and Problems</title>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Theory of Computing Systems</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract Computability theoretic learning theory (machine inductive inference) typically involves learning programs for languages or functions from a stream of complete data about them and, importantly, allows mind changes as to conjectured programs. This theory takes ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cNGIg7j_YKkJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12205036158119891312&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="72">
        <url>http://www.springerlink.com/index/6LYLFEKMFX7KTYQ4.pdf</url>
        <title status="complete" source="scholar.google.com">On the data consumption benefits of accepting increased uncertainty</title>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2004</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In the context of learning paradigms of identification in the limit, we address the question: why is uncertainty sometimes desirable? We use mind change bounds on the output hypotheses as a measure of uncertainty, and interpret &#39;desirable&#39;as reduction in data ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:vahgiAbccK4J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12569788480607004861&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="73">
        <url>http://www.eecis.udel.edu/~case/papers/pr2.pdf</url>
        <title status="complete" source="scholar.google.com">On the Necessity of U-Shaped Learning</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/pr2.pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case</author>
        <proceeding status="complete" source="scholar.google.com">eecis.udel.edu</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. A U-shaped curve in a cognitive-developmental trajectory refers to a three-step process: good performance followed by bad performance followed by good performance once again. U-shaped curves have been observed in a wide variety of cognitive- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17336137048815070431&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="74">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540110001896</url>
        <title status="complete" source="scholar.google.com">Teaching randomized learners with feedback</title>
        <pdf>http://eprints.lib.hokudai.ac.jp/dspace/bitstream/2115/45035/1/IC209-3_296-319.pdf</pdf>
        <author status="complete" source="scholar.google.com">FJ Balbach, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2011</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present paper introduces a new model for teaching randomized learners. Our new model, though based on the classical teaching dimension model, allows to study the influence of the learner&#39;s memory size and of the presence or absence of feedback. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:vdSsjvGr8NAJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15055722608268727485&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="75">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397512009310</url>
        <title status="complete" source="scholar.google.com">Memory-limited non-U-shaped learning with solved open problems</title>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Herein we also distinguish between semantic and syntactic U-shapes. We answer a number of open questions in the prior literature as well as provide new results regarding syntactic U-shapes. Importantly for cognitive science, we see more of a previously noticed pattern ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="76">
        <url>http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTR/tcstr_07_31/tcstr_07_31.pdf</url>
        <title status="complete" source="scholar.google.com">TCS Technical Report</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTR/tcstr_07_31/tcstr_07_31.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, T Zeugmann, S Zilles</author>
        <year>2007</year>
        <source>www-alg.ist.hokudai.ac.jp</source>
        <snippet status="partial" source="scholar.google.com">Abstract In the past 40 years, research on inductive inference has developed along different lines, concerning different formalizations of learning models and in particular of target concepts for learning. One common root of many of these is Gold&#39;s model of identification ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:uMhVpfJ4388J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:uMhVpfJ4388J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14978823869208840376&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="77">
        <url>http://www.springerlink.com/index/J0W128K65840063R.pdf</url>
        <title status="complete" source="scholar.google.com">Learning via finitely many queries</title>
        <pdf>http://rutcor.rutgers.edu/~amai/aimath04/AcceptedPapers/Lee-aimath04.pdf</pdf>
        <author status="complete" source="scholar.google.com">AC Lee</author>
        <proceeding status="complete" source="scholar.google.com">Annals of Mathematics and Artificial Intelligence</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This work introduces a new query inference model that can access data and communicate with the teacher by asking finitely many Boolean queries in a language L. In this model the parameters of interest are the number of queries used and the expressive power of L. We ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:j_c9uEG18zwJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4392053355484936079&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="78">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5366247</url>
        <title status="complete" source="scholar.google.com">An Evolutionary Mining Model in Incremental Data Mining</title>
        <author status="partial" source="scholar.google.com">F Jiancong, L Yongquan&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; Computation, 2009. ICNC&#39; &#8230;</proceeding>
        <year>2009</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Incremental data mining is very important to solve the temporal dynamic property of knowledge, improve the performance of mining processes and efficiency of mining results. Incremental data occurs with the passage of time. Evolutionary methods can be adopted ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:wDB-xDkMhDUJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3856220623185260736&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="79">
        <url>http://www.springerlink.com/index/077MQYMTMHJRW1KN.pdf</url>
        <title status="complete" source="scholar.google.com">Optimization and simulation: Sequential packing of flexible objects using evolutionary algorithms</title>
        <author status="complete" source="scholar.google.com">H Behnke, M Kolonko, U Mertins, S Schnitter</author>
        <proceeding status="partial" source="scholar.google.com">Stochastic Algorithms: &#8230;</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We want to fill a given two-dimensional closed contour as accurately as possible with a fixed number of identical, flexible objects. These objects have to be packed sequentially. They adapt themselves to the surface they are packed on, but their deformation can only be ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:avCi12WCx5cJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10936853594013626474&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="80">
        <url>http://dl.comp.nus.edu.sg/dspace/handle/1900.100/2317</url>
        <title status="complete" source="scholar.google.com">Consistent and Conservative Iterative Learning</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2317/1/TRC3-07.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, S Lange, S ZILLES</author>
        <year>2007</year>
        <source>dl.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract: The present study aims at insights into the nature of incremental learning in the context of Gold&#39;s model of identification in the limit. With a focus on natural requirements such as consistency and conservativeness, incremental learning is analysed both for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:g4a22neUaasJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12351566695531710083&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="81">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397512007128</url>
        <title status="complete" source="scholar.google.com">Learning in the limit with lattice-structured hypothesis spaces</title>
        <author status="complete" source="scholar.google.com">J Heinz, A Kasprzik, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We define a collection of language classes which are TxtEx-learnable (learnable in the limit from positive data). The learners map any data input to an element of a fixed lattice, and keep the least upper bound of all lattice elements thus obtained as the current hypothesis. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ZwsP5kjqVmoJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7662569414835768167&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="82">
        <url>http://www.eecis.udel.edu/~case/siena/pat.pdf</url>
        <title status="complete" source="scholar.google.com">Some Information on Pattern Languages</title>
        <pdf>http://www.eecis.udel.edu/~case/siena/pat.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">eecis.udel.edu</proceeding>
        <snippet status="partial" source="scholar.google.com">Much work has been done on learnability of pattern languages Ang80, Sal94a, Sal94b, CJK+01, BJEG98 and finite unions thereof Shi83, Wri89, KMU95, BUV96, CJLZ99. Nix83 as well as SA95 outline interesting applications of pattern inference algorithms. For example, ...</snippet>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:03VU6gCWWScJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="83">
        <url>http://pdf.aminer.org/000/108/782/on_learning_to_coordinate_random_bits_help_insightful_normal_forms.pdf</url>
        <title status="complete" source="scholar.google.com">On Learning To Coordinate: Random Bits Help, Insightful Normal Forms, and</title>
        <pdf>http://pdf.aminer.org/000/108/782/on_learning_to_coordinate_random_bits_help_insightful_normal_forms.pdf</pdf>
        <author status="complete" source="scholar.google.com">C Isomorphisms</author>
        <proceeding status="complete" source="scholar.google.com">pdf.aminer.org</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. A mere bounded number of random bits udiciously employed by a probabilistically correct algorithmic coordinator is shown to increase the power of learning to coordinate compared to deterministic algorithmic coordinators. Furthermore, these probabilistic ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:w8cP6wx7_90J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:w8cP6wx7_90J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15996639696856795075&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="84">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.24.5351&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Variants of iterative learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.24.5351&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S en Langea, G Grieserb</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract We investigate the principal learning capabilities of iterative learners in some more details. Thereby, we con ne ourselves to study the learnability of indexable concept classes. The general scenario of iterative learning is as follows. An iterative learner successively ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:DBc68Bpi7TAJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:DBc68Bpi7TAJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3525581951139976972&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="85">
        <url>http://www.comp.nus.edu.sg/~sanjay/paps/coord.pdf</url>
        <title status="complete" source="scholar.google.com">On Learning To Coordinate: Random Bits Help, Insightful Normal Forms, and Competency Isomorphisms</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/coord.pdf</pdf>
        <author status="complete" source="scholar.google.com">JCSJF Montagnac, G Simic, A Sorbic</author>
        <proceeding status="complete" source="scholar.google.com">comp.nus.edu.sg</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract A mere bounded number of random bits judiciously employed by a probabilistically correct algorithmic coordinator is shown to increase the power of learning to coordinate compared to deterministic algorithmic coordinators. Furthermore, these probabilistic ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:hy1_83_8liEJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:hy1_83_8liEJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2420399476234464647&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="86">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.18.300&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">DOI Technical Report</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.18.300&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">R udiger Reischuk, T Zeugmann</author>
        <year>1997</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract We advocate to analyze the average complexity of learning problems. An appropriate framework for this purpose is introduced. Based on it we consider the problem of learning monomials and the special case of learning monotone monomials in the limit and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:HdiQ-g2CqaQJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:HdiQ-g2CqaQJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11865157689834264605&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="87">
        <title status="complete" source="scholar.google.com">Auf dem Weg zum inkrementellen Lernen von Entscheidungsb aumen mit Hilfe von Hypothesenbewertungen</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:TWjG9KrUJFgJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6351435205215414349&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="59">
    <url>http://www.sciencedirect.com/science/article/pii/S016800729500064X</url>
    <title status="complete" source="scholar.google.com">Characterizing language identification in terms of computable numberings</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.100.4696&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
    <proceeding status="complete" source="scholar.google.com">Annals of Pure and Applied Logic</proceeding>
    <year>1997</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... positive data are two extensively studied problems in this framework. We informallydescribe these problems. Corresponding author. E-mail: sanjay@iscs.nus.sg.0168-0072/97/$17.00 1997 Eisevier Science BV All rights reserved ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:rVGICIY2FScJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>5</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=2816217091286782381&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>6</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=2816217091286782381&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="6">
        <result id="0">
        <url>http://www.springerlink.com/index/X42R7787R321T705.pdf</url>
        <title status="complete" source="scholar.google.com">Generalization and specialization strategies for learning re languages</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/mon.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Annals of Mathematics and Artificial Intelligence</proceeding>
        <year>1998</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract Overgeneralization is a major issue in the identification of grammars for formal languages from positive data. Different formulations of generalization and specialization strategies have been proposed to address this problem, and recently there has been a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:vGf5KkQAIYkJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9881179350206343100&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9881179350206343100&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540108000266</url>
        <title status="complete" source="scholar.google.com">Learning in Friedberg numberings</title>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In this paper we consider learnability in some special numberings, such as Friedberg numberings, which contain all the recursively enumerable languages, but have simpler grammar equivalence problem compared to acceptable numberings. We show that every ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Hq2mBjhdYAMJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=243296875089145118&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=243296875089145118&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/037l58m020020m31.pdf</url>
        <title status="complete" source="scholar.google.com">Synthesizing noise-tolerant language learners</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.114.3595&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1997</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">An index for an re class of languages (by definition) generates a sequence of grammars defining the class. An index for an indexed family of languages (by definition) generates a sequence of decision procedures defining the family. F. Stephan&#39;s model of noisy data is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:87KSL3z6TQYJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=454294548715320051&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=454294548715320051&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/D56708146217R601.pdf</url>
        <title status="complete" source="scholar.google.com">Learning in Friedberg numberings</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2613/1/TR11-07.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In this paper we consider learnability in some special numberings, such as Friedberg numberings, which contain all the recursively enumerable languages, but have simpler grammar equivalence problem compared to acceptable numberings. We show that every ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cLgmLVtjoKkJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>26</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12222878631934212208&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12222878631934212208&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397500001328</url>
        <title status="complete" source="scholar.google.com">Synthesizing noise-tolerant language learners</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">An index for an re class of languages (by definition) generates a sequence of grammars defining the class. An index for an indexed family of languages (by definition) generates a sequence of decision procedures defining the family. F. Stephan&#39;s model of noisy data is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:kQjLOj-Cp0IJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4802950735694858385&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4802950735694858385&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397510007425</url>
        <title status="complete" source="scholar.google.com">Inductive inference and computable numberings</title>
        <author status="complete" source="scholar.google.com">K Ambos-Spies, S Badaev, S Goncharov</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2011</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">It has been previously observed that for many TxtEx-learnable computable families of computably enumerable (ce for short) sets all their computable numberings are evidently 0â²-equivalent, ie are equivalent with respect to reductions computable in the halting ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:8nPDWt5nFVwJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6635323830703453170&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="60">
    <url>http://www.springerlink.com/index/P208502963J65423.pdf</url>
    <title status="complete" source="scholar.google.com">Language learning with some negative information</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.106.1279&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">G Baliga, J Case, S Jain</author>
    <proceeding status="complete" source="scholar.google.com">STACS 93</proceeding>
    <year>1993</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... information. In other cases, we show that small additions of open negative informationcan more than * Email addresses of the authors are baliga@cis.udel.edu,case@cis.udel.edu and sanjay@iss.nus.sg respectively. Page 2. 673 ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:fzcSwps37zIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>7</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=3670213363445675903&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>6</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=3670213363445675903&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="6">
        <result id="0">
        <url>http://www.tandfonline.com/doi/abs/10.1080/09528139408953778</url>
        <title status="complete" source="scholar.google.com">Infinitary self-reference in learning theory</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.47.5822&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="partial" source="scholar.google.com">Journal of Experimental &amp; Theoretical Artificial &#8230;</proceeding>
        <year>1994</year>
        <source>Taylor &amp; Francis</source>
        <snippet status="partial" source="scholar.google.com">Abstract Kleene&#39;s second recursion theorem provides a means for transforming any program p into a program e (p) which first creates a quiescent self-copy and then runs p on that self-copy together with any externally given input. e (p), in effect, has complete (low level), self- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:W3Ho86D-EPAJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17298606135970394459&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>47</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17298606135970394459&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/f074701617482876.pdf</url>
        <title status="complete" source="scholar.google.com">Language learning from good examples</title>
        <author status="complete" source="scholar.google.com">S Lange, J Nessel, R Wiehagen</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic learning theory</proceeding>
        <year>1994</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We study learning of indexable families of recursive languages from good examples. We show that this approach is considerably more powerful than learning from all examples and point out reasons for this additional power. We present several characterizations of types ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:rlr8GkY64YwJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10151459107844676270&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>14</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10151459107844676270&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/PXQ20Q54786440M4.pdf</url>
        <title status="complete" source="scholar.google.com">Learning recursive languages from good examples</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.31.2851&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, J Nessel, R Wiehagen</author>
        <proceeding status="partial" source="scholar.google.com">Annals of Mathematics and Artificial &#8230;</proceeding>
        <year>1998</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract We study learning of indexable families of recursive languages from good examples. We show that this approach can be considerably more powerful than learning from all examples and point out reasons for this additional power. We present several ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:PVOh0ndKrioJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3075477474035979069&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3075477474035979069&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/78867137810P8066.pdf</url>
        <title status="complete" source="scholar.google.com">Learning with higher order additional information</title>
        <author status="complete" source="scholar.google.com">G Baliga, J Case</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1994</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">[Go167] studied, among other things, algorithmic learning (in the limit) of deci- sion procedures for languages given informants, ie, given enumerations of the characteristic functions of the languages. [FW79] shows that learning power is increased if, in addition to the informants, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:eFGnga8zZ4AJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9252420788343492984&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9252420788343492984&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/P3T027KM6X24LN74.pdf</url>
        <title status="complete" source="scholar.google.com">Learning from good examples</title>
        <author status="complete" source="scholar.google.com">R Freivalds, E Kinber, R Wiehagen</author>
        <proceeding status="partial" source="scholar.google.com">Algorithmic Learning for Knowledge- &#8230;</proceeding>
        <year>1995</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The usual information in inductive inference for the purposes of learning an unknown recursive function f is the set of all input/output examples (n, f (n)), nâ â. In contrast to this approach we show that it is considerably more powerful to work with finite sets of âgoodâ ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:or_7ehtJnkAJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4656239447123935138&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4656239447123935138&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <title status="complete" source="scholar.google.com">Department of Computer and Information Sciences University of Delaware Newark, DE 19716, USA</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RLkDr-qUHr8J:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13771608446225070404&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="61">
    <url>http://www.springerlink.com/index/f763141n66140230.pdf</url>
    <title status="complete" source="scholar.google.com">Kolmogorov numberings and minimal identification</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.100.2442&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">R Freivalds, S Jain</author>
    <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
    <year>1995</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... Science University of Latvia Rak/a bulvaris 29, LV-1459, Riga, Latvia Emaih rusins~mii.lu.lv 2Department of Information Systems and Computer Science National University of SingaporeLower Kent Ridge Rd Singapore 0511 Republic of Singapore Email: sanjay~iscs.nus.sg ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:ij7C47LGUQkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>10</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=671536291082550922&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>6</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=671536291082550922&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="6">
        <result id="0">
        <url>http://www.springerlink.com/index/P718V55764733017.pdf</url>
        <title status="complete" source="scholar.google.com">On the complexity of random strings</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.108.8689&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">M Kummer</author>
        <proceeding status="complete" source="scholar.google.com">STACS 96</proceeding>
        <year>1996</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We show that the set R of Kolmogorov random strings is truth-table complete. This improves the previously known Turing completeness of R and shows how the halting problem can be encoded into the distribution of random strings rather than using the time complexity of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:WC8ZnZ5eahMJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1399034669585477464&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>50</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1399034669585477464&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <title status="complete" source="scholar.google.com">A survey of inductive inference with an emphasis on queries</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.33.5664&amp;rep=rep1&amp;type=pdf</pdf>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GnKgfqPifP0J:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18265723380539879962&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18265723380539879962&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/71332606k5154565.pdf</url>
        <title status="complete" source="scholar.google.com">On learning and co-learning of minimal programs</title>
        <pdf>http://kluedo.ub.uni-kl.de/files/78/lsa_10.ps.gz</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1996</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In [8] Freivalds, Karpinski and Smith explored a special type of learning in the limit: identification of an unknown concept (function) by eliminating (erasing) all but one possible hypothesis. The motivation behind learning by erasing lies in the process of human and automated ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:eDmTjrKxEWIJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7066624670775327096&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7066624670775327096&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397599002698</url>
        <title status="complete" source="scholar.google.com">Learning languages and functions by erasing</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.33.6746&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="partial" source="scholar.google.com">S Jain, E Kinber, S Lange, R Wiehagen&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Theoretical computer &#8230;</proceeding>
        <year>2000</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Learning by erasing means the process of eliminating potential hypotheses from further consideration thereby converging to the least hypothesis never eliminated. This hypothesis must be a solution to the actual learning problem. The capabilities of learning by erasing ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:HTriKiOK64cJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>16</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9794073698295233053&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9794073698295233053&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.comp.nus.edu.sg/~sanjay/paps/kolinf.pdf</url>
        <title status="complete" source="scholar.google.com">An infinite class of functions identifiable using minimal programs in all Kolmogorov numberings</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/kolinf.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <proceeding status="partial" source="scholar.google.com">International Journal of Foundations of Computer &#8230;</proceeding>
        <year>1995</year>
        <source>comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">ABSTRACT Identification of programs for computable functions from their graphs by algorithmic devices is a well studied problem in learning theory. Freivalds and Chen consider identification of &#39;minimal&#39;and &#39;nearly minimal&#39;programs for functions from their ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:nTLW_Sixi_wJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:nTLW_Sixi_wJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18197833508936102557&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18197833508936102557&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397596002952</url>
        <title status="complete" source="scholar.google.com">Kolmogorov numberings and minimal identification</title>
        <author status="complete" source="scholar.google.com">R Freivalds, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>1997</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Identification of programs for computable functions from their graphs by algorithmic devices is a well studied problem in learning theory. Freivalds and Chen consider identification of &#39;minimal&#39;and &#39;nearly minimal&#39;programs for functions from their graphs. To address certain ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:8AD7cpk4JoUJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9594418287869624560&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9594418287869624560&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="62">
    <url>http://www.sciencedirect.com/science/article/pii/S0020019010002942</url>
    <title status="complete" source="scholar.google.com">Regular patterns, regular languages and context-free languages</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/regpat.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, YS Ong, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Information Processing Letters</proceeding>
    <year>2010</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... E-mail addresses: sanjay@comp.nus.edu.sg (S. Jain), yuhshin@gmail.com (YS Ong),fstephan@comp.nus.edu.sg (F. Stephan). 1 Supported in part by NUS grant numbersR252-000-420-112 and C252-000-087-001. 2 Supported ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:AJWPTe9OxrkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>19</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=13386473732110783744&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>4</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=13386473732110783744&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="4">
        <result id="0">
        <url>http://dl.comp.nus.edu.sg/dspace/handle/1900.100/3112</url>
        <title status="complete" source="scholar.google.com">On automatic families</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/3112/1/TRB1-10.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, YS Ong, S Pu, F Stephan</author>
        <year>2010</year>
        <source>dl.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract: This paper summarises previous work on automatic families. It then investigates a natural measure which exists inside every automatic family: the size of a regular language in this family is just the length of its index. This measure satisfies various properties similar to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:8apC6ZMa79sJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>20</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15847914836316039921&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15847914836316039921&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6280459</url>
        <title status="complete" source="scholar.google.com">The Complexity of Verbal Languages over Groups</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/verbal.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Miasnikov, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">Logic in Computer Science ( &#8230;</proceeding>
        <year>2012</year>
        <source>ieeexplore.ieee.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper investigates the complexity of verbal languages and pattern languages of Thurston automatic groups in terms of the Chomsky hierarchy. Here the language generated by a pattern is taken as the set of representatives of all strings obtained when ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:WALgH4K5iXMJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8325389354702733912&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.comp.nus.edu.sg/~fstephan/automatatheory-pstopdf.pdf</url>
        <title status="complete" source="scholar.google.com">CS5236âAdvanced Automata Theory</title>
        <pdf>http://www.comp.nus.edu.sg/~fstephan/automatatheory-pstopdf.pdf</pdf>
        <author status="complete" source="scholar.google.com">F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">comp.nus.edu.sg</proceeding>
        <snippet status="partial" source="scholar.google.com">Advanced Automata Theory is a lecture which will first review the basics of formal languages and automata theory and then give insight into specific topics from the theory of automata theory. In computer science, automata are an important tool for many theoretical results ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:oVDhZmpU7vIJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:oVDhZmpU7vIJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17505021617605005473&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/8224872526133417.pdf</url>
        <title status="complete" source="scholar.google.com">Regular and context-free pattern languages over small alphabets</title>
        <pdf>https://dspace.lboro.ac.uk/dspace-jspui/bitstream/2134/10117/6/Reidenbach_Schmid_DLT_2012.pdf</pdf>
        <author status="complete" source="scholar.google.com">D Reidenbach, M Schmid</author>
        <proceeding status="complete" source="scholar.google.com">Developments in Language Theory</proceeding>
        <year>2012</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Pattern languages are generalisations of the copy language, which is a standard textbook example of a context-sensitive and non-context-free language. In this work, we investigate a counter-intuitive phenomenon: with respect to alphabets of size 2 and 3, pattern ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:bx6aocTVeWQJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7240052916476321391&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="63">
    <url>http://www.springerlink.com/index/1p9a8e58kgtl7mwk.pdf</url>
    <title status="complete" source="scholar.google.com">Mind change complexity of learning logic programs</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.105.2902&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
    <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
    <year>1999</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 School of Computing National University of Singapore Singapore 119260, Republic ofSingapore Email: sanjay@comp.nus.edu.sg 2 School of Computer Science and EngineeringThe University of New South Wales Sydney, NSW 2052, Australia Email: arun@cse.unsw.edu ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:1GrxM06Kkp0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>9</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=11354289679037983444&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>5</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=11354289679037983444&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="5">
        <result id="0">
        <url>http://dl.acm.org/citation.cfm?id=267485</url>
        <title status="complete" source="scholar.google.com">Generalized notions of mind change complexity</title>
        <pdf>http://pdf.aminer.org/000/889/421/generalized_notions_of_mind_change_complexity.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Sharma, F Stephan, Y Ventsov</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; of the tenth annual conference on &#8230;</proceeding>
        <year>1997</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Speed of convergence in Gold&#39;s identification in the limit model can be measured by deriving bounds on the number of mind changes made by a learner before the onset of convergence. Two approaches to date are bounds given by constants (referred here as ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:wvC_V1rFm8sJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>31</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14671537202899448002&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>15</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14671537202899448002&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://projecteuclid.org/euclid.jsl/1080938842</url>
        <title status="complete" source="scholar.google.com">Parsimony hierarchies for inductive inference</title>
        <pdf>http://pdf.aminer.org/002/865/517/parsimony_hierarchies_for_inductive_inference.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Ambainis, J Case, S Jain, M Suraj</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
        <year>2004</year>
        <source>projecteuclid.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Freivalds defined an acceptable programming system independent criterion for learning programs for functions in which the final programs were required to be both correct and ânearlyâ minimal size, ie, within a computable function of being purely minimal size. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:PPOiazrZf9IJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15168080914944291644&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15168080914944291644&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/fnukkg3q6jalgx4r.pdf</url>
        <title status="complete" source="scholar.google.com">On sufficient conditions for learnability of logic programs from positive data</title>
        <author status="complete" source="scholar.google.com">E Martin, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Inductive Logic Programming</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Shinohara, Arimura, and Krishna Rao have shown learnability in the limit of minimal models of classes of logic programs from positive only data. In most cases, these results involve logic programs in which the âsizeâ of the head yields a bound on the size of the body ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:JX5Gq6SN42UJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7341867555931717157&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7341867555931717157&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://dl.acm.org/citation.cfm?id=307450</url>
        <title status="complete" source="scholar.google.com">On a generalized notion of mistake bounds</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.115.8551&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the twelfth annual conference on &#8230;</proceeding>
        <year>1999</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract The present paper proposes the use of constructive ordinals as mistake bounds in the online learning model. This approach elegantly generalizes the applicability of the on-line mistake bound model to learnability analysis of very expressive concept classes like ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MyqL-H2ICScJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2812929516891744819&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2812929516891744819&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.12.1102&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Two Probabilistic Approaches to First-Order Theory Induction</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.12.1102&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">F ZeleznÃ½</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">A research field achieves maturity when the underlying theories shift from guaranteeing fantastic results upon satisfying unrealistic conditions, towards giving the mere hope that reasonable outcomes can be expected in the usual case. It has been several years since ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:AXKrRNS5QwEJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:AXKrRNS5QwEJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=91120738813833729&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="64">
    <url>http://www.sciencedirect.com/science/article/pii/002001909400172U</url>
    <title status="complete" source="scholar.google.com">On a question about learning nearly minimal programs</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/mexex.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain</author>
    <proceeding status="complete" source="scholar.google.com">Information processing letters</proceeding>
    <year>1995</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... in the above model be of (nearly) minimal size. For nearly minimal identification withat most m errors and n mind changes one requires, in addition to iden- [ Email:sanjay@iscs.nus.sg. tification with at most m errors and n mind ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:XnonSyojIRIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>9</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=1306364031470631518&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>5</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=1306364031470631518&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="5">
        <result id="0">
        <title status="complete" source="scholar.google.com">A survey of inductive inference with an emphasis on queries</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.33.5664&amp;rep=rep1&amp;type=pdf</pdf>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GnKgfqPifP0J:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18265723380539879962&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18265723380539879962&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.comp.nus.edu.sg/~sanjay/paps/parsh.pdf</url>
        <title status="complete" source="scholar.google.com">Machine induction without revolutionary changes in hypothesis size</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/parsh.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>1996</year>
        <source>comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper provides a beginning study of the effects on inductive inference of paradigm shifts whose absence is approximately modeled by various formal approaches to forbidding large changes in the size of programs conjectured. One approach, called ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:UBoOOrjlzAYJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:UBoOOrjlzAYJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=490019038887287376&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=490019038887287376&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/P10132MM72722530.pdf</url>
        <title status="complete" source="scholar.google.com">Machine induction without revolutionary paradigm shifts</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1995</year>
        <source>Springer</source>
        <snippet status="complete" source="scholar.google.com">This paper provides a beginning study of the effects on inductive inference of paradigm shifts whose absence is approximately modeled by various formal approaches to forbidding large changes in the size of programs conjectured.</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:xSMXOf0nWRcJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1682419904337617861&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <title status="complete" source="scholar.google.com">Department of Computer and Information Sciences University of Delaware Newark, DE 19716, USA Email: case@ cis. udel. edu</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:XViiPr1RB8kJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.comp.nus.edu.sg/~sanjay/paps/isolated.pdf</url>
        <title status="complete" source="scholar.google.com">On a question of nearly minimal identification of functions</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/isolated.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Information processing letters</proceeding>
        <year>1999</year>
        <source>comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract Suppose A and B are classes of recursive functions. A is said to be an m-cover (â-cover) for B, iff for each gâ B, there exsits an fâ A such that f differs from g on at most m inputs (finitely many inputs). C, a class of recursive functions, is a-immune iff C is infinite ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:yEb7lxSYYo4J:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:yEb7lxSYYo4J:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10259930115320006344&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="65">
    <url>http://www.sciencedirect.com/science/article/pii/S0890540103000828</url>
    <title status="complete" source="scholar.google.com">Learning by switching type of information</title>
    <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
    <year>2003</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... We would like to thank the anonymous referees for useful comments. Sanjay Jain was supportedin part by NUS grant number R252-000-127-112. Frank Stephan was supported by the DeutscheForschungsgemeinschaft (DFG) under the Heisenberg grant Ste 967/1â1. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:T69CcuOiZkMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>8</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=4856748345923907407&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>5</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=4856748345923907407&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="5">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000006000912</url>
        <title status="complete" source="scholar.google.com">On the learnability of vector spaces</title>
        <pdf>http://home.gwu.edu/~harizanv/LearningVectorSpaces.pdf</pdf>
        <author status="complete" source="scholar.google.com">VS Harizanov, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The central topic of the paper is the learnability of the recursively enumerable subspaces of Vâ/V, where Vâ is the standard recursive vector space over the rationals with (countably) infinite dimension and V is a given recursively enumerable subspace of Vâ. It is shown ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:vAJdKbhcpJQJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10710787759831581372&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10710787759831581372&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/vg7tbegp60j98yac.pdf</url>
        <title status="complete" source="scholar.google.com">On the learnability of vector spaces</title>
        <pdf>http://home.gwu.edu/~harizanv/LearningWithStephanJournal.pdf</pdf>
        <author status="complete" source="scholar.google.com">V Harizanov, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2002</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The central topic of the paper is the learnability of the recursively enumerable subspaces of Vâ/V, where Vâ is the standard recursive vector space over the rationals with countably infinite dimension, and V is a given recursively enumerable subspace of Vâ. It is shown ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:fNrxctUkabMJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12927904704518806140&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12927904704518806140&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/N525J247J5PU4534.pdf</url>
        <title status="complete" source="scholar.google.com">Introduction to the Philosophy and Mathematics of Algorithmic Learning Theory</title>
        <pdf>http://sites.google.com/site/omundodalogica/livros-de-introducao-a-logica/Logic,Epistemology,andtheUnityofScienceVol.9-Induction,AlgorithmicLearningTheory,andPhilosophy.pdf#page=15</pdf>
        <author status="complete" source="scholar.google.com">V Harizanov, N Goethe, M Friend</author>
        <proceeding status="partial" source="scholar.google.com">Induction, Algorithmic Learning Theory, &#8230;</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Algorithmic learning theory is a mathematically precise, general framework for studying the existence of computational strategies for converging to the truth in empirical questions. As such, algorithmic learning theory has immediate implications for the philosophy of science ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:HtxJBnGArxcJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1706724006721870878&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://fs1.bib.tiera.ru/content/dvd57/Friend%20M.%20(ed.),%20Harizanov%20V.S.%20(ed.)%20-%20Induction,%20Algorithmic%20Learning%20Theory,%20and%20Philosophy(2007)(304).pdf#page=14</url>
        <title status="complete" source="scholar.google.com">INTRODUCTION TO THE PHILOSOPHY AND MATHEMATICS OF ALGORITHMIC LEARNING THEORY</title>
        <author status="complete" source="scholar.google.com">H Putnam</author>
        <proceeding status="partial" source="scholar.google.com">LOGIC, EPISTEMOLOGY, AND THE UNITY OF &#8230;</proceeding>
        <year>2007</year>
        <source>fs1.bib.tiera.ru</source>
        <snippet status="partial" source="scholar.google.com">Algorithmic learning theory is a mathematically precise, general framework for studying the existence of computational strategies for converging to the truth in empirical questions. As such, algorithmic learning theory has immediate implications for the philosophy of science ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GZZ7jcGSvDUJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:GZZ7jcGSvDUJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3872131139631814169&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/g654385j7014634v.pdf</url>
        <title status="complete" source="scholar.google.com">Inductive Inference Systems for Learning Classes of Algorithmically Generated Sets and Structures</title>
        <pdf>http://fs1.bib.tiera.ru/content/dvd57/Friend%20M.%20(ed.),%20Harizanov%20V.S.%20(ed.)%20-%20Induction,%20Algorithmic%20Learning%20Theory,%20and%20Philosophy(2007)(304).pdf#page=40</pdf>
        <author status="complete" source="scholar.google.com">V Harizanov</author>
        <proceeding status="partial" source="scholar.google.com">Induction, Algorithmic Learning Theory, and &#8230;</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Computability theorists have extensively studied sets A the elements of which can be enumerated by Turing machines. These sets, also called computably enumerable sets, can be identified with their G del codes. Although each Turing machine has a unique G del ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:dLv33n0UvL8J:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13815940287710083956&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="66">
    <url>http://www.springerlink.com/index/371821UW3L4225G8.pdf</url>
    <title status="complete" source="scholar.google.com">Automatic learners with feedback queries</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/autofeednew.pdf</pdf>
    <author status="partial" source="scholar.google.com">J Case, S Jain, Y Ong, P Semukhin&#8230;</author>
    <proceeding status="partial" source="scholar.google.com">Models of Computation in &#8230;</proceeding>
    <year>2011</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 Department of Computer and Information Sciences, University of Delaware, Newark, DE19716-2586, USA case@cis.udel.edu 2 Department of Computer Science, National Universityof Singapore, Singapore 117417, Republic of Singapore sanjay@comp.nus.edu.sg, yuhshin ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:RXW6gzjPnq0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>18</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=12510664656516969797&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>2</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=12510664656516969797&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="2">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000011001565</url>
        <title status="complete" source="scholar.google.com">Learnability of automatic classes</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2895/1/TRA1-09.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, Q Luo, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2011</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present work initiates the study of the learnability of automatic indexable classes which are classes of regular languages of a certain form. AngluinÊ¼s tell-tale condition characterises when these classes are explanatorily learnable. Therefore, the more ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:YFpXlQRP4YwJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>19</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10151481916173802080&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10151481916173802080&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www-test.comp.nus.edu.sg/~fstephan/autolearn.ps</url>
        <title status="complete" source="scholar.google.com">Learnability of automatic classes</title>
        <pdf>http://www-test.comp.nus.edu.sg/~fstephan/autolearn.ps</pdf>
        <author status="complete" source="scholar.google.com">S Jaina, Q Luob, F Stephanc</author>
        <year>2012</year>
        <source>www-test.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract The present work initiates the study of the learnability of automatic indexable classes which are classes of regular languages of a certain form. Angluin&#39;s tell-tale condition characterises when these classes are explanatorily learnable. Therefore, the more ...</snippet>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:JuK-zNs-g04J:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="67">
    <url>http://www.springerlink.com/index/71332606k5154565.pdf</url>
    <title status="complete" source="scholar.google.com">On learning and co-learning of minimal programs</title>
    <pdf>http://kluedo.ub.uni-kl.de/files/78/lsa_10.ps.gz</pdf>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>1996</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... of ISCS National University of Singapore Singapore Email: sanjay@iscs.nus.sg z Departmentof Computer Science Sacred Heart University 5151 Park Avenue Fairfield, CT 06432-1000 Email:kinber~shu.sacredheart.edu Universits Kaiserslautern Faehbereich Informatik Po O ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:eDmTjrKxEWIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>8</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=7066624670775327096&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>4</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=7066624670775327096&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="4">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397599002698</url>
        <title status="complete" source="scholar.google.com">Learning languages and functions by erasing</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.33.6746&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="partial" source="scholar.google.com">S Jain, E Kinber, S Lange, R Wiehagen&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Theoretical computer &#8230;</proceeding>
        <year>2000</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Learning by erasing means the process of eliminating potential hypotheses from further consideration thereby converging to the least hypothesis never eliminated. This hypothesis must be a solution to the actual learning problem. The capabilities of learning by erasing ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:HTriKiOK64cJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>16</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9794073698295233053&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9794073698295233053&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540101929220</url>
        <title status="complete" source="scholar.google.com">Learning by the process of elimination</title>
        <author status="partial" source="scholar.google.com">R Freivalds, M Karpinski, CH Smith&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Information and &#8230;</proceeding>
        <year>2002</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Elimination of potential hypotheses is a fundamental component of many learning processes. In order to understand the nature of elimination, herein we study the following model of learning recursive functions from examples. On any target function, the learning ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GP3h4Rz_L6sJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12335358403904929048&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12335358403904929048&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.3560&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Learning by the Process of Elimination</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.3560&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">M Karpinski, CH Smith, R Wiehagen</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract The process of elimination is a fundamental component of many learning processes. In order to understand the nature of elimination, herein we study an extreme model of learning from examples where learning is considered to be the elimination of all, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:B1zWNUKhVRwJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:B1zWNUKhVRwJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2041715311825542151&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://people.cs.uchicago.edu/~teutsch/research_statement.pdf</url>
        <title status="complete" source="scholar.google.com">Penn State University</title>
        <pdf>http://people.cs.uchicago.edu/~teutsch/research_statement.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Teutsch</author>
        <year>2012</year>
        <source>people.cs.uchicago.edu</source>
        <snippet status="partial" source="scholar.google.com">Summary My current research in mathematics and computer science explores the interaction between combinatorics, game theory, and computation, often with an eye towards applications in information security. I am interested in the power of language and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ix3owLh9Yx8J:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:ix3owLh9Yx8J:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="68">
    <url>http://pdf.aminer.org/000/311/008/unions_of_identifiable_families_of_languages.pdf</url>
    <title status="complete" source="scholar.google.com">Team learning of formal languages</title>
    <pdf>http://pdf.aminer.org/000/311/008/unions_of_identifiable_families_of_languages.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
    <proceeding status="complete" source="scholar.google.com">WSIMLC95</proceeding>
    <year>1995</year>
    <source>pdf.aminer.org</source>
    <snippet status="partial" source="scholar.google.com">Page 1. Team Learning of Formal Languages Sanjay Jain Dept. of Info. Systems &amp;Computer Science National University of Singapore Singapore 0511, Republic ofSingapore sanjay@iscs.nus.sg Arun Sharma School of Computer ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:VMXWutYixfwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:VMXWutYixfwJ:scholar.google.com/+author:%22Jain+Sanjay%22+NUS&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <numVersions>21</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=18214002573622822228&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>4</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=18214002573622822228&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="4">
        <result id="0">
        <url>http://www.springerlink.com/index/pt317625671130v0.pdf</url>
        <title status="complete" source="scholar.google.com">Adaptation and learning in multi-agent systems: Some remarks and a bibliography</title>
        <author status="complete" source="scholar.google.com">G WeiÃ</author>
        <proceeding status="complete" source="scholar.google.com">Adaption and learning in multi-agent systems</proceeding>
        <year>1996</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In the last years the topic of adaptation and learning in multi-agent systems has gained increasing attention in Artificial Intelligence. This article is intended to provide a compact, introductory and motivational guide to this topic. The article consists of two sections. In the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:jaM1QLN_fJUJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10771624816616514445&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>168</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10771624816616514445&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <title status="complete" source="scholar.google.com">Adaptation and learning in multi-agent systems: Some remarks and a bibliography</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.45.1884&amp;rep=rep1&amp;type=pdf</pdf>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1uPoBunJoYgJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>15</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9845372263089103830&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>27</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9845372263089103830&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/615516R770962476.pdf</url>
        <title status="complete" source="scholar.google.com">Learning and communication in multi-agent systems</title>
        <pdf>https://wwwipr.ira.uka.de/en/publications/download/id/121/d/article121.pdf</pdf>
        <author status="complete" source="scholar.google.com">H Friedrich, M Kaiser, O Rogalla, R Dillmann</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; Artificial Intelligence Meets &#8230;</proceeding>
        <year>1997</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper discusses the significance of communication between individual agents that are embedded into learning Multi-Agent Systems. For several learning tasks occurring within a Multi-Agent System, communication activities are investigated and the need for a mutual ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:K_s8qw-tbvIJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17469090287425747755&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17469090287425747755&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://wwwipr.ira.uka.de/en/publications/download/id/91/d/article91.pdf</url>
        <title status="complete" source="scholar.google.com">Communication as the basis for learning in multi-agent systems</title>
        <pdf>http://wwwipr.ira.uka.de/en/publications/download/id/91/d/article91.pdf</pdf>
        <author status="complete" source="scholar.google.com">M Kaiser, R Dillman, O Rogalla</author>
        <proceeding status="partial" source="scholar.google.com">ECAI&#39;96 Workshop on Learning &#8230;</proceeding>
        <year>1996</year>
        <source>wwwipr.ira.uka.de</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper discusses the signi cance of communication between individual agents that are embedded into learning Multi-Agent Systems. For several learning tasks occurring within a Multi-Agent System, communication activities are investigated and the need for a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:8VPuMGqfZG8J:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:8VPuMGqfZG8J:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8026715714317341681&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8026715714317341681&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="69">
    <url>http://dl.comp.nus.edu.sg/dspace/handle/1900.100/1903</url>
    <title status="complete" source="scholar.google.com">Memory-Limited U-Shaped Learning</title>
    <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1903/1/tr51-05.pdf</pdf>
    <author status="complete" source="scholar.google.com">L CARLUCCI, J CASE, S JAIN, F STEPHAN</author>
    <year>2005</year>
    <source>dl.comp.nus.edu.sg</source>
    <snippet status="partial" source="scholar.google.com">... sanjay@comp.nus.edu.sg 4 School of Computing and Department of Mathematics, NationalUniversity of Singapore, 3 Science Drive 2, Singapore 117543, Republic of Singapore.fstephan@comp.nus.edu.sg ... Supported in part by NUS grant number R252â000â127â112. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:2QKGOB0_q7AJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>4</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=12730338166427747033&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=12730338166427747033&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://www.springerlink.com/index/RL2050457GU60010.pdf</url>
        <title status="complete" source="scholar.google.com">Iterative learning from positive data and negative counterexamples</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1918/1/TRA3-06.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A model for learning in the limit is defined where a (so-called iterative) learner gets all positive examples from the target language, tests every new conjecture with a teacher (oracle) if it is a subset of the target language (and if it is not, then it receives a negative ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:LnGoLrd_Ie4J:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>15</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17159136479996834094&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17159136479996834094&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=1</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="70">
    <url>http://iospress.metapress.com/index/506U32192564M0H5.pdf</url>
    <title status="complete" source="scholar.google.com">Prescribed learning of indexed families</title>
    <pdf>https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2573/1/TRB9-07.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, F Stephan, Y Nan</author>
    <proceeding status="complete" source="scholar.google.com">Fundamenta Informaticae</proceeding>
    <year>2008</year>
    <source>IOS Press</source>
    <snippet status="partial" source="scholar.google.com">... Sanjay Jainâ School of Computing, National University of Singapore Singapore 117590, Republicof Singapore sanjay@comp.nus.edu.sg ... Ye Nanâ School of Computing, National University ofSingapore Singapore 117590, Republic of Singapore g0701171@nus.edu.sg ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:L0BIVfdJrrIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>29</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=12875309711335374895&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=12875309711335374895&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540110002026</url>
        <title status="complete" source="scholar.google.com">Hypothesis spaces for learning</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/hypdep.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2011</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In this paper we survey some results in inductive inference showing how learnability of a class of languages may depend on the hypothesis space chosen. Additionally, optimal hypothesis spaces, usable for every learnable class, are considered. We also discuss ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:nE03dzw6FbIJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12832226744634658204&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12832226744634658204&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=1</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="71">
    <url>http://www.springerlink.com/index/612574GMH0421876.pdf</url>
    <title status="complete" source="scholar.google.com">Closed left-re sets</title>
    <pdf>http://people.cs.uchicago.edu/~teutsch/papers/closedleftre.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, F Stephan, J Teutsch</author>
    <proceeding status="partial" source="scholar.google.com">Theory and Applications of Models of &#8230;</proceeding>
    <year>2011</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 Department of Computer Science, National University of Singapore, Singapore 117543,Republic of Singapore sanjay@comp.nus.edu.sg 2 Department of Mathematics, NationalUniversity of Singapore, Singapore 119076, Republic of Singapore fstephan@comp.nus.edu. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:s0qpXrQ3YzQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>19</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=3774922160488401587&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>2</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=3774922160488401587&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="2">
        <result id="0">
        <url>http://dl.acm.org/citation.cfm?id=2287724</url>
        <title status="complete" source="scholar.google.com">Arithmetic complexity via effective names for random sequences</title>
        <pdf>http://people.cs.uchicago.edu/~teutsch/papers/enumerating_randoms.pdf</pdf>
        <author status="complete" source="scholar.google.com">B Kjos-Hanssen, F Stephan, J Teutsch</author>
        <proceeding status="partial" source="scholar.google.com">ACM Transactions on &#8230;</proceeding>
        <year>2012</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract We investigate enumerability properties for classes of sets which permit recursive, lexicographically increasing approximations, or left-re sets. In addition to pinpointing the complexity of left-re Martin-LÃ¶f, computably, Schnorr, and Kurtz random sets, weakly 1- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:5nJDGcmI8dAJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15055965426569933542&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15055965426569933542&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://people.cs.uchicago.edu/~teutsch/papers/reselect.pdf</url>
        <title status="complete" source="scholar.google.com">Selection by Recursively Enumerable Setsâ</title>
        <pdf>http://people.cs.uchicago.edu/~teutsch/papers/reselect.pdf</pdf>
        <author status="complete" source="scholar.google.com">W Merkle, F Stephan, J Teutsch, W Wang, Y Yang</author>
        <proceeding status="complete" source="scholar.google.com">people.cs.uchicago.edu</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. For given sets A, B, and Z of natural numbers where the members of Z are z0&lt; z1&lt;..., one says that A is selected from B by Z if A (i)= B (zi) for all i. Furthermore, say that A is selected from B if A is selected from B by some recursively enumerable set, and that A is ...</snippet>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:zpiy9JO5GLIJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="72">
    <url>http://www.sciencedirect.com/science/article/pii/S0022000000917367</url>
    <title status="complete" source="scholar.google.com">Synthesizing learners tolerating computable noisy data</title>
    <author status="complete" source="scholar.google.com">J Case, S Jain</author>
    <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
    <year>2001</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... nus.edu.sgf2. ... f1 E-mail: case@cis.udel.edu. f2 E-mail: sanjay@comp.nus.edu.sg. Copyright Â©2001 Academic Press. All rights reserved. Bibliographic information. Citing and related articles.Related articles. No articles found. Cited by in Scopus (2). Related reference work articles ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:I11qjU5RhmMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>4</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=7171508854455950627&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>2</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=7171508854455950627&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="2">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397508001503</url>
        <title status="complete" source="scholar.google.com">Learning indexed families of recursive languages from positive data: A survey</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/tcs08lzz.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, T Zeugmann, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In the past 40 years, research on inductive inference has developed along different lines, eg, in the formalizations used, and in the classes of target concepts considered. One common root of many of these formalizations is Gold&#39;s model of identification in the limit. This model ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:kHdpMOKBOpwJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11257453027040786320&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>39</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11257453027040786320&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/RK67V5644693N33P.pdf</url>
        <title status="complete" source="scholar.google.com">Learning families of closed sets in matroids</title>
        <pdf>http://carlossicoli.free.fr/D/Dinneen_M.J.,_Khoussainov_B.,_Nies_A.-Computation,_Physics_and_Beyond-Springer(2012).pdf#page=130</pdf>
        <author status="complete" source="scholar.google.com">Z Gao, F Stephan, G Wu, A Yamamoto</author>
        <proceeding status="partial" source="scholar.google.com">Computation, Physics and &#8230;</proceeding>
        <year>2012</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In this paper it is studied for which oracles A and which types of A-re matroids the class of all A-re closed sets in the matroid is learnable by an unrelativised learner. The learning criteria considered comprise in particular criteria more general than behaviourally correct ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:imU_RCcj09AJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>21</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15047409431530661258&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15047409431530661258&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="73">
    <url>http://www.sciencedirect.com/science/article/pii/S0022000004000212</url>
    <title status="complete" source="scholar.google.com">Robust learningârich and poor</title>
    <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan, R Wiehagen</author>
    <proceeding status="partial" source="scholar.google.com">Journal of Computer and System &#8230;</proceeding>
    <year>2004</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... 265 ,in: KP Jantke, Editor, Analogical and Inductive Inference, Proceedings of the InternationalWorkshop, Springer, Berlin (1986), pp. 220â227. Corresponding Author Contact InformationCorresponding author. 1 Supported in part by NUS Grant R252-000-127-112. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:ukImu-_3fDcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>2</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=3998343178207249082&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>6</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=3998343178207249082&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="6">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397508001400</url>
        <title status="complete" source="scholar.google.com">Learning recursive functions: A survey</title>
        <pdf>http://webdocs.cs.ualberta.ca/~zilles/zeugmannZ08survey.pdf</pdf>
        <author status="complete" source="scholar.google.com">T Zeugmann, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Studying the learnability of classes of recursive functions has attracted considerable interest for at least four decades. Starting with Gold&#39;s (1967) model of learning in the limit, many variations, modifications and extensions have been proposed. These models differ in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2f2VA5VmFfUJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17660134303999589849&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>14</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17660134303999589849&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/Y1537725320743Q1.pdf</url>
        <title status="complete" source="scholar.google.com">Dynamically delayed postdictive completeness and consistency in learning</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/PcpPcsDelayTR.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In computational function learning in the limit, an algorithmic learner tries to find a program for a computable function g given successively more values of g, each time outputting a conjectured program for g. A learner is called postdictively complete iff all available data is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:7IuxNDCJ05gJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11012296353986481132&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11012296353986481132&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/l5p6329uk2633r03.pdf</url>
        <title status="complete" source="scholar.google.com">Directions for computability theory beyond pure mathematical</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/rft-directions.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Mathematical problems from applied logic II</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper begins by briefly indicating the principal, non-standard motivations of the author for his decades of work in Computability Theory (CT), aka Recursive Function Theory. Then it discusses its proposed, general directions beyond those from pure mathematics for CT. These ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:BWKg2uLmRxMJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1389332872072028677&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1389332872072028677&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540104000550</url>
        <title status="complete" source="scholar.google.com">Learning all subfunctions of a function</title>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Sublearning, a model for learning of subconcepts of a concept, is presented. Sublearning a class of total recursive functions informally means to learn all functions from that class together with all of their subfunctions. While in language learning it is known to be ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:u64grAkFrAEJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=120476829132828347&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=120476829132828347&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://projecteuclid.org/euclid.jsl/1305810752</url>
        <title status="complete" source="scholar.google.com">Robust separations in inductive inference</title>
        <author status="complete" source="scholar.google.com">M Fulk</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
        <year>2011</year>
        <source>projecteuclid.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Results in recursion-theoretic inductive inference have been criticized as depending on unrealistic self-referential examples. JM BÄrzdiÅÅ¡ proposed a way of ruling out such examples, and conjectured that one of the earliest results of inductive inference ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:VRX6dMGFfUgJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5223478208757372245&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5223478208757372245&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.springerlink.com/index/l5rax18a05jhx5br.pdf</url>
        <title status="complete" source="scholar.google.com">Learning all subfunctions of a function</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/subex.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory and Kernel Machines</proceeding>
        <year>2003</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Sublearning, a model for learning of subconcepts of a concept, is presented. Sublearning a class of total recursive functions informally means to learn all functions from that class together with all of their subfunctions. While in language learning it is known to be ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FXBRXtWXmCoJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3069370088719216661&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="74">
    <url>http://www.springerlink.com/index/u584873247003656.pdf</url>
    <title status="complete" source="scholar.google.com">Mitotic classes</title>
    <pdf>https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2569/1/TRB8-07.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
    <year>2007</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 Department of Computer Science, National University of Singapore, Singapore 117543,Republic of Singapore sanjay@comp.nus.edu.sg 2 Department of Computer Science andDepartment of Mathematics, National University of Singapore, Singapore 117543, Republic of ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:bEfvZa6Aqn8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>9</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=9199306675380504428&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=9199306675380504428&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <title status="complete" source="scholar.google.com">Inductive inference: theories and techniques</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:lKSmli8IdK8J:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="75">
    <url>http://www.springerlink.com/index/Q3641U74N61G1323.pdf</url>
    <title status="complete" source="scholar.google.com">Numberings optimal for learning</title>
    <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2823/1/TRA8-08+-+Frank+Stephan+and+Sanjay+Jain.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2008</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 Department of Computer Science, National University of Singapore, Singapore 117543,Republic of Singapore sanjay@comp.nus.edu.sg 2 Department of Computer Science andDepartment of Mathematics, National University of Singapore, Singapore 117543, Republic of ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:IUHpyvyqy04J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>25</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=5677819757943406881&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=5677819757943406881&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540110002026</url>
        <title status="complete" source="scholar.google.com">Hypothesis spaces for learning</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/hypdep.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2011</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In this paper we survey some results in inductive inference showing how learnability of a class of languages may depend on the hypothesis space chosen. Additionally, optimal hypothesis spaces, usable for every learnable class, are considered. We also discuss ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:nE03dzw6FbIJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12832226744634658204&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12832226744634658204&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=1</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="76">
    <url>http://www.sciencedirect.com/science/article/pii/S0304397502004218</url>
    <title status="complete" source="scholar.google.com">On learning of functions refutably</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.100.9346&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen, T Zeugmann</author>
    <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
    <year>2003</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... Informatik, 1993.. Corresponding Author Contact Information Corresponding author.1 Supported in part by NUS grant number R252-000-127-112. Copyright Â© 2002Elsevier Science BV All rights reserved. Theoretical Computer ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:p7s2pvsnODgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>12</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=4051031826598640551&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>6</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=4051031826598640551&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="6">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S030439750200422X</url>
        <title status="complete" source="scholar.google.com">Refuting learning revisited</title>
        <author status="complete" source="scholar.google.com">W Merkle, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We consider, within the framework of inductive inference, the concept of refuting learning as introduced by Mukouchi and Arikawa, where the learner is not only required to learn all concepts in a given class but also has to explicitly refute concepts outside the class. In the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RVIbTNh5upMJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10644954639140344389&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10644954639140344389&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/L23CUU7HRC4JU3UV.pdf</url>
        <title status="complete" source="scholar.google.com">Refuting learning revisited</title>
        <pdf>http://pdf.aminer.org/001/093/440/refuting_learning_revisited.pdf</pdf>
        <author status="complete" source="scholar.google.com">W Merkle, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We consider, within the framework of inductive inference, the concept of refuting learning as introduced by Mukouchi and Arikawa, where the learner is not only required to learn all concepts in a given class but also has to explicitly refute concepts outside the class. In the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:KuoyBNoKaj4J:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4497419109372455466&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4497419109372455466&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397508001412</url>
        <title status="complete" source="scholar.google.com">Reflective inductive inference of recursive functions</title>
        <author status="complete" source="scholar.google.com">G Grieser</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In this paper, we investigate reflective inductive inference of recursive functions. A reflective IIM is a learning machine that is additionally able to assess its own competence. First, we formalize reflective learning from arbitrary, and from canonical, example sequences. Here, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:NX7O4wMNs5oJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11147267813030133301&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11147267813030133301&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000003001491</url>
        <title status="complete" source="scholar.google.com">Trees and learning</title>
        <author status="complete" source="scholar.google.com">W Merkle, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We characterize FIN-, EX-and BC-learning, as well as the corresponding notions of team learning, in terms of isolated branches on effectively given sequences of trees. The more restrictive models of FIN-learning and strong-monotonic BC-learning are characterized in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:hQkNKCpTD28J:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8002706503386335621&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <title status="complete" source="scholar.google.com">Mathematisches Institut, Universitat Heidelberg 69120 Heidelberg, Germany, EU</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:OnDXsF3WybQJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <title status="complete" source="scholar.google.com">Reflexive Induktive Inferenz</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:arZY9pLbFEAJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4617556942206318186&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="77">
    <url>http://www.sciencedirect.com/science/article/pii/S0304397510002057</url>
    <title status="complete" source="scholar.google.com">Incremental learning with temporary memory</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/tem.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, S Lange, SE Moelius, S Zilles</author>
    <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
    <year>2010</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... in[14]is:foreachk,thereisaclassoflanguagesthatcanbeidentifiedbymemorizingkC1examples,butthatcannot beidentifiedbymemorizingonlykexamples(Theorem7below).FurtherresultsontheBem-learningmodelareobtained in[5,4].1 E-mailaddresses:sanjay@comp.nus.edu.sg(S.Jain ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:3nbCH_5_qskJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>6</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=14531567877095585502&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>5</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=14531567877095585502&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="5">
        <result id="0">
        <url>http://www.springerlink.com/index/WW86604W658G5101.pdf</url>
        <title status="complete" source="scholar.google.com">Solutions to open questions for non-U-shaped learning with memory limitations</title>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2010</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A U-shape occurs when a learner first learns, then unlearns, and, finally, relearns, some target concept. Within the framework of Inductive Inference, previous results have shown, for example, that U-shapes are unnecessary for explanatory learning, but are necessary for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ibyShxgPJ6sJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12332842702605565065&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12332842702605565065&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/74M53LP013269545.pdf</url>
        <title status="complete" source="scholar.google.com">Learning without coding</title>
        <author status="complete" source="scholar.google.com">S Moelius, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2010</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Iterative learning is a model of language learning from positive data, due to Wiehagen. When compared to a learner in Gold&#39;s original model of language learning from positive data, an iterative learner can be thought of as memory-limited. However, an iterative ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:y3d_62hDJLIJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12836458955819415499&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12836458955819415499&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=nEBfBghRSgsC&amp;oi=fnd&amp;pg=PA300&amp;ots=42d4reIyFd&amp;sig=IDRJ8v6CyA-UQi1o02j39tQg3Xo</url>
        <title status="complete" source="scholar.google.com">Learning without Coding</title>
        <pdf>http://www.eecis.udel.edu/~moelius/publications/lwoc_tr.pdf</pdf>
        <author status="complete" source="scholar.google.com">SEM Iii, S Zilles</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; , ALT 2010, Canberra, Australia, October 6-8, &#8230;</proceeding>
        <year>2010</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">Abstract. Iterative learning is a model of language learning from positive data, due to Wiehagen. When compared to a learner in Gold&#39;s original model of language learning from positive data, an iterative learner can be thought of as memory-limited. However, an ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:L2vGQFeWA-0J:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17078659513412119343&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397512009310</url>
        <title status="complete" source="scholar.google.com">Memory-limited non-U-shaped learning with solved open problems</title>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Herein we also distinguish between semantic and syntactic U-shapes. We answer a number of open questions in the prior literature as well as provide new results regarding syntactic U-shapes. Importantly for cognitive science, we see more of a previously noticed pattern ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397512009322</url>
        <title status="complete" source="scholar.google.com">Learning without coding</title>
        <author status="complete" source="scholar.google.com">S Jain, SE Moelius III, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Abstract Iterative learning is a model of language learning from positive data, due to Wiehagen. When compared to a learner in Gold&#39;s original model of language learning from positive data, an iterative learner can be thought of as memory-limited. However, an ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="78">
    <url>http://www.comp.nus.edu.sg/~sanjay/paps/parsh.pdf</url>
    <title status="complete" source="scholar.google.com">Machine induction without revolutionary changes in hypothesis size</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/parsh.pdf</pdf>
    <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
    <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
    <year>1996</year>
    <source>comp.nus.edu.sg</source>
    <snippet status="partial" source="scholar.google.com">... Email: case@cis.udel.edu Sanjay Jain Department of Information Systems andComputer Science National University of Singapore Singapore 119260, Republicof Singapore Email: sanjay@iscs.nus.sg Arun Sharma School of ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:UBoOOrjlzAYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:UBoOOrjlzAYJ:scholar.google.com/+author:%22Jain+Sanjay%22+NUS&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <numVersions>8</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=490019038887287376&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>3</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=490019038887287376&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="3">
        <result id="0">
        <url>http://projecteuclid.org/euclid.jsl/1080938842</url>
        <title status="complete" source="scholar.google.com">Parsimony hierarchies for inductive inference</title>
        <pdf>http://pdf.aminer.org/002/865/517/parsimony_hierarchies_for_inductive_inference.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Ambainis, J Case, S Jain, M Suraj</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
        <year>2004</year>
        <source>projecteuclid.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Freivalds defined an acceptable programming system independent criterion for learning programs for functions in which the final programs were required to be both correct and ânearlyâ minimal size, ie, within a computable function of being purely minimal size. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:PPOiazrZf9IJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15168080914944291644&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15168080914944291644&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://search.ieice.org/bin/summary.php?id=e86-d_2_219</url>
        <title status="complete" source="scholar.google.com">Criteria for inductive inference with mind changes and anomalies of recursive real-valued functions</title>
        <author status="partial" source="scholar.google.com">E Hirowatari, K Hirata, T Miyahara&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; on Information and &#8230;</proceeding>
        <year>2003</year>
        <source>search.ieice.org</source>
        <snippet status="partial" source="scholar.google.com">This paper investigates the interaction of&lt; I&gt; mind changes&lt;/I&gt; and&lt; I&gt; anomalies&lt;/I&gt; for inductive inference of recursive real-valued functions. We show that the criteria for inductive inference of recursive real-valued functions by bounding the number of mind changes and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:rFwCx_sXAPUJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17654136909435395244&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17654136909435395244&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/l5p6329uk2633r03.pdf</url>
        <title status="complete" source="scholar.google.com">Directions for computability theory beyond pure mathematical</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/rft-directions.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Mathematical problems from applied logic II</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper begins by briefly indicating the principal, non-standard motivations of the author for his decades of work in Computability Theory (CT), aka Recursive Function Theory. Then it discusses its proposed, general directions beyond those from pure mathematics for CT. These ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:BWKg2uLmRxMJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1389332872072028677&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1389332872072028677&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="79">
    <url>http://www.comp.nus.edu.sg/~sanjay/paps/kolinf.pdf</url>
    <title status="complete" source="scholar.google.com">An infinite class of functions identifiable using minimal programs in all Kolmogorov numberings</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/kolinf.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain</author>
    <proceeding status="partial" source="scholar.google.com">International Journal of Foundations of Computer &#8230;</proceeding>
    <year>1995</year>
    <source>comp.nus.edu.sg</source>
    <snippet status="partial" source="scholar.google.com">... National University of Singapore Singapore 0511 Republic of Singapore Email:sanjay@iscs.nus.sg ABSTRACT Identification of programs for computable functions from theirgraphs by algo- rithmic devices is a well studied problem in learning theory. Freivalds and Chen ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:nTLW_Sixi_wJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:nTLW_Sixi_wJ:scholar.google.com/+author:%22Jain+Sanjay%22+NUS&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <numVersions>6</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=18197833508936102557&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>3</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=18197833508936102557&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="3">
        <result id="0">
        <url>http://www.springerlink.com/index/71332606k5154565.pdf</url>
        <title status="complete" source="scholar.google.com">On learning and co-learning of minimal programs</title>
        <pdf>http://kluedo.ub.uni-kl.de/files/78/lsa_10.ps.gz</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1996</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In [8] Freivalds, Karpinski and Smith explored a special type of learning in the limit: identification of an unknown concept (function) by eliminating (erasing) all but one possible hypothesis. The motivation behind learning by erasing lies in the process of human and automated ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:eDmTjrKxEWIJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7066624670775327096&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7066624670775327096&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/UP723K584R2TU525.pdf</url>
        <title status="complete" source="scholar.google.com">Identifying nearly minimal GÃ¶del numbers from additional information</title>
        <author status="complete" source="scholar.google.com">R Freivalds, O Botuscharov, R Wiehagen</author>
        <proceeding status="partial" source="scholar.google.com">Annals of Mathematics and &#8230;</proceeding>
        <year>1998</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract A new identification type close to the identification of minimal Gdel numbers is considered. The type is defined by allowing as input both the graph of the target function and an arbitrary upper bound of the minimal index of the target function in a Gdel numbering of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:n0UluhBY3lcJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6331594954995221919&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6331594954995221919&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397599002698</url>
        <title status="complete" source="scholar.google.com">Learning languages and functions by erasing</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.33.6746&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="partial" source="scholar.google.com">S Jain, E Kinber, S Lange, R Wiehagen&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Theoretical computer &#8230;</proceeding>
        <year>2000</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Learning by erasing means the process of eliminating potential hypotheses from further consideration thereby converging to the least hypothesis never eliminated. This hypothesis must be a solution to the actual learning problem. The capabilities of learning by erasing ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:HTriKiOK64cJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>16</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9794073698295233053&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9794073698295233053&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="80">
    <url>http://www.springerlink.com/index/H2112615PHQ60P40.pdf</url>
    <title status="complete" source="scholar.google.com">Learning and extending sublanguages</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.114.3889&amp;rep=rep1&amp;type=pdf#page=150</pdf>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2006</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... Sanjay Jain1,â and Efim Kinber2 1 School of Computing, National University of Singapore,Singapore 117543 sanjay@comp.nus.edu.sg 2 Department of Computer Science, Sacred HeartUniversity, Fairfield, CT 06432-1000, USA kinbere@sacredheart.edu Abstract. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:keIkDRy3wyUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>11</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=2721219930969399953&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=2721219930969399953&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397508001515</url>
        <title status="complete" source="scholar.google.com">Learning and extending sublanguages</title>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A number of natural models for learning in the limit are introduced to deal with the situation when a learner is required to provide a grammar covering the input even if only a part of the target language is available. Examples of language families are exhibited that are ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:eK38qPkm9ZIJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10589412952555433336&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10589412952555433336&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=1</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="81">
    <url>http://www.springerlink.com/index/RL2050457GU60010.pdf</url>
    <title status="complete" source="scholar.google.com">Iterative learning from positive data and negative counterexamples</title>
    <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1918/1/TRA3-06.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2006</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... Sanjay Jain1,â and Efim Kinber2 1 School of Computing, National University of Singapore,Singapore 117543 sanjay@comp.nus.edu.sg 2 Department of Computer Science, Sacred HeartUniversity, Fairfield, CT 06432-1000, USA kinbere@sacredheart.edu Abstract. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:LnGoLrd_Ie4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>15</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=17159136479996834094&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=17159136479996834094&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://www.springerlink.com/index/82329846173M8772.pdf</url>
        <title status="complete" source="scholar.google.com">One-shot learners using negative counterexamples and nearest positive examples</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2315/1/tra3-07.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">As some cognitive research suggests, in the process of learning languages, in addition to overt explicit negative evidence, a child often receives covert explicit evidence in form of corrected or rephrased sentences. In this paper, we suggest one approach to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:70f8Jtnk5nEJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8207498992242411503&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8207498992242411503&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=1</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="82">
    <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.72.3587&amp;rep=rep1&amp;type=pdf</url>
    <title status="complete" source="scholar.google.com">A Polynomial Time Learner for a Subclass of Regular Patterns</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.72.3587&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="partial" source="scholar.google.com">J Case, S Jain, R Reischuk, F Stephan&#8230;</author>
    <proceeding status="partial" source="scholar.google.com">Electronic Colloquium on &#8230;</proceeding>
    <year>2004</year>
    <source>Citeseer</source>
    <snippet status="partial" source="scholar.google.com">... case@cis.udel.edu Sanjay Jain â  School of Computing National University of SingaporeSingapore 117543 sanjay@comp.nus.edu.sg RÃ¼diger Reischuk Institute for TheoreticalInformatics University at LÃ¼beck Ratzeburger Allee 160 23538 LÃ¼beck, Germany ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:n2qisYftnREJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:n2qisYftnREJ:scholar.google.com/+author:%22Jain+Sanjay%22+NUS&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <numVersions>32</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=1269431837044927135&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=1269431837044927135&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://www.springerlink.com/index/JUR0L848X014323K.pdf</url>
        <title status="complete" source="scholar.google.com">Interaction Faults Caused by Third-Party External SystemsâA Case Study and Challenges</title>
        <author status="complete" source="scholar.google.com">B Nassu, T Nanya</author>
        <proceeding status="complete" source="scholar.google.com">Service Availability</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Interaction faults caused by a flawed external system designed by a third party are a major issue faced by interconnected systems. In this paper, we define a scenario where this type of problem occurs, and describe some fault cases observed in real systems. We also discuss ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:vADuHe8JO6YJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11978178556525936828&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11978178556525936828&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=1</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="83">
    <url>http://www.springerlink.com/index/8mkw9eu65cxv7uya.pdf</url>
    <title status="complete" source="scholar.google.com">Learning multiple languages in groups</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.103.2412&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2005</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... Sanjay Jain1,â and Efim Kinber2 1 School of Computing, National University of Singapore,Singapore 117543 sanjay@comp.nus.edu.sg 2 Department of Computer Science, Sacred HeartUniversity, Fairfield, CT 06432-1000, USA kinbere@sacredheart.edu Abstract. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:FO3LtAlHWaUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>9</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=11914632396198898964&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=11914632396198898964&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397507005506</url>
        <title status="complete" source="scholar.google.com">Learning multiple languages in groups</title>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We consider a variant of Gold&#39;s learning paradigm where a learner receives as input n different languages (in the form of one text where all input languages are interleaved). Our goal is to explore the situation when a more âcoarseâ classification of input languages is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ceSqnui4hbIJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12863891219887613041&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="84">
    <url>http://www.springerlink.com/index/0F9V180D4H1PDFK4.pdf</url>
    <title status="complete" source="scholar.google.com">Learning how to separate</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/resep.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2001</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 School of Computing, National University of Singapore, Singapore 119260, sanjay@comp.nus.edu.sg 2 Mathematisches Institut, Im Neuenheimer Feld 294, Ruprecht-Karls-UniversitÃ¤tHeidelberg, 69120 Heidelberg, Germany, fstephan@math.uni-heidelberg.de Abstract. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:SdXNvUSIHnoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>19</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=8799620550752064841&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=8799620550752064841&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397503006108</url>
        <title status="complete" source="scholar.google.com">Learning how to separate</title>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The main question addressed in the present work is how to find effectively a recursive function separating two sets drawn arbitrarily from a given collection of disjoint sets. In particular, it is investigated when one can find better learners which satisfy additional ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:nF9d1Ps158kJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14548656476959629212&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14548656476959629212&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=1</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="85">
    <url>http://www.springerlink.com/index/97285WVT37N48810.pdf</url>
    <title status="complete" source="scholar.google.com">On learning languages from positive data and a limited number of short counterexamples</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/bncfull.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
    <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
    <year>2006</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... Sanjay Jain1,â and Efim Kinber2 1 School of Computing, National University of Singapore,Singapore 117543 sanjay@comp.nus.edu.sg 2 Department of Computer Science, Sacred HeartUniversity, Fairfield, CT 06432-1000, USA kinbere@sacredheart.edu Abstract. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:y-Vc4Y2Mb7QJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>6</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=13001765190241150411&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=13001765190241150411&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://www.scholarbank.nus.edu.sg/handle/10635/16035</url>
        <title status="complete" source="scholar.google.com">Specification mining: Methodologies, theories and applications</title>
        <pdf>http://www.scholarbank.nus.edu.sg/bitstream/handle/10635/16035/LoD.pdf?sequence=1</pdf>
        <author status="complete" source="scholar.google.com">D Lo</author>
        <year>2008</year>
        <source>scholarbank.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">In this dissertation, we describe theories, methodologies and applications of mining expressive software specifications from program execution traces. By observing program execution traces, specifications in the formats of automata, frequent behavioral patterns, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ED_riljR9zMJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3744691793399856912&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3744691793399856912&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=1</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="86">
    <url>https://qir.kyushu-u.ac.jp/dspace/handle/2324/3005</url>
    <title status="complete" source="scholar.google.com">Incremental concept learning for bounded data mining</title>
    <pdf>https://qir.kyushu-u.ac.jp/dspace/bitstream/2324/3005/1/trcs136.pdf</pdf>
    <author status="complete" source="scholar.google.com">J Case, S Jain, S Lange, T Zeugmann</author>
    <proceeding status="complete" source="scholar.google.com">136</proceeding>
    <year>1997</year>
    <source>qir.kyushu-u.ac.jp</source>
    <snippet status="partial" source="scholar.google.com">... Title Incremental Concept Learning for Bounded Data Mining Author(s) Case, John; Jain, Sanjay;Lange, Steffen; Zeugmann, Thomas ... Department of ISCS National University of Singapore LowerKent Ridge Road Singapore 119260, Rep. of Singapore sanjay@iscs.nus.edu.sg ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:WfNv0upB4Q0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>11</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=1000153069061665625&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>2</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=1000153069061665625&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="2">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397500001316</url>
        <title status="complete" source="scholar.google.com">On the learnability of recursively enumerable languages from good examples</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/good.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, S Lange, J Nessel</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present paper investigates identification of indexed families L of recursively enumerable languages from good examples. We distinguish class-preserving learning from good examples (the good examples have to be generated with respect to a hypothesis space ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:pT5ZV88QH0cJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5124833383680655013&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5124833383680655013&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://dl.acm.org/citation.cfm?id=312744</url>
        <title status="complete" source="scholar.google.com">APL-generated teaching and testing items to enhance a student&#39;s ability to discover functional relationships</title>
        <author status="complete" source="scholar.google.com">AJ Surkan</author>
        <proceeding status="complete" source="scholar.google.com">ACM SIGAPL APL Quote Quad</proceeding>
        <year>1999</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Ideas and designs for programs to generate teaching examples are introduced. Some of these ideas are tested and demonstrated by a prototype APL program. Descriptions of the internal structure and requirements of the example generators are presented. The ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:N6RdjfRMrMYJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14315901928731419703&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="87">
    <url>http://www.springerlink.com/index/7GC8VF50JMNQE5QM.pdf</url>
    <title status="complete" source="scholar.google.com">Predictive learning models for concept drift</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.47.4237&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="partial" source="scholar.google.com">J Case, S Jain, S Kaufmann, A Sharma&#8230;</author>
    <proceeding status="partial" source="scholar.google.com">Algorithmic Learning &#8230;</proceeding>
    <year>1998</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... Sciences, University of Delaware, 101A Smith Hall, Newark, DE 19716-2586, USA,case@cis.udel.edu 2 Department of Information Systems and Computer Science, NationalUniversity of Singapore, Singapore 119260, Republic of Singapore, sanjay@iscs.nus.edu.sg ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:73sA2o7ntSUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>17</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=2717332550916799471&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>2</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=2717332550916799471&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="2">
        <result id="0">
        <url>http://www.springerlink.com/index/L22830307P19676J.pdf</url>
        <title status="complete" source="scholar.google.com">Exploiting concept clumping for efficient incremental e-mail categorization</title>
        <pdf>http://www.cse.unsw.edu.au/~wobcke/papers/e-mail-clumping.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Krzywicki, W Wobcke</author>
        <proceeding status="complete" source="scholar.google.com">Advanced Data Mining and Applications</proceeding>
        <year>2010</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We introduce a novel approach to incremental e-mail categorization based on identifying and exploiting âclumpsâ of messages that are classified similarly. Clumping reflects the local coherence of a classification scheme and is particularly important in a setting where the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:XvyJOBzRUkwJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5499688014110653534&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5499688014110653534&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/X00153146476M151.pdf</url>
        <title status="complete" source="scholar.google.com">Probabilistic user modeling in the presence of drifting concepts</title>
        <pdf>https://enhum.googlecode.com/svn/trunk/paper/mainPaper.pdf</pdf>
        <author status="complete" source="scholar.google.com">V Bhardwaj, R Devarajan</author>
        <proceeding status="partial" source="scholar.google.com">Advances in Knowledge Discovery and Data &#8230;</proceeding>
        <year>2010</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. We investigate supervised prediction tasks which involve multiple agents over time, in the presence of drifting concepts. The motivation behind choosing the topic is that such tasks arise in many domains which require predicting human actions. An example of such ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:WIwGZMVBxBUJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1568450886274288728&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1568450886274288728&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="88">
    <url>http://www.sciencedirect.com/science/article/pii/S0890540104000550</url>
    <title status="complete" source="scholar.google.com">Learning all subfunctions of a function</title>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen</author>
    <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
    <year>2004</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... pp. 220â227. Corresponding Author Contact Information Corresponding author.Fax: +65-6779-4580. 1 Supported in part by NUS Grant No. R252-000-127-112.Copyright Â© 2004 Elsevier Inc. All rights reserved. Information ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:u64grAkFrAEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>3</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=120476829132828347&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>2</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=120476829132828347&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="2">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397508001515</url>
        <title status="complete" source="scholar.google.com">Learning and extending sublanguages</title>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A number of natural models for learning in the limit are introduced to deal with the situation when a learner is required to provide a grammar covering the input even if only a part of the target language is available. Examples of language families are exhibited that are ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:eK38qPkm9ZIJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10589412952555433336&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10589412952555433336&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/H2112615PHQ60P40.pdf</url>
        <title status="complete" source="scholar.google.com">Learning and extending sublanguages</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.114.3889&amp;rep=rep1&amp;type=pdf#page=150</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A number of natural models for learning in the limit is introduced to deal with the situation when a learner is required to provide a grammar covering the input even if only a part of the target language is available. Examples of language families are exhibited that are ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:keIkDRy3wyUJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2721219930969399953&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2721219930969399953&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="89">
    <url>http://www.tandfonline.com/doi/abs/10.1080/09528130010029802</url>
    <title status="complete" source="scholar.google.com">On an open problem in classification of languages</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.100.6827&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain</author>
    <proceeding status="partial" source="scholar.google.com">Journal of Experimental &amp; Theoretical Artificial &#8230;</proceeding>
    <year>2001</year>
    <source>Taylor &amp; Francis</source>
    <snippet status="partial" source="scholar.google.com">... SANJAY JAIN School of Computing, National University of Singapore, Singapore 119260 e-mail:sanjay@comp.nus.edu.sg Abstract. ... For , let = . Let = . Page 6. 118 S. Jain AcknowledgmentsThe author was supported in part by NUS grant number RP3992710. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:WX04j3ypwhIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>5</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=1351829190608452953&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=1351829190608452953&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://www.springerlink.com/index/U07211K470R73N12.pdf</url>
        <title status="complete" source="scholar.google.com">Learning and classifying</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/classifylearn.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Martin, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We define and study a learning paradigm that sits between identification in the limit and classification. More precisely, we expect that a learner be able to identify in the limit which members of a set D of n possible data belong to a target language, where n and D are ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:dAVDyGPzGgMJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=223758741395408244&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="90">
    <url>http://www.springerlink.com/index/et9pbxuppma6j9j0.pdf</url>
    <title status="complete" source="scholar.google.com">Learning languages in a union</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/kalapp.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, Y Ng, T Tay</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2001</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 School of Computing National University of Singapore Singapore 119260 sanjay@comp.nus.edu.sg 2 School of Computing National University of Singapore Singapore 119260ngyenkao@comp.nus.edu.sg 3 Department of Mathematics National University of Singapore ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:pFjStsX955MJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>14</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=10657766068813191332&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=10657766068813191332&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://www.springerlink.com/index/8mkw9eu65cxv7uya.pdf</url>
        <title status="complete" source="scholar.google.com">Learning multiple languages in groups</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.103.2412&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We consider a variant of Gold&#39;s learning paradigm where a learner receives as input n different languages (in form of one text where all input languages are interleaved). Our goal is to explore the situation when a more âcoarseâ classification of input languages is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FO3LtAlHWaUJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11914632396198898964&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11914632396198898964&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=1</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="91">
    <url>http://www.sciencedirect.com/science/article/pii/S0304397596002952</url>
    <title status="complete" source="scholar.google.com">Kolmogorov numberings and minimal identification</title>
    <author status="complete" source="scholar.google.com">R Freivalds, S Jain</author>
    <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
    <year>1997</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... program for /. Let p=M(/[n]). The criterion of success known as &#39;Es.-identification [2,4, 11] requires that the sequence po, p}, p... * Corresponding author. Tel.: +657727842;fax: +657794580; e-mail: sanjay@iscs.nus.sg. 0304-3975 ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:8AD7cpk4JoUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>6</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=9594418287869624560&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=9594418287869624560&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://www.math.cornell.edu/~dtaimina/mathinLV/mathinlv.html</url>
        <title status="complete" source="scholar.google.com">Some Notes on Mathematics in Latvia Through the Centuries</title>
        <pdf>http://www.math.cornell.edu/~dtaimina/mathinLV/mathinlv.html</pdf>
        <author status="complete" source="scholar.google.com">D Taimina</author>
        <proceeding status="complete" source="scholar.google.com">math.cornell.edu</proceeding>
        <snippet status="partial" source="scholar.google.com">This paper was written in 1997 as a compilation of all materials available for me at the time and being away from Latvia. To write a full account would be too big task for me alone and having no support. I hope that Latvian mathematicians one day will take this paper as a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:PJp7RaFpTgoJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="92">
    <url>http://www.springerlink.com/index/2567642l84087416.pdf</url>
    <title status="complete" source="scholar.google.com">Control structures in hypothesis spaces: The influence on learning</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.100.9732&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">J Case, S Jain, M Suraj</author>
    <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
    <year>1997</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... of Computer and Information Sciences University of Delaware Newark, DE 19716, USA{case,suraj } @cis.udel.edu 2 Department of Information Systems and Computer Science NationalUniversity of Singapore Singapore 119260 Republic of Singapore sanjay~iscs.nus.sg ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:k0PPox92zbIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>11</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=12884083987241190291&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=12884083987241190291&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://www.jstor.org/stable/10.2307/2694927</url>
        <title status="complete" source="scholar.google.com">Some independence results for control structures in complete numberings</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.109.7224&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, J Nessel</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
        <year>2001</year>
        <source>JSTOR</source>
        <snippet status="partial" source="scholar.google.com">Acceptable programming systems have many nice properties like smn-Theorem, Composition and Kleene Recursion Theorem. Those properties are sometimes called control structures, to emphasize that they yield tools to implement programs in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Ndzt1LIRQ_8J:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18393564762885446709&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18393564762885446709&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=1</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="93">
    <url>http://www.springerlink.com/index/f581mp71128658l0.pdf</url>
    <title status="complete" source="scholar.google.com">Team learning of recursive languages</title>
    <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
    <proceeding status="complete" source="scholar.google.com">PRICAI&#39;96: Topics in Artificial Intelligence</proceeding>
    <year>1996</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... Systems &amp; Computer Science, National University of Singapore, Singapore 119260, Republicof Singapore, Emaih sanjay@iscs.nus.sg 2 School of Computer Science and Engineering, TheUniversity of New South Wales, Sydney, NSW 2052, Australia, Emaih arun@cse.unsw ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:Q2WHuIBNz38J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>4</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=9209664978242987331&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=9209664978242987331&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://dare.uva.nl/record/363483</url>
        <title status="complete" source="scholar.google.com">Knowing one&#39;s limits: logical analysis of inductive inference</title>
        <pdf>http://dare.uva.nl/document/200643</pdf>
        <author status="complete" source="scholar.google.com">N Gierasimczuk</author>
        <year>2010</year>
        <source>dare.uva.nl</source>
        <snippet status="partial" source="scholar.google.com">This book is about change. Change of mind, revision of beliefs, formation of conjectures, and strategies for learning. We compare two major paradigms of formal epistemology that deal with the dynamics of informational states: formal learning theory and dynamic epistemic ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:0XobFzY4lzYJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3933674604498483921&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3933674604498483921&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=1</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="94">
    <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.49.1587&amp;rep=rep1&amp;type=pdf</url>
    <title status="complete" source="scholar.google.com">Learning Concepts Incrementally with Bounded Data Mining</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.49.1587&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">J Case, S Jain, S Lange, T Zeugmann</author>
    <proceeding status="partial" source="scholar.google.com">&#8230; Induction, The 14th Intl. Conf. on &#8230;</proceeding>
    <year>1997</year>
    <source>Citeseer</source>
    <snippet status="partial" source="scholar.google.com">... John Case Department of CIS University of Delaware Newark DE 19716, USAcase@cis.udel.edu Sanjay Jain Department of ISCS National University of Singapore LowerKent Ridge Road Singapore 119260, Rep. of Singapore sanjay@iscs.nus.sg ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:bu5T4_fbfgkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:bu5T4_fbfgkJ:scholar.google.com/+author:%22Jain+Sanjay%22+NUS&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <numVersions>7</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=684226051124227694&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=684226051124227694&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://www.springerlink.com/index/u0n8by7hk9tk8q85.pdf</url>
        <title status="complete" source="scholar.google.com">The induction of temporal grammatical rules from multivariate time series</title>
        <author status="complete" source="scholar.google.com">G GuimarÃ£es</author>
        <proceeding status="complete" source="scholar.google.com">Grammatical Inference: Algorithms and Applications</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In this paper the induction of temporal grammatical rules from multivariate time series is presented in the context of temporal data mining. This includes the use of unsupervised neural networks for the detection of the most significant temporal patterns in multivariate ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Hrjxn3ZO25kJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11086541179099133982&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>11</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11086541179099133982&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=1</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="95">
    <url>http://dl.acm.org/citation.cfm?id=307450</url>
    <title status="complete" source="scholar.google.com">On a generalized notion of mistake bounds</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.115.8551&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
    <proceeding status="partial" source="scholar.google.com">Proceedings of the twelfth annual conference on &#8230;</proceeding>
    <year>1999</year>
    <source>dl.acm.org</source>
    <snippet status="partial" source="scholar.google.com">Page 1. On a Generalized Notion of Mistake Bounds Sanjay Jain School of ComputingNational University of Singapore Singapore 119260, Republic of Singapore Email:sanjay@comp.nus.edu.sg Abstract The present paper ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:MyqL-H2ICScJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>13</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=2812929516891744819&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=2812929516891744819&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://projecteuclid.org/euclid.jsl/1080938842</url>
        <title status="complete" source="scholar.google.com">Parsimony hierarchies for inductive inference</title>
        <pdf>http://pdf.aminer.org/002/865/517/parsimony_hierarchies_for_inductive_inference.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Ambainis, J Case, S Jain, M Suraj</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
        <year>2004</year>
        <source>projecteuclid.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Freivalds defined an acceptable programming system independent criterion for learning programs for functions in which the final programs were required to be both correct and ânearlyâ minimal size, ie, within a computable function of being purely minimal size. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:PPOiazrZf9IJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15168080914944291644&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15168080914944291644&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=1</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="96">
    <url>http://www.sciencedirect.com/science/article/pii/S0890540103001743</url>
    <title status="complete" source="scholar.google.com">Counting extensional differences in BC-learning</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.97.1000&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, F Stephan, SA Terwijn</author>
    <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
    <year>2004</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... 243â248. Corresponding Author Contact Information Corresponding author. Fax: +65-6779-4580.1 Supported in part by NUS Grant No. R252-000-127-112. 2 Supported by the Heisenbergprogram of the German Science Foundation (DFG), Grant No. Ste 967/1â1. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:7Abr25fIqYAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>15</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=9271161862474106604&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=9271161862474106604&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540103002438</url>
        <title status="complete" source="scholar.google.com">Generalized notions of mind change complexity</title>
        <pdf>http://www.math.uni-heidelberg.de/logic/fstephan/ssv-mathpreprints-com.ps</pdf>
        <author status="complete" source="scholar.google.com">A Sharma, F Stephan, Y Ventsov</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Gold introduced the notion of learning in the limit where a class S is learnable iff there is a recursive machine M which reads the course of values of a function f and converges to a program for f whenever f is in S. An important measure for the speed of convergence in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cA20SaS7b8gJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14442968844286037360&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14442968844286037360&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=1</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="97">
    <url>http://www.sciencedirect.com/science/article/pii/S0304397503006108</url>
    <title status="complete" source="scholar.google.com">Learning how to separate</title>
    <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
    <year>2004</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... J. Inform. Process. Cybernet., (EIK) 12 (1976), pp. 421â438. Corresponding AuthorContact Information Corresponding author. Tel.: +65-6874-7842. 1 Sanjay Jain wassupported in part by NUS grant number R252-000-127-112. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:nF9d1Ps158kJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>6</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=14548656476959629212&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=14548656476959629212&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=100</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://xb.ynni.edu.cn/index.php/jne/article/viewArticle/1316</url>
        <title status="complete" source="scholar.google.com">åºäº Lie ç¾¤çæºå¨å­¦ä¹ çè®ºæ¡æ¶</title>
        <pdf>http://xb.ynni.edu.cn/index.php/jne/article/viewFile/1316/882</pdf>
        <author status="complete" source="scholar.google.com">æå¡é¿LFC</author>
        <proceeding status="complete" source="scholar.google.com">äºåæ°æå¤§å­¦å­¦æ¥ (èªç¶ç§å­¦ç)</proceeding>
        <year>2004</year>
        <source>xb.ynni.edu.cn</source>
        <snippet status="complete" source="scholar.google.com">æè¦åç¨å·æè¯å¥½æ°å­¦ç»æçLie ç¾¤æ¥ç ç©¶æºå¨å­¦ä¹ , æåºäºåºäºLie ç¾¤çæºå¨å­¦ä¹ (ML) åºæ¬æ¦å¿µ, å¯¹å¶ç©ºé´å­¦ä¹ æ¦å¿µç­, å½¢æäºåºäºLie ç¾¤çå­¦ä¹ çè®ºæ¡æ¶. è¯¥çè®ºæ¡æ¶å¯ä»¥ç¨ä»£æ°åå ä½çæ¹æ³æ¥æè¿°æºå¨å­¦ä¹ ç³»ç», å¼¥è¡¥äºåææºå¨å­¦ä¹ çè®ºçä¸è¶³.</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:_gPqiNcN-pgJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11023138257308877822&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11023138257308877822&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=1</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="98">
    <url>http://www.comp.nus.edu.sg/~fstephan/conservative.ps</url>
    <title status="complete" source="scholar.google.com">On Conservative Learning of Re Languages</title>
    <pdf>http://www.comp.nus.edu.sg/~fstephan/conservative.ps</pdf>
    <author status="complete" source="scholar.google.com">Z Gao, S Jain, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">comp.nus.edu.sg</proceeding>
    <snippet status="partial" source="scholar.google.com">... sanjay@comp.nus.edu.sg 3 Department of Mathematics and Department of Computer Science,National University of Singapore, Singapore 119076, Republic of Singapore. fstephan@comp.nus.edu.sg ... Work is supported in part by NUS grant R252-000-420-112. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:GhE8Fjp-QkoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:GhE8Fjp-QkoJ:scholar.google.com/+author:%22Jain+Sanjay%22+NUS&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="99">
    <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.88.1495&amp;rep=rep1&amp;type=pdf</url>
    <title status="complete" source="scholar.google.com">Some Results on U-shaped, Vacillatory and Team Learning</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.88.1495&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
    <year>2008</year>
    <source>Citeseer</source>
    <snippet status="partial" source="scholar.google.com">... unisi.it 2 Department of Computer and Information Sciences, University of Delaware, Newark,DE 19716-2586,USA Email: case@cis.udel.edu 3 School of Computing, 3 Science Drive 2,National University of Singapore, Singapore 117543 Email: sanjay@comp.nus.edu.sg 4 ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:mMyKHdGlAbYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:mMyKHdGlAbYJ:scholar.google.com/+author:%22Jain+Sanjay%22+NUS&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <numVersions>5</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=13114945907441978520&amp;hl=en&amp;num=100&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="100">
    <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.87.324&amp;rep=rep1&amp;type=pdf</url>
    <title status="complete" source="scholar.google.com">and Frank STEPHAN</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.87.324&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">L CARLUCCI, S JAIN, E KINBER</author>
    <year>2005</year>
    <source>Citeseer</source>
    <snippet status="partial" source="scholar.google.com">... Email addresses: carlucci5@unisi.it (Lorenzo Carlucci), sanjay@comp.nus.edu.sg (SanjayJain), kinbere@sacredheart.edu (Efim Kinber), fstephan@comp.nus.edu.sg (Frank Stephan). ...2 Supported in part by NUS grant number R252â000â127â112. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:zCZ2O2IclZIJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:zCZ2O2IclZIJ:scholar.google.com/+author:%22Jain+Sanjay%22+NUS&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <numVersions>4</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=10562379709297338060&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="101">
    <url>http://www.springerlink.com/index/3225687880N096U5.pdf</url>
    <title status="complete" source="scholar.google.com">Enlarging learnable classes</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/maximal.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, T KÃ¶tzing, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2012</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 Department of Computer Science, National University of Singapore, Singapore 117417,Republic of Singapore sanjay@comp.nus.edu.sg 2 Max-Planck-Institut fÃ¼r Informatik, CampusE 1 4, 66123 SaarbrÃ¼cken, Germany koetzing@mpi-inf.mpg.de 3 Department of Mathematics ...</snippet>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="102">
    <url>http://www.springerlink.com/index/8g7wr0478wk14071.pdf</url>
    <title status="complete" source="scholar.google.com">Invertible classes</title>
    <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1905/1/tr22-05.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, J Nessel, F Stephan</author>
    <proceeding status="partial" source="scholar.google.com">Theory and Applications of Models of &#8230;</proceeding>
    <year>2006</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 School of Computing, National University of Singapore, Republic of Singaporesanjay@comp.nus.edu.sg 2 College of Business Administration for Managers, Ho Chi Minh City,Vietnam ibea@gmx.de 3 Department of Mathematics, National University of Singapore, Republic ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:oYIrV-Ln2hcJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>25</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=1718941167106359969&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="103">
    <url>http://www.springerlink.com/index/V233X697X81081KW.pdf</url>
    <title status="complete" source="scholar.google.com">Automatic learning from positive data and negative counterexamples</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/autoncex.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2012</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... Sanjay Jain1,â and Efim Kinber2 1 School of Computing, National University of Singapore,Singapore 117417 sanjay@comp.nus.edu.sg 2 Department of Computer Science, Sacred HeartUniversity, Fairfield, CT 06825â1000, USA kinbere@sacredheart.edu Abstract. ...</snippet>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="104">
    <url>https://dl.comp.nus.edu.sg/dspace/handle/1900.100/1510</url>
    <title status="complete" source="scholar.google.com">U-shaped leaning may be necessary</title>
    <pdf>https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1510/1/upload.pdf</pdf>
    <author status="complete" source="scholar.google.com">C Lorenzo, C John, J Sanjay, S Frank</author>
    <year>2004</year>
    <source>dl.comp.nus.edu.sg</source>
    <snippet status="partial" source="scholar.google.com">... Email addresses: carlucci5@unisi.it (Lorenzo Carlucci), case@cis.udel.edu (John Case),sanjay@comp.nus.edu.sg (Sanjay Jain), fstephan@comp.nus.edu. sg (Frank Stephan). ...2 Supported in part by NUS grant number R252â000â127â112. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:aN5UGzEe8gMJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>9</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=284322922738540136&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="105">
    <url>http://www.springerlink.com/index/4enrcymnapyrp535.pdf</url>
    <title status="complete" source="scholar.google.com">Absolute versus probabilistic classification in a logical setting</title>
    <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1917/1/TRC3-06.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, E Martin, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2005</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 School of Computing, National University of Singapore, Singapore 117543, Republic ofSingapore sanjay@comp.nus.edu.sg 2 School of Computer Science and Engineering, TheUniversity of New South Wales, UNSW Sydney NSW 2052, Australia emartin@cse.unsw.edu. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:p540yMA9CCoJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>25</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=3028738647608565415&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="106">
    <url>http://www.springerlink.com/index/U07211K470R73N12.pdf</url>
    <title status="complete" source="scholar.google.com">Learning and classifying</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/classifylearn.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, E Martin, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2011</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 Department of Computer Science, National University of Singapore, Singapore 117417,Republic of Singapore sanjay@comp.nus.edu.sg 2 School of Computer Science and Engineering,The University of New South Wales, Sydney NSW 2052, Australia emartin@cse.unsw ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:dAVDyGPzGgMJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>18</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=223758741395408244&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="107">
    <url>https://dl.comp.nus.edu.sg/dspace/handle/1900.100/1447</url>
    <title status="complete" source="scholar.google.com">Learning Language from Positive Data and Finite Number of Queries</title>
    <author status="complete" source="scholar.google.com">J Sanjay, E KINBER</author>
    <year>2004</year>
    <source>dl.comp.nus.edu.sg</source>
    <snippet status="partial" source="scholar.google.com">... Back to NUS homepage. ...</snippet>
    <numVersions>2</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=2108210738637164572&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="108">
    <url>http://www.springerlink.com/index/8384J0WTU304212H.pdf</url>
    <title status="complete" source="scholar.google.com">Inductive inference of languages from samplings</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/subinc.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2010</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 School of Computing, National University of Singapore, Singapore 117417, Republic ofSingapore sanjay@comp.nus.edu.sg 2 Department of Computer Science, Sacred HeartUniversity, Fairfield, CT 06825-1000, USA kinbere@sacredheart.edu Abstract. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:u3qTQ0h3CqMJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>4</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=11748333730204449467&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="109">
    <url>http://www-test.comp.nus.edu.sg/~fstephan/krtlearn.ps</url>
    <title status="complete" source="scholar.google.com">Effectivity Questions for Kleene&#39;s Recursion Theorem</title>
    <pdf>http://www-test.comp.nus.edu.sg/~fstephan/krtlearn.ps</pdf>
    <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">www-test.comp.nus.edu.sg</proceeding>
    <snippet status="partial" source="scholar.google.com">... 1 Department of Computer and Information Sciences University of Delaware, Newark, DE19716-2586, USA case@cis.udel.edu 2 Department of Computer Science National Universityof Singapore, Singapore 117417 sanjay@comp.nus.edu.sg 3 Department of Mathematics ...</snippet>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:SQJ83x5mChcJ:scholar.google.com/+author:%22Jain+Sanjay%22+NUS&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="110">
    <url>https://www.comp.nus.edu.sg/~fstephan/union.ps</url>
    <title status="complete" source="scholar.google.com">Unionability and Extendability of Learnable Classes</title>
    <pdf>https://www.comp.nus.edu.sg/~fstephan/union.ps</pdf>
    <author status="complete" source="scholar.google.com">S Jain, T KÃ¶tzing, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">comp.nus.edu.sg</proceeding>
    <snippet status="partial" source="scholar.google.com">... 1 Department of Computer Science, National University of Singapore, Singapore 117543,Republic of Singapore sanjay@comp.nus.edu.sg 2 Max-Planck-Institut fÃ¼r Informatik, CampusE 1 4, 66123 SaarbrÃ¼cken, Germany koetzing@mpi-inf.mpg.de 3 Department of Mathematics ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:8him4J3YEhAJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:8him4J3YEhAJ:scholar.google.com/+author:%22Jain+Sanjay%22+NUS&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <numVersions>10</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=1158226226778085618&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="111">
    <url>http://www.springerlink.com/index/l5rax18a05jhx5br.pdf</url>
    <title status="complete" source="scholar.google.com">Learning all subfunctions of a function</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/subex.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen</author>
    <proceeding status="complete" source="scholar.google.com">Learning Theory and Kernel Machines</proceeding>
    <year>2003</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 School of Computing, National University of Singapore 3 Science Drive 2, Singapore 117543sanjay@comp.nus.edu.sg 2 Department of Computer Science, Sacred Heart University Fairfield,CT 06432-1000, USA kinbere@sacredheart.edu 3 Department of Computer Science ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:FXBRXtWXmCoJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>6</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=3069370088719216661&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="112">
    <url>http://www.springerlink.com/index/D891256047178X85.pdf</url>
    <title status="complete" source="scholar.google.com">Learning from streams</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.157.1225&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, F Stephan, N Ye</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>2009</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 Department of Computer Science, National University of Singapore, Singapore 117417,Republic of Singapore sanjay@comp.nus.edu.sg 2 Department of Computer Science andDepartment of Mathematics, National University of Singapore, Singapore 117417, Republic of ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:1jKd9b4XsWYJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>22</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=7399721771678380758&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="113">
    <url>http://www.springerlink.com/index/66PQ885G78N0K742.pdf</url>
    <title status="complete" source="scholar.google.com">Input-Dependence in Function-Learning</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/cie.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, E Martin, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Computation and Logic in the Real World</proceeding>
    <year>2007</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 Department of Computer Science, National University of Singapore, Singapore 117543,Republic of Singapore sanjay@comp.nus.edu.sg 2 Department of Computer Science andEngineering, The University of New South Wales, Sydney 2052, NSW, Commonwealth of ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:2SOO9izoryMJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>7</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=2571529192064558041&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="114">
    <url>http://www0.comp.nus.edu.sg/~fstephan/conservative.ps</url>
    <title status="complete" source="scholar.google.com">On Conservative Learning of Recursively Enumerable Languagesâ</title>
    <pdf>http://www0.comp.nus.edu.sg/~fstephan/conservative.ps</pdf>
    <author status="complete" source="scholar.google.com">Z Gao, S Jain, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">comp.nus.edu.sg</proceeding>
    <snippet status="partial" source="scholar.google.com">... 1 Department of Computer Science, University of Regina Regina, Saskatchewan, Canada S4S0A2 ziyuan84@yahoo.com 2 Department of Computer Science, National University of SingaporeSingapore 117417, Republic of Singapore sanjay@comp.nus.edu.sg and fstephan ...</snippet>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:DqnKt_JVh5gJ:scholar.google.com/+author:%22Jain+Sanjay%22+NUS&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="115">
    <url>http://www.springerlink.com/index/D2798548132P7V20.pdf</url>
    <title status="complete" source="scholar.google.com">Automatic functions, linear time and learning</title>
    <pdf>https://www.iscs.nus.edu.sg/~fstephan/autolintime.ps</pdf>
    <author status="complete" source="scholar.google.com">J Case, S Jain, S Seah, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">How the World Computes</proceeding>
    <year>2012</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... sanjay@comp.nus.edu.sg 3 Department of Mathematics, National University of Singapore,Singapore 119076, Republic of Singapore a0030907@nus.edu.sg, fstephan@comp.nus.edu.sg Abstract. ... The fourth author was supported in part by NUS grant R252-000-420-112. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:1rUoLH2c-KAJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>12</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=11599192901718422998&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="116">
    <url>http://dl.comp.nus.edu.sg/dspace/handle/1900.100/2317</url>
    <title status="complete" source="scholar.google.com">Consistent and Conservative Iterative Learning</title>
    <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2317/1/TRC3-07.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, S Lange, S ZILLES</author>
    <year>2007</year>
    <source>dl.comp.nus.edu.sg</source>
    <snippet status="partial" source="scholar.google.com">... corresponding author Email addresses: sanjay@comp.nus.edu.sg (Sanjay Jain),s.lange@fbi.h-da.de (Steffen Lange), sandra.zilles@dfki.de (Sandra Zilles). 1 Sanjay Jain wassupported in part by NUS grant number R252-000-127-112 and R252-000-212-112. 1 Page ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:g4a22neUaasJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>7</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=12351566695531710083&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="117">
    <url>http://www.springerlink.com/index/63mdygem6382h1gf.pdf</url>
    <title status="complete" source="scholar.google.com">Identifying clusters from positive data</title>
    <author status="partial" source="scholar.google.com">J Case, S Jain, E Martin, A Sharma&#8230;</author>
    <proceeding status="partial" source="scholar.google.com">&#8230; Inference: Algorithms and &#8230;</proceeding>
    <year>2004</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 Computer and Information Sciences Department, University of Delaware, Newark, DE19716-2586, United States of America case@cis.udel.edu 2 School of Computing, NationalUniversity of Singapore, Singapore 117543 {sanjay,fstephan}@comp.nus.edu.sg 3 School of ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:0HVe3V8fkkIJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>7</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=4796931049699309008&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="118">
    <url>http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTR/tcstr_12_55/tcstr_12_55.pdf</url>
    <title status="complete" source="scholar.google.com">TCS Technical Report</title>
    <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTR/tcstr_12_55/tcstr_12_55.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, F Stephan, T Zeugmann</author>
    <year>2012</year>
    <source>www-alg.ist.hokudai.ac.jp</source>
    <snippet status="partial" source="scholar.google.com">... National University of Singapore Singapore 117417 Republic of Singapore sanjay@comp.nus.edu.sg Frank Stephan ... Department of Mathematics National University of Singapore Singapore117417 fstephan@comp.nus.edu.sg Thomas Zeugmann Division of Computer Science ...</snippet>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:T08e7eABP1kJ:scholar.google.com/+author:%22Jain+Sanjay%22+NUS&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="119">
    <url>http://www.sciencedirect.com/science/article/pii/S0020019009001495</url>
    <title status="complete" source="scholar.google.com">On some open problems in monotonic and conservative learning</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.150.8724&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain</author>
    <proceeding status="complete" source="scholar.google.com">Information Processing Letters</proceeding>
    <year>2009</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... These indices are interpreted in E-mail address: sanjay@comp.nus.edu.sg. 1 Supported in partby NUS grant number R252-000-308-112. ... 1 Supported in part by NUS grant numberR252-000-308-112. Copyright Â© 2009 Elsevier BV All rights reserved. Bibliographic information. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:rLD1ZHEcOwMJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>7</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=232811079090417836&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="120">
    <url>http://www.tandfonline.com/doi/abs/10.1080/095281397147275</url>
    <title status="complete" source="scholar.google.com">Strong monotonic and set-driven inductive inference</title>
    <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1392/1/report.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain</author>
    <proceeding status="partial" source="scholar.google.com">Journal of Experimental &amp; Theoretical Artificial &#8230;</proceeding>
    <year>1997</year>
    <source>Taylor &amp; Francis</source>
    <snippet status="partial" source="scholar.google.com">Page 1. J. Ex pt . Th eor . Ar t if . In tell . 9(1997)137Â±143 Strong monotonic and set-driven inductiveinference SANJAY JAIN Department of Information Systems and Computer Science, NationalUniversity of Singapore, Singapore 119260 e-mail: sanjay! iscs.nus.sg Abstract. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:oUu_DHYm4S8J:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>9</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=3450081078004370337&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="121">
    <url>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6280459</url>
    <title status="complete" source="scholar.google.com">The Complexity of Verbal Languages over Groups</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/verbal.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, A Miasnikov, F Stephan</author>
    <proceeding status="partial" source="scholar.google.com">Logic in Computer Science ( &#8230;</proceeding>
    <year>2012</year>
    <source>ieeexplore.ieee.org</source>
    <snippet status="partial" source="scholar.google.com">Page 1. The Complexity of Verbal Languages over Groups Sanjay Jain Departmentof Computer Science National University of Singapore Singapore 117417 Email:sanjay@comp.nus.edu.sg Alexei Miasnikov Department of ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:WALgH4K5iXMJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>13</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=8325389354702733912&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="122">
    <url>http://www.sciencedirect.com/science/article/pii/S0304397512009322</url>
    <title status="complete" source="scholar.google.com">Learning without coding</title>
    <author status="complete" source="scholar.google.com">S Jain, SE Moelius III, S Zilles</author>
    <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
    <year>2012</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... fed elements drawn from {#} and from some unknown target language L Ã¢Å â  N, where N is theset of natural numbers, {0, 1, 2, ...}3 After being fed each such element, the learner outputs ahypothesis Ã¢Ëâcorresponding author Email addresses: sanjay@comp.nus.edu.sg ...</snippet>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="123">
    <url>https://dl.comp.nus.edu.sg/dspace/handle/1900.100/1367</url>
    <title status="complete" source="scholar.google.com">Kolmogorov Numberings and Minimal Identification</title>
    <pdf>https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1367/1/report.pdf</pdf>
    <author status="complete" source="scholar.google.com">F Rusins, J Sanjay</author>
    <year>1994</year>
    <source>dl.comp.nus.edu.sg</source>
    <snippet status="partial" source="scholar.google.com">... National University of Singapore Singapore 0511 Republic of Singapore Email:sanjay@iscs.nus.sg Abstract Identi cation of programs for computable functions from their graphsby algo- rithmic devices is a well studied problem in learning theory. Freivalds and Chen ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:bnNuMR6wxEwJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>3</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=5531739886042641262&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="124">
    <url>http://www.springerlink.com/index/P10132MM72722530.pdf</url>
    <title status="complete" source="scholar.google.com">Machine induction without revolutionary paradigm shifts</title>
    <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
    <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
    <year>1995</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... and Information Sciences, University of Delaware, Newark, DE 19716, USA, Email:case~cis.udel.edu 2 Department of Information Systems and Computer Science, NationalUniversity of Singapore, Singapore 0511, Republic of Singapore, Email: sanjay@iscs.nus.sg, ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:xSMXOf0nWRcJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>4</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=1682419904337617861&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="125">
    <url>http://www.sciencedirect.com/science/article/pii/S0304397509001674</url>
    <title status="complete" source="scholar.google.com">One-shot learners using negative counterexamples and nearest positive examples</title>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
    <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
    <year>2009</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... theconclusion. Correspondingauthor.Tel.:+6565167842;fax:+6567794580.E-mailaddresses:sanjay@comp.nus.edu.sg(S.Jain),kinbere@sacredheart.edu(E.Kinber). 0304-3975/$ seefrontmatter&#39;2009ElsevierB.V.Allrightsreserved. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:r9OMYh_KopUJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>6</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=10782402694024582063&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="126">
    <url>http://www.springerlink.com/index/f5135321112vt1h2.pdf</url>
    <title status="complete" source="scholar.google.com">Branch and bound on the network model</title>
    <author status="complete" source="scholar.google.com">S Jain</author>
    <proceeding status="partial" source="scholar.google.com">Foundations of Software Technology and Theoretical &#8230;</proceeding>
    <year>1995</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">Page 1. Branch and Bound on the Network Model Sanjay Jain 1 Department of InformationSystems and Computer Science Lower Kent Ridge Road National University of SingaporeSingapore 0511, Republic of Singapore Emaih sanjay@iscs.nus.sg Abstract. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:k5z2ZUBdz1UJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>4</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=6183263344572931219&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="127">
    <url>http://cs5824.userapi.com/u11728334/docs/e94a06839701/Hiroki_Arimura_Algorithmic_Learning_Theory_11_c.pdf</url>
    <title status="complete" source="scholar.google.com">Algorithmic learning theory</title>
    <pdf>http://cs5824.userapi.com/u11728334/docs/e94a06839701/Hiroki_Arimura_Algorithmic_Learning_Theory_11_c.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, HU Simon, E Tomita</author>
    <year>2005</year>
    <source>cs5824.userapi.com</source>
    <snippet status="partial" source="scholar.google.com">... E-mail: arim@ i. kyushu-u. ac. jp Sanjay Jain National University of Singapore, Schoolof Computing 3 Science Drive 2, Singapore 117543, Singapore E-mail: sanjay@comp. nus. edu. sg Arun Sharma The University of New ...</snippet>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:cQybcc99cNAJ:scholar.google.com/+author:%22Jain+Sanjay%22+NUS&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <numVersions>8</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=15019643087198293105&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="128">
    <url>http://www.springerlink.com/index/2TFVJ5FR0PY9BTGF.pdf</url>
    <title status="complete" source="scholar.google.com">Costs of general purpose learning</title>
    <pdf>http://pdf.aminer.org/000/620/043/costs_of_general_purpose_learning.pdf</pdf>
    <author status="complete" source="scholar.google.com">J Case, KJ Chen, S Jain</author>
    <proceeding status="complete" source="scholar.google.com">STACS 99</proceeding>
    <year>1999</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... of CIS University of Delaware Newark, DE 19716, USA case@cis.udel.edu 2 Institute forInformation Sciences Academica Sinica Taipei, 15, Taiwan Republic of China 3 School ofComputing National University of Singapore Singapore 119260 sanjay@comp.nus.edu.sg ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:mYn4ergsVsAJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>10</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=13859314074127993241&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="129">
    <url>http://www.sciencedirect.com/science/article/pii/S0890540103002657</url>
    <title status="complete" source="scholar.google.com">Classes with easily learnable subclasses</title>
    <pdf>http://www.math.uni-heidelberg.de/logic/postscripts/tr59.ps</pdf>
    <author status="complete" source="scholar.google.com">S Jain, W Menzel, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
    <year>2004</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... Intelligence, vol. 961, 1995, pp. 190â258. Corresponding Author Contact InformationCorresponding author. Fax: +65-6779-4580. 1 Sanjay Jain was supported in partby NUS Grant No. R252-000-127-112. 2 While previously ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:2l6PgklSSt8J:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>7</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=16089763094411042522&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="130">
    <url>http://www.comp.nus.edu.sg/~sanjay/paps/isolated.pdf</url>
    <title status="complete" source="scholar.google.com">On a question of nearly minimal identification of functions</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/isolated.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain</author>
    <proceeding status="complete" source="scholar.google.com">Information processing letters</proceeding>
    <year>1999</year>
    <source>comp.nus.edu.sg</source>
    <snippet status="partial" source="scholar.google.com">Page 1. On a Question of Nearly Minimal Identification of Functions Sanjay Jain Schoolof Computing National University of Singapore Singapore 119260 sanjay@comp.nus.edu.sg Abstract Suppose A and B are classes of recursive functions. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:yEb7lxSYYo4J:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:yEb7lxSYYo4J:scholar.google.com/+author:%22Jain+Sanjay%22+NUS&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <numVersions>10</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=10259930115320006344&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="131">
    <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.98.3940&amp;rep=rep1&amp;type=pdf</url>
    <title status="complete" source="scholar.google.com">Finite identification of functions by teams with success ratio</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.98.3940&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, A Sharma, M Velauthapillai</author>
    <year>2007</year>
    <source>Citeseer</source>
    <snippet status="partial" source="scholar.google.com">Finite identification of functions by teams with success ratio 1 2 and above Sanjay Jain Departmentof Information Systems and Computer Science National University of Singapore Lower Kent RidgeRoad, Singapore 0511 Republic of Singapore Email: sanjay@iscs.nus.sg ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:P24AmYe9XGQJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:P24AmYe9XGQJ:scholar.google.com/+author:%22Jain+Sanjay%22+NUS&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <numVersions>2</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=7231863491735350847&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="132">
    <url>http://www.worldscientific.com/doi/abs/10.1142/S0129054198000209</url>
    <title status="complete" source="scholar.google.com">Minimal Concept Identification and Reliability</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.3448&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain</author>
    <proceeding status="partial" source="scholar.google.com">International Journal of Foundations of Computer &#8230;</proceeding>
    <year>1998</year>
    <source>World Scientific</source>
    <snippet status="partial" source="scholar.google.com">... MINIMAL CONCEPT IDENTIFICATION AND RELIABILITY SANJAY JAIN Department ofInformation Systems and Computer Science National University of Singapore Singapore119260, Republic of Singapore Email: sanjay@iscs.nus.edu.sg ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:iCbXmd0phx4J:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>10</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=2199772974739302024&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="133">
    <url>http://www.sciencedirect.com/science/article/pii/S0020019008003104</url>
    <title status="complete" source="scholar.google.com">On some open problems in reflective inductive inference</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.150.8614&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain</author>
    <proceeding status="complete" source="scholar.google.com">Information Processing Letters</proceeding>
    <year>2009</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... Consistency is the requirement that each hypothesis conjectured by the learner, after seeinginput Ï, must con- tain the data in Ï [2,3,15,8]. It is known that consistency is E-mail address:sanjay@comp.nus.edu.sg. 1 Supported in part by NUS grant number R252-000-308-112. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:StJGq90VtMwJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>6</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=14750438721350718026&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="134">
    <url>http://books.google.com.sg/books?hl=en&amp;lr=&amp;id=0rAiPOK6S5gC&amp;oi=fnd&amp;pg=PR1&amp;dq=%22Jain+Sanjay%22+NUS&amp;ots=A-KLblkucr&amp;sig=2WYcJ9uK9x2awYHc6gbdkgD9bOk</url>
    <title status="complete" source="scholar.google.com">Algorithmic Learning Theory: 11th International Conference, ALT 2000 Sydney, Australia, December 11-13, 2000 Proceedings</title>
    <author status="complete" source="scholar.google.com">H Arimura, S Jain, A Sharma</author>
    <year>2000</year>
    <source>books.google.com</source>
    <snippet status="partial" source="scholar.google.com">... E-mail: arim@ i. kyushu-u. ac. jp Sanjay Jain National University of Singapore, Schoolof Computing 3 Science Drive 2, Singapore 117543, Singapore E-mail: sanjay@comp. nus. edu. sg Arun Sharma The University of New ...</snippet>
    <numVersions>3</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=8366415245540386701&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="135">
    <url>http://dl.comp.nus.edu.sg/dspace/handle/1900.100/1400</url>
    <title status="complete" source="scholar.google.com">On intrinsic complexity of learning geometrical concepts from texts</title>
    <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1400/1/report.pdf</pdf>
    <author status="complete" source="scholar.google.com">J Sanjay, E KINBER</author>
    <year>1999</year>
    <source>dl.comp.nus.edu.sg</source>
    <snippet status="partial" source="scholar.google.com">... texts Sanjay Jain School of Computing National University of Singapore Singapore 119260sanjay@comp.nus.edu.sg Efim Kinber Department of Computer Science Sacred Heart UniversityFairfield, CT 06432-1000 USA kinbere@sacredheart.edu June 10, 1999 1 Introduction ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:DAWdzjlgDVIJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>2</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=5912487687203128588&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="136">
    <url>http://www.springerlink.com/index/R244418312565362.pdf</url>
    <title status="complete" source="scholar.google.com">On the amount of nonconstructivity in learning formal languages from positive data</title>
    <author status="complete" source="scholar.google.com">S Jain, F Stephan, T Zeugmann</author>
    <proceeding status="partial" source="scholar.google.com">Theory and Applications of Models of &#8230;</proceeding>
    <year>2012</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 Department of Computer Science National University of Singapore, Singapore 117417sanjay@comp.nus.edu.sg 2 Department of Computer Science and Department of MathematicsNational University of Singapore, Singapore 117543 fstephan@comp.nus.edu.sg 3 Division ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:PTqhzkyLOnIJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>3</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=8231044430973450813&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="137">
    <url>https://dl.comp.nus.edu.sg/dspace/handle/1900.100/1366</url>
    <title status="complete" source="scholar.google.com">An Infinite Class of Functions Identifiable Using Minimal Programs in all Kolmogorov Numberings</title>
    <pdf>https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1366/1/report.pdf</pdf>
    <author status="complete" source="scholar.google.com">J Sanjay</author>
    <year>1994</year>
    <source>dl.comp.nus.edu.sg</source>
    <snippet status="partial" source="scholar.google.com">... National University of Singapore Lower Kent Ridge Rd Singapore 0511 Republic of SingaporeEmail: sanjay@iscs.nus.sg Abstract Identi cation of programs for computable functions from theirgraphs by algo- rithmic devices is a well studied problem in learning theory. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:5Zov-saALFAJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>2</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=5777134014098807525&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="138">
    <url>http://www.sciencedirect.com/science/article/pii/S0890540198927821</url>
    <title status="complete" source="scholar.google.com">The synthesis of language learners</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.2144&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">GR Baliga, J Case, S Jain</author>
    <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
    <year>1999</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... 155â173. f1 E-mail: baliga@gboro.rowan.edu. f2 E-mail: case@cis.udel.edu. f3 E-mail:sanjay@comp.nus.edu.sg. Copyright Â© 1999 Academic Press. All rights reserved. Informationand Computation Volume 152, Issue 1, 10 June 1999, Pages 16-43. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:Bgc6-PuulWUJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>11</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=7319949166585186054&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>28</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=7319949166585186054&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="28">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397508001503</url>
        <title status="complete" source="scholar.google.com">Learning indexed families of recursive languages from positive data: A survey</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/tcs08lzz.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, T Zeugmann, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In the past 40 years, research on inductive inference has developed along different lines, eg, in the formalizations used, and in the classes of target concepts considered. One common root of many of these formalizations is Gold&#39;s model of identification in the limit. This model ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:kHdpMOKBOpwJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11257453027040786320&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>39</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11257453027040786320&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397505006444</url>
        <title status="complete" source="scholar.google.com">A non-learnable class of E-pattern languages</title>
        <pdf>https://dspace.lboro.ac.uk/dspace/bitstream/2134/3463/1/tcs_reidenbach.pdf</pdf>
        <author status="complete" source="scholar.google.com">D Reidenbach</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2006</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We investigate the inferrability of E-pattern languages (also known as extended or erasing pattern languages) from positive data in Gold&#39;s learning model. As the main result, our analysis yields a negative outcome for the full class of E-pattern languagesâand even for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:DsWJFuI5WG8J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8023226379364058382&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>30</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8023226379364058382&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397508001497</url>
        <title status="complete" source="scholar.google.com">Discontinuities in pattern inference</title>
        <pdf>https://dspace.lboro.ac.uk/dspace/bitstream/2134/3469/3/Reidenbach_TCS_Discontinuities_Pattern_Inference.pdf</pdf>
        <author status="complete" source="scholar.google.com">D Reidenbach</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper deals with the inferrability of classes of E-pattern languagesâalso referred to as extended or erasing pattern languagesâfrom positive data in Gold&#39;s model of identification in the limit. The first main part of the paper shows that the recently presented negative result ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:j-9N_GCa18kJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14544263262956810127&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>24</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14544263262956810127&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/NYRGBXAELWDDY9C7.pdf</url>
        <title status="complete" source="scholar.google.com">A negative result on inductive inference of extended pattern languages</title>
        <pdf>https://dspace.lboro.ac.uk/dspace-jspui/bitstream/2134/3471/1/reidenbach_alt02.pdf</pdf>
        <author status="complete" source="scholar.google.com">D Reidenbach</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2002</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The question of learnability of the class of extended pattern languages is considered to be one of the eldest and outstanding open problems in inductive inference of formal languages. This paper provides an appropriate answer presenting a subclass-the terminal-free ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:yBulyWkO2EwJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5537191589369420744&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>23</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5537191589369420744&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/8qe12am4l99c98f1.pdf</url>
        <title status="complete" source="scholar.google.com">Replacing limit learners with equally powerful one-shot query learners</title>
        <pdf>http://pdf.aminer.org/000/109/104/replacing_limit_learners_with_equally_powerful_one_shot_query_learners.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2004</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Different formal learning models address different aspects of human learning. Below we compare Gold-style learningâinterpreting learning as a limiting process in which the learner may change its mind arbitrarily often before converging to a correct hypothesisâto ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RELpoe9ZeCUJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2700006862357086788&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>18</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2700006862357086788&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.springerlink.com/index/N884MNE4CUJH830Q.pdf</url>
        <title status="complete" source="scholar.google.com">Comparison of query learning and Gold-style learning in dependence of the hypothesis space</title>
        <pdf>http://webdocs.cs.ualberta.ca/~zilles/langeZ04ALTqueries.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2004</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Different formal learning models address different aspects of learning. Below we compare learning via queriesâinterpreting learning as a one-shot process in which the learner is required to identify the target concept with just one hypothesisâto Gold-style learningâ ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:48VonLqHnMcJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14383520545472300515&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>17</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14383520545472300515&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540105001379</url>
        <title status="complete" source="scholar.google.com">Relations between Gold-style learning and query learning</title>
        <pdf>http://www2.cs.uregina.ca/~zilles/langeZ05queries.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2005</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Different formal learning models address different aspects of human learning. Below we compare Gold-style learningâmodelling learning as a limiting process in which the learner may change its mind arbitrarily often before converging to a correct hypothesisâto ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:rNC7VkEdryUJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2715421266792927404&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>15</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2715421266792927404&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540106000253</url>
        <title status="complete" source="scholar.google.com">Mind change efficient learning</title>
        <pdf>http://mind-change-bayes-net.googlecode.com/svn/branches/mclc.pdf</pdf>
        <author status="complete" source="scholar.google.com">W Luo, O Schulte</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2006</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper studies efficient learning with respect to mind changes. Our starting point is the idea that a learner that is efficient with respect to mind changes minimizes mind changes not only globally in the entire learning problem, but also locally in subproblems after receiving ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Nc6YcK5juMUJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14247247022051085877&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14247247022051085877&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.springerlink.com/index/BN4WUBDWE0233BPV.pdf</url>
        <title status="complete" source="scholar.google.com">Synthesizing learners tolerating computable noisy data</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/nrec.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1998</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">An index for an re class of languages (by definition) generates a sequence of grammars defining the class. An index for an indexed family of languages (by definition) generates a sequence of decision procedures defining the family. F. Stephan&#39;s model of noisy data is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:NQuQP4PCMXcJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8588859833335155509&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>10</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8588859833335155509&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.sciencedirect.com/science/article/pii/S030439750300611X</url>
        <title status="complete" source="scholar.google.com">Separation of uniform learning classes</title>
        <author status="complete" source="scholar.google.com">S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Within the scope of inductive inference a recursion theoretic approach is used to model learning behaviour. The fundamental model considered is Gold&#39;s identification of recursive functions in the limit. Modifying the corresponding definition has proposed several ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:_GkVxdVyPRgJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1746678492949735932&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1746678492949735932&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www.springerlink.com/index/lwppl43dfva4ulg5.pdf</url>
        <title status="complete" source="scholar.google.com">Mind change efficient learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.72.7998&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">W Luo, O Schulte</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper studies efficient learning with respect to mind changes. Our starting point is the idea that a learner that is efficient with respect to mind changes minimizes mind changes not only globally in the entire learning problem, but also locally in subproblems after receiving ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Tr_ZFZkwJUUJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4982441996810043214&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4982441996810043214&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://www.tandfonline.com/doi/abs/10.1080/09528130119716</url>
        <title status="complete" source="scholar.google.com">On the role of search for learning from examples</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.36.230&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">SA Kurtz, CH Smith, R Wiehagen</author>
        <proceeding status="partial" source="scholar.google.com">Journal of Experimental &amp; &#8230;</proceeding>
        <year>2001</year>
        <source>Taylor &amp; Francis</source>
        <snippet status="partial" source="scholar.google.com">Gold (1967) discovered a fundamental enumeration technique, the socalled identification-by-enumeration, a simple but powerful class of algorithms for learning from examples (inductive inference). We introduce a variety of more sophisticated (and more powerful) enumeration ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:7826UNEm518J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6910534833667755503&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6910534833667755503&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000004001308</url>
        <title status="complete" source="scholar.google.com">Increasing the power of uniform inductive learners</title>
        <pdf>http://webdocs.cs.ualberta.ca/~zilles/zilles05increasing.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2005</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The analysis of theoretical learning models is basically concerned with the comparison of identification capabilities in different models. Modifications of the formal constraints affect the quality of the corresponding learners on the one hand and regulate the quantity of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:7Fxc7yuFFUMJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4833916198797991148&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4833916198797991148&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="13">
        <url>http://www.springerlink.com/index/l5p6329uk2633r03.pdf</url>
        <title status="complete" source="scholar.google.com">Directions for computability theory beyond pure mathematical</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/rft-directions.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Mathematical problems from applied logic II</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper begins by briefly indicating the principal, non-standard motivations of the author for his decades of work in Computability Theory (CT), aka Recursive Function Theory. Then it discusses its proposed, general directions beyond those from pure mathematics for CT. These ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:BWKg2uLmRxMJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1389332872072028677&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1389332872072028677&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="14">
        <url>http://www.springerlink.com/index/uhq0emr1dtqgjrkx.pdf</url>
        <title status="complete" source="scholar.google.com">Learning recursive concepts with anomalies</title>
        <pdf>http://cs5824.userapi.com/u11728334/docs/a70c63d88f80/Hiroki_Arimura_Algorithmic_Learning_Theory_11_c.pdf#page=111</pdf>
        <author status="complete" source="scholar.google.com">G Grieser, S Lange, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper provides a systematic study of inductive inference of indexable concept classes in learning scenarios in which the learner is successful if its final hypothesis describes a finite variant of the target concept-henceforth called learning with anomalies. As usual, we ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:aWrK9G-Cpf4J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>17</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18349215674150840937&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18349215674150840937&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="15">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000000917367</url>
        <title status="complete" source="scholar.google.com">Synthesizing learners tolerating computable noisy data</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">An index for an re class of languages (by definition) generates a sequence of grammars defining the class. An index for an indexed family of recursive languages (by definition) generates a sequence of decision procedures defining the family. F. Stephan&#39;s model of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:I11qjU5RhmMJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7171508854455950627&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7171508854455950627&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="16">
        <url>http://www.springerlink.com/index/u3ut0lt1eh93eh77.pdf</url>
        <title status="complete" source="scholar.google.com">Merging uniform inductive learners</title>
        <pdf>http://cs5824.userapi.com/u11728334/docs/31019397c5f8/Jyrki_Kivinen_Computational_Learning_Theory_15.pdf#page=213</pdf>
        <author status="complete" source="scholar.google.com">S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
        <year>2002</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The fundamental learning model considered here is identification of recursive functions in the limit as introduced by Gold [8], but the concept is investigated on a meta-level. A set of classes of recursive functions is uniformly learnable under an inference criterion I, if there ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:LstjBzIqX7UJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13069211038013180718&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13069211038013180718&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="17">
        <url>http://www.springerlink.com/index/QCKQQRTHHQ5K217C.pdf</url>
        <title status="complete" source="scholar.google.com">Intrinsic complexity of uniform learning</title>
        <pdf>http://webdocs.cs.ualberta.ca/~zilles/zilles03uniform.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2003</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Inductive inference is concerned with algorithmic learning of recursive functions. In the model of learning in the limit a learner successful for a class of recursive functions must eventually find a program for any function in the class from a gradually growing sequence ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:HMm4NBIPwV4J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6827755080938735900&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6827755080938735900&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="18">
        <url>ftp://142.58.111.31/fas-info/ftp/ftp/pub/cs/theses/2007/WeiLuoPhD.pdf</url>
        <title status="complete" source="scholar.google.com">Mind change optimal learning: theory and applications</title>
        <pdf>ftp://142.58.111.31/fas-info/ftp/ftp/pub/cs/theses/2007/WeiLuoPhD.pdf</pdf>
        <author status="complete" source="scholar.google.com">W Luo</author>
        <year>2007</year>
        <source>142.58.111.31</source>
        <snippet status="partial" source="scholar.google.com">Abstract Learning theories play a significant role to machine learning as computability and complexity theories to software engineering. Gold&#39;s language learning paradigm is one cornerstone of modern learning theories. The aim of this thesis is to establish an inductive ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:AdqaxUFSDqAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:AdqaxUFSDqAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>34</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11533246138184030721&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11533246138184030721&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="19">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397506004890</url>
        <title status="complete" source="scholar.google.com">An approach to intrinsic complexity of uniform learning</title>
        <pdf>http://www2.cs.uregina.ca/~zilles/zilles06intrinsic.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2006</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Inductive inference is concerned with algorithmic learning of recursive functions. In the model of learning in the limit a learner successful for a class of recursive functions must eventually find a program for any function in the class from a gradually growing sequence ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:-afF2fspAVQJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6053165535829796857&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6053165535829796857&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="20">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397505005220</url>
        <title status="complete" source="scholar.google.com">Inductive inference of approximations for recursive concepts</title>
        <pdf>http://eprints.lib.hokudai.ac.jp/dspace/bitstream/2115/17147/1/TCS348-1.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, G Grieser, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2005</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper provides a systematic study of inductive inference of indexable concept classes in learning scenarios where the learner is successful if its final hypothesis describes a finite variant of the target concept, ie, learning with anomalies. Learning from positive data only ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:f-x_hcXi3wMJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=279191039896448127&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="21">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.98.2477&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Inductive inference of approximations for recursive</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.98.2477&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Langea, G Grieserb, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper provides a systematic study of inductive inference of indexable concept classes in learning scenarios where the learner is successful if its final hypothesis describes a finite variant of the target concept, ie, learning with anomalies. Learning from positive ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MWKAkpxb010J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="22">
        <url>http://www.springerlink.com/index/U2V8151P2N16110H.pdf</url>
        <title status="complete" source="scholar.google.com">Learnability of co-re classes</title>
        <pdf>http://www.comp.nus.edu.sg/~fstephan/corelearn.ps</pdf>
        <author status="complete" source="scholar.google.com">Z Gao, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Language and Automata Theory and Applications</proceeding>
        <year>2012</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The object of investigation in this paper is the learnability of co-recursively enumerable (co-re) languages based on Gold&#39;s [11] original model of inductive inference. In particular, the following learning models are studied: finite learning, explanatory learning, vacillatory ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:aenPm2LFsxAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1203522552749615465&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="23">
        <url>http://scholarbank.nus.edu/handle/10635/34660</url>
        <title status="complete" source="scholar.google.com">Variants of Partial Learning in Inductive Inference</title>
        <pdf>http://scholarbank.nus.edu/bitstream/handle/10635/34660/test.pdf?sequence=1</pdf>
        <author status="complete" source="scholar.google.com">GAO ZIYUAN</author>
        <year>2012</year>
        <source>scholarbank.nus.edu</source>
        <snippet status="partial" source="scholar.google.com">This thesis studies several variants of partial learning under the framework of inductive inference. In particular, the following learning criteria are examined: con fident partial learning, partially conservative learning, essentially class consistent partial learning, and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:82yGne6LC9AJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14991229641594137843&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="24">
        <url>http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTR/tcstr_07_31/tcstr_07_31.pdf</url>
        <title status="complete" source="scholar.google.com">TCS Technical Report</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTR/tcstr_07_31/tcstr_07_31.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, T Zeugmann, S Zilles</author>
        <year>2007</year>
        <source>www-alg.ist.hokudai.ac.jp</source>
        <snippet status="partial" source="scholar.google.com">Abstract In the past 40 years, research on inductive inference has developed along different lines, concerning different formalizations of learning models and in particular of target concepts for learning. One common root of many of these is Gold&#39;s model of identification ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:uMhVpfJ4388J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:uMhVpfJ4388J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14978823869208840376&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="25">
        <url>http://www2.cs.uregina.ca/~zilles/langeZ05algorithmic.pdf</url>
        <title status="complete" source="scholar.google.com">Algorithmic Learning: Formal models and prototypical applications</title>
        <pdf>http://www2.cs.uregina.ca/~zilles/langeZ05algorithmic.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Proceedings of Leipziger Informatiktage</proceeding>
        <year>2005</year>
        <source>cs.uregina.ca</source>
        <snippet status="partial" source="scholar.google.com">Abstract: The vision of assistance systems is to use machines not merely as tools but as intelligent assistants with which humans can solve their tasks cooperatively. The approach considered below is to enhance the required machine-human interaction by machine ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:pYmurl745-gJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:pYmurl745-gJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16782655621960731045&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="26">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.26.7011&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">SIIM Technical Report</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.26.7011&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, G Grieser, T Zeugmann</author>
        <year>2001</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper provides a systematic study of inductive inference of indexable concept classes in learning scenarios where the learner is successful if its nal hypothesis describes a nite variant of the target concept, ie, learning with anomalies. Learning from positive ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:XFunvZj2iAQJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:XFunvZj2iAQJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=326782108861684572&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="27">
        <url>http://www.springerlink.com/index/D891256047178X85.pdf</url>
        <title status="complete" source="scholar.google.com">Learning from streams</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.157.1225&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan, N Ye</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Learning from streams is a process in which a group of learners separately obtain information about the target to be learned, but they can communicate with each other in order to learn the target. We are interested in machine models for learning from streams ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1jKd9b4XsWYJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>22</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7399721771678380758&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="139">
    <url>http://www.springerlink.com/index/80x7h9xc6ju9crv4.pdf</url>
    <title status="complete" source="scholar.google.com">Intrinsic complexity of learning geometrical concepts from positive data</title>
    <pdf>http://cs5824.userapi.com/u11728334/docs/be3e0641bab1/David_Helmbold_Computational_Learning_Theory_14.pdf#page=185</pdf>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
    <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
    <year>2001</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... Sanjay Jain â1 and Efim Kinber ââ2 1 School of Computing, National University of Singapore,Singapore 119260. sanjay@comp.nus.edu.sg 2 Department of Computer Science, Sacred HeartUniversity, Fairfield, CT 06432-1000, USA kinbere@sacredheart.edu Abstract. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:UVtfeQ_guscJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>9</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=14392061916281264977&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=14392061916281264977&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397506004890</url>
        <title status="complete" source="scholar.google.com">An approach to intrinsic complexity of uniform learning</title>
        <pdf>http://www2.cs.uregina.ca/~zilles/zilles06intrinsic.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2006</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Inductive inference is concerned with algorithmic learning of recursive functions. In the model of learning in the limit a learner successful for a class of recursive functions must eventually find a program for any function in the class from a gradually growing sequence ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:-afF2fspAVQJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6053165535829796857&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6053165535829796857&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=1</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="140">
    <url>http://www.sciencedirect.com/science/article/pii/S0304397506004932</url>
    <title status="complete" source="scholar.google.com">Learning a subclass of regular patterns in polynomial time</title>
    <pdf>http://eprints2008.lib.hokudai.ac.jp/dspace/bitstream/2115/17138/1/TCS364-1-115.pdf</pdf>
    <author status="partial" source="scholar.google.com">J Case, S Jain, R Reischuk, F Stephan&#8230;</author>
    <proceeding status="partial" source="scholar.google.com">Theoretical computer &#8230;</proceeding>
    <year>2006</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... E-mail addresses: case@cis.udel.edu (J. Case), sanjay@comp.nus.edu.sg (S. Jain),reischuk@tcs.uni-luebeck.de (R. Reischuk), fstephan@comp.nus.edu.sg (F. Stephan),thomas@ist.hokudai.ac.jp (T. Zeugmann). ... 2 Supported in part by NUS Grant number R252-000- ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:l0-OdtlbjkwJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>15</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=5516447583130505111&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>3</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=5516447583130505111&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="3">
        <result id="0">
        <url>http://www.tesisenred.net/bitstream/handle/10803/8792/Thesis.pdf</url>
        <title status="complete" source="scholar.google.com">Language Learning with Correction Queries</title>
        <pdf>http://www.tesisenred.net/bitstream/handle/10803/8792/Thesis.pdf</pdf>
        <author status="complete" source="scholar.google.com">C TËÄ±rnauca</author>
        <year>2009</year>
        <source>tesisenred.net</source>
        <snippet status="partial" source="scholar.google.com">I would not be here today if it was not for my dear friend and colleague Mihai Ionescu, who persuaded me to continue my studies and to enroll in a PhD program in Tarragona. Also, I would like to address my gratitude to my mother, first of all, for raising me the way she did, ...</snippet>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:kvw1EEn1D8AJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13839549874086214802&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540112001137</url>
        <title status="complete" source="scholar.google.com">Automatic learning of subclasses of pattern languages</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/autopat.pdf</pdf>
        <author status="partial" source="scholar.google.com">J Case, S Jain, TD Le, YS Ong, P Semukhin&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Information and &#8230;</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Automatic classes are classes of languages for which a finite automaton can decide the membership problem for the languages in the class, in a uniform way, given an index for the language. For alphabet size of at least 4, every automatic class of erasing pattern ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:h4T-C1MLkHMJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>17</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8327168162319467655&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8327168162319467655&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.tdx.cat/handle/10803/8792</url>
        <title status="complete" source="scholar.google.com">Language learning with correction queries</title>
        <pdf>http://www.tdx.cat/bitstream/handle/10803/8792/Thesis.pdf.txt?sequence=2</pdf>
        <author status="complete" source="scholar.google.com">C Tirnauca</author>
        <year>2009</year>
        <source>tdx.cat</source>
        <snippet status="partial" source="scholar.google.com">In the field of grammatical inference, the goal of any learning algorithm is to identify a target concept from a given class by having access to a specific type of information. The main learning settings are Gold&#39;s model of learning in the limit and Angluin&#39;s query learning. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:vPYbLipk9tIJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15201447724560676540&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15201447724560676540&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="141">
    <url>http://www.comp.nus.edu.sg/~sanjay/paps/robsur-c.pdf</url>
    <title status="complete" source="scholar.google.com">A Survey of Robust Learning</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/robsur-c.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain</author>
    <year>2008</year>
    <source>comp.nus.edu.sg</source>
    <snippet status="partial" source="scholar.google.com">Page 1. A Survey of Robust Learning Sanjay Jain1 School of Computing National Universityof Singapore Singapore 119260 sanjay@comp.nus.edu.sg Abstract. ... 8 AcknowledgementsSanjay Jain was supported in part by NUS grant number RP3992710. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:td7IYjEIaMwJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:td7IYjEIaMwJ:scholar.google.com/+author:%22Jain+Sanjay%22+NUS&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <numVersions>6</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=14729031589518958261&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="142">
    <url>http://dml.cz/bitstream/handle/10338.dmlcz/124505/Kybernetika_30-1994-1_2.pdf</url>
    <title status="complete" source="scholar.google.com">Refinements of inductive inference by Popperian and reliable machines</title>
    <pdf>http://dml.cz/bitstream/handle/10338.dmlcz/124505/Kybernetika_30-1994-1_2.pdf</pdf>
    <author status="complete" source="scholar.google.com">J Case, S Jain, S Ngo Manguelle</author>
    <proceeding status="complete" source="scholar.google.com">Kybernetika</proceeding>
    <year>1994</year>
    <source>dml.cz</source>
    <snippet status="partial" source="scholar.google.com">Page 1. Kybernetika John Case; Sanjay Jain; Suzanne Ngo Manguelle Refinements ofinductive inference by Popperian and reliable machines Kybernetika, Vol. 30 (1994), No.1, 23--52 Persistent URL: http://dml.cz/dmlcz/124505 Terms of use: ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:PRizLZZ6kAUJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:PRizLZZ6kAUJ:scholar.google.com/+author:%22Jain+Sanjay%22+NUS&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <numVersions>9</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=400955152266369085&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>45</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=400955152266369085&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="45">
        <result id="0">
        <url>http://dl.acm.org/citation.cfm?id=130426</url>
        <title status="complete" source="scholar.google.com">On the role of procrastination for machine learning</title>
        <author status="complete" source="scholar.google.com">R Freivalds, CH Smith</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the fifth annual workshop on &#8230;</proceeding>
        <year>1992</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">While procrastination is generally regarded as an undesirable quality, this paper points out a potential advantage to some uses of procrastination. Working with a formal model of machine learning we show that machines that procrastinate about how many learning ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:w1wR6hm3dGMJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7166554228982373571&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>102</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7166554228982373571&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=StUzu3bjlEIC&amp;oi=fnd&amp;pg=PR1&amp;ots=x4bgN1BDsl&amp;sig=4F9-v-S0d8tihBOthZGJ2_C6zMY</url>
        <title status="complete" source="scholar.google.com">Elements of scientific inquiry</title>
        <author status="complete" source="scholar.google.com">E Martin, DN Osherson</author>
        <year>1998</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">One influential view of science focuses on the credibility that scientists attach to alternative theories and on the evolution of these credibilities under the impact of data. Interpreting credibility as probability leads to the Bayesian analysis of inquiry, which has helped us to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:5uRXANb3dl4J:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6806900385317905638&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>96</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6806900385317905638&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://epubs.siam.org/doi/pdf/10.1137/S0097539793249694</url>
        <title status="complete" source="scholar.google.com">The power of vacillation in language learning</title>
        <pdf>http://dare.uva.nl/document/1137</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">SIAM Journal on Computing</proceeding>
        <year>1999</year>
        <source>SIAM</source>
        <snippet status="partial" source="scholar.google.com">Some extensions are considered of Gold&#39;s influential model of language learning by machine from positive data. Studied are criteria of successful learning featuring convergence in the limit to vacillation between several alternative correct grammars. The ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:iB0Rc-7Qrq0J:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>23</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12515170137060482440&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>82</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12515170137060482440&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://dl.acm.org/citation.cfm?id=146670</url>
        <title status="complete" source="scholar.google.com">Learning via queries</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.33.5985&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">WI Gasarch, CH Smith</author>
        <proceeding status="complete" source="scholar.google.com">Journal of the ACM (JACM)</proceeding>
        <year>1992</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Traditional work in inductive inference has been to model a learner receiving data about a function f and trying to learn the function. The data is usually just the values f (0), f (1),â¦. The scenario is modeled so that the learner is also allowed to ask questions about ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:-Ioa5u2vvaYJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>19</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12014952817196960504&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>77</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12014952817196960504&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.tandfonline.com/doi/abs/10.1080/09528139408953778</url>
        <title status="complete" source="scholar.google.com">Infinitary self-reference in learning theory</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.47.5822&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="partial" source="scholar.google.com">Journal of Experimental &amp; Theoretical Artificial &#8230;</proceeding>
        <year>1994</year>
        <source>Taylor &amp; Francis</source>
        <snippet status="partial" source="scholar.google.com">Abstract Kleene&#39;s second recursion theorem provides a means for transforming any program p into a program e (p) which first creates a quiescent self-copy and then runs p on that self-copy together with any externally given input. e (p), in effect, has complete (low level), self- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:W3Ho86D-EPAJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17298606135970394459&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>47</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17298606135970394459&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://dl.acm.org/citation.cfm?id=227685</url>
        <title status="complete" source="scholar.google.com">On the impact of forgetting on learning machines</title>
        <author status="complete" source="scholar.google.com">R Freivalds, E Kinber, CH Smith</author>
        <proceeding status="complete" source="scholar.google.com">Journal of the ACM (JACM)</proceeding>
        <year>1995</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract. People tend not to have perfect memories when it comesto learning, or to anything else for that matter. Most formal studies of learning, however, assume a perfect memory. Some approaches have restricted the number of items that could be retained. We ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:C51qYEFEaxkJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1831632721037401355&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>35</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1831632721037401355&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.sciencedirect.com/science/article/pii/0890540189900059</url>
        <title status="complete" source="scholar.google.com">Trade-off among parameters affecting inductive inference</title>
        <author status="complete" source="scholar.google.com">R Freivalds, CH Smith, M Velauthapillai</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>1989</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper is concerned with the algorithmic learning, by example in the limit, of programs that compute recursive functions. The particular focus is on the relationship of three parameters that effect inferribility: the number of experimental trials, the plurality of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:E8fRF4ctoDcJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4008253726603200275&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>29</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4008253726603200275&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/dhnm8ddvum0w11lk.pdf</url>
        <title status="complete" source="scholar.google.com">Supporting increment and decrement operations in balancing networks</title>
        <pdf>http://bit.csc.lsu.edu/~busch/papers/journal/2000-CJTCS-antitokens.pdf</pdf>
        <author status="partial" source="scholar.google.com">W Aiello, C Busch, M Herlihy, M Mavronicolas, N Shavit&#8230;</author>
        <proceeding status="complete" source="scholar.google.com">STACS 99</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Counting networks are a class of distributed data structures that support highly concurrent implementations of shared Fetch&amp;Increment counters. Applications of these counters include shared pools and stacks, load balancing, and software barriers [4, 12, 13, 18]. A ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:AD1qFSokE5gJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>24</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10958142081489059072&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>18</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10958142081489059072&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://dl.acm.org/citation.cfm?id=93369</url>
        <title status="complete" source="scholar.google.com">On the role of search for learning</title>
        <author status="complete" source="scholar.google.com">SA Kurtz, CH Smith</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the second annual workshop on &#8230;</proceeding>
        <year>1989</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Google, Inc. (search). ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:l0ESapfD5FAJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5828998872811323799&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>18</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5828998872811323799&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://dl.acm.org/citation.cfm?id=168326</url>
        <title status="complete" source="scholar.google.com">On the impact of forgetting on learning machines</title>
        <author status="complete" source="scholar.google.com">R Freivalds, E Kinber, CH Smith</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; of the sixth annual conference on &#8230;</proceeding>
        <year>1993</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Various aspects of machine learning have been under empirical investigation for quite some time[MCM 83, Sha87]. More recently, theoretical studies have become popular[HP88, RHW89, FC90, WV91, COL! 12]. The research described in this paper contributes t~ ward ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:H3V4QsJJNPQJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17596770742731044127&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>15</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17596770742731044127&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www.springerlink.com/index/najyku8tm4xhhpdl.pdf</url>
        <title status="complete" source="scholar.google.com">Learning with refutation</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.137.7727&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1998</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In their pioneering work, Mukouchi and Arikawa modeled a learning situation in which the learner is expected to refute texts which are not representative of L, the class of languages being identified. Lange and Watson extended this model to consider justified refutation in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:L2zSWvne_uYJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>19</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16644986435359894575&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>15</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16644986435359894575&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://www.springerlink.com/index/78867137810P8066.pdf</url>
        <title status="complete" source="scholar.google.com">Learning with higher order additional information</title>
        <author status="complete" source="scholar.google.com">G Baliga, J Case</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1994</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">[Go167] studied, among other things, algorithmic learning (in the limit) of deci- sion procedures for languages given informants, ie, given enumerations of the characteristic functions of the languages. [FW79] shows that learning power is increased if, in addition to the informants, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:eFGnga8zZ4AJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9252420788343492984&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9252420788343492984&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <url>http://www.springerlink.com/index/M10332H915246783.pdf</url>
        <title status="complete" source="scholar.google.com">On the classification of computable languages</title>
        <pdf>http://www.cis.udel.edu/~case/papers/classif.ps</pdf>
        <author status="complete" source="scholar.google.com">J Case, E Kinber, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">STACS 97</proceeding>
        <year>1997</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A one-sided classifier for a given class of languages converges to 1 on every language from the class and outputs 0 infinitely often on languages outside the class. A two-sided classifier, on the other hand, converges to 1 on languages from the class and converges to 0 on ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RuRE4B4a4IgJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9862911903855338566&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9862911903855338566&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="13">
        <url>http://www.springerlink.com/index/p57461825q674388.pdf</url>
        <title status="complete" source="scholar.google.com">Memory limited inductive inference machines</title>
        <author status="complete" source="scholar.google.com">R Freivalds, C Smith</author>
        <proceeding status="complete" source="scholar.google.com">Algorithm TheoryâSWAT&#39;92</proceeding>
        <year>1992</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The traditional model of learning in the limit is restricted so as to allow the learning machines only a fixed, finite amount of memory to store input and other data. A class of recursive functions is presented that cannot be learned deterministically by any such machine, but ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:yu7VO0T5SDoJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4199880723979955914&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4199880723979955914&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="14">
        <url>http://www.tandfonline.com/doi/abs/10.1080/09528130119716</url>
        <title status="complete" source="scholar.google.com">On the role of search for learning from examples</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.36.230&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">SA Kurtz, CH Smith, R Wiehagen</author>
        <proceeding status="partial" source="scholar.google.com">Journal of Experimental &amp; &#8230;</proceeding>
        <year>2001</year>
        <source>Taylor &amp; Francis</source>
        <snippet status="partial" source="scholar.google.com">Gold (1967) discovered a fundamental enumeration technique, the socalled identification-by-enumeration, a simple but powerful class of algorithms for learning from examples (inductive inference). We introduce a variety of more sophisticated (and more powerful) enumeration ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:7826UNEm518J:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6910534833667755503&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6910534833667755503&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="15">
        <title status="complete" source="scholar.google.com">A survey of inductive inference with an emphasis on queries</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.33.5664&amp;rep=rep1&amp;type=pdf</pdf>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:GnKgfqPifP0J:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=18265723380539879962&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=18265723380539879962&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="16">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397502004218</url>
        <title status="complete" source="scholar.google.com">On learning of functions refutably</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.100.9346&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Learning of recursive functions refutably informally means that for every recursive function, the learning machine has either to learn this function or to refute it, that is to signal that it is not able to learn it. Three modi of making precise the notion of refuting are considered. We ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:p7s2pvsnODgJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4051031826598640551&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4051031826598640551&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="17">
        <url>http://www.springerlink.com/index/73400QH743225525.pdf</url>
        <title status="complete" source="scholar.google.com">A refutation of Barzdins&#39; conjecture</title>
        <author status="complete" source="scholar.google.com">S Kurtz, C Smith</author>
        <proceeding status="complete" source="scholar.google.com">Analogical and Inductive Inference</proceeding>
        <year>1989</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Gold [Gol67] discovered the enumeration technique, a simple but powerful class of algorithms for learning in the limit (inductive inference). We introduce a provably more powerful technique, which enables us to refute a conjecture of Barzdins [Zeu87] ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RXfMSaxQa1wJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6659505174900143941&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6659505174900143941&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="18">
        <url>http://www.springerlink.com/index/5fvlvahq3bcmcvmh.pdf</url>
        <title status="complete" source="scholar.google.com">Learning recursive functions refutably</title>
        <pdf>http://www-alg.ist.hokudai.ac.jp/~thomas/publications/alt01jkwz.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen, T Zeugmann</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Learning of recursive functions refutably means that for every recursive function, the learning machine has either to learn this function or to refute it, ie, to signal that it is not able to learn it. Three modi of making precise the notion of refuting are considered. We show that the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:odjl50e9rvgJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17919468083884710049&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17919468083884710049&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="19">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000004001308</url>
        <title status="complete" source="scholar.google.com">Increasing the power of uniform inductive learners</title>
        <pdf>http://webdocs.cs.ualberta.ca/~zilles/zilles05increasing.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2005</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The analysis of theoretical learning models is basically concerned with the comparison of identification capabilities in different models. Modifications of the formal constraints affect the quality of the corresponding learners on the one hand and regulate the quantity of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:7Fxc7yuFFUMJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4833916198797991148&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4833916198797991148&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="20">
        <url>http://www.springerlink.com/index/n8rfuueg4ytgbeg5.pdf</url>
        <title status="complete" source="scholar.google.com">On the comparison of inductive inference criteria for uniform learning of finite classes</title>
        <pdf>http://cs5824.userapi.com/u11728334/docs/20e8cf4a8295/Naoki_Abe_Algorithmic_Learning_Theory_12_conf_A.pdf#page=260</pdf>
        <author status="complete" source="scholar.google.com">S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We consider a learning model in which each element of a class of recursive functions is to be identified in the limit by a computable strategy. Given gradually growing initial segments of the graph of a function, the learner is supposed to generate a sequence of hypotheses ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:-wk6JIpicNgJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15596073855036819963&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15596073855036819963&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="21">
        <url>http://www.springerlink.com/index/l5p6329uk2633r03.pdf</url>
        <title status="complete" source="scholar.google.com">Directions for computability theory beyond pure mathematical</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/rft-directions.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Mathematical problems from applied logic II</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper begins by briefly indicating the principal, non-standard motivations of the author for his decades of work in Computability Theory (CT), aka Recursive Function Theory. Then it discusses its proposed, general directions beyond those from pure mathematics for CT. These ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:BWKg2uLmRxMJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1389332872072028677&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1389332872072028677&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="22">
        <url>http://www.comp.nus.edu.sg/~sanjay/paps/parsh.pdf</url>
        <title status="complete" source="scholar.google.com">Machine induction without revolutionary changes in hypothesis size</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/parsh.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>1996</year>
        <source>comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper provides a beginning study of the effects on inductive inference of paradigm shifts whose absence is approximately modeled by various formal approaches to forbidding large changes in the size of programs conjectured. One approach, called ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:UBoOOrjlzAYJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:UBoOOrjlzAYJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=490019038887287376&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=490019038887287376&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="23">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397500000281</url>
        <title status="complete" source="scholar.google.com">Costs of general purpose learning</title>
        <author status="complete" source="scholar.google.com">J Case, KJ Chen, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Leo Harrington surprisingly constructed a machine which can learn any computable function f according to the following criterion (called Bcâ-identification). His machine, on the successive graph points of f, outputs a corresponding infinite sequence of programs p 0, p ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:wrVARSN1uLUJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13094344710925891010&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13094344710925891010&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="24">
        <url>http://www.springerlink.com/index/Q4H243321323V6K8.pdf</url>
        <title status="complete" source="scholar.google.com">The complexity of learning SUBSEQ (A)</title>
        <pdf>http://fs1.bib.tiera.ru/content/dvd52/Balcazar%20J.%20L.%20(Ed),%20Long%20Ph.%20M.%20(Ed),%20Stephan%20F.%20(Ed)%20-%20Algorithmic%20Learning%20Theory.%2017th%20International%20Conference,%20ALT%202006,%20Barcelona,%20Spain,%20October%207-10,%202006,%20Proceedings(2006)(393).pdf#page=120</pdf>
        <author status="complete" source="scholar.google.com">S Fenner, W Gasarch</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Higman showed that if A is any language then SUBSEQ (A) is regular, where SUBSEQ (A) is the language of all subsequences of strings in A. We consider the following inductive inference problem: given A (Îµ), A (0), A (1), A (00),... learn, in the limit, a DFA for SUBSEQ ( ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Jza4kQkTdmMJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>36</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7166936788827125287&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7166936788827125287&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="25">
        <url>http://www.springerlink.com/index/N06E3108MYXKV600.pdf</url>
        <title status="complete" source="scholar.google.com">Team learning of computable languages</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.108.396&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Theory of Computing Systems</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. A team of learning machines is a multiset of learning machines. A team is said to learn a concept successfully if each member of some nonempty subset, of predetermined size, of the team learns the concept. Team learning of languages may be viewed as a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:o5szlboYGy4J:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3322276339762043811&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3322276339762043811&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="26">
        <title status="complete" source="scholar.google.com">Computable Metamathematics and its Application to Game Theory</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:jJ7Q9VjBkRYJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1626293528282832524&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1626293528282832524&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="27">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540104000392</url>
        <title status="complete" source="scholar.google.com">On the classification of recursive languages</title>
        <author status="complete" source="scholar.google.com">J Case, E Kinber, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A one-sided classifier for a given class of languages converges to 1 on every language from the class and outputs 0 infinitely often on languages outside the class. A two-sided classifier, on the other hand, converges to 1 on languages from the class and converges to 0 on ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:PVNAR5fT1ogJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9860301080863200061&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9860301080863200061&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="28">
        <url>http://www.sciencedirect.com/science/article/pii/S002200009791518X</url>
        <title status="complete" source="scholar.google.com">Maximal machine learnable classes</title>
        <author status="complete" source="scholar.google.com">J Case, MA Fulk</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>1999</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A class of computable functions ismaximaliff it can be incrementally learned by some inductive inference machine (IIM), but no infinitely larger class of computable functions can be so learned. Rolf Wiehagen posed the question whether there exist such maximal ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:h3X5TruWkhIJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1338297770510480775&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1338297770510480775&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="29">
        <url>http://www.springerlink.com/index/0F9V180D4H1PDFK4.pdf</url>
        <title status="complete" source="scholar.google.com">Learning how to separate</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/resep.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The main question addressed in the present work is how to find effectively a recursive function separating two sets drawn arbitrarily from a given collection of disjoint sets. In particular, it is investigated in which cases it is possible to satisfy the following additional ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:SdXNvUSIHnoJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>19</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8799620550752064841&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8799620550752064841&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="30">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397503006108</url>
        <title status="complete" source="scholar.google.com">Learning how to separate</title>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The main question addressed in the present work is how to find effectively a recursive function separating two sets drawn arbitrarily from a given collection of disjoint sets. In particular, it is investigated when one can find better learners which satisfy additional ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:nF9d1Ps158kJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14548656476959629212&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14548656476959629212&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="31">
        <url>http://dl.acm.org/citation.cfm?id=307450</url>
        <title status="complete" source="scholar.google.com">On a generalized notion of mistake bounds</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.115.8551&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the twelfth annual conference on &#8230;</proceeding>
        <year>1999</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract The present paper proposes the use of constructive ordinals as mistake bounds in the online learning model. This approach elegantly generalizes the applicability of the on-line mistake bound model to learnability analysis of very expressive concept classes like ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MyqL-H2ICScJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2812929516891744819&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2812929516891744819&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=45</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="32">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397500000232</url>
        <title status="complete" source="scholar.google.com">Robust learning with infinite additional information</title>
        <author status="complete" source="scholar.google.com">S Kaufmann, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present work investigates Gold-style algorithmic learning from inputâoutput examples where the learner has access to oracles as additional information. This access is required to be robust in the sense that a single learning algorithm has to succeed with every oracle ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:SjHpI41Yt-EJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16264565942487953738&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="33">
        <url>http://www.springerlink.com/index/P10132MM72722530.pdf</url>
        <title status="complete" source="scholar.google.com">Machine induction without revolutionary paradigm shifts</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1995</year>
        <source>Springer</source>
        <snippet status="complete" source="scholar.google.com">This paper provides a beginning study of the effects on inductive inference of paradigm shifts whose absence is approximately modeled by various formal approaches to forbidding large changes in the size of programs conjectured.</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:xSMXOf0nWRcJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1682419904337617861&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="34">
        <title status="complete" source="scholar.google.com">Department of Computer and Information Sciences University of Delaware Newark, DE 19716, USA Email: case@ cis. udel. edu</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:XViiPr1RB8kJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="35">
        <url>http://www.springerlink.com/index/3225687880N096U5.pdf</url>
        <title status="complete" source="scholar.google.com">Enlarging learnable classes</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/maximal.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, T KÃ¶tzing, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2012</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">An early result in inductive inference shows that the class of Ex-learnable sets is not closed under unions. In this paper we are interested in the following question: For what classes of functions is the union with an arbitrary Ex-learnable class again Ex-learnable, either ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="36">
        <url>http://www.comp.nus.edu.sg/~sanjay/paps/robsur-c.pdf</url>
        <title status="complete" source="scholar.google.com">A Survey of Robust Learning</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/robsur-c.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <year>2008</year>
        <source>comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract. A class of objects is said to be robustly learnable if not only this class itself is learnable but all of its computable âtransformationsâ are also learnable. We study robust learning within the framework of inductive inference. A class of recursive functions is said ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:td7IYjEIaMwJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:td7IYjEIaMwJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14729031589518958261&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="37">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.20.8500&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">SIIM Technical Report</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.20.8500&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen, T Zeugmann</author>
        <year>2001</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract Learning of recursive functions refutably informally means that for every recursive function, the learning machine has either to learn this function or to refute it, that is to signal that it is not able to learn it. Three modi of making precise the notion of refuting are ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:jT4EcmddjbEJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:jT4EcmddjbEJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12793984815305342605&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="38">
        <url>http://www.springerlink.com/index/2TFVJ5FR0PY9BTGF.pdf</url>
        <title status="complete" source="scholar.google.com">Costs of general purpose learning</title>
        <pdf>http://pdf.aminer.org/000/620/043/costs_of_general_purpose_learning.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, KJ Chen, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">STACS 99</proceeding>
        <year>1999</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Leo Harrington surprisingly constructed a machine which can learn any computable function f according to the following criterion (called Be*-identification). His machine, on the successive graph points of f, outputs a corresponding infinite sequence of programs p 0, p ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:mYn4ergsVsAJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13859314074127993241&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="39">
        <url>http://www.springerlink.com/index/812361171q2264pu.pdf</url>
        <title status="complete" source="scholar.google.com">Resource Restricted Computability Theoretic Learning: Illustrative Topics and Problems</title>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Theory of Computing Systems</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract Computability theoretic learning theory (machine inductive inference) typically involves learning programs for languages or functions from a stream of complete data about them and, importantly, allows mind changes as to conjectured programs. This theory takes ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cNGIg7j_YKkJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12205036158119891312&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="40">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.35.4596&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">On the Impact of Forgetting on Learning Machines</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.35.4596&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">R usi ns Freivalds, E m Kinbery, CH Smithz</author>
        <proceeding status="complete" source="scholar.google.com">Citeseer</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract People tend not to have perfect memories when it comes to learning, or to anything else for that matter. Most formal studies of learning, however, assume a perfect memory. Some approaches have restricted the number of items that could be retained. We ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:7iUDiaMYszoJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:7iUDiaMYszoJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4229751565688448494&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="41">
        <url>http://www.worldscientific.com/doi/abs/10.1142/S0129054198000209</url>
        <title status="complete" source="scholar.google.com">Minimal Concept Identification and Reliability</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.3448&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <proceeding status="partial" source="scholar.google.com">International Journal of Foundations of Computer &#8230;</proceeding>
        <year>1998</year>
        <source>World Scientific</source>
        <snippet status="partial" source="scholar.google.com">Identification, by algorithmic devices, of grammars for languages from positive data is a well studied problem. In this paper we are mainly concerned about the learnability of indexed families of uniformly recursive languages. Mukouchi introduced the notion of minimal and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:iCbXmd0phx4J:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2199772974739302024&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="42">
        <title status="complete" source="scholar.google.com">Department of Computer and Information Sciences University of Delaware Newark, DE 19716, USA</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RLkDr-qUHr8J:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13771608446225070404&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="43">
        <url>https://www.comp.nus.edu.sg/~fstephan/union.ps</url>
        <title status="complete" source="scholar.google.com">Unionability and Extendability of Learnable Classes</title>
        <pdf>https://www.comp.nus.edu.sg/~fstephan/union.ps</pdf>
        <author status="complete" source="scholar.google.com">S Jain, T KÃ¶tzing, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">comp.nus.edu.sg</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. An early result in inductive inference shows that the class of Ex-learnable sets is not closed under unions. In this paper we are interested in what classes of functions can be unioned with arbitrary Ex-learnable classes, either effectively (in an index for a learner of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:8him4J3YEhAJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:8him4J3YEhAJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1158226226778085618&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="44">
        <url>http://projecteuclid.org/euclid.jsl/1245158093</url>
        <title status="complete" source="scholar.google.com">The complexity of learning SUBSEQ (A)</title>
        <author status="complete" source="scholar.google.com">S Fenner, W Gasarch, B Postow</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
        <year>2009</year>
        <source>projecteuclid.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Higman essentially showed that if A is any language then SUBSEQ (A) is regular, where SUBSEQ (A) is the language of all subsequences of strings in A. Let sâ, sâ, sâ,â¦ be the standard lexicographic enumeration of all strings over some finite alphabet. We ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:g5V9744bXBUJ:scholar.google.com/&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1539135473371157891&amp;hl=en&amp;num=45&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="143">
    <url>http://www.sciencedirect.com/science/article/pii/S0890540107000491</url>
    <title status="complete" source="scholar.google.com">Results on memory-limited U-shaped learning</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.8567&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
    <year>2007</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... Fax: +65 6779 4580. E-mail addresses: carlucci5@unisi.it (L. Carlucci), case@cis.udel.edu (J.Case), sanjay@comp.nus.edu.sg (S. Jain), fstephan@ comp.nus.edu.sg (F. Stephan). 1 Supportedin part by NSF Grant No. NSF CCR-0208616. 2 Supported in part by NUS Grant No. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:aPOveNlKjhoJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>23</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=1913549189572195176&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>21</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=1913549189572195176&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="21">
        <result id="0">
        <url>http://www.springerlink.com/index/AM7558R84445558T.pdf</url>
        <title status="complete" source="scholar.google.com">U-shaped, iterative, and iterative-with-counter learning</title>
        <author status="complete" source="scholar.google.com">J Case, SE Moelius</author>
        <proceeding status="complete" source="scholar.google.com">Machine Learning</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper solves an important problem left open in the literature by showing that U-shapes are unnecessary in iterative learning from positive data. A U-shape occurs when a learner first learns, then unlearns, and, finally, relearns, some target concept. Iterative ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:sZ5F-vPpsDUJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3868849313996447409&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3868849313996447409&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397510002045</url>
        <title status="complete" source="scholar.google.com">Iterative learning of simple external contextual languages</title>
        <author status="partial" source="scholar.google.com">L Becerra-Bonache, J Case, S Jain&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Theoretical Computer &#8230;</proceeding>
        <year>2010</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">It is investigated for which choice of a parameter q, denoting the number of contexts, the class of simple external contextual languages is iteratively learnable. On the one hand, the class admits, for all values of q, polynomial time learnability provided an adequate choice ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:f8VfCBmn_xMJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1441054131738363263&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1441054131738363263&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/e654657xu548t251.pdf</url>
        <title status="complete" source="scholar.google.com">Iterative learning of simple external contextual languages</title>
        <pdf>http://cs5235.userapi.com/u133638729/docs/e02780dda47c/Yoav_Freund_Algorithmic_Learning_Theory_19_conf.pdf#page=371</pdf>
        <author status="partial" source="scholar.google.com">L Becerra-Bonache, J Case, S Jain&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Algorithmic Learning &#8230;</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">It is investigated for which choice of a parameter q, denoting the number of contexts, the class of simple external contextual languages is iteratively learnable. On one hand, the class admits, for all values of q, polynomial time learnability provided an adequate choice of the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:scvYnWO_FuQJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>25</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16435534324706102193&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16435534324706102193&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/1N4582H1226U0066.pdf</url>
        <title status="complete" source="scholar.google.com">Optimal language learning</title>
        <pdf>http://cs5235.userapi.com/u133638729/docs/e02780dda47c/Yoav_Freund_Algorithmic_Learning_Theory_19_conf.pdf#page=431</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Moelius</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Gold&#39;s original paper on inductive inference introduced a notion of an optimal learner. Intuitively, a learner identifies a class of objects optimally iff there is no other learner that: requires as little of each presentation of each object in the class in order to identify that ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:IPVBINypfzwJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4359389727217022240&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4359389727217022240&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/WW86604W658G5101.pdf</url>
        <title status="complete" source="scholar.google.com">Solutions to open questions for non-U-shaped learning with memory limitations</title>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2010</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A U-shape occurs when a learner first learns, then unlearns, and, finally, relearns, some target concept. Within the framework of Inductive Inference, previous results have shown, for example, that U-shapes are unnecessary for explanatory learning, but are necessary for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ibyShxgPJ6sJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12332842702605565065&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12332842702605565065&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397510002057</url>
        <title status="complete" source="scholar.google.com">Incremental learning with temporary memory</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/tem.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, S Lange, SE Moelius, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2010</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In the inductive inference framework of learning in the limit, a variation of the bounded example memory (Bem) language learning model is considered. Intuitively, the new model constrains the learner&#39;s memory not only in how much data may be stored, but also in how ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:3nbCH_5_qskJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14531567877095585502&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14531567877095585502&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397509000668</url>
        <title status="complete" source="scholar.google.com">Parallelism increases iterative learning power</title>
        <author status="complete" source="scholar.google.com">J Case, SE Moelius III</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2009</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Iterative learning (It-learning) is a Gold-style learning model in which each of a learner&#39;s output conjectures may depend only upon the learner&#39;s current conjecture and the current input element. Two extensions of the It-learning model are considered, each of which ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:AmR2ykO8WnsJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8888623813914682370&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8888623813914682370&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/H18M222XV34JT501.pdf</url>
        <title status="complete" source="scholar.google.com">Learning with temporary memory</title>
        <pdf>http://cs5235.userapi.com/u133638729/docs/e02780dda47c/Yoav_Freund_Algorithmic_Learning_Theory_19_conf.pdf#page=461</pdf>
        <author status="complete" source="scholar.google.com">S Lange, S Moelius, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In the inductive inference framework of learning in the limit, a variation of the bounded example memory (Bem) language learning model is considered. Intuitively, the new model constrains the learner&#39;s memory not only in how much data may be retained, but also in ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:3UoB5xip-78J:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13833836604818541277&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13833836604818541277&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.springerlink.com/index/74M53LP013269545.pdf</url>
        <title status="complete" source="scholar.google.com">Learning without coding</title>
        <author status="complete" source="scholar.google.com">S Moelius, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2010</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Iterative learning is a model of language learning from positive data, due to Wiehagen. When compared to a learner in Gold&#39;s original model of language learning from positive data, an iterative learner can be thought of as memory-limited. However, an iterative ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:y3d_62hDJLIJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12836458955819415499&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12836458955819415499&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.springerlink.com/index/B827045M7662102M.pdf</url>
        <title status="complete" source="scholar.google.com">Iterative learning from positive data and counters</title>
        <author status="complete" source="scholar.google.com">T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We analyze iterative learning in the limit from positive data with the additional information provided by a counter. The simplest type of counter provides the current iteration number (counting up from 0 to infinity), which is known to improve learning power over plain ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:R2qx8w66hzAJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3496968209057278535&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3496968209057278535&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www.socsci.uci.edu/~lpearl/colareadinggroup/readings/Heinz2010Manu_CompLearningDevPsych.pdf</url>
        <title status="complete" source="scholar.google.com">Computational theories of learning and developmental psycholinguistics</title>
        <pdf>http://www.socsci.uci.edu/~lpearl/colareadinggroup/readings/Heinz2010Manu_CompLearningDevPsych.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Heinz</author>
        <proceeding status="partial" source="scholar.google.com">Under review for the The Cambridge Handbook of &#8230;</proceeding>
        <year>2010</year>
        <source>socsci.uci.edu</source>
        <snippet status="partial" source="scholar.google.com">A computer is something that computes, and since humans make computations when pro- cessing information, humans are computers. What kinds of computations do humans make when they learn languages? Answering this question requires the collaborative efforts of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:0YVDFo-F5rUJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:0YVDFo-F5rUJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13107310615108748753&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13107310615108748753&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.145.8803&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Optimal language learning (expanded version)</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.145.8803&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, SE Moelius</author>
        <year>2008</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. Gold&#39;s original paper on inductive inference introduced a notion of an optimal learner. Intuitively, a learner identifies a class of objects optimally iff there is no other learner that: requires as little of each presentation of each object in the class in order to identify ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:d7PuVqTQuiMJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:d7PuVqTQuiMJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2574599541247357815&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2574599541247357815&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.146.2248&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Learning with temporary memory (expanded version)</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.146.2248&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Lange, SE Moelius, S Zilles</author>
        <year>2008</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. In the inductive inference framework of learning in the limit, a variation of the bounded example memory (Bem) language learning model is considered. Intuitively, the new model constrains the learner&#39;s memory not only in how much data may be retained, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:7lJI0YadCZkJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:7lJI0YadCZkJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11027518364955726574&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11027518364955726574&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="13">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=nEBfBghRSgsC&amp;oi=fnd&amp;pg=PA300&amp;ots=42d4reJAEa&amp;sig=XZo7_wbg4CVvdvOrheA_Jx5FDls</url>
        <title status="complete" source="scholar.google.com">Learning without Coding</title>
        <pdf>http://www.eecis.udel.edu/~moelius/publications/lwoc_tr.pdf</pdf>
        <author status="complete" source="scholar.google.com">SEM Iii, S Zilles</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; , ALT 2010, Canberra, Australia, October 6-8, &#8230;</proceeding>
        <year>2010</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">Abstract. Iterative learning is a model of language learning from positive data, due to Wiehagen. When compared to a learner in Gold&#39;s original model of language learning from positive data, an iterative learner can be thought of as memory-limited. However, an ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:L2vGQFeWA-0J:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17078659513412119343&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="14">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540111001088</url>
        <title status="complete" source="scholar.google.com">Optimal language learning from positive data</title>
        <author status="complete" source="scholar.google.com">J Case, SE Moelius</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2011</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">GoldÊ¼s original paper on inductive inference introduced a notion of an optimal learner. Intuitively, a learner identifies a class of objects optimally iff there is no other learner that: requires as little of each presentation of each object in the class in order to identify that ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Lka8Q86r5ysJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3163686165639087662&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="15">
        <url>http://www2.cs.uregina.ca/~zilles/langeMZ08TR.pdf</url>
        <title status="complete" source="scholar.google.com">Incremental Learning with Temporary Memory</title>
        <pdf>http://www2.cs.uregina.ca/~zilles/langeMZ08TR.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Langea, S Zillesc</author>
        <proceeding status="complete" source="scholar.google.com">cs.uregina.ca</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract In the inductive inference framework of learning in the limit, a variation of the bounded example memory (Bem) language learning model is considered. Intuitively, the new model constrains the learner&#39;s memory not only in how much data may be retained, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MRIpRUDfVdEJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:MRIpRUDfVdEJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15084207994078564913&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="16">
        <url>http://onlinelibrary.wiley.com/doi/10.1111/tops.12004/full</url>
        <title status="complete" source="scholar.google.com">Editors&#39; Introduction: Why Formal Learning Theory Matters for Cognitive Science</title>
        <author status="complete" source="scholar.google.com">S Fulop, N Chater</author>
        <proceeding status="complete" source="scholar.google.com">Topics in Cognitive Science</proceeding>
        <year>2013</year>
        <source>Wiley Online Library</source>
        <snippet status="partial" source="scholar.google.com">Abstract This article reviews a number of different areas in the foundations of formal learning theory. After outlining the general framework for formal models of learning, the Bayesian approach to learning is summarized. This leads to a discussion of Solomonoff&#39;s Universal ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="17">
        <url>http://www.springerlink.com/index/812361171q2264pu.pdf</url>
        <title status="complete" source="scholar.google.com">Resource Restricted Computability Theoretic Learning: Illustrative Topics and Problems</title>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Theory of Computing Systems</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract Computability theoretic learning theory (machine inductive inference) typically involves learning programs for languages or functions from a stream of complete data about them and, importantly, allows mind changes as to conjectured programs. This theory takes ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cNGIg7j_YKkJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12205036158119891312&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="18">
        <url>http://www.eecis.udel.edu/~case/papers/pr2.pdf</url>
        <title status="complete" source="scholar.google.com">On the Necessity of U-Shaped Learning</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/pr2.pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case</author>
        <proceeding status="complete" source="scholar.google.com">eecis.udel.edu</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. A U-shaped curve in a cognitive-developmental trajectory refers to a three-step process: good performance followed by bad performance followed by good performance once again. U-shaped curves have been observed in a wide variety of cognitive- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17336137048815070431&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="19">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397512009310</url>
        <title status="complete" source="scholar.google.com">Memory-limited non-U-shaped learning with solved open problems</title>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Herein we also distinguish between semantic and syntactic U-shapes. We answer a number of open questions in the prior literature as well as provide new results regarding syntactic U-shapes. Importantly for cognitive science, we see more of a previously noticed pattern ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="20">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397512009322</url>
        <title status="complete" source="scholar.google.com">Learning without coding</title>
        <author status="complete" source="scholar.google.com">S Jain, SE Moelius III, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Abstract Iterative learning is a model of language learning from positive data, due to Wiehagen. When compared to a learner in Gold&#39;s original model of language learning from positive data, an iterative learner can be thought of as memory-limited. However, an ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="144">
    <url>http://www.sciencedirect.com/science/article/pii/S030439750800145X</url>
    <title status="complete" source="scholar.google.com">Absolute versus probabilistic classification in a logical setting</title>
    <author status="complete" source="scholar.google.com">S Jain, E Martin, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
    <year>2008</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... South Wales, UNSW Sydney NSW 2052, Australia. E-mail addresses:sanjay@comp.nus.edu.sg (S. Jain), emartin@cse.unsw.edu.au (E. Martin),fstephan@comp.nus.edu.sg (F. Stephan). 1 National ICT Australia is funded by ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:m9ipjfJFSGUJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>3</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=7298160104215009435&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=7298160104215009435&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://www.springerlink.com/index/U07211K470R73N12.pdf</url>
        <title status="complete" source="scholar.google.com">Learning and classifying</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/classifylearn.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Martin, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We define and study a learning paradigm that sits between identification in the limit and classification. More precisely, we expect that a learner be able to identify in the limit which members of a set D of n possible data belong to a target language, where n and D are ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:dAVDyGPzGgMJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=223758741395408244&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="145">
    <url>http://www.jstor.org/stable/10.2307/2275636</url>
    <title status="complete" source="scholar.google.com">The structure of intrinsic complexity of learning</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/intrin.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
    <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
    <year>1997</year>
    <source>JSTOR</source>
    <snippet status="partial" source="scholar.google.com">Page 1. THE JOURNAL OF SYMBOLIC LOGIC Volume 62, Number 4, Dec. 1997THE STRUCTURE OF INTRINSIC COMPLEXITY OF LEARNING SANJAY JAIN ANDARUN SHARMA Abstract. Limiting identification of re indexes ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:HBFHddPtUW8J:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>6</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=8021453903785038108&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>23</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=8021453903785038108&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="23">
        <result id="0">
        <url>http://dl.acm.org/citation.cfm?id=238093</url>
        <title status="complete" source="scholar.google.com">Elementary formal systems, intrinsic complexity, and procrastination</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.96.6124&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the ninth annual conference on &#8230;</proceeding>
        <year>1996</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Recently, rich subclasses of elementary formal systems(EFS) have been shown to be identifiable in the limit from only positive data. Examples of these classes are Angluin&#39;s pattern languages, unions of pattern languages by Wright and Shinohara, and classes of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:UjWHaftOaIkJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9901250622488261970&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>33</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9901250622488261970&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397599000055</url>
        <title status="complete" source="scholar.google.com">Ordinal mind change complexity of language identification</title>
        <author status="complete" source="scholar.google.com">A Ambainis, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>1999</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The approach of ordinal mind change complexity, introduced by Freivalds and Smith, uses (notations for) constructive ordinals to bound the number of mind changes made by a learning machine. This approach provides a measure of the extent to which a learning ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:vR2MAdwEA-MJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16357923614505049533&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>28</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16357923614505049533&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000001917593</url>
        <title status="complete" source="scholar.google.com">Language learning from texts: Degrees of intrinsic complexity and their characterizations</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/rolfintrin.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber, R Wiehagen</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper deals with two problems:(1) what makes languages learnable in the limit by natural strategies of varying hardness, and (2) what makes classes of languages the hardest ones to learn. To quantify hardness of learning, we use intrinsic complexity based on ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:8fj8PkF24gUJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=424031337527965937&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>17</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=424031337527965937&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/a81263786620675p.pdf</url>
        <title status="complete" source="scholar.google.com">Ordinal mind change complexity of language identification</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.150.7815&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">A Ambainis, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
        <year>1997</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The approach of ordinal mind change complexity, introduced by Freivalds and Smith, uses constructive ordinals to bound the number of mind changes made by a learning machine. This approach provides a measure of the extent to which a learning machine has to keep ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:L3MXwPUbmY4J:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10275274767126197039&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=10275274767126197039&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://dl.acm.org/citation.cfm?id=307465</url>
        <title status="complete" source="scholar.google.com">On the intrinsic complexity of learning recursive functions</title>
        <author status="partial" source="scholar.google.com">E Kinber, C Papazian, C Smith&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the twelfth &#8230;</proceeding>
        <year>1999</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract The intrinsic complexity of learning compares the difficulty of learning classes of objects by using some reducibility notion. For several types of learning recursive functions (learning in the limit, learning with a bounded number of mind changes, learning with ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:7vprogRmWLwJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13571709647171877614&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13571709647171877614&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540103000592</url>
        <title status="complete" source="scholar.google.com">On the intrinsic complexity of learning recursive functions</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.105.5266&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="partial" source="scholar.google.com">S Jain, E Kinber, C Papazian, C Smith&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Information and &#8230;</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The intrinsic complexity of learning compares the difficulty of learning classes of objects by using some reducibility notion. For several types of learning recursive functions, both natural complete classes are exhibited and necessary and sufficient conditions for completeness ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1E4tVz7znzUJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3864074454383283924&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3864074454383283924&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397509007981</url>
        <title status="complete" source="scholar.google.com">Mind change complexity of inferring unbounded unions of restricted pattern languages from positive data</title>
        <author status="complete" source="scholar.google.com">M de Brecht, A Yamamoto</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2010</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper shows that the mind change complexity of inferring from positive data the class of unbounded unions of languages of regular patterns with constant segment length bound is of the form [Formula: see text], assuming that the patterns are defined over a finite ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:S_0At17bfksJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5440026599753841995&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5440026599753841995&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/953nl87770n8u582.pdf</url>
        <title status="complete" source="scholar.google.com">Mind change complexity of inferring unbounded unions of pattern languages from positive data</title>
        <pdf>http://fs1.bib.tiera.ru/content/dvd52/Balcazar%20J.%20L.%20(Ed),%20Long%20Ph.%20M.%20(Ed),%20Stephan%20F.%20(Ed)%20-%20Algorithmic%20Learning%20Theory.%2017th%20International%20Conference,%20ALT%202006,%20Barcelona,%20Spain,%20October%207-10,%202006,%20Proceedings(2006)(393).pdf#page=135</pdf>
        <author status="complete" source="scholar.google.com">M de Brecht, A Yamamoto</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper gives a proof that the class of unbounded unions of languages of regular patterns with constant segment length bound is inferable from positive data with mind change bound between Ï Ï and www Ï^ Ï^ Ï. We give a very tight bound on the mind change ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:s5QaNydO4G4J:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7989471669290439859&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=7989471669290439859&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.springerlink.com/index/4H6654381W4512X6.pdf</url>
        <title status="complete" source="scholar.google.com">Robust learning of automatic classes of languages</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/3143/1/TRA4-10.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Martin, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper adapts and investigates the paradigm of robust learning, originally defined in the inductive inference literature for classes of recursive functions, to learning languages from positive data. Robustness is a very desirable property, as it captures a form of invariance ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:638p0aK98c4J:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>22</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14911908348191932395&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14911908348191932395&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://iospress.metapress.com/index/TRRD110H759Y5W0B.pdf</url>
        <title status="complete" source="scholar.google.com">The intrinsic complexity of learning: A survey</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/intrinsur.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Fundamenta Informaticae</proceeding>
        <year>2003</year>
        <source>IOS Press</source>
        <snippet status="partial" source="scholar.google.com">The theory of learning in the limit has been a focus of study by several researchers over the last three decades. There have been several suggestions on how to measure the complexity or hardness of learning. In this paper we survey the work done in one specific such ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:b9x1IASxyRcJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1714095764473764975&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1714095764473764975&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://epubs.siam.org/doi/abs/10.1137/070700577</url>
        <title status="complete" source="scholar.google.com">Mitotic classes in inductive inference</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.137.6190&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">SIAM Journal on Computing</proceeding>
        <year>2008</year>
        <source>SIAM</source>
        <snippet status="partial" source="scholar.google.com">For the natural notion of splitting classes into two disjoint subclasses via a recursive classifier working on texts, the question of how these splittings can look in the case of learnable classes is addressed. Here the strength of the classes is compared using the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:8Dgog4Yp7VIJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>24</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5975477938293324016&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5975477938293324016&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://www.springerlink.com/index/QCKQQRTHHQ5K217C.pdf</url>
        <title status="complete" source="scholar.google.com">Intrinsic complexity of uniform learning</title>
        <pdf>http://webdocs.cs.ualberta.ca/~zilles/zilles03uniform.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2003</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Inductive inference is concerned with algorithmic learning of recursive functions. In the model of learning in the limit a learner successful for a class of recursive functions must eventually find a program for any function in the class from a gradually growing sequence ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:HMm4NBIPwV4J:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6827755080938735900&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6827755080938735900&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <url>http://www.springerlink.com/index/u584873247003656.pdf</url>
        <title status="complete" source="scholar.google.com">Mitotic classes</title>
        <pdf>https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2569/1/TRB8-07.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">For the natural notion of splitting classes into two disjoint subclasses via a recursive classifier working on texts, the question is addressed how these splittings can look in the case of learnable classes. Here the strength of the classes is compared using the strong ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:bEfvZa6Aqn8J:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9199306675380504428&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9199306675380504428&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="13">
        <url>http://www.springerlink.com/index/80x7h9xc6ju9crv4.pdf</url>
        <title status="complete" source="scholar.google.com">Intrinsic complexity of learning geometrical concepts from positive data</title>
        <pdf>http://cs5824.userapi.com/u11728334/docs/be3e0641bab1/David_Helmbold_Computational_Learning_Theory_14.pdf#page=185</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Computational Learning Theory</proceeding>
        <year>2001</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Intrinsic complexity is used to measure complexity of learning areas limited by broken-straight lines (called open semi-hulls) 1 and intersections of such areas. Any strategy learning such geometrical concept can be viewed as a sequence of primitive basic ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:UVtfeQ_guscJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14392061916281264977&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14392061916281264977&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="14">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540101929104</url>
        <title status="complete" source="scholar.google.com">Induction by enumeration</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.35.5739&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">E Martin, D Osherson</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2001</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Induction by enumeration has a clear interpretation within the numerical paradigm of inductive discovery (ie, the one pioneered by EM Gold (1967, Inform. and Control10, 447â474)). The concept is less easily interpreted within the first-order paradigm discussed by ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:685CqakMUSUJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2688944375345630955&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2688944375345630955&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="15">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000003000679</url>
        <title status="complete" source="scholar.google.com">Intrinsic complexity of learning geometrical concepts from positive data</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/geometry.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2003</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Intrinsic complexity is used to measure the complexity of learning areas limited by broken-straight lines (called open semi-hulls) and intersections of such areas. Any strategy learning such geometrical concepts can be viewed as a sequence of primitive basic strategies. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:X_seyV1VkhsJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1986744246918380383&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1986744246918380383&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="16">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397506004890</url>
        <title status="complete" source="scholar.google.com">An approach to intrinsic complexity of uniform learning</title>
        <pdf>http://www2.cs.uregina.ca/~zilles/zilles06intrinsic.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2006</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Inductive inference is concerned with algorithmic learning of recursive functions. In the model of learning in the limit a learner successful for a class of recursive functions must eventually find a program for any function in the class from a gradually growing sequence ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:-afF2fspAVQJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6053165535829796857&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6053165535829796857&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="17">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.34.4686&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">How rich is the structure of the intrinsic complexity of learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.34.4686&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">A Ambainis</author>
        <proceeding status="complete" source="scholar.google.com">Information processing letters</proceeding>
        <year>2000</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">There are several possible meanings for the term &quot;the complexity of learning&quot;. Traditionally, it is understood as the complexity of a learning algorithm. Recently, Freivalds, Kinber and Smith 1] proposed a new view of the complexity of learning. They de ned reductions between ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:X7AXCXx5q7AJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:X7AXCXx5q7AJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12730402345328291935&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="18">
        <url>http://faculty.sacredheart.edu/kinbere/jkw_JCSS.ps</url>
        <title status="complete" source="scholar.google.com">Language Learning from Texts: Degrees of Intrinsic Complexity and Their Characterizations</title>
        <pdf>http://faculty.sacredheart.edu/kinbere/jkw_JCSS.ps</pdf>
        <author status="complete" source="scholar.google.com">R Wiehagen</author>
        <year>2001</year>
        <source>faculty.sacredheart.edu</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper deals with two problems: 1) what makes languages to be learnable in the limit by natural strategies of varying hardness; 2) what makes classes of languages to be the hardest ones to learn. To quantify hardness of learning, we use intrinsic complexity ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:r6APmnQoog8J:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:r6APmnQoog8J:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1126507338062078127&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="19">
        <url>http://dl.comp.nus.edu.sg/dspace/handle/1900.100/1400</url>
        <title status="complete" source="scholar.google.com">On intrinsic complexity of learning geometrical concepts from texts</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1400/1/report.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Sanjay, E KINBER</author>
        <year>1999</year>
        <source>dl.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract: The goal of this paper is to quantify complexity of algorithmic learning of geometrical concepts from growing finite segments. The geometrical concepts we consider are variants of open-hulls. We use intrinsic complexity as our complexity measure. The ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:DAWdzjlgDVIJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5912487687203128588&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="20">
        <url>http://www.springerlink.com/index/K463H6036PH8678U.pdf</url>
        <title status="complete" source="scholar.google.com">Splitting of learnable classes</title>
        <pdf>http://users.dsic.upv.es/workshops/icgi2010/slides/Li.pdf</pdf>
        <author status="complete" source="scholar.google.com">H Li, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">Grammatical Inference: Theoretical Results and &#8230;</proceeding>
        <year>2010</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A class LL is called mitotic if it admits a splitting L 0, L 1 L _0, L _1 such that L, L 0, L 1 L, L _0, L _1 are all equivalent with respect to a certain reducibility. Such a splitting might be called a symmetric splitting. In this paper we investigate the possibility of constructing a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cV405y-RMO8J:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>19</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17235435408875347569&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="21">
        <url>http://www.princeton.edu/~osherson/IL/essay4.pdf</url>
        <title status="complete" source="scholar.google.com">Advanced Topics in Inductive Logic1</title>
        <pdf>http://www.princeton.edu/~osherson/IL/essay4.pdf</pdf>
        <author status="complete" source="scholar.google.com">E Martin, D Osherson</author>
        <year>2003</year>
        <source>princeton.edu</source>
        <snippet status="partial" source="scholar.google.com">1This work was supported by Australian Research Council Grant# A49803051 to Martin and by NSF Grant# IIS-9978135 to Osherson. We thank Scott Weinstein for generously checking proofs and offering improvements to several arguments. Thanks also to Sebastian Rahtz ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:IneW_kNr_wUJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:IneW_kNr_wUJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=432182029029111586&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="22">
        <url>http://hal.archives-ouvertes.fr/hal-00678163/</url>
        <title status="complete" source="scholar.google.com">Mind Change Speed-up for Learning Languages from Positive Data</title>
        <pdf>http://hal.archives-ouvertes.fr/docs/00/67/81/63/PDF/9.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="partial" source="scholar.google.com">Symposium on Theoretical Aspects of &#8230;</proceeding>
        <year>2012</year>
        <source>hal.archives-ouvertes.fr</source>
        <snippet status="partial" source="scholar.google.com">Abstract Within the frameworks of learning in the limit of indexed classes of recursive languages from positive data and automatic learning in the limit of indexed classes of regular languages (with automatically computable sets of indices), we study the problem ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:y8ex7vN-mE8J:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5735473711603107787&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="146">
    <url>http://www.sciencedirect.com/science/article/pii/S0022000007000797</url>
    <title status="complete" source="scholar.google.com">Non-U-shaped vacillatory and team learning</title>
    <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
    <proceeding status="partial" source="scholar.google.com">Journal of Computer and System &#8230;</proceeding>
    <year>2008</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... Corresponding author. E-mail addresses: carlucci@di.uniroma1.it (L. Carlucci), case@cis.udel.edu (J. Case), sanjay@comp.nus.edu.sg (S. Jain), fstephan@comp.nus.edu.sg (F. Stephan). ... NSFCCR-0208616. 2 Supported in part by NUS Grant No. R252-000-127-112. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:EQmrDMaxldIJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>4</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=15174229983668930833&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>11</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=15174229983668930833&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="11">
        <result id="0">
        <url>http://www.springerlink.com/index/AM7558R84445558T.pdf</url>
        <title status="complete" source="scholar.google.com">U-shaped, iterative, and iterative-with-counter learning</title>
        <author status="complete" source="scholar.google.com">J Case, SE Moelius</author>
        <proceeding status="complete" source="scholar.google.com">Machine Learning</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper solves an important problem left open in the literature by showing that U-shapes are unnecessary in iterative learning from positive data. A U-shape occurs when a learner first learns, then unlearns, and, finally, relearns, some target concept. Iterative ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:sZ5F-vPpsDUJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3868849313996447409&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3868849313996447409&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540108000266</url>
        <title status="complete" source="scholar.google.com">Learning in Friedberg numberings</title>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In this paper we consider learnability in some special numberings, such as Friedberg numberings, which contain all the recursively enumerable languages, but have simpler grammar equivalence problem compared to acceptable numberings. We show that every ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Hq2mBjhdYAMJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=243296875089145118&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=243296875089145118&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://colt2010.haifa.il.ibm.com/presentation/COLT10Talk-NUTechniques.pdf</url>
        <title status="complete" source="scholar.google.com">Strongly non-U-shaped learning results by general techniques</title>
        <pdf>http://colt2010.haifa.il.ibm.com/presentation/COLT10Talk-NUTechniques.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of COLT (Conference on &#8230;</proceeding>
        <year>2010</year>
        <source>colt2010.haifa.il.ibm.com</source>
        <snippet status="partial" source="scholar.google.com">Let N={0, 1, 2,...}, the set of all natural numbers. A language is a set Lâ N. A presentation for L is essentially an (infinite) listing T of all and only the elements of L. Such a T is called a text for L. We numerically name programs or grammars in some standard general hypothesis ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:t15I2yZe0eEJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:t15I2yZe0eEJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16271890449647034039&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16271890449647034039&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/D56708146217R601.pdf</url>
        <title status="complete" source="scholar.google.com">Learning in Friedberg numberings</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2613/1/TR11-07.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In this paper we consider learnability in some special numberings, such as Friedberg numberings, which contain all the recursively enumerable languages, but have simpler grammar equivalence problem compared to acceptable numberings. We show that every ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cLgmLVtjoKkJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>26</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12222878631934212208&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12222878631934212208&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/1N4582H1226U0066.pdf</url>
        <title status="complete" source="scholar.google.com">Optimal language learning</title>
        <pdf>http://cs5235.userapi.com/u133638729/docs/e02780dda47c/Yoav_Freund_Algorithmic_Learning_Theory_19_conf.pdf#page=431</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Moelius</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Gold&#39;s original paper on inductive inference introduced a notion of an optimal learner. Intuitively, a learner identifies a class of objects optimally iff there is no other learner that: requires as little of each presentation of each object in the class in order to identify that ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:IPVBINypfzwJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4359389727217022240&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4359389727217022240&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.springerlink.com/index/WW86604W658G5101.pdf</url>
        <title status="complete" source="scholar.google.com">Solutions to open questions for non-U-shaped learning with memory limitations</title>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2010</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A U-shape occurs when a learner first learns, then unlearns, and, finally, relearns, some target concept. Within the framework of Inductive Inference, previous results have shown, for example, that U-shapes are unnecessary for explanatory learning, but are necessary for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ibyShxgPJ6sJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12332842702605565065&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12332842702605565065&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.springerlink.com/index/q3u47561122j7n59.pdf</url>
        <title status="complete" source="scholar.google.com">Some recent results in U-shaped learning</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1902/1/TR41-05.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theory and Applications of Models of Computation</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. U-shaped learning deals with a learner first having the correct hypothesis, then changing it to an incorrect hypothesis and then relearning the correct hypothesis. This phenomenon has been observed by psychologists in various studies of children ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:O2n5Ep7n5KgJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>25</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12170106759171107131&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12170106759171107131&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.145.8803&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">Optimal language learning (expanded version)</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.145.8803&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, SE Moelius</author>
        <year>2008</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. Gold&#39;s original paper on inductive inference introduced a notion of an optimal learner. Intuitively, a learner identifies a class of objects optimally iff there is no other learner that: requires as little of each presentation of each object in the class in order to identify ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:d7PuVqTQuiMJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:d7PuVqTQuiMJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2574599541247357815&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=2574599541247357815&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540111001088</url>
        <title status="complete" source="scholar.google.com">Optimal language learning from positive data</title>
        <author status="complete" source="scholar.google.com">J Case, SE Moelius</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2011</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">GoldÊ¼s original paper on inductive inference introduced a notion of an optimal learner. Intuitively, a learner identifies a class of objects optimally iff there is no other learner that: requires as little of each presentation of each object in the class in order to identify that ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Lka8Q86r5ysJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3163686165639087662&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.springerlink.com/index/812361171q2264pu.pdf</url>
        <title status="complete" source="scholar.google.com">Resource Restricted Computability Theoretic Learning: Illustrative Topics and Problems</title>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Theory of Computing Systems</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract Computability theoretic learning theory (machine inductive inference) typically involves learning programs for languages or functions from a stream of complete data about them and, importantly, allows mind changes as to conjectured programs. This theory takes ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cNGIg7j_YKkJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12205036158119891312&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www.eecis.udel.edu/~case/papers/pr2.pdf</url>
        <title status="complete" source="scholar.google.com">On the Necessity of U-Shaped Learning</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/pr2.pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case</author>
        <proceeding status="complete" source="scholar.google.com">eecis.udel.edu</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. A U-shaped curve in a cognitive-developmental trajectory refers to a three-step process: good performance followed by bad performance followed by good performance once again. U-shaped curves have been observed in a wide variety of cognitive- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17336137048815070431&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="147">
    <url>http://www.sciencedirect.com/science/article/pii/S0890540108000266</url>
    <title status="complete" source="scholar.google.com">Learning in Friedberg numberings</title>
    <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
    <year>2008</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... Corresponding author. Fax: +65 6779 4580. E-mail addresses: sanjay@comp.nus.edu.sg (S.Jain), fstephan@comp.nus.edu.sg (F. Stephan). 1 Supported in part by NUS Grant Nos.R252-000-127-112, R252-000-308-112. 0890-5401/$ - see front matter Â© 2008 Elsevier Inc. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:Hq2mBjhdYAMJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>5</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=243296875089145118&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>9</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=243296875089145118&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="9">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540110002026</url>
        <title status="complete" source="scholar.google.com">Hypothesis spaces for learning</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/hypdep.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2011</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In this paper we survey some results in inductive inference showing how learnability of a class of languages may depend on the hypothesis space chosen. Additionally, optimal hypothesis spaces, usable for every learnable class, are considered. We also discuss ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:nE03dzw6FbIJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12832226744634658204&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12832226744634658204&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397510002057</url>
        <title status="complete" source="scholar.google.com">Incremental learning with temporary memory</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/tem.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, S Lange, SE Moelius, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2010</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In the inductive inference framework of learning in the limit, a variation of the bounded example memory (Bem) language learning model is considered. Intuitively, the new model constrains the learner&#39;s memory not only in how much data may be stored, but also in how ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:3nbCH_5_qskJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14531567877095585502&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14531567877095585502&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397509000620</url>
        <title status="complete" source="scholar.google.com">Prescribed learning of re classes</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.108.2025&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan, N Ye</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2009</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This work extends studies of Angluin, Lange and Zeugmann on the dependence of learning on the hypothesis space chosen for the language class in the case of learning uniformly recursive language classes. The concepts of class-comprising (where the learner can ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:YdSz3nZgLTsJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>20</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4264170485848462433&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4264170485848462433&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/74M53LP013269545.pdf</url>
        <title status="complete" source="scholar.google.com">Learning without coding</title>
        <author status="complete" source="scholar.google.com">S Moelius, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2010</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Iterative learning is a model of language learning from positive data, due to Wiehagen. When compared to a learner in Gold&#39;s original model of language learning from positive data, an iterative learner can be thought of as memory-limited. However, an iterative ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:y3d_62hDJLIJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12836458955819415499&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12836458955819415499&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/Q3641U74N61G1323.pdf</url>
        <title status="complete" source="scholar.google.com">Numberings optimal for learning</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2823/1/TRA8-08+-+Frank+Stephan+and+Sanjay+Jain.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper extends previous studies on learnability in non-acceptable numberings by considering the question: for which criteria which numberings are optimal, that is, for which numberings it holds that one can learn every learnable class using the given numbering ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:IUHpyvyqy04J:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>25</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5677819757943406881&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5677819757943406881&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=nEBfBghRSgsC&amp;oi=fnd&amp;pg=PA300&amp;ots=42d4reKsD9&amp;sig=8rBZacF3sgiNSRZE7wltRomkH_8</url>
        <title status="complete" source="scholar.google.com">Learning without Coding</title>
        <pdf>http://www.eecis.udel.edu/~moelius/publications/lwoc_tr.pdf</pdf>
        <author status="complete" source="scholar.google.com">SEM Iii, S Zilles</author>
        <proceeding status="partial" source="scholar.google.com">&#8230; , ALT 2010, Canberra, Australia, October 6-8, &#8230;</proceeding>
        <year>2010</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">Abstract. Iterative learning is a model of language learning from positive data, due to Wiehagen. When compared to a learner in Gold&#39;s original model of language learning from positive data, an iterative learner can be thought of as memory-limited. However, an ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:L2vGQFeWA-0J:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17078659513412119343&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.sciencedirect.com/science/article/pii/S0022000009000749</url>
        <title status="complete" source="scholar.google.com">Numberings optimal for learning</title>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2010</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">This paper extends previous studies on learnability in non-acceptable numberings by considering the question: for which criteria which numberings are optimal, that is, for which numberings it holds that one can learn every learnable class using the given numbering ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:41DjdY4aypgJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11009641438226108643&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11009641438226108643&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <title status="complete" source="scholar.google.com">Program self-reference</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.156.5672&amp;rep=rep1&amp;type=pdf</pdf>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:YxqD3ZnzbpwJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11272214759526832739&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397512009322</url>
        <title status="complete" source="scholar.google.com">Learning without coding</title>
        <author status="complete" source="scholar.google.com">S Jain, SE Moelius III, S Zilles</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Abstract Iterative learning is a model of language learning from positive data, due to Wiehagen. When compared to a learner in Gold&#39;s original model of language learning from positive data, an iterative learner can be thought of as memory-limited. However, an ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="148">
    <url>http://www.sciencedirect.com/science/article/pii/S0022000007000785</url>
    <title status="complete" source="scholar.google.com">Learning languages from positive data and negative counterexamples</title>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
    <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
    <year>2008</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... In both cases, a successful learner stabilizes on a correct description of the target language, *Corresponding author. E-mail addresses: sanjay@comp.nus.edu.sg (S. Jain), kinbere@sacredheart.edu (E. Kinber). 1 Supported in part by NUS grant No. R252-000-127-112. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:fqTRm8eJU3AJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>4</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=8093964445720618110&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>13</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=8093964445720618110&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="13">
        <result id="0">
        <url>http://www.springerlink.com/index/82329846173M8772.pdf</url>
        <title status="complete" source="scholar.google.com">One-shot learners using negative counterexamples and nearest positive examples</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2315/1/tra3-07.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">As some cognitive research suggests, in the process of learning languages, in addition to overt explicit negative evidence, a child often receives covert explicit evidence in form of corrected or rephrased sentences. In this paper, we suggest one approach to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:70f8Jtnk5nEJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>12</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8207498992242411503&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8207498992242411503&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540107000983</url>
        <title status="complete" source="scholar.google.com">Iterative learning from positive data and negative counterexamples</title>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A model for learning in the limit is defined where a (so-called iterative) learner gets all positive examples from the target language, tests every new conjecture with a teacher (oracle) if it is a subset of the target language (and if it is not, then it receives a negative ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:DfGaZ2CzXhUJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1539865349243728141&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1539865349243728141&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.tesisenred.net/bitstream/handle/10803/8792/Thesis.pdf</url>
        <title status="complete" source="scholar.google.com">Language Learning with Correction Queries</title>
        <pdf>http://www.tesisenred.net/bitstream/handle/10803/8792/Thesis.pdf</pdf>
        <author status="complete" source="scholar.google.com">C TËÄ±rnauca</author>
        <year>2009</year>
        <source>tesisenred.net</source>
        <snippet status="partial" source="scholar.google.com">I would not be here today if it was not for my dear friend and colleague Mihai Ionescu, who persuaded me to continue my studies and to enroll in a PhD program in Tarragona. Also, I would like to address my gratitude to my mother, first of all, for raising me the way she did, ...</snippet>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:kvw1EEn1D8AJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13839549874086214802&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/6813w3k86555t79h.pdf</url>
        <title status="complete" source="scholar.google.com">Iterative learning from texts and counterexamples using additional information</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2937/1/TRB4-09.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A variant of iterative learning in the limit (cf.[LZ96]) is studied when a learner gets negative examples refuting conjectures containing data in excess of the target language and uses additional information of the following four types: a) memorizing up to n input elements ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:m0uIqOprI_kJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17952311195222952859&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17952311195222952859&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.tdx.cat/handle/10803/8792</url>
        <title status="complete" source="scholar.google.com">Language learning with correction queries</title>
        <pdf>http://www.tdx.cat/bitstream/handle/10803/8792/Thesis.pdf.txt?sequence=2</pdf>
        <author status="complete" source="scholar.google.com">C Tirnauca</author>
        <year>2009</year>
        <source>tdx.cat</source>
        <snippet status="partial" source="scholar.google.com">In the field of grammatical inference, the goal of any learning algorithm is to identify a target concept from a given class by having access to a specific type of information. The main learning settings are Gold&#39;s model of learning in the limit and Angluin&#39;s query learning. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:vPYbLipk9tIJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15201447724560676540&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15201447724560676540&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.springerlink.com/index/RL2050457GU60010.pdf</url>
        <title status="complete" source="scholar.google.com">Iterative learning from positive data and negative counterexamples</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1918/1/TRA3-06.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A model for learning in the limit is defined where a (so-called iterative) learner gets all positive examples from the target language, tests every new conjecture with a teacher (oracle) if it is a subset of the target language (and if it is not, then it receives a negative ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:LnGoLrd_Ie4J:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>15</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17159136479996834094&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17159136479996834094&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397507006585</url>
        <title status="complete" source="scholar.google.com">Learning languages from positive data and a limited number of short counterexamples</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1899/1/TR21-05.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We consider two variants of a model for learning languages in the limit from positive data and a limited number of short negative counterexamples (counterexamples are considered to be short if they are smaller than the largest element of input seen so far). Negative ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:oTUPOOVeFnkJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8725265666657957281&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8725265666657957281&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/97285WVT37N48810.pdf</url>
        <title status="complete" source="scholar.google.com">On learning languages from positive data and a limited number of short counterexamples</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/bncfull.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. We consider two variants of a model for learning languages in the limit from positive data and a limited number of short negative counterexamples (counterexamples are considered to be short if they are smaller that the largest element of input seen so far). ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:y-Vc4Y2Mb7QJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13001765190241150411&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13001765190241150411&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.springerlink.com/index/V233X697X81081KW.pdf</url>
        <title status="complete" source="scholar.google.com">Automatic learning from positive data and negative counterexamples</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/autoncex.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2012</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We introduce and study a model for learning in the limit by finite automata from positive data and negative counterexamples. The focus is on learning classes of languages with a membership problem computable by finite automata (so-called automatic classes). We ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397509001674</url>
        <title status="complete" source="scholar.google.com">One-shot learners using negative counterexamples and nearest positive examples</title>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2009</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">As some cognitive research suggests, in the process of learning languages, in addition to overt explicit negative evidence, a child often receives covert explicit evidence in form of corrected or rephrased sentences. In this paper, we suggest one approach to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:r9OMYh_KopUJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10782402694024582063&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www.springerlink.com/index/X524068561K52072.pdf</url>
        <title status="complete" source="scholar.google.com">Iterative learning from texts and counterexamples using additional information</title>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Machine learning</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract A variant of iterative learning in the limit (cf. Lange and Zeugmann 1996) is studied when a learner gets negative examples refuting conjectures containing data in excess of the target language and uses additional information of the following four types:(a) memorizing ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:3qdCfFnTLTgJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4048124021366237150&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://www.eecis.udel.edu/~case/papers/pr2.pdf</url>
        <title status="complete" source="scholar.google.com">On the Necessity of U-Shaped Learning</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/pr2.pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case</author>
        <proceeding status="complete" source="scholar.google.com">eecis.udel.edu</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. A U-shaped curve in a cognitive-developmental trajectory refers to a three-step process: good performance followed by bad performance followed by good performance once again. U-shaped curves have been observed in a wide variety of cognitive- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17336137048815070431&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.118.7824&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">NEGATIVE DATA IN LEARNING LANGUAGES</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.118.7824&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S JAIN, E KINBER</author>
        <proceeding status="partial" source="scholar.google.com">Mathematical Logic in Asia: Proceedings of the 9th &#8230;</proceeding>
        <year>2006</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">The paper is a survey of recent results on algorithmic learning (inductive inference) of languages from full collection of positive examples and some negative data. Different types of negative data are considered. We primarily concentrate on learning using (1) carefully ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:xhc83r1kuQwJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:xhc83r1kuQwJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=916874765786683334&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="149">
    <url>http://www.sciencedirect.com/science/article/pii/S0304397510007656</url>
    <title status="complete" source="scholar.google.com">Uncountable automatic classes and learning</title>
    <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2896/1/TRB1-09.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, Q Luo, P Semukhin, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
    <year>2011</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... Such a sequence is called a text for the language. After reading Ã¢Ëâ Corresponding author.E-mail addresses: sanjay@comp.nus.edu.sg (S. Jain), qlluo@singnet.com.sg (Q. Luo),pavel@semukhin.name (P. Semukhin), fstephan@comp.nus.edu.sg (F. Stephan). ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:A3ovHOqvSVQJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>30</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=6073578992515906051&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>8</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=6073578992515906051&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="8">
        <result id="0">
        <url>http://dl.comp.nus.edu.sg/dspace/handle/1900.100/3112</url>
        <title status="complete" source="scholar.google.com">On automatic families</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/3112/1/TRB1-10.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, YS Ong, S Pu, F Stephan</author>
        <year>2010</year>
        <source>dl.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract: This paper summarises previous work on automatic families. It then investigates a natural measure which exists inside every automatic family: the size of a regular language in this family is just the length of its index. This measure satisfies various properties similar to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:8apC6ZMa79sJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>20</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15847914836316039921&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15847914836316039921&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/P142346471G1117R.pdf</url>
        <title status="complete" source="scholar.google.com">Learning figures with the hausdorff metric by fractals</title>
        <pdf>http://mahito.info/Files/Sugiyama_ALT2010.pdf</pdf>
        <author status="partial" source="scholar.google.com">M Sugiyama, E Hirowatari, H Tsuiki&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Algorithmic Learning &#8230;</proceeding>
        <year>2010</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Discretization is a fundamental process for machine learning from analog data such as continuous signals. For example, the discrete Fourier analysis is one of the most essential signal processing methods for learning or recognition from continuous signals. However, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:sWX3XHtrfVsJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6592543607125140913&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6592543607125140913&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>https://dspace.lboro.ac.uk/dspace/handle/2134/6458</url>
        <title status="complete" source="scholar.google.com">Inferring descriptive generalisations of formal languages</title>
        <pdf>https://dspace.lboro.ac.uk/dspace-jspui/bitstream/2134/6458/3/Freydenberger_Reidenbach_COLT_2010[1].pdf</pdf>
        <author status="complete" source="scholar.google.com">DD Freydenberger, D Reidenbach</author>
        <year>2010</year>
        <source>dspace.lboro.ac.uk</source>
        <snippet status="partial" source="scholar.google.com">In the present paper, we introduce a variant of Gold-style learners that is not required to infer precise descriptions of the languages in a class, but that must find descriptive patterns, ie, optimal generalisations within a class of pattern languages. Our first main result ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:y89Prha3ZOIJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16313365058284408779&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16313365058284408779&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540112001137</url>
        <title status="complete" source="scholar.google.com">Automatic learning of subclasses of pattern languages</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/autopat.pdf</pdf>
        <author status="partial" source="scholar.google.com">J Case, S Jain, TD Le, YS Ong, P Semukhin&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Information and &#8230;</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Automatic classes are classes of languages for which a finite automaton can decide the membership problem for the languages in the class, in a uniform way, given an index for the language. For alphabet size of at least 4, every automatic class of erasing pattern ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:h4T-C1MLkHMJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>17</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8327168162319467655&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8327168162319467655&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/371821UW3L4225G8.pdf</url>
        <title status="complete" source="scholar.google.com">Automatic learners with feedback queries</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/autofeednew.pdf</pdf>
        <author status="partial" source="scholar.google.com">J Case, S Jain, Y Ong, P Semukhin&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Models of Computation in &#8230;</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Automatic classes are classes of languages for which a finite automaton can decide whether a given element is in a set given by its index. The present work studies the learnability of automatic families by automatic learners which, in each round, output a hypothesis and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RXW6gzjPnq0J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12510664656516969797&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12510664656516969797&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=PZjcvI3LWWoC&amp;oi=fnd&amp;pg=PA1&amp;ots=RujHEJjBwx&amp;sig=ZprIP4InIbbhhAgXJ00PR6f2xCc</url>
        <title status="complete" source="scholar.google.com">Inclusion of pattern languages and related problems</title>
        <pdf>http://publikationen.ub.uni-frankfurt.de/frontdoor/deliver/index/docId/22351/file/dissertation.pdf</pdf>
        <author status="complete" source="scholar.google.com">DD Freydenberger</author>
        <year>2011</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">Pattern, dh endliche WÃ¶rter aus Variablen und Terminalsymbolen, stellen eine kompakte, elegante und natÃ¼rliche Methode dar, gewisse kontextsensitive Sprachen zu reprÃ¤sentieren. Ein Pattern erzeugt ein Wort durch eine Substitution, die alle Variablen im Pattern durch ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2qmJCHCGK18J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6857722673339410906&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.springerlink.com/index/H4H25161Q638L4N4.pdf</url>
        <title status="complete" source="scholar.google.com">Learning figures with the Hausdorff metric by fractalsâtowards computable binary classification</title>
        <pdf>http://mahito.info/Files/Sugiyama_MLJ01.pdf</pdf>
        <author status="complete" source="scholar.google.com">M Sugiyama, E Hirowatari, H Tsuiki, A Yamamoto</author>
        <proceeding status="complete" source="scholar.google.com">Machine Learning</proceeding>
        <year>2012</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract We present learning of figures, nonempty compact sets in Euclidean space, based on Gold&#39;s learning model aiming at a computable foundation for binary classification of multivariate data. Encoding real vectors with no numerical error requires infinite ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FAyQDaL5NyQJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2609828983492054036&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://mahito.info/Files/Sugiyama_PhDthesis.pdf</url>
        <title status="complete" source="scholar.google.com">Studies on Computational Learning via Discretization</title>
        <pdf>http://mahito.info/Files/Sugiyama_PhDthesis.pdf</pdf>
        <author status="complete" source="scholar.google.com">M Sugiyama</author>
        <year>2012</year>
        <source>mahito.info</source>
        <snippet status="partial" source="scholar.google.com">Abstract Thisthesispresentscutting-edgestudiesoncomputationallearning. Thekeyissue throughout the thesis is amalgamation of two processes; discretization of continuous objects and learning from such objects provided by data. Machine learning, or data mining and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:QKRXZUBQR78J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:QKRXZUBQR78J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13783073422099063872&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="150">
    <url>http://www.sciencedirect.com/science/article/pii/S0890540106000320</url>
    <title status="complete" source="scholar.google.com">Variations on U-shaped learning</title>
    <author status="complete" source="scholar.google.com">L Carlucci, S Jain, E Kinber, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
    <year>2006</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... Fax: +65 6779 4580. E-mail addresses: carlucci5@unisi.it (L. Carlucci), sanjay@comp.nus.edu.sg (S. Jain), kinbere@sacredheart.edu (E. Kinber), fstephan@comp.nus.edu.sg (F. Stephan). ...NSF CCR-0208616. 2 Supported in part by NUS Grant No. R252â000â127â112. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:29Nshv64fAAJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>4</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=35106300428604379&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>8</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=35106300428604379&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="8">
        <result id="0">
        <url>http://www.springerlink.com/index/prebbr91cb17uenx.pdf</url>
        <title status="complete" source="scholar.google.com">Unlearning helps</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2205/1/TRA5-06.pdf</pdf>
        <author status="complete" source="scholar.google.com">G Baliga, J Case, W Merkle, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">Automata, Languages and &#8230;</proceeding>
        <year>2000</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Overregularization seen in child language learning, re verb tense constructs, involves abandoning correct behaviors for incorrect ones and later reverting to correct behaviors. Quite a number of other child development phenomena also follow this U-shaped form of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Kz0TSnrOJQwJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>24</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=875332727217536299&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>20</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=875332727217536299&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540107000491</url>
        <title status="complete" source="scholar.google.com">Results on memory-limited U-shaped learning</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.8567&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">U-shaped learning is a learning behaviour in which the learner first learns a given target behaviour, then unlearns it and finally relearns it. Such a behaviour, observed by psychologists, for example, in the learning of past-tenses of English verbs, has been ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:aPOveNlKjhoJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>23</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1913549189572195176&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>21</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1913549189572195176&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540107001095</url>
        <title status="complete" source="scholar.google.com">When unlearning helps</title>
        <author status="partial" source="scholar.google.com">G Baliga, J Case, W Merkle, F Stephan&#8230;</author>
        <proceeding status="partial" source="scholar.google.com">Information and &#8230;</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Overregularization seen in child language learning, for example, verb tense constructs, involves abandoning correct behaviours for incorrect ones and later reverting to correct behaviours. Quite a number of other child development phenomena also follow this U- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:4FHwvqlchk8J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5730369459998183904&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>18</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5730369459998183904&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/AM7558R84445558T.pdf</url>
        <title status="complete" source="scholar.google.com">U-shaped, iterative, and iterative-with-counter learning</title>
        <author status="complete" source="scholar.google.com">J Case, SE Moelius</author>
        <proceeding status="complete" source="scholar.google.com">Machine Learning</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper solves an important problem left open in the literature by showing that U-shapes are unnecessary in iterative learning from positive data. A U-shape occurs when a learner first learns, then unlearns, and, finally, relearns, some target concept. Iterative ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:sZ5F-vPpsDUJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3868849313996447409&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>13</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=3868849313996447409&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540108000266</url>
        <title status="complete" source="scholar.google.com">Learning in Friedberg numberings</title>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In this paper we consider learnability in some special numberings, such as Friedberg numberings, which contain all the recursively enumerable languages, but have simpler grammar equivalence problem compared to acceptable numberings. We show that every ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Hq2mBjhdYAMJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=243296875089145118&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=243296875089145118&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.springerlink.com/index/D56708146217R601.pdf</url>
        <title status="complete" source="scholar.google.com">Learning in Friedberg numberings</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2613/1/TR11-07.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In this paper we consider learnability in some special numberings, such as Friedberg numberings, which contain all the recursively enumerable languages, but have simpler grammar equivalence problem compared to acceptable numberings. We show that every ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cLgmLVtjoKkJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>26</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12222878631934212208&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12222878631934212208&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.eecis.udel.edu/~case/papers/pr2.pdf</url>
        <title status="complete" source="scholar.google.com">On the Necessity of U-Shaped Learning</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/pr2.pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case</author>
        <proceeding status="complete" source="scholar.google.com">eecis.udel.edu</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. A U-shaped curve in a cognitive-developmental trajectory refers to a three-step process: good performance followed by bad performance followed by good performance once again. U-shaped curves have been observed in a wide variety of cognitive- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17336137048815070431&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397512009310</url>
        <title status="complete" source="scholar.google.com">Memory-limited non-U-shaped learning with solved open problems</title>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Herein we also distinguish between semantic and syntactic U-shapes. We answer a number of open questions in the prior literature as well as provide new results regarding syntactic U-shapes. Importantly for cognitive science, we see more of a previously noticed pattern ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="151">
    <url>http://www.jstor.org/stable/10.2307/2275402</url>
    <title status="complete" source="scholar.google.com">Machine learning of higher-order programs</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.103.5222&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">G Baliga, J Case, S Jain, M Suraj</author>
    <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
    <year>1994</year>
    <source>JSTOR</source>
    <snippet status="partial" source="scholar.google.com">Page 1. THE JOURNAL OF SYMBOLIC LOGIC Volume 59, Number 2, June 1994MACHINE LEARNING OF HIGHER-ORDER PROGRAMS GANESH BALIGA, JOHNCASE, SANJAY JAIN, AND MANDAYAM SURAJ Abstract. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:tK5KeAIyrjgJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>5</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=4084256898261102260&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>15</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=4084256898261102260&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="15">
        <result id="0">
        <url>http://epubs.siam.org/doi/pdf/10.1137/S0097539793249694</url>
        <title status="complete" source="scholar.google.com">The power of vacillation in language learning</title>
        <pdf>http://dare.uva.nl/document/1137</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">SIAM Journal on Computing</proceeding>
        <year>1999</year>
        <source>SIAM</source>
        <snippet status="partial" source="scholar.google.com">Some extensions are considered of Gold&#39;s influential model of language learning by machine from positive data. Studied are criteria of successful learning featuring convergence in the limit to vacillation between several alternative correct grammars. The ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:iB0Rc-7Qrq0J:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>23</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12515170137060482440&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>82</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12515170137060482440&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.25.5007&amp;rep=rep1&amp;type=pdf</url>
        <title status="complete" source="scholar.google.com">A limiting rst order realizability interpretation</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.25.5007&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">M Nakata, S Hayashi</author>
        <proceeding status="complete" source="scholar.google.com">SCMJ Online</proceeding>
        <year>2001</year>
        <source>Citeseer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. Constructive Mathematics might be regarded as a fragment of classical mathematics in which any proof of an existence theorem is equipped with a computable function giving the solution of the theorem. Limit Computable Mathematics (LCM) ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:fxCSabkZe8YJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:fxCSabkZe8YJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14302053325775966335&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>19</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14302053325775966335&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/78867137810P8066.pdf</url>
        <title status="complete" source="scholar.google.com">Learning with higher order additional information</title>
        <author status="complete" source="scholar.google.com">G Baliga, J Case</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1994</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">[Go167] studied, among other things, algorithmic learning (in the limit) of deci- sion procedures for languages given informants, ie, given enumerations of the characteristic functions of the languages. [FW79] shows that learning power is increased if, in addition to the informants, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:eFGnga8zZ4AJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9252420788343492984&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9252420788343492984&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/M10332H915246783.pdf</url>
        <title status="complete" source="scholar.google.com">On the classification of computable languages</title>
        <pdf>http://www.cis.udel.edu/~case/papers/classif.ps</pdf>
        <author status="complete" source="scholar.google.com">J Case, E Kinber, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">STACS 97</proceeding>
        <year>1997</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A one-sided classifier for a given class of languages converges to 1 on every language from the class and outputs 0 infinitely often on languages outside the class. A two-sided classifier, on the other hand, converges to 1 on languages from the class and converges to 0 on ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RuRE4B4a4IgJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9862911903855338566&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>12</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9862911903855338566&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/746143G84P1761X0.pdf</url>
        <title status="complete" source="scholar.google.com">Vacillatory and BC learning on noisy data</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.1104&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1996</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In an earlier paper, Frank Stephan introduced a form of noisy data which nonetheless uniquely determines the true data: correct information occurs infinitely often while incorrect information occurs only finitely often. The present paper considers the effects of this form ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:DwzAHopQyuMJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16414020346056805391&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16414020346056805391&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://dl.acm.org/citation.cfm?id=267512</url>
        <title status="complete" source="scholar.google.com">Inferring answers to queries</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.84.522&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">WI Gasarch, ACY Lee</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the tenth annual conference on &#8230;</proceeding>
        <year>1997</year>
        <source>dl.acm.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract The usual focus of recursion-theoretic inductive inference is to infer a program (resp. grammar) for a function f (resp. language A) from observations and/or queries about f (resp. A). We propose a new line of research which examines the question of inferring the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:UtJsPvltVj0J:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>17</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4419841001572323922&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>6</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=4419841001572323922&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397599002686</url>
        <title status="complete" source="scholar.google.com">Vacillatory and BC learning on noisy data</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2000</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present work employs a model of noise introduced earlier by the third author. In this model noisy data nonetheless uniquely determines the true data: correct information occurs infinitely often while incorrect information occurs only finitely often. The present paper ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:f2xw58_6_98J:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16140895360367225983&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16140895360367225983&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/l5p6329uk2633r03.pdf</url>
        <title status="complete" source="scholar.google.com">Directions for computability theory beyond pure mathematical</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/rft-directions.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Mathematical problems from applied logic II</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper begins by briefly indicating the principal, non-standard motivations of the author for his decades of work in Computability Theory (CT), aka Recursive Function Theory. Then it discusses its proposed, general directions beyond those from pure mathematics for CT. These ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:BWKg2uLmRxMJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1389332872072028677&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1389332872072028677&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.comp.nus.edu.sg/~sanjay/paps/parsh.pdf</url>
        <title status="complete" source="scholar.google.com">Machine induction without revolutionary changes in hypothesis size</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/parsh.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>1996</year>
        <source>comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper provides a beginning study of the effects on inductive inference of paradigm shifts whose absence is approximately modeled by various formal approaches to forbidding large changes in the size of programs conjectured. One approach, called ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:UBoOOrjlzAYJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:UBoOOrjlzAYJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=490019038887287376&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=490019038887287376&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://projecteuclid.org/euclid.jsl/1243948324</url>
        <title status="complete" source="scholar.google.com">Learning correction grammars</title>
        <pdf>https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2307/1/TR12-06.pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
        <year>2009</year>
        <source>projecteuclid.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract We investigate a new paradigm in the context of learning in the limit, namely, learning correction grammars for classes of computably enumerable (ce) languages. Knowing a language may feature a representation of it in terms of two grammars. The ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:0zSN0GENz58J:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11515437485971551443&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11515437485971551443&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540104000392</url>
        <title status="complete" source="scholar.google.com">On the classification of recursive languages</title>
        <author status="complete" source="scholar.google.com">J Case, E Kinber, A Sharma, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2004</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A one-sided classifier for a given class of languages converges to 1 on every language from the class and outputs 0 infinitely often on languages outside the class. A two-sided classifier, on the other hand, converges to 1 on languages from the class and converges to 0 on ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:PVNAR5fT1ogJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=9860301080863200061&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=9860301080863200061&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://www.sciencedirect.com/science/article/pii/S002200000700075X</url>
        <title status="complete" source="scholar.google.com">Inferring answers to queries</title>
        <author status="complete" source="scholar.google.com">WI Gasarch, ACY Lee</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
        <year>2008</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">One focus of inductive inference is to infer a program for a function f from observations or queries about f. We propose a new line of research which examines the question of inferring the answers to queries. For a given class of computable functions, we consider the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:lfpd7MA2YpkJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11052456637747821205&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11052456637747821205&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="12">
        <url>http://www.springerlink.com/index/P10132MM72722530.pdf</url>
        <title status="complete" source="scholar.google.com">Machine induction without revolutionary paradigm shifts</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain, A Sharma</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1995</year>
        <source>Springer</source>
        <snippet status="complete" source="scholar.google.com">This paper provides a beginning study of the effects on inductive inference of paradigm shifts whose absence is approximately modeled by various formal approaches to forbidding large changes in the size of programs conjectured.</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:xSMXOf0nWRcJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1682419904337617861&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="13">
        <title status="complete" source="scholar.google.com">Department of Computer and Information Sciences University of Delaware Newark, DE 19716, USA Email: case@ cis. udel. edu</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:XViiPr1RB8kJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="14">
        <title status="complete" source="scholar.google.com">Department of Computer and Information Sciences University of Delaware Newark, DE 19716, USA</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RLkDr-qUHr8J:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13771608446225070404&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="152">
    <url>http://epubs.siam.org/doi/pdf/10.1137/S0097539792239461</url>
    <title status="complete" source="scholar.google.com">Learning from multiple sources of inaccurate data</title>
    <author status="complete" source="scholar.google.com">G Baliga, S Jain, A Sharma</author>
    <proceeding status="complete" source="scholar.google.com">SIAM Journal on Computing</proceeding>
    <year>1997</year>
    <source>SIAM</source>
    <snippet status="partial" source="scholar.google.com">... 08024 (baliga@gboro.rowan.edu). â¡ Department of Information Systems and ComputerScience, National University of Singapore, Singapore, Republic of Singapore 119260(sanjay@iscs.nus.sg). Â§ School of Computer Science ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:2bqtl92062sJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>5</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=7776508045410810585&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>6</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=7776508045410810585&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="6">
        <result id="0">
        <url>http://www.springerlink.com/index/746143G84P1761X0.pdf</url>
        <title status="complete" source="scholar.google.com">Vacillatory and BC learning on noisy data</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.1104&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>1996</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In an earlier paper, Frank Stephan introduced a form of noisy data which nonetheless uniquely determines the true data: correct information occurs infinitely often while incorrect information occurs only finitely often. The present paper considers the effects of this form ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:DwzAHopQyuMJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>18</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16414020346056805391&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>9</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16414020346056805391&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397599002686</url>
        <title status="complete" source="scholar.google.com">Vacillatory and BC learning on noisy data</title>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical computer science</proceeding>
        <year>2000</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">The present work employs a model of noise introduced earlier by the third author. In this model noisy data nonetheless uniquely determines the true data: correct information occurs infinitely often while incorrect information occurs only finitely often. The present paper ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:f2xw58_6_98J:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16140895360367225983&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16140895360367225983&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>ftp://www.netlib.no/netlib/bibnet/journals/siamjcomput.pdf.gz</url>
        <title status="complete" source="scholar.google.com">A Bibliography of Publications in SIAM Journal on Computing</title>
        <pdf>ftp://www.netlib.no/netlib/bibnet/journals/siamjcomput.pdf.gz</pdf>
        <author status="complete" source="scholar.google.com">NHF Beebe</author>
        <year>2004</year>
        <source>netlib.no</source>
        <snippet status="partial" source="scholar.google.com">[BG96] Dario Bini and Luca Gemignani. Erratum:âFast parallel computation of the polynomial remainder sequence via BÃ©zout and Hankel matricesâ[SIAM J. Comput. 24 (1995), no. 1, 63â77, MR 95j: 65048]. SIAM Journal on Computing, 25 (6): 1358, December 1996. CODEN ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:oJYqSAY0EeAJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:oJYqSAY0EeAJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>70</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16145743340685137568&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://193.137.214.36/software/math/netlib/bibnet/journals/siamjcomput.pdf.gz</url>
        <title status="complete" source="scholar.google.com">A Complete Bibliography of Publications in SIAM Journal on Computing</title>
        <pdf>http://193.137.214.36/software/math/netlib/bibnet/journals/siamjcomput.pdf.gz</pdf>
        <author status="complete" source="scholar.google.com">NHF Beebe</author>
        <year>2012</year>
        <source>193.137.214.36</source>
        <snippet status="partial" source="scholar.google.com">[BG96] Dario Bini and Luca Gemignani. Erratum:âFast parallel computation of the polynomial remainder sequence via BÃ©zout and Hankel matricesâ[SIAM J. Comput. 24 (1995), no. 1, 63â77, MR 95j: 65048]. SIAM Journal on Computing, 25 (6): 1358, December 1996. CODEN ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:kxJQi2innDMJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:kxJQi2innDMJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>83</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=3719031459756905107&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://i.yz.yamagata-u.ac.jp/paper/inoue03doctor_thesis_web.pdf</url>
        <title status="complete" source="scholar.google.com">Statistical learning from multiple information sources</title>
        <pdf>http://i.yz.yamagata-u.ac.jp/paper/inoue03doctor_thesis_web.pdf</pdf>
        <author status="complete" source="scholar.google.com">M Inoue</author>
        <year>2004</year>
        <source>i.yz.yamagata-u.ac.jp</source>
        <snippet status="partial" source="scholar.google.com">Abstract In intelligent information processing tasks such as pattern recognition and information retrieval (IR), probabilistic models are now widely used because they can represent ambiguities of observed data and are robust against noises. Parameters of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ZDvF75IFYJ4J:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:ZDvF75IFYJ4J:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11412127584402881380&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.springerlink.com/index/D891256047178X85.pdf</url>
        <title status="complete" source="scholar.google.com">Learning from streams</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.157.1225&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan, N Ye</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Learning from streams is a process in which a group of learners separately obtain information about the target to be learned, but they can communicate with each other in order to learn the target. We are interested in machine models for learning from streams ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1jKd9b4XsWYJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>22</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7399721771678380758&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="153">
    <url>http://www.sciencedirect.com/science/article/pii/S0890540105001616</url>
    <title status="complete" source="scholar.google.com">Learning languages from positive data and a finite number of queries</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.90.3248&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
    <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
    <year>2006</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... Corresponding author. Fax: +65 6779 4580. E-mailaddresses: sanjay@comp.nus.edu.sg (S.Jain), kinbere@sacredheart.edu (E. Kinber). 1 This work was supported in part by NUS GrantNo. R252-000-127-112. 0890-5401/$ - see front matter Â© 2005 Elsevier Inc. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:FzZ78mu49FgJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>7</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=6409950943424230935&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>11</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=6409950943424230935&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="11">
        <result id="0">
        <url>http://www.springerlink.com/index/x8jvrne9hhf37f3y.pdf</url>
        <title status="complete" source="scholar.google.com">Learning languages from positive data and a finite number of queries</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.104.362&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="partial" source="scholar.google.com">FSTTCS 2004: Foundations of Software Technology &#8230;</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A computational model for learning languages in the limit from full positive data and a bounded number of queries to the teacher (oracle) is introduced and explored. Equivalence, superset, and subset queries are considered. If the answer is negative, the teacher may ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:uaRWKzH8L68J:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12623585568653485241&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12623585568653485241&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540107000983</url>
        <title status="complete" source="scholar.google.com">Iterative learning from positive data and negative counterexamples</title>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">A model for learning in the limit is defined where a (so-called iterative) learner gets all positive examples from the target language, tests every new conjecture with a teacher (oracle) if it is a subset of the target language (and if it is not, then it receives a negative ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:DfGaZ2CzXhUJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1539865349243728141&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1539865349243728141&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/9406440M16X31MP7.pdf</url>
        <title status="complete" source="scholar.google.com">Generalizing over several learning settings</title>
        <pdf>http://www.informatik.uni-trier.de/~kasprzik/genmalgo.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Kasprzik</author>
        <proceeding status="partial" source="scholar.google.com">Grammatical Inference: Theoretical Results and &#8230;</proceeding>
        <year>2010</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We recapitulate inference from membership and equivalence queries, positive and negative samples. Regular languages cannot be learned from one of those information sources only [1, 2, 3]. Combinations of two sources allowing regular (polynomial) inference are MQs ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ciNsnoXvwW8J:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8052980965882733426&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8052980965882733426&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.informatik.uni-trier.de/~kasprzik/KasprzikDiss.pdf</url>
        <title status="complete" source="scholar.google.com">Formal tree languages and their algorithmic learnability</title>
        <pdf>http://www.informatik.uni-trier.de/~kasprzik/KasprzikDiss.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Kasprzik</author>
        <year>2011</year>
        <source>informatik.uni-trier.de</source>
        <snippet status="partial" source="scholar.google.com">Abstract This thesis centers on formal tree languages and on their learnability by algorithmic methods in abstractions of several learning settings. After a general introduction (Chapter 1), we present a survey of relevant definitions for the formal tree concept as well as special ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:XUrGPQUipE4J:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:XUrGPQUipE4J:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5666691637045512797&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5666691637045512797&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/RL2050457GU60010.pdf</url>
        <title status="complete" source="scholar.google.com">Iterative learning from positive data and negative counterexamples</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1918/1/TRA3-06.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A model for learning in the limit is defined where a (so-called iterative) learner gets all positive examples from the target language, tests every new conjecture with a teacher (oracle) if it is a subset of the target language (and if it is not, then it receives a negative ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:LnGoLrd_Ie4J:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>15</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17159136479996834094&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17159136479996834094&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397507006585</url>
        <title status="complete" source="scholar.google.com">Learning languages from positive data and a limited number of short counterexamples</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1899/1/TR21-05.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We consider two variants of a model for learning languages in the limit from positive data and a limited number of short negative counterexamples (counterexamples are considered to be short if they are smaller than the largest element of input seen so far). Negative ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:oTUPOOVeFnkJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8725265666657957281&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8725265666657957281&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <title status="complete" source="scholar.google.com">Meta-Algorithm GENMODEL: Generalizing over three learning settings using observation tables</title>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:t3h93fDd9-MJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16426842192435050679&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://www.springerlink.com/index/97285WVT37N48810.pdf</url>
        <title status="complete" source="scholar.google.com">On learning languages from positive data and a limited number of short counterexamples</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/bncfull.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. We consider two variants of a model for learning languages in the limit from positive data and a limited number of short negative counterexamples (counterexamples are considered to be short if they are smaller that the largest element of input seen so far). ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:y-Vc4Y2Mb7QJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13001765190241150411&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13001765190241150411&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.informatik.uni-trier.de/~kasprzik/genmultiC.pdf</url>
        <title status="complete" source="scholar.google.com">Polynomial learning of regular multi-dimensional tree languages in different settings: A meta-algorithm/a unified perspective</title>
        <pdf>http://www.informatik.uni-trier.de/~kasprzik/genmultiC.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Kasprzik</author>
        <proceeding status="complete" source="scholar.google.com">informatik.uni-trier.de</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. We recapitulate regular inference from membership and equivalence queries, positive and negative finite samples. We present a metaalgorithm which generalizes over as many settings involving one or more of those information sources as possible and covers ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:g7whWBtsbRsJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:g7whWBtsbRsJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1976354676184038531&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://www.irisa.fr/s4/wg22/phd/RECENT/IdentSynth.pdf</url>
        <title status="complete" source="scholar.google.com">Model Identification and Synthesis of Discrete-Event Systems</title>
        <pdf>http://www.irisa.fr/s4/wg22/phd/RECENT/IdentSynth.pdf</pdf>
        <author status="complete" source="scholar.google.com">MP Cabasino, P Darondeau, MP Fanti, C Seatzu</author>
        <proceeding status="complete" source="scholar.google.com">irisa.fr</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract This chapter focuses on two important and tightly related problems, namely the identification and synthesis of discrete-event systems. Particular attention is devoted to two main formalisms in this area, ie, finite state automata and Petri nets. The goal of this ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:qDs33p6VuQ0J:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:qDs33p6VuQ0J:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://ubt.opus.hbz-nrw.de/volltexte/2012/737/</url>
        <title status="partial" source="scholar.google.com">Formal tree languages and their algorithmic learnability Formal tree languages and their algorithmic learnability Formale Baumsprachen und ihre Lernbarkeit mittels &#8230;</title>
        <pdf>http://ubt.opus.hbz-nrw.de/volltexte/2012/737/pdf/KasprzikDiss.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Kasprzik</author>
        <year>2011</year>
        <source>ubt.opus.hbz-nrw.de</source>
        <snippet status="partial" source="scholar.google.com">Abstract This thesis centers on formal tree languages and on their learnability by algorithmic methods in abstractions of several learning settings. After a general introduction (Chapter 1), we present a survey of relevant definitions for the formal tree concept as well as special ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RVo3_2YrNw8J:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="154">
    <url>http://www.springerlink.com/index/2e9yk3herkaudm15.pdf</url>
    <title status="complete" source="scholar.google.com">On Learning to Coordinate</title>
    <author status="complete" source="scholar.google.com">J Case, S Jain, F Montagna, G Simi, A Sorbi</author>
    <proceeding status="partial" source="scholar.google.com">Learning Theory and Kernel &#8230;</proceeding>
    <year>2003</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1 Department of Computer and Information Sciences University of Delaware, Newark, DE19716-2586 (USA) case@cis.udel.edu 2 School of Computing National University of Singapore,Singapore 117543, Republic of Singapore sanjay@comp.nus.edu.sg 3 Dipartimento di ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:5qBDtcPhVL8J:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>2</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=13786892589963911398&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>2</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=13786892589963911398&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="2">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540112001411</url>
        <title status="complete" source="scholar.google.com">Learning Secrets Interactively Dynamic Modeling in Inductive Inference</title>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Introduced is a new inductive inference paradigm, dynamic modeling. Within this learning paradigm, for example, function h learns function g iff, in the i-th iteration, h and g both produce output, h gets the sequence of all outputs from g in prior iterations as input, g gets ...</snippet>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/J0W128K65840063R.pdf</url>
        <title status="complete" source="scholar.google.com">Learning via finitely many queries</title>
        <pdf>http://rutcor.rutgers.edu/~amai/aimath04/AcceptedPapers/Lee-aimath04.pdf</pdf>
        <author status="complete" source="scholar.google.com">AC Lee</author>
        <proceeding status="complete" source="scholar.google.com">Annals of Mathematics and Artificial Intelligence</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This work introduces a new query inference model that can access data and communicate with the teacher by asking finitely many Boolean queries in a language L. In this model the parameters of interest are the number of queries used and the expressive power of L. We ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:j_c9uEG18zwJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4392053355484936079&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="155">
    <url>http://projecteuclid.org/euclid.jsl/1080938842</url>
    <title status="complete" source="scholar.google.com">Parsimony hierarchies for inductive inference</title>
    <pdf>http://pdf.aminer.org/002/865/517/parsimony_hierarchies_for_inductive_inference.pdf</pdf>
    <author status="complete" source="scholar.google.com">A Ambainis, J Case, S Jain, M Suraj</author>
    <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
    <year>2004</year>
    <source>projecteuclid.org</source>
    <snippet status="partial" source="scholar.google.com">... Grant support was received by A. Ambainis from Latvian Science Council Grant 01.0354, J. Casefrom NSF grant CCR-0208616, and by S. Jain from NUS grant R252-000-127-112. c 2004,Association for Symbolic Logic 0022-4812/04/6901-0023/$5.10 287 Page 2. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:PPOiazrZf9IJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>11</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=15168080914944291644&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>12</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=15168080914944291644&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="12">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397505006468</url>
        <title status="complete" source="scholar.google.com">Mathematics based on incremental learningâExcluded middle and inductive inference</title>
        <author status="complete" source="scholar.google.com">S Hayashi</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2006</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">Learning theoretic aspects of mathematics and logic have been studied by many authors. They study how mathematical and logical objects are algorithmically âlearnedâ(inferred) from finite data. Although they study mathematical objects, the objective of the studies is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FcUj6KHpAfAJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17294360925673080085&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>19</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17294360925673080085&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/Y1537725320743Q1.pdf</url>
        <title status="complete" source="scholar.google.com">Dynamically delayed postdictive completeness and consistency in learning</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/PcpPcsDelayTR.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2008</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In computational function learning in the limit, an algorithmic learner tries to find a program for a computable function g given successively more values of g, each time outputting a conjectured program for g. A learner is called postdictively complete iff all available data is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:7IuxNDCJ05gJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>14</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11012296353986481132&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11012296353986481132&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=fIPs5l1jjX8C&amp;oi=fnd&amp;pg=PA1&amp;ots=tULKAFzBXV&amp;sig=bCzThpv_ryVpntcYYlKQ7TqGuzY</url>
        <title status="complete" source="scholar.google.com">Noncomputable spectral sets</title>
        <pdf>http://arxiv.org/pdf/math/0701904</pdf>
        <author status="complete" source="scholar.google.com">J Teutsch</author>
        <year>2007</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">Suppose, however, the programmer would be satisfied to know just whether or not her program is minimal up to finitely many errors. In this case, even the jument-numen is helpless: something much stronger is needed. Just as we can associate equality with the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:AfsORm7mcPEJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>11</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17397658721828403969&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17397658721828403969&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://dl.comp.nus.edu.sg/dspace/handle/1900.100/3042</url>
        <title status="complete" source="scholar.google.com">Turing degrees and the Ershov hierarchy</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/3042/1/TRC6-09.pdf</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, Y Yang, L Yu</author>
        <year>2009</year>
        <source>dl.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract: An nr. e. set can be defined as the symmetric difference of n recursively enumerable sets. The classes of these sets form a natural hierarchy which became a well-studied topic in recursion theory. In a series of ground-breaking papers, Ershov ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:dsqImiE0SQYJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>22</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=452950556458666614&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=452950556458666614&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.springerlink.com/index/51R88P473336HU02.pdf</url>
        <title status="complete" source="scholar.google.com">Feasible iteration of feasible learning functionals</title>
        <pdf>http://cs5235.userapi.com/u133638729/docs/ceb9e6352614/Marcus_Hutter_Algorithmic_Learning_Theory_18_co.pdf#page=45</pdf>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing, T Paddock</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">For learning functions in the limit, an algorithmic learner obtains successively more data about a function and calculates trials each resulting in the output of a corresponding program, where, hopefully, these programs eventually converge to a correct program for ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:4nPXyisn9PIJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17506660720536155106&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17506660720536155106&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://www.springerlink.com/index/l5p6329uk2633r03.pdf</url>
        <title status="complete" source="scholar.google.com">Directions for computability theory beyond pure mathematical</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/rft-directions.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Mathematical problems from applied logic II</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper begins by briefly indicating the principal, non-standard motivations of the author for his decades of work in Computability Theory (CT), aka Recursive Function Theory. Then it discusses its proposed, general directions beyond those from pure mathematics for CT. These ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:BWKg2uLmRxMJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1389332872072028677&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1389332872072028677&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="6">
        <url>http://www.springerlink.com/index/3u7121w65176281t.pdf</url>
        <title status="complete" source="scholar.google.com">Learning correction grammars</title>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We investigate a new paradigm in the context of learning in the limit: learning correction grammars for classes of re languages. Knowing a language may feature a representation of the target language in terms of two sets of rules (two grammars). The second grammar is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:WspX_CCq1PEJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17425739916852578906&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17425739916852578906&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="7">
        <url>http://projecteuclid.org/euclid.jsl/1243948324</url>
        <title status="complete" source="scholar.google.com">Learning correction grammars</title>
        <pdf>https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2307/1/TR12-06.pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
        <year>2009</year>
        <source>projecteuclid.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract We investigate a new paradigm in the context of learning in the limit, namely, learning correction grammars for classes of computably enumerable (ce) languages. Knowing a language may feature a representation of it in terms of two grammars. The ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:0zSN0GENz58J:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11515437485971551443&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11515437485971551443&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="8">
        <url>http://www.springerlink.com/index/12017035066353VR.pdf</url>
        <title status="complete" source="scholar.google.com">Resource Restricted Computability Theoretic Learning: Illustrative Topics and Problems</title>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Computation and Logic in the Real World</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Computability theoretic learning theory (machine inductive inference) typically involves learning programs for languages or functions from a stream of complete data about them and, importantly, allows mind changes as to conjectured programs. This theory takes into ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MIjRDNBNqiIJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2497894499293956144&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="9">
        <url>http://onlinelibrary.wiley.com/doi/10.1002/malq.201020054/full</url>
        <title status="complete" source="scholar.google.com">Rice and RiceâShapiro Theorems for transfinite correction grammars</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/rice.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Mathematical Logic Quarterly</proceeding>
        <year>2011</year>
        <source>Wiley Online Library</source>
        <snippet status="partial" source="scholar.google.com">Abstract Hay and, then, Johnson extended the classic Rice and Rice-Shapiro Theorems for computably enumerable sets, to analogs for all the higher levels in the finite Ershov Hierarchy. The present paper extends their work (with some motivations presented) to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:EuckXGHSWuIJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16310580316075255570&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="10">
        <url>http://www.springerlink.com/index/812361171q2264pu.pdf</url>
        <title status="complete" source="scholar.google.com">Resource Restricted Computability Theoretic Learning: Illustrative Topics and Problems</title>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Theory of Computing Systems</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract Computability theoretic learning theory (machine inductive inference) typically involves learning programs for languages or functions from a stream of complete data about them and, importantly, allows mind changes as to conjectured programs. This theory takes ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cNGIg7j_YKkJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12205036158119891312&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="11">
        <url>http://people.cs.uchicago.edu/~teutsch/research_statement.pdf</url>
        <title status="complete" source="scholar.google.com">Penn State University</title>
        <pdf>http://people.cs.uchicago.edu/~teutsch/research_statement.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Teutsch</author>
        <year>2012</year>
        <source>people.cs.uchicago.edu</source>
        <snippet status="partial" source="scholar.google.com">Summary My current research in mathematics and computer science explores the interaction between combinatorics, game theory, and computation, often with an eye towards applications in information security. I am interested in the power of language and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ix3owLh9Yx8J:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:ix3owLh9Yx8J:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="156">
    <url>http://www.sciencedirect.com/science/article/pii/S0890540107000740</url>
    <title status="complete" source="scholar.google.com">Some natural conditions on incremental learning</title>
    <pdf>http://www2.cs.uregina.ca/~zilles/jainLZ07incremental.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, S Lange, S Zilles</author>
    <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
    <year>2007</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... [4], Gennari et al. [5], Kinber and Stephan [7], Lange â Corresponding author. E-mail addresses:sanjay@comp.nus.edu.sg (S. Jain), s.lange@fbi.h-da.de (S. Lange), zilles@cs.ualberta.ca(S. Zilles). 1 Sanjay Jain was supported in part by NUS Grant Nos. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:fy0ckG0INFYJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>7</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=6211599052712979839&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>2</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=6211599052712979839&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="2">
        <result id="0">
        <url>http://pdf.aminer.org/000/311/170/a_unified_algorithm_for_extending_classes_of_languages_identifiable_in.pdf</url>
        <title status="complete" source="scholar.google.com">String extension learning</title>
        <pdf>http://pdf.aminer.org/000/311/170/a_unified_algorithm_for_extending_classes_of_languages_identifiable_in.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Heinz</author>
        <proceeding status="partial" source="scholar.google.com">Proceedings of the 48th annual meeting of the &#8230;</proceeding>
        <year>2010</year>
        <source>pdf.aminer.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract This paper defines a collection of functions which define classes of languages, which have the property that they are identifiable in the limit from positive data from a very simple kind of learner. Furthermore these learners are always incremental, maximally ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:YxW_ul8db8sJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:YxW_ul8db8sJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>13</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14658967609106437475&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>19</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14658967609106437475&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397512007128</url>
        <title status="complete" source="scholar.google.com">Learning in the limit with lattice-structured hypothesis spaces</title>
        <author status="complete" source="scholar.google.com">J Heinz, A Kasprzik, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2012</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We define a collection of language classes which are TxtEx-learnable (learnable in the limit from positive data). The learners map any data input to an element of a fixed lattice, and keep the least upper bound of all lattice elements thus obtained as the current hypothesis. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ZwsP5kjqVmoJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7662569414835768167&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="157">
    <url>http://www.sciencedirect.com/science/article/pii/S0890540110002026</url>
    <title status="complete" source="scholar.google.com">Hypothesis spaces for learning</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/hypdep.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain</author>
    <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
    <year>2011</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... Learning of one language is usually not much interesting, as some learner, which always outputsthe grammar for E-mail address: sanjay@comp.nus.edu.sg 1 Supported in part by NUS GrantNo. R252-000-308-112. 0890-5401/$ - see front matter ? 2010 Elsevier Inc. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:nE03dzw6FbIJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>9</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=12832226744634658204&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>5</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=12832226744634658204&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="5">
        <result id="0">
        <url>http://www.informatik.uni-trier.de/~kasprzik/KasprzikDiss.pdf</url>
        <title status="complete" source="scholar.google.com">Formal tree languages and their algorithmic learnability</title>
        <pdf>http://www.informatik.uni-trier.de/~kasprzik/KasprzikDiss.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Kasprzik</author>
        <year>2011</year>
        <source>informatik.uni-trier.de</source>
        <snippet status="partial" source="scholar.google.com">Abstract This thesis centers on formal tree languages and on their learnability by algorithmic methods in abstractions of several learning settings. After a general introduction (Chapter 1), we present a survey of relevant definitions for the formal tree concept as well as special ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:XUrGPQUipE4J:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:XUrGPQUipE4J:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=5666691637045512797&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=5666691637045512797&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/H4H25161Q638L4N4.pdf</url>
        <title status="complete" source="scholar.google.com">Learning figures with the Hausdorff metric by fractalsâtowards computable binary classification</title>
        <pdf>http://mahito.info/Files/Sugiyama_MLJ01.pdf</pdf>
        <author status="complete" source="scholar.google.com">M Sugiyama, E Hirowatari, H Tsuiki, A Yamamoto</author>
        <proceeding status="complete" source="scholar.google.com">Machine Learning</proceeding>
        <year>2012</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract We present learning of figures, nonempty compact sets in Euclidean space, based on Gold&#39;s learning model aiming at a computable foundation for binary classification of multivariate data. Encoding real vectors with no numerical error requires infinite ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FAyQDaL5NyQJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2609828983492054036&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://mahito.info/Files/Sugiyama_PhDthesis.pdf</url>
        <title status="complete" source="scholar.google.com">Studies on Computational Learning via Discretization</title>
        <pdf>http://mahito.info/Files/Sugiyama_PhDthesis.pdf</pdf>
        <author status="complete" source="scholar.google.com">M Sugiyama</author>
        <year>2012</year>
        <source>mahito.info</source>
        <snippet status="partial" source="scholar.google.com">Abstract Thisthesispresentscutting-edgestudiesoncomputationallearning. Thekeyissue throughout the thesis is amalgamation of two processes; discretization of continuous objects and learning from such objects provided by data. Machine learning, or data mining and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:QKRXZUBQR78J:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:QKRXZUBQR78J:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13783073422099063872&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www-test.comp.nus.edu.sg/~fstephan/krtlearn.ps</url>
        <title status="complete" source="scholar.google.com">Effectivity Questions for Kleene&#39;s Recursion Theorem</title>
        <pdf>http://www-test.comp.nus.edu.sg/~fstephan/krtlearn.ps</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">www-test.comp.nus.edu.sg</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. The present paper explores the interaction between two recursion-theoretic notions: program self-reference and learning partial recursive functions in the limit. Kleene&#39;s Recursion Theorem formalises the notion of program self-reference: It says that given a ...</snippet>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:SQJ83x5mChcJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://ubt.opus.hbz-nrw.de/volltexte/2012/737/</url>
        <title status="partial" source="scholar.google.com">Formal tree languages and their algorithmic learnability Formal tree languages and their algorithmic learnability Formale Baumsprachen und ihre Lernbarkeit mittels &#8230;</title>
        <pdf>http://ubt.opus.hbz-nrw.de/volltexte/2012/737/pdf/KasprzikDiss.pdf</pdf>
        <author status="complete" source="scholar.google.com">A Kasprzik</author>
        <year>2011</year>
        <source>ubt.opus.hbz-nrw.de</source>
        <snippet status="partial" source="scholar.google.com">Abstract This thesis centers on formal tree languages and on their learnability by algorithmic methods in abstractions of several learning settings. After a general introduction (Chapter 1), we present a survey of relevant definitions for the formal tree concept as well as special ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:RVo3_2YrNw8J:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="158">
    <url>http://www.sciencedirect.com/science/article/pii/S030439750700549X</url>
    <title status="complete" source="scholar.google.com">A general comparison of language learning from examples and from queries</title>
    <pdf>http://pdf.aminer.org/000/235/383/inductive_learning_of_recurrence_term_languages_from_positive_data.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, S Lange, S Zilles</author>
    <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
    <year>2007</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... concept. These hypotheses are built upon instances of the target concept âCorresponding author. E-mail addresses: sanjay@comp.nus.edu.sg (S. Jain),s.lange@fbi.h-da.de (S. Lange), zilles@cs.ualberta.ca (S. Zilles). 0304 ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:KrySs3uRs9AJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>9</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=15038523541199961130&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>5</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=15038523541199961130&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="5">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0890540110002026</url>
        <title status="complete" source="scholar.google.com">Hypothesis spaces for learning</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/hypdep.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
        <year>2011</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In this paper we survey some results in inductive inference showing how learnability of a class of languages may depend on the hypothesis space chosen. Additionally, optimal hypothesis spaces, usable for every learnable class, are considered. We also discuss ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:nE03dzw6FbIJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12832226744634658204&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>5</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=12832226744634658204&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.tesisenred.net/bitstream/handle/10803/8792/Thesis.pdf</url>
        <title status="complete" source="scholar.google.com">Language Learning with Correction Queries</title>
        <pdf>http://www.tesisenred.net/bitstream/handle/10803/8792/Thesis.pdf</pdf>
        <author status="complete" source="scholar.google.com">C TËÄ±rnauca</author>
        <year>2009</year>
        <source>tesisenred.net</source>
        <snippet status="partial" source="scholar.google.com">I would not be here today if it was not for my dear friend and colleague Mihai Ionescu, who persuaded me to continue my studies and to enroll in a PhD program in Tarragona. Also, I would like to address my gratitude to my mother, first of all, for raising me the way she did, ...</snippet>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:kvw1EEn1D8AJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13839549874086214802&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397509006318</url>
        <title status="complete" source="scholar.google.com">Necessary and sufficient conditions for learning with correction queries</title>
        <author status="complete" source="scholar.google.com">C TÃ®rnÄucÄ, S Kobayashi</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2009</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We investigate the newly introduced model of learning with correction queries in the context of query learning. We present necessary and sufficient conditions for a class of languages to be inferable within this setting. We also offer a complete picture of how is the model of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:KfPGJVWwbwoJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=752013542546666281&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>2</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=752013542546666281&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.tdx.cat/handle/10803/8792</url>
        <title status="complete" source="scholar.google.com">Language learning with correction queries</title>
        <pdf>http://www.tdx.cat/bitstream/handle/10803/8792/Thesis.pdf.txt?sequence=2</pdf>
        <author status="complete" source="scholar.google.com">C Tirnauca</author>
        <year>2009</year>
        <source>tdx.cat</source>
        <snippet status="partial" source="scholar.google.com">In the field of grammatical inference, the goal of any learning algorithm is to identify a target concept from a given class by having access to a specific type of information. The main learning settings are Gold&#39;s model of learning in the limit and Angluin&#39;s query learning. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:vPYbLipk9tIJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15201447724560676540&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15201447724560676540&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397509001674</url>
        <title status="complete" source="scholar.google.com">One-shot learners using negative counterexamples and nearest positive examples</title>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2009</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">As some cognitive research suggests, in the process of learning languages, in addition to overt explicit negative evidence, a child often receives covert explicit evidence in form of corrected or rephrased sentences. In this paper, we suggest one approach to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:r9OMYh_KopUJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10782402694024582063&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="159">
    <url>http://www.sciencedirect.com/science/article/pii/S0022000010001030</url>
    <title status="complete" source="scholar.google.com">Index sets and universal numberings</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/numberings.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, F Stephan, J Teutsch</author>
    <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
    <year>2011</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... In the present work, partial answers are obtained: on one hand, if the numbering ÃË is a KolmogorovThis research was supported in part by NUS grant numbers R252-000-212-112 (all authors),R252-000-308-112 (S. Jain and F. Stephan) and R146-000- 4-112 (F. Stephan ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:cT7EhZyVHq4J:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>20</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=12546630111392448113&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>3</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=12546630111392448113&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="3">
        <result id="0">
        <url>http://arxiv.org/abs/1208.0682</url>
        <title status="complete" source="scholar.google.com">Things that can be made into themselves</title>
        <pdf>http://arxiv.org/pdf/1208.0682</pdf>
        <author status="complete" source="scholar.google.com">F Stephan, J Teutsch</author>
        <proceeding status="complete" source="scholar.google.com">arXiv preprint arXiv:1208.0682</proceeding>
        <year>2012</year>
        <source>arxiv.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract: We investigate which classes of sets have numberings in which the index set of the left-re members of the class is itself a member of the class. For example, the Martin-L\&quot; of random sets can be made into themselves. Furthermore we characterize the left-re sets ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ROipzEzVDQcJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=508296858790651972&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=508296858790651972&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/GV753PN418354057.pdf</url>
        <title status="complete" source="scholar.google.com">Characteristics of minimal effective programming systems</title>
        <pdf>http://arxiv.org/pdf/1204.1372</pdf>
        <author status="complete" source="scholar.google.com">S Moelius</author>
        <proceeding status="complete" source="scholar.google.com">How the World Computes</proceeding>
        <year>2012</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The Rogers semilattice of effective programming systems (eps es) is the collection of all effective numberings of the partial computable functions ordered such that Î¸â¤ Ï whenever Î¸-programs can be algorithmically translated into Ï-programs. Herein, it is shown that an ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:g0BGGdSd9WwJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7851355059672989827&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://people.cs.uchicago.edu/~teutsch/research_statement.pdf</url>
        <title status="complete" source="scholar.google.com">Penn State University</title>
        <pdf>http://people.cs.uchicago.edu/~teutsch/research_statement.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Teutsch</author>
        <year>2012</year>
        <source>people.cs.uchicago.edu</source>
        <snippet status="partial" source="scholar.google.com">Summary My current research in mathematics and computer science explores the interaction between combinatorics, game theory, and computation, often with an eye towards applications in information security. I am interested in the power of language and ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ix3owLh9Yx8J:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:ix3owLh9Yx8J:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="160">
    <url>http://www.sciencedirect.com/science/article/pii/S0304397508001515</url>
    <title status="complete" source="scholar.google.com">Learning and extending sublanguages</title>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
    <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
    <year>2008</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... author. E-mail addresses: sanjay@comp.nus.edu.sg (S. Jain), kinbere@sacredheart.edu (E. Kinber). ... comments. This research was supported in part by NUS grant numbersR252-000-127-112, R252-000-212-112 and R252-000-308- 112. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:eK38qPkm9ZIJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>4</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=10589412952555433336&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>3</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=10589412952555433336&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="3">
        <result id="0">
        <url>https://dspace.lboro.ac.uk/dspace/handle/2134/6458</url>
        <title status="complete" source="scholar.google.com">Inferring descriptive generalisations of formal languages</title>
        <pdf>https://dspace.lboro.ac.uk/dspace-jspui/bitstream/2134/6458/3/Freydenberger_Reidenbach_COLT_2010[1].pdf</pdf>
        <author status="complete" source="scholar.google.com">DD Freydenberger, D Reidenbach</author>
        <year>2010</year>
        <source>dspace.lboro.ac.uk</source>
        <snippet status="partial" source="scholar.google.com">In the present paper, we introduce a variant of Gold-style learners that is not required to infer precise descriptions of the languages in a class, but that must find descriptive patterns, ie, optimal generalisations within a class of pattern languages. Our first main result ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:y89Prha3ZOIJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>8</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16313365058284408779&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16313365058284408779&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://books.google.com/books?hl=en&amp;lr=&amp;id=PZjcvI3LWWoC&amp;oi=fnd&amp;pg=PA1&amp;ots=RujHEJjFCD&amp;sig=HEdl-DIPwMMDVgZfRhYs25hKYSQ</url>
        <title status="complete" source="scholar.google.com">Inclusion of pattern languages and related problems</title>
        <pdf>http://publikationen.ub.uni-frankfurt.de/frontdoor/deliver/index/docId/22351/file/dissertation.pdf</pdf>
        <author status="complete" source="scholar.google.com">DD Freydenberger</author>
        <year>2011</year>
        <source>books.google.com</source>
        <snippet status="partial" source="scholar.google.com">Pattern, dh endliche WÃ¶rter aus Variablen und Terminalsymbolen, stellen eine kompakte, elegante und natÃ¼rliche Methode dar, gewisse kontextsensitive Sprachen zu reprÃ¤sentieren. Ein Pattern erzeugt ein Wort durch eine Substitution, die alle Variablen im Pattern durch ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:2qmJCHCGK18J:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6857722673339410906&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/8384J0WTU304212H.pdf</url>
        <title status="complete" source="scholar.google.com">Inductive inference of languages from samplings</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/subinc.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2010</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We introduce, discuss, and study a model for inductive inference from samplings, formalizing an idea of learning different âprojectionsâ of languages. One set of our results addresses the problem of finding a uniform learner for all samplings of a language from a certain set ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:u3qTQ0h3CqMJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11748333730204449467&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="161">
    <url>http://www.sciencedirect.com/science/article/pii/S0022000011001565</url>
    <title status="complete" source="scholar.google.com">Learnability of automatic classes</title>
    <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2895/1/TRA1-09.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, Q Luo, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
    <year>2011</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... E-mail addresses: sanjay@comp.nus.edu.sg (S. Jain), lqinglon@dso.org.sg (Q.Luo), fstephan@comp.nus.edu.sg (F. Stephan). Sanjay Jain was supported in partby NUS grants R252-000-308-112 and C252-000-087-001. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:YFpXlQRP4YwJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>19</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=10151481916173802080&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>3</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=10151481916173802080&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="3">
        <result id="0">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397510007656</url>
        <title status="complete" source="scholar.google.com">Uncountable automatic classes and learning</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2896/1/TRB1-09.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, Q Luo, P Semukhin, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2011</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">In this paper we consider uncountable classes recognizable by Ï-automata and investigate suitable learning paradigms for them. In particular, the counterparts of explanatory, vacillatory and behaviourally correct learning are introduced for this setting. Here the ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:A3ovHOqvSVQJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>30</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6073578992515906051&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=6073578992515906051&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://dl.comp.nus.edu.sg/dspace/handle/1900.100/3112</url>
        <title status="complete" source="scholar.google.com">On automatic families</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/3112/1/TRB1-10.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, YS Ong, S Pu, F Stephan</author>
        <year>2010</year>
        <source>dl.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract: This paper summarises previous work on automatic families. It then investigates a natural measure which exists inside every automatic family: the size of a regular language in this family is just the length of its index. This measure satisfies various properties similar to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:8apC6ZMa79sJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>20</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15847914836316039921&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15847914836316039921&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/4H6654381W4512X6.pdf</url>
        <title status="complete" source="scholar.google.com">Robust learning of automatic classes of languages</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/3143/1/TRA4-10.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Martin, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper adapts and investigates the paradigm of robust learning, originally defined in the inductive inference literature for classes of recursive functions, to learning languages from positive data. Robustness is a very desirable property, as it captures a form of invariance ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:638p0aK98c4J:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>22</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14911908348191932395&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14911908348191932395&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="162">
    <url>http://www.sciencedirect.com/science/article/pii/S0022000006000304</url>
    <title status="complete" source="scholar.google.com">Learning languages in a union</title>
    <author status="complete" source="scholar.google.com">S Jain, YK Ng, TS Tay</author>
    <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
    <year>2007</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... This is essentially the model * Corresponding author. E-mail address: sanjay@comp.nus.edu.sg (S. Jain). 1 Supported in part by NUS grant number R252-000-127-112.0022-0000/$ â see front matter Â© 2006 Elsevier Inc. All rights reserved. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:GHk691m3r34J:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>3</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=9128716566731061528&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>3</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=9128716566731061528&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="3">
        <result id="0">
        <url>http://www.springerlink.com/index/8mkw9eu65cxv7uya.pdf</url>
        <title status="complete" source="scholar.google.com">Learning multiple languages in groups</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.103.2412&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2005</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">We consider a variant of Gold&#39;s learning paradigm where a learner receives as input n different languages (in form of one text where all input languages are interleaved). Our goal is to explore the situation when a more âcoarseâ classification of input languages is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:FO3LtAlHWaUJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11914632396198898964&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=11914632396198898964&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://kalngyk.zymichost.com/pub/alt2005j.pdf</url>
        <title status="complete" source="scholar.google.com">Inferring Unions of Pattern Languages By Most Fitting Covers From Positive Examples</title>
        <pdf>http://kalngyk.zymichost.com/pub/alt2005j.pdf</pdf>
        <author status="complete" source="scholar.google.com">YK Nga, T Shinohara</author>
        <proceeding status="complete" source="scholar.google.com">kalngyk.zymichost.com</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract We are interested in the inductive inference of classes of unions, of the pattern languages and their subclasses, from positive examples using strategies that guarantee some form of minimality in the intermediate hypotheses. It is known that a strategy based ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:Ow6NkCWum3IJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:Ow6NkCWum3IJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397507005506</url>
        <title status="complete" source="scholar.google.com">Learning multiple languages in groups</title>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2007</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">We consider a variant of Gold&#39;s learning paradigm where a learner receives as input n different languages (in the form of one text where all input languages are interleaved). Our goal is to explore the situation when a more âcoarseâ classification of input languages is ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ceSqnui4hbIJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12863891219887613041&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="163">
    <url>http://www.jstor.org/stable/10.2307/2694927</url>
    <title status="complete" source="scholar.google.com">Some independence results for control structures in complete numberings</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.109.7224&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, J Nessel</author>
    <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
    <year>2001</year>
    <source>JSTOR</source>
    <snippet status="partial" source="scholar.google.com">Page 1. THE JOURNAL OF SYMBOLIC LOGIC Volume 66. Number 1. March 2001SOME INDEPENDENCE RESULTS FOR CONTROL STRUCTURES IN COMPLETENUMBERINGS SANJAY JAIN AND JOCHEN NESSEL Abstract. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:Ndzt1LIRQ_8J:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>6</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=18393564762885446709&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>6</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=18393564762885446709&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="6">
        <result id="0">
        <url>http://www.springerlink.com/index/l5p6329uk2633r03.pdf</url>
        <title status="complete" source="scholar.google.com">Directions for computability theory beyond pure mathematical</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/rft-directions.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Mathematical problems from applied logic II</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper begins by briefly indicating the principal, non-standard motivations of the author for his decades of work in Computability Theory (CT), aka Recursive Function Theory. Then it discusses its proposed, general directions beyond those from pure mathematics for CT. These ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:BWKg2uLmRxMJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1389332872072028677&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1389332872072028677&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/W133056GWT2U0160.pdf</url>
        <title status="complete" source="scholar.google.com">Properties complementary to program self-reference</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.75.7113&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Moelius</author>
        <proceeding status="complete" source="scholar.google.com">Mathematical Foundations of Computer Science 2007</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">In computability theory, program self-reference is formalized by the not-necessarily-constructive form of Kleene&#39;s Recursion Theorem (krt). In a programming system in which krt holds, for any preassigned, algorithmic task, there exists a program that, in a sense, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:HVdi_mZbe9kJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15671219826278422301&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15671219826278422301&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/90850606T400V451.pdf</url>
        <title status="complete" source="scholar.google.com">Characterizing programming systems allowing program self-reference</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.77.5914&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S MoeliusIII</author>
        <proceeding status="complete" source="scholar.google.com">Computation and Logic in the Real World</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The interest is in characterizing insightfully the power of program self-reference in effective programming systems (epses), the computability-theoretic analogs of programming languages. In an eps in which the constructive form of Kleene&#39;s Recursion Theorem (KRT) ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:qHcBEsnodBsJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1978462086610646952&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1978462086610646952&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.springerlink.com/index/033p213548270347.pdf</url>
        <title status="complete" source="scholar.google.com">Characterizing programming systems allowing program self-reference</title>
        <author status="complete" source="scholar.google.com">J Case, SE Moelius</author>
        <proceeding status="complete" source="scholar.google.com">Theory of Computing Systems</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract The interest is in characterizing insightfully the power of program self-reference in effective programming systems (), the computability-theoretic analogs of programming languages (for the partial computable functions). In an in which the constructive form of ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ULQx_s3xNu0J:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17093115302766556240&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17093115302766556240&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="4">
        <title status="complete" source="scholar.google.com">Program self-reference</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.156.5672&amp;rep=rep1&amp;type=pdf</pdf>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:YxqD3ZnzbpwJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=11272214759526832739&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="5">
        <url>http://iospress.metapress.com/index/14N3018H35413625.pdf</url>
        <title status="complete" source="scholar.google.com">Properties Complementary to Program Self-Reference</title>
        <author status="complete" source="scholar.google.com">J Case, SE Moelius III</author>
        <proceeding status="complete" source="scholar.google.com">Fundamenta Informaticae</proceeding>
        <year>2011</year>
        <source>IOS Press</source>
        <snippet status="partial" source="scholar.google.com">In computability theory, program self-reference is formalized by the not-necessarily-constructive form of Kleene&#39;s Recursion Theorem (krt). In a programming system in which krt holds, for any preassigned, algorithmic task, there exists a program that, in a sense, ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:ZjJs8XnrXFoJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=6511338070244864614&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="164">
    <url>http://epubs.siam.org/doi/abs/10.1137/070700577</url>
    <title status="complete" source="scholar.google.com">Mitotic classes in inductive inference</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.137.6190&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">SIAM Journal on Computing</proceeding>
    <year>2008</year>
    <source>SIAM</source>
    <snippet status="partial" source="scholar.google.com">... This work was supported in part by NUS grants R252-000- 212-112 and R252-000-308-112.http://www.siam.org/journals/sicomp/38-4/70057.html â School of Computing, National Universityof Singapore, Singapore 117590, Singapore (sanjay@ comp.nus.edu.sg). ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:8Dgog4Yp7VIJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>24</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=5975477938293324016&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>2</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=5975477938293324016&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="2">
        <result id="0">
        <url>http://www.springerlink.com/index/4H6654381W4512X6.pdf</url>
        <title status="complete" source="scholar.google.com">Robust learning of automatic classes of languages</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/3143/1/TRA4-10.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Martin, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper adapts and investigates the paradigm of robust learning, originally defined in the inductive inference literature for classes of recursive functions, to learning languages from positive data. Robustness is a very desirable property, as it captures a form of invariance ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:638p0aK98c4J:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>22</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14911908348191932395&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14911908348191932395&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/K463H6036PH8678U.pdf</url>
        <title status="complete" source="scholar.google.com">Splitting of learnable classes</title>
        <pdf>http://users.dsic.upv.es/workshops/icgi2010/slides/Li.pdf</pdf>
        <author status="complete" source="scholar.google.com">H Li, F Stephan</author>
        <proceeding status="partial" source="scholar.google.com">Grammatical Inference: Theoretical Results and &#8230;</proceeding>
        <year>2010</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A class LL is called mitotic if it admits a splitting L 0, L 1 L _0, L _1 such that L, L 0, L 1 L, L _0, L _1 are all equivalent with respect to a certain reducibility. Such a splitting might be called a symmetric splitting. In this paper we investigate the possibility of constructing a ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cV405y-RMO8J:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>19</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17235435408875347569&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="165">
    <url>http://www.springerlink.com/index/N06E3108MYXKV600.pdf</url>
    <title status="complete" source="scholar.google.com">Team learning of computable languages</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.108.396&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, A Sharma</author>
    <proceeding status="complete" source="scholar.google.com">Theory of Computing Systems</proceeding>
    <year>2000</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... 1School of Computing, National University of Singapore, Singapore 119260, Republic ofSingapore sanjay@comp.nus.edu.sg 2School of Computer Science and Engineering, Universityof New South Wales, Sydney, NSW 2052, Australia arun@cse.unsw.edu.au Abstract. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:o5szlboYGy4J:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>7</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=3322276339762043811&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>2</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=3322276339762043811&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="2">
        <result id="0">
        <url>http://ciillibrary.org:8000/ciil/repository/sharada/s28.pdf</url>
        <title status="complete" source="scholar.google.com">INDIC ARTICLES 2000-AN ANALYSIS</title>
        <pdf>http://ciillibrary.org:8000/ciil/repository/sharada/s28.pdf</pdf>
        <author status="complete" source="scholar.google.com">BA Sharada</author>
        <proceeding status="complete" source="scholar.google.com">ciillibrary.org</proceeding>
        <snippet status="partial" source="scholar.google.com">The concept Indexing has opened new avenues to project the metadata in any manner the research demands. Here is one such way that presents the contribution published in journals and anthologies during the year 2000 January to December. The articles reflect ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:t76I7qHpgfAJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:t76I7qHpgfAJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/D891256047178X85.pdf</url>
        <title status="complete" source="scholar.google.com">Learning from streams</title>
        <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.157.1225&amp;rep=rep1&amp;type=pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, F Stephan, N Ye</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Learning from streams is a process in which a group of learners separately obtain information about the target to be learned, but they can communicate with each other in order to learn the target. We are interested in machine models for learning from streams ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:1jKd9b4XsWYJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>22</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=7399721771678380758&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="166">
    <url>http://www.comp.nus.edu.sg/~sanjay/paps/robsur.pdf</url>
    <title status="complete" source="scholar.google.com">A tour of robust learning</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/robsur.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
    <proceeding status="partial" source="scholar.google.com">&#8230; and Models. Perspectives East and West. &#8230;</proceeding>
    <year>2003</year>
    <source>comp.nus.edu.sg</source>
    <snippet status="partial" source="scholar.google.com">Page 1. Chapter 1 A TOUR OF ROBUST LEARNING Sanjay Jainâ School of Computing,National University of Singapore, Singapore 119260 sanjay@comp.nus.edu.sg ... SanjayJain is supported in part by the NUS grant number RP3992710. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:OhqoyUDoLugJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:OhqoyUDoLugJ:scholar.google.com/+author:%22Jain+Sanjay%22+NUS&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <numVersions>5</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=16730565030686759482&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>2</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=16730565030686759482&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="2">
        <result id="0">
        <url>http://dl.comp.nus.edu.sg/dspace/handle/1900.100/3112</url>
        <title status="complete" source="scholar.google.com">On automatic families</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/3112/1/TRB1-10.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, YS Ong, S Pu, F Stephan</author>
        <year>2010</year>
        <source>dl.comp.nus.edu.sg</source>
        <snippet status="partial" source="scholar.google.com">Abstract: This paper summarises previous work on automatic families. It then investigates a natural measure which exists inside every automatic family: the size of a regular language in this family is just the length of its index. This measure satisfies various properties similar to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:8apC6ZMa79sJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>20</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=15847914836316039921&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>8</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=15847914836316039921&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/4H6654381W4512X6.pdf</url>
        <title status="complete" source="scholar.google.com">Robust learning of automatic classes of languages</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/3143/1/TRA4-10.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Martin, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper adapts and investigates the paradigm of robust learning, originally defined in the inductive inference literature for classes of recursive functions, to learning languages from positive data. Robustness is a very desirable property, as it captures a form of invariance ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:638p0aK98c4J:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>22</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14911908348191932395&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14911908348191932395&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="167">
    <url>http://www.sciencedirect.com/science/article/pii/S0890540107000983</url>
    <title status="complete" source="scholar.google.com">Iterative learning from positive data and negative counterexamples</title>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
    <proceeding status="complete" source="scholar.google.com">Information and Computation</proceeding>
    <year>2007</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... In Gold&#39;s original model the learner is able to store potentially all input (positive) examples inits long-term memory (one can clearly make distinction between long-term memory, where alearner stores necessary data H32891 Supported in part by NUS Grant Nos. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:DfGaZ2CzXhUJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>4</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=1539865349243728141&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>4</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=1539865349243728141&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="4">
        <result id="0">
        <url>http://www.springerlink.com/index/6813w3k86555t79h.pdf</url>
        <title status="complete" source="scholar.google.com">Iterative learning from texts and counterexamples using additional information</title>
        <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2937/1/TRB4-09.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">A variant of iterative learning in the limit (cf.[LZ96]) is studied when a learner gets negative examples refuting conjectures containing data in excess of the target language and uses additional information of the following four types: a) memorizing up to n input elements ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:m0uIqOprI_kJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>9</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17952311195222952859&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>3</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=17952311195222952859&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.sciencedirect.com/science/article/pii/S0304397509001674</url>
        <title status="complete" source="scholar.google.com">One-shot learners using negative counterexamples and nearest positive examples</title>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
        <year>2009</year>
        <source>Elsevier</source>
        <snippet status="partial" source="scholar.google.com">As some cognitive research suggests, in the process of learning languages, in addition to overt explicit negative evidence, a child often receives covert explicit evidence in form of corrected or rephrased sentences. In this paper, we suggest one approach to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:r9OMYh_KopUJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=10782402694024582063&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/X524068561K52072.pdf</url>
        <title status="complete" source="scholar.google.com">Iterative learning from texts and counterexamples using additional information</title>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Machine learning</proceeding>
        <year>2011</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract A variant of iterative learning in the limit (cf. Lange and Zeugmann 1996) is studied when a learner gets negative examples refuting conjectures containing data in excess of the target language and uses additional information of the following four types:(a) memorizing ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:3qdCfFnTLTgJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=4048124021366237150&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="3">
        <url>http://www.eecis.udel.edu/~case/papers/pr2.pdf</url>
        <title status="complete" source="scholar.google.com">On the Necessity of U-Shaped Learning</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/pr2.pdf</pdf>
        <author status="complete" source="scholar.google.com">L Carlucci, J Case</author>
        <proceeding status="complete" source="scholar.google.com">eecis.udel.edu</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. A U-shaped curve in a cognitive-developmental trajectory refers to a three-step process: good performance followed by bad performance followed by good performance once again. U-shaped curves have been observed in a wide variety of cognitive- ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=17336137048815070431&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="168">
    <url>http://www.sciencedirect.com/science/article/pii/S0304397507004598</url>
    <title status="complete" source="scholar.google.com">Invertible classes</title>
    <author status="complete" source="scholar.google.com">S Jain, J Nessel, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
    <year>2007</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... Corresponding author. Tel.: +65 6516 2759; fax: +65 7795 5452. E-mail addresses:sanjay@comp.nus.edu.sg (S. Jain), ibea@gmx.de (J. Nessel), fstephan@comp.nus.edu.sg (F.Stephan). ... The first author was supported in part by NUS grant number R252â000â127â112. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:3U142Fpm-UsJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>3</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=5474519362410401245&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="169">
    <url>http://iospress.metapress.com/index/TRRD110H759Y5W0B.pdf</url>
    <title status="complete" source="scholar.google.com">The intrinsic complexity of learning: A survey</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/intrinsur.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain</author>
    <proceeding status="complete" source="scholar.google.com">Fundamenta Informaticae</proceeding>
    <year>2003</year>
    <source>IOS Press</source>
    <snippet status="partial" source="scholar.google.com">Page 1. Fundamenta Informaticae 57 (2003) 17â37 17 IOS Press The Intrinsic Complexity ofLearning: A Survey Sanjay Jain Ð° School of Computing National University of SingaporeSingapore 119260, Republic of Singapore sanjay@comp.nus.edu.sg Abstract. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:b9x1IASxyRcJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>8</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=1714095764473764975&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>2</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=1714095764473764975&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="2">
        <result id="0">
        <url>http://hal.inria.fr/hal-00573633/</url>
        <title status="complete" source="scholar.google.com">Measuring learning complexity with criteria epitomizers</title>
        <pdf>http://hal.inria.fr/docs/00/57/36/33/PDF/31.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="partial" source="scholar.google.com">Leibniz International Proceedings in Informatics ( &#8230;</proceeding>
        <year>2011</year>
        <source>hal.inria.fr</source>
        <snippet status="partial" source="scholar.google.com">RÃ©sumÃ©: In prior papers, beginning with the seminal work by Freivalds et~ al.~ 1995, the notion of\ emph {intrinsic complexity} is used to analyze the learning complexity of sets of functions in a Gold-style learning setting. Herein are pointed out some weaknesses of this ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:BnuuDxP3ocUJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>7</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=14240935157961751302&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=14240935157961751302&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://rsta.royalsocietypublishing.org/content/370/1971/3570.short</url>
        <title status="complete" source="scholar.google.com">Computability-theoretic learning complexity</title>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="partial" source="scholar.google.com">Philosophical Transactions of the &#8230;</proceeding>
        <year>2012</year>
        <source>rsta.royalsocietypublishing.org</source>
        <snippet status="partial" source="scholar.google.com">Abstract Initially discussed are some of Alan Turing&#39;s wonderfully profound and influential ideas about mind and mechanismâincluding regarding their connection to the main topic of the present study, which is within the field of computability-theoretic learning theory. ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:A4Qc6wulYm8J:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>2</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=8026158956535383043&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=8026158956535383043&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=2</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="170">
    <url>http://www.sciencedirect.com/science/article/pii/S0168007205000941</url>
    <title status="complete" source="scholar.google.com">Generality&#39;s price: Inescapable deficiencies in machine-learned programs</title>
    <pdf>http://www.cis.syr.edu/~royer/archive/gen.pdf</pdf>
    <author status="complete" source="scholar.google.com">J Case, KJ Chen, S Jain, W Merkle, JS Royer</author>
    <proceeding status="partial" source="scholar.google.com">Annals of Pure and Applied &#8230;</proceeding>
    <year>2006</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... 2005 Elsevier BV All rights reserved. â Corresponding author. E-mail addresses:case@cis.udel.edu (J. Case), kchen@iis.sinica.edu.tw (K.-J. Chen), sanjay@comp.nus.edu.sg(S. Jain), merkle@math.uni-heidelberg.de (W. Merkle), royer@ecs.syr.edu (JS Royer). ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:JENiSWTOK-AJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>13</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=16153231418617643812&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>3</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=16153231418617643812&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="3">
        <result id="0">
        <url>http://www.springerlink.com/index/l5p6329uk2633r03.pdf</url>
        <title status="complete" source="scholar.google.com">Directions for computability theory beyond pure mathematical</title>
        <pdf>http://www.eecis.udel.edu/~case/papers/rft-directions.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Mathematical problems from applied logic II</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">This paper begins by briefly indicating the principal, non-standard motivations of the author for his decades of work in Computability Theory (CT), aka Recursive Function Theory. Then it discusses its proposed, general directions beyond those from pure mathematics for CT. These ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:BWKg2uLmRxMJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1389332872072028677&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>4</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=1389332872072028677&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://www.springerlink.com/index/12017035066353VR.pdf</url>
        <title status="complete" source="scholar.google.com">Resource Restricted Computability Theoretic Learning: Illustrative Topics and Problems</title>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Computation and Logic in the Real World</proceeding>
        <year>2007</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Computability theoretic learning theory (machine inductive inference) typically involves learning programs for languages or functions from a stream of complete data about them and, importantly, allows mind changes as to conjectured programs. This theory takes into ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:MIjRDNBNqiIJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>5</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=2497894499293956144&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/812361171q2264pu.pdf</url>
        <title status="complete" source="scholar.google.com">Resource Restricted Computability Theoretic Learning: Illustrative Topics and Problems</title>
        <author status="complete" source="scholar.google.com">J Case</author>
        <proceeding status="complete" source="scholar.google.com">Theory of Computing Systems</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract Computability theoretic learning theory (machine inductive inference) typically involves learning programs for languages or functions from a stream of complete data about them and, importantly, allows mind changes as to conjectured programs. This theory takes ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:cNGIg7j_YKkJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=12205036158119891312&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="171">
    <url>http://www.sciencedirect.com/science/article/pii/S0022000012000876</url>
    <title status="complete" source="scholar.google.com">Learning with ordinal-bounded memory from positive data</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/bemord.pdf</pdf>
    <author status="complete" source="scholar.google.com">L Carlucci, S Jain, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
    <year>2012</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... Let us call intensional memory the learnerÃ¢â¬â¢s memory Corresponding author.E-mail addresses: carlucci@di.uniroma1.it (L. Carlucci), sanjay@comp.nus.edu.sg (S. Jain), fstephan@comp.nus.edu.sg (F. Stephan). Lorenzo ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:SO2jYG0s_0kJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>3</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=5332029332114369864&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="172">
    <url>http://www.sciencedirect.com/science/article/pii/S0304397507005506</url>
    <title status="complete" source="scholar.google.com">Learning multiple languages in groups</title>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
    <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
    <year>2007</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... Tel.: +65 6874 7842; fax: +65 6779 4580. E-mail addresses: sanjay@comp.nus.edu.sg (S. Jain),kinbere@sacredheart.edu (E. Kinber). ... The first author was supported in part by NUS grant numbersR252-000-127-112, R252-000-212-112 and R252-000-308-112. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:ceSqnui4hbIJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>4</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=12863891219887613041&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="173">
    <url>http://www.springerlink.com/index/8hkxd64aqlcbl09v.pdf</url>
    <title status="complete" source="scholar.google.com">Generality&#39;s Price</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.7086&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">J Case, KJ Chen, S Jain, W Merkle, J Royer</author>
    <proceeding status="partial" source="scholar.google.com">Learning Theory and Kernel &#8230;</proceeding>
    <year>2003</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... cis.udel.edu 2 Institute of Information Science, Academia Sinica Nankang 115, Taipei, Taiwan,ROC kchen@iis.sinica.edu.tw 3 School of Computing, National University of Singapore 3 ScienceDrive 2, Singapore 117543, Republic of Singapore sanjay@comp.nus.edu.sg 4 ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:8r24VLwPns4J:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>8</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=14888354719683100146&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="174">
    <url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.118.7824&amp;rep=rep1&amp;type=pdf</url>
    <title status="complete" source="scholar.google.com">NEGATIVE DATA IN LEARNING LANGUAGES</title>
    <pdf>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.118.7824&amp;rep=rep1&amp;type=pdf</pdf>
    <author status="complete" source="scholar.google.com">S JAIN, E KINBER</author>
    <proceeding status="partial" source="scholar.google.com">Mathematical Logic in Asia: Proceedings of the 9th &#8230;</proceeding>
    <year>2006</year>
    <source>Citeseer</source>
    <snippet status="partial" source="scholar.google.com">... SANJAY JAIN School of Computing, National University of Singapore, Singapore 117543. Email:sanjay@comp.nus.edu.sg EFIM KINBER Department of Computer Science, Sacred HeartUniversity, Fairfield, CT 06432-1000, USA Email: kinbere@sacredheart.edu ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:xhc83r1kuQwJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:xhc83r1kuQwJ:scholar.google.com/+author:%22Jain+Sanjay%22+NUS&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</htmlLink>
    <numVersions>4</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=916874765786683334&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="175">
    <url>http://onlinelibrary.wiley.com/doi/10.1002/malq.201020054/full</url>
    <title status="complete" source="scholar.google.com">Rice and RiceâShapiro Theorems for transfinite correction grammars</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/rice.pdf</pdf>
    <author status="complete" source="scholar.google.com">J Case, S Jain</author>
    <proceeding status="complete" source="scholar.google.com">Mathematical Logic Quarterly</proceeding>
    <year>2011</year>
    <source>Wiley Online Library</source>
    <snippet status="partial" source="scholar.google.com">... Email: John Case (case@cis.udel.edu), Sanjay Jain (sanjay@comp.nus.edu.sg). *Department of Computer and Information Sciences, University of Delaware, Newark,DE 19716-2586, United States of America. Publication History. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:EuckXGHSWuIJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>3</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=16310580316075255570&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="176">
    <url>http://www.sciencedirect.com/science/article/pii/S0022000009000749</url>
    <title status="complete" source="scholar.google.com">Numberings optimal for learning</title>
    <author status="complete" source="scholar.google.com">S Jain, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Journal of Computer and System Sciences</proceeding>
    <year>2010</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... Corresponding author. E-mail addresses: sanjay@comp.nus.edu.sg (S. Jain), fstephan@comp.nus.edu.sg (F. Stephan). 1 Supported in part by NUS grant number R252-000-308-112. 2Supported in part by NUS grant numbers R252-000-308-112 and R146-000-114-112. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:41DjdY4aypgJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>3</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=11009641438226108643&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=11009641438226108643&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://www-test.comp.nus.edu.sg/~fstephan/krtlearn.ps</url>
        <title status="complete" source="scholar.google.com">Effectivity Questions for Kleene&#39;s Recursion Theorem</title>
        <pdf>http://www-test.comp.nus.edu.sg/~fstephan/krtlearn.ps</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">www-test.comp.nus.edu.sg</proceeding>
        <snippet status="partial" source="scholar.google.com">Abstract. The present paper explores the interaction between two recursion-theoretic notions: program self-reference and learning partial recursive functions in the limit. Kleene&#39;s Recursion Theorem formalises the notion of program self-reference: It says that given a ...</snippet>
        <htmlLink>http://scholar.googleusercontent.com/scholar?q=cache:SQJ83x5mChcJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</htmlLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="177">
    <url>http://www.springerlink.com/index/X524068561K52072.pdf</url>
    <title status="complete" source="scholar.google.com">Iterative learning from texts and counterexamples using additional information</title>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
    <proceeding status="complete" source="scholar.google.com">Machine learning</proceeding>
    <year>2011</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... Editor: A. Blum. S. Jain was supported in part by NUS grant numbers R252-000-308-112 andC-252-000-087-001. S. Jain ( ) School of Computing, National University of Singapore, Singapore117417, Republic of Singapore e-mail: sanjay@comp.nus.edu.sg ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:3qdCfFnTLTgJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>7</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=4048124021366237150&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="178">
    <url>http://www.springerlink.com/index/T448G2083421512J.pdf</url>
    <title status="complete" source="scholar.google.com">Input-Dependence in Function-Learning</title>
    <author status="complete" source="scholar.google.com">S Jain, E Martin, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">Theory of Computing Systems</proceeding>
    <year>2009</year>
    <source>Springer</source>
    <snippet status="partial" source="scholar.google.com">... S. Jain and F. Stephan were supported in part by NUS grant numbers R252-000-212-112 andR252-000-308-112. ... S. Jain ( ) Department of Computer Science, National University of Singapore,Singapore 117417, Republic of Singapore e-mail: sanjay@comp.nus.edu.sg ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:f-T8tNbGjGkJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>4</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=7605672496183698559&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="179">
    <url>http://epubs.siam.org/doi/abs/10.1137/050629112</url>
    <title status="complete" source="scholar.google.com">Identifying Clusters from Positive Data</title>
    <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/cluster.pdf</pdf>
    <author status="complete" source="scholar.google.com">J Case, S Jain, E Martin, A Sharma, F Stephan</author>
    <proceeding status="complete" source="scholar.google.com">SIAM Journal on Computing</proceeding>
    <year>2006</year>
    <source>SIAM</source>
    <snippet status="partial" source="scholar.google.com">... The work of J. Case is supported in part by NSF grant CCR-0208616 and by USDA IFAFS grant01-04145. The work of S. Jain is supported in part by NUS grant R252-000-127-112. ... The workof F. Stephan is supported in part by NUS grant R252-000-212-112. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:J3Yj85UdkaEJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>30</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=11642119041595962919&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
  <result id="180">
    <url>http://projecteuclid.org/euclid.jsl/1243948324</url>
    <title status="complete" source="scholar.google.com">Learning correction grammars</title>
    <pdf>https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2307/1/TR12-06.pdf</pdf>
    <author status="complete" source="scholar.google.com">L Carlucci, J Case, S Jain</author>
    <proceeding status="complete" source="scholar.google.com">Journal of Symbolic Logic</proceeding>
    <year>2009</year>
    <source>projecteuclid.org</source>
    <snippet status="partial" source="scholar.google.com">... Sanjay Jain was supported in part by NUS grant numbers R252-000-308-112 andR252-000-212-112. c 2009, Association for Symbolic Logic 1943-5886/09/7402-0006/$3.80489 Page 2. 490 LORENZO CARLUCCI, JOHN CASE, AND SANJAY JAIN ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:0zSN0GENz58J:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>7</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=11515437485971551443&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>3</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=11515437485971551443&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="3">
        <result id="0">
        <url>http://www.springerlink.com/index/426358m7702847h2.pdf</url>
        <title status="complete" source="scholar.google.com">Difficulties in forcing fairness of polynomial time inductive inference</title>
        <author status="complete" source="scholar.google.com">J Case, T KÃ¶tzing</author>
        <proceeding status="complete" source="scholar.google.com">Algorithmic Learning Theory</proceeding>
        <year>2009</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">There are difficulties obtaining fair feasibility from polynomial time updated language learning in the limit from positive data. Pitt 1989 noted that unfair delaying tricks can achieve polynomial time updates but with no feasibility constraint on the whole learning process. In ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:bIREIdSBRukJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>10</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16809265407298143340&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>7</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=16809265407298143340&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=3</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="1">
        <url>http://onlinelibrary.wiley.com/doi/10.1002/malq.201020054/full</url>
        <title status="complete" source="scholar.google.com">Rice and RiceâShapiro Theorems for transfinite correction grammars</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/rice.pdf</pdf>
        <author status="complete" source="scholar.google.com">J Case, S Jain</author>
        <proceeding status="complete" source="scholar.google.com">Mathematical Logic Quarterly</proceeding>
        <year>2011</year>
        <source>Wiley Online Library</source>
        <snippet status="partial" source="scholar.google.com">Abstract Hay and, then, Johnson extended the classic Rice and Rice-Shapiro Theorems for computably enumerable sets, to analogs for all the higher levels in the finite Ershov Hierarchy. The present paper extends their work (with some motivations presented) to ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:EuckXGHSWuIJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>3</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=16310580316075255570&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
      <result id="2">
        <url>http://www.springerlink.com/index/U2V8151P2N16110H.pdf</url>
        <title status="complete" source="scholar.google.com">Learnability of co-re classes</title>
        <pdf>http://www.comp.nus.edu.sg/~fstephan/corelearn.ps</pdf>
        <author status="complete" source="scholar.google.com">Z Gao, F Stephan</author>
        <proceeding status="complete" source="scholar.google.com">Language and Automata Theory and Applications</proceeding>
        <year>2012</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">The object of investigation in this paper is the learnability of co-recursively enumerable (co-re) languages based on Gold&#39;s [11] original model of inductive inference. In particular, the following learning models are studied: finite learning, explanatory learning, vacillatory ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:aenPm2LFsxAJ:scholar.google.com/&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>4</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=1203522552749615465&amp;hl=en&amp;num=3&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="181">
    <url>http://www.sciencedirect.com/science/article/pii/S0304397507006585</url>
    <title status="complete" source="scholar.google.com">Learning languages from positive data and a limited number of short counterexamples</title>
    <pdf>http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1899/1/TR21-05.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
    <proceeding status="complete" source="scholar.google.com">Theoretical Computer Science</proceeding>
    <year>2007</year>
    <source>Elsevier</source>
    <snippet status="partial" source="scholar.google.com">... Corresponding author. Tel.: +65 6874 7842; fax: +65 6779 4580. E-mail addresses:sanjay@comp.nus.edu.sg (S. Jain), kinbere@sacredheart.edu (E. Kinber). 0304-3975/$ -see front matter cÂ© 2007 Elsevier BV All rights reserved. doi ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:oTUPOOVeFnkJ:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>8</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=8725265666657957281&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <numCite>1</numCite>
    <citeLink>http://scholar.google.com.sg/scholar?cites=8725265666657957281&amp;as_sdt=2005&amp;sciodt=1,5&amp;hl=en&amp;num=83</citeLink>
    <citedBy totalresults="1">
        <result id="0">
        <url>http://www.springerlink.com/index/97285WVT37N48810.pdf</url>
        <title status="complete" source="scholar.google.com">On learning languages from positive data and a limited number of short counterexamples</title>
        <pdf>http://www.comp.nus.edu.sg/~sanjay/paps/bncfull.pdf</pdf>
        <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
        <proceeding status="complete" source="scholar.google.com">Learning Theory</proceeding>
        <year>2006</year>
        <source>Springer</source>
        <snippet status="partial" source="scholar.google.com">Abstract. We consider two variants of a model for learning languages in the limit from positive data and a limited number of short negative counterexamples (counterexamples are considered to be short if they are smaller that the largest element of input seen so far). ...</snippet>
        <relatedLink>http://scholar.google.com.sg/scholar?q=related:y-Vc4Y2Mb7QJ:scholar.google.com/&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</relatedLink>
        <numVersions>6</numVersions>
        <versionLink>http://scholar.google.com.sg/scholar?cluster=13001765190241150411&amp;hl=en&amp;num=1&amp;as_sdt=0,5&amp;sciodt=0,5</versionLink>
        <numCite>1</numCite>
        <citeLink>http://scholar.google.com.sg/scholar?cites=13001765190241150411&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=1</citeLink>
        <citedBy totalresults="0">
        </citedBy>
      </result>
    </citedBy>
  </result>
  <result id="182">
    <url>http://hal.archives-ouvertes.fr/hal-00678163/</url>
    <title status="complete" source="scholar.google.com">Mind Change Speed-up for Learning Languages from Positive Data</title>
    <pdf>http://hal.archives-ouvertes.fr/docs/00/67/81/63/PDF/9.pdf</pdf>
    <author status="complete" source="scholar.google.com">S Jain, E Kinber</author>
    <proceeding status="partial" source="scholar.google.com">Symposium on Theoretical Aspects of &#8230;</proceeding>
    <year>2012</year>
    <source>hal.archives-ouvertes.fr</source>
    <snippet status="partial" source="scholar.google.com">... sanjay@comp.nus.edu.sg 2 Department of Computer Science, Sacred Heart University, Fairfield,CT 06825-1000, USA kinbere@sacredheart.edu Abstract ... This measure of complexity of â SanjayJain was supported in part by NUS grant number C-252-000-087-001. ...</snippet>
    <relatedLink>http://scholar.google.com.sg/scholar?q=related:y8ex7vN-mE8J:scholar.google.com/&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</relatedLink>
    <numVersions>8</numVersions>
    <versionLink>http://scholar.google.com.sg/scholar?cluster=5735473711603107787&amp;hl=en&amp;num=83&amp;as_sdt=1,5&amp;as_vis=1</versionLink>
    <citedBy totalresults="0">
    </citedBy>
  </result>
</query>
</results>
