Total results = 28
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.41.615&amp;rep=rep1&amp;type=pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397500002723" class=yC0>Learning algebraic structures from text</a></h3><div class="gs_a">F Stephan, Y Ventsov - Theoretical Computer Science, 2001 - Elsevier</div><div class="gs_rs">The present work investigates the learnability of classes of substructures of some algebraic <br>structures: submonoids and subgroups of given groups, ideals of given commutative rings, <br>subfields of given vector spaces. The learner sees all positive data but no negative one <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3422401916475334820&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 23</a> <a href="/scholar?q=related:pOAgDmnQfi8J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3422401916475334820&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'pOAgDmnQfi8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://pdf.aminer.org/002/865/517/parsimony_hierarchies_for_inductive_inference.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aminer.org</span><span class="gs_ggsS">aminer.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://projecteuclid.org/euclid.jsl/1080938842" class=yC2>Parsimony hierarchies for inductive inference</a></h3><div class="gs_a"><a href="/citations?user=Wy0bQrwAAAAJ&amp;hl=en&amp;oi=sra">A Ambainis</a>, <a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, M Suraj - Journal of Symbolic Logic, 2004 - projecteuclid.org</div><div class="gs_rs">Abstract Freivalds defined an acceptable programming system independent criterion for <br>learning programs for functions in which the final programs were required to be both correct <br>and ânearlyâ minimal size, ie, within a computable function of being purely minimal size. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15168080914944291644&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 12</a> <a href="/scholar?q=related:PPOiazrZf9IJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/3A/3E/RN147185337.html?source=googlescholar" class="gs_nph" class=yC4>BL Direct</a> <a href="/scholar?cluster=15168080914944291644&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'PPOiazrZf9IJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://mind-change-bayes-net.googlecode.com/svn/branches/mclc.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from googlecode.com</span><span class="gs_ggsS">googlecode.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0890540106000253" class=yC5>Mind change efficient learning</a></h3><div class="gs_a"><a href="/citations?user=fIxBU34AAAAJ&amp;hl=en&amp;oi=sra">W Luo</a>, O Schulte - Information and Computation, 2006 - Elsevier</div><div class="gs_rs">This paper studies efficient learning with respect to mind changes. Our starting point is the <br>idea that a learner that is efficient with respect to mind changes minimizes mind changes not <br>only globally in the entire learning problem, but also locally in subproblems after receiving <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14247247022051085877&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 12</a> <a href="/scholar?q=related:Nc6YcK5juMUJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14247247022051085877&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'Nc6YcK5juMUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://www.math.uni-heidelberg.de/logic/fstephan/ssv-mathpreprints-com.ps" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PS]</span> from uni-heidelberg.de</span><span class="gs_ggsS">uni-heidelberg.de <span class=gs_ctg2>[PS]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0890540103002438" class=yC7>Generalized notions of mind change complexity</a></h3><div class="gs_a">A Sharma, F Stephan, Y Ventsov - Information and Computation, 2004 - Elsevier</div><div class="gs_rs">Gold introduced the notion of learning in the limit where a class S is learnable iff there is a <br>recursive machine M which reads the course of values of a function f and converges to a <br>program for f whenever f is in S. An important measure for the speed of convergence in <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14442968844286037360&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 9</a> <a href="/scholar?q=related:cA20SaS7b8gJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14442968844286037360&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'cA20SaS7b8gJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.72.7998&amp;rep=rep1&amp;type=pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/lwppl43dfva4ulg5.pdf" class=yC9>Mind change efficient learning</a></h3><div class="gs_a"><a href="/citations?user=fIxBU34AAAAJ&amp;hl=en&amp;oi=sra">W Luo</a>, O Schulte - Learning Theory, 2005 - Springer</div><div class="gs_rs">This paper studies efficient learning with respect to mind changes. Our starting point is the <br>idea that a learner that is efficient with respect to mind changes minimizes mind changes not <br>only globally in the entire learning problem, but also locally in subproblems after receiving <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4982441996810043214&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 7</a> <a href="/scholar?q=related:Tr_ZFZkwJUUJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4982441996810043214&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'Tr_ZFZkwJUUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.8.1793&amp;rep=rep1&amp;type=pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397505006456" class=yCB>Unifying logic, topology and learning in parametric logic</a></h3><div class="gs_a">E Martin, A Sharma, F Stephan - Theoretical computer science, 2006 - Elsevier</div><div class="gs_rs">Many connections have been established between learning and logic, or learning and <br>topology, or logic and topology. Still, the connections are not at the heart of these fields. <br>Each of them is fairly independent of the others when attention is restricted to basic <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15440473385555122436&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 7</a> <a href="/scholar?q=related:BNnirbyUR9YJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15440473385555122436&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 29 versions</a> <a onclick="return gs_ocit(event,'BNnirbyUR9YJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/tpxvht2u27uhrbtf.pdf" class=yCD>Learning, logic, and topology in a common framework</a></h3><div class="gs_a">E Martin, A Sharma, F Stephan - Algorithmic Learning Theory, 2002 - Springer</div><div class="gs_rs">Many connections have been established between learning and logic, or learning and <br>topology, or logic and topology. Still, the connections are not at the heart of these fields. <br>Each of them is fairly independent of the others when attention is restricted to basic <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=554371163819176501&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 7</a> <a href="/scholar?q=related:NXIp5aKFsQcJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/5F/60/RN123383126.html?source=googlescholar" class="gs_nph" class=yCE>BL Direct</a> <a href="/scholar?cluster=554371163819176501&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'NXIp5aKFsQcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.105.2902&amp;rep=rep1&amp;type=pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/1p9a8e58kgtl7mwk.pdf" class=yCF>Mind change complexity of learning logic programs</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, A Sharma - Computational Learning Theory, 1999 - Springer</div><div class="gs_rs">The present paper motivates the study of mind change complexity for learning minimal <br>models of length-bounded logic programs. It establishes ordinal mind change complexity <br>bounds for learnability of these classes both from positive facts and from positive and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11354289679037983444&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 5</a> <a href="/scholar?q=related:1GrxM06Kkp0J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/5D/62/RN059505117.html?source=googlescholar" class="gs_nph" class=yC11>BL Direct</a> <a href="/scholar?cluster=11354289679037983444&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'1GrxM06Kkp0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.105.5266&amp;rep=rep1&amp;type=pdf" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0890540103000592" class=yC12>On the intrinsic complexity of learning recursive functions</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, E Kinber, C Papazian, C Smith&hellip; - Information and  &hellip;, 2003 - Elsevier</div><div class="gs_rs">The intrinsic complexity of learning compares the difficulty of learning classes of objects by <br>using some reducibility notion. For several types of learning recursive functions, both natural <br>complete classes are exhibited and necessary and sufficient conditions for completeness <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3864074454383283924&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 5</a> <a href="/scholar?q=related:1E4tVz7znzUJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3864074454383283924&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'1E4tVz7znzUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/w7a5t1fc79t023u9.pdf" class=yC14>Compute inclusion depth of a pattern</a></h3><div class="gs_a"><a href="/citations?user=fIxBU34AAAAJ&amp;hl=en&amp;oi=sra">W Luo</a> - Learning Theory, 2005 - Springer</div><div class="gs_rs">We define a concept of inclusion depth (see Definition 1) to capture mind-change complexity <br>[3, 1] of pattern identification problems [2]. Our basic question is whether the inclusion depth <br>for any pattern is computable. We conjecture a combinatorial characterization that, if true, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14899502024658495280&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 5</a> <a href="/scholar?q=related:MKf7hSaqxc4J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14899502024658495280&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'MKf7hSaqxc4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397509007981" class=yC15>Mind change complexity of inferring unbounded unions of restricted pattern languages from positive data</a></h3><div class="gs_a">M de Brecht, A Yamamoto - Theoretical Computer Science, 2010 - Elsevier</div><div class="gs_rs">This paper shows that the mind change complexity of inferring from positive data the class of <br>unbounded unions of languages of regular patterns with constant segment length bound is <br>of the form [Formula: see text], assuming that the patterns are defined over a finite <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5440026599753841995&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 5</a> <a href="/scholar?q=related:S_0At17bfksJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5440026599753841995&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'S_0At17bfksJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://search.ieice.org/bin/summary.php?id=e86-d_2_219" class=yC16>Criteria for inductive inference with mind changes and anomalies of recursive real-valued functions</a></h3><div class="gs_a">E Hirowatari, K Hirata, T Miyahara&hellip; - &hellip;  on Information and  &hellip;, 2003 - search.ieice.org</div><div class="gs_rs">This paper investigates the interaction of&lt; I&gt; mind changes&lt;/I&gt; and&lt; I&gt; anomalies&lt;/I&gt; for <br>inductive inference of recursive real-valued functions. We show that the criteria for inductive <br>inference of recursive real-valued functions by bounding the number of mind changes and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17654136909435395244&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 5</a> <a href="/scholar?q=related:rFwCx_sXAPUJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17654136909435395244&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'rFwCx_sXAPUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397501004029" class=yC17>On learning unions of pattern languages and tree patterns in the mistake bound model</a></h3><div class="gs_a">SA Goldman, SS Kwek - Theoretical computer science, 2002 - Elsevier</div><div class="gs_rs">We present efficient on-line algorithms for learning unions of a constant number of tree <br>patterns, unions of a constant number of one-variable pattern languages, and unions of a <br>constant number of pattern languages with fixed length substitutions. By fixed length <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13629384158032478012&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 4</a> <a href="/scholar?q=related:PL_cHq5MJb0J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13629384158032478012&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'PL_cHq5MJb0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://fs1.bib.tiera.ru/content/dvd52/Balcazar%20J.%20L.%20(Ed),%20Long%20Ph.%20M.%20(Ed),%20Stephan%20F.%20(Ed)%20-%20Algorithmic%20Learning%20Theory.%2017th%20International%20Conference,%20ALT%202006,%20Barcelona,%20Spain,%20October%207-10,%202006,%20Proceedings(2006)(393).pdf#page=135" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tiera.ru</span><span class="gs_ggsS">tiera.ru <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/953nl87770n8u582.pdf" class=yC18>Mind change complexity of inferring unbounded unions of pattern languages from positive data</a></h3><div class="gs_a">M de Brecht, A Yamamoto - Algorithmic Learning Theory, 2006 - Springer</div><div class="gs_rs">This paper gives a proof that the class of unbounded unions of languages of regular patterns <br>with constant segment length bound is inferable from positive data with mind change bound <br>between Ï Ï and www Ï^ Ï^ Ï. We give a very tight bound on the mind change <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7989471669290439859&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 3</a> <a href="/scholar?q=related:s5QaNydO4G4J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/06/22/RN195821070.html?source=googlescholar" class="gs_nph" class=yC1A>BL Direct</a> <a href="/scholar?cluster=7989471669290439859&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'s5QaNydO4G4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://cs5235.userapi.com/u133638729/docs/0b3b37a51a80/Ricard_Gavald_Algorithmic_Learning_Theory_14_co.pdf#page=54" class=yC1C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from userapi.com</span><span class="gs_ggsS">userapi.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/QTAUAWTR9PFWEC4K.pdf" class=yC1B>On ordinal VC-dimension and some notions of complexity</a></h3><div class="gs_a">E Martin, A Sharma, F Stephan - Algorithmic Learning Theory, 2003 - Springer</div><div class="gs_rs">We generalize the classical notion of VC-dimension to ordinal VC-dimension, in the context <br>of logical learning paradigms. Logical learning paradigms encompass the numerical <br>learning paradigms commonly studied in Inductive inference. A logical learning paradigm <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11598219360499038989&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 3</a> <a href="/scholar?q=related:DXua8Q4n9aAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/14/0E/RN139774909.html?source=googlescholar" class="gs_nph" class=yC1D>BL Direct</a> <a href="/scholar?cluster=11598219360499038989&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 24 versions</a> <a onclick="return gs_ocit(event,'DXua8Q4n9aAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://sites.google.com/site/omundodalogica/livros-de-introducao-a-logica/Logic,Epistemology,andtheUnityofScienceVol.9-Induction,AlgorithmicLearningTheory,andPhilosophy.pdf#page=68" class=yC1F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from google.com</span><span class="gs_ggsS">google.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/m447337826676k75.pdf" class=yC1E>Deduction, Induction, and beyond in Parametric Logic</a></h3><div class="gs_a">E Martin, A Sharma, F Stephan - Induction, Algorithmic Learning Theory,  &hellip;, 2007 - Springer</div><div class="gs_rs">With parametric logic, we propose a unified approach to deduction and induction, both <br>viewed as particular instances of a generalized notion of logical consequence. This <br>generalized notion of logical consequence is Tarskian, in the sense that if a sentence Ï is <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3826540455174914098&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 2</a> <a href="/scholar?q=related:MsBcJUWaGjUJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3826540455174914098&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'MsBcJUWaGjUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://fs1.bib.tiera.ru/content/dvd52/Balcazar%20J.%20L.%20(Ed),%20Long%20Ph.%20M.%20(Ed),%20Stephan%20F.%20(Ed)%20-%20Algorithmic%20Learning%20Theory.%2017th%20International%20Conference,%20ALT%202006,%20Barcelona,%20Spain,%20October%207-10,%202006,%20Proceedings(2006)(393).pdf#page=120" class=yC21><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tiera.ru</span><span class="gs_ggsS">tiera.ru <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/Q4H243321323V6K8.pdf" class=yC20>The complexity of learning SUBSEQ (A)</a></h3><div class="gs_a">S Fenner, W Gasarch - Algorithmic Learning Theory, 2006 - Springer</div><div class="gs_rs">Higman showed that if A is any language then SUBSEQ (A) is regular, where SUBSEQ (A) is <br>the language of all subsequences of strings in A. We consider the following inductive <br>inference problem: given A (Îµ), A (0), A (1), A (00),... learn, in the limit, a DFA for SUBSEQ (<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7166936788827125287&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 2</a> <a href="/scholar?q=related:Jza4kQkTdmMJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/12/1C/RN195821068.html?source=googlescholar" class="gs_nph" class=yC22>BL Direct</a> <a href="/scholar?cluster=7166936788827125287&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 36 versions</a> <a onclick="return gs_ocit(event,'Jza4kQkTdmMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/tfnvaubgr6letkab.pdf" class=yC23>On a syntactic characterization of classification with a mind change bound</a></h3><div class="gs_a">E Martin, A Sharma - Learning Theory, 2005 - Springer</div><div class="gs_rs">Most learning paradigms impose a particular syntax on the class of concepts to be learned; <br>the chosen syntax can dramatically affect whether the class is learnable or not. For <br>classification paradigms, where the task is to determine whether the underlying world <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13286944438442872482&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 2</a> <a href="/scholar?q=related:ok69y5G1ZLgJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13286944438442872482&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'ok69y5G1ZLgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0890540104000392" class=yC24>On the classification of recursive languages</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, E Kinber, A Sharma, F Stephan - Information and Computation, 2004 - Elsevier</div><div class="gs_rs">A one-sided classifier for a given class of languages converges to 1 on every language from <br>the class and outputs 0 infinitely often on languages outside the class. A two-sided classifier, <br>on the other hand, converges to 1 on languages from the class and converges to 0 on <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9860301080863200061&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 1</a> <a href="/scholar?q=related:PVNAR5fT1ogJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9860301080863200061&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'PVNAR5fT1ogJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397506004907" class=yC25>On ordinal VC-dimension and some notions of complexity</a></h3><div class="gs_a">E Martin, A Sharma, F Stephan - Theoretical computer science, 2006 - Elsevier</div><div class="gs_rs">We generalize the classical notion of VapnikâChernovenkis (VC) dimension to ordinal VC-<br>dimension, in the context of logical learning paradigms. Logical learning paradigms <br>encompass the numerical learning paradigms commonly studied in Inductive Inference. A <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17050550864274109231&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 1</a> <a href="/scholar?q=related:L7PJYay5n-wJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17050550864274109231&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'L7PJYay5n-wJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB20" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW20"><a href="http://www.comp.nus.edu.sg/~sanjay/paps/resep.pdf" class=yC27><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/0F9V180D4H1PDFK4.pdf" class=yC26>Learning how to separate</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, F Stephan - Algorithmic Learning Theory, 2001 - Springer</div><div class="gs_rs">The main question addressed in the present work is how to find effectively a recursive <br>function separating two sets drawn arbitrarily from a given collection of disjoint sets. In <br>particular, it is investigated in which cases it is possible to satisfy the following additional <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8799620550752064841&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 1</a> <a href="/scholar?q=related:SdXNvUSIHnoJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/0F/48/RN105609000.html?source=googlescholar" class="gs_nph" class=yC28>BL Direct</a> <a href="/scholar?cluster=8799620550752064841&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 19 versions</a> <a onclick="return gs_ocit(event,'SdXNvUSIHnoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="ftp://142.58.111.31/fas-info/ftp/ftp/pub/cs/theses/2007/WeiLuoPhD.pdf" class=yC2A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 142.58.111.31</span><span class="gs_ggsS">142.58.111.31 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="ftp://142.58.111.31/fas-info/ftp/ftp/pub/cs/theses/2007/WeiLuoPhD.pdf" class=yC29>Mind change optimal learning: theory and applications</a></h3><div class="gs_a"><a href="/citations?user=fIxBU34AAAAJ&amp;hl=en&amp;oi=sra">W Luo</a> - 2007 - 142.58.111.31</div><div class="gs_rs">Abstract Learning theories play a significant role to machine learning as computability and <br>complexity theories to software engineering. Gold&#39;s language learning paradigm is one <br>cornerstone of modern learning theories. The aim of this thesis is to establish an inductive <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11533246138184030721&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 1</a> <a href="/scholar?q=related:AdqaxUFSDqAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11533246138184030721&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 34 versions</a> <a onclick="return gs_ocit(event,'AdqaxUFSDqAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md21', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md21" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:AdqaxUFSDqAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a>  <a href="/scholar?q=info:AdqaxUFSDqAJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=14678773570696185909&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB22" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW22"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.97.1000&amp;rep=rep1&amp;type=pdf" class=yC2C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0890540103001743" class=yC2B>Counting extensional differences in BC-learning</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, F Stephan, SA Terwijn - Information and Computation, 2004 - Elsevier</div><div class="gs_rs">Let BC be the model of behaviourally correct function learning as introduced by Ba Ì rzdins <br>[Theory of Algorithms and Programs, vol. 1, Latvian State University, 1974, p. 82â88] and <br>Case and Smith [Theoret. Comput. Sci. 25 (1983) 193â220]. We introduce a mind change <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9271161862474106604&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 1</a> <a href="/scholar?q=related:7Abr25fIqYAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9271161862474106604&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'7Abr25fIqYAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB23" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW23"><a href="http://arxiv.org/pdf/1106.5294" class=yC2E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arxiv.org</span><span class="gs_ggsS">arxiv.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397511006712" class=yC2D>Set systems: Order types, continuous nondeterministic deformations, and quasi-orders</a></h3><div class="gs_a">Y Akama - Theoretical Computer Science, 2011 - Elsevier</div><div class="gs_rs">By reformulating a learning process of a set system L as a game between Teacher and <br>Learner, we define the order type of L to be the order type of the game tree, if the tree is well-<br>founded. The features of the order type of L (dimL in symbol) are (1) we can represent any <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4933316456325941923&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 1</a> <a href="/scholar?q=related:o4rl3y2pdkQJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4933316456325941923&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'o4rl3y2pdkQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB24" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW24"><a href="http://www.comp.nus.edu.sg/~sanjay/paps/bemord.pdf" class=yC30><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0022000012000876" class=yC2F>Learning with ordinal-bounded memory from positive data</a></h3><div class="gs_a">L Carlucci, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, F Stephan - Journal of Computer and System Sciences, 2012 - Elsevier</div><div class="gs_rs">A bounded example memory learner operates incrementally and maintains a memory of <br>finitely many data items. The paradigm is well-studied and known to coincide with set-driven <br>learning. A hierarchy of stronger and stronger learning criteria had earlier been obtained <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:SO2jYG0s_0kJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5332029332114369864&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'SO2jYG0s_0kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB25" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW25"><a href="http://www.iip.ist.i.kyoto-u.ac.jp/member/matthew/Sigma2_full_version.pdf" class=yC32><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from kyoto-u.ac.jp</span><span class="gs_ggsS">kyoto-u.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.iip.ist.i.kyoto-u.ac.jp/member/matthew/Sigma2_full_version.pdf" class=yC31>Interpreting Learners as Realizers for Î£0</a></h3><div class="gs_a">M de Brecht, A Yamamoto - iip.ist.i.kyoto-u.ac.jp</div><div class="gs_rs">Abstract. We introduce the concept of a Î£0 2-admissible representation, which we then use <br>to interpret some basic Gold-style models of inductive inference within the field of <br>computable analysis. We interpret inductive inference problems as functions between <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:icHOhA4simwJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'icHOhA4simwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md25', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md25" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:icHOhA4simwJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB26" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW26"><a href="http://unsworks.unsw.edu.au/fapi/datastream/unsworks:2490/SOURCE2" class=yC34><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unsw.edu.au</span><span class="gs_ggsS">unsw.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://unsworks.unsw.edu.au/fapi/datastream/unsworks:2490/SOURCE2" class=yC33>Limiting Programs for Induction in Artificial Intelligence</a></h3><div class="gs_a">P Caldon - unsworks.unsw.edu.au</div><div class="gs_rs">ABSTRACT. This thesis examines a novel induction-based framework for logic <br>programming. Limiting programs are logic programs distinguished by two features, in <br>general they contain an infinite data stream over which induction will be performed, and in <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:iAv-0VdveX4J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9113437743936834440&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'iAv-0VdveX4J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md26', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md26" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:iAv-0VdveX4J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ri"><h3 class="gs_rt"><a href="http://projecteuclid.org/euclid.jsl/1245158093" class=yC35>The complexity of learning SUBSEQ (A)</a></h3><div class="gs_a">S Fenner, W Gasarch, B Postow - Journal of Symbolic Logic, 2009 - projecteuclid.org</div><div class="gs_rs">Abstract Higman essentially showed that if A is any language then SUBSEQ (A) is regular, <br>where SUBSEQ (A) is the language of all subsequences of strings in A. Let sâ, sâ, sâ,â¦ <br>be the standard lexicographic enumeration of all strings over some finite alphabet. We <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:g5V9744bXBUJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1539135473371157891&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'g5V9744bXBUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
