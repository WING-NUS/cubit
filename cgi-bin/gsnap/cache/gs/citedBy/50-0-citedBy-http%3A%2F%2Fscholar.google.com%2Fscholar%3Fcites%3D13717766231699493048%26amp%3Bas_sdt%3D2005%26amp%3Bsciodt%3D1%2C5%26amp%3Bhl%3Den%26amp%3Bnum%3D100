Total results = 50
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.ldmc.buaa.edu.cn/download/data_mining/A%20survey%20of%20content-based%20image%20retrieval%20with%20high-level%20semantics%20.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from buaa.edu.cn</span><span class="gs_ggsS">buaa.edu.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320306002184" class=yC0>A survey of content-based image retrieval with high-level semantics</a></h3><div class="gs_a">Y Liu, D Zhang, G Lu, WY Ma - Pattern Recognition, 2007 - Elsevier</div><div class="gs_rs">In order to improve the retrieval accuracy of content-based image retrieval systems, research <br>focus has been shifted from designing sophisticated low-level feature extraction algorithms <br>to reducing the &#39;semantic gap&#39;between the visual features and the richness of human <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7879404000356825275&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 576</a> <a href="/scholar?q=related:u3gPAzFEWW0J:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7879404000356825275&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 19 versions</a> <a onclick="return gs_ocit(event,'u3gPAzFEWW0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://www-cs.stanford.edu/groups/vision/documents/JiaFei-FeiIJCV_2009.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from stanford.edu</span><span class="gs_ggsS">stanford.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/h6h645811456802u.pdf" class=yC2>Optimol: automatic online picture collection via incremental model learning</a></h3><div class="gs_a"><a href="/citations?user=feX1fWAAAAAJ&amp;hl=en&amp;oi=sra">LJ Li</a>, <a href="/citations?user=rDfyQnIAAAAJ&amp;hl=en&amp;oi=sra">L Fei-Fei</a> - International journal of computer vision, 2010 - Springer</div><div class="gs_rs">Abstract The explosion of the Internet provides us with a tremendous resource of images <br>shared online. It also confronts vision researchers the problem of finding effective methods <br>to navigate the vast amount of visual information. Semantic image understanding plays a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2952832210663907282&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 155</a> <a href="/scholar?q=related:0h_0NUCR-igJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2952832210663907282&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 27 versions</a> <a onclick="return gs_ocit(event,'0h_0NUCR-igJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://lms.comp.nus.edu.sg/papers/media/2004/acmmm04-feng.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1027527.1027748" class=yC4>A bootstrapping framework for annotating and retrieving WWW images</a></h3><div class="gs_a">H Feng, R Shi, TS Chua - Proceedings of the 12th annual ACM  &hellip;, 2004 - dl.acm.org</div><div class="gs_rs">Abstract Most current image retrieval systems and commercial search engines use mainly <br>text annotations to index and retrieve WWW images. This research explores the use of <br>machine learning approaches to automatically annotate WWW images based on a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13909887808073208556&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 87</a> <a href="/scholar?q=related:7JK9gUPZCcEJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13909887808073208556&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'7JK9gUPZCcEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://lms.comp.nus.edu.sg/papers/media/2004/civr04-shirui.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/89ny0ybc9lbxc74k.pdf" class=yC6>An adaptive image content representation and segmentation approach to automatic image annotation</a></h3><div class="gs_a">R Shi, H Feng, TS Chua, CH Lee - Image and Video Retrieval, 2004 - Springer</div><div class="gs_rs">Automatic image annotation has been intensively studied for content-based image retrieval <br>recently. In this paper, we propose a novel approach to automatic image annotation based <br>on two key components:(a) an adaptive visual feature representation of image contents <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17434341814561893566&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 44</a> <a href="/scholar?q=related:vmyzXYI58_EJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/0E/3A/RN153246528.html?source=googlescholar" class="gs_nph" class=yC8>BL Direct</a> <a href="/scholar?cluster=17434341814561893566&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'vmyzXYI58_EJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://www.benthamscience.com/cseng/samples/cseng1-1/Tsai.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from benthamscience.com</span><span class="gs_ggsS">benthamscience.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.benthamscience.com/cseng/samples/cseng1-1/Tsai.pdf" class=yC9>Automatically annotating images with keywords: A review of image annotation systems</a></h3><div class="gs_a">CF Tsai, C Hung - Recent Patents on Computer Science, 2008 - benthamscience.com</div><div class="gs_rs">Abstract: The explosive growth of image data leads to the research and development of <br>Content-Based Image Retrieval (CBIR) systems. CBIR systems extract and retrieve images <br>by their low-level features, such as color, texture, and shape. However, these visual <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9686744838602593986&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 40</a> <a href="/scholar?q=related:wpbBrhs7boYJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'wpbBrhs7boYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md4', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md4" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:wpbBrhs7boYJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320311002391" class=yCB>A review on automatic image annotation techniques</a></h3><div class="gs_a">D Zhang, MM Islam, G Lu - Pattern Recognition, 2012 - Elsevier</div><div class="gs_rs">Nowadays, more and more images are available. However, to find a required image for an <br>ordinary user is a challenging task. Large amount of researches on image retrieval have <br>been carried out in the past two decades. Traditionally, research in this area focuses on <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13853996943203153734&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 27</a> <a href="/scholar?q=related:Rrf4dtFIQ8AJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13853996943203153734&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'Rrf4dtFIQ8AJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://www.soliun.unal.edu.co/~fgonza/papers/caicedo08airs.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unal.edu.co</span><span class="gs_ggsS">unal.edu.co <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/D006806TR52W3221.pdf" class=yCC>A semantic content-based retrieval method for histopathology images</a></h3><div class="gs_a"><a href="/citations?user=U50zLvkAAAAJ&amp;hl=en&amp;oi=sra">J Caicedo</a>, <a href="/citations?user=IUB__IwAAAAJ&amp;hl=en&amp;oi=sra">F Gonzalez</a>, E Romero - Information Retrieval Technology, 2008 - Springer</div><div class="gs_rs">This paper proposes a model for content-based retrieval of histopathology images. The most <br>remarkable characteristic of the proposed model is that it is able to extract high-level <br>features that reflect the semantic content of the images. This is accomplished by a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4522837198694162010&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 15</a> <a href="/scholar?q=related:Wp4WHXhYxD4J:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/4B/4A/RN231333731.html?source=googlescholar" class="gs_nph" class=yCE>BL Direct</a> <a href="/scholar?cluster=4522837198694162010&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 21 versions</a> <a onclick="return gs_ocit(event,'Wp4WHXhYxD4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0950705109001622" class=yCF>Dynamic Adaboost learning with feature selection based on parallel genetic algorithm for image annotation</a></h3><div class="gs_a">R Li, J Lu, Y Zhang, T Zhao - Knowledge-Based Systems, 2010 - Elsevier</div><div class="gs_rs">Image annotation can be formulated as a classification problem. Recently, Adaboost <br>learning with feature selection has been used for creating an accurate ensemble classifier. <br>We propose dynamic Adaboost learning with feature selection based on parallel genetic <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13513176228514267581&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 16</a> <a href="/scholar?q=related:vYHYFy9yiLsJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13513176228514267581&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'vYHYFy9yiLsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://www.cis.umac.mo/~fstzgg/kais2009.pdf" class=yC11><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from umac.mo</span><span class="gs_ggsS">umac.mo <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/whnm738681754n37.pdf" class=yC10>Improving keyword based web image search with visual feature distribution and term expansion</a></h3><div class="gs_a">Z Gong, Q Liu - Knowledge and information systems, 2009 - Springer</div><div class="gs_rs">Abstract This paper discusses techniques for improving the performance of keyword-based <br>web image queries. Firstly, a web page is segmented into several text blocks based on <br>semantic cohesion. The text blocks which contain web images are taken as the associated <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4969198903344743681&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 12</a> <a href="/scholar?q=related:AcUfHBMk9kQJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4969198903344743681&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'AcUfHBMk9kQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://cs5235.userapi.com/u133638729/docs/cc090e9c4cd3/Stphane_MarchandMaillet_Adaptive_Multimedia_Ret.pdf#page=21" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from userapi.com</span><span class="gs_ggsS">userapi.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/060X37237MR07354.pdf" class=yC12>Safire: Towards standardized semantic rich image annotation</a></h3><div class="gs_a">C Hentschel, <a href="/citations?user=LuMoBX0AAAAJ&amp;hl=en&amp;oi=sra">A NÃ¼rnberger</a>, I Schmitt&hellip; - &hellip;  Multimedia Retrieval: User, &hellip;, 2007 - Springer</div><div class="gs_rs">Most of the currently existing image retrieval systems make use of either low-level features <br>or semantic (textual) annotations. A combined usage during annotation and retrieval is <br>rarely attempted. In this paper, we propose a standardized annotation framework that <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7262605361726696444&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 10</a> <a href="/scholar?q=related:_CuR-Rj1yWQJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/5C/35/RN206775887.html?source=googlescholar" class="gs_nph" class=yC14>BL Direct</a> <a href="/scholar?cluster=7262605361726696444&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'_CuR-Rj1yWQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://nlp.kuee.kyoto-u.ac.jp/~shibata/paper/ACMMultimedia2007.pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from kyoto-u.ac.jp</span><span class="gs_ggsS">kyoto-u.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1291327" class=yC15>Automatic object model acquisition and object recognition by integrating linguistic and visual information</a></h3><div class="gs_a">T Shibata, N Kato, S Kurohashi - &hellip;  of the 15th international conference on  &hellip;, 2007 - dl.acm.org</div><div class="gs_rs">Abstract In order to make the best use of multimedia contents effectively, the crucial point is <br>the structural analysis of the contents, in which several media processing techniques, <br>including image, audio and text analyses, should be integrated. To understand utterances <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12078077933530749006&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 4</a> <a href="/scholar?q=related:TpiVXePznacJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12078077933530749006&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'TpiVXePznacJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5460008" class=yC17>A Weighted feature support vector machines method for semantic image classification</a></h3><div class="gs_a">K Wang, X Wang, Y Zhong - Measuring Technology and  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Organizing images into (semantically) meaningful categories using low-level visual <br>features is a challenging and important problem in content-based image retrieval. Much <br>machine learning methods has been done on automatic semantic image classification. In <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7101058239605894933&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 4</a> <a href="/scholar?q=related:Fe8RjdgGjGIJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7101058239605894933&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'Fe8RjdgGjGIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4285064" class=yC18>Learning Semantic Concepts for Image Retrieval using the Max-Min Posterior Pseudo-Probabilities</a></h3><div class="gs_a">Y Deng, X Liu, Y Jia - Multimedia and Expo, 2007 IEEE  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Semantic gap is the main problem in current content-based image retrieval. This <br>paper proposes an approach which aims to learn semantic concepts from visual features. <br>Each concept is modeled as a posterior pseudo-probability function, and the function <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=313400038164741865&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 4</a> <a href="/scholar?q=related:6T5nm6xrWQQJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=313400038164741865&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'6T5nm6xrWQQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5653562" class=yC19>Image labeling via incremental model learning</a></h3><div class="gs_a">Y Qu, C Chen, D Wu, Y Xie - Image Processing (ICIP), 2010  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The well-built dataset is a pre-requisite for object categorization. The processes of <br>collecting and labeling the images are laborious and monotonous. In order to label images <br>efficiently, we propose an incremental learning model to label images automatically with a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8596211120439482952&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 3</a> <a href="/scholar?q=related:SNoOKHjgS3cJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8596211120439482952&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'SNoOKHjgS3cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4295682" class=yC1A>Image Database Search using Fuzzy and Quantum Logic</a></h3><div class="gs_a">I Schmitt, <a href="/citations?user=LuMoBX0AAAAJ&amp;hl=en&amp;oi=sra">A Nurnberger</a> - Fuzzy Systems Conference, 2007.  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Most of the currently existing image retrieval systems make use of either low-level <br>features or semantic (textual) annotations. A combined usage during annotation and <br>retrieval is rarely attempted. In this paper, we present a query language that makes use of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11722956507545577285&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 2</a> <a href="/scholar?q=related:RaebLdVOsKIJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'RaebLdVOsKIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://cinacs.informatik.uni-hamburg.de/index.php?gid=204&amp;option=com_docman&amp;task=doc_download" class=yC1C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uni-hamburg.de</span><span class="gs_ggsS">uni-hamburg.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/1162r6t712414800.pdf" class=yC1B>Multi-modal multi-label semantic indexing of images based on hybrid ensemble learning</a></h3><div class="gs_a">W Li, M Sun, C Habel - &hellip;  in Multimedia Information ProcessingâPCM 2007, 2007 - Springer</div><div class="gs_rs">Automatic image annotation (AIA) refers to the association of words to whole images which <br>is considered as a promising and effective approach to bridge the semantic gap between <br>low-level visual features and high-level semantic concepts. In this paper, we formulate the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17228583680018449715&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 2</a> <a href="/scholar?q=related:M4WXdpM5GO8J:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/15/0D/RN221518248.html?source=googlescholar" class="gs_nph" class=yC1D>BL Direct</a> <a href="/scholar?cluster=17228583680018449715&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'M4WXdpM5GO8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://hal.archives-ouvertes.fr/docs/00/46/59/60/PDF/These_ED_0366-370_-_Najlae_IDRISSI_-_2008.pdf" class=yC1F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://hal.archives-ouvertes.fr/tel-00465960/" class=yC1E>La navigation dans les bases d&#39;images: prise en compte des attributs de texture</a></h3><div class="gs_a">N Idrissi - 2008 - hal.archives-ouvertes.fr</div><div class="gs_rs">RÃ©sumÃ© Ce travail de recherche entre dans le cadre des systÃ¨mes de recherche d&#39;images <br>par le contenu, en particulier la recherche par la texture. Le but de ce travail est de permettre <br>Ã  l&#39;utilisateur de naviguer dans de grande base de donnÃ©es d&#39;images sans formulation de <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5345067601461757147&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 2</a> <a href="/scholar?q=related:28STBap-LUoJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5345067601461757147&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'28STBap-LUoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://nlp.kuee.kyoto-u.ac.jp/~shibata/paper/NLP2005kato.pdf" class=yC21><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from kyoto-u.ac.jp</span><span class="gs_ggsS">kyoto-u.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://nlp.kuee.kyoto-u.ac.jp/~shibata/paper/NLP2005kato.pdf" class=yC20>è¨èªæå ±ã¨æ åæå ±ã®çµ±åã«ããç©ä½ã®ã¢ãã«å­¦ç¿ã¨èªè­</a></h3><div class="gs_a">å è¤ç´éï¼ æ´ç°ç¥ç§ï¼ é»æ©ç¦å¤« - è¨èªå¦çå­¦ä¼ ç¬¬ 11 åå¹´æ¬¡ &hellip;, 2005 - nlp.kuee.kyoto-u.ac.jp</div><div class="gs_rs">å®ä¸çæå ±, æ åæå ±ãªã©ã®é«åº¦ãªå©ç¨ã®ããã«ã¯, ãã®åå®¹ã®æ§é ççè§£ãå¿è¦ã§ãã. <br>æãã¯, æççªçµæ åã®æ¤ç´¢ã»è¦ç´ãç®çã¨ãã¦, ãã®çºè©±ã®æ§é è§£æãè¡ãªã£ã¦ãã [4] ã, <br>æ åä¸­ã®çºè©±ã, æ å (ç»åå) ãåç§ããã«è§£æããã®ã«ã¯éçããã, çºè©±ã®æèã¨æ åãã<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8568233887414531399&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 2</a> <a href="/scholar?q=related:R7XO-1J76HYJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8568233887414531399&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'R7XO-1J76HYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md17', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md17" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:R7XO-1J76HYJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/28481R371NL60168.pdf" class=yC22>The Study on the Semantic Image Retrieval Using the Cognitive Spatial Relationships in the Semantic Web</a></h3><div class="gs_a">H Kong, M Hwang, K Na, P Kim - Industrial Applications of Semantic Web, 2005 - Springer</div><div class="gs_rs">In present day, there are a number of image data in the web because of the development of <br>the image acquisition devices. So, many researchers have been studying about the image <br>retrieval and management. Keyword matching, contents-based and concept-based <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11581306725231661228&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 1</a> <a href="/scholar?q=related:rJBGMBsRuaAJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/35/08/RN200061273.html?source=googlescholar" class="gs_nph" class=yC23>BL Direct</a> <a href="/scholar?cluster=11581306725231661228&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'rJBGMBsRuaAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="http://cs5235.userapi.com/u133638729/docs/cc090e9c4cd3/Stphane_MarchandMaillet_Adaptive_Multimedia_Ret.pdf#page=10" class=yC25><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from userapi.com</span><span class="gs_ggsS">userapi.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/81772u531k7607gn.pdf" class=yC24>A method for processing the natural language query in ontology-based image retrieval system</a></h3><div class="gs_a"><a href="/citations?user=4tn6Ym8AAAAJ&amp;hl=en&amp;oi=sra">M Hwang</a>, H Kong, S Baek, P Kim - Adaptive Multimedia Retrieval: User,  &hellip;, 2007 - Springer</div><div class="gs_rs">There is a large amount of image data on the web because of the development of many <br>image acquisition devices nowadays. Hence, many researchers have been focusing on the <br>study how to manage and retrieve these huge images efficiently. In this paper, we use two <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4021830819661796725&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 1</a> <a href="/scholar?q=related:ddWoaNJp0DcJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/0F/09/RN206775876.html?source=googlescholar" class="gs_nph" class=yC26>BL Direct</a> <a href="/scholar?cluster=4021830819661796725&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'ddWoaNJp0DcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB20" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW20"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.85.6418&amp;rep=rep1&amp;type=pdf" class=yC28><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.85.6418&amp;rep=rep1&amp;type=pdf" class=yC27>Relevance Feedback in Content-Based Image Retrieval</a></h3><div class="gs_a">VN Gudivada - International Journal of Computer Science  &hellip;, 2010 - Citeseer</div><div class="gs_rs">Abstract Content-Based Image Retrieval (CBIR) systems are required to effectively harness <br>information from ubiquitous image collections. Despite intense research efforts by the <br>multidisciplinary CBIR community since early 1990s, apparently there is a mismatch <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9299656211777907456&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 1</a> <a href="/scholar?q=related:AOtGjA0ED4EJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9299656211777907456&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'AOtGjA0ED4EJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md20', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md20" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:AOtGjA0ED4EJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="http://bura.brunel.ac.uk/bitstream/2438/5452/1/FulltextThesis.pdf" class=yC2A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from brunel.ac.uk</span><span class="gs_ggsS">brunel.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://bura.brunel.ac.uk/handle/2438/5452" class=yC29>Parallelizing support vector machines for scalable image annotation</a></h3><div class="gs_a">NK Alham - 2011 - bura.brunel.ac.uk</div><div class="gs_rs">Machine learning techniques have facilitated image retrieval by automatically classifying <br>and annotating images with keywords. Among them Support Vector Machines (SVMs) are <br>used extensively due to their generalization properties. However, SVM training is notably <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9458899288383748179&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 1</a> <a href="/scholar?q=related:U_hOksnCRIMJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9458899288383748179&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'U_hOksnCRIMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/X13462692Q13P0Q5.pdf" class=yC2B>Composition based semantic scene retrieval for ancient murals</a></h3><div class="gs_a">Q Wang, D Lu, <a href="/citations?user=NQZdq10AAAAJ&amp;hl=en&amp;oi=sra">H Zhang</a> - &hellip; in Multimedia Information Processing-PCM 2010, 2010 - Springer</div><div class="gs_rs">Retrieval of similar scenes in ancient murals research is an important but time-consuming <br>job for researchers. However, content-based image retrieval (CBIR) systems cannot fully <br>deal with such issues since they lack of the abilities to handle complex semantic and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9224232574820071336&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 1</a> <a href="/scholar?q=related:qLe8m6cOA4AJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9224232574820071336&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'qLe8m6cOA4AJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB23" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW23"><a href="http://cinacs.informatik.uni-hamburg.de/index2.php?gid=205&amp;option=com_docman&amp;task=doc_view" class=yC2D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uni-hamburg.de</span><span class="gs_ggsS">uni-hamburg.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4584367" class=yC2C>Multi-modal multi-label semantic indexing of images using unlabeled data</a></h3><div class="gs_a">W Li, M Sun - &hellip;  and Web Information Technology, 2008. ALPIT&#39; &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Automatic image annotation (AIA) refers to the association of words to whole <br>images which is considered as a promising and effective approach to bridge the semantic <br>gap between low-level visual features and high-level semantic concepts. In this paper, we <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7969847875393440005&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 1</a> <a href="/scholar?q=related:BUm6pmqWmm4J:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7969847875393440005&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'BUm6pmqWmm4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1593305" class=yC2E>Deriving semantic terms for images by mining the web</a></h3><div class="gs_a">Z Gong, Q Liu, J Guo - Proceedings of the 11th International Conference  &hellip;, 2009 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we provide a novel image annotation model by mining the Web. In our <br>approach, the concepts or words appearing in the associated text are extracted and filtered <br>as the semantic annotations for the corresponding Web images. In order to alleviate the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12961349594611427879&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 1</a> <a href="/scholar?q=related:J6p3vMj237MJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'J6p3vMj237MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB25" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW25"><a href="http://users.monash.edu.au/~dengs/resource/papers/dicta08-1.pdf" class=yC30><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from monash.edu.au</span><span class="gs_ggsS">monash.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4700065" class=yC2F>Digital Image Retrieval Using Intermediate Semantic Features and Multistep Search</a></h3><div class="gs_a">D Zhang, Y Liu, J Hou - Computing: Techniques and  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Recently, semantic image retrieval has attracted large amount of interest due to the <br>rapid growth of digital image storage. However, existing approaches have severe limitations. <br>In this paper, a new approach to digital image retrieval using intermediate semantic <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15194773661582496466&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 2</a> <a href="/scholar?q=related:0hIWzSOu3tIJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15194773661582496466&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'0hIWzSOu3tIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB26" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW26"><a href="http://bioinformatics.oxfordjournals.org/content/27/10/1422.full" class=yC32><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from oxfordjournals.org</span><span class="gs_ggsS">oxfordjournals.org <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://bioinformatics.oxfordjournals.org/content/27/10/1422.short" class=yC31>Inference of transcriptional regulatory network by bootstrapping patterns</a></h3><div class="gs_a">HC Wang, YHS Chen, <a href="/citations?user=X5Is2lAAAAAJ&amp;hl=en&amp;oi=sra">HY Kao</a>, SJ Tsai - Bioinformatics, 2011 - Oxford Univ Press</div><div class="gs_rs">Abstract Motivation: Transcriptional regulatory networks, which consist of linkages between <br>transcription factors (TF) and target genes (TGene), control the expression of a genome and <br>play important roles in all aspects of an organism&#39;s life cycle. Accurate prediction of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=712821187540519058&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=50">Cited by 1</a> <a href="/scholar?q=related:koi55xdz5AkJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=712821187540519058&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'koi55xdz5AkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB27" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW27"><a href="http://www.cis.umac.mo/~fstzgg/dawak2006.pdf" class=yC34><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from umac.mo</span><span class="gs_ggsS">umac.mo <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/x860855r630j2366.pdf" class=yC33>Automatic image annotation by mining the web</a></h3><div class="gs_a">Z Gong, Q Liu, J Zhang - Data Warehousing and Knowledge Discovery, 2006 - Springer</div><div class="gs_rs">Automatic image annotation has been becoming an attractive research subject. Most current <br>image annotation methods are based on training techniques. The major weaknesses of <br>such solutions include limited annotation vocabulary and labor-intensive involvement. <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:w_kfJz2koUcJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/32/45/RN194891621.html?source=googlescholar" class="gs_nph" class=yC35>BL Direct</a> <a href="/scholar?cluster=5161587230499666371&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'w_kfJz2koUcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1937748" class=yC36>Weakly supervised landmark labeling in searched data</a></h3><div class="gs_a">Y Qu, C Chen, Y Cheng, Z Yuan - Proceedings of the Second  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract Millions of place-specified photos are uploaded on the internet. Modeling and <br>representing the landmark is very important for landmark retrieval and auto-annotation. In <br>this paper, we aim at collecting images with a specific landmark and labeling the landmark <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:9tcmK_XxuccJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'9tcmK_XxuccJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB29" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW29"><a href="http://arxiv.org/pdf/1006.4568" class=yC38><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arxiv.org</span><span class="gs_ggsS">arxiv.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://arxiv.org/abs/1006.4568" class=yC37>Approaches, Challenges and Future Direction of Image Retrieval</a></h3><div class="gs_a">HH Wang, D Mohamad, <a href="/citations?user=irGmToYAAAAJ&amp;hl=en&amp;oi=sra">NA Ismail</a> - arXiv preprint arXiv:1006.4568, 2010 - arxiv.org</div><div class="gs_rs">Abstract: This paper attempts to discuss the evolution of the retrieval approaches focusing <br>on development, challenges and future direction of the image retrieval. It highlights both the <br>already addressed and outstanding issues. The explosive growth of image data leads to <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:68W4L1Yk0nwJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8994291358398727659&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'68W4L1Yk0nwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1650234" class=yC39>Building an automatic annotate image system by using bootstrapping</a></h3><div class="gs_a">YL Lin, CH Kuo, NL Tsao - Proceedings of the 10th IASTED International  &hellip;, 2007 - dl.acm.org</div><div class="gs_rs">Abstract The images are always playing an important role on teaching and learning. <br>However, it is not easy to get sufficient and appropriate images rapidly for these purposes. In <br>this paper, we have designed a database that can automatically collect and classify <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:zMyiMF2n0-sJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16993109837688786124&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'zMyiMF2n0-sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB31" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW31"><a href="http://www.scholarbank.nus.edu.sg/bitstream/handle/10635/14783/thesis_body%20(huamin).pdf?sequence=2" class=yC3B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.scholarbank.nus.edu.sg/handle/10635/14783" class=yC3A>Auto-annotation of multimedia contents: Theory and application</a></h3><div class="gs_a">F HUAMIN - 2005 - scholarbank.nus.edu.sg</div><div class="gs_rs">In this thesis, we propose a learning-based framework for auto-annotation of multimedia <br>contents. The framework is open and is designed to incorporate different base learners, <br>including the single-view machine learning (traditional) and the bootstrapping approaches<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:3raxSNrVELEJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12758932877839808222&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'3raxSNrVELEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> The Study on the Efficient Browsing Methodology in the Ontology-based Image Retrieval System</h3><div class="gs_a"><a href="/citations?user=4tn6Ym8AAAAJ&amp;hl=en&amp;oi=sra">M Hwang</a>, H Kong, P Kim</div><div class="gs_fl"><a href="/scholar?q=related:dj9dZ8waXb0J:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'dj9dZ8waXb0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:367"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB33" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW33"><a href="http://www.editlib.org/p/25570/proceeding_25570.pdf" class=yC3D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from editlib.org</span><span class="gs_ggsS">editlib.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.editlib.org/noaccess/25570" class=yC3C>Building an Image Database for Teaching and Learning by Using Bootstrapping</a></h3><div class="gs_a">YL Lin, CH Kuo, NL Tsao - World Conference on Educational Multimedia,  &hellip;, 2007 - editlib.org</div><div class="gs_rs">Abstract The images are always playing an important role on teaching and learning. <br>However, it is not easy to get sufficient and appropriate images rapidly for these purposes. In <br>this paper, we have designed a database that can automatically collect and classify <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:8vzpaUx09I8J:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10373043713284373746&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'8vzpaUx09I8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:366"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB34" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW34"><a href="http://www.cim.mcgill.ca/~levine/KyleThesis.pdf" class=yC3F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mcgill.ca</span><span class="gs_ggsS">mcgill.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.cim.mcgill.ca/~levine/KyleThesis.pdf" class=yC3E>Improving Image Classification by Co-training with Multi-modal Features</a></h3><div class="gs_a">K Weston - 2011 - cim.mcgill.ca</div><div class="gs_rs">ABSTRACT We explore the use of co-training to improve the performance of image <br>classification in the setting where multiple classifiers are used and several types of features <br>are available. Features are assigned to classifiers in an optimal manner using hierarchical <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ekq8hO9TSQIJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=164755149564955258&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'ekq8hO9TSQIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md34', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md34" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:ekq8hO9TSQIJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:365"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB35" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW35"><a href="http://researchbank.rmit.edu.au/eserv/rmit:6607/Awgiskandar.pdf" class=yC41><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from rmit.edu.au</span><span class="gs_ggsS">rmit.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://researchbank.rmit.edu.au/view/rmit:6607" class=yC40>Image retrieval using automatic region tagging</a></h3><div class="gs_a">D Awg Iskandar - 2008 - researchbank.rmit.edu.au</div><div class="gs_rs">Abstract The task of tagging, annotating or labelling image content automatically with <br>semantic keywords is a challenging problem. To automatically tag images semantically <br>based on the objects that they contain is essential for image retrieval. In addressing these <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ceiBkQS09s4J:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14913305147798055025&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'ceiBkQS09s4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:364"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB36" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW36"><a href="https://scholarworks.iu.edu/dspace/bitstream/handle/2022/13690/Yu_indiana_0093A_11081.pdf?sequence=1" class=yC43><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from iu.edu</span><span class="gs_ggsS">iu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="https://scholarworks.iu.edu/dspace/handle/2022/13690" class=yC42>Semi-supervised learning for identifying opinions in Web content</a></h3><div class="gs_a">N Yu - 2011 - scholarworks.iu.edu</div><div class="gs_rs">Abstract: Opinions published on the World Wide Web (Web) offer opportunities for detecting <br>personal attitudes regarding topics, products, and services. The opinion detection literature <br>indicates that both a large body of opinions and a wide variety of opinion features are <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:BBh8nLEeIWUJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7287139420245596164&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'BBh8nLEeIWUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:363"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1734640" class=yC44>Automatic online labeling images via co-active-learning</a></h3><div class="gs_a">Y Qu, L Liu, Y Xie, Z Yuan - &hellip;  of the First International Conference on  &hellip;, 2009 - dl.acm.org</div><div class="gs_rs">Abstract The well-built dataset is a pre-requisite for computer vision research. However, the <br>process of collecting and labeling the images is laborious and monotonous. In this paper, <br>we aim to automatic labeling and collecting the images for the visual object category. We <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:x8a6pmvrc1gJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'x8a6pmvrc1gJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:362"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/Y74K834227735258.pdf" class=yC45>Two-stage localization for image labeling</a></h3><div class="gs_a">Y Qu, D Wu, Y Cheng, C Chen - Advances in Multimedia Information  &hellip;, 2010 - Springer</div><div class="gs_rs">The well-built dataset is a pre-requisite for object categorization. However, the processes of <br>collecting and labeling the images are laborious and monotonous. In this paper, we focus on <br>an automatic labeling of images by using a bounding box for each visual object. We <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:4HcbtxNXZhAJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1181727694419359712&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'4HcbtxNXZhAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:361"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB39" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW39"><a href="http://upcommons.upc.edu/pfc/bitstream/2099.1/7724/1/MasterThesisMehdi.pdf" class=yC47><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from upc.edu</span><span class="gs_ggsS">upc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://upcommons.upc.edu/handle/2099.1/7724" class=yC46>Contextual Bag-Of-Visual-Words and ECOC-Rank for Retrieval and Multi-class Object Recognition</a></h3><div class="gs_a"><a href="/citations?user=c646VbAAAAAJ&amp;hl=en&amp;oi=sra">M Mirza-Mohammadi</a> - 2009 - upcommons.upc.edu</div><div class="gs_rs">Multi-class object categorization is an important line of research in Computer Vision and <br>Pattern Recognition fields. An artificial intelligent system is able to interact with its <br>environment if it is able to distinguish among a set of cases, instances, situations, objects, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:n9rbxLvb19AJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15048738279389911711&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'n9rbxLvb19AJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:360"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB40" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW40"><a href="http://www.informed.unal.edu.co/jccaicedo/papers/masterThesis.pdf" class=yC49><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unal.edu.co</span><span class="gs_ggsS">unal.edu.co <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.informed.unal.edu.co/jccaicedo/papers/masterThesis.pdf" class=yC48>A Prototype System to Archive and Retrieve Histopathology Images by Content</a></h3><div class="gs_a">JCC Rueda - informed.unal.edu.co</div><div class="gs_rs">Medical images have been widely used to support clinical decisions in health centers for <br>many years. The medical practice requires to evaluate patient&#39;s health with reliable evidence <br>to recommend effective treatments and medical images provide enough information about <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:j-jb4aQMXI4J:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10258087953546602639&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'j-jb4aQMXI4J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md40', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md40" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:j-jb4aQMXI4J:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:359"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB41" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW41"><a href="http://www.usc.edu/dept/ise/caie/Checked%20Papers%20%5Bruhi%2012th%20sept%5D/word%20format%20papers/REGISTRATION%20PAID%20PAPERS%20FOR%20PROCEEDINGS/pdf/184%203%20A%20PSO-SVM%20Approach%20for%20Image%20Retrieval%20and%20Clustering.pdf" class=yC4B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from usc.edu</span><span class="gs_ggsS">usc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.usc.edu/dept/ise/caie/Checked%20Papers%20%5Bruhi%2012th%20sept%5D/word%20format%20papers/REGISTRATION%20PAID%20PAPERS%20FOR%20PROCEEDINGS/pdf/184%203%20A%20PSO-SVM%20Approach%20for%20Image%20Retrieval%20and%20Clustering.pdf" class=yC4A>A PSO-SVM Approach for Image Retrieval and Clustering</a></h3><div class="gs_a">L Ma, <a href="/citations?user=FTNyLhcAAAAJ&amp;hl=en&amp;oi=sra">L Lin</a>, <a href="/citations?user=1NG9laQAAAAJ&amp;hl=en&amp;oi=sra">M Gen</a> - usc.edu</div><div class="gs_rs">Abstract In order to improve the retrieval accuracy of content-based image retrieval systems, <br>several approaches have been designed for sophisticated low-level feature extraction and <br>the &#39;semantic gap&#39;reduction between the visual features and the richness of human <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:0mGV6cZqv3UJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'0mGV6cZqv3UJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md41', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md41" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:0mGV6cZqv3UJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:358"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5172797" class=yC4C>A New Approach for Interactive Image Retrieval Based on Fuzzy Feedback and Support Vector Machine</a></h3><div class="gs_a">M Javidi, BS Aski, H Homaei&hellip; - &hellip;  for Modelling Control &amp;  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we introduce an efficient content-based image retrieval system based <br>on fuzzy relevance feedback. Conventional content based image retrieval (CBIR) systems <br>that use relevance feedback (RF), want user to mark retrieved images as relevant or <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:r8yC6nOMUbwJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13569781581727583407&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'r8yC6nOMUbwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:357"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB43" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW43"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/book04-chuats.pdf" class=yC4E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/1324717R67U00675.pdf" class=yC4D>A Scalable Bootstrapping Framework for Auto-Annotation of Large Image Collections</a></h3><div class="gs_a">TS Chua, H Feng - Intelligent Multimedia Processing with Soft Computing, 2005 - Springer</div><div class="gs_rs">Image annotation aims to assign semantic concepts to images based on their visual <br>contents. It has received much attention recently as huge dynamic collections of <br>images/videos become available on the Web. Most recent approaches employ supervised <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:yeMT7QgHwSoJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/3D/45/RN157975788.html?source=googlescholar" class="gs_nph" class=yC4F>BL Direct</a> <a href="/scholar?cluster=3080751355016766409&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'yeMT7QgHwSoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:356"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB44" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW44"><a href="http://www.mickey.ai.kyutech.ac.jp/~ipsj/event/sympo2005/papers/B-2-2.pdf" class=yC51><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from kyutech.ac.jp</span><span class="gs_ggsS">kyutech.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.mickey.ai.kyutech.ac.jp/~ipsj/event/sympo2005/papers/B-2-2.pdf" class=yC50>ãã­ã¹ãã¨ç»åãçµ±ä¸çã«æ±ãæ¦å¿µçæå ±æ¤ç´¢</a></h3><div class="gs_a">é«å¶ä¿®ï¼ å·ä¸éå¹¸ï¼ è¤ç°åå£«ï¼ ä¸­å³¶èª ï¼ ä¼è¤å²é - mickey.ai.kyutech.ac.jp</div><div class="gs_rs">ã­ã¼ã¯ã¼ãã«ããè³ªåãç¨ããç»åæ¤ç´¢ã·ã¹ãã ã§ã¯, ç»åã®åå®¹ãèª¬æããã®ã«å¿è¦ååãª<br>ãã­ã¹ããç»åã«ä»å ãã¦ãããã¨ãéè¦ã§ãã. ããã§ã¯, ä¸»é¡ã®å¤§ã¾ããªéãã«å¿ããç»åã®<br>ã¿ã¤ãåããåºã«, å¤ãã®ã¦ã¼ã¶ã WWW ãä»ãã¦æ¤ç´¢ããç»åã«ãã­ã¹ããä»å ãããããã<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:GQuTBN57EwEJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'GQuTBN57EwEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md44', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md44" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:GQuTBN57EwEJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:355"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB45" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW45"><a href="http://gxbwk.njournal.sdu.edu.cn/EN/article/downloadArticleFile.do?attachType=PDF&amp;id=2357" class=yC53><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from sdu.edu.cn</span><span class="gs_ggsS">sdu.edu.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://gxbwk.njournal.sdu.edu.cn/EN/article/downloadArticleFile.do?attachType=PDF&amp;id=2357" class=yC52>ä¸ç§åºäºä¸»å¨å­¦ä¹ çéæååè®­ç»ç®æ³</a></h3><div class="gs_a">è°¢ä¼çï¼ åæ - å±±ä¸å¤§å­¦å­¦æ¥ (å·¥å­¦ç), 2012 - gxbwk.njournal.sdu.edu.cn</div><div class="gs_rs">æè¦: ä¸ºäºæ´å¥½å°åæ¥ä¸»å¨å­¦ä¹ , åçç£å­¦ä¹ åéæå­¦ä¹ è¿3 ç§æºå¨å­¦ä¹ æ¹æ³çä¼å¿, ç ç©¶äº1 <br>ä¸ªä¸éè¦2 ä¸ªåååä½è§å¾, æ³åè½åå¼ºçé«æå­¦ä¹ ç®æ³. ä»èç±»åè®¾åºå, <br>ç»åºæ¯è½®ååè®­ç»è¿ç¨ä¸­æ·»å èªå¨æ è®°æ ·æ¬çç½®ä¿¡åº¦åº¦éæ¹æ³, éä½è¯¯æ è®°ç; æåºä½ä¸ºä¸»å¨<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:uvHDUMGVfrUJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13078055025446744506&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'uvHDUMGVfrUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md45', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md45" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:uvHDUMGVfrUJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:354"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB46" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW46"><a href="http://ethesys.lib.cyut.edu.tw/ETD-db/ETD-search/getfile?URN=etd-0628107-151251&amp;filename=etd-0628107-151251.pdf" class=yC55><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cyut.edu.tw</span><span class="gs_ggsS">cyut.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ethesys.lib.cyut.edu.tw/ETD-db/ETD-search/view_etd?URN=etd-0628107-151251" class=yC54>Semantic Consumer Image Retrieval System Based on Multi-layer Color Features</a></h3><div class="gs_a">YL Yin - 2007 - ethesys.lib.cyut.edu.tw</div><div class="gs_rs">Abstract In recent years, digital photography has been gradually replacing traditional film <br>photography into the mainstream imaging methods. Due to the convenience of digital <br>photography, the average consumer may also possess a staggering amount of digital <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:S1zgX3G2MdwJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'S1zgX3G2MdwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:353"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB47" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW47"><a href="http://www.zndxzk.com.cn/upfile/soft/20111216/4-32-348-p0750.pdf" class=yC57><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from zndxzk.com.cn</span><span class="gs_ggsS">zndxzk.com.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.zndxzk.com.cn/upfile/soft/20111216/4-32-348-p0750.pdf" class=yC56>åºäº ReliefF ç¹å¾å ææ¯æåéæºçè¯­ä¹å¾ååç±»</a></h3><div class="gs_a">åæ°ï¼ æåå¹³ - ä¸­åå¤§å­¦å­¦æ¥ (èªç¶ç§å­¦ç), 2011 - zndxzk.com.cn</div><div class="gs_rs">æè¦: æåºä¸ç§åºäºReliefF ç¹å¾å ææ¯æåéæºçè¯­ä¹å¾ååç±»æ¹æ³. é¦å, éè¿ReliefF <br>ç®æ³è®¡ç®è®­ç»æ°æ®éä¸­å¾åçç¹å¾æé; ç¶å, å©ç¨å·æä¸åæéçç¹å¾åéæ¥è®¡ç®æ ¸å½æ°å¹¶ä¸<br>è®­ç»æ¯æåéæº; æå, ç¨ç»è¿è®­ç»çæ¯æåéæºå¯¹æµè¯æ°æ®éä¸­çå¾åè¿è¡èªå¨åç±». å®éª<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:6-HQvzq9nZoJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'6-HQvzq9nZoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md47', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md47" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:6-HQvzq9nZoJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:352"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB48" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW48"><a href="http://tkuir.lib.tku.edu.tw/dspace/bitstream/987654321/7051/2/942520S032005.pdf" class=yC59><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tku.edu.tw</span><span class="gs_ggsS">tku.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://tkuir.lib.tku.edu.tw/dspace/handle/987654321/7051" class=yC58>ä»¥èªå©å¼å»ºæ§æ³å»ºç«æå­¸ç¨ä¹ååç´ æåº«</a></h3><div class="gs_a">é­ç¶è¯ - 2005 - tkuir.lib.tku.edu.tw</div><div class="gs_rs">å¨ç¶²éç¶²è·¯ç¼éçç¾ä»ç¤¾æ, ååç´ æåº«å·²ç¶éå¸¸çæ®é. ä½æ¯å°éçºäºæå­¸èè¨­è¨çåçåé¡<br>ç³»çµ±, å»æ¯å°ä¹åå°. èæ¬è¨ç«[æå­¸å°ååçåé¡ç³»çµ±ä¹è¨­è¨] å°ä»¥æå­¸çºåºç¼é», <br>è¨­è¨ååæª¢ç´¢ç³»çµ±, ä¿é²å­¸ç¿èçå­¸ç¿ææ. æ¬è¨ç«ææåºä¹ç³»çµ±å·æä»¥ä¸ç¹è²: 1. ä»¥èªå©å¼<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:gh953tBg68MJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'gh953tBg68MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:351"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB49" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW49"><a href="http://www.dca.fee.unicamp.br/~leopini/private/teses-pdf/Tese-Andre_Tavares_da_Silva.pdf" class=yC5B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unicamp.br</span><span class="gs_ggsS">unicamp.br <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.dca.fee.unicamp.br/~leopini/private/teses-pdf/Tese-Andre_Tavares_da_Silva.pdf" class=yC5A>RecuperaÃ§Ã£o de imagens por conteÃºdo baseada em realimentaÃ§Ã£o de relevÃ¢ncia e classificador por floresta de caminhos Ã³timos</a></h3><div class="gs_a"><a href="/citations?user=9NtADMMAAAAJ&amp;hl=en&amp;oi=sra">AT da Silva</a> - 2011 - dca.fee.unicamp.br</div><div class="gs_rs">Resumo Com o crescente aumento de coleÃ§Ãµes de imagens resultantes da popularizaÃ§Ã£o <br>da Internet e das cÃ¢meras digitais, mÃ©todos eficientes de busca tornam-se cada vez mais <br>necessÃ¡rios. Neste contexto, esta tese propÃµe novos mÃ©todos de recuperaÃ§Ã£o de <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:nsmD7c2pTkgJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5210288520832469406&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'nsmD7c2pTkgJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md49', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md49" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:nsmD7c2pTkgJ:scholar.google.com/&amp;hl=en&amp;num=50&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
