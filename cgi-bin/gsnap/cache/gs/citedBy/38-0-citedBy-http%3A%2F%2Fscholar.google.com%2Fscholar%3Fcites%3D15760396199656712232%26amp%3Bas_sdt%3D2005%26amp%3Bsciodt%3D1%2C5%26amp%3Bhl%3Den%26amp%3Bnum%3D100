Total results = 38
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://infoscience.epfl.ch/record/87348/files/Scaringella2006_1436.pdf?version=1" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from epfl.ch</span><span class="gs_ggsS">epfl.ch <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1598089" class=yC0>Automatic genre classification of music content: a survey</a></h3><div class="gs_a">N Scaringella, G Zoia, D Mlynek - Signal Processing Magazine, &hellip;, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper reviews the state-of-the-art in automatic genre classification of music <br>collections through three main paradigms: expert systems, unsupervised classification, and <br>supervised classification. The paper discusses the importance of music genres with their <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10199946037291292194&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 138</a> <a href="/scholar?q=related:IpbmGOF8jY0J:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/4F/53/RN186343633.html?source=googlescholar" class="gs_nph" class=yC2>BL Direct</a> <a href="/scholar?cluster=10199946037291292194&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'IpbmGOF8jY0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://ismir2004.ismir.net/proceedings/p094-page-517-paper211.pdf" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ismir.net</span><span class="gs_ggsS">ismir.net <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://ismir2004.ismir.net/proceedings/p094-page-517-paper211.pdf" class=yC3>Artist classification with web-based data</a></h3><div class="gs_a"><a href="/citations?user=MtyaO2cAAAAJ&amp;hl=en&amp;oi=sra">P Knees</a>, E Pampalk, <a href="/citations?user=dyGS5YYAAAAJ&amp;hl=en&amp;oi=sra">G Widmer</a> - Proceedings of 5th  &hellip;, 2004 - ismir2004.ismir.net</div><div class="gs_rs">ABSTRACT Manifold approaches exist for organization of music by genre and/or style. In <br>this paper we propose the use of text categorization techniques to classify artists present on <br>the Internet. In particular, we retrieve and analyze webpages ranked by search engines to <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7846799555450707294&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 107</a> <a href="/scholar?q=related:Xh1VHp9u5WwJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7846799555450707294&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 24 versions</a> <a onclick="return gs_ocit(event,'Xh1VHp9u5WwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md1', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md1" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Xh1VHp9u5WwJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www.cs.berkeley.edu/~jpaisley/Papers/HMMmix.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from berkeley.edu</span><span class="gs_ggsS">berkeley.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4355329" class=yC5>Music analysis using hidden Markov mixture models</a></h3><div class="gs_a">Y Qi, <a href="/citations?user=r31_fYQAAAAJ&amp;hl=en&amp;oi=sra">JW Paisley</a>, <a href="/citations?user=2nmHOtoAAAAJ&amp;hl=en&amp;oi=sra">L Carin</a> - Signal Processing, IEEE  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We develop a hidden Markov mixture model based on a Dirichlet process (DP) <br>prior, for representation of the statistics of sequential data for which a single hidden Markov <br>model (HMM) may not be sufficient. The DP prior has an intrinsic clustering property that <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5218986525433725451&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 36</a> <a href="/scholar?q=related:CwIH8JeQbUgJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/18/23/RN218431299.html?source=googlescholar" class="gs_nph" class=yC7>BL Direct</a> <a href="/scholar?cluster=5218986525433725451&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'CwIH8JeQbUgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://ismir2005.ismir.net/proceedings/1060.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ismir.net</span><span class="gs_ggsS">ismir.net <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://ismir2005.ismir.net/proceedings/1060.pdf" class=yC8>On the modeling of time information for automatic genre recognition systems in audio signals</a></h3><div class="gs_a">N Scaringella, G Zoia - Proc. ISMIR, 2005 - ismir2005.ismir.net</div><div class="gs_rs">ABSTRACT The creation of huge databases coming from both restoration of existing <br>analogue archives and new content is demanding fast and more and more reliable tools for <br>content analysis and description, to be used for searches, content queries and interactive <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1328047709943651246&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 32</a> <a href="/scholar?q=related:rlv2G1ssbhIJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1328047709943651246&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'rlv2G1ssbhIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md3', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md3" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:rlv2G1ssbhIJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://kar.kent.ac.uk/24005/1/AutoSIla.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from kent.ac.uk</span><span class="gs_ggsS">kent.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4414136" class=yCA>Automatic music genre classification using ensemble of classifiers</a></h3><div class="gs_a"><a href="/citations?user=IpqI30MAAAAJ&amp;hl=en&amp;oi=sra">CN Silla</a>, <a href="/citations?user=p06IMtYAAAAJ&amp;hl=en&amp;oi=sra">CAA Kaestner</a>&hellip; - Systems, Man and  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents a novel approach to the task of automatic music genre <br>classification which is based on multiple feature vectors and ensemble of classifiers. Multiple <br>feature vectors are extracted from a single music piece. First, three 30-second music <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14399118387236915592&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 24</a> <a href="/scholar?q=related:iEkNJuLx08cJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14399118387236915592&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'iEkNJuLx08cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.122.8375&amp;rep=rep1&amp;type=pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/NU57211424755281.pdf" class=yCC>Classification in music research</a></h3><div class="gs_a">C Weihs, U Ligges, F MÃ¶rchen&hellip; - Advances in Data Analysis  &hellip;, 2007 - Springer</div><div class="gs_rs">Abstract Since a few years, classification in music research is a very broad and quickly <br>growing field. Most important for adequate classification is the knowledge of adequate <br>observable or deduced features on the basis of which meaningful groups or classes can <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15380270100375207934&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 25</a> <a href="/scholar?q=related:_v9sCiuycdUJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/5F/48/RN219724959.html?source=googlescholar" class="gs_nph" class=yCE>BL Direct</a> <a href="/scholar?cluster=15380270100375207934&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'_v9sCiuycdUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://www.macdorman.com/kfm/writings/pubs/MacDorman2008SongEmotionPrediction.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from macdorman.com</span><span class="gs_ggsS">macdorman.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.tandfonline.com/doi/abs/10.1080/09298210801927846" class=yCF>Automatic emotion prediction of song excerpts: Index construction, algorithm design, and empirical comparison</a></h3><div class="gs_a"><a href="/citations?user=W-DuNjYAAAAJ&amp;hl=en&amp;oi=sra">KF MacDorman</a>, SOCC Ho - Journal of New Music Research, 2007 - Taylor &amp; Francis</div><div class="gs_rs">Abstract Music&#39;s allure lies in its power to stir the emotions. But the relation between the <br>physical properties of an acoustic signal and its emotional impact remains an open area of <br>research. This paper reports the results and possible implications of a pilot study and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7874111709628445547&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 17</a> <a href="/scholar?q=related:a7MljuF2Rm0J:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/1E/52/RN230853769.html?source=googlescholar" class="gs_nph" class=yC11>BL Direct</a> <a href="/scholar?cluster=7874111709628445547&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'a7MljuF2Rm0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://arxiv.org/pdf/0911.3842" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arxiv.org</span><span class="gs_ggsS">arxiv.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://iopscience.iop.org/1367-2630/12/5/053030" class=yC12>Musical genres: beating to the rhythms of different drums</a></h3><div class="gs_a"><a href="/citations?user=mzcslqgAAAAJ&amp;hl=en&amp;oi=sra">DC Correa</a>, JH Saito, L da F Costa - New Journal of Physics, 2010 - iopscience.iop.org</div><div class="gs_rs">Abstract. Online music databases have increased significantly as a consequence of the <br>rapid growth of the Internet and digital audio, requiring the development of faster and more <br>efficient tools for music content analysis. Musical genres are widely used to organize <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17406528136124087628&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 12</a> <a href="/scholar?q=related:TL2Eth1pkPEJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17406528136124087628&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'TL2Eth1pkPEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://seungminrho.kr/pubs/VIE2008/VIE2008.pdf" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from seungminrho.kr</span><span class="gs_ggsS">seungminrho.kr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4743506" class=yC14>A fuzzy inference-based music emotion recognition system</a></h3><div class="gs_a">S Jun, S Rho, B Han, E Hwang - &hellip; Information Engineering, 2008 &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Music is a language of emotions, and hence music emotion could be useful in <br>music understanding, recommendation, retrieval and some other music-related applications. <br>Many issues for music emotion recognition have been addressed by different disciplines <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13436713969779099379&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 7</a> <a href="/scholar?q=related:80Y2LSrMeLoJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13436713969779099379&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'80Y2LSrMeLoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4064549" class=yC16>Adaptive feature selection for speech/music classification</a></h3><div class="gs_a">AR Abu-El-Quran, RA Goubran&hellip; - &hellip;  Processing, 2006 IEEE &hellip;, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose a new system for classifying audio segments as speech <br>or music. The proposed system improves classification accuracy, particularly in low signal-to-<br>noise ratio (SNR) environments. The system selects the features with the highest <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9130373005392763900&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 7</a> <a href="/scholar?q=related:_FtApd-ZtX4J:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9130373005392763900&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'_FtApd-ZtX4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://cjc.ict.ac.cn/quanwenjiansuo/2007-05/zyb.zip" class=yC18><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ict.ac.cn</span><span class="gs_ggsS">ict.ac.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://cjc.ict.ac.cn/quanwenjiansuo/2007-05/zyb.zip" class=yC17>åºäºåå®¹çé³é¢ä¸é³ä¹åæç»¼è¿° [J]</a></h3><div class="gs_a">å¼ ä¸å½¬ï¼ å¨æ°ï¼ è¾¹èç¥ºï¼ é­å - è®¡ç®æºå­¦æ¥, 2007 - cjc.ict.ac.cn</div><div class="gs_rs">æè¦æºå¨å¬è§åæ¬ä¸å¤§ç ç©¶é¢å: è¯­é³ä¿¡å·å¤çä¸è¯å«, ä¸è¬é³é¢ä¿¡å·åæ, åºäºåå®¹çé³ä¹ä¿¡å·<br>åæ. å¶ä¸­, è¯­é³ä¿¡å·å¤çä¸è¯å«æ©å·²æä¸ºä¸ä¸ªä¼ ç»çç ç©¶ç­ç¹. éçä¿¡æ¯ç§å­¦ä¸ææ¯çè¿éåå±<br>, åºäºåå®¹çé³é¢ä¸é³ä¹ä¿¡å·åæä¹éæ¸æä¸ºä¸ä¸ªæ°çç ç©¶ç­ç¹, è¿å å¹´æ¥åå¾äºå¤§éç ç©¶<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3219106275905615902&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 14</a> <a href="/scholar?q=related:HriVNRqQrCwJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3219106275905615902&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'HriVNRqQrCwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md10', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md10" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:HriVNRqQrCwJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://www.cp.jku.at/people/knees/publications/knees_oegai05-1.pdf" class=yC1A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from jku.at</span><span class="gs_ggsS">jku.at <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.cp.jku.at/people/knees/publications/knees_oegai05-1.pdf" class=yC19>Automatic classification of musical artists based on web-data</a></h3><div class="gs_a"><a href="/citations?user=MtyaO2cAAAAJ&amp;hl=en&amp;oi=sra">P Knees</a>, E Pampalk, <a href="/citations?user=dyGS5YYAAAAJ&amp;hl=en&amp;oi=sra">G Widmer</a> - 2004 - cp.jku.at</div><div class="gs_rs">Abstract The organization of music is one of the central challenges in times of increasing <br>distribution of digital music. A well-tried means is the classification in genres and/or styles. In <br>this paper we propose the use of text categorization techniques to classify artists present <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6981113465710064158&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 5</a> <a href="/scholar?q=related:HjJYpLXl4WAJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6981113465710064158&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'HjJYpLXl4WAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md11', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md11" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:HjJYpLXl4WAJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://www8.cs.umu.se/~drewes/biblio/ps-files/malgebra.pdf" class=yC1C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from umu.se</span><span class="gs_ggsS">umu.se <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/264762w7764x4038.pdf" class=yC1B>An algebra for tree-based music generation</a></h3><div class="gs_a"><a href="/citations?user=jLbEbEMAAAAJ&amp;hl=en&amp;oi=sra">F Drewes</a>, J HÃ¶gberg - Algebraic Informatics, 2007 - Springer</div><div class="gs_rs">We present an algebra whose operations act on musical pieces, and show how this algebra <br>can be used to generate music in a tree-based fashion. Starting from input which is either <br>generated by a regular tree grammar or provided by the user via a digital keyboard, a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2099003852459208849&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 5</a> <a href="/scholar?q=related:kfABAOIoIR0J:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/36/57/RN221721844.html?source=googlescholar" class="gs_nph" class=yC1D>BL Direct</a> <a href="/scholar?cluster=2099003852459208849&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'kfABAOIoIR0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://www.dar.cam.ac.uk/dcrr/dcrr004.pdf" class=yC1F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cam.ac.uk</span><span class="gs_ggsS">cam.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.dar.cam.ac.uk/dcrr/dcrr004.pdf" class=yC1E>Towards modelling harmonic movement in music: Analysing properties and dynamic aspects of pc set sequences in Bach&#39;s chorales</a></h3><div class="gs_a"><a href="/citations?user=rsGh_pAAAAAJ&amp;hl=en&amp;oi=sra">M Rohrmeier</a> - 2006 - dar.cam.ac.uk</div><div class="gs_rs">7.2 Discussion The model presented here computes key estimations from a <br>frequency/probability basis for a smaller sliding window of context. Generally, the resulting <br>key estimations show that basic chord/pc-set statistics and relatively small context are <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13982245595092454158&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 4</a> <a href="/scholar?q=related:DovBoUnqCsIJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13982245595092454158&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'DovBoUnqCsIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md13', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md13" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:DovBoUnqCsIJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5444356" class=yC20>Audio feature clustering for hearing aid systems</a></h3><div class="gs_a">N Shams, B Ghoraani&hellip; - Science and Technology  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents a novel approach for classification of audio signals for a noise <br>free hearing aid system. Due to the large number of people who suffer from hearing <br>problems, the impact of developing such a system is significant. Using the proposed <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7366708824023458412&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 3</a> <a href="/scholar?q=related:bGKnG6XOO2YJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'bGKnG6XOO2YJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.73.8829&amp;rep=rep1&amp;type=pdf" class=yC22><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.aes.org/e-lib/browse.cfm?elib=13813" class=yC21>Music genre categorization in humans and machines</a></h3><div class="gs_a">E Guaus, <a href="/citations?user=x4X0Ia8AAAAJ&amp;hl=en&amp;oi=sra">P Herrera</a> - Watermark, 2012 - aes.org</div><div class="gs_rs">Music Genre Classification is one of the most active tasks in Music Information Retrieval <br>(MIR). Many successful approaches can be found in literature. Most of them are based on <br>Machine Learning algorithms applied to different audio features automatically computed <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8161705124473775999&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 3</a> <a href="/scholar?q=related:f6e-cZEzRHEJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8161705124473775999&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'f6e-cZEzRHEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/H1101872445X6587.pdf" class=yC23>Music search and recommendation</a></h3><div class="gs_a">K Brandenburg, C Dittmar, M Gruhne, J AbeÃer&hellip; - Handbook of Multimedia &hellip;, 2009 - Springer</div><div class="gs_rs">In the last ten years, our ways to listen to music have drastically changed: In earlier times, we <br>went to record stores or had to use low bit-rate audio coding to get some music and to store <br>it on PCs. Nowadays, millions of songs are within reach via on-line distributors. Some <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13957177137684117375&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 3</a> <a href="/scholar?q=related:f3fdjqjascEJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13957177137684117375&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'f3fdjqjascEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://www.cp.jku.at/research/papers/knees_thesis.pdf" class=yC25><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from jku.at</span><span class="gs_ggsS">jku.at <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.cp.jku.at/research/papers/knees_thesis.pdf" class=yC24>Automatische klassifikation von musikkÃ¼nstlern basierend auf web-daten</a></h3><div class="gs_a"><a href="/citations?user=MtyaO2cAAAAJ&amp;hl=en&amp;oi=sra">P Knees</a> - 2004 - cp.jku.at</div><div class="gs_rs">Kurzfassung Musikorganisation stellt in einer Zeit der stark wachsenden Verbreitung <br>digitaler Musik eine der zentralen Herausforderungen dar. Ein bewÃ¤hrtes Mittel ist die <br>Einteilung von Musik in Genres. In dieser Arbeit wird ein Ansatz zur automatischen <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12103689371500696190&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 3</a> <a href="/scholar?q=related:flL481rx-KcJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12103689371500696190&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'flL481rx-KcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md17', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md17" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:flL481rx-KcJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><a href="http://cjc.ict.ac.cn/eng/qwjse/view.asp?id=2381" class=yC26>A Review of Content-Based Audio and Music Analysis</a></h3><div class="gs_a">YB Zhang, J Zhou, ZQ Bian, J Guo - CHINESE JOURNAL OF  &hellip;, 2007 - cjc.ict.ac.cn</div><div class="gs_rs">Abstract Machine hearing includes three fields: Speech signal processing and recognition, <br>general audio signal processing, and content-based music analysis. Speech signal <br>processing and recognition has been a traditional research field for many years. There are <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11924188369424478068&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 1</a> <a href="/scholar?q=related:dO9jGiU6e6UJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/38/5D/RN212307498.html?source=googlescholar" class="gs_nph" class=yC27>BL Direct</a> <a href="/scholar?cluster=11924188369424478068&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'dO9jGiU6e6UJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md18', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md18" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:dO9jGiU6e6UJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="http://kar.kent.ac.uk/24094/1/AutomaticSillaJr.pdf" class=yC29><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from kent.ac.uk</span><span class="gs_ggsS">kent.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://kar.kent.ac.uk/24094/" class=yC28>Automatic genre classification of latin music using ensemble of classifiers</a></h3><div class="gs_a"><a href="/citations?user=IpqI30MAAAAJ&amp;hl=en&amp;oi=sra">CN Silla Jr</a>, <a href="/citations?user=p06IMtYAAAAJ&amp;hl=en&amp;oi=sra">CAA Kaestner</a>, <a href="/citations?user=kaUy9GEAAAAJ&amp;hl=en&amp;oi=sra">AL Koerich</a> - Anais do XXVI Congresso da &hellip;, 2006 - kar.kent.ac.uk</div><div class="gs_rs">This paper presents a novel approach to the task of automatic music genre classification <br>which is based on ensemble learning. Feature vectors are extracted from three 30-second <br>music segments from the beginning, middle and end of each music piece. Individual <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4868255627668865635&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 1</a> <a href="/scholar?q=related:Y8L_QrOEj0MJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4868255627668865635&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'Y8L_QrOEj0MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB20" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW20"><a href="http://lsas2008.dke-research.de/conftool/uploads/158/10-Sturm20121212.pdf" class=yC2B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from dke-research.de</span><span class="gs_ggsS">dke-research.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://lsas2008.dke-research.de/conftool/uploads/158/10-Sturm20121212.pdf" class=yC2A>A survey of evaluation in music genre recognition</a></h3><div class="gs_a"><a href="/citations?user=KdeYIvMAAAAJ&amp;hl=en&amp;oi=sra">BL Sturm</a> - Proc. Adaptive Multimedia Retrieval.  &hellip;, 2012 - lsas2008.dke-research.de</div><div class="gs_rs">Abstract. Much work is focused upon music genre recognition (MGR) from audio recordings, <br>symbolic data, and other modalities. While reviews have been written of some of this work <br>before, no survey has been made of the approaches to evaluating approaches to MGR. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4253992352053677712&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 1</a> <a onclick="return gs_ocit(event,'kE5jbYE3CTsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md20', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md20" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:kE5jbYE3CTsJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="http://www.cs.berkeley.edu/~jpaisley/Papers/DPHMMmix%20ICASSP%202007.pdf" class=yC2D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from berkeley.edu</span><span class="gs_ggsS">berkeley.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4217446" class=yC2C>Dirichlet Process HMM Mixture Models with Application to Music Analysis</a></h3><div class="gs_a">Y Qi, <a href="/citations?user=r31_fYQAAAAJ&amp;hl=en&amp;oi=sra">JW Paisley</a>, <a href="/citations?user=2nmHOtoAAAAJ&amp;hl=en&amp;oi=sra">L Carin</a> - Acoustics, Speech and Signal  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract A hidden Markov mixture model is developed using a Dirichlet process (DP) prior, <br>to represent the statistics of sequential data for which a single hidden Markov model (HMM) <br>may not be sufficient. The DP prior has an intrinsic clustering property that encourages <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4287850558857962117&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 1</a> <a href="/scholar?q=related:hWKwgl2BgTsJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4287850558857962117&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'hWKwgl2BgTsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB22" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW22"><a href="http://www.iis.sinica.edu.tw/page/jise/2010/201011_08.pdf" class=yC2F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from sinica.edu.tw</span><span class="gs_ggsS">sinica.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5480365" class=yC2E>Clustering Music Recordings Based on Genres</a></h3><div class="gs_a">WH Tsai, DF Bao - Information Science and Applications (ICISA &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Existing systems for automatic genre classification follows a supervised framework <br>that extracts genre-specific information from manually-labeled music data and then identifies <br>unknown music data. However, such systems may not be suitable for personal music <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14484950119341849861&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 3</a> <a href="/scholar?q=related:BX2flGPhBMkJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14484950119341849861&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'BX2flGPhBMkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> A project report submitted for the award of BSc Computer Science with Artificial Intelligence</h3><div class="gs_a">L Collard - 2007</div><div class="gs_fl"><a href="/scholar?q=related:dTdLIlVUU0oJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'dTdLIlVUU0oJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> BOOSTING CLASSIFIERS FOR AUTOMATIC MUSIC GENRE CLASSIFICATION</h3><div class="gs_a"><a href="/citations?user=9LUdPM4AAAAJ&amp;hl=en&amp;oi=sra">U BagcÄ±</a> - 2005 - KoÃ§ University</div><div class="gs_fl"><a href="/scholar?q=related:jcFEOihwyjUJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3876033747384320397&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'jcFEOihwyjUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5381799" class=yC30>Dominant Audio Descriptors for Audio Classification and Retrieval</a></h3><div class="gs_a">A Fadeev, O Missaoui, H Frigui - Machine Learning and  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose a new general low-level feature representation for audio <br>signals. Our approach, called Dominant Audio Descriptor is inspired by the MPEG-7 <br>Dominant Color Descriptor. It is based on clustering time-local features and identifying <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12076153049038964286&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 1</a> <a href="/scholar?q=related:PsY3RTcdl6cJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12076153049038964286&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'PsY3RTcdl6cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/FT671731J0403662.pdf" class=yC31>A Survey of Music Structure Analysis Techniques for Music Applications</a></h3><div class="gs_a">N Maddage, <a href="/citations?user=z8_x7C8AAAAJ&amp;hl=en&amp;oi=sra">H Li</a>, M Kankanhalli - Recent Advances in Multimedia Signal  &hellip;, 2009 - Springer</div><div class="gs_rs">Music carries multilayer information which forms different structures. The information <br>embedded in the music can be categorized into time information, harmony/melody, music <br>regions, music similarities, song structures and music semantics. In this chapter, we first <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:3vo8SvZRZuUJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16529989600559299294&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'3vo8SvZRZuUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB27" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW27"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.73.5165&amp;rep=rep1&amp;type=pdf" class=yC33><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.73.5165&amp;rep=rep1&amp;type=pdf" class=yC32>Multi-Task Learning for Sequential Data</a></h3><div class="gs_a">Y Xue, S Ji, <a href="/citations?user=2nmHOtoAAAAJ&amp;hl=en&amp;oi=sra">L Carin</a> - 2008 - Citeseer</div><div class="gs_rs">Abstract The problem of multi-task learning (MTL) is considered for sequential data, such as <br>that typically modeled via a hidden Markov model (HMM). A given task is composed of a set <br>of sequential data, for which an HMM is to be learned, and MTL is employed to learn the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:e249fbMpiuMJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16395963244272774779&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'e249fbMpiuMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md27', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md27" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:e249fbMpiuMJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB28" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW28"><a href="http://digitalcommons.ryerson.ca/cgi/viewcontent.cgi?article=1670&amp;context=dissertations" class=yC35><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ryerson.ca</span><span class="gs_ggsS">ryerson.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://digitalcommons.ryerson.ca/dissertations/662/" class=yC34>Software-hardware analysis of signal feature classification algorithms</a></h3><div class="gs_a">H Asefi-Ghamari - 2010 - digitalcommons.ryerson.ca</div><div class="gs_rs">Abstract Over the last few decades, signal feature analysis has been significantly used in a <br>wide variety of fields. While several techniques have been proposed in the area of signal <br>feature extraction and classification, all of these techniques are achieved by using modern <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:tWhSgVEgwD0J:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'tWhSgVEgwD0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB29" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW29"><a href="http://ctp.di.fct.unl.pt/~sc/publicacoes/BarreiraCavacoFSilva_EPIA2011.pdf" class=yC37><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unl.pt</span><span class="gs_ggsS">unl.pt <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/5J02203424827147.pdf" class=yC36>Unsupervised music genre classification with a model-based approach</a></h3><div class="gs_a">L Barreira, <a href="/citations?user=GYSlP0UAAAAJ&amp;hl=en&amp;oi=sra">S Cavaco</a>, J da Silva - Progress in Artificial Intelligence, 2011 - Springer</div><div class="gs_rs">New music genres emerge constantly resulting from the influence of existing genres and <br>other factors. In this paper we propose a data-driven approach which is able to cluster and <br>classify music samples according to their type/category. The clustering method uses no <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6707776253226512888&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 2</a> <a href="/scholar?q=related:-PFdhvbOFl0J:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6707776253226512888&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'-PFdhvbOFl0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Data Mining Techniques for Automatic Recognition of Carnatic Raga Swaram Notes</h3><div class="gs_a">K Priya, RG Ramani, SG Jacob - International  &hellip;, 2012 - Foundation of Computer Science ( &hellip;</div><div class="gs_fl"><a href="/scholar?q=related:yPvZjxP1xdsJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15836333129084828616&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'yPvZjxP1xdsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB31" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW31"><a href="http://www.cse.iitb.ac.in/~sharat/icvgip.org/ncvpripg2008/papers/59.pdf" class=yC39><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from iitb.ac.in</span><span class="gs_ggsS">iitb.ac.in <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.cse.iitb.ac.in/~sharat/icvgip.org/ncvpripg2008/papers/59.pdf" class=yC38>Music genre classification using auto-associative neural networks</a></h3><div class="gs_a">A Ballaney, SK Mitra, A Maitra - &hellip;  of National Conference on Computer Vision,  &hellip; - cse.iitb.ac.in</div><div class="gs_rs">AbstractâClassification of musical genres gives a useful measure of similarity and is often <br>the most useful descriptor of a musical piece. Principal Component Analysis (PCA) has been <br>generally applied on raw music signals to capture the major components for each genre. <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Gfrumeo7uI8J:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Gfrumeo7uI8J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md31', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md31" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Gfrumeo7uI8J:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB32" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW32"><a href="http://deimos.eos.uoguelph.ca/sareibi/PUBLICATIONS_dr/thesisX/msc_thesis_cfreeman_2007.pdf" class=yC3B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uoguelph.ca</span><span class="gs_ggsS">uoguelph.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[BOOK]</span><span class="gs_ct2">[B]</span></span> <a href="http://deimos.eos.uoguelph.ca/sareibi/PUBLICATIONS_dr/thesisX/msc_thesis_cfreeman_2007.pdf" class=yC3A>Audio environment classification for hearing aids</a></h3><div class="gs_a">University of Guelph. School of Engineering&hellip; - 2007 - deimos.eos.uoguelph.ca</div><div class="gs_rs">Abstract This thesis examines background classification systems for hearing aids in four <br>stages. In the first stage, the K-nearest neighbours classifiers (KNN), hidden Markov models <br>(HMM), artificial neural networks (ANN) and ANNs with windowed input (WANN) are <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ZdWLos7qiPIJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17476476527222445413&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'ZdWLos7qiPIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md32', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md32" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:ZdWLos7qiPIJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a>  <a href="/scholar?q=info:ZdWLos7qiPIJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=11728912456639824998&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:367"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB33" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW33"><a href="http://research.mercubuana.ac.id/proceeding/Regular_90-95_001.pdf" class=yC3D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mercubuana.ac.id</span><span class="gs_ggsS">mercubuana.ac.id <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://research.mercubuana.ac.id/proceeding/Regular_90-95_001.pdf" class=yC3C>Wavelet-Based Feature Extraction for Musical Genre Classification using Support Vector Machines</a></h3><div class="gs_a">L Chen, E Bovbel, M Dashouk - The Proc. of SITIS, 2005 - research.mercubuana.ac.id</div><div class="gs_rs">Abstract Musical genre classification task falls into two major stages: feature extraction and <br>classification. The latter implies a choice of a variety of machine leaning methods, as support <br>vector machines, neural networks, etc. However, the former stage provides much more <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7002801375496950328&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 1</a> <a href="/scholar?q=related:ONIco7_yLmEJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7002801375496950328&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'ONIco7_yLmEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:366"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB34" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW34"><a href="http://run.unl.pt/bitstream/10362/4761/1/Barreira_2010.pdf" class=yC3F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unl.pt</span><span class="gs_ggsS">unl.pt <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://run.unl.pt/handle/10362/4761" class=yC3E>Unsupervised automatic music genre classification</a></h3><div class="gs_a">LFM Barreira - 2010 - run.unl.pt</div><div class="gs_rs">In this study we explore automatic music genre recognition and classification of digital <br>music. Music has always been a reflection of culture di erences and an influence in our <br>society. Today&#39;s digital content development triggered the massive use of digital music. <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:pn217Deja68J:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12640376239735274918&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'pn217Deja68J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:365"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.dbpia.co.kr/view/ar_view.asp?arid=1394275" class=yC40>An Auto Playlist Generation System with One Seed Song</a></h3><div class="gs_a">JH Lee - International Journal of Fuzzy Logic and Intelligent  &hellip;, 2010 - dbpia.co.kr</div><div class="gs_rs">The rise of music resources has led to a parallel rise in the need to manage thousands of <br>songs on user devices. So users have a tendency to build playlist for manage songs. <br>However the manual selection of songs for creating playlist is a troublesome work. This <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:JAfy89PXaGEJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'JAfy89PXaGEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:364"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.dbpia.co.kr/view/ar_view.asp?arid=1372503" class=yC41>Auto Playlist Generator with One Seed Song</a></h3><div class="gs_a">JH Lee - ISIS 2009 PROCEEDINGS OF THE 10TH SYMPOSIUM &hellip;, 2009 - dbpia.co.kr</div><div class="gs_rs">The rise of music resources has led to a parallel rise in the need to manage thousands of <br>songs on user devices. User playlists, especially, expect to be generated automatically, <br>because the manual selection of songs for creating playlist is a troublesome work. This <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:NTQXI0kYPQsJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'NTQXI0kYPQsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:363"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.dbpia.co.kr/view/ar_view.asp?arid=1461397" class=yC42>ì¬ì©ìì ì·¨í¥ì ê³ ë ¤í ìì ì¬ì ëª©ë¡ ìì± ìì¤í</a></h3><div class="gs_a">ê¹ì©ì¸ - íêµ­ì§ë¥ìì¤ííí ë¼ë¬¸ì§, 2010 - dbpia.co.kr</div><div class="gs_rs">ììì ìì°ê³¼ ìì ì¦ê°ì í¨ê» ì¬ì©ìì ì¥ì¹ì ì ì¥ëì´ ìë ììì ê´ë¦¬íê¸° ìí ê´ì¬ <br>ëí ì¦ê°íê³  ìë¤. ì¼ë°ì ì¼ë¡ ì¬ì©ìë ììì í¨ê³¼ì ì¼ë¡ ê´ë¦¬íê¸° ìí´ ì¬ì ëª©ë¡ì <br>ìì±íê³  ì´ë¥¼ ì ííë ë°©ë²ì ì¬ì©íê³  ìë¤. íì§ë§ íì¬ ì¬ì©ëë ì¬ì ëª©ë¡ì ìì± ë°©ë²<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:RA6DRqlrkkkJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'RA6DRqlrkkkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
