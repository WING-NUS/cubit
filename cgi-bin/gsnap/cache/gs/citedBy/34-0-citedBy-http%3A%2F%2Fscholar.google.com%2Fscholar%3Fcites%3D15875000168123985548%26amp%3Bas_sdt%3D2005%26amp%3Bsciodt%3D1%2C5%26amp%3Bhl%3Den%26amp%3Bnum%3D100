Total results = 34
<div class="gs_r" style="z-index:400"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0167865504002466" class=yC0>A new Hausdorff distance for image matching</a></h3><div class="gs_a">C Zhao, W Shi, Y Deng - Pattern Recognition Letters, 2005 - Elsevier</div><div class="gs_rs">Object matching in two-dimensional images has been an important topic in computer vision, <br>object recognition, and image analysis. The Hausdorff distance plays an important role in <br>image matching. In order to deal with image matching problems in random noisy <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14120979449344642958&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 67</a> <a href="/scholar?q=related:jk_HNv7L98MJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14120979449344642958&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'jk_HNv7L98MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320307002208" class=yC1>Text search for medieval manuscript images</a></h3><div class="gs_a">Y Leydier, F Lebourgeois, H Emptoz - Pattern Recognition, 2007 - Elsevier</div><div class="gs_rs">In this article we introduce a text search algorithm designed for ancient manuscripts. Word-<br>spotting is the best alternative to word recognition on this type of document. Our method is <br>based on differential features that are compared using a cohesive elastic matching <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13843491501393468413&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 47</a> <a href="/scholar?q=related:_Vuyryz2HcAJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13843491501393468413&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'_Vuyryz2HcAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://lib-repos.fun.ac.jp/dspace/bitstream/10445/3007/4/kterasaw_2005_04_icdar.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from fun.ac.jp</span><span class="gs_ggsS">fun.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1575584" class=yC2>Eigenspace method for text retrieval in historical document images</a></h3><div class="gs_a">K Terasawa, T Nagasaki&hellip; - Document Analysis and  &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract A new method for text retrieval that does not need segmentation is described. <br>Segmenting the images in historical documents into individual characters is difficult. <br>Therefore, the conventional OCR method, which uses segmentation, does not work well. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6242473973587464242&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 24</a> <a href="/scholar?q=related:MlBNQwG5oVYJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6242473973587464242&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'MlBNQwG5oVYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://pixel-shaker.fr/wp-content/uploads/publications/Baudrier2008.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from pixel-shaker.fr</span><span class="gs_ggsS">pixel-shaker.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320307003287" class=yC4>Binary-image comparison with local-dissimilarity quantification</a></h3><div class="gs_a"><a href="/citations?user=ZFkMdjUAAAAJ&amp;hl=en&amp;oi=sra">Ã Baudrier</a>, F Nicolier, G Millon, S Ruan - Pattern Recognition, 2008 - Elsevier</div><div class="gs_rs">In this paper, we present a method for binary image comparison. For binary images, intensity <br>information is poor and shape extraction is often difficult. Therefore binary images have to be <br>compared without using feature extraction. Due to the fact that different scene patterns can <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6906001158270479844&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 26</a> <a href="/scholar?q=related:5O0lwXYL118J:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6906001158270479844&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'5O0lwXYL118J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1575602" class=yC6>Omnilingual segmentation-free word spotting for ancient manuscripts indexation</a></h3><div class="gs_a">Y Leydier, F Le Bourgeois&hellip; - Document Analysis and  &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This article introduces a new word spotting method designed for ancient <br>manuscripts. We take advantage of the robustness of the gradient feature and propose a <br>new segmentation-free matching algorithm that tolerates spatial variations. We test our <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12311120418152292886&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 18</a> <a href="/scholar?q=related:FqIGD8vi2aoJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12311120418152292886&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'FqIGD8vi2aoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320309000454" class=yC7>Towards an omnilingual word retrieval system for ancient manuscripts</a></h3><div class="gs_a">Y Leydier, A Ouji, F LeBourgeois, H Emptoz - Pattern Recognition, 2009 - Elsevier</div><div class="gs_rs">In this article, we introduce the first method that allows the indexation of ancient manuscripts <br>of any language and alphabet. We describe a word retrieval engine inspired by recent word-<br>spotting advances on ancient manuscripts. Our approach does not need any layout <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14700726840350339242&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 19</a> <a href="/scholar?q=related:qvAhayx5A8wJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14700726840350339242&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'qvAhayx5A8wJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://etienne.baudrier.free.fr/Baudrier_ISJ07.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from free.fr</span><span class="gs_ggsS">free.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.ingentaconnect.com/content/maney/isj/2007/00000055/00000003/art00005" class=yC8>Hausdorff distance-based multiresolution maps applied to image similarity measure</a></h3><div class="gs_a"><a href="/citations?user=ZFkMdjUAAAAJ&amp;hl=en&amp;oi=sra">E Baudrier</a>, G Millon, F Nicolier&hellip; - &hellip;  Science Journal, The, 2007 - ingentaconnect.com</div><div class="gs_rs">Abstract: Image comparison is widely used in image processing. For binary images that are <br>not composed of a single shape, a local comparison can be interesting because the features <br>are usually poor (colour) or difficult to extract (texture, forms). Thus a new binary image <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15259524146260032305&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 7</a> <a href="/scholar?q=related:MTtT01y4xNMJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/43/3C/RN215450910.html?source=googlescholar" class="gs_nph" class=yCA>BL Direct</a> <a href="/scholar?cluster=15259524146260032305&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'MTtT01y4xNMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/81l6v663305v4670.pdf" class=yCB>A survey of keyword spotting techniques for printed document images</a></h3><div class="gs_a">A Murugappan, B Ramachandran&hellip; - Artificial Intelligence  &hellip;, 2011 - Springer</div><div class="gs_rs">Abstract This paper attempts to provide a survey of the past researches on character based <br>as keyword based approaches used for retrieving information from document images. This <br>survey also provides insights into the strengths and weaknesses of current techniques, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4152659816115326052&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 6</a> <a href="/scholar?q=related:ZMyX3Bk2oTkJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4152659816115326052&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'ZMyX3Bk2oTkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://lib-repos.fun.ac.jp/dspace/bitstream/10445/3005/4/kterasaw_2006_02_das.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from fun.ac.jp</span><span class="gs_ggsS">fun.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/722L7H0P17172167.pdf" class=yCC>Automatic keyword extraction from historical document images</a></h3><div class="gs_a">K Terasawa, T Nagasaki, T Kawashima - Document Analysis Systems VII, 2006 - Springer</div><div class="gs_rs">This paper presents an automatic keyword extraction method from historical document <br>images. The proposed method is language independent because it is purely appearance <br>based, where neither lexical information nor any other statistical language models are <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9967589935856755165&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 5</a> <a href="/scholar?q=related:3SGAcTz-U4oJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/45/33/RN183130648.html?source=googlescholar" class="gs_nph" class=yCE>BL Direct</a> <a href="/scholar?cluster=9967589935856755165&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'3SGAcTz-U4oJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://inderscience.metapress.com/index/g04343p28gxv8m74.pdf" class=yCF>Feature string-based intelligent information retrieval from Tamil document images</a></h3><div class="gs_a">S Abirami, D Manjula - International Journal of Computer Applications  &hellip;, 2009 - Inderscience</div><div class="gs_rs">Information Retrieval (IR) in document images has become a growing and challenging <br>problem due to its rising popularity. This paper proposes a simple and effective method to <br>extract the text and perform intelligent IR from Tamil Document Images without Optical <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=808284528493685425&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 4</a> <a href="/scholar?q=related:sWpPBn-aNwsJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=808284528493685425&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'sWpPBn-aNwsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://www.cvc.uab.es/icdar2009/papers/3725a291.pdf" class=yC11><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uab.es</span><span class="gs_ggsS">uab.es <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5277695" class=yC10>Compression and String Matching Method for Printed Document Images</a></h3><div class="gs_a">H Imura, Y Tanaka - &hellip; Analysis and Recognition, 2009. ICDAR&#39;09 &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper describes a compression technique for printed document images and <br>string matching method on the compressed images. To send digitized document images <br>over the Web, compression of the document images is required. Moreover, in order to deal <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7342645067431189823&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 3</a> <a href="/scholar?q=related:P50CLMlQ5mUJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7342645067431189823&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'P50CLMlQ5mUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5871643" class=yC12>A novel word spotting method based on recurrent neural networks</a></h3><div class="gs_a"><a href="/citations?user=7OHIhKkAAAAJ&amp;hl=en&amp;oi=sra">V Frinken</a>, A Fischer, <a href="/citations?user=_0aMq28AAAAJ&amp;hl=en&amp;oi=sra">R Manmatha</a>&hellip; - Pattern Analysis and  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Keyword spotting refers to the process of retrieving all instances of a given keyword <br>from a document. In the present paper, a novel keyword spotting method for handwritten <br>documents is described. It is derived from a neural network-based system for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8670462868721127333&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 11</a> <a href="/scholar?q=related:pU9WgAqsU3gJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8670462868721127333&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'pU9WgAqsU3gJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://tel.archives-ouvertes.fr/docs/00/05/84/25/PDF/TheseEBaudrier2005.pdf" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://tel.archives-ouvertes.fr/tel-00011570/" class=yC13>Comparaison d&#39;images binaires reposant sur une mesure locale des dissimilaritÃ©s. Application Ã  la classification.</a></h3><div class="gs_a"><a href="/citations?user=ZFkMdjUAAAAJ&amp;hl=en&amp;oi=sra">E Baudrier</a> - 2005 - tel.archives-ouvertes.fr</div><div class="gs_rs">Lors de la comparaison de deux images, il n&#39;est pas toujours nÃ©cessaire de comparer <br>l&#39;ensemble des Ã©lÃ©ments prÃ©sents dans les images. Par exemple, si la comparaison porte <br>sur les traits grossiers de l&#39;image, il n&#39;est pas utile de conserver une haute dÃ©finition pour l&#39;<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12627266598230521198&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 3</a> <a href="/scholar?q=related:bnWvpxEQPa8J:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12627266598230521198&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'bnWvpxEQPa8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://lib-repos.fun.ac.jp/dspace/bitstream/10445/5733/2/kawasima_2006_6_2006DTW.pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from fun.ac.jp</span><span class="gs_ggsS">fun.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://lib-repos.fun.ac.jp/dspace/handle/10445/5733" class=yC15>åºæç©ºéæ³ã¨ DTW ã«ããå¤ææ¸ã¯ã¼ãã¹ãããã£ã³ã°</a></h3><div class="gs_a">å¯ºæ²¢æ²å¾ï¼ é·å´å¥ï¼ å·å¶ç¨å¤« - 2006 - lib-repos.fun.ac.jp</div><div class="gs_rs">æ­´å²çææ¸ã®ãã£ã¸ã¿ã«ã¢ã¼ã«ã¤ãã®æ§ç¯ãèããå ´å, æ¯ç­ææ¸ãæå­ã«å¯¾ããææ¸è§£æææ³ã®<br>éçºã¯å¿è¦ä¸å¯æ¬ ã§ãã. æ¬è«æã§ã¯æ¯ç­ææ¸ãææ¸ç»åã«å¯¾ããã­ã¼ã¯ã¼ãæ¤ç´¢ã®ããã®æ°ãã<br>ææ³ã¨ãã¦, æå­èªè­ææ³ã«ãããç»åã®é¨åãããã³ã°åé¡ã¨ãã¦æ¤ç´¢ãè¡ãæ¹æ³ãææ¡ãã<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9259646640704185024&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 2</a> <a href="/scholar?q=related:wOLPXI_fgIAJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9259646640704185024&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'wOLPXI_fgIAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://www.ppgia.pucpr.br/~alekoe/Papers/ALEKOE-JUCS2011.pdf" class=yC18><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from pucpr.br</span><span class="gs_ggsS">pucpr.br <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://jucs.org/jucs_17_1/an_ocr_free_method/jucs_17_01_0048_0063_rios.pdf" class=yC17>An OCR Free Method for Word Spotting in Printed Documents: the Evaluation of Different Feature Sets</a></h3><div class="gs_a">I Rios, <a href="/citations?user=pRK8DCUAAAAJ&amp;hl=en&amp;oi=sra">A de Souza Britto Jr</a>, <a href="/citations?user=kaUy9GEAAAAJ&amp;hl=en&amp;oi=sra">AL Koerich</a>&hellip; - Journal of Universal  &hellip;, 2011 - jucs.org</div><div class="gs_rs">Abstract: An OCR free word spotting method is developed and evaluated under a strong <br>experimental protocol. Different feature sets are evaluated under the same experimental <br>conditions. In addition, a tuning process in the document segmentation step is proposed <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12835005042238415074&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 1</a> <a href="/scholar?q=related:4uD3SBUZH7IJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12835005042238415074&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'4uD3SBUZH7IJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.188.2447&amp;rep=rep1&amp;type=pdf" class=yC1A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1774099" class=yC19>Evaluation of different feature sets in an ocr free method for word spotting in printed documents</a></h3><div class="gs_a">I Rios, <a href="/citations?user=pRK8DCUAAAAJ&amp;hl=en&amp;oi=sra">AS Britto Jr</a>, <a href="/citations?user=kaUy9GEAAAAJ&amp;hl=en&amp;oi=sra">AL Koerich</a>&hellip; - Proceedings of the 2010  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract This paper presents the evaluation of tree feature sets in an OCR free word spotting <br>method under a strong experimental protocol. Different feature sets are evaluated under the <br>same experimental conditions. In addition, a tuning process in the document <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18067988446306032530&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 1</a> <a href="/scholar?q=related:ktvue8NjvvoJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18067988446306032530&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'ktvue8NjvvoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://www.comp.leeds.ac.uk/dch/papers/design%20synthesis/ijpd2010.pdf" class=yC1C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from leeds.ac.uk</span><span class="gs_ggsS">leeds.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://inderscience.metapress.com/index/X328258645225103.pdf" class=yC1B>Computer-aided design synthesis: an application of shape grammars</a></h3><div class="gs_a">A McKay, I Jowers, HH Chau&hellip; - International Journal of  &hellip;, 2011 - Inderscience</div><div class="gs_rs">Computer-aided design systems enable the creation of digital product definitions that are <br>widely used throughout the design process. Typically, such product definitions are created <br>after the bulk of [shape] designing has been completed because their creation requires a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1937826496601104952&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 1</a> <a href="/scholar?q=related:OKI_fu6K5BoJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1937826496601104952&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'OKI_fu6K5BoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://liris.cnrs.fr/m2disco/coresa/coresa-2006/files/126.pdf" class=yC1E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cnrs.fr</span><span class="gs_ggsS">cnrs.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://liris.cnrs.fr/m2disco/coresa/coresa-2006/files/126.pdf" class=yC1D>Contribution Ã  la crÃ©ation d&#39;un moteur de recherche sÃ©miotique: application aux manuscrits latins mÃ©diÃ©vaux</a></h3><div class="gs_a">Y Leydier, F Lebourgeois, H Emptoz - COmpression et REprÃ©sentation  &hellip;, 2006 - liris.cnrs.fr</div><div class="gs_rs">RÃ©sumÃ© Cet article prÃ©sente une mÃ©thode de recherche de mots par similaritÃ© de formes <br>(word-spotting) dÃ©diÃ©es aux manuscrits latins mÃ©diÃ©vaux. Nous proposons une nouvelle <br>mÃ©thode de comparaison des formes qui tire avantage de la robustesse du gradient et <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15409259525681653472&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 1</a> <a href="/scholar?q=related:4CYPmOWv2NUJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15409259525681653472&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'4CYPmOWv2NUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md17', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md17" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:4CYPmOWv2NUJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB18" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW18"><a href="http://lib-repos.fun.ac.jp/dspace/bitstream/10445/3014/1/hdiss2005.pdf" class=yC20><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from fun.ac.jp</span><span class="gs_ggsS">fun.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> <a href="http://lib-repos.fun.ac.jp/dspace/handle/10445/3014" class=yC1F>å¤ææ¸ç»åãå¯¾è±¡ã«ããã¯ã¼ãã¹ãããã£ã³ã°</a></h3><div class="gs_a">å¯ºæ²¢æ²å¾ï¼ é·å´å¥ï¼ å·å¶ç¨å¤« - 2005 - lib-repos.fun.ac.jp</div><div class="gs_rs">Abstract In creating digital archives of historical documents, it is important to develop <br>effective text retrieval systems for handwritten old characters. This paper describes a new <br>method for text retrieval which requires neither text format transcription nor character <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3666284760451558486&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 1</a> <a href="/scholar?q=related:VqwkmJBC4TIJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3666284760451558486&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'VqwkmJBC4TIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ri"><h3 class="gs_rt"><a href="http://comjnl.oxfordjournals.org/content/early/2012/07/20/comjnl.bxs100.short" class=yC21>Compression of Chinese Document Images by Complex Shape Matching</a></h3><div class="gs_a">CY Shiah, YS Yen - The Computer Journal, 2012 - Br Computer Soc</div><div class="gs_rs">Abstract In this paper, we present a novel approach for compressing Chinese document <br>images and the procedure consists of four phases. In the first phase, document images are <br>segmented into Chinese characters using connected component analysis. Since the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:iQa9BPgwqNYJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'iQa9BPgwqNYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ri"><h3 class="gs_rt"><a href="http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=1266186" class=yC22>Multisensor image registration using modified Hausdorff distance matrix metrics</a></h3><div class="gs_a">Q Li, G Qu, X Zhao, Q Yu - Seventh  &hellip;, 2011 - proceedings.spiedigitallibrary.org</div><div class="gs_rs">abstract As to multi-sensor image registration, a novel algorithm for registration synthetic <br>aperture radar (SAR) image to Optical image based on Weight Hausdorff Distance Matrix <br>(WHDM) Metric is proposed in the paper. In the proposed method, edge feature is used for <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:iMKjRXypluMJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16399481444325638792&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'iMKjRXypluMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md20', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md20" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:iMKjRXypluMJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Spotting Arabic Keywords in Handwritten Documents</h3><div class="gs_a">R SAABNI, J EL-SANA</div><div class="gs_fl"><a onclick="return gs_ocit(event,'HlZbW0B4FQ0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5693636" class=yC23>A Full-Text Search System for Images of Hand-Written Cursive Documents</a></h3><div class="gs_a">H Imura, Y Tanaka - Frontiers in Handwriting Recognition ( &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We propose a full-text search technique for image-scanned documents that does <br>not recognize individual characters. The system is as fast as a full-text search of machine-<br>readable documents. Such a system is important when working with historical handwritten <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:9S-mckxtgTgJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4071655713228074997&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'9S-mckxtgTgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6003077" class=yC24>Fast historic document retrieval by extracting document image summary</a></h3><div class="gs_a">CY Shiah, YS Yen - Multimedia Technology (ICMT), 2011  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Historic documents such as Chinese calligraphy and old newspapers usually were <br>handwritten or printed in poor quality so that an automatic optical character recognition <br>procedure for scanned document images is difficult to apply. Thus efficient pattern <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:f63dgvRiySkJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'f63dgvRiySkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB24" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW24"><a href="https://lib-repos.fun.ac.jp/dspace/bitstream/10445/5732/3/kawasima_2006_7_DAS2008.pdf" class=yC26><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from fun.ac.jp</span><span class="gs_ggsS">fun.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="https://lib-repos.fun.ac.jp/dspace/handle/10445/5732" class=yC25>Automatic Keyword Extraction from Historical Document Images</a></h3><div class="gs_a">T Kengo, N Takeshi, K Toshio - 2006 - lib-repos.fun.ac.jp</div><div class="gs_rs">This paper presents an automatic keyword extraction method from historical document <br>images. The proposed method is language independent because it is purely appearance <br>based, where neither lexical information nor any other statistical language models are <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:49WpshASgZYJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10844969240611116515&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'49WpshASgZYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1441582" class=yC27>Filtering in Chinese document images based on templates and confidence measure</a></h3><div class="gs_a">C Jiewei, X Weiran, G Jun - Signal Processing, 2004.  &hellip;, 2004 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract A fast approach to keyword spotting in Chinese document images based on <br>multiple templates matching and confidence measure is presented. The system generates <br>keyword lexicon of diverse fonts and two-stage feature vectors prior to the procedure of <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:IuYDuVMHZb0J:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13647322301983876642&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'IuYDuVMHZb0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ri"><h3 class="gs_rt"><a href="http://inderscience.metapress.com/index/P97215M384755217.pdf" class=yC28>A global collaborative design framework for sketch-based parametric CAD modelling</a></h3><div class="gs_a">P Farrugia, F Balzan, JC Borg - International Journal of Product  &hellip;, 2011 - Inderscience</div><div class="gs_rs">Despite that paper-based freehand sketching is still widely used during the conceptual <br>design phase, few are the tools available that allow designers to exploit sketches resulting <br>from this activity at a later design phase. This paper reports the ongoing research on a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:mEpM_TbmehMJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1403687357731588760&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'mEpM_TbmehMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB27" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW27"><a href="http://lib-repos.fun.ac.jp/dspace/bitstream/10445/6611/3/3103004.pdf" class=yC2A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from fun.ac.jp</span><span class="gs_ggsS">fun.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> <a href="http://lib-repos.fun.ac.jp/dspace/handle/10445/6611" class=yC29>ç»åæ¤ç´¢ã«ãããã£ã¸ã¿ã«ã¢ã¼ã«ã¤ãã®ç¥è²¡å</a></h3><div class="gs_a">å¯ºæ²¢æ²å¾ - 2006 - lib-repos.fun.ac.jp</div><div class="gs_rs">æ¦ è¦: è²´éãªæåè²¡ãæ­´å²çææ¸ãªã©ããã£ã¸ã¿ã«ã¢ã¼ã«ã¤ãã¨ãã¦èç©ä¿å­ããåãçµã¿ãçã<br>ã§ãã. ããããã£ã¸ã¿ã«ã¢ã¼ã«ã¤ããåãªãä¿å­æè¡ã«çã¾ããããã¨ãªã, åºãä¸çã«å¬éãã¦ç¥è²¡<br>ã¨ãã¦ã®æå¹å©ç¨ãæ´»æ§åãããã¨ãèããå ´å, è³æããã£ã¸ã¿ã«åãã¦è²¯èµããæ¹æ³ã«å ãã¦, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:nWVqI8BU-lcJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6339472609682023837&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'nWVqI8BU-lcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB28" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW28"><a href="http://www.biblioteca.pucpr.br/tede/tde_arquivos/14/TDE-2009-06-09T153510Z-1189/Publico/Israel_Rios%20PPGIa.pdf" class=yC2C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from pucpr.br</span><span class="gs_ggsS">pucpr.br <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.biblioteca.pucpr.br/tede/tde_arquivos/14/TDE-2009-06-09T153510Z-1189/Publico/Israel_Rios%20PPGIa.pdf" class=yC2B>Busca por Palavras em Imagens de Documentos: Uma Abordagem Independente de OCR</a></h3><div class="gs_a">I RIOS - 2007 - biblioteca.pucpr.br</div><div class="gs_rs">Resumo Hoje em dia, hÃ¡ um grande volume de informaÃ§Ã£o disponÃ­vel na forma digital, seja <br>em grandes empresas seja em bibliotecas digitais. Grande parte dessa informaÃ§Ã£o Ã© <br>composta de imagens de documentos digitalizados. Devido ao grande volume, existe a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:aaqgMCP6wwMJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=271335431618996841&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'aaqgMCP6wwMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB29" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW29"><a href="http://www.arocmag.com/ch/reader/create_pdf.aspx?file_no=1423&amp;flag=1&amp;journal_id=arocmag" class=yC2E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arocmag.com</span><span class="gs_ggsS">arocmag.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.arocmag.com/ch/reader/create_pdf.aspx?file_no=1423&amp;flag=1&amp;journal_id=arocmag" class=yC2D>åºäºå¤æ¨¡æ¿å¹éåå¯ä¿¡åº¦åæçä¸­æææ¡£å¾åå³é®è¯è¿æ»¤æ¹æ³</a></h3><div class="gs_a">éçä¼ï¼ å¾èç¶ï¼ é­å - è®¡ç®æºåºç¨ç ç©¶, 2005 - arocmag.com</div><div class="gs_rs">æè¦: éå¯¹äºèç½ä¸­æææ¡£å¾åéæ³ä¿¡æ¯è¿æ»¤æåºäºä¸ç§å¤æ¨¡æ¿å¹éç»åå¯ä¿¡åº¦åæçæ¹æ³. <br>è¯¥æ¹æ³åæäºä¼ ç»OCR éåº¦æ¢çç¼ºç¹, åæ¶æ¹åäºåºäºå¾åç¹å¾å¹éæ¹æ³å¯¹å­ä½ååªé³ææç<br>ç¹æ§. éè¿æ¹åå³é®è¯æç´¢æ¹å¼ææå°åå°äºè®¡ç®é, æé«äºè¯å«éåº¦. å®éªç»æè¡¨æäºè¯¥æ¹æ³<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:CweKReSawFAJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5818821023772575499&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'CweKReSawFAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md29', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md29" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:CweKReSawFAJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB30" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW30"><a href="http://www.taf.or.jp/publication/kjosei_22/index-1/page/p486.pdf" class=yC30><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from taf.or.jp</span><span class="gs_ggsS">taf.or.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.taf.or.jp/publication/kjosei_22/index-1/page/p486.pdf" class=yC2F>ç»åæ¤ç´¢ãç¨ãããã£ã¸ã¿ã«ã¢ã¼ã«ã¤ãã®ã¤ã³ãã¯ã·ã³ã°</a></h3><div class="gs_a">å·å¶ç¨å¤« - taf.or.jp</div><div class="gs_rs">2-1 åå¦çã¯ããã«, å¥åç»åã«å¯¾ãã¦åå¦çãæ½ã. åå¦çã¯,ããããå¤å¦çã«ãã, <br>èæ¯ãæ¶å»ããæå­è¡ã®ååºãããæå­è¡ã®ä¸­å¿ä½ç½®ã®æ­£è¦åã ã® 3 æ®µéã§è¡ã. ãããå¤å¦çã¯, <br>ç»ç´ å¤ãä¸å®ã®ãããå¤ä»¥ä¸ã® (ããªãã¡é»ã«è¿ã) ãã¯ã»ã«ã®ã¿ãæå¹æåã¨ãã¦æ½åºã, ãã<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Stn1SnjjKmwJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Stn1SnjjKmwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md30', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md30" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Stn1SnjjKmwJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB31" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW31"><a href="http://www.eshukan.com/upfiles/jwz/20120608165229608.pdf" class=yC32><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from eshukan.com</span><span class="gs_ggsS">eshukan.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.eshukan.com/upfiles/jwz/20120608165229608.pdf" class=yC31>éç¨äºç§»å¨ MPLS çæ¹è¿ RSVP åè®®ç ç©¶</a></h3><div class="gs_a">å´ä¸éï¼ æ¨éï¼ ä¸ç - è®¡ç®æºåºç¨ç ç©¶, 2005 - eshukan.com</div><div class="gs_rs">æè¦: é¦åæåºäºä¸ç§æ¹è¿çèµæºé¢çåè®®, è½å¤ä¿è¯åºäºåçº§ç§»å¨çç§»å¨MPLS <br>å¨åæ¢è¿ç¨ä¸­è¿ç»­çéä¸­æå¡è´¨é. éè¿°äºè¯¥æ¹è¿åè®®çå·¥ä½è¿ç¨, è¯æäºå®è½å¾å¥½å°éåºç§»å¨<br>MPLS, å¹¶è½ä¿è¯å¯¹ç§»å¨MPLS å¨åæ¢åçæ°è·¯å¾è¿è¡å¿«éçèµæºé¢ç, ä»èä¿éä¸å¡çéä¸­<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:xByHki2kywoJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=777895876290354372&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'xByHki2kywoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md31', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md31" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:xByHki2kywoJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB32" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW32"><a href="http://lib-repos.fun.ac.jp/dspace/bitstream/10445/3008/1/exbm.pdf" class=yC34><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from fun.ac.jp</span><span class="gs_ggsS">fun.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="https://lib-repos.fun.ac.jp/dspace/handle/10445/5716" class=yC33>Extended Boyer-Moore æ³ã«ããå¤ãæ°èç»åããã®é«éå¨ææ¤ç´¢</a></h3><div class="gs_a">å¯ºæ²¢æ²å¾ï¼ å³¶è²´å®ï¼ å·å¶ç¨å¤«ï¼ ç°ä¸­è­² - 2009 - lib-repos.fun.ac.jp</div><div class="gs_rs">Boyer-Moore æ³ã¯, ãããã­ã¹ãã¹ããªã³ã°ã®ä¸­ããä¸ããããã­ã¼ã¯ã¼ãã¨å®å¨ã«ä¸è´ããé¨åã<br>æ¢ãåºãéå¸¸ã«é«éãªã¢ã«ã´ãªãºã ã¨ãã¦ããç¥ããã¦ãã. æ¬ç ç©¶ã§ã¯, æ¤ç´¢ã®å¯¾è±¡ããã­ã¹ã<br>ã¹ããªã³ã°ããä¸è¬ã®å®ãã¯ãã«ç³»åã«æ¡å¼µãã, Extended-Boyer-Moore æ³ãææ¡ãã. å®<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:8sYWx2W0r70J:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13668341743317599986&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'8sYWx2W0r70J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md32', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md32" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:8sYWx2W0r70J:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:367"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB33" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW33"><a href="http://asso-aria.org/coria/2012/413.pdf" class=yC36><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from asso-aria.org</span><span class="gs_ggsS">asso-aria.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://asso-aria.org/coria/2012/413.pdf" class=yC35>SystÃ¨me gÃ©nÃ©rique et omni-langage de navigation dans des bases de documents anciens basÃ© sur de la recherche de mots par composition interactive de  &hellip;</a></h3><div class="gs_a">QA BUI - asso-aria.org</div><div class="gs_rs">RÃSUMÃ. La recherche de mots ou de groupe de mots pour la navigation dans des <br>collections de documents anciens numÃ©risÃ©s est un sujet de recherche actif dans la <br>communautÃ© internationale. En raison en particulier de la qualitÃ© mÃ©diocre de ce type de <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:TXX80uRpcCMJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2553657420232291661&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'TXX80uRpcCMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md33', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md33" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:TXX80uRpcCMJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
