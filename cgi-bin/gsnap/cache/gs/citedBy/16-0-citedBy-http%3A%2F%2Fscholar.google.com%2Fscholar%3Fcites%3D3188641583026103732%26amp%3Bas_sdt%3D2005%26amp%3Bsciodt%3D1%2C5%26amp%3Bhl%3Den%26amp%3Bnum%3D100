Total results = 16
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.comp.nus.edu.sg/~mohan/papers/fusion_survey.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/E31M71152774R630.pdf" class=yC0>Multimodal fusion for multimedia analysis: a survey</a></h3><div class="gs_a"><a href="/citations?user=2s3sftgAAAAJ&amp;hl=en&amp;oi=sra">PK Atrey</a>, <a href="/citations?user=Qq4AAT4AAAAJ&amp;hl=en&amp;oi=sra">MA Hossain</a>, <a href="/citations?user=VcOjgngAAAAJ&amp;hl=en&amp;oi=sra">A El Saddik</a>, MS Kankanhalli - Multimedia Systems, 2010 - Springer</div><div class="gs_rs">Abstract This survey aims at providing multimedia researchers with a state-of-the-art <br>overview of fusion strategies, which are used for combining multiple modalities in order to <br>accomplish various multimedia analysis tasks. The existing literature on multimodal fusion <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2303959858949282248&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16">Cited by 65</a> <a href="/scholar?q=related:yFlu6UhP-R8J:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2303959858949282248&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'yFlu6UhP-R8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="https://doc.telin.nl/dsweb/Get/Version-19633/Experiential+Sampling+for+Video+Surveillance.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from telin.nl</span><span class="gs_ggsS">telin.nl <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=982452.982462" class=yC2>Experiential sampling for video surveillance</a></h3><div class="gs_a"><a href="/citations?user=wIE1tY4AAAAJ&amp;hl=en&amp;oi=sra">J Wang</a>, MS Kankanhalli, W Yan, R Jain - First ACM SIGMM international  &hellip;, 2003 - dl.acm.org</div><div class="gs_rs">Abstract Due to the decreasing costs and increasing miniaturization of video cameras, the <br>use of digital video based surveillance as a tool for real-time monitoring is rapidly <br>increasing. In this paper, we present a new methodology for real-time video surveillance <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8248092148146348629&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16">Cited by 26</a> <a href="/scholar?q=related:VaLzxBscd3IJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8248092148146348629&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 19 versions</a> <a onclick="return gs_ocit(event,'VaLzxBscd3IJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www.mirlab.org/conference_papers/International_Conference/ICICS_PCM%202003/PDFFILES/PAPERS/2C13P0906.PDF" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mirlab.org</span><span class="gs_ggsS">mirlab.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1292638" class=yC4>Adaptive monitoring for video surveillance</a></h3><div class="gs_a"><a href="/citations?user=wIE1tY4AAAAJ&amp;hl=en&amp;oi=sra">J Wang</a>, WQ Yan, MS Kankanhalli&hellip; - &hellip; , 2003 and Fourth  &hellip;, 2003 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Adaptability is one of the key issues in the important area of surveillance systems. <br>Based on attention and sensor samples, the experiential sampling technique provides a <br>general framework for analyzing video data. In this paper, we present a scheme for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5994628161929859462&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16">Cited by 10</a> <a href="/scholar?q=related:htFhaI0yMVMJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5994628161929859462&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 31 versions</a> <a onclick="return gs_ocit(event,'htFhaI0yMVMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://www.acs.uwinnipeg.ca/pkatrey/papers/2008_QoISN_Context.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uwinnipeg.ca</span><span class="gs_ggsS">uwinnipeg.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4660120" class=yC6>Context-aware QoI computation in multi-sensor systems</a></h3><div class="gs_a"><a href="/citations?user=Qq4AAT4AAAAJ&amp;hl=en&amp;oi=sra">M Anwar Hossain</a>, <a href="/citations?user=2s3sftgAAAAJ&amp;hl=en&amp;oi=sra">PK Atrey</a>&hellip; - Mobile Ad Hoc and  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Multi-sensor systems are increasingly being deployed in many application <br>scenarios due to the enormous potential they can offer. However, as the processing of <br>sensory data often results in imprecise outcome, measuring the quality of information (QoI) <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10524634738593057101&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16">Cited by 6</a> <a href="/scholar?q=related:TUmTaIgDD5IJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10524634738593057101&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'TUmTaIgDD5IJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://pdf.aminer.org/000/501/968/probability_fusion_for_correlated_multimedia_streams.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aminer.org</span><span class="gs_ggsS">aminer.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1027624" class=yC8>Probability fusion for correlated multimedia streams</a></h3><div class="gs_a"><a href="/citations?user=2s3sftgAAAAJ&amp;hl=en&amp;oi=sra">PK Atrey</a>, MS Kankanhalli - Proceedings of the 12th annual ACM  &hellip;, 2004 - dl.acm.org</div><div class="gs_rs">Abstract The fusion of multiple correlated observations of a multimedia system is a research <br>problem arising in many multimedia applications. In this paper, we propose a novel <br>framework for the probabilistic fusion of correlated multimedia observations. Assuming <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2250071575916020779&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16">Cited by 5</a> <a href="/scholar?q=related:K4StSS3cOR8J:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2250071575916020779&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'K4StSS3cOR8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://kusu.comp.nus.edu/proceedings/icme05/defevent/papers/cr1290.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu</span><span class="gs_ggsS">nus.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1521455" class=yCA>Estimation of speaking speed for faster face detection in video-footage</a></h3><div class="gs_a">O Ikeda - Multimedia and Expo, 2005. ICME 2005. IEEE  &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We previously reported a face detection system based on color segmentation using <br>HSV. It was shown that the color is more effective than other colors not only in accurate <br>segmentation but also in effective extraction of facial features. The first is crucial for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11279001107654950258&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16">Cited by 3</a> <a href="/scholar?q=related:cr0Cq78Ph5wJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11279001107654950258&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'cr0Cq78Ph5wJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://www.mirlab.org/conference_papers/International_Conference/ICICS_PCM%202003/PDFFILES/PAPERS/1A11P0911.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mirlab.org</span><span class="gs_ggsS">mirlab.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1292401" class=yCC>Information-integration approach to designing digital video albums</a></h3><div class="gs_a">C Madhwacharyula, W Jun, Y Weiqi, J Yi&hellip; - &hellip; , 2003 and Fourth  &hellip;, 2003 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present the architecture of the DVA (digital video album) system. <br>Information-integration is the key principle utilized in this system to allow for content-based <br>indexing, intuitive access and retrieval of digital video. Our implementation of the system <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4720112419584736435&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16">Cited by 1</a> <a href="/scholar?q=related:s_xBxTw1gUEJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4720112419584736435&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'s_xBxTw1gUEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/g1826625710n5885.pdf" class=yCE>Detection of a speaker in video by combined analysis of speech sound and mouth movement</a></h3><div class="gs_a">O Ikeda - Advances in Visual Computing, 2007 - Springer</div><div class="gs_rs">We present a robust method to detect and locate a speaker using a joint analysis of speech <br>sound and video image. First, the short speech sound data is analyzed to estimate the rate <br>of spoken syllables, and a difference image is formed using the optimal frame distance <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:cDCKKe13f1IJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/1A/40/RN219256216.html?source=googlescholar" class="gs_nph" class=yCF>BL Direct</a> <a href="/scholar?cluster=5944601893640220784&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'cDCKKe13f1IJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Fundamentals of Media Security</h3><div class="gs_a">WQ Yan, J Weir - 2010 - WeiQi Yan, Jonathan Weir &amp; Ventus  &hellip;</div><div class="gs_fl"><a href="/scholar?q=related:AREtVtYBdcMJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14084165429751517441&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'AREtVtYBdcMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=982484.982497" class=yC10>Experiential sampling for monitoring</a></h3><div class="gs_a">WQ Yan, MS Kankanhalli, J Wang&hellip; - Proceedings of the 2003  &hellip;, 2003 - dl.acm.org</div><div class="gs_rs">Abstract This demonstration presents a novel prototype of experiential sampling for <br>monitoring in a multi-camera setting. The system utilizes the experiential sampling technique <br>to compute the importance of each frame in multiple video streams, and selects the most <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:VaVPYpYnYI0J:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10187185883960026453&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'VaVPYpYnYI0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> STUDENTENSUPPORT. BE</h3><div class="gs_a">W YAN, J WEIR, LKS AUF</div><div class="gs_fl"><a href="/scholar?q=related:Dqk1jcCPctEJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15092283358437550350&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'Dqk1jcCPctEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://www.comp.nus.edu.sg/~mohan/papers/mmas.pdf" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/ANUKC34M23G9MBJH.pdf" class=yC11>Multimedia analysis and synthesis</a></h3><div class="gs_a">M Kankanhalli - AI 2003: Advances in Artificial Intelligence, 2003 - Springer</div><div class="gs_rs">We describe novel approaches to multimedia analysis and synthesis problems. We first <br>present the experiential sampling technique which has the ability to focus on the analysis <br>task by making use of the contextual information. Sensor samples are used to gather <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:t5HWlg4ROjIJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/18/3A/RN141850840.html?source=googlescholar" class="gs_nph" class=yC13>BL Direct</a> <a href="/scholar?cluster=3619224004903473591&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'t5HWlg4ROjIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> VENTUS. DK</h3><div class="gs_a">W YAN, J WEIR</div><div class="gs_fl"><a href="/scholar?q=related:nL_voShiBdEJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'nL_voShiBdEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://137.132.14.55/bitstream/handle/10635/23028/PhD%20Thesis%20-%20Pradeep%20Kumar%20Atrey%20-%202006.pdf?sequence=1" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.14.55</span><span class="gs_ggsS">137.132.14.55 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://137.132.14.55/handle/10635/23028" class=yC14>Information assimilation in Multimedia surveillance systems</a></h3><div class="gs_a"><a href="/citations?user=2s3sftgAAAAJ&amp;hl=en&amp;oi=sra">PK ATREY</a> - 2007 - 137.132.14.55</div><div class="gs_rs">Most multimedia surveillance systems nowadays utilize multiple types of sensors to detect <br>events of interest as and when they occur in the environment. However, due to the <br>asynchrony among and diversity of sensors, information assimilation, ie how to combine <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:qAMSwNgggb4J:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13727289254509413288&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'qAMSwNgggb4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> BOOKBOON. COM</h3><div class="gs_a">W YAN, J WEIR</div><div class="gs_fl"><a href="/scholar?q=related:ygZFwB_L5psJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11233889657752454858&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'ygZFwB_L5psJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> STUDENTENSUPPORT. NL</h3><div class="gs_a">W YAN, J WEIR</div><div class="gs_fl"><a href="/scholar?q=related:UN3X_foQH1oJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6493927857878195536&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'UN3X_foQH1oJ')" href="#" class="gs_nph">Cite</a></div></div></div>
