Total results = 58
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://pdf.aminer.org/001/202/088/evaluating_learning_algorithms_composed_by_a_constructive_meta_learning_scheme.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aminer.org</span><span class="gs_ggsS">aminer.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=vLiTXDHr_sYC&amp;oi=fnd&amp;pg=PA3&amp;ots=CWpAvz3Egl&amp;sig=U3QaEi-6hZo3Fxjx0eE2PLPQwOM" class=yC0>Supervised machine learning: A review of classification techniques</a></h3><div class="gs_a"><a href="/citations?user=h6zwXYMAAAAJ&amp;hl=en&amp;oi=sra">SB Kotsiantis</a>, ID Zaharakis&hellip; - Frontiers in Artificial  &hellip;, 2007 - books.google.com</div><div class="gs_rs">Abstract. The goal of supervised learning is to build a concise model of the distribution of <br>class labels in terms of predictor features. The resulting classifier is then used to assign <br>class labels to the testing instances where the values of the predictor features are known, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14303520413580717028&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 411</a> <a href="/scholar?q=related:5OsGaQhQgMYJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/35/5E/RN221091897.html?source=googlescholar" class="gs_nph" class=yC2>BL Direct</a> <a href="/scholar?cluster=14303520413580717028&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 19 versions</a> <a onclick="return gs_ocit(event,'5OsGaQhQgMYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://www.cse.ust.hk/nevinZhangGroup/readings/yi/Webb+al_MLJ05.pdf" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ust.hk</span><span class="gs_ggsS">ust.hk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/U8W306673M1P866K.pdf" class=yC3>Not so naive bayes: Aggregating one-dependence estimators</a></h3><div class="gs_a"><a href="/citations?user=_1tpf8AAAAAJ&amp;hl=en&amp;oi=sra">GI Webb</a>, JR Boughton, Z Wang - Machine Learning, 2005 - Springer</div><div class="gs_rs">Of numerous proposals to improve the accuracy of naive Bayes by weakening its attribute <br>independence assumption, both LBR and Super-Parent TAN have demonstrated <br>remarkable error performance. However, both techniques obtain this outcome at a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15733477462998097701&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 262</a> <a href="/scholar?q=related:JZ-dn2SKWNoJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15733477462998097701&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 30 versions</a> <a onclick="return gs_ocit(event,'JZ-dn2SKWNoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[BOOK]</span><span class="gs_ct2">[B]</span></span> <a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=2hwcFSxQ1CAC&amp;oi=fnd&amp;pg=PA3&amp;ots=eLZPA8dkXQ&amp;sig=Y8gAZNORCrfUS04rDOqFJAC3JEo" class=yC5>Multi-sensor data fusion: an introduction</a></h3><div class="gs_a">HB Mitchell - 2007 - books.google.com</div><div class="gs_rs">This textbook provides a comprehensive introduction to the theories and techniques of multi-<br>sensor data fusion. It is aimed at advanced undergraduate and first-year graduate students <br>in electrical engineering and computer science, as well as researchers and professional <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2636337003161738899&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 139</a> <a href="/scholar?q=related:k16sVYkmliQJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2636337003161738899&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'k16sVYkmliQJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md2', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md2" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:k16sVYkmliQJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=12028274002121835158&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4721435" class=yC6>A novel Bayes model: hidden naive Bayes</a></h3><div class="gs_a"><a href="/citations?user=S_PLKWEAAAAJ&amp;hl=en&amp;oi=sra">L Jiang</a>, <a href="/citations?user=AFn_Ki0AAAAJ&amp;hl=en&amp;oi=sra">H Zhang</a>, Z Cai - Knowledge and Data Engineering,  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Because learning an optimal Bayesian network classifier is an NP-hard problem, <br>learning-improved naive Bayes has attracted much attention from researchers. In this paper, <br>we summarize the existing improved algorithms and propose a novel Bayes model: <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1800038226608956828&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 37</a> <a href="/scholar?q=related:nKUm5zoF-xgJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1800038226608956828&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'nKUm5zoF-xgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.108.4587&amp;rep=rep1&amp;type=pdf#page=149" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.108.4587&amp;rep=rep1&amp;type=pdf#page=149" class=yC7>A comparative study of semi-naive Bayes methods in classification learning</a></h3><div class="gs_a">F Zheng, <a href="/citations?user=_1tpf8AAAAAJ&amp;hl=en&amp;oi=sra">GI Webb</a> - Proceedings of the Fourth Australasian Data Mining  &hellip;, 2005 - Citeseer</div><div class="gs_rs">Abstract. Numerous techniques have sought to improve the accuracy of Naive Bayes (NB) <br>by alleviating the attribute interdependence problem. This paper summarizes these semi-<br>naive Bayesian methods into two groups: those that apply conventional NB with a new <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14787956401609767151&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 35</a> <a href="/scholar?q=related:7_jpT_9fOc0J:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14787956401609767151&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'7_jpT_9fOc0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md4', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md4" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:7_jpT_9fOc0J:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4406010" class=yC9>Survey of improving k-nearest-neighbor for classification</a></h3><div class="gs_a"><a href="/citations?user=S_PLKWEAAAAJ&amp;hl=en&amp;oi=sra">L Jiang</a>, Z Cai, D Wang, S Jiang - Fuzzy Systems and  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract KNN (k-nearest-neighbor) has been widely used as an effective classification <br>model. In this paper, we summarize three main shortcomings confronting KNN and single <br>out three main methods for overcoming its three shortcomings. Keeping to these methods, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1154120468644810009&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 23</a> <a href="/scholar?q=related:Gc2UkXNCBBAJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1154120468644810009&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'Gc2UkXNCBBAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://diposit.ub.edu/dspace/bitstream/2445/8523/2/556420.pdf.txt" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[TXT]</span> from ub.edu</span><span class="gs_ggsS">ub.edu <span class=gs_ctg2>[TXT]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4358942" class=yCA>To select or to weigh: A comparative study of linear combination schemes for superparent-one-dependence estimators</a></h3><div class="gs_a">Y Yang, <a href="/citations?user=_1tpf8AAAAAJ&amp;hl=en&amp;oi=sra">GI Webb</a>, <a href="/citations?user=ziZYMpwAAAAJ&amp;hl=en&amp;oi=sra">J Cerquides</a>, <a href="/citations?user=RMtts8IAAAAJ&amp;hl=en&amp;oi=sra">KB Korb</a>&hellip; - Knowledge and Data &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We conduct a large-scale comparative study on linearly combining superparent-<br>one-dependence estimators (SPODEs), a popular family of seminaive Bayesian classifiers. <br>Altogether, 16 model selection and weighing schemes, 58 benchmark data sets, and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10762205393327541285&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 21</a> <a href="/scholar?q=related:JcwU3cgIW5UJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/43/25/RN220812210.html?source=googlescholar" class="gs_nph" class=yCC>BL Direct</a> <a href="/scholar?cluster=10762205393327541285&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 26 versions</a> <a onclick="return gs_ocit(event,'JcwU3cgIW5UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/d15m025726662146.pdf" class=yCD>Survey of improving naive bayes for classification</a></h3><div class="gs_a"><a href="/citations?user=S_PLKWEAAAAJ&amp;hl=en&amp;oi=sra">L Jiang</a>, D Wang, Z Cai, X Yan - Advanced Data Mining and Applications, 2007 - Springer</div><div class="gs_rs">The attribute conditional independence assumption of naive Bayes essentially ignores <br>attribute dependencies and is often violated. On the other hand, although a Bayesian <br>network can represent arbitrary attribute dependencies, learning an optimal Bayesian <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12672170718585455211&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 20</a> <a href="/scholar?q=related:a4Jk5iCY3K8J:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/57/63/RN212713179.html?source=googlescholar" class="gs_nph" class=yCE>BL Direct</a> <a href="/scholar?cluster=12672170718585455211&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'a4Jk5iCY3K8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://myweb.nutn.edu.tw/~bcchien/Papers/J_PR2004.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nutn.edu.tw</span><span class="gs_ggsS">nutn.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320304001669" class=yCF>Learning effective classifiers with Z-value measure based on genetic programming</a></h3><div class="gs_a">BC Chien, JY Lin, WP Yang - Pattern recognition, 2004 - Elsevier</div><div class="gs_rs">This paper presents a learning scheme for data classification based on genetic <br>programming. The proposed learning approach consists of an adaptive incremental learning <br>strategy and distance-based fitness functions for generating the discriminant functions <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11996779849191332158&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 16</a> <a href="/scholar?q=related:PhmdD7YffaYJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11996779849191332158&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'PhmdD7YffaYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/983j52396j081h36.pdf" class=yC11>Landscapes of naÃ¯ve bayes classifiers</a></h3><div class="gs_a"><a href="/citations?user=BC-9GqIAAAAJ&amp;hl=en&amp;oi=sra">Z Hoare</a> - Pattern Analysis &amp; Applications, 2008 - Springer</div><div class="gs_rs">Abstract The performance of the NaÃ¯ve Bayes classifier (NB) is of interest to many <br>researchers. The desire to improve upon the apparent good performance of NB while <br>maintaining its efficiency and simplicity is demonstrated by the variety of adaptations to NB <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14699769284547609511&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 15</a> <a href="/scholar?q=related:p4OoFUgSAMwJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/3D/3D/RN221579226.html?source=googlescholar" class="gs_nph" class=yC12>BL Direct</a> <a href="/scholar?cluster=14699769284547609511&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'p4OoFUgSAMwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/kj53007842r54k74.pdf" class=yC13>Dynamic k-nearest-neighbor naive bayes with attribute weighted</a></h3><div class="gs_a"><a href="/citations?user=S_PLKWEAAAAJ&amp;hl=en&amp;oi=sra">L Jiang</a>, <a href="/citations?user=AFn_Ki0AAAAJ&amp;hl=en&amp;oi=sra">H Zhang</a>, Z Cai - Fuzzy Systems and Knowledge Discovery, 2006 - Springer</div><div class="gs_rs">Abstract. K-Nearest-Neighbor (KNN) has been widely used in classification problems. <br>However, there exist three main problems confronting KNN according to our observation: 1) <br>KNN&#39;s accuracy is degraded by a simple vote; 2) KNN&#39;s accuracy is typically sensitive to <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9069794238283084369&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 13</a> <a href="/scholar?q=related:UXK_Ts5h3n0J:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/01/25/RN197021810.html?source=googlescholar" class="gs_nph" class=yC14>BL Direct</a> <a href="/scholar?cluster=9069794238283084369&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'UXK_Ts5h3n0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://bioinformatics.oxfordjournals.org/content/22/8/981.full" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from oxfordjournals.org</span><span class="gs_ggsS">oxfordjournals.org <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://bioinformatics.oxfordjournals.org/content/22/8/981.short" class=yC15>Enhancing instance-based classification with local density: a new algorithm for classifying unbalanced biomedical data</a></h3><div class="gs_a">C Plant, <a href="/citations?user=T9OSNwkAAAAJ&amp;hl=en&amp;oi=sra">C BÃ¶hm</a>, B Tilg, C Baumgartner - Bioinformatics, 2006 - Oxford Univ Press</div><div class="gs_rs">Abstract Motivation: Classification is an important data mining task in biomedicine. In <br>particular, classification on biomedical data often claims the separation of pathological and <br>healthy samples with highest discriminatory performance for diagnostic issues. Even more <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10087973663039661060&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 11</a> <a href="/scholar?q=related:BKT5IJmu_4sJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/26/62/RN185657508.html?source=googlescholar" class="gs_nph" class=yC17>BL Direct</a> <a href="/scholar?cluster=10087973663039661060&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'BKT5IJmu_4sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.134.8561&amp;rep=rep1&amp;type=pdf" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/B74V38018UL342U5.pdf" class=yC18>To select or to weigh: A comparative study of model selection and model weighing for spode ensembles</a></h3><div class="gs_a">Y Yang, <a href="/citations?user=_1tpf8AAAAAJ&amp;hl=en&amp;oi=sra">G Webb</a>, <a href="/citations?user=ziZYMpwAAAAJ&amp;hl=en&amp;oi=sra">J Cerquides</a>, <a href="/citations?user=RMtts8IAAAAJ&amp;hl=en&amp;oi=sra">K Korb</a>&hellip; - &hellip;  Learning: ECML 2006, 2006 - Springer</div><div class="gs_rs">Abstract. An ensemble of Super-Parent-One-Dependence Estimators (SPODEs) offers a <br>powerful yet simple alternative to naive Bayes classifiers, achieving significantly higher <br>classification accuracy at a moderate cost in classification efficiency. Currently there exist <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5858871580709021580&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 10</a> <a href="/scholar?q=related:jOfKOKnkTlEJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/57/5C/RN196505520.html?source=googlescholar" class="gs_nph" class=yC1A>BL Direct</a> <a href="/scholar?cluster=5858871580709021580&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'jOfKOKnkTlEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.83.182&amp;rep=rep1&amp;type=pdf" class=yC1C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/UQ14YHB2TQ83GCBP.pdf" class=yC1B>Instance cloning local naive bayes</a></h3><div class="gs_a"><a href="/citations?user=S_PLKWEAAAAJ&amp;hl=en&amp;oi=sra">L Jiang</a>, <a href="/citations?user=AFn_Ki0AAAAJ&amp;hl=en&amp;oi=sra">H Zhang</a>, J Su - Advances in Artificial Intelligence, 2005 - Springer</div><div class="gs_rs">The instance-based k-nearest neighbor algorithm (KNN)[1] is an effective classification <br>model. Its classification is simply based on a vote within the neighborhood, consisting of k <br>nearest neighbors of the test instance. Recently, researchers have been interested in <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12957522103297243912&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 10</a> <a href="/scholar?q=related:CPtNeLNd0rMJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12957522103297243912&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'CPtNeLNd0rMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://www.idsia.ch/~zaffalon/papers/2009u09-lazyNCC.pdf" class=yC1E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from idsia.ch</span><span class="gs_ggsS">idsia.ch <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1610560" class=yC1D>Lazy naive credal classifier</a></h3><div class="gs_a">G Corani, M Zaffalon - Proceedings of the 1st ACM SIGKDD Workshop  &hellip;, 2009 - dl.acm.org</div><div class="gs_rs">Abstract We propose a local (or lazy) version of the naive credal classifier. The latter is an <br>extension of naive Bayes to imprecise probability developed to issue reliable classifications <br>despite small amounts of data, which may then be carrying highly uncertain information <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16762785031580788988&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 9</a> <a href="/scholar?q=related:_KibVSxgoegJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16762785031580788988&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'_KibVSxgoegJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://pdf.aminer.org/000/367/113/learning_lazy_naive_bayesian_classifiers_for_ranking.pdf" class=yC20><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aminer.org</span><span class="gs_ggsS">aminer.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/1GHL5LCWXF5QTNAW.pdf" class=yC1F>Learning k-nearest neighbor naive bayes for ranking</a></h3><div class="gs_a"><a href="/citations?user=S_PLKWEAAAAJ&amp;hl=en&amp;oi=sra">L Jiang</a>, <a href="/citations?user=AFn_Ki0AAAAJ&amp;hl=en&amp;oi=sra">H Zhang</a>, J Su - Advanced Data Mining and Applications, 2005 - Springer</div><div class="gs_rs">Abstract. Accurate probability-based ranking of instances is crucial in many real-world data <br>mining applications. KNN (k-nearest neighbor)[1] has been intensively studied as an <br>effective classification model in decades. However, its performance in ranking is unknown. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16982822198004947898&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 6</a> <a href="/scholar?q=related:uhu0a88ar-sJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/15/32/RN171655183.html?source=googlescholar" class="gs_nph" class=yC21>BL Direct</a> <a href="/scholar?cluster=16982822198004947898&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'uhu0a88ar-sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320310002116" class=yC22>Nearest neighbour group-based classification</a></h3><div class="gs_a">NA Samsudin, <a href="/citations?user=D828shcAAAAJ&amp;hl=en&amp;oi=sra">AP Bradley</a> - Pattern Recognition, 2010 - Elsevier</div><div class="gs_rs">The purpose of group-based classification (GBC) is to determine the class label for a set of <br>test samples, utilising the prior knowledge that the samples belong to same, but unknown <br>class. This can be seen as a simplification of the well studied, but computationally <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13711027719327147525&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 7</a> <a href="/scholar?q=related:BWYHDBFbR74J:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13711027719327147525&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'BWYHDBFbR74J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://myweb.nutn.edu.tw/~bcchien/Papers/C_DaWak2003.pdf" class=yC24><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nutn.edu.tw</span><span class="gs_ggsS">nutn.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/kwhxm7113m46dg8q.pdf" class=yC23>Generating effective classifiers with supervised learning of genetic programming</a></h3><div class="gs_a">BC Chien, JH Yang, nd Lin - Data Warehousing and Knowledge Discovery, 2003 - Springer</div><div class="gs_rs">A new approach of learning classifiers using genetic programming has been developed <br>recently. Most of the previous researches generate classification rules to classify data. <br>However, the generation of rules is time consuming and the recognition accuracy is <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8244358436687042431&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 5</a> <a href="/scholar?q=related:f9e5U1HYaXIJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/0D/4D/RN137105833.html?source=googlescholar" class="gs_nph" class=yC25>BL Direct</a> <a href="/scholar?cluster=8244358436687042431&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'f9e5U1HYaXIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/gbaa7k30uxaxe3bv.pdf" class=yC26>Enhancing SNNB with local accuracy estimation and ensemble techniques</a></h3><div class="gs_a">Z Xie, Q Zhang, W Hsu, M Lee - Database Systems for Advanced  &hellip;, 2005 - Springer</div><div class="gs_rs">NaÃ¯ve Bayes, the simplest Bayesian classifier, has shown excellent performance given its <br>unrealistic independence assumption. This paper studies the selective neighborhood-based <br>naÃ¯ve Bayes (SNNB) for lazy classification, and develops three variant algorithms, SNNB-<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12182676847007854754&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 5</a> <a href="/scholar?q=related:onBHtwuQEakJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/42/12/RN180225819.html?source=googlescholar" class="gs_nph" class=yC27>BL Direct</a> <a href="/scholar?cluster=12182676847007854754&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'onBHtwuQEakJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.worldscientific.com/doi/abs/10.1142/S0218001408006703" class=yC28>Using instance cloning to improve naive Bayes for ranking</a></h3><div class="gs_a"><a href="/citations?user=S_PLKWEAAAAJ&amp;hl=en&amp;oi=sra">L Jiang</a>, D Wang, <a href="/citations?user=AFn_Ki0AAAAJ&amp;hl=en&amp;oi=sra">H Zhang</a>, Z Cai&hellip; - International Journal of  &hellip;, 2008 - World Scientific</div><div class="gs_rs">Improving naive Bayes (simply NB) 15, 28 for classification has received significant <br>attention. Related work can be broadly divided into two approaches: eager learning and lazy <br>learning. 1 Different from eager learning, the key idea for extending naive Bayes using <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7414001306681404089&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 4</a> <a href="/scholar?q=related:ueoGSejS42YJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7414001306681404089&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'ueoGSejS42YJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/91690x/20084/26461517.0.html" class=yC29>ä¸ç§æé« K-è¿é»ç®æ³æççæ°ç®æ³</a></h3><div class="gs_a">éå¾®å¾®ï¼ åæ¶ - è®¡ç®æºå·¥ç¨ä¸åºç¨, 2008 - cqvip.com</div><div class="gs_rs">æè¦: K-è¿é»(K-Nearest-Neighbor, KNN) ç®æ³æ¯ä¸ç§æåºæ¬çåºäºå®ä¾çå­¦ä¹ æ¹æ³, <br>è¢«å¹¿æ³åºç¨äºæºå¨å­¦ä¹ ä¸æ°æ®ææ. å¶å­¦ä¹ è¿ç¨åªæ¯ç®åå°å­å¨å·²ç¥çè®­ç»æ°æ®. <br>å½éå°æ°çæ¥è¯¢å®ä¾æ¶, ä¸ç³»åç¸ä¼¼çå®ä¾è¢«ä»å­å¨å¨ä¸­ååº, å¹¶ç¨æ¥åç±»æ°çæ¥è¯¢å®ä¾. KNN <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2186608336545091899&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 7</a> <a href="/scholar?q=related:O5GtarJkWB4J:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2186608336545091899&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'O5GtarJkWB4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="http://www.jofcis.com/publishedpapers/2011_7_5_1672_1679.pdf" class=yC2B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from jofcis.com</span><span class="gs_ggsS">jofcis.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.jofcis.com/publishedpapers/2011_7_5_1672_1679.pdf" class=yC2A>Attribute weighting via differential evolution algorithm for attribute weighted naive bayes (wnb)</a></h3><div class="gs_a">J WU, Z CAI - Journal of Computational Information Systems, 2011 - jofcis.com</div><div class="gs_rs">Abstract The naive Bayes (NB) is a popular classification technique for data mining and <br>machine learning, which is based on the attribute independence assumption. Researchers <br>have proposed out many effective methods to improve the performance of NB by lowering <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16552908283708498577&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 4</a> <a href="/scholar?q=related:keIQCmK-t-UJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'keIQCmK-t-UJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md21', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md21" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:keIQCmK-t-UJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5466902" class=yC2C>Naive Bayes variants in classification learning</a></h3><div class="gs_a">KM Al-Aidaroos, AA Bakar&hellip; - Information Retrieval &amp;  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Naive Bayesian classifier is one of the most effective and efficient classification <br>algorithms. The elegant simplicity and apparent accuracy of naive Bayes (NB) even when <br>the independence assumption is violated, fosters the on-going interest in the model. This <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7356674255857019278&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 3</a> <a href="/scholar?q=related:jmmeJEIoGGYJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'jmmeJEIoGGYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1374266" class=yC2D>A study of selective neighborhood-based naive Bayes for efficient lazy learning</a></h3><div class="gs_a">Z Xie, Q Zhang - Tools with Artificial Intelligence, 2004. ICTAI  &hellip;, 2004 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This work studies two accuracy estimation techniques, global accuracy estimation <br>and local accuracy estimation, under the algorithmic framework of the selective <br>neighborhood-based naive Bayes (SNNB) for lazy classification, resulting in two concrete <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12195886944766945750&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 3</a> <a href="/scholar?q=related:1mmoR49-QKkJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12195886944766945750&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'1mmoR49-QKkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1565680" class=yC2E>Learning instance greedily cloning naive Bayes for ranking</a></h3><div class="gs_a"><a href="/citations?user=S_PLKWEAAAAJ&amp;hl=en&amp;oi=sra">L Jiang</a>, <a href="/citations?user=AFn_Ki0AAAAJ&amp;hl=en&amp;oi=sra">H Zhang</a> - Data Mining, Fifth IEEE International  &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Naive Bayes (simply NB)(Langley et al., 1992) has been widely used in machine <br>learning and data mining as a simple and effective classification algorithm. Since its <br>conditional independence assumption is rarely true, researchers have made a substantial <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9167201524584654787&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 3</a> <a href="/scholar?q=related:w6dJeTdxOH8J:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9167201524584654787&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'w6dJeTdxOH8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4405983" class=yC2F>A double layer Bayesian classifier</a></h3><div class="gs_a"><a href="/citations?user=kwuOVEsAAAAJ&amp;hl=en&amp;oi=sra">J Sun</a>, C Wang, S Chen - Fuzzy Systems and Knowledge  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Numerous approaches have been proposed to relax the conditional independence <br>assumption of naive Bayes, the accuracy performance was indeed improved relative to <br>naive Bayes when the assumption is violated. But most of the previous approaches <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10206241075410545758&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 3</a> <a href="/scholar?q=related:XqzY3y7ao40J:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10206241075410545758&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'XqzY3y7ao40J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/0824226J22581928.pdf" class=yC30>Lazy averaged one-dependence estimators</a></h3><div class="gs_a"><a href="/citations?user=S_PLKWEAAAAJ&amp;hl=en&amp;oi=sra">L Jiang</a>, <a href="/citations?user=AFn_Ki0AAAAJ&amp;hl=en&amp;oi=sra">H Zhang</a> - Advances in Artificial Intelligence, 2006 - Springer</div><div class="gs_rs">Naive Bayes is a probability-based classification model based on the conditional <br>independence assumption. In many real-world applications, however, this assumption is <br>often violated. Responding to this fact, researchers have made a substantial amount of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13614724449872390674&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 2</a> <a href="/scholar?q=related:Eip41cA38bwJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/45/47/RN190745350.html?source=googlescholar" class="gs_nph" class=yC31>BL Direct</a> <a href="/scholar?cluster=13614724449872390674&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'Eip41cA38bwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4420482" class=yC32>Lazy metacost naive bayes</a></h3><div class="gs_a"><a href="/citations?user=h6zwXYMAAAAJ&amp;hl=en&amp;oi=sra">S Kotsiantis</a>, D Kanellopoulos - &hellip;  Information Technology, 2007.  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper firstly provides a review on the various methodologies that have tried to <br>handle the problem of learning from data sets with an unbalanced class distribution. Finally, <br>it presents an experimental study of these methodologies with the local application of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12010770348495360839&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 1</a> <a href="/scholar?q=related:R1PcBP_TrqYJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12010770348495360839&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'R1PcBP_TrqYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5565252" class=yC33>A knn classifier with pso feature weight learning ensemble</a></h3><div class="gs_a">Q Cao, Y Liu - Intelligent Control and Information Processing ( &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Feature selection and weighting are normally ways to improve KNN classification <br>algorithm. In this paper, we use the reverse cloud algorithm to map the training samples into <br>clouds. Each attribute is mapped to a cloud vector. Reverse cloud algorithm is not <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14716700605531781717&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 1</a> <a href="/scholar?q=related:VXp_cjo5PMwJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'VXp_cjo5PMwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB29" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW29"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.14.7598&amp;rep=rep1&amp;type=pdf" class=yC35><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.14.7598&amp;rep=rep1&amp;type=pdf" class=yC34>Not so naive Bayesian classification</a></h3><div class="gs_a"><a href="/citations?user=_1tpf8AAAAAJ&amp;hl=en&amp;oi=sra">GI Webb</a>, JR Boughton, Z Wang - 2003 - Citeseer</div><div class="gs_rs">Abstract Of numerous proposals to improve the accuracy of naive Bayes by weakening its <br>attribute independence assumption, both LBR and TAN have demonstrated remarkable <br>error performance. However, both techniques obtain this outcome at a considerable <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3506417857079767457&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 1</a> <a href="/scholar?q=related:oXFTlXZMqTAJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3506417857079767457&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'oXFTlXZMqTAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md29', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md29" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:oXFTlXZMqTAJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/G4010234V5821204.pdf" class=yC36>NaÃ¯ve bayesian tree pruning by local accuracy estimation</a></h3><div class="gs_a">Z Xie - Advanced Data Mining and Applications, 2006 - Springer</div><div class="gs_rs">Abstract. NaÃ¯ve Bayesian Tree is a high-accuracy classification method by combining <br>decision tree and naÃ¯ve Bayes together. It uses averaged global accuracy as the <br>measurement of goodness in the induction process of the tree structure, and chooses the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6591671991816114643&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 1</a> <a href="/scholar?q=related:01EXnMBSelsJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/33/35/RN193430154.html?source=googlescholar" class="gs_nph" class=yC37>BL Direct</a> <a href="/scholar?cluster=6591671991816114643&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'01EXnMBSelsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB31" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW31"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.188.6436&amp;rep=rep1&amp;type=pdf" class=yC39><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.188.6436&amp;rep=rep1&amp;type=pdf" class=yC38>Scaling Up the Accuracy of K-Nearest-Neighbour Classifiers: A NaÃ¯ve-Bayes Hybrid</a></h3><div class="gs_a"><a href="/citations?user=S_PLKWEAAAAJ&amp;hl=en&amp;oi=sra">L Jiang</a>, D Wang, Z Cai, S Jiang, X Yan - International Journal of  &hellip;, 2009 - Citeseer</div><div class="gs_rs">Learning classifiers to address the classification problems is a fundamental issue in data <br>mining. Typically, a set of training instances with corresponding class labels is given, and a <br>classifier is learned and used to predict the class of an unseen instance. An instance is <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17452917978880282074&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 1</a> <a href="/scholar?q=related:2g0wqW44NfIJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17452917978880282074&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'2g0wqW44NfIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md31', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md31" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:2g0wqW44NfIJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5559858" class=yC3A>Dynamic K-Nearest-Neighbor with Distance and attribute weighted for classification</a></h3><div class="gs_a">J Wu, Z Cai, Z Gao - Electronics and Information Engineering ( &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract K-Nearest-Neighbor (KNN) as an important classification method based on closest <br>training examples has been widely used in data mining due to its simplicity, effectiveness, <br>and robustness. However, the class probability estimation, the neighborhood size and the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17322062901187043329&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 2</a> <a href="/scholar?q=related:AeA5sm5UZPAJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17322062901187043329&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'AeA5sm5UZPAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:367"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB33" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW33"><a href="http://myweb.nutn.edu.tw/~bcchien/Papers/C_SMC2006.pdf" class=yC3C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nutn.edu.tw</span><span class="gs_ggsS">nutn.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4274545" class=yC3B>Features selection based on rough membership and genetic programming</a></h3><div class="gs_a">BC Chien, JH Yang - &hellip; , Man and Cybernetics, 2006. SMC&#39;06.  &hellip;, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper discusses the feature selection problem upon supervised learning. A <br>learning method based on rough sets and genetic programming is proposed to select <br>significant features and classify numerical data. The proposed method uses rough <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11261742654759125715&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 1</a> <a href="/scholar?q=related:00LI-Ea_SZwJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11261742654759125715&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'00LI-Ea_SZwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:366"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB34" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW34"><a href="http://file.lw23.com/b/b0/b06/b069553c-1d35-47e8-b834-1c5f439511ea.pdf" class=yC3D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from lw23.com</span><span class="gs_ggsS">lw23.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> L2DLNB: ææ°å­¦ä¹ åå±æ´ç´ è´å¶æ¯åç±»å¨*</h3><div class="gs_a">å­æ±æï¼ çå´éªï¼ ççºï¼ éä¸ç¦ - è®¡ç®æºç§å­¦, 2007</div><div class="gs_fl"><a href="/scholar?cites=12169885826678135561&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=58">Cited by 1</a> <a href="/scholar?q=related:CRs2OK4e5KgJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12169885826678135561&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'CRs2OK4e5KgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:365"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB35" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW35"><a href="http://www.csse.monash.edu.au/~webb/Files/ZhengWebb08a.pdf" class=yC3F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from monash.edu.au</span><span class="gs_ggsS">monash.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.csse.monash.edu.au/~webb/Files/ZhengWebb08a.pdf" class=yC3E>Semi-naive Bayesian Classification</a></h3><div class="gs_a">F Zheng, <a href="/citations?user=_1tpf8AAAAAJ&amp;hl=en&amp;oi=sra">GI Webb</a> - 2008 - csse.monash.edu.au</div><div class="gs_rs">Abstract The success and popularity of naive Bayes (NB) has led to a field of research <br>exploring algorithms that seek to retain its numerous strengths while reducing error by <br>alleviating the attribute interdependence problem. These algorithms can be categorized <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:vrTnGPqG-4MJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9510343446840718526&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'vrTnGPqG-4MJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md35', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md35" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:vrTnGPqG-4MJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a>  <a href="/scholar?q=info:vrTnGPqG-4MJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=12737756951874756161&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:364"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB36" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW36"><a href="http://eprints.uthm.edu.my/2697/1/Noorhaniza_Wahid_1.pdf" class=yC41><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uthm.edu.my</span><span class="gs_ggsS">uthm.edu.my <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://eprints.uthm.edu.my/2697/" class=yC40>A novel approach to data mining using simplified swarm optimization</a></h3><div class="gs_a">N Wahid - 2011 - eprints.uthm.edu.my</div><div class="gs_rs">Data mining has become an increasingly important approach to deal with the rapid growth of <br>data collected and stored in databases. In data mining, data classification and feature <br>selection are considered the two main factors that drive people when making decisions. <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:DH8QHkom8ooJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'DH8QHkom8ooJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:363"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB37" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW37"><a href="http://www.joics.com/publishedpapers/2011_8_7_1063_1073.pdf" class=yC43><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from joics.com</span><span class="gs_ggsS">joics.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.joics.com/publishedpapers/2011_8_7_1063_1073.pdf" class=yC42>Learning Averaged One-dependence Estimators by Attribute Weightingâ</a></h3><div class="gs_a">J Wu, Z Cai - 2011 - joics.com</div><div class="gs_rs">Abstract Averaged One-Dependence Estimators (AODE) as the most effective improved <br>Naive Bayes (NB) algorithm is a probabilistic classification learning technique. It addresses <br>the attribute independence assumption of naive Bayes by averaging all of the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:MWVpHq_9zDoJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'MWVpHq_9zDoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md37', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md37" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:MWVpHq_9zDoJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:362"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB38" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW38"><a href="http://www.csse.monash.edu.au/~webb/Files/Webb06b.pdf" class=yC45><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from monash.edu.au</span><span class="gs_ggsS">monash.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=VOiPmr1x7HcC&amp;oi=fnd&amp;pg=PA7&amp;ots=kVSSL5HuA2&amp;sig=KnwkbffBMlxPBSQuBIcFzHMJm6g" class=yC44>Anytime Learning and Classification for Online Applications}</a></h3><div class="gs_a"><a href="/citations?user=_1tpf8AAAAAJ&amp;hl=en&amp;oi=sra">GI Webb</a>, Y Li, M Looi, N Zhong - Advances in Intelligent IT:  &hellip;, 2006 - books.google.com</div><div class="gs_rs">Abstract. Many online applications of machine learning require fast classification and hence <br>utilize efficient classifiers such as naÃ¯ve Bayes. However, outside periods of peak <br>computational load, additional computational resources will often be available. Anytime <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:MtKyLmtAB5kJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11026853041729098290&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'MtKyLmtAB5kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:361"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/X526QP4371817727.pdf" class=yC46>Bayesian Decision Theory</a></h3><div class="gs_a">HB Mitchell - Data Fusion: Concepts and Ideas, 2012 - Springer</div><div class="gs_rs">The subject of this chapter, and the one that follows it, is Bayesian decision theory and its <br>use in multi-sensor data fusion. To make our discussion concrete we shall concentrate on <br>the pattern recognition problem [19] in which an unknown pattern, or object, O is to be <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:xeT7PBB6cbQJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'xeT7PBB6cbQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:360"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB40" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW40"><a href="http://jnrs.gop.edu.tr/papers/2012-1/JNRS-2012-1-08.pdf" class=yC48><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from gop.edu.tr</span><span class="gs_ggsS">gop.edu.tr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://jnrs.gop.edu.tr/papers/2012-1/JNRS-2012-1-08.pdf" class=yC47>Least Squares Approach to Locally Weighted Naive Bayes Method</a></h3><div class="gs_a">U Orhan, K Adem, O Comert - Journal of New Results in Science, 2012 - jnrs.gop.edu.tr</div><div class="gs_rs">Abstract This study proposes a new approach which calculates the weights of Locally <br>Weighted Naive Bayes (LWNB) developed on Naive Bayes (NB) which is known with its <br>simple structure. In this approach, a new equation is described by assigning a powered <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'6myoYm8nV7AJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md40', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md40" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:6myoYm8nV7AJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:359"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0957417412008640" class=yC49>A network intrusion detection system based on a Hidden NaÃ¯ve Bayes multiclass classifier</a></h3><div class="gs_a">L Koc, T Mazzuchi, S Sarkani - Expert Systems with Applications, 2012 - Elsevier</div><div class="gs_rs">With increasing Internet connectivity and traffic volume, recent intrusion incidents have <br>reemphasized the importance of network intrusion detection systems for combating <br>increasingly sophisticated network attacks. Techniques such as pattern recognition and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:A9n7cSThXnMJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8313329508819917059&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'A9n7cSThXnMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:358"><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=7URT9Xpfsj4C&amp;oi=fnd&amp;pg=PA134&amp;ots=ejstRo5Lj3&amp;sig=tB-eP9jz6I_QAwfOGqXOThWDh0c" class=yC4A>Survey of Improving Naive Bayes for Classiï¬cation</a></h3><div class="gs_a">DW LiangxiaoJiang, Z Cai, X Yan - Advanced Data Mining and  &hellip;, 2007 - books.google.com</div><div class="gs_rs">Abstract. The attribute conditional independence assumption of naive Bayes essentially <br>ignores attribute dependencies and is often violated. On the other hand, although a <br>Bayesian network can represent arbitrary attribute dependencies, learning an optimal <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:IuaElPDpTgcJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'IuaElPDpTgcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:357"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5487185" class=yC4B>KNN algorithm improving based on cloud model</a></h3><div class="gs_a">L Yu, C Gui-Sheng - Advanced Computer Control (ICACC),  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract KNN algorithm is particularly sensitive to outliers and noise contained in the training <br>data set. In this paper, we use the reverse cloud algorithm to map the training samples into <br>clouds. Each attribute is mapped to a cloud vector. Reverse cloud algorithm is not <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:TmncqwQb-tUJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'TmncqwQb-tUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:356"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4959281" class=yC4C>A Classifier Selection Strategy for Lazy Bayesian Rules Based on Local Accuracy Estimation</a></h3><div class="gs_a">Z Xie - Education Technology and Computer Science, 2009.  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Lazy Bayesian rule (LBR) is a novel classification method of high predictability. <br>However, its classifier selection strategy is somewhat simple, in that it always uses the most <br>specific one to make the final decision. In this paper, we suggest to use the one with the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:XRwGtiohtksJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5455584465932131421&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'XRwGtiohtksJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:355"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6093359" class=yC4D>Maintaining imbalance highly dependent medical data using dirichlet process data generation</a></h3><div class="gs_a">T Antaresti, MI Fanany&hellip; - &hellip;  (ICDIM), 2011 Sixth  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The existence of imbalanced data between one class and another class is an <br>important issue to be considered in a classification problem. One of the well-known data <br>balancing technique is the artificial oversampling, which increase the size of datasets. In <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:vPgEtzU9goEJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'vPgEtzU9goEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:354"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/FPUJ365GQQ885078.pdf" class=yC4E>Boosting Local NaÃ¯ve Bayesian Rules</a></h3><div class="gs_a">Z Xie - Advances in Neural NetworksâISNN 2009, 2009 - Springer</div><div class="gs_rs">Abstract. Several classification algorithms based on local naÃ¯ve Bayesian rules have been <br>recently developed to provide high predictability. However, most of them use classifier <br>selection strategy in decision making. To make use of classifier fusion strategy, this paper <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:gL8oxCecJoIJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9378354968654299008&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'gL8oxCecJoIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:353"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB47" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW47"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.111.8388&amp;rep=rep1&amp;type=pdf" class=yC50><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4021480" class=yC4F>Augmented Naive Bayes Based on Evolutional Strategy</a></h3><div class="gs_a">D Zeng, S Zhang, Z Cai, S Jiang&hellip; - &hellip;  Systems Design and  &hellip;, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The naive Bayesian classifier provides a very simple and effective model for <br>machine learning, but its attribute independence assumption is often violated in the real <br>world. To improve the performance of Bayesian classifier, we present a novel algorithm <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:qfUKxTQRp7kJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13377680136469149097&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'qfUKxTQRp7kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:352"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB48" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW48"><a href="http://www.ijert.org/browse/may-2012-edition?download=135%3Aimproved-knn-algorithm-by-optimizing-cross-validation&amp;start=100" class=yC52><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ijert.org</span><span class="gs_ggsS">ijert.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ijert.org/browse/may-2012-edition?download=135%3Aimproved-knn-algorithm-by-optimizing-cross-validation&amp;start=100" class=yC51>Improved kNN Algorithm by Optimizing Cross-validation</a></h3><div class="gs_a">MSS Dadhania, JS Dhobi - International Journal of Engineering, 2012 - ijert.org</div><div class="gs_rs">Abstract Nowadays web applications based on short text is increasing rapidly. Moreover, the <br>classification algorithms which are applied to short text data are Support Vector Machines <br>algorithm, k-Nearest Neighbors algorithm and Naive Bayes algorithm. kNN algorithm <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:X2sMyXxOOuwJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'X2sMyXxOOuwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md48', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md48" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:X2sMyXxOOuwJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:351"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB49" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW49"><a href="http://www.csse.monash.edu.au/~webb/cse459/l4refs.pdf" class=yC54><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from monash.edu.au</span><span class="gs_ggsS">monash.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.csse.monash.edu.au/~webb/cse459/l4refs.pdf" class=yC53>CSE459 Lecture 4 References</a></h3><div class="gs_a"><a href="/citations?user=_1tpf8AAAAAJ&amp;hl=en&amp;oi=sra">GI Webb</a> - 2004 - csse.monash.edu.au</div><div class="gs_rs">Domingos, P., &amp; Pazzani, M. (1996). Beyond independence: Conditions for the optimality of the <br>simple Bayesian classifier. In Proceedings of the Thirteenth International Conference on Machine <br>Learning, pp. 105â112. Morgan Kaufmann. Friedman, N., Geiger, D., &amp; Goldszmidt, M. <b> ...</b> </div><div class="gs_fl"><a href="/scholar?q=related:0oQp6s7PdfEJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17399041223014581458&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'0oQp6s7PdfEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md49', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md49" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:0oQp6s7PdfEJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:350"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB50" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW50"><a href="http://www.nii.ac.jp/TechReports/09-016E.pdf" class=yC56><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nii.ac.jp</span><span class="gs_ggsS">nii.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.nii.ac.jp/TechReports/09-016E.pdf" class=yC55>Adaptive Classification Using Shared-Neighbor Information</a></h3><div class="gs_a">ME Houle, M Nett - 2009 - nii.ac.jp</div><div class="gs_rs">Abstract Nearest-neighbor approaches for classification have long been recognized for their <br>potential in achieving low error rates, despite their perceived lack of scalability. Recent <br>advances in the efficient computation of approximate k-nearest neighborhoods have <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:5tnu-6BRf3gJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8682748358456957414&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'5tnu-6BRf3gJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:349"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB51" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW51"><a href="http://www.ceaj.org/Jweb_gcyyy/CN/article/downloadArticleFile.do?attachType=PDF&amp;id=15715" class=yC58><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ceaj.org</span><span class="gs_ggsS">ceaj.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ceaj.org/Jweb_gcyyy/CN/article/downloadArticleFile.do?attachType=PDF&amp;id=15715" class=yC57>éå¾®å¾®, å æ¶</a></h3><div class="gs_a">LU Wei&#39;wei, LIU Jing - Computer Engineering and Applications, 2008 - ceaj.org</div><div class="gs_rs">æè¦: K&#39;è¿é»(K&#39;Nearest&#39;Neighbor, KNN) ç®æ³æ¯) ç§æåºæ¬çåºäºå®ä¾ç# ä¹ æ¹æ³, <br>è¢«å¹¿æ³åºç¨äºæºå¨# ä¹ ä¸æ°æ®ææ, å¶# ä¹ è¿ç¨åªæ¯ç®åå°å­å¨å·²ç¥çè®­ç»æ°æ®, <br>å½éå°æ°çæ¥è¯¢å®ä¾æ¶,) ç³»åç¸ä¼¼çå®ä¾è¢«ä»å­å¨å¨ä¸­ååº, å¹¶ç¨æ¥åç±»æ°çæ¥è¯¢å®ä¾, KNN <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:POJjAfXh73cJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8642374652353831484&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'POJjAfXh73cJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md51', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md51" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:POJjAfXh73cJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:348"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB52" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW52"><a href="http://szgrabowski.kis.p.lodz.pl/PhD/PhD-calosc-1106b.doc" class=yC5A><span class="gs_ggsL"><span class=gs_ctg2>[DOC]</span> from lodz.pl</span><span class="gs_ggsS">lodz.pl <span class=gs_ctg2>[DOC]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[DOC]</span><span class="gs_ct2">[DOC]</span></span> <a href="http://szgrabowski.kis.p.lodz.pl/PhD/PhD-calosc-1106b.doc" class=yC59>Rozprawa doktorska</a></h3><div class="gs_a">S Grabowski - szgrabowski.kis.p.lodz.pl</div><div class="gs_rs">Informatyka w duÅ¼ej mierze polega na czynieniu moÅ¼liwie dobrego uÅ¼ytku z <br>danych.âCzynienie dobrego uÅ¼ytkuâ oznacza tu m. in. analizÄ i kategoryzacjÄ danych, <br>transmisjÄ i wyszukiwanie danych oraz wygodne metody ich prezentacji. Rozpoznawanie <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:w-FXE_jJ314J:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6836404826685301187&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'w-FXE_jJ314J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md52', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md52" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:w-FXE_jJ314J:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:347"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB53" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW53"><a href="http://portal.inf.ufg.br/mestrado/sites/www.inf.ufg.br.mestrado/files/uploads/Dissertacoes/Fernando%20Chagas.pdf" class=yC5C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ufg.br</span><span class="gs_ggsS">ufg.br <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://portal.inf.ufg.br/mestrado/sites/www.inf.ufg.br.mestrado/files/uploads/Dissertacoes/Fernando%20Chagas.pdf" class=yC5B>VariaÃ§Ãµes do MÃ©todo kNN e suas AplicaÃ§Ãµes na ClassificaÃ§Ã£o AutomÃ¡tica de Textos</a></h3><div class="gs_a">FC SANTOS - portal.inf.ufg.br</div><div class="gs_rs">Grande parte das pesquisas relacionadas com a classificaÃ§Ã£o automÃ¡tica de textos (CAT) <br>tem procurado melhorar o desempenho (eficÃ¡cia ou eficiÃªncia) do classificador responsÃ¡vel <br>por classificar automaticamente um documento d, ainda nÃ£o classificado. O mÃ©todo dos k <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:uFp-UZdJN38J:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9166876480792058552&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'uFp-UZdJN38J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md53', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md53" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:uFp-UZdJN38J:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:346"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB54" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW54"><a href="http://www.arocmag.com/arocmag/ch/reader/create_pdf.aspx?file_no=201205005" class=yC5E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arocmag.com</span><span class="gs_ggsS">arocmag.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.arocmag.com/arocmag/ch/reader/create_pdf.aspx?file_no=201205005" class=yC5D>åºäº AR æ¨¡åææ³çé«æ¯è¿ç¨å¤æ¨¡åå»ºæ¨¡æ¹æ³</a></h3><div class="gs_a">éå«å«ï¼ æ¨æ§ä¸­ - è®¡ç®æºåºç¨ç ç©¶, 2012 - arocmag.com</div><div class="gs_rs">æè¦: éå¯¹Kî è¿é»ç®æ³ä¸­é¾ä»¥ç¡®å®K å¼çå®éé®é¢, æåºä¸ç§åºäºAR æ¨¡åææ³çé«æ¯è¿ç¨å¤<br>æ¨¡åå»ºæ¨¡æ¹æ³. è¯¥æ¹æ³åé´AR æ¨¡åçææ³, å°åä¸æ¶å»çè¾åºå¼ä½ä¸ºå½åæ¶å»è¾åºå¼çä¸ä¸ªå½±å<br>å ç´ æ¾å¥è¾å¥éä¸­, éè¿è®¡ç®è®­ç»æ ·æ¬çå¹³åæå°è·ç¦»ä»èå¾å°ä¸ä¸ªæç´¢åå¾, æ ¹æ®æç´¢åå¾<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:7MXtVcZd2MEJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13968017350716147180&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'7MXtVcZd2MEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md54', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md54" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:7MXtVcZd2MEJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:345"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/92718x/201103/1001732252.html" class=yC5F>k å­å¸ååç±»æ¹æ³</a></h3><div class="gs_a">çå»æ - å±±è¥¿å¤§å­¦å­¦æ¥: èªç¶ç§å­¦ç, 2012 - cqvip.com</div><div class="gs_rs">åºäºå¸åçk å±é¨è¶å¹³é¢è·ç¦»åç±»æ¹æ³, éè¿æ¹è¿k è¿é»ç®æ³å¨å¤çå°æ ·æ¬é®é¢æ¶çå³ç­è¾¹çè<br>æ¾èæé«åç±»æ§è½. ä½æ¯, è¯¥æ¹æ³å¯¹åªå£°åç±»çæ°ç®ææ, å¹¶ä¸å¨ä¸ç±»æ ·æ¬&quot; åå´&quot; å¦ä¸ç±»æ ·æ¬æ¶, <br>ç±äºå¤å´ç±»å¸åä¸åé¨æ ·æ¬çè·ç¦»ä¸ºé¶èå¯¼è´åç±»éè¯¯. éå¯¹ä¸è¿°é®é¢, æåºäºk å­å¸ååç±»<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:V0ZnVrN5Oz8J:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4556369259171104343&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'V0ZnVrN5Oz8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:344"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB56" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW56"><a href="http://szgrabowski.kis.p.lodz.pl/ro05/phd-final.pdf" class=yC61><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from lodz.pl</span><span class="gs_ggsS">lodz.pl <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://szgrabowski.kis.p.lodz.pl/ro05/phd-final.pdf" class=yC60>Konstrukcja klasyfikatorÃ³w minimalnoodlegÅoÅciowych o strukturze sieciowej</a></h3><div class="gs_a">S GRABOWSKI - szgrabowski.kis.p.lodz.pl</div><div class="gs_rs">Informatyka w duÅej mierze polega na czynieniu moÅliwie dobrego uÅytku z <br>danych.âCzynienie dobrego uÅytkuâ oznacza tu m. in. analizÄ i kategoryzacjÄ danych, <br>transmisjÄ i wyszukiwanie danych oraz wygodne metody ich prezentacji. Rozpoznawanie <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:0UGHWlcnycoJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'0UGHWlcnycoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md56', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md56" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:0UGHWlcnycoJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:343"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/88688x/200931/33265110.html" class=yC62>KNN åç±»ç®æ³ç ç©¶</a></h3><div class="gs_a">æç§å¨ - ç§æä¿¡æ¯, 2009 - cqvip.com</div><div class="gs_rs">KNN ç®æ³æ¯åºç¨æå¹¿æ³çåç±»ææ¯ä¹ä¸. æç« ç®è¦ä»ç»äºKNN ç®æ³çåºæ¬åç, <br>éç¹è®ºè¿°äºç ç©¶äººåéå¯¹KNN ç®æ³çä¸è¶³æåçåç§æ¹è¿. ä¸»è¦ä»è·ç¦»è®¡ç®çæ¹è¿, <br>éä½è®¡ç®å¤æåº¦, K å¼çéæ©, ä¸å¶å®æ¹æ³éæå ä¸ªæ¹é¢è¿è¡åæç ç©¶.</div><div class="gs_fl"><a href="/scholar?q=related:w5Iqu7YWoaMJ:scholar.google.com/&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11790730273512657603&amp;hl=en&amp;num=58&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'w5Iqu7YWoaMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
