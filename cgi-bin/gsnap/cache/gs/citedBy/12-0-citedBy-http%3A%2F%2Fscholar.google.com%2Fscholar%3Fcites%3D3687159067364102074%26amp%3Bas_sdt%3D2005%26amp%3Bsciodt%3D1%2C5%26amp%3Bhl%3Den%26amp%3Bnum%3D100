Total results = 12
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://mrim.imag.fr/publications/2005/MAR05/p760-martinet.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from imag.fr</span><span class="gs_ggsS">imag.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1099737" class=yC0>A model for weighting image objects in home photographs</a></h3><div class="gs_a">J Martinet, Y Chiaramella, P Mulhem - Proceedings of the 14th ACM  &hellip;, 2005 - dl.acm.org</div><div class="gs_rs">Abstract The paper presents a contribution to image indexing consisting in a weighting <br>model for visible objects--or image objects--in home photographs. To improve its <br>effectiveness this weighting model has been designed according to human perception <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17549140672152019705&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12">Cited by 18</a> <a href="/scholar?q=related:-SL7RHYSi_MJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17549140672152019705&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'-SL7RHYSi_MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4493928" class=yC2>A novel semantic-based image retrieval method</a></h3><div class="gs_a">A Lakdashti, MS Moin, K Badie - &hellip;  Technology, 2008. ICACT  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we design a fuzzy system for image retrieval to reduce the semantic <br>gap in the content-based image retrieval systems. Our main contribution is three-fold:(1) <br>designing a fuzzy modeling approach to model the expert human behavior in the image <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15433318057971010105&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12">Cited by 9</a> <a href="/scholar?q=related:Ocr7JgEpLtYJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15433318057971010105&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'Ocr7JgEpLtYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4493589" class=yC3>Semantic-based image retrieval: A fuzzy modeling approach</a></h3><div class="gs_a">A Lakdashti, M Shahram Moin&hellip; - Computer Systems and  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose a new fuzzy based image retrieval approach to reduce <br>the semantic gap in content-based image retrieval systems. Our main contributions are:(1) <br>an algorithm for reduction of feature space dimensionality,(2) a fuzzy modeling approach <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9004873066698193170&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12">Cited by 6</a> <a href="/scholar?q=related:EjkHJFi893wJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9004873066698193170&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'EjkHJFi893wJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/W4512P2555X2466K.pdf" class=yC4>A new approach in content-based image retrieval using fuzzy</a></h3><div class="gs_a">H Aboulmagd, N El-Gayar, H Onsi - Telecommunication Systems, 2009 - Springer</div><div class="gs_rs">Abstract Finding an image from a large set of images is an extremely difficult problem. One <br>solution is to label images manually, but this is very expensive, time consuming and <br>infeasible for many applications. Furthermore, the labeling process depends on the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12227511873793325518&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12">Cited by 6</a> <a href="/scholar?q=related:znlS3EPZsKkJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12227511873793325518&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'znlS3EPZsKkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://140.126.5.184/Jita_web/publish/vol4_num1/Natural%20Language%20based%20Fuzzy%20Queries%20and%20Fuzzy%20Mapping.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 140.126.5.184</span><span class="gs_ggsS">140.126.5.184 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://140.126.5.184/Jita_web/publish/vol4_num1/Natural%20Language%20based%20Fuzzy%20Queries%20and%20Fuzzy%20Mapping.pdf" class=yC5>Natural language based fuzzy queries and fuzzy mapping of feature database for image retrieval</a></h3><div class="gs_a"><a href="/citations?user=S9PFkO8AAAAJ&amp;hl=en&amp;oi=sra">S Kulkarni</a> - Journal of Information Technology and Applications, 2010 - 140.126.5.184</div><div class="gs_rs">One of the most common techniques for adding the images into a database is to store <br>images together with some descriptive text or keywords assigned by human operators. <br>These text or keywords are developed based on most prominent feature of an image. For <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10408701560854963497&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12">Cited by 3</a> <a href="/scholar?q=related:KWXQA-wic5AJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'KWXQA-wic5AJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md4', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md4" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:KWXQA-wic5AJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://researchonline.ballarat.edu.au:8080/vital/access/services/Download/vital:3590/SOURCE1" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ballarat.edu.au</span><span class="gs_ggsS">ballarat.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4496870" class=yC7>Human Perception based Image Retrieval using Emergence Index and Fuzzy Similarity Measure</a></h3><div class="gs_a">S Deb, <a href="/citations?user=S9PFkO8AAAAJ&amp;hl=en&amp;oi=sra">S Kulkarni</a> - &hellip;  and Information, 2007. ISSNIP 2007. 3rd  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The main concern dealing with content-based image retrieval (CBIR) is to bridge <br>the semantic gap. The high level query posed by the user and low level features extracted <br>by the machine illustrates the problem of semantic gap. To solve the problem of semantic <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14503471145840987193&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12">Cited by 1</a> <a href="/scholar?q=related:Ocz6GSquRskJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14503471145840987193&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'Ocz6GSquRskJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/B25V45313M7L6756.pdf" class=yC9>A multimedia retrieval framework based on automatic graded relevance judgments</a></h3><div class="gs_a"><a href="/citations?user=s4oWIYgAAAAJ&amp;hl=en&amp;oi=sra">M Redi</a>, B Merialdo - Advances in Multimedia Modeling, 2012 - Springer</div><div class="gs_rs">Traditional Content Based Multimedia Retrieval (CBMR) systems measure the relevance of <br>visual samples using a binary scale (Relevant/Non Relevant). However, a picture can be <br>relevant to a semantic category with different degrees, depending on the way such <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4735741410108444102&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12">Cited by 2</a> <a href="/scholar?q=related:xg2fsbi7uEEJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4735741410108444102&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'xg2fsbi7uEEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://mrim.imag.fr/georges.quenot/articles/trec04.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from imag.fr</span><span class="gs_ggsS">imag.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://mrim.imag.fr/georges.quenot/articles/trec04.pdf" class=yCA>CLIPS-LIS-LSR-LABRI experiments at TRECVID 2004</a></h3><div class="gs_a">GM QuÅenot, D Moraru, S Ayache, M Charhad&hellip; - mrim.imag.fr</div><div class="gs_rs">Abstract This paper presents the systems used by CLIPS-IMAG and its partners, LSR-IMAG, <br>LIS and LABRI laboratories, to perform the tasks proposed in the TRECVID 2004 workshop. <br>SBD was performed using a system based on image difference with motion compensation <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:MiLoLGk0hkMJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4865634073750020658&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'MiLoLGk0hkMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md7', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md7" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:MiLoLGk0hkMJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://lib.semi.ac.cn:8080/tsh/dzzy/wsqk/spie/vol6623/66230u.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from semi.ac.cn</span><span class="gs_ggsS">semi.ac.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://lib.semi.ac.cn:8080/tsh/dzzy/wsqk/spie/vol6623/66230u.pdf" class=yCC>Research on Methodology of Image Semantic Understanding</a></h3><div class="gs_a">YAO Mina, ZHU Ronga, Y Zhena - Proc. of SPIE Vol - lib.semi.ac.cn</div><div class="gs_rs">ABSTRACT To solve the âsemantic gapâ problem, image semantic understanding is the key <br>technique. In this paper, firstly analyzes the current situation of image semantic <br>understanding research, which includes some methods of image semantic representation <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:MBdXMrOU6KsJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12387314272447174448&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'MBdXMrOU6KsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md8', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md8" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:MBdXMrOU6KsJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6252587" class=yCE>Hybrid technique for colour image classification and efficient retrieval based on fuzzy logic and neural networks</a></h3><div class="gs_a">R Fernando, <a href="/citations?user=S9PFkO8AAAAJ&amp;hl=en&amp;oi=sra">S Kulkarni</a> - Neural Networks (IJCNN), The 2012  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Developments in the technology and the Internet have led to increase in number of <br>digital images and videos. Thousands of images are added to WWW every day. To retrieve <br>the specific images efficiently from database or from Internet is becoming a challenge now <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:TI2ymFFbgF8J:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'TI2ymFFbgF8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://www.arocmag.com/ch/reader/create_pdf.aspx?file_no=200904007&amp;flag=1&amp;journal_id=arocmag" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arocmag.com</span><span class="gs_ggsS">arocmag.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.arocmag.com/ch/reader/create_pdf.aspx?file_no=200904007&amp;flag=1&amp;journal_id=arocmag" class=yCF>åºäºè¯­ä¹ä¿¡æ¯çå¾åçè§£å³é®é®é¢ç ç©¶</a></h3><div class="gs_a">æ±è - è®¡ç®æºåºç¨ç ç©¶, 2009 - arocmag.com</div><div class="gs_rs">æè¦: ä¸ºäºç¼©ç­ä»äºä½å±è§è§ç¹å¾ä¸é«å±è¯­ä¹ç¹å¾ä¹é´çâè¯­ä¹é¸¿æ²â è·ç¦», <br>æåºäºæ¥éè§£å³çä¸¤å¤§å³é®é®é¢. é¦åæè¯­ä¹æ½è±¡ç¨åº¦ç»åºäºä¸ç§å¾åè¯­ä¹å±æ¬¡æ¨¡å, <br>çéåæä¸æ¯è¾äºåç§è¯­ä¹ä¿¡æ¯æåæ¹æ³çç¹ç¹åå­å¨é®é¢; ç¶åä»ç»äºå ç§å¸åçè¯­ä¹ç¹å¾<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:9SjgnHdzmVUJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6168088122230843637&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'9SjgnHdzmVUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md10', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md10" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:9SjgnHdzmVUJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://www.eshukan.com/upfiles/jwz/20120422135903591.pdf" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from eshukan.com</span><span class="gs_ggsS">eshukan.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.eshukan.com/upfiles/jwz/20120422135903591.pdf" class=yC11>æ¿ç­æè¿°è§èçç ç©¶ç»¼è¿°å¡</a></h3><div class="gs_a">è¡åï¼ çææ - è®¡ç®æºåºç¨ç ç©¶, 2009 - eshukan.com</div><div class="gs_rs">æè¦: å½åå¤æ¿ç­æè¿°è§èæ¹é¢çç ç©¶, ä¸»è¦æåä¸ªæµæ´¾: KAoS, Rei, Ponder åPRAL. <br>é¦åå¯¹è¿å ä¸ªæµæ´¾è¿è¡äºè¯¦ç»çä»ç», å©ç¨ä¸¾ä¾çæ¹å¼éè¿°å®ä»¬æ¿ç­çè¡¨ç¤ºæ¹æ³, æ¿ç­ç±»å, <br>åæ¶æ¦æ¬ä»ç»äºå®ä»¬çæ¿ç­å²çªåç°åè§£å³æ¹æ³. æç§æ¿ç­è¡¨è¾¾, æ¿ç­ç±»å, æ¿ç­å²çªè§£å³å<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:rqwIzyWXsKMJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11795093612726365358&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'rqwIzyWXsKMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md11', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md11" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:rqwIzyWXsKMJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
