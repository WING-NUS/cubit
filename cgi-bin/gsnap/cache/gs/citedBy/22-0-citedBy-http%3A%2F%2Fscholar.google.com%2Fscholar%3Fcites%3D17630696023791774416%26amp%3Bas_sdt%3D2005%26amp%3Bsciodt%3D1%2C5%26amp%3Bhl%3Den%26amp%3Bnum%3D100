Total results = 22
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://dblab.cs.nccu.edu.tw/presentation/980105/p447-knees-SigiR%2007%20Proceedings%20of%20the%2030th%20annual%20international%20ACM%20SigiR%20conference%20on%20Research%20and%20development%20in%20information%20retrieval.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nccu.edu.tw</span><span class="gs_ggsS">nccu.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1277741.1277818" class=yC0>A music search engine built upon audio-based and web-based similarity measures</a></h3><div class="gs_a"><a href="/citations?user=MtyaO2cAAAAJ&amp;hl=en&amp;oi=sra">P Knees</a>, T Pohle, <a href="/citations?user=TQR8qIEAAAAJ&amp;hl=en&amp;oi=sra">M Schedl</a>, <a href="/citations?user=dyGS5YYAAAAJ&amp;hl=en&amp;oi=sra">G Widmer</a> - Proceedings of the 30th annual  &hellip;, 2007 - dl.acm.org</div><div class="gs_rs">Abstract An approach is presented to automatically build a search engine for large-scale <br>music collections that can be queried through natural language. While existing approaches <br>depend on explicit manual annotations and meta-data assigned to the individual audio <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7890776677626521731&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 60</a> <a href="/scholar?q=related:g6jdx5SrgW0J:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7890776677626521731&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'g6jdx5SrgW0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.google.com/patents?hl=en&amp;lr=&amp;vid=USPAT7340455&amp;id=aJSpAAAAEBAJ&amp;oi=fnd&amp;printsec=abstract" class=yC2>Client-based generation of music playlists from a server-provided subset of music similarity vectors</a></h3><div class="gs_a">J Platt, E Renshaw - US Patent 7,340,455, 2008 - Google Patents</div><div class="gs_rs">A âMusic Mapperâ automatically constructs a set coordinate vectors for use in inferring <br>similarity between various pieces of music. In particular, given a music similarity graph <br>expressed as links between various artists, albums, songs, etc., the Music Mapper applies <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1498486971016938739&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 8</a> <a href="/scholar?q=related:8wQE-PWxyxQJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1498486971016938739&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'8wQE-PWxyxQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www.comp.nus.edu.sg/~yuy/mm09fp-yu.pdf" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1631320" class=yC3>Local summarization and multi-level LSH for retrieving multi-variant audio tracks</a></h3><div class="gs_a">Y Yu, M Crucianu, V Oria, <a href="/citations?user=gtglwgYAAAAJ&amp;hl=en&amp;oi=sra">L Chen</a> - Proceedings of the 17th ACM  &hellip;, 2009 - dl.acm.org</div><div class="gs_rs">Abstract In this paper we study the problem of detecting and grouping multi-variant audio <br>tracks in large audio datasets. To address this issue, a fast and reliable retrieval method is <br>necessary. But reliability requires elaborate representations of audio content, which <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16316125069897825666&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 7</a> <a href="/scholar?q=related:gv0a9k2FbuIJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16316125069897825666&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'gv0a9k2FbuIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="https://www.academypublisher.com/~academz3/ojs/index.php/jmm/article/viewFile/04013039/1259" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from academypublisher.com</span><span class="gs_ggsS">academypublisher.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="https://www.academypublisher.com/~academz3/ojs/index.php/jmm/article/view/04013039" class=yC5>Multi-model music content description and retrieval using IEEE 1599 XML standard</a></h3><div class="gs_a">A Pinto - Journal of Multimedia, 2009 - academypublisher.com</div><div class="gs_rs">Abstract The new format IEEE 1599 for music and audio content description defines a <br>standard for the representation of retrieval models within music and music/audio formats that <br>makes use of XML documents as content descriptors. In this article, it is described how <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2546109486065397015&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 6</a> <a href="/scholar?q=related:Fy0udBaZVSMJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2546109486065397015&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'Fy0udBaZVSMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.133.9375&amp;rep=rep1&amp;type=pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/QV6556N28262362J.pdf" class=yC7>Searching for Music Using Natural Language Queries and Relevance Feedback</a></h3><div class="gs_a"><a href="/citations?user=MtyaO2cAAAAJ&amp;hl=en&amp;oi=sra">P Knees</a>, <a href="/citations?user=dyGS5YYAAAAJ&amp;hl=en&amp;oi=sra">G Widmer</a> - Adaptive Multimedial Retrieval: Retrieval, User, and  &hellip;, 2008 - Springer</div><div class="gs_rs">We extend an approach to search inside large-scale music collections by enabling the user <br>to give feedback on the retrieved music pieces. In the original approach, a search engine <br>that can be queried through free-form natural language text is automatically built upon <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10493467192982822382&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 6</a> <a href="/scholar?q=related:7t30s9BIoJEJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10493467192982822382&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'7t30s9BIoJEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://159.226.100.14/bitstream/12502/328/1/%E8%BF%91%E5%87%A0%E5%B9%B4%E6%9D%A5%E5%9B%BD%E5%A4%96%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E6%A8%A1%E5%9E%8B%E7%A0%94%E7%A9%B6%E8%BF%9B%E5%B1%95(%E5%AD%99%E5%9D%A6%20%E5%91%A8%E9%9D%99%E6%80%A1).pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 159.226.100.14</span><span class="gs_ggsS">159.226.100.14 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/90041a/20083/26876167.0.html" class=yC9>è¿å å¹´æ¥å½å¤ä¿¡æ¯æ£ç´¢æ¨¡åç ç©¶è¿å±</a></h3><div class="gs_a">å­å¦ï¼ å¨éæ¡ - å¾ä¹¦é¦å»ºè®¾, 2008 - cqvip.com</div><div class="gs_rs">æè¦: ä¿¡æ¯æ£ç´¢æ¨¡åæ¯ä¿¡æ¯æ£ç´¢çæ ¸å¿. è¿å å¹´æ¥å½å¤å¯¹äºå¸å°æ¨¡åçç ç©¶ä¸»è¦è¡¨ç°å¨å¯¹å¸å°<br>æ¨¡åçæ¹è¿åå¯¹æ©å±å¸å°æ¨¡åçè¿ä¸æ­¥ä¼å. å¯¹åéç©ºé´æ¨¡åçç ç©¶, ä¸»è¦éä¸­å¨å¯¹åéç©ºé´<br>æ¨¡åçæ©å±ç ç©¶åå¯¹åéç©ºé´æ¨¡åçåºç¨æ¹é¢. æ¦çæ¨¡åçåå±ä¸»è¦éä¸­å¨ç»§ç»­å¯¹æ¦çæ¨¡å<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8188366386632450835&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 8</a> <a href="/scholar?q=related:E-P5RdjronEJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8188366386632450835&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'E-P5RdjronEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/Q8205NH13L1RH912.pdf" class=yCB>Effectiveness of signal segmentation for music content representation</a></h3><div class="gs_a">N Maddage, M Kankanhalli, <a href="/citations?user=z8_x7C8AAAAJ&amp;hl=en&amp;oi=sra">H Li</a> - Advances in Multimedia Modeling, 2008 - Springer</div><div class="gs_rs">In this paper we compare the effectiveness of rhythm based signal segmentation technique <br>with the traditional fixed length segmentation for music contents representation. We consider <br>vocal regions, instrumental regions and chords which represent the harmony as different <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10581131093821192891&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 3</a> <a href="/scholar?q=related:u3oNKau615IJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/59/2C/RN221721717.html?source=googlescholar" class="gs_nph" class=yCC>BL Direct</a> <a href="/scholar?cluster=10581131093821192891&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'u3oNKau615IJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://www.comp.nus.edu.sg/~yuy/IJSC_0302_P209.pdf" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.worldscientific.com/doi/abs/10.1142/S1793351X09000732" class=yCD>Multi-version music search using acoustic feature union and exact soft mapping</a></h3><div class="gs_a">Y Yu, JOE KAZUKI, V Oria, F Moerchen&hellip; - &hellip;  Journal of Semantic  &hellip;, 2009 - World Scientific</div><div class="gs_rs">Research on audio-based music retrieval has primarily concentrated on refining audio <br>features to improve search quality. However, much less work has been done on improving <br>the time efficiency of music audio searches. Representing music audio documents in an <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9092383457372538155&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 3</a> <a href="/scholar?q=related:KwVUupSiLn4J:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9092383457372538155&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'KwVUupSiLn4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0022000011001164" class=yCF>Semantic annotation of digital music</a></h3><div class="gs_a">F Rahman, J Siddiqi - Journal of Computer and System Sciences, 2011 - Elsevier</div><div class="gs_rs">In recent times, digital music items on the internet have been evolving in a vast information <br>space where consumers try to find/locate the piece of music of their choice by means of <br>search engines. The current trend of searching for music by means of music consumersÊ¼ <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14461845254462820080&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 2</a> <a href="/scholar?q=related:8M7sBKPLssgJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14461845254462820080&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'8M7sBKPLssgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://www.ntu.edu.sg/home/aseschng/SpeechTechWeb/members/Conformation_theses/WangLei_ConfirmationReport_Final.pdf" class=yC11><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntu.edu.sg</span><span class="gs_ggsS">ntu.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ntu.edu.sg/home/aseschng/SpeechTechWeb/members/Conformation_theses/WangLei_ConfirmationReport_Final.pdf" class=yC10>Unsupervised Techniques for Audio Content Analysis and Summarization</a></h3><div class="gs_a">W Lei - 2008 - ntu.edu.sg</div><div class="gs_rs">Abstract This thesis explores unsupervised algorithms for broadcast audio analysis and <br>summarization. For this work, the audio content analysis and summarization task will be to <br>extract semantic structures from audio databases and organize them into a hierarchical <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7070979980582480431&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 1</a> <a href="/scholar?q=related:L2qEJNQqIWIJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7070979980582480431&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'L2qEJNQqIWIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md9', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md9" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:L2qEJNQqIWIJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4811478" class=yC12>Content-based music retrieval with nonlinear feature space transformation using relevance feedback</a></h3><div class="gs_a">S Sakai, K Kameyama - &hellip; Man and Cybernetics, 2008. SMC 2008 &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In recent years, studies of similar music retrieval have been conducted actively. <br>However, because the similarity of music is based on subjective measures, the systems <br>need to be adaptive to user preference. In this paper, we propose an effective method for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4148896160275621445&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 1</a> <a href="/scholar?q=related:ReY1cxPXkzkJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'ReY1cxPXkzkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Finding Song Melody Similarities Using a DNA String Matching Algorithm</h3><div class="gs_a">JD Frey - 2008 - Kent State University</div><div class="gs_fl"><a href="/scholar?cites=7649735878998872942&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 1</a> <a href="/scholar?q=related:btNJfUBSKWoJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7649735878998872942&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'btNJfUBSKWoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md11', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md11" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:btNJfUBSKWoJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=2562952860425959605&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://www3.ntu.edu.sg/home5/WANG0161/WangLeiFiles/ICME07Wang.pdf" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntu.edu.sg</span><span class="gs_ggsS">ntu.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4284699" class=yC13>A vector-based approach to broadcast audio database indexing and retrieval</a></h3><div class="gs_a"><a href="/citations?user=HwIAqgIAAAAJ&amp;hl=en&amp;oi=sra">L Wang</a>, <a href="/citations?user=z8_x7C8AAAAJ&amp;hl=en&amp;oi=sra">H Li</a>, <a href="/citations?user=FJodrCcAAAAJ&amp;hl=en&amp;oi=sra">ES Chng</a> - Multimedia and Expo, 2007 IEEE  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper proposes a novel framework to index and retrieve audio content from <br>broadcast database that contains both speech and music. In this framework, we model the <br>acoustic events using hidden Markov models, which are then used to decode the audio <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6340676194927570589&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 1</a> <a href="/scholar?q=related:ne5uqmeb_lcJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6340676194927570589&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'ne5uqmeb_lcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1823753" class=yC15>Word level automatic alignment of music and lyrics using vocal synthesis</a></h3><div class="gs_a">NC Maddage, <a href="/citations?user=jnU62sUAAAAJ&amp;hl=en&amp;oi=sra">KC Sim</a>, <a href="/citations?user=z8_x7C8AAAAJ&amp;hl=en&amp;oi=sra">H Li</a> - ACM Transactions on Multimedia  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract We propose a signal-based approach instead of the commonly used model-based <br>approach, to automatically align vocal music with text lyrics at the word level. In this <br>approach, we use a text-to-speech system to synthesize the singing voice according to the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16739146216492474140&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 1</a> <a href="/scholar?q=related:HJ9bzctkTegJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16739146216492474140&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'HJ9bzctkTegJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5202589" class=yC16>Audio retrieval by segment-based manifold-ranking</a></h3><div class="gs_a">Y Peng, Z Yang, J Xiao - &hellip;  and Expo, 2009. ICME 2009. IEEE  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper proposes a new approach for the query-by-example audio retrieval, <br>named as segment-based manifold-ranking algorithm. Our approach adopts the audio <br>segment, instead of the whole audio, as the basic unit for the manifold-ranking process. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2060782852195983931&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 1</a> <a href="/scholar?q=related:O6Jb6BVfmRwJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2060782852195983931&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'O6Jb6BVfmRwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://www.adammikeal.com/courses/dh/sota/paper/dh-sota.pdf" class=yC18><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from adammikeal.com</span><span class="gs_ggsS">adammikeal.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.adammikeal.com/courses/dh/sota/paper/dh-sota.pdf" class=yC17>Supporting Music Interaction and Analysis with Computers</a></h3><div class="gs_a">A Mikeal - adammikeal.com</div><div class="gs_rs">ABSTRACT The relationship of computers to music is long and rich, dating back to the <br>earliest years of electronic music experimentation and Musique concrete. Working at Bell <br>Labs in 1957, Max Matthews wrote MUSIC, the first software application for creating sound <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:mktzK4W0ZloJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6514092395090627482&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'mktzK4W0ZloJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md15', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md15" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:mktzK4W0ZloJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/FT671731J0403662.pdf" class=yC19>A Survey of Music Structure Analysis Techniques for Music Applications</a></h3><div class="gs_a">N Maddage, <a href="/citations?user=z8_x7C8AAAAJ&amp;hl=en&amp;oi=sra">H Li</a>, M Kankanhalli - Recent Advances in Multimedia Signal  &hellip;, 2009 - Springer</div><div class="gs_rs">Music carries multilayer information which forms different structures. The information <br>embedded in the music can be categorized into time information, harmony/melody, music <br>regions, music similarities, song structures and music semantics. In this chapter, we first <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:3vo8SvZRZuUJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16529989600559299294&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'3vo8SvZRZuUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://www.ijcsi.org/papers/IJCSI-9-2-3-461-465.pdf" class=yC1B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ijcsi.org</span><span class="gs_ggsS">ijcsi.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ijcsi.org/papers/IJCSI-9-2-3-461-465.pdf" class=yC1A>Tag Based Audio Search Engine</a></h3><div class="gs_a">P Vellachu, S Abburu - 2012 - ijcsi.org</div><div class="gs_rs">Abstract The volume of the music database is increasing day by day. Getting the required <br>song as per the choice of the listener is a big challenge. Hence, it is really hard to manage <br>this huge quantity, in terms of searching, filtering, through the music database. It is <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Fl_RS-yqRuAJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16160792244726619926&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'Fl_RS-yqRuAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md17', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md17" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Fl_RS-yqRuAJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Rhythm Based Music Segmentation and Octave Scale Cepstral Features for Sung Language Recognition</h3><div class="gs_a">NC Maddage, <a href="/citations?user=z8_x7C8AAAAJ&amp;hl=en&amp;oi=sra">H Li</a> - Ninth Annual Conference of the International Speech  &hellip;, 2008</div><div class="gs_fl"><a href="/scholar?q=related:AyQEVurA-bEJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'AyQEVurA-bEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="http://www.thesai.org/downloads/Volume2No9/Paper%2011%20-%20Hybrid%20Query%20by%20Humming%20and%20Metadata%20Search%20System%20(HQMS)%20Analysis%20over%20Diverse%20Features.pdf" class=yC1D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from thesai.org</span><span class="gs_ggsS">thesai.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.thesai.org/downloads/Volume2No9/Paper%2011%20-%20Hybrid%20Query%20by%20Humming%20and%20Metadata%20Search%20System%20(HQMS)%20Analysis%20over%20Diverse%20Features.pdf" class=yC1C>Hybrid Query by Humming and Metadata Search System (HQMS) Analysis over Diverse Features</a></h3><div class="gs_a">NA Khan, <a href="/citations?user=O9uR-cUAAAAJ&amp;hl=en&amp;oi=sra">M Mushtaq</a> - International Journal, 2011 - thesai.org</div><div class="gs_rs">AbstractâRetrieval of music content over web is one of the toughest job tasks and found <br>some of the significant challenge. Song retrieval over web is the emerging problem from the <br>category of Music Information Retrieval. Several searching techniques related to metadata <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:kGm2sSnoCXEJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8145296666849077648&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'kGm2sSnoCXEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md19', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md19" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:kGm2sSnoCXEJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB20" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW20"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.63.6223&amp;rep=rep1&amp;type=pdf" class=yC1F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.63.6223&amp;rep=rep1&amp;type=pdf" class=yC1E>Effectiveness of Signal Segmentation for Music Content Representation</a></h3><div class="gs_a">NCMMS Kankanhalli, <a href="/citations?user=z8_x7C8AAAAJ&amp;hl=en&amp;oi=sra">H Li</a> - Citeseer</div><div class="gs_rs">Abstract. In this paper we compare the effectiveness of rhythm based signal segmentation <br>technique with the traditional fixed length segmentation for music contents representation. <br>We consider vocal regions, instrumental regions and chords which represent the harmony <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:tis58lxAeiEJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2412311318355323830&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'tis58lxAeiEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md20', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md20" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:tis58lxAeiEJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2043615" class=yC20>Beat space segmentation and octave scale cepstral feature for sung language recognition in pop music</a></h3><div class="gs_a">NC Maddage, <a href="/citations?user=z8_x7C8AAAAJ&amp;hl=en&amp;oi=sra">H Li</a> - ACM Transactions on Multimedia Computing,  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract Sung language recognition relies on both effective feature extraction and acoustic <br>modeling. In this paper, we study rhythm based music segmentation with the frame size <br>being the duration of the smallest note in the music, as opposed to fixed length <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:PDNw-UBaogIJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'PDNw-UBaogIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
