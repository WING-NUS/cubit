Total results = 11
<div class="gs_r" style="z-index:400"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/AM7558R84445558T.pdf" class=yC0>U-shaped, iterative, and iterative-with-counter learning</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, SE Moelius - Machine Learning, 2008 - Springer</div><div class="gs_rs">Abstract This paper solves an important problem left open in the literature by showing that U-<br>shapes are unnecessary in iterative learning from positive data. A U-shape occurs when a <br>learner first learns, then unlearns, and, finally, relearns, some target concept. Iterative <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3868849313996447409&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11">Cited by 13</a> <a href="/scholar?q=related:sZ5F-vPpsDUJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/14/04/RN231197058.html?source=googlescholar" class="gs_nph" class=yC1>BL Direct</a> <a href="/scholar?cluster=3868849313996447409&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'sZ5F-vPpsDUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0890540108000266" class=yC2>Learning in Friedberg numberings</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, F Stephan - Information and Computation, 2008 - Elsevier</div><div class="gs_rs">In this paper we consider learnability in some special numberings, such as Friedberg <br>numberings, which contain all the recursively enumerable languages, but have simpler <br>grammar equivalence problem compared to acceptable numberings. We show that every <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=243296875089145118&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11">Cited by 9</a> <a href="/scholar?q=related:Hq2mBjhdYAMJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=243296875089145118&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'Hq2mBjhdYAMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://colt2010.haifa.il.ibm.com/presentation/COLT10Talk-NUTechniques.pdf" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ibm.com</span><span class="gs_ggsS">ibm.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://colt2010.haifa.il.ibm.com/presentation/COLT10Talk-NUTechniques.pdf" class=yC3>Strongly non-U-shaped learning results by general techniques</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, T KÃ¶tzing - Proceedings of COLT (Conference on  &hellip;, 2010 - colt2010.haifa.il.ibm.com</div><div class="gs_rs">Let N={0, 1, 2,...}, the set of all natural numbers. A language is a set Lâ N. A presentation for <br>L is essentially an (infinite) listing T of all and only the elements of L. Such a T is called a text <br>for L. We numerically name programs or grammars in some standard general hypothesis <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16271890449647034039&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11">Cited by 9</a> <a href="/scholar?q=related:t15I2yZe0eEJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16271890449647034039&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'t15I2yZe0eEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md2', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md2" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:t15I2yZe0eEJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2613/1/TR11-07.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/D56708146217R601.pdf" class=yC5>Learning in Friedberg numberings</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, F Stephan - Algorithmic Learning Theory, 2007 - Springer</div><div class="gs_rs">In this paper we consider learnability in some special numberings, such as Friedberg <br>numberings, which contain all the recursively enumerable languages, but have simpler <br>grammar equivalence problem compared to acceptable numberings. We show that every <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12222878631934212208&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11">Cited by 6</a> <a href="/scholar?q=related:cLgmLVtjoKkJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/1F/45/RN216180780.html?source=googlescholar" class="gs_nph" class=yC7>BL Direct</a> <a href="/scholar?cluster=12222878631934212208&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 26 versions</a> <a onclick="return gs_ocit(event,'cLgmLVtjoKkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://cs5235.userapi.com/u133638729/docs/e02780dda47c/Yoav_Freund_Algorithmic_Learning_Theory_19_conf.pdf#page=431" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from userapi.com</span><span class="gs_ggsS">userapi.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/1N4582H1226U0066.pdf" class=yC8>Optimal language learning</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, S Moelius - Algorithmic Learning Theory, 2008 - Springer</div><div class="gs_rs">Gold&#39;s original paper on inductive inference introduced a notion of an optimal learner. <br>Intuitively, a learner identifies a class of objects optimally iff there is no other learner that: <br>requires as little of each presentation of each object in the class in order to identify that <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4359389727217022240&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11">Cited by 7</a> <a href="/scholar?q=related:IPVBINypfzwJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4359389727217022240&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'IPVBINypfzwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/WW86604W658G5101.pdf" class=yCA>Solutions to open questions for non-U-shaped learning with memory limitations</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, T KÃ¶tzing - Algorithmic Learning Theory, 2010 - Springer</div><div class="gs_rs">A U-shape occurs when a learner first learns, then unlearns, and, finally, relearns, some <br>target concept. Within the framework of Inductive Inference, previous results have shown, for <br>example, that U-shapes are unnecessary for explanatory learning, but are necessary for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12332842702605565065&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11">Cited by 5</a> <a href="/scholar?q=related:ibyShxgPJ6sJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12332842702605565065&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'ibyShxgPJ6sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1902/1/TR41-05.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/q3u47561122j7n59.pdf" class=yCB>Some recent results in U-shaped learning</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, F Stephan - Theory and Applications of Models of Computation, 2006 - Springer</div><div class="gs_rs">Abstract. U-shaped learning deals with a learner first having the correct hypothesis, then <br>changing it to an incorrect hypothesis and then relearning the correct hypothesis. This <br>phenomenon has been observed by psychologists in various studies of children <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12170106759171107131&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11">Cited by 3</a> <a href="/scholar?q=related:O2n5Ep7n5KgJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/0B/32/RN188840463.html?source=googlescholar" class="gs_nph" class=yCD>BL Direct</a> <a href="/scholar?cluster=12170106759171107131&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 25 versions</a> <a onclick="return gs_ocit(event,'O2n5Ep7n5KgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.145.8803&amp;rep=rep1&amp;type=pdf" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.145.8803&amp;rep=rep1&amp;type=pdf" class=yCE>Optimal language learning (expanded version)</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, SE Moelius - 2008 - Citeseer</div><div class="gs_rs">Abstract. Gold&#39;s original paper on inductive inference introduced a notion of an optimal <br>learner. Intuitively, a learner identifies a class of objects optimally iff there is no other learner <br>that: requires as little of each presentation of each object in the class in order to identify <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2574599541247357815&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11">Cited by 1</a> <a href="/scholar?q=related:d7PuVqTQuiMJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2574599541247357815&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'d7PuVqTQuiMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md7', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md7" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:d7PuVqTQuiMJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0890540111001088" class=yC10>Optimal language learning from positive data</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, SE Moelius - Information and Computation, 2011 - Elsevier</div><div class="gs_rs">GoldÊ¼s original paper on inductive inference introduced a notion of an optimal learner. <br>Intuitively, a learner identifies a class of objects optimally iff there is no other learner that: <br>requires as little of each presentation of each object in the class in order to identify that <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Lka8Q86r5ysJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3163686165639087662&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'Lka8Q86r5ysJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/812361171q2264pu.pdf" class=yC11>Resource Restricted Computability Theoretic Learning: Illustrative Topics and Problems</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a> - Theory of Computing Systems, 2009 - Springer</div><div class="gs_rs">Abstract Computability theoretic learning theory (machine inductive inference) typically <br>involves learning programs for languages or functions from a stream of complete data about <br>them and, importantly, allows mind changes as to conjectured programs. This theory takes <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:cNGIg7j_YKkJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12205036158119891312&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'cNGIg7j_YKkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://www.eecis.udel.edu/~case/papers/pr2.pdf" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from udel.edu</span><span class="gs_ggsS">udel.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.eecis.udel.edu/~case/papers/pr2.pdf" class=yC12>On the Necessity of U-Shaped Learning</a></h3><div class="gs_a">L Carlucci, <a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a> - eecis.udel.edu</div><div class="gs_rs">Abstract. A U-shaped curve in a cognitive-developmental trajectory refers to a three-step <br>process: good performance followed by bad performance followed by good performance <br>once again. U-shaped curves have been observed in a wide variety of cognitive-<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17336137048815070431&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'32wcjMtUlvAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md10', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md10" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
