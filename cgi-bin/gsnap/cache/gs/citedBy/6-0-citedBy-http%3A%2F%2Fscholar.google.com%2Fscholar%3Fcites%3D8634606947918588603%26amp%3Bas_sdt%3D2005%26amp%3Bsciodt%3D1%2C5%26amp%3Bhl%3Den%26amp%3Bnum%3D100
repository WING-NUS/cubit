Total results = 6
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://spiedigitallibrary.org/spiereviews/resource/1/spivj2/v1/i1/p018004_s1" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from spiedigitallibrary.org</span><span class="gs_ggsS">spiedigitallibrary.org <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[HTML]</span><span class="gs_ct2">[HTML]</span></span> <a href="http://spiedigitallibrary.org/spiereviews/resource/1/spivj2/v1/i1/p018004_s1" class=yC0>Video browsing interfaces and applications: a review</a></h3><div class="gs_a"><a href="/citations?user=GOIf9NIAAAAJ&amp;hl=en&amp;oi=sra">K Schoeffmann</a>, <a href="/citations?user=tiASHnwAAAAJ&amp;hl=en&amp;oi=sra">F Hopfgartner</a>, <a href="/citations?user=ZgWULzYAAAAJ&amp;hl=en&amp;oi=sra">O Marques</a>&hellip; - SPIE  &hellip;, 2010 - spiedigitallibrary.org</div><div class="gs_rs">We present a comprehensive review of the state of the art in video browsing and retrieval <br>systems, with special emphasis on interfaces and applications. There has been a significant <br>increase in activity (eg, storage, retrieval, and sharing) employing video data in the past <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16240610479951437381&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6">Cited by 16</a> <a href="/scholar?q=related:Rd79YC89YuEJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16240610479951437381&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'Rd79YC89YuEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md0', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md0" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Rd79YC89YuEJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://www.ee.columbia.edu/ln/dvmm/publications/08/mir2008_zavesky.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from columbia.edu</span><span class="gs_ggsS">columbia.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1460136" class=yC2>CuZero: embracing the frontier of interactive visual search for informed users</a></h3><div class="gs_a">E Zavesky, <a href="/citations?user=OMVTRscAAAAJ&amp;hl=en&amp;oi=sra">SF Chang</a> - Proceeding of the 1st ACM international  &hellip;, 2008 - dl.acm.org</div><div class="gs_rs">Abstract Users of most visual search systems suffer from two primary sources of frustration. <br>Before a search over this data is executed, a query must be formulated. Traditional keyword <br>search systems offer only passive, non-interactive input, which frustrates users that are <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17719139335607675463&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6">Cited by 10</a> <a href="/scholar?q=related:R-qLgFgH5_UJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17719139335607675463&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'R-qLgFgH5_UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://doras.dcu.ie/4584/1/camera-ready-fixed-copyright-civr2009_111.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from dcu.ie</span><span class="gs_ggsS">dcu.ie <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1646396.1646400" class=yC4>User variance and its impact on video retrieval benchmarking</a></h3><div class="gs_a">P Wilkins, <a href="/citations?user=1BxhcigAAAAJ&amp;hl=en&amp;oi=sra">R Troncy</a>, <a href="/citations?user=ZXIo4JAAAAAJ&amp;hl=en&amp;oi=sra">M Halvey</a>, D Byrne&hellip; - Proceedings of the  &hellip;, 2009 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we describe one of the largest multi-site interactive video retrieval <br>experiments conducted in a laboratory setting. Interactive video retrieval performance is <br>difficult to cross-compare as variables exist across users, interfaces and the underlying <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12005218464993286976&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6">Cited by 3</a> <a href="/scholar?q=related:QJviaJYam6YJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12005218464993286976&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'QJviaJYam6YJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://upcommons.upc.edu/e-prints/bitstream/2117/8755/7/2010-Giro-CIVR-PrePrint.pdf.txt" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[TXT]</span> from upc.edu</span><span class="gs_ggsS">upc.edu <span class=gs_ctg2>[TXT]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1816093" class=yC6>System architecture of a web service for Content-Based Image Retrieval</a></h3><div class="gs_a">X Giro-i-Nieto, C Ventura, <a href="/citations?user=VCBBx24AAAAJ&amp;hl=en&amp;oi=sra">J Pont-Tuset</a>&hellip; - Proceedings of the  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract This paper presents the system architecture of a Content-Based Image Retrieval <br>system implemented as a web service. The proposed solution is composed of two parts, a <br>client running a graphical user interface for query formulation and a server where the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4556522505111364353&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6">Cited by 2</a> <a href="/scholar?q=related:AWM8sBMFPD8J:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4556522505111364353&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'AWM8sBMFPD8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2345542" class=yC8>Feature based retrieval for animation video</a></h3><div class="gs_a">P Kosamkar, M Potey - Proceedings of the International Conference on  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract Numerous researches have been conducted for content based representation, <br>analysis and retrieval but mainly for the professionally edited videos such as news, &amp; sports <br>videos not on animation video. The objective is to adapt existing image based information <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ydVEL3kFP5sJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'ydVEL3kFP5sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://ojs.academypublisher.com/index.php/jsw/article/viewFile/060611541162/3198" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from academypublisher.com</span><span class="gs_ggsS">academypublisher.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ojs.academypublisher.com/index.php/jsw/article/view/4194" class=yC9>Research on Uncertainty of audio and Video Information Hiding Based on Semantic and Statistical Moment</a></h3><div class="gs_a">J Zhang - Journal of Software, 2011 - ojs.academypublisher.com</div><div class="gs_rs">Abstract nowadays, audio and video media data is already facilitates generation, <br>transmission, storage and circulation on the global scale. Audio and video data is <br>geometrically fast as the rate of growth, the video data processing and analysis have <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:lYcJZb5-DpEJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10452431141377509269&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'lYcJZb5-DpEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
