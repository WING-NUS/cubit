Total results = 32
<div class="gs_r" style="z-index:400"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6212356" class=yC0>Visual-Textual Joint Relevance Learning for Tag-Based Social Image Search</a></h3><div class="gs_a">Y Gao, <a href="/citations?user=rHagaaIAAAAJ&amp;hl=en&amp;oi=sra">M Wang</a>, ZJ Zha, <a href="/citations?user=d3h-zScAAAAJ&amp;hl=en&amp;oi=sra">J Shen</a>, X Li, X Wu - 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract With the popularity of social media websites, extensive research efforts have been <br>dedicated to tag-based social image search. Both visual information and tags have been <br>investigated in the research field. However, most existing methods use tags and visual <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3875216273605194683&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=32">Cited by 4</a> <a href="/scholar?q=related:u_MMSKuIxzUJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3875216273605194683&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'u_MMSKuIxzUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5957302" class=yC1>Object retrieval using visual query context</a></h3><div class="gs_a"><a href="/citations?user=cvgKxDQAAAAJ&amp;hl=en&amp;oi=sra">L Yang</a>, <a href="/citations?user=gsTrHoMAAAAJ&amp;hl=en&amp;oi=sra">B Geng</a>, <a href="/citations?user=KzJWndQAAAAJ&amp;hl=en&amp;oi=sra">Y Cai</a>, <a href="/citations?user=EoYbukgAAAAJ&amp;hl=en&amp;oi=sra">A Hanjalic</a>&hellip; - &hellip; , IEEE Transactions on, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Object retrieval aims at retrieving images containing objects similar to the query <br>object captured in the region of interest (ROI) of the query image. Boosted by the invention <br>and wide popularity of SIFT image features and bag-of-visual-words image representation<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3584466087704044943&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=32">Cited by 3</a> <a href="/scholar?q=related:j6UIW-qUvjEJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3584466087704044943&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'j6UIW-qUvjEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2396424" class=yC2>Intent and its discontents: the user at the wheel of the online video search engine</a></h3><div class="gs_a"><a href="/citations?user=EoYbukgAAAAJ&amp;hl=en&amp;oi=sra">A Hanjalic</a>, <a href="/citations?user=Fhmp7lQAAAAJ&amp;hl=en&amp;oi=sra">C Kofler</a>, <a href="/citations?user=eIiM958AAAAJ&amp;hl=en&amp;oi=sra">M Larson</a> - Proceedings of the 20th ACM  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract We embrace the position of the user in the driver&#39;s seat of the video search engine <br>by proposing a principled framework for multimedia retrieval that moves beyond what users <br>are searching for also to encompass why they search. This&#39; why&#39;is understood as the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15326088102097729723&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=32">Cited by 2</a> <a onclick="return gs_ocit(event,'uzjgge0zsdQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://www2012.org/proceedings/proceedings/p439.pdf" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from www2012.org</span><span class="gs_ggsS">www2012.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2187896" class=yC3>Leveraging user comments for aesthetic aware image search reranking</a></h3><div class="gs_a"><a href="/citations?user=n6SjPicAAAAJ&amp;hl=en&amp;oi=sra">J San Pedro</a>, <a href="/citations?user=mDNhPjAAAAAJ&amp;hl=en&amp;oi=sra">T Yeh</a>, N Oliver - &hellip;  of the 21st international conference on  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract The increasing number of images available online has created a growing need for <br>efficient ways to search for relevant content. Text-based query search is the most common <br>approach to retrieve images from the Web. In this approach, the similarity between the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13071435724180160819&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=32">Cited by 2</a> <a href="/scholar?q=related:MwEcJIkRZ7UJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13071435724180160819&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'MwEcJIkRZ7UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://ict.usc.edu/pubs/Collecting%20Relevance%20Feedback%20on%20Titles%20and%20Photographs%20in%20Weblog%20Posts.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from usc.edu</span><span class="gs_ggsS">usc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2166993" class=yC5>Collecting relevance feedback on titles and photographs in weblog posts</a></h3><div class="gs_a">A Campbell, C Wienberg, A Gordon - Proceedings of the 2012 ACM  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract We investigate new interfaces that allow users to specify topics of interest in <br>streams of weblog stories by providing relevance feedback to a search algorithm. Noting that <br>weblog stories often contain photographs taken by the blogger during the course of the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5557518031015946516&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=32">Cited by 2</a> <a href="/scholar?q=related:FKmIRzRFIE0J:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5557518031015946516&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'FKmIRzRFIE0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/J283672740V22214.pdf" class=yC7>Video Scene Analysis: A Machine Learning Perspective</a></h3><div class="gs_a">W Gao, Y Tian, L Duan, J Li, Y Li - Video Segmentation and Its Applications, 2011 - Springer</div><div class="gs_rs">With the increasing proliferation of digital video contents, learning-based video scene <br>analysis has proven to be an effective methodology for improving the access and retrieval of <br>large video collections. This chapter is devoted to present a survey and tutorial on the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10604264458586599537&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=32">Cited by 1</a> <a href="/scholar?q=related:cbBaXlfqKZMJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10604264458586599537&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'cbBaXlfqKZMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2382336.2382364" class=yC8>Chat with illustration: A chat system with visual aids</a></h3><div class="gs_a">Y Jiang, J Liu, Z Li, C Xu, H Lu - &hellip;  of the 4th International Conference on  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract Traditional instant messaging service mainly transfers textual message, while the <br>visual message is ignored to a great extent. In this paper, we propose a novel instant <br>messaging scheme with visual aids named Chat with Illustration (CWI), which presents <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17482999641366356404&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=32">Cited by 1</a> <a onclick="return gs_ocit(event,'tGHsf4sXoPIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6115976" class=yC9>Inferring users&#39; image-search goals with pseudo-images</a></h3><div class="gs_a">Z Lu, <a href="/citations?user=yDEavdMAAAAJ&amp;hl=en&amp;oi=sra">X Yang</a>, <a href="/citations?user=S9g81n8AAAAJ&amp;hl=en&amp;oi=sra">W Lin</a>, X Chen&hellip; - &hellip;  and Image Processing ( &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The analysis of user search goals for a query can be very useful in improving <br>search engine relevance and user experience. Although the research on inferring user <br>goals or intents for text search has received much attention, little has been proposed for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=53482375402677059&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=32">Cited by 1</a> <a href="/scholar?q=related:Q-Oe4-8BvgAJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Q-Oe4-8BvgAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://people.ict.usc.edu/~gordon/publications/CIKM12.PDF" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from usc.edu</span><span class="gs_ggsS">usc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://people.ict.usc.edu/~gordon/publications/CIKM12.PDF" class=yCA>PhotoFall: Discovering Weblog Stories Through Photographs</a></h3><div class="gs_a">C Wienberg, AS Gordon - 2012 - people.ict.usc.edu</div><div class="gs_rs">ABSTRACT An effective means of retrieving relevant photographs from the web is to search <br>for terms that would likely appear in the surrounding text in multimedia documents. In this <br>paper, we investigate the complementary search strategy, where relevant multimedia <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:MJ6YAaioPKcJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12050692142471355952&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'MJ6YAaioPKcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md8', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md8" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:MJ6YAaioPKcJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://luzheng.org/papers/VideoAder_hu_icimcs2011.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from luzheng.org</span><span class="gs_ggsS">luzheng.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2043683" class=yCC>Videoader: a video advertising system based on intelligent analysis of visual content</a></h3><div class="gs_a">J Hu, G Li, <a href="/citations?user=Qz_zAEUAAAAJ&amp;hl=en&amp;oi=sra">Z Lu</a>, J Xiao, <a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a> - Proceedings of the Third International  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract Recent years have witnessed the prevalence of context based video advertisement. <br>However, those advertisement systems solely take the metadata into account, such as titles, <br>descriptions and tags. In this paper, we present a novel video advertising system called <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:MNCeA-0fUWEJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7012421197621022768&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'MNCeA-0fUWEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2396335" class=yCE>Attribute-assisted reranking for web image retrieval</a></h3><div class="gs_a"><a href="/citations?user=qioooCAAAAAJ&amp;hl=en&amp;oi=sra">J Cai</a>, ZJ Zha, W Zhou, Q Tian - &hellip;  of the 20th ACM international conference &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract Image search reranking is an effective approach to refine the text-based image <br>search result. Most existing reranking approaches are based on low-level visual features. In <br>this paper, we propose to exploit semantic attributes for image search reranking. Based on <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'ERzpCzIw_OQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2382382" class=yCF>Personalized video recommendation based on viewing history with the study on YouTube</a></h3><div class="gs_a">X Zhao, H Luan, <a href="/citations?user=qioooCAAAAAJ&amp;hl=en&amp;oi=sra">J Cai</a>, J Yuan, X Chen&hellip; - Proceedings of the 4th  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract With internet delivery of video content surging to an un-precedented level, video <br>recommendation has become an important approach for helping people access interesting <br>videos. In this paper, we propose a novel approach to integrate viewing history for <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'cw91DuwhwUYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2240141" class=yC10>A unified context model for web image retrieval</a></h3><div class="gs_a"><a href="/citations?user=cvgKxDQAAAAJ&amp;hl=en&amp;oi=sra">L Yang</a>, <a href="/citations?user=gsTrHoMAAAAJ&amp;hl=en&amp;oi=sra">B Geng</a>, <a href="/citations?user=EoYbukgAAAAJ&amp;hl=en&amp;oi=sra">A Hanjalic</a>, <a href="/citations?user=6G-l4o0AAAAJ&amp;hl=en&amp;oi=sra">XS Hua</a> - ACM Transactions on Multimedia  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract Content-based web image retrieval based on the query-by-example (QBE) principle <br>remains a challenging problem due to the semantic gap as well as the gap between a user&#39;s <br>intent and the representativeness of a typical image query. In this article, we propose to <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:StexGGOCaHsJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'StexGGOCaHsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0925231212009046" class=yC11>Richang Hong, Linxie Tang, Jun Hu, Guanda Li, Jiang-Guo Jiang</a></h3><div class="gs_a"><a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, L Tang, J Hu, G Li, JG Jiang - Neurocomputing, 2013 - Elsevier</div><div class="gs_rs">Abstract We have witnessed the booming of contextual video advertising recent years. <br>However, those advertisement systems solely take the metadata into account, such as titles, <br>descriptions and tags. This kind of text-based contextual advertising reveals a number of <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'qWujGb64isAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://www-sop.inria.fr/members/Alexis.Joly/HamzaouiThese.pdf" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from inria.fr</span><span class="gs_ggsS">inria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www-sop.inria.fr/members/Alexis.Joly/HamzaouiThese.pdf" class=yC12>PHD THESIS Shared-Neighbours methods for visual content structuring and mining</a></h3><div class="gs_a">A HAMZAOUI - 2012 - www-sop.inria.fr</div><div class="gs_rs">Abstract Unsupervised data clustering remains a crucial step in many recent multimedia <br>retrieval approaches, including for instance, visual objects discovery, multimedia documents <br>suggestion or event&#39;s detection across different media. However, the performance and <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'D2yIG03C35oJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md14', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md14" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:D2yIG03C35oJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://www.commit-nl.nl/sites/default/files/675955_survey_mm-search-optimization.pdf" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from commit-nl.nl</span><span class="gs_ggsS">commit-nl.nl <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.commit-nl.nl/sites/default/files/675955_survey_mm-search-optimization.pdf" class=yC14>A Survey on Multimedia Search Optimization based on Multimodal Information Resources</a></h3><div class="gs_a"><a href="/citations?user=Fhmp7lQAAAAJ&amp;hl=en&amp;oi=sra">C Kofler</a>, M Larson, <a href="/citations?user=EoYbukgAAAAJ&amp;hl=en&amp;oi=sra">A Hanjalic</a> - commit-nl.nl</div><div class="gs_rs">Abstract. This survey constitutes a literature study that overviews the state-of-the-art in <br>multimedia search. Techniques that are covered include multimodal re-ranking, pseudo-<br>relevance feedback, query classification and query suggestion. Discussion of the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:1DJ7H6YdmWsJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'1DJ7H6YdmWsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md15', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md15" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:1DJ7H6YdmWsJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/G03281H8435RX780.pdf" class=yC16>Image Search: A Story of One User Interface</a></h3><div class="gs_a">Å  ZehnalovÃ¡, Z HorÃ¡k, M Kudelka - &hellip;  of the Third International Conference on  &hellip; - Springer</div><div class="gs_rs">With the rapid development of information technology, the emphasis on the quality of user <br>interfaces has been increasing recently, also with regard to mobile platforms, accessibility <br>etc. In this paper we focus on engaging more interactive ways to image search. While <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:DIWzUJfQcOwJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'DIWzUJfQcOwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://www2012.wwwconference.org/proceedings/companion/p799.pdf" class=yC18><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from wwwconference.org</span><span class="gs_ggsS">wwwconference.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2188203" class=yC17>QAque: faceted query expansion techniques for exploratory search using community QA resources</a></h3><div class="gs_a">A Otsuka, Y Seki, N Kando, T Satoh - Proceedings of the 21st  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract Recently, query suggestions have become quite useful in web searches. Most <br>provide additional and correct terms based on the initial query entered by users. However, <br>query suggestions often recommend queries that differ from the user&#39;s search intentions <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:bSU-WW5OqmUJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7325753979722147181&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'bSU-WW5OqmUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6362232" class=yC19>Beyond Text QA: Multimedia Answer Generation by Harvesting Web Information</a></h3><div class="gs_a">L Nie, M Wang, Y Gao, ZJ Zha, TS Chua - 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Community question answering (cQA) services have gained popularity over the <br>past years. It not only allows community members to post and answer questions but also <br>enables general users to seek information from a comprehensive set of well-answered <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'RkwabUTK41cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/tour-pattern-TIST-final.pdf" class=yC1B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2168770" class=yC1A>Mining Travel Patterns from Geotagged Photos</a></h3><div class="gs_a">YT Zheng, ZJ Zha, TS Chua - ACM Transactions on Intelligent Systems  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract Recently, the phenomenal advent of photo-sharing services, such as Flickr and <br>Panoramio, have led to volumous community-contributed photos with text tags, timestamps, <br>and geographic references on the Internet. The photos, together with their time-and geo-<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:KJZndCcP9wwJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=934232109833754152&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'KJZndCcP9wwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2382344" class=yC1C>Training support vector machine through redundant data reduction</a></h3><div class="gs_a">XJ Shen, HX Wu, Q Zhu - &hellip;  of the 4th International Conference on Internet  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract Support Vector Machine (SVM) training in a large data set involves a huge <br>optimization problem to make SVM impractical even for a moderate data set. In this paper, <br>we propose a method to speed SVM training by removing redundant data in the training <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'fCWFi3eNYW4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="http://mvillegas.info/pub/Leiva11_ICMI_QueryRefinement.pdf" class=yC1E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mvillegas.info</span><span class="gs_ggsS">mvillegas.info <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2070539" class=yC1D>Query refinement suggestion in multimodal image retrieval with relevance feedback</a></h3><div class="gs_a"><a href="/citations?user=N0E7MlUAAAAJ&amp;hl=en&amp;oi=sra">LA Leiva</a>, <a href="/citations?user=18e7rpsAAAAJ&amp;hl=en&amp;oi=sra">M Villegas</a>, <a href="/citations?user=I815O2UAAAAJ&amp;hl=en&amp;oi=sra">R Paredes</a> - &hellip; of the 13th international conference on &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract In the literature, it has been shown that relevance feedback is a good strategy for <br>the system to interact with the user and provide better results in a content-based image <br>retrieval (CBIR) system. On the other hand, there are many retrieval systems which <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5572812788679938878&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=32">Cited by 1</a> <a href="/scholar?q=related:PpMFjbSbVk0J:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5572812788679938878&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'PpMFjbSbVk0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0165168412003209" class=yC1F>Marginalized multi-layer multi-instance kernel for video concept detection</a></h3><div class="gs_a">ZJ Zha, T Mei, <a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, Z Gu - Signal Processing, 2012 - Elsevier</div><div class="gs_rs">Abstract Video concept detection has been extensively studied in recent years. Most of <br>existing video concept detection approaches have treated video as a flat data sequence. <br>However, video is essentially a kind of media with hierarchical structure, including multiple <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:n1cAnKhSEEoJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'n1cAnKhSEEoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6410834" class=yC20>Inferring user image-search goals by mining query logs with semi-supervised spectral clustering</a></h3><div class="gs_a">Z Lu, <a href="/citations?user=yDEavdMAAAAJ&amp;hl=en&amp;oi=sra">X Yang</a>, <a href="/citations?user=S9g81n8AAAAJ&amp;hl=en&amp;oi=sra">W Lin</a>, X Chen&hellip; - &hellip;  and Image Processing ( &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Inferring user search goals for a query can be very useful in improving search <br>engine relevance and user experience. Although the research on analyzing user goals or <br>intents for text search has received much attention, little has been proposed for image <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'D2wVn9NQHL4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6380623" class=yC21>Video-to-Shot Tag Propagation by Graph Sparse Group Lasso</a></h3><div class="gs_a">X Zhu, Z Huang, J Cui, <a href="/citations?user=krryaDkAAAAJ&amp;hl=en&amp;oi=sra">H Shen</a> - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Traditional approaches to video tagging are designed to propagate tags at the <br>same level, such as generating tags for the test video when the training videos are <br>associated with the tags at the video-level or assigning tags to the test shot when given a <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'0c5mnwWSqk0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB25" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW25"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/zhangAF.pdf" class=yC23><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/zhangAF.pdf" class=yC22>Attribute Feedback</a></h3><div class="gs_a">H Zhang, ZJ Zha, <a href="/citations?user=DNuiPHwAAAAJ&amp;hl=en&amp;oi=sra">S Yan</a>, J Bian, TS Chua - 2012 - 137.132.145.151</div><div class="gs_rs">ABSTRACT This work presents a new interactive Content Based Image Retrieval (CBIR) <br>scheme, termed Attribute Feedback (AF). Unlike traditional relevance feedback purely <br>founded on low-level visual features, the Attribute Feedback system shapes users&#39; <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:uiwKptSKrpUJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'uiwKptSKrpUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md25', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md25" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:uiwKptSKrpUJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6360132" class=yC24>Associating and Recalling News Events with Visual Suggestions</a></h3><div class="gs_a">H Wang, WG Teng - ieeexplore.ieee.org</div><div class="gs_rs">AbstractâAs more and more information including news articles, personal stories and so on <br>gathered on the Internet, how a user perceives and memorizes every details of what he or <br>she reads is of significant challenge. In view of this information overload problem, recent <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'8ZiKqCPFqRcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB27" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW27"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/msp123-bian.pdf" class=yC26><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/msp123-bian.pdf" class=yC25>Visual Query Attributes Suggestion</a></h3><div class="gs_a">J Bian, ZJ Zha, H Zhang, Q Tian, TS Chua - 2012 - 137.132.145.151</div><div class="gs_rs">ABSTRACT Query suggestion is an effective solution to help users deliver their search <br>intent. While many query suggestion approaches have been proposed for test-based image <br>retrieval with query-by-keywords, query suggestion for content-based image retrieval (<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:k27VrRGwV90J:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'k27VrRGwV90J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md27', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md27" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:k27VrRGwV90J:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB28" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW28"><a href="http://journal.univagora.ro/download/pdf/613.pdf" class=yC28><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from univagora.ro</span><span class="gs_ggsS">univagora.ro <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://journal.univagora.ro/download/pdf/613.pdf" class=yC27>The Role of Visual Rhetoric in Semantic Multimedia: Strategies for Decision Making in Times of Crisis</a></h3><div class="gs_a"><a href="/citations?user=i4pkJB4AAAAJ&amp;hl=en&amp;oi=sra">AMP Brasoveanu</a>, <a href="/citations?user=lyZnORoAAAAJ&amp;hl=en&amp;oi=sra">I Dzitac</a> - 2006 - journal.univagora.ro</div><div class="gs_rs">Abstract: As semantic multimedia is approaching mainstream, even the great improvements <br>that can be seen in its classic schools, like the data mining inspired Information Retrieval <br>based on metadata analysis, or Computer Vision, might not be enough. We identify a new <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:GUsSyZY5eXIJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8248687512287071001&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'GUsSyZY5eXIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md28', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md28" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:GUsSyZY5eXIJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5999642" class=yC29>Multimedia Question Answering</a></h3><div class="gs_a"><a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, M Wang, G Li, Z Zha, T Chua - 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Recent explosive growth of multimedia content on the Web has led to the popularity <br>and proliferation of search technology. However, faced the vast quantity of information <br>content returned by search engines, users are often bewildered and have to painstakingly <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3052222141799642610&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=32">Cited by 1</a> <a href="/scholar?q=related:8rWM2d2rWyoJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3052222141799642610&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'8rWM2d2rWyoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB30" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW30"><a href="http://people.cs.clemson.edu/~jzwang/1301863/mm2012/p319-kofler.pdf" class=yC2B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from clemson.edu</span><span class="gs_ggsS">clemson.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://people.cs.clemson.edu/~jzwang/1301863/mm2012/p319-kofler.pdf" class=yC2A>When Video Search Goes Wrong: Predicting Query Failure Using Search Engine Logs and Visual Search Results</a></h3><div class="gs_a"><a href="/citations?user=Fhmp7lQAAAAJ&amp;hl=en&amp;oi=sra">C Kofler</a>, <a href="/citations?user=cvgKxDQAAAAJ&amp;hl=en&amp;oi=sra">L Yang</a>, <a href="/citations?user=eIiM958AAAAJ&amp;hl=en&amp;oi=sra">M Larson</a>, <a href="/citations?user=7Yq4wf4AAAAJ&amp;hl=en&amp;oi=sra">T Mei</a>&hellip; - Proceedings of the  &hellip;, 2012 - people.cs.clemson.edu</div><div class="gs_rs">ABSTRACT The recent increase in the volume and variety of video content available online <br>presents growing challenges for video search. Users face increased difficulty in formulating <br>effective queries and search engines must deploy highly effective algorithms to provide <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'S_qh-WwURJ4J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md30', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md30" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:S_qh-WwURJ4J:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2043686" class=yC2C>The effects of heterogeneous information combination on large scale social image search</a></h3><div class="gs_a">Z Cheng, J Ren, <a href="/citations?user=d3h-zScAAAAJ&amp;hl=en&amp;oi=sra">J Shen</a>, <a href="/citations?user=6Il_ZIoAAAAJ&amp;hl=en&amp;oi=sra">H Miao</a> - Proceedings of the Third International  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract This paper documents a comprehensive empirical study of the effects of <br>heterogeneous information combination on large scale social image search. Our goal is to <br>investigate how various kinds of information source can contribute the improvement of the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:hB4F_FDw2AAJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=61062825585745540&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'hB4F_FDw2AAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
