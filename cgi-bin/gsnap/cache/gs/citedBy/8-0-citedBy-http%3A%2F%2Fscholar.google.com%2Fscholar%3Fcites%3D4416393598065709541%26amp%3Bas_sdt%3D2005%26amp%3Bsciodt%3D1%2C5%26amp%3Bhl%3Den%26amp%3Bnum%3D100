Total results = 8
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://vireo.cs.cityu.edu.hk/papers/beyond%20search%20event%20driven%20summarization%20for%20web%20videos_acmtmm10.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cityu.edu.hk</span><span class="gs_ggsS">cityu.edu.hk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2043613" class=yC0>Beyond search: Event-driven summarization for web videos</a></h3><div class="gs_a"><a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, <a href="/citations?user=ByBLlEwAAAAJ&amp;hl=en&amp;oi=sra">J Tang</a>, HK Tan, <a href="/citations?user=jk5DWVMAAAAJ&amp;hl=en&amp;oi=sra">CW Ngo</a>, <a href="/citations?user=DNuiPHwAAAAJ&amp;hl=en&amp;oi=sra">S Yan</a>&hellip; - ACM Transactions on  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract The explosive growth of Web videos brings out the challenge of how to efficiently <br>browse hundreds or even thousands of videos at a glance. Given an event-driven query, <br>social media Web sites usually return a large number of videos that are diverse and noisy <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4403112343352155411&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 13</a> <a href="/scholar?q=related:E52k-1j_Gj0J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4403112343352155411&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'E52k-1j_Gj0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5673752" class=yC2>Multi-modality transfer based on multi-graph optimization for domain adaptive video concept annotation</a></h3><div class="gs_a">S Xu, S Tang, Y Zhang, J Li - Image and Video Technology ( &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Multi-modality, the unique and important property of video data, is typically ignored <br>in existing video adaptation processes. To solve this problem, we propose a novel <br>approach, named multi-modality transfer based on multi-graph optimization (MMT-MGO) <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16379685269125004665&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 1</a> <a href="/scholar?q=related:ef3kDvhUUOMJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16379685269125004665&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'ef3kDvhUUOMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1878142" class=yC3>Concept detector refinement using social videos</a></h3><div class="gs_a"><a href="/citations?user=-BFEdeMAAAAJ&amp;hl=en&amp;oi=sra">X Liu</a>, <a href="/citations?user=KdPSGmAAAAAJ&amp;hl=en&amp;oi=sra">B Huet</a> - Proceedings of the international workshop on Very- &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract The explosion of social video sharing sites gives new challenges on video search <br>and indexing techniques. Because of the concept diversity in social videos, it is very hard to <br>build a well annotated dataset that provides good coverage over the whole meaning of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18083707735018173218&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 1</a> <a href="/scholar?q=related:IvO9l1889voJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18083707735018173218&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'IvO9l1889voJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6135507" class=yC4>Event Driven Web Video Summarization by Tag Localization and Key-Shot Identification</a></h3><div class="gs_a"><a href="/citations?user=rHagaaIAAAAJ&amp;hl=en&amp;oi=sra">M Wang</a>, <a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, G Li, ZJ Zha, <a href="/citations?user=DNuiPHwAAAAJ&amp;hl=en&amp;oi=sra">S Yan</a>&hellip; - &hellip; , IEEE Transactions on, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract With the explosive growth of web videos on the Internet, it becomes challenging to <br>efficiently browse hundreds or even thousands of videos. When searching an event query, <br>users are often bewildered by the vast quantity of web videos returned by search engines. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17159319909387631227&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 6</a> <a href="/scholar?q=related:e3pWKosmIu4J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'e3pWKosmIu4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0925231212001518" class=yC5>Exploring multi-modality structure for cross domain adaptation in video concept annotation</a></h3><div class="gs_a">S Xu, S Tang, Y Zhang, J Li, YT Zheng - Neurocomputing, 2012 - Elsevier</div><div class="gs_rs">Domain adaptive video concept detection and annotation has recently received significant <br>attention, but in existing video adaptation processes, all the features are treated as one <br>modality, while multi-modalities, the unique and important property of video data, is <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:02zCLL48PksJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5421837788893048019&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'02zCLL48PksJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5673753" class=yC6>A Collaborative Approach for Image Annotation</a></h3><div class="gs_a">F Sun, Y Ge, D Wang, X Wang - Image and Video Technology ( &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Automatic image annotation is a promising solution to enable more effective image <br>retrieval by keywords. Different statistical models and machine learning methods have been <br>introduced for image auto-annotation. In this paper, we propose a collaborative approach, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:28RkbF_hARkJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1801969125881595099&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'28RkbF_hARkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0165168412002204" class=yC7>Multimedia encyclopedia construction by mining web knowledge</a></h3><div class="gs_a"><a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, ZJ Zha, Y Gao, TS Chua, X Wu - Signal Processing, 2012 - Elsevier</div><div class="gs_rs">Abstract In recent years, we have witnessed the blooming of Web 2.0 content such as <br>Wikipedia, Flickr and YouTube, etc. How might we benefit from such rich media resources <br>available on the internet? This paper presents a novel concept called Mediapedia, a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:-PXgd9tRpOoJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'-PXgd9tRpOoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5999642" class=yC8>Multimedia Question Answering</a></h3><div class="gs_a"><a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, M Wang, G Li, Z Zha, T Chua - 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Recent explosive growth of multimedia content on the Web has led to the popularity <br>and proliferation of search technology. However, faced the vast quantity of information <br>content returned by search engines, users are often bewildered and have to painstakingly <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3052222141799642610&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 1</a> <a href="/scholar?q=related:8rWM2d2rWyoJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3052222141799642610&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'8rWM2d2rWyoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
