Total results = 38
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://bioinformatics.tudelft.nl/sites/default/files/IEEETCSVT_keyframes.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tudelft.nl</span><span class="gs_ggsS">tudelft.nl <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=809162" class=yC0>An integrated scheme for automated video abstraction based on unsupervised cluster-validity analysis</a></h3><div class="gs_a"><a href="/citations?user=EoYbukgAAAAJ&amp;hl=en&amp;oi=sra">A Hanjalic</a>, HJ Zhang - Circuits and Systems for Video  &hellip;, 1999 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Key frames and previews are two forms of a video abstract, widely used for various <br>applications in video browsing and retrieval systems. We propose in this paper a novel <br>method for generating these two abstract forms for an arbitrary video sequence. The <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15603811592461882962&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 321</a> <a href="/scholar?q=related:UhbQhvjfi9gJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/1E/05/RN071920409.html?source=googlescholar" class="gs_nph" class=yC2>BL Direct</a> <a href="/scholar?cluster=15603811592461882962&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 23 versions</a> <a onclick="return gs_ocit(event,'UhbQhvjfi9gJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.83.2870&amp;rep=rep1&amp;type=pdf" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=779294" class=yC3>Time-constrained keyframe selection technique</a></h3><div class="gs_a"><a href="/citations?user=Dz6O99EAAAAJ&amp;hl=en&amp;oi=sra">A Girgensohn</a>, J Boreczky - Multimedia Computing and  &hellip;, 1999 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In accessing large collections of digitized videos, it is often difficult to find both the <br>appropriate video file and the portion of the video that is of interest. The paper describes a <br>novel technique for determining keyframes that are different from each other and provide a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13796428433192147022&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 105</a> <a href="/scholar?q=related:TliEOZDCdr8J:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13796428433192147022&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'TliEOZDCdr8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://207.21.18.5/publications/FXPAL-PR-00-042.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 207.21.18.5</span><span class="gs_ggsS">207.21.18.5 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/VM462N2LKQ5U76M0.pdf" class=yC5>Time-constrained keyframe selection technique</a></h3><div class="gs_a"><a href="/citations?user=Dz6O99EAAAAJ&amp;hl=en&amp;oi=sra">A Girgensohn</a>, J Boreczky - Multimedia Tools and Applications, 2000 - Springer</div><div class="gs_rs">In accessing large collections of digitized videos, it is often difficult to find both the <br>appropriate video file and the portion of the video that is of interest. This paper describes a <br>novel technique for determining keyframes that are different from each other and provide a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7557676727578200534&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 85</a> <a href="/scholar?q=related:1gmJAvFC4mgJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/2F/59/RN081868153.html?source=googlescholar" class="gs_nph" class=yC7>BL Direct</a> <a href="/scholar?cluster=7557676727578200534&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'1gmJAvFC4mgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1208494" class=yC8>Two-stage hierarchical video summary extraction to match low-level user browsing preferences</a></h3><div class="gs_a">AM Ferman, <a href="/citations?user=GzwcDjUAAAAJ&amp;hl=en&amp;oi=sra">AM Tekalp</a> - Multimedia, IEEE Transactions on, 2003 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract A compact summary of video that conveys visual content at various levels of detail <br>enhances user interaction significantly. In this paper, we propose a two-stage framework to <br>generate MPEG-7-compliant hierarchical key frame summaries of video sequences. At the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14954004510676164577&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 76</a> <a href="/scholar?q=related:4R9xbN9Lh88J:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/35/41/RN133994220.html?source=googlescholar" class="gs_nph" class=yC9>BL Direct</a> <a href="/scholar?cluster=14954004510676164577&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'4R9xbN9Lh88J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.34.7315&amp;rep=rep1&amp;type=pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.34.7315&amp;rep=rep1&amp;type=pdf" class=yCA>A content-based scene change detection and classification technique using background tracking</a></h3><div class="gs_a">JH Oh, KA Hua, N Liang - SPIE Conf. on Multimedia Computing and  &hellip;, 2000 - Citeseer</div><div class="gs_rs">ABSTRACT Scene is considered a good unit for indexing and retrieving data from large <br>video databases. In this paper, we present a new content-based approach for detecting and <br>classifying scene changes in video sequences. Our technique can detect and classify not <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6424789323867752620&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 49</a> <a href="/scholar?q=related:rAjcndlvKVkJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/19/39/RN075601499.html?source=googlescholar" class="gs_nph" class=yCC>BL Direct</a> <a href="/scholar?cluster=6424789323867752620&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'rAjcndlvKVkJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md4', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md4" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:rAjcndlvKVkJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.62.8011&amp;rep=rep1&amp;type=pdf" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S1077201499901973" class=yCD>Video summarization using R-sequences</a></h3><div class="gs_a">X Sun, MS Kankanhalli - Real-time imaging, 2000 - Elsevier</div><div class="gs_rs">In this paper, we propose a new method of temporal summarization of digital video. First, we <br>address the problem of extracting a fixed number of representative frames to summarize a <br>given digital video. To solve it, we have devised an algorithm called content-based <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11637094992950468232&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 43</a> <a href="/scholar?q=related:iB5KeD1Ef6EJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/29/15/RN088895812.html?source=googlescholar" class="gs_nph" class=yCF>BL Direct</a> <a href="/scholar?cluster=11637094992950468232&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'iB5KeD1Ef6EJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://vision.ece.ucsb.edu/publications/01PCMSun.pdf" class=yC11><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ucsb.edu</span><span class="gs_ggsS">ucsb.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/JFJ90VDQTRH7YW6L.pdf" class=yC10>A motion activity descriptor and its extraction in compressed domain</a></h3><div class="gs_a">X Sun, A Divakaran, <a href="/citations?user=wRYM4qgAAAAJ&amp;hl=en&amp;oi=sra">B Manjunath</a> - Advances in Multimedia Information  &hellip;, 2001 - Springer</div><div class="gs_rs">A novel motion activity descriptor and its extraction from a compressed MPEG (MPEG-1/2) <br>video stream are presented. The descriptor consists of two parts, a temporal descriptor and a <br>spatial descriptor. To get the temporal descriptor, the âmotion intensityâ is first computed <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1346163829134953280&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 37</a> <a href="/scholar?q=related:QIsRzd6IrhIJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/55/46/RN103714011.html?source=googlescholar" class="gs_nph" class=yC12>BL Direct</a> <a href="/scholar?cluster=1346163829134953280&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'QIsRzd6IrhIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://vis.uky.edu/~cheung/doc/dissertation.pdf" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uky.edu</span><span class="gs_ggsS">uky.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=900898" class=yC13>Efficient video similarity measurement and search</a></h3><div class="gs_a"><a href="/citations?user=kMAzq_QAAAAJ&amp;hl=en&amp;oi=sra">S Cheung</a>, A Zakhor - Image Processing, 2000. Proceedings.  &hellip;, 2000 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We consider the use of meta-data and/or video-domain methods to detect similar <br>videos on the Web. Meta-data is extracted from the textual and hyperlink information <br>associated with each video clip. In the video domain, we apply an efficient similarity <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2005871302642537296&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 35</a> <a href="/scholar?q=related:UJMoe1JJ1hsJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2005871302642537296&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'UJMoe1JJ1hsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md7', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md7" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:UJMoe1JJ1hsJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=6573395083773582598&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.151.4511&amp;rep=rep1&amp;type=pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.151.4511&amp;rep=rep1&amp;type=pdf" class=yC15>Temporal multi-resolution analysis for video segmentation</a></h3><div class="gs_a">Y Lin, MS Kankanhalli, TS Chua - Proc. SPIE Conf. Storage and Retrieval  &hellip;, 2000 - Citeseer</div><div class="gs_rs">ABSTRACT Video segmentation is an important step in many of the video applications. We <br>observe that the video shot boundary is a multi-resolution edge phenomenon in the feature <br>space. Based on this observation, we have developed a novel temporal multiresolution <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16519319399723706276&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 26</a> <a href="/scholar?q=related:pCfAj3hpQOUJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/29/3A/RN073068022.html?source=googlescholar" class="gs_nph" class=yC17>BL Direct</a> <a href="/scholar?cluster=16519319399723706276&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'pCfAj3hpQOUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md8', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md8" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:pCfAj3hpQOUJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://pdf.aminer.org/000/321/495/representation_of_motion_activity_in_hierarchical_levels_for_video_indexing.pdf" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aminer.org</span><span class="gs_ggsS">aminer.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1037981" class=yC18>Representation of motion activity in hierarchical levels for video indexing and filtering</a></h3><div class="gs_a">X Sun, <a href="/citations?user=wRYM4qgAAAAJ&amp;hl=en&amp;oi=sra">BS Manjunath</a>&hellip; - Image Processing. 2002.  &hellip;, 2002 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract A method for video indexing and filtering based on motion activity characteristics in <br>hierarchical levels is proposed. To extract motion activity information, an MPEG (MPEG-1/2) <br>video is first adaptively segmented into hierarchical levels with fixed percentage of original <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5389924596281594981&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 21</a> <a href="/scholar?q=related:ZVSB_9zbzEoJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5389924596281594981&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'ZVSB_9zbzEoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.google.com/patents?hl=en&amp;lr=&amp;vid=USPAT6807306&amp;id=LeQRAAAAEBAJ&amp;oi=fnd&amp;printsec=abstract" class=yC1A>Time-constrained keyframe selection method</a></h3><div class="gs_a"><a href="/citations?user=Dz6O99EAAAAJ&amp;hl=en&amp;oi=sra">A Girgensohn</a>, JS Boreczky - US Patent 6,807,306, 2004 - Google Patents</div><div class="gs_rs">A method for candidate frame selection involves sampling the source frames of the source <br>video at a predetermined fixed periodic interval. The largest frame differences represent <br>candidate boundaries, and the frames before and after the N/2 largest candidate <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1684767940426596478&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 18</a> <a href="/scholar?q=related:fgAY-oN_YRcJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1684767940426596478&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'fgAY-oN_YRcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="https://ritdml.rit.edu/bitstream/handle/1850/4189/ASavakisConfProc11-09-2003.pdf?sequence=1" class=yC1C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from rit.edu</span><span class="gs_ggsS">rit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1292250" class=yC1B>Key frame extraction using MPEG-7 motion descriptors</a></h3><div class="gs_a">R Narasimha, A Savakis, RM Rao&hellip; - Signals, Systems and  &hellip;, 2003 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We address the problem of key frame extraction in the compressed domain that is of <br>great importance in content-based system applications. A novel MPEG-7 motion activity <br>descriptor is discussed that is a combination of temporal and spatial descriptors. These <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=610426752021475140&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 16</a> <a href="/scholar?q=related:RK-ik-WreAgJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/16/12/RN147642979.html?source=googlescholar" class="gs_nph" class=yC1D>BL Direct</a> <a href="/scholar?cluster=610426752021475140&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'RK-ik-WreAgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://hal.upmc.fr/docs/00/54/35/15/PDF/truong_people_reidentification.pdf" class=yC1F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from upmc.fr</span><span class="gs_ggsS">upmc.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0165168409003806" class=yC1E>People re-identification by spectral classification of silhouettes</a></h3><div class="gs_a">DN Truong Cong, L Khoudour, C Achard, C Meurie&hellip; - Signal Processing, 2010 - Elsevier</div><div class="gs_rs">The problem described in this paper consists in re-identifying moving people in different <br>sites which are completely covered with non-overlapping cameras. Our proposed framework <br>relies on the spectral classification of the appearance-based signatures extracted from the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10097940611702123781&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 15</a> <a href="/scholar?q=related:Be1-M3wXI4wJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10097940611702123781&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'Be1-M3wXI4wJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://www1bpt.bridgeport.edu/~jelee/pubs/VideoAbstraction.pdf" class=yC21><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from bridgeport.edu</span><span class="gs_ggsS">bridgeport.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[BOOK]</span><span class="gs_ct2">[B]</span></span> <a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=2Z3LcUZvZIwC&amp;oi=fnd&amp;pg=PA321&amp;ots=ApONeb5Qcg&amp;sig=dD0dGl7JRDmhMSKsTLDRnfUj_RY" class=yC20>Video abstraction</a></h3><div class="gs_a">J Oh, Q Wen, <a href="/citations?user=CCOAVjAAAAAJ&amp;hl=en&amp;oi=sra">J Lee</a>, S Hwang - 2004 - books.google.com</div><div class="gs_rs">ABSTRACT This chapter introduces Video Abstraction, which is a short representation of an <br>original video, and widely used in video cataloging, indexing, and retrieving. It provides a <br>general view of video abstraction and presents different methods to produce various video <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16877988807179254615&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 13</a> <a href="/scholar?q=related:VzvwjmWpOuoJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16877988807179254615&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'VzvwjmWpOuoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="https://ritdml.rit.edu/bitstream/handle/1850/4190/ASavakisConfProc12-2003.pdf?sequence=1" class=yC23><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from rit.edu</span><span class="gs_ggsS">rit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://proceedings.spiedigitallibrary.org/data/Conferences/SPIEP/22457/439_1.pdf" class=yC22>A neural network approach to key frame extraction</a></h3><div class="gs_a">R Narasimha, A Savakis&hellip; - Proceedings  &hellip;, 2004 - proceedings.spiedigitallibrary.org</div><div class="gs_rs">ABSTRACT We present a neural network based approach to key frame extraction in the <br>compressed domain. The proposed method is an amalgamation of both the MPEG-7 <br>descriptors namely motion intensity descriptor and spatial activity descriptor. Shot <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4659083009524651687&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 8</a> <a href="/scholar?q=related:p1bG8U9jqEAJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/29/3D/RN146760737.html?source=googlescholar" class="gs_nph" class=yC24>BL Direct</a> <a href="/scholar?cluster=4659083009524651687&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'p1bG8U9jqEAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://ir.lib.ncku.edu.tw/bitstream/987654321/55780/2/4010101201015.pdf" class=yC26><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ncku.edu.tw</span><span class="gs_ggsS">ncku.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1608107" class=yC25>Efficient news video querying and browsing based on distributed news video servers</a></h3><div class="gs_a">CY Chen, JC Wang, JF Wang - Multimedia, IEEE Transactions  &hellip;, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This study presents an efficient news video querying and browsing system based <br>on distributed news video servers. The proposed architecture includes distributed news <br>video preprocessing (NVP) server and visualized querying/browsing (VQB) server. The <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4280785232659073724&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 5</a> <a href="/scholar?q=related:vMphEH1naDsJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/57/53/RN220107782.html?source=googlescholar" class="gs_nph" class=yC27>BL Direct</a> <a href="/scholar?cluster=4280785232659073724&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'vMphEH1naDsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> åºäºèªéåºéå¼çèªå¨æåå³é®å¸§çèç±»ç®æ³ [J]</h3><div class="gs_a">çæ¹ç³ï¼ é¡»å¾·ï¼ å´ä¼é« - è®¡ç®æºç ç©¶ä¸åå±, 2005</div><div class="gs_fl"><a href="/scholar?cites=11926962739508120224&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 11</a> <a href="/scholar?q=related:oIqzeWsVhaUJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11926962739508120224&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'oIqzeWsVhaUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://www.cs.ucf.edu/dsg/publication/2001/non-linear-approach-to.pdf" class=yC29><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ucf.edu</span><span class="gs_ggsS">ucf.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.cs.ucf.edu/dsg/publication/2001/non-linear-approach-to.pdf" class=yC28>Non-linear approach to shot boundary detection</a></h3><div class="gs_a">KA Hua, JH Oh, K Vu - SPIE Conf. on Multimedia Computing and  &hellip;, 2001 - cs.ucf.edu</div><div class="gs_rs">ABSTRACT Shot boundary detection (SBD) is the first fundamental step to managing video <br>databases. It segments video data into the basic units for indexing and retrieval. Many <br>automatic SBD techniques exist. They, however, are based on sequential search, and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1016584186660182707&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 3</a> <a href="/scholar?q=related:s9oogu6hGw4J:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/03/46/RN092621686.html?source=googlescholar" class="gs_nph" class=yC2A>BL Direct</a> <a href="/scholar?cluster=1016584186660182707&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'s9oogu6hGw4J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md17', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md17" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:s9oogu6hGw4J:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB18" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW18"><a href="http://summit.sfu.ca/system/files/iritems1/9703/ETD4606.pdf" class=yC2C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from sfu.ca</span><span class="gs_ggsS">sfu.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://summit.sfu.ca/item/9703" class=yC2B>MoViShare: building location-aware mobile social networks for video sharing</a></h3><div class="gs_a">ZM Jia - 2009 - summit.sfu.ca</div><div class="gs_rs">Abstract: Social networking and content sharing are the two major reasons for the explosion <br>of web 2.0 applications in recent years. Although more people enjoy Internet and multimedia <br>via their cell phones, most of the services for online video sharing are still restricted to <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1556240331934345736&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 1</a> <a href="/scholar?q=related:CCoVKlbgmBUJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1556240331934345736&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'CCoVKlbgmBUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="http://vision.ece.ucsb.edu/publications/04ThesisXinding.pdf" class=yC2E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ucsb.edu</span><span class="gs_ggsS">ucsb.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://vision.ece.ucsb.edu/publications/04ThesisXinding.pdf" class=yC2D>Motion Activity for Video Indexing</a></h3><div class="gs_a">X Sun - 2004 - vision.ece.ucsb.edu</div><div class="gs_rs">Digital video is playing an increasingly important role in our daily life. In recent years, the <br>development of software and hardware technology has enabled the creation of a large <br>amount of digital video content. Due to the rapid increase in the size of digital video <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12772188113583056007&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 1</a> <a href="/scholar?q=related:h6SVWmvtP7EJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12772188113583056007&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'h6SVWmvtP7EJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md19', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md19" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:h6SVWmvtP7EJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a>  <a href="/scholar?q=info:h6SVWmvtP7EJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=680131113377766680&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1506507" class=yC2F>Hierarchical indexing of ocean survey video by mean shift clustering and MDL principle</a></h3><div class="gs_a">Q Luo, TM Khoshgoftaar, E An - Information Reuse and  &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Our contribution is proposing a novel framework for building a hierarchical index for <br>videos. First, a set of key frames for the finest level of the hierarchy is computed by mean-<br>shift clustering. Second, clusters are successively merged based on the minimum <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11115723526681985879&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 1</a> <a href="/scholar?q=related:VwNVZaf7QpoJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'VwNVZaf7QpoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> A Protagonist-Based Video Summarization System</h3><div class="gs_a">S Chung - 2007</div><div class="gs_fl"><a href="/scholar?cites=17578564192656751997&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 1</a> <a href="/scholar?q=related:ff20fP-a8_MJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17578564192656751997&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'ff20fP-a8_MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> ãã¤ãã¼ãããªãå©ç¨ãããããªã»ãã¼ã¿ãã¼ã¹ã®æå³æ§é ã«åºã¥ããã©ã¦ã¸ã³ã°ææ³</h3><div class="gs_a">çå°¼åè¡ï¼ æ¸¡éè±è± - ç¬¬ 12 åãã¼ã¿å·¥å­¦ã¯ã¼ã¯ã·ã§ãã (DEWS01), 2001</div><div class="gs_fl"><a href="/scholar?cites=12399101709276903321&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=38">Cited by 1</a> <a href="/scholar?q=related:mXdjs091EqwJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'mXdjs091EqwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1549614" class=yC30>An efficient news video browsing system for wireless network application</a></h3><div class="gs_a">CY Chen, JC Wang, JF Wang&hellip; - &hellip;  and Mobile Computing,  &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, an efficient news video browsing system for wireless network <br>application is presented. To provide a better news video categorization, the news scripts of <br>all the news stories are utilized to perform semantic analysis first. Theses stories are then <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:k1bfBL6Y0F4J:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6832128576613996179&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'k1bfBL6Y0F4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB24" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW24"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.37.6196&amp;rep=rep1&amp;type=pdf" class=yC32><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.37.6196&amp;rep=rep1&amp;type=pdf" class=yC31>Very Efficient Video Segmentation Techniques</a></h3><div class="gs_a">KA Hua, JH Oh - 2007 - Citeseer</div><div class="gs_rs">Abstract Shot boundary detection (SBD) is the first fundamental step to managing video <br>databases. It segments video data into the basic units for indexing and retrieval. Many <br>automatic SBD techniques exists. They, however, are based on sequential search, and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:UbrFCOX1BREJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1226656837571820113&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'UbrFCOX1BREJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md24', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md24" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:UbrFCOX1BREJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB25" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW25"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.705&amp;rep=rep1&amp;type=pdf" class=yC34><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.705&amp;rep=rep1&amp;type=pdf" class=yC33>A Practical Technique for Video Decomposing</a></h3><div class="gs_a">JH Oh, KA Hua - Proceedings of the 11th Conference of The Chinese- &hellip;, 2000 - Citeseer</div><div class="gs_rs">Abstract Shot boundary detection (SBD) is the first fundamental step to managing video <br>databases. It segments video data into the basic units for indexing and retrieval. Many <br>automatic SBD techniques exists. They, however, are based on sequential search, and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:_AVlJaeA6L4J:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13756386517178451452&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'_AVlJaeA6L4J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md25', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md25" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:_AVlJaeA6L4J:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> School of Computer Science, University of Central Florida Orlando, FL 32816-2362</h3><div class="gs_a">JH Oh, KA Hua, N Liang</div><div class="gs_fl"><a href="/scholar?q=related:S9dRX-vPyXsJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8919889146807441227&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'S9dRX-vPyXsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB27" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW27"><a href="http://digital.library.unt.edu/ark:/67531/metadc3695/m2/1/high_res_d/thesis.pdf" class=yC36><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unt.edu</span><span class="gs_ggsS">unt.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://digital.library.unt.edu/ark:/67531/metadc3695/m2/1/high_res_d/thesis.pdf" class=yC35>FPGA PROTOTYPING OF A WATERMARKING ALGORITHM FOR MPEG-4 Wei Cai, BE</a></h3><div class="gs_a"><a href="/citations?user=nvAKagcAAAAJ&amp;hl=en&amp;oi=sra">E Kougianos</a> - 2007 - digital.library.unt.edu</div><div class="gs_rs">In the immediate future, multimedia product distribution through the Internet will become <br>main stream. However, it can also have the side effect of unauthorized duplication and <br>distribution of multimedia products. That effect could be a critical challenge to the legal <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:MMX8c0TXjTEJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3570746768578364720&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'MMX8c0TXjTEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md27', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md27" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:MMX8c0TXjTEJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.dbpia.co.kr/view/ar_view.asp?arid=1742495" class=yC37>The Key frame Detection from Video Data using Region Change and Edge Distribution</a></h3><div class="gs_a">CC Park - ITC-CSCC: 2003, 1262~ 1265 ìª½ (ì´ 4 ìª½), 2003 - dbpia.co.kr</div><div class="gs_rs">Abstract: This study proposed the system that generated the key frame based on the spatial <br>and temporal correlation between regions as well as form flow in each frame. To detect an <br>accurate scene switching, the cut was detected by using the relative distribution of <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:fZNXi7YMdsIJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'fZNXi7YMdsIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Computer Science Program, School of EECS University of Central Florida, Orlando, FL 32816-2362</h3><div class="gs_a">KA Hua, JH Oh, K Vu</div><div class="gs_fl"><a href="/scholar?q=related:GNeDjlpmar4J:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13720891753861732120&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'GNeDjlpmar4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ri"><h3 class="gs_rt"><a href="http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=837877" class=yC38>Image feature meaning for automatic key-frame extraction</a></h3><div class="gs_a">V Di Lecce, A Guerriero - Electronic  &hellip;, 2003 - proceedings.spiedigitallibrary.org</div><div class="gs_rs">abstract Video abstraction and summarization, being request in several applications, has <br>address a number of researches to automatic video analysis techniques. The processes for <br>automatic video analysis are based on the recognition of short sequences of contiguous <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ah8KmYBwxZcJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/5F/59/RN146760610.html?source=googlescholar" class="gs_nph" class=yC39>BL Direct</a> <a href="/scholar?cluster=10936270967764819818&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'ah8KmYBwxZcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> ë¨ì´ì ì ì¬ì± ì²ëì í´ë¬ì¤í°ë§ ìê³ ë¦¬ì¦</h3><div class="gs_a">WS Measure - ëì§í¸ëìê´ê³¼ ì§ìì¸íë¼ êµ¬ì¶</div><div class="gs_fl"><a href="/scholar?q=related:wYNWFeae2EIJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4816774512510403521&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'wYNWFeae2EIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB32" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW32"><a href="http://www.dist.unina.it/doc/tesilaur/2009.Macillo.pdf" class=yC3B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unina.it</span><span class="gs_ggsS">unina.it <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.dist.unina.it/doc/tesilaur/2009.Macillo.pdf" class=yC3A>UNIVERSITÃ DEGLI STUDI DI NAPOLI FEDERICO II</a></h3><div class="gs_a">I LA, PDD E&#39;IL - 2011 - dist.unina.it</div><div class="gs_rs">Il crescente utilizzo di prodotti in acciaio formati a freddo nella realizzazione di edifici <br>residenziali di piccole e medie dimensioni (housing) rappresenta ormai un fenomeno <br>consolidato nel mercato delle costruzioni nord americano ed australiano. Le ragioni di <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:x7u1JBay8xIJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1365630920198306759&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'x7u1JBay8xIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md32', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md32" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:x7u1JBay8xIJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:367"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.dbpia.co.kr/Article/?arid=1219164&amp;arid=1219164" class=yC3C>ë¹ëì¤ ë°°ì­ëª ì¶ì¶ì ì´ì©í ìë ì´ë¸íì´ì</a></h3><div class="gs_a">ì¡°ê·¼ì - íêµ­ì ë³´ê³¼íí 2009 íêµ­ì»´í¨í°ì¢í©íì ëí ë¼ë¬¸ì§, 2009 - dbpia.co.kr</div><div class="gs_rs">ë³¸ ë¼ë¬¸ì ìíë ëë¼ë§ ë±ìì ë±ì¥íë ì¸ë¬¼ì ë°°ì­ëªì ì¹ íì´ì§ë¡ë¶í° ì¶ì¶íì¬ <br>ìëì ì¼ë¡ ì´ë¸íì´ì (Annotation) íë ë°©ë²ì ì ìíë¤. ìì ë´ìì ê°ê°ì ë°°ì°ë¤ì´ <br>ë±ì¥í¨ì ë°ë¼ ë°ìëë ë¤ìí ìê°ì ë³´ì ë°°ì­ëªì ì¼ì¹ìí¤ë ì¼ì ìë¹í ì´ë ¤ì´ ì¼ì´ë¤<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:2FFJX9QgOKMJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'2FFJX9QgOKMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:366"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.dbpia.co.kr/view/ar_view.asp?arid=729264" class=yC3D>ëììì ì¥ë©´ë³ ë¹ëì¤ ë±ê¸ì ê³ ë ¤í ìì¸</a></h3><div class="gs_a">ê¹ìë´ - ê²ì &amp; ìí°íì¸ë¨¼í¸ ë¼ë¬¸ì§, 2006 - dbpia.co.kr</div><div class="gs_rs">ìµê·¼ ìí, ëë¼ë§, ë®¤ì§ë¹ëì¤ ë±ì ë¤ìí ì¤í¸ë¦¬ë° ë¹ëì¤ë¤ì´ ì¹ì íµí´ ëë¦¬ í¼ì ¸ëê°ê³  <br>ìë¤. ê¸°ì¡´ì ì¤í¸ë¦¬ë° ë¹ëì¤ ìë¹ì¤ë ì¬ì©ìì ë°ë¥¸ ëìì ìë¹ì¤ ì íì ëí´ ìê·¹ì ì´ê³ , <br>ëìì ì ì²´ì ì¼ê´ì ì¸ ì íì ê°íë ë°©ë²ì ì¬ì©íê³  ìë¤. ë³¸ ì°êµ¬ììë íëì ëìì<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:fdBgsa-__fMJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'fdBgsa-__fMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:365"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/92166x/201002/32954060.html" class=yC3E>èªéåº CCV åç­ä»·å³ç³»èç±»çè§é¢æè¦ççæ</a></h3><div class="gs_a">ç½æï¼ æ´çåï¼ ç¿ç´ å° - éåºå¤§å­¦å­¦æ¥: èªç¶ç§å­¦ç, 2010 - cqvip.com</div><div class="gs_rs">å¨éæè§é¢æè¦çæè¿ç¨ä¸­, æåä»£è¡¨å¸§æ¯å³é®. éè¿åæè§é¢å¸§åºå±çé¢è²ç¹å¾, <br>æ ¹æ®å¶åå®¹èªå¨è®¾ç½®è¿ééå¼, æåé¢è²èååé, å¹¶ä»¥æ­¤è¿è¡åºäºç­ä»·å³ç³»çèªéåºèç±». <br>å¨ç¡®å®æ´ä½ååå, æ ¹æ®æ¶åºç¹å¾è¿è¡å±é¨ä¿®æ­£. æ´ä¸ªè¿ç¨æ éè®¾å®ä»»ä½éå¼åäººä¸ºå¹²é¢, å¯¹<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:y42auKrIZIEJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9323797764130901451&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'y42auKrIZIEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:364"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB36" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW36"><a href="http://gospel.aid.design.kyushu-u.ac.jp/~ushiama/papers/DEWS2001.pdf" class=yC40><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from kyushu-u.ac.jp</span><span class="gs_ggsS">kyushu-u.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://gospel.aid.design.kyushu-u.ac.jp/~ushiama/papers/DEWS2001.pdf" class=yC3F>A Method for Semantic Content-based Video Database Browsing with Hyper-Video</a></h3><div class="gs_a">T Ushiama, T Watanabey - gospel.aid.design.kyushu-u.ac.jp</div><div class="gs_rs">We have studied on the mechanism that support users to browse video database e ciently <br>based on their interests. In this paper, we introduced an approach for the browsing video <br>databases with hyper-videos that are generated automatically from content descriptions of <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Ayb_yDWXc5IJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Ayb_yDWXc5IJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md36', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md36" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Ayb_yDWXc5IJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:363"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> A New Motion-Tolerant Dissolve Detection Algorithm</h3><div class="gs_a">HH Lin - 2006</div><div class="gs_fl"><a href="/scholar?q=related:pVto9E4Uu6MJ:scholar.google.com/&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11798045978167630757&amp;hl=en&amp;num=38&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'pVto9E4Uu6MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
