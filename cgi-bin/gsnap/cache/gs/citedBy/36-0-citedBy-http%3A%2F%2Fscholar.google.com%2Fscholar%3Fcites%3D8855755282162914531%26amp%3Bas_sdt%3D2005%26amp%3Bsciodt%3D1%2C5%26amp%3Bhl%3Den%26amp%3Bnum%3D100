Total results = 36
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="https://www1.comp.nus.edu.sg/~phanquyt/papers/icdar09.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5277790" class=yC0>A Laplacian Method for Video Text Detection</a></h3><div class="gs_a"><a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>, P Shivakumara&hellip; - Document Analysis and  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose an efficient text detection method based on the Laplacian <br>operator. The maximum gradient difference value is computed for each pixel in the <br>Laplacian-filtered image. K-means is then used to classify all the pixels into two clusters: <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7510299777898364636&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 36</a> <a href="/scholar?q=related:3L5TUtvxOWgJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7510299777898364636&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 19 versions</a> <a onclick="return gs_ocit(event,'3L5TUtvxOWgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://www.comp.nus.edu.sg/~tancl/publications/c2009/CRC-WT-8.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5277693" class=yC2>A robust wavelet transform based technique for video text detection</a></h3><div class="gs_a">P Shivakumara, <a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>&hellip; - Document Analysis and  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose a new method based on wavelet transform, statistical <br>features and central moments for both graphics and scene text detection in video images. <br>The method uses wavelet single level decomposition LH, HL and HH subbands for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7554870103400534811&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 29</a> <a href="/scholar?q=related:G1No5VRK2GgJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7554870103400534811&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 19 versions</a> <a onclick="return gs_ocit(event,'G1No5VRK2GgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3337634/" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from nih.gov</span><span class="gs_ggsS">nih.gov <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5729827" class=yC4>Text string detection from natural scenes by structure-based partition and grouping</a></h3><div class="gs_a">C Yi, <a href="/citations?user=aAWeB4wAAAAJ&amp;hl=en&amp;oi=sra">YL Tian</a> - Image Processing, IEEE Transactions on, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Text information in natural scene images serves as important clues for many image-<br>based applications such as scene understanding, content-based image retrieval, assistive <br>navigation, and automatic geocoding. However, locating text from a complex background <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3016895145552734713&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 23</a> <a href="/scholar?q=related:-WlFkyYq3ikJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3016895145552734713&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'-WlFkyYq3ikJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://www.comp.nus.edu.sg/~TANCL/publications/c2009/CRC-Gradient-473.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5277754" class=yC6>A gradient difference based technique for video text detection</a></h3><div class="gs_a">P Shivakumara, <a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>&hellip; - Document Analysis and  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Text detection in video images has received increasing attention, particularly in <br>scene text detection in video images, as it plays a vital role in video indexing and information <br>retrieval. This paper proposes a new and robust gradient difference technique for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7216000860360142616&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 16</a> <a href="/scholar?q=related:GO-t7IxiJGQJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7216000860360142616&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'GO-t7IxiJGQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://staging.comp.nus.edu.sg/~tancl/publications/j2010/Revised-Manuscript_Full.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320310000415" class=yC8>Accurate video text detection through classification of low and high contrast images</a></h3><div class="gs_a">P Shivakumara, W Huang, <a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">T Quy Phan</a>, C Lim Tan - Pattern Recognition, 2010 - Elsevier</div><div class="gs_rs">Detection of both scene text and graphic text in video images is gaining popularity in the <br>area of information retrieval for efficient indexing and understanding the video. In this paper, <br>we explore a new idea of classifying low contrast and high contrast video images in order <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7529734029965228028&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 14</a> <a href="/scholar?q=related:_Hc_vTT9fmgJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7529734029965228028&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'_Hc_vTT9fmgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://www.comp.nus.edu.sg/~tancl/publications/j2010/TCSVT4004-FinalPDF.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5585735" class=yCA>New Fourier-statistical features in RGB space for video text detection</a></h3><div class="gs_a">P Shivakumara, <a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>&hellip; - Circuits and Systems for  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose new Fourier-statistical features (FSF) in RGB space for <br>detecting text in video frames of unconstrained background, different fonts, different scripts, <br>and different font sizes. This paper consists of two parts namely automatic classification of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8338467067798852630&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 9</a> <a href="/scholar?q=related:FpRxe54vuHMJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8338467067798852630&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'FpRxe54vuHMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://media-lab.engr.ccny.cuny.edu/Paper/2010/ACM-MM-2010.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cuny.edu</span><span class="gs_ggsS">cuny.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1874156" class=yCC>Context-based indoor object detection as an aid to blind persons accessing unfamiliar environments</a></h3><div class="gs_a"><a href="/citations?user=yWsMg_gAAAAJ&amp;hl=en&amp;oi=sra">X Yang</a>, <a href="/citations?user=aAWeB4wAAAAJ&amp;hl=en&amp;oi=sra">YL Tian</a>, C Yi, A Arditi - Proceedings of the international  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract Independent travel is a well known challenge for blind or visually impaired persons. <br>In this paper, we propose a computer vision-based indoor wayfinding system for assisting <br>blind people to independently access unfamiliar buildings. In order to find different rooms (<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7212352597227931482&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 7</a> <a href="/scholar?q=related:WgejeHlsF2QJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7212352597227931482&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'WgejeHlsF2QJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://www.comp.nus.edu.sg/~tancl/publications/c2010/ShivaTextDetection-407.pdf" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.comp.nus.edu.sg/~tancl/publications/c2010/ShivaTextDetection-407.pdf" class=yCE>New wavelet and color features for text detection in Video</a></h3><div class="gs_a">P Shivakumara, <a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - Proceedings of the 2010 20th  &hellip;, 2010 - comp.nus.edu.sg</div><div class="gs_rs">Abstract-Automatic text detection in video is an important task for efficient and accurate <br>indexing and retrieval of multimedia data such as events identification, events boundary <br>identification etc. This paper presents a new method comprising of wavelet decomposition <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6715471896415485265&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 4</a> <a href="/scholar?q=related:Ub32FBwmMl0J:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6715471896415485265&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'Ub32FBwmMl0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md7', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md7" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Ub32FBwmMl0J:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5560063" class=yC10>Mash up of Breaking News and Contextual Web Information: A Novel Service for Connected Television</a></h3><div class="gs_a"><a href="/citations?user=ugI69q0AAAAJ&amp;hl=en&amp;oi=sra">T Chattopadhyay</a>, <a href="/citations?user=hkKS-xsAAAAJ&amp;hl=en&amp;oi=sra">A Pal</a>&hellip; - &hellip;  and Networks (ICCCN),  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The Connected TV can be described as an Internet enabled TV. In the current <br>paper we have proposed a system for connected TV that mash up the information from <br>internet and RSS feeds related to the breaking news aired over the TV. The proposed <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14225660364296598291&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 2</a> <a href="/scholar?q=related:E7NABbuya8UJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'E7NABbuya8UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320311000550" class=yC11>A novel mutual nearest neighbor based symmetry for text frame classification in video</a></h3><div class="gs_a">P Shivakumara, A Dutta, <a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">T Quy Phan</a>, C Lim Tan&hellip; - Pattern Recognition, 2011 - Elsevier</div><div class="gs_rs">In the field of multimedia retrieval in video, text frame classification is essential for text <br>detection, event detection, event boundary detection, etc. We propose a new text frame <br>classification method that introduces a combination of wavelet and median moment with k-<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11993170311716469446&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 2</a> <a href="/scholar?q=related:xvqeINtMcKYJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11993170311716469446&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'xvqeINtMcKYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1815395" class=yC12>An eigen value based approach for text detection in video</a></h3><div class="gs_a">DS Guru, S Manjunath, P Shivakumara&hellip; - Proceedings of the 9th  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, a novel approach for detection of text and non-text regions in video <br>frames is proposed. The proposed approach performs block wise eigen analysis on the <br>gradient image of the video frame. For each block of the gradient frame, the dominant <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10040391418189623075&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 3</a> <a href="/scholar?q=related:I68Sb8yiVosJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'I68Sb8yiVosJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5766755" class=yC13>A Low Complexity Sign Detection and Text Localization Method for Mobile Applications</a></h3><div class="gs_a">KL Bouman, G Abdollahian, M Boutin&hellip; - &hellip; , IEEE Transactions on, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We propose a low complexity method for sign detection and text localization in <br>natural images. This method is designed for mobile applications (eg, unmanned or <br>handheld devices) in which computational and energy resources are limited. No prior <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11501213600771041036&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 5</a> <a href="/scholar?q=related:DGfZd9WEnJ8J:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11501213600771041036&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'DGfZd9WEnJ8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1815366" class=yC14>A new wavelet-median-moment based method for multi-oriented video text detection</a></h3><div class="gs_a">P Shivakumara, A Dutta, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a>, <a href="/citations?user=2_z_CogAAAAJ&amp;hl=en&amp;oi=sra">U Pal</a> - Proceedings of the 9th IAPR  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we present a new method based on wavelet-median-moments and a <br>novel idea of angle projection for detecting multi-oriented text in video. The proposed <br>method uses wavelet decomposition first to obtain three high frequency sub-bands (LH, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3151128915057296173&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 3</a> <a href="/scholar?q=related:LcNzhw0PuysJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3151128915057296173&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'LcNzhw0PuysJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://www.comp.nus.edu.sg/~tancl/publications/c2010/ShivaTextFrame-406.pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5597182" class=yC15>Novel Edge Features for Text Frame Classification in Video</a></h3><div class="gs_a">P Shivakumara, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - Pattern Recognition (ICPR), 2010  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Text frame classification is needed in many applications such as event <br>identification, exact event boundary identification, navigation, video surveillance in <br>multimedia etc. To the best of our knowledge, there are no methods reported solely <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2099114078782469171&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 1</a> <a href="/scholar?q=related:M7TZECKNIR0J:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2099114078782469171&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'M7TZECKNIR0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6195336" class=yC17>Recent Advances in Video Based Document Processing: A Review</a></h3><div class="gs_a"><a href="/citations?user=JzinqNcAAAAJ&amp;hl=en&amp;oi=sra">N Sharma</a>, <a href="/citations?user=2_z_CogAAAAJ&amp;hl=en&amp;oi=sra">U Pal</a>, M Blumenstein - Document Analysis Systems &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Extraction and recognition of text present in video has become a very popular <br>research area in the last decade. Generally, text present in video frames is of different size, <br>orientation, style, etc. with complex backgrounds, noise, low resolution and contrast. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2870249651013170216&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 3</a> <a href="/scholar?q=related:KDRUsdks1ScJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2870249651013170216&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'KDRUsdks1ScJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://ijcsi.org/papers/IJCSI-8-5-3-225-234.pdf" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ijcsi.org</span><span class="gs_ggsS">ijcsi.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://ijcsi.org/papers/IJCSI-8-5-3-225-234.pdf" class=yC18>Robust Model for Text Extraction from Complex Video Inputs Based on SUSAN Contour Detection and Fuzzy C Means Clustering</a></h3><div class="gs_a">YS Kumaraswamy - ijcsi.org</div><div class="gs_rs">Abstract: The proposed system introduces a novel approach for extracting text effectively <br>from different types of complex video inputs. The valuable information within the text can be <br>deployed for text indexing and localization. The proposed system uses contour based <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:hNWbFBdJXOYJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16599222690059638148&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'hNWbFBdJXOYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md15', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md15" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:hNWbFBdJXOYJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.187.8732" class=yC1A>Gradient based Approach for Text Detection in Video Frames 1</a></h3><div class="gs_a">A Dutta, <a href="/citations?user=2_z_CogAAAAJ&amp;hl=en&amp;oi=sra">U Pal</a>, A Bandyopadhya, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - Citeseer</div><div class="gs_rs">Abstract: In this paper we propose a simple but efficient methodology for text detection in <br>video frames. The method is based on the gradient information and edge map selection. In <br>the proposed method we first find the gradient of the image and then enhance the gradient <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:kQafJH2bOxUJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1529987460210034321&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'kQafJH2bOxUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md16', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md16" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:kQafJH2bOxUJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.csa.com/partners/viewrecord.php?requester=gs&amp;collection=TRD&amp;recid=16512403CI" class=yC1B>Robust Model for Text Extraction from Complex Video Inputs Based on SUSAN Contour Detection and Fuzzy C Means Clustering</a></h3><div class="gs_a">NKN Murthy, YS Kumaraswamy - International Journal of Computer  &hellip;, 2011 - csa.com</div><div class="gs_rs">The proposed system introduces a novel approach for extracting text effectively from <br>different types of complex video inputs. The valuable information within the text can be <br>deployed for text indexing and localization. The proposed system uses contour based <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Nq0zNgfHueQJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Nq0zNgfHueQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><a href="http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=777124" class=yC1C>New performance evaluation models for character detection in images</a></h3><div class="gs_a">YW Wang, XQ Ding, CS Liu&hellip; - IS&amp;T/SPIE  &hellip;, 2010 - proceedings.spiedigitallibrary.org</div><div class="gs_rs">abstract Detection of characters regions is a meaningful research work for both highlighting <br>region of interest and recognition for further information processing. A lot of researches have <br>been performed on character localization and extraction and this leads to the great needs <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:1hLxOUwyU6UJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11912920742296097494&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'1hLxOUwyU6UJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md18', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md18" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:1hLxOUwyU6UJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> An Eigen Based Approach for Text Detection in Video</h3><div class="gs_a">DS Guru, S a Manjunath, P Shivakumara, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a></div><div class="gs_fl"><a href="/scholar?q=related:58NidEcD8MgJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'58NidEcD8MgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB20" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW20"><a href="http://www-ee.ccny.cuny.edu/www/web/yltian/Publications/CVIU-Text.pdf" class=yC1E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cuny.edu</span><span class="gs_ggsS">cuny.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www-ee.ccny.cuny.edu/www/web/yltian/Publications/CVIU-Text.pdf" class=yC1D>Text Extraction from Scene Images by Character Appearance and Structure Modeling</a></h3><div class="gs_a">C Yi, <a href="/citations?user=aAWeB4wAAAAJ&amp;hl=en&amp;oi=sra">Y Tian</a> - Computer Vision and Image Understanding, 2012 - www-ee.ccny.cuny.edu</div><div class="gs_rs">Abstract In this paper, we propose a novel algorithm to detect text information from natural <br>scene images. Scene text classification and detection are still open research topics. Our <br>proposed algorithm is able to model both character appearance and structure to generate <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'tSKshEXi35gJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md20', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md20" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:tSKshEXi35gJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="http://media-lab.engr.ccny.cuny.edu/xyang/papers/MVAP_Navigation.pdf" class=yC20><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cuny.edu</span><span class="gs_ggsS">cuny.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/L87KU3T806V81371.pdf" class=yC1F>Toward a computer vision-based wayfinding aid for blind persons to access unfamiliar indoor environments</a></h3><div class="gs_a"><a href="/citations?user=aAWeB4wAAAAJ&amp;hl=en&amp;oi=sra">YL Tian</a>, <a href="/citations?user=yWsMg_gAAAAJ&amp;hl=en&amp;oi=sra">X Yang</a>, C Yi, A Arditi - Machine Vision and Applications, 2012 - Springer</div><div class="gs_rs">Abstract Independent travel is a well-known challenge for blind and visually impaired <br>persons. In this paper, we propose a proof-of-concept computer vision-based wayfinding aid <br>for blind people to independently access unfamiliar indoor environments. In order to find <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11997268116089564575&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 1</a> <a href="/scholar?q=related:n22jjsnbfqYJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11997268116089564575&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'n22jjsnbfqYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> A New Bayesian Classifier Approach to Text Detection in Video Frames</h3><div class="gs_a">RP Sreedhar, P Shivakumara, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - 2004</div><div class="gs_fl"><a href="/scholar?q=related:q1fckUBzW2sJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'q1fckUBzW2sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB23" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW23"><a href="http://cdn.intechweb.org/pdfs/11406.pdf" class=yC22><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from intechweb.org</span><span class="gs_ggsS">intechweb.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://cdn.intechweb.org/pdfs/11406.pdf" class=yC21>Recognition of Characters from Streaming Videos</a></h3><div class="gs_a"><a href="/citations?user=ugI69q0AAAAJ&amp;hl=en&amp;oi=sra">T Chattopadhyay</a>, <a href="/citations?user=hkKS-xsAAAAJ&amp;hl=en&amp;oi=sra">A Pal</a>, <a href="/citations?user=TrdrjEQAAAAJ&amp;hl=en&amp;oi=sra">A Sinha</a> - cdn.intechweb.org</div><div class="gs_rs">Over the past few years, Video has become one of the prime source for recreation, be it <br>Television or Internet. Television brings a whole lot of professionally produced video content <br>(International or local, sports or educational, news or entertainment) to the home for the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10036602239941883215&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 1</a> <a href="/scholar?q=related:TzWgn48sSYsJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10036602239941883215&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'TzWgn48sSYsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md23', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md23" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:TzWgn48sSYsJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> A Chinese Words Detection Method in Camera Based Images</h3><div class="gs_a">Q Chen, Y Zhou, K Chen, <a href="/citations?user=jKIoTVoAAAAJ&amp;hl=en&amp;oi=sra">L Song</a>, <a href="/citations?user=yDEavdMAAAAJ&amp;hl=en&amp;oi=sra">X Yang</a> - American Journal of Engineering and  &hellip;, 2011</div><div class="gs_fl"><a href="/scholar?q=related:IGoSrmDDaaEJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11631042332665735712&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'IGoSrmDDaaEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6405797" class=yC23>A Survey on Video Caption Extraction Technology</a></h3><div class="gs_a">Z Wang, L Yang, X Wu, Y Zhang - &hellip;  Information Networking and  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Video caption extraction has become a very popular research area in the last few <br>decades. Many reasons makes it a challenging task. A large number of techniques have <br>been proposed to address this problem. This paper reviews the progress in this area and <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'Q1IzsQRzLusJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB26" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW26"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.182.2656&amp;rep=rep1&amp;type=pdf" class=yC25><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5597615" class=yC24>A New Symmetry based on Proximity of Wavelet-Moments for Text Frame Classification in Video</a></h3><div class="gs_a">P Shivakumara, A Dutta, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a>&hellip; - &hellip; Recognition (ICPR), 2010 &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper proposes the use of a new symmetry property based on proximity of the <br>median moments in the wavelet domain. The method divides a given frame into 16 equally <br>sized blocks to classify the true text frame. The average of high frequency subbands of a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:yFldyq2cYugJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16745118634755316168&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'yFldyq2cYugJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> New SVD-Statistical Features in RGB Space for Video Text Detection</h3><div class="gs_a">P Shivakumara, <a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a></div><div class="gs_fl"><a href="/scholar?q=related:IkKe89j4CdMJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'IkKe89j4CdMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> A HYBRID METHOD FOR TEXT DETECTION USING COLOR AND EDGE FEATURES</h3><div class="gs_a"><a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>, P Shivakumara, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a></div><div class="gs_fl"><a href="/scholar?q=related:HHSg_adPR8AJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'HHSg_adPR8AJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB29" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW29"><a href="http://www.joca.cn/CN/abstract/abstract16020.shtml" class=yC27><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from joca.cn</span><span class="gs_ggsS">joca.cn <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[HTML]</span><span class="gs_ct2">[HTML]</span></span> <a href="http://www.joca.cn/CN/abstract/abstract16020.shtml" class=yC26>å¤æèæ¯ä¸çç¥¨æ®å­ç¬¦åå²æ¹æ³</a></h3><div class="gs_a">å¶é¾æ¬¢ï¼ çä¿å³°ï¼ é«ç³ï¼ è¢å - è®¡ç®æºåºç¨, 2012 - joca.cn</div><div class="gs_rs">æè¦: éå¯¹ç¥¨æ®å­ç¬¦è¯å«ä¸­å¾åå­å¨çåºçº¹, å°ç« åå¾æ¡ç­å¤æèæ¯å¹²æ°é®é¢, <br>æåºä¸ç§ææçå­ç¬¦åå²æ¹æ³. éè¿å¿«éæåå°æ³¢åæ¢æååºå¾åä¸­å·ææ¾èæ§çå­ç¬¦çº¹çç¹å¾<br>. éç¨ä¸ç§ç±ç²å°ç²¾çæç´¢ç­ç¥, å¨å¾ååºåååç´ ä¸¤ä¸ªå±æ¬¡ä¸éæ­¥åºååºæå­åèæ¯. é¦å<b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'fYObD-Fwd0oJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md29', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md29" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:fYObD-Fwd0oJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/95033x/201110/39427606.html" class=yC28>åºäºè§é¢å¾åçéè·¯ç¾å®³æ¥è­¦ç³»ç»è®¾è®¡å®ç°</a></h3><div class="gs_a">æç¾¤æ»¨ï¼ é»æµ©éï¼ èåå³° - è®¡ç®æºå·¥ç¨ä¸è®¾è®¡, 2011 - cqvip.com</div><div class="gs_rs">éå¯¹å¹¿ä¸çå±±å²­å°åºéè·¯çç¹æ®æåµ, ç ç©¶äºè¿è¡å±±å²­å¬è·¯, æ¡¥æ¢è£ç¼åè¾¹å¡æ»å¡çæ§çè§é¢<br>çæ§ç³»ç»çè®¾è®¡ä¸å®ç°. åå«éå¯¹åæåµè¿è¡å¾åå¤çç ç©¶, è®¾è®¡äºéåçå¾çè¯ä¸åææ¹æ³, <br>éè¿åç§ç¾å®³çè§é¢å¾åçé¢å¤çä»¥ååå¤ç, ç¹å¾æåååæ, ä¸ºé¢è­¦ç»ææä¾æ°æ®åºç¡<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:hdZiHTqGli0J:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3284960562372597381&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'hdZiHTqGli0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/95033x/201110/39427607.html" class=yC29>åºäºæ¡ä»¶ç¬ç»å¯åº¦æåçææ¬å®ä½æ¹æ³</a></h3><div class="gs_a">å¼ å»ºæï¼ çå¨ï¼ å¼ èï¼ æä¸¹ï¼ æ¿è³ - è®¡ç®æºå·¥ç¨ä¸è®¾è®¡, 2011 - cqvip.com</div><div class="gs_rs">ä¸ºäºè§£å³è§é¢æ£ç´¢ä¸­ææ¬å®ä½ç²¾ç¡®åº¦ä¸é«çé®é¢, æåºä¸ç§åºäºæ¡ä»¶ç¬ç»å¯åº¦æåçææ¬å®ä½<br>æ¹æ³. æ ¹æ®ææ¬ç¬ç»çç¹å¾å¯¹è§é¢å¾åä¸­çææ¬è¿è¡åæ­¥å®ä½, ç¨åºäºæ¡ä»¶å¯åº¦çæ¹æ³æ»¤å»<br>ä¸é¨åéææ¬åºå, åå©ç¨å¨æå½¢æå­¦å¯¹æåçææ¬åºåç²¾ç¡®å®ä½å¹¶å¯¹å¶ä¼åå¾å°æç»çææ¬<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:8JdyOOghZFUJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6153080272158103536&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'8JdyOOghZFUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.joca.cn/EN/article/showWenXian.do?id=16020" class=yC2A>Character segmentation method of check under complex background</a></h3><div class="gs_a">L YE, JF YU, L GAO, J YUAN - joca.cn</div><div class="gs_rs">Reference ï¼»1ï¼½ å¼ å°åï¼éå¹¼å¹³ï¼ä½æåï¼ç­. ç¥¨æ®å­ç¬¦è¯å«çé¢å¤çç®æ³ç ç©¶[J]. <br>å¾®è®¡ç®æºä¿¡æ¯ï¼2007,23(6):261-263. ï¼»2ï¼½ çç²,æå°æ¶. åºäºè¿éåæåçè½¦çå­ç¬¦åå²ç®æ³[J]. <br>è®¡ç®æºä»¿çï¼2011,28(4):336-339. ï¼»3ï¼½ LIU H,WU Q,ZHANG H B.Skew detection for <b> ...</b> </div><div class="gs_fl"><a onclick="return gs_ocit(event,'71MQTBpxlWIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md32', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md32" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:71MQTBpxlWIJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:367"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.dbpia.co.kr/view/ar_view.asp?arid=1532991" class=yC2B>í´ëì í ëììììì ë¬¸ì ìì­ ê²ì¶ ë°©ë²</a></h3><div class="gs_a">ì¤ìí - é»å­å·¥å­¸æï¥æèª, 2010 - dbpia.co.kr</div><div class="gs_rs">ìµê·¼ ì¹´ë©ë¼ê° íì¬ë í´ëì íê° ëë¦¬ ë³´ê¸ëë©´ì í´ëì íë¡ ì´¬ìí ëìììì ë¬¸ììì­ì <br>ê²ì¶íê³  ì¸ìíì¬ ì¬ì©ììê² ì ì©í ì ë³´ë¥¼ ì ê³µíë ê¸°ë¥ì ëí ì°êµ¬ê° íë°í ì´ë£¨ì´ì§ê³  <br>ìë¤. ë°ë¼ì í´ëì íë¡ ì´¬ìë ëìììì ë¬¸ì ìì­ì ê²ì¶íê¸° ìí ë°©ë²ì´ íìíë¤. <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:rABJrJpPFTwJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'rABJrJpPFTwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:366"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/94832x/201107/38232127.html" class=yC2C>åºäºèç¾¤ä¼åç®æ³çå¤æèæ¯å¾åæå­æ£æµæ¹æ³</a></h3><div class="gs_a">ææè±ï¼ æç - è®¡ç®æºåºç¨, 2011 - cqvip.com</div><div class="gs_rs">éå¯¹å¤æèæ¯å¾åä¸­çæå­æ£æµé®é¢, æåºä¸ç§åºäºèç¾¤ä¼åç®æ³çå¤æèæ¯å¾åæå­æ£æµæ¹æ³<br>. è¯¥æ¹æ³é¦åéç¨èç¾¤ä¼åç®æ³æåå¾åè¾¹ç¼; ç¶åå¨è¾¹ç¼å¾åä¸æåç¹å¾, <br>éåç±ç²å°ç²¾å¤çº§æ£æµ, éªè¯çç­ç¥è¿è¡æå­æ£æµ. ä¸åºäºSoble ç®å­, Canny ç®å­ç­æ¹æ³ç<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1115743545472934882&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 3</a> <a href="/scholar?q=related:4mNZ2Nfqew8J:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1115743545472934882&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'4mNZ2Nfqew8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:365"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB35" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW35"><a href="http://www.joca.cn/CN/article/downloadArticleFile.do?attachType=PDF&amp;id=16030" class=yC2E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from joca.cn</span><span class="gs_ggsS">joca.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.joca.cn/CN/article/downloadArticleFile.do?attachType=PDF&amp;id=16030" class=yC2D>åºäºå¤ç±»æ°æ®åç±»çæ¹è¿åééæ©ç®æ³</a></h3><div class="gs_a">éä»è±ï¼ éªçæ° - è®¡ç®æºåºç¨, 2012 - joca.cn</div><div class="gs_rs">3204 è®¡ç®æºåºç¨ ç¬¬32å· äº²ååé«æä½åéæ°ç®å¤;é«äº²ååæä½åå¼æ¦çå°å£ç®æ³ <br>ç²¾ç¡®åº¦ç¸è¾äºå¶ä»3ä¸ªç®æ³æ¯è¾çæ³çåå ä¸»è¦æ¯å ä¸ºéåº¦ å¼è®¡ç®æ¹å¼o ç»¼ä¸åæç¨ç¥ï¼æ¹è¿åééæ©ç®æ³éç¨äºé«ç»´ <br>çå¤ç±»æ°æ®åç±»é®é¢,é¥æå¾åæ­£ç¬¦åé«ç»´ãç±»å«å¤çç¹ç¹ï¼ <b> ...</b> </div><div class="gs_fl"><a onclick="return gs_ocit(event,'oVlB7G6wsb4J')" href="#" class="gs_nph">Cite</a></div></div></div>
