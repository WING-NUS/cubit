<div class="gs_r" style="z-index:400"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6041635" class=yC0>Sport Video Intelligence Analysis Using Mid-Level and Low-Level Vision Information</a></h3><div class="gs_a">Q Ping, Z Weitao - Future Computer Science and Education ( &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Because of large audiences, great business prospects and potential applications, <br>sports video has attracted academic and industry attention. From the low-level feature <br>extraction and mid-level key primitive generation, we preliminary success the shot <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ParUCdwx_dwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15923938678579440189&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'ParUCdwx_dwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB101" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW101"><a href="http://scholarbank.nus.sg/bitstream/handle/10635/14908/yuan%20junsong.pdf?sequence=1" class=yC2><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.sg</span><span class="gs_ggsS">nus.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://scholarbank.nus.sg/handle/10635/14908" class=yC1>Robust short clip representation and fast search through large video collections</a></h3><div class="gs_a">Y JUNSONG - 2005 - scholarbank.nus.sg</div><div class="gs_rs">In this thesis we present a video copy detection method to effectively and efficiently search <br>and locate clip re-occurrences (copies) inside large video collections. Three aspects of <br>video copy detection including (1) feature robustness to coding variations,(2) search <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:hXrmIZF49UMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4896952734569626245&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'hXrmIZF49UMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB102" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW102"><a href="http://jcst.ict.ac.cn:8080/jcst/EN/article/downloadArticleFile.do?attachType=PDF&amp;id=460" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ict.ac.cn</span><span class="gs_ggsS">ict.ac.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://jcst.ict.ac.cn:8080/jcst/EN/article/downloadArticleFile.do?attachType=PDF&amp;id=460" class=yC3>Semantic and Structural Analysis of TV Diving Programs</a></h3><div class="gs_a">F Wang12, JT Li, YD Zhang, SX Lin - jcst.ict.ac.cn</div><div class="gs_rs">Abstract Automatic content analysis of sports videos is a valuable and challenging task. <br>Motivated by analogies between a class of sports videos and languages, the authors <br>propose a novel approach for sports video analysis based on compiler principles. It <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:rRuNJj8B4HQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8421732673924176813&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'rRuNJj8B4HQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB103" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW103"><a href="http://goal.i2r.a-star.edu.sg/BCA2004.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from a-star.edu.sg</span><span class="gs_ggsS">a-star.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://goal.i2r.a-star.edu.sg/BCA2004.pdf" class=yC5>AUTOMATIC SPORTS CONTENT ANALYSISâSTATE-OF-ART AND RECENT RESULTS</a></h3><div class="gs_a">K WAN, C XU, Q TIAN, M LEONG - goal.i2r.a-star.edu.sg</div><div class="gs_rs">ABSTRACT The global appeal of sports content is widely expected to be a key driver content <br>for DTV interactivity. Its regular structures are amenable for automatic analysis and <br>semantics extraction, leading to significant opportunities in interactive advertising and time<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:omyOLG4vn80J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14816613449312660642&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'omyOLG4vn80J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md103', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md103" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:omyOLG4vn80J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://cjc.ict.ac.cn/eng/qwjse/view.asp?id=1889" class=yC7>Information-Theoretic Co-Clustering for Video Shot Categorization</a></h3><div class="gs_a">W Peng, Y Shi-Qiang, LIU Zhi-Qiang - 2005 - cjc.ict.ac.cn</div><div class="gs_rs">Background Automatic categorization of video shots is very useful in video content analysis <br>applications, such as structure parsing and semantic event extraction. In previous works, <br>various low-level features, including color, texture, motion, have been used to describe the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11647645484631929685&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:VTMrPdu_pKEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/45/3E/RN178864073.html?source=googlescholar" class="gs_nph" class=yC8>BL Direct</a> <a href="/scholar?cluster=11647645484631929685&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'VTMrPdu_pKEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md104', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md104" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:VTMrPdu_pKEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB105" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW105"><a href="http://www.scholarbank.nus.edu.sg/bitstream/handle/10635/13168/Wang%20Hee%20Lin%20Thesis_for%20upload.pdf?sequence=1" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.scholarbank.nus.edu.sg/handle/10635/13168" class=yC9>Motion and emotion: Semantic knowledge for hollywood film indexing</a></h3><div class="gs_a">WHEE LIN - 2008 - scholarbank.nus.edu.sg</div><div class="gs_rs">The thesis proposes novel frameworks for the automated classification of affective and <br>directing related higher-level semantic knowledge from Hollywood domain multimedia to <br>augment indexing. We have proposed a framework grounded in psychology and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:2t9CPgxwxEAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4666978311749165018&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'2t9CPgxwxEAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB106" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW106"><a href="http://eprints.qut.edu.au/4941/1/4941.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from qut.edu.au</span><span class="gs_ggsS">qut.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/BBTKVA997MQWAG5L.pdf" class=yCB>Multi-level semantic analysis for sports video</a></h3><div class="gs_a"><a href="/citations?user=_OblDDgAAAAJ&amp;hl=en&amp;oi=sra">D Tjondronegoro</a>, <a href="/citations?user=Vt5edEkAAAAJ&amp;hl=en&amp;oi=sra">YP Chen</a> - Knowledge-Based Intelligent Information and &hellip;, 2005 - Springer</div><div class="gs_rs">There has been a huge increase in the utilization of video as one of the most preferred type <br>of media due to its content richness for many significant applications including sports. To <br>sustain an ongoing rapid growth of sports video, there is an emerging demand for a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:WDpKQaYtphsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/42/0E/RN178306708.html?source=googlescholar" class="gs_nph" class=yCD>BL Direct</a> <a href="/scholar?cluster=1992330077241227864&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'WDpKQaYtphsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> ANNOTATION FOR TENNIES VIDEO</h3><div class="gs_a">YP Thsengï¼ ï¦éæ°</div><div class="gs_fl"><a href="/scholar?q=related:-aBCRFbnKscJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'-aBCRFbnKscJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB108" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW108"><a href="http://eprints.qut.edu.au/archive/00002199/01/PhDThesis_Tjondronegoro.pdf" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from qut.edu.au</span><span class="gs_ggsS">qut.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://eprints.qut.edu.au/archive/00002199" class=yCE>PhD Thesis:&quot; Content-based Video Indexing for Sports Applications using Multi-modal approach&quot;</a></h3><div class="gs_a"><a href="/citations?user=_OblDDgAAAAJ&amp;hl=en&amp;oi=sra">DW Tjondronegoro</a> - 2005 - eprints.qut.edu.au</div><div class="gs_rs">Triggered by technology innovations, there has been a huge increase in the utilization of <br>video, as one of the most preferred types of media due to its content richness, for many <br>significant applications. To sustain an ongoing rapid growth of video information, there is <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:k7wHTZYfh10J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6739390097781144723&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'k7wHTZYfh10J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Semantic Analysis in Sports Video</h3><div class="gs_a">YP Thseng, JJJ Lien</div><div class="gs_fl"><a href="/scholar?q=related:-N47T3WGvxkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1855349409898553080&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'-N47T3WGvxkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6407294" class=yC10>Hidden conditional random field-based soccer video events detection</a></h3><div class="gs_a">X Qian, X Hou, YY Tang, H Wang, Z Li - Image Processing, IET, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Detect highlight event is an important step for semantic-based video retrieval. <br>Hidden conditional random field (HCRF) is a discriminative model, which is effective in <br>fusing observations for event inference. Mid-level semantics and their refinements are <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'LSh8UUfngu8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Features for Content Analysis</h3><div class="gs_a"><a href="/citations?user=jk5DWVMAAAAJ&amp;hl=en&amp;oi=sra">CW Ngo</a>, F Wang - Springer</div><div class="gs_fl"><a href="/scholar?q=related:E07DYJW0q8UJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'E07DYJW0q8UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.emeraldinsight.com/journals.htm?articleid=1623734&amp;show=abstract" class=yC11>Delivering a Fully Interactive Mobile TV</a></h3><div class="gs_a"><a href="/citations?user=_OblDDgAAAAJ&amp;hl=en&amp;oi=sra">D Tjondronegoro</a>, <a href="/citations?user=HwIAqgIAAAAJ&amp;hl=en&amp;oi=sra">L Wang</a>, A Joly - International Journal of Web &hellip;, 2007 - emeraldinsight.com</div><div class="gs_rs">Abstract: Affordable mobile devices with video playback functionality are rapidly growing in <br>the market. Current wireless and third generation communication networks enable smoother <br>and higher quality streaming video. With the support of these technologies, most <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:615RYmlUqmwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/0C/17/RN216699992.html?source=googlescholar" class="gs_nph" class=yC12>BL Direct</a> <a href="/scholar?cluster=7830163713734827755&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'615RYmlUqmwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB113" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW113"><a href="http://users.cis.fiu.edu/~mchen005/PDF/MDMBookChapter12.pdf" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from fiu.edu</span><span class="gs_ggsS">fiu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/q31301510k17413k.pdf" class=yC13>Video Event Mining via Multimodal Content Analysis and Classification</a></h3><div class="gs_a">M Chen, SC Chen, ML Shyu, C Zhang - Multimedia Data Mining and  &hellip;, 2007 - Springer</div><div class="gs_rs">As digital video data become more and more pervasive, the issue of mining information from <br>video data becomes increasingly important. In this chapter, we present an effective <br>multimedia data mining framework for event mining with its application in the automatic <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:1SL8Zhv6W_UJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17679999757771875029&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'1SL8Zhv6W_UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB114" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW114"><a href="ftp://ftp.cqeec.com/2004GC113/TN7/85226X/019/006/11309792.pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cqeec.com</span><span class="gs_ggsS">cqeec.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="ftp://ftp.cqeec.com/2004GC113/TN7/85226X/019/006/11309792.pdf" class=yC15>Semantic and Structural Analysis of TV Diving Programs</a></h3><div class="gs_a">Wang-ä¸Fei, JT Li, YD Zhang, SX Lin - cqeec.com</div><div class="gs_rs">Abstract Automatic content analysis of sports videos is a valuable and challenging task. <br>Motivated by analogies between a cla ss of sports videos and languages, the authors <br>propose a noveI approach for sports video analysis ba sed on compiler principles. It <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:fJWWcfXoswgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'fJWWcfXoswgJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md114', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md114" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:fJWWcfXoswgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB115" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW115"><a href="http://arizona.openrepository.com/arizona/bitstream/10150/217073/1/azu_etd_11980_sip1_m.pdf" class=yC18><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from openrepository.com</span><span class="gs_ggsS">openrepository.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://arizona.openrepository.com/arizona/handle/10150/217073" class=yC17>CSI in the Web 2.0 Age: Data Collection, Selection, and Investigation for Knowledge Discovery</a></h3><div class="gs_a">T Fu - 2011 - arizona.openrepository.com</div><div class="gs_rs">The growing popularity of various Web 2.0 media has created massive amounts of user-<br>generated content such as online reviews, blog articles, shared videos, forums threads, and <br>wiki pages. Such content provides insights into web users&#39; preferences and opinions, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:9OAIdejzxwIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=200396888162754804&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'9OAIdejzxwIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB116" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW116"><a href="http://137.132.14.55/bitstream/handle/10635/14402/thesis.pdf?sequence=1" class=yC1A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.14.55</span><span class="gs_ggsS">137.132.14.55 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://137.132.14.55/handle/10635/14402" class=yC19>Event detection in soccer video based on audio/visual keywords</a></h3><div class="gs_a">K YULIN - 2004 - 137.132.14.55</div><div class="gs_rs">In this thesis, we propose a multi-modal two-level event detection framework and <br>demonstrate it on soccer videos. We use a mid-level representation called Audio and Visual <br>Keyword (AVK) that can be learned and detected in video segments. AVKs are intended to <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:8u8rejdXeoUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9618095849987633138&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'8u8rejdXeoUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB117" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW117"><a href="http://dro.deakin.edu.au/eserv/DU:30009746/chen-towardsuniversalandstatistical-2006.pdf" class=yC1C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from deakin.edu.au</span><span class="gs_ggsS">deakin.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1651300" class=yC1B>Towards universal and statistical-driven heuristics for automatic classification of sports video events</a></h3><div class="gs_a"><a href="/citations?user=_OblDDgAAAAJ&amp;hl=en&amp;oi=sra">D Tjondronegoro</a>, YPP Chen - Multi-Media Modelling  &hellip;, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Researchers worldwide have been actively seeking for the most robust and <br>powerful solutions to detect and classify key events (or highlights) in various sports domains. <br>Most approaches have employed manual heuristics that model the typical pattern of audio<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:U2HCkGlZPtIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15149644506456023379&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'U2HCkGlZPtIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1386022" class=yC1D>Meta Data Extraction from Linguistic Meeting Transcripts for the Annodex File Format</a></h3><div class="gs_a">C Schremmer, S Pfeiffer - &hellip; 2005. MMM 2005. Proceedings of the &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Semantic interpretation of the data distributed over the Internet is subject to major <br>current research activity. The Continuous Media Web (CMWeb) extends the World Wide <br>Web to time-continuously sampled data such as audio and video in regard to the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:OSDuk_TQqFMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6028297850107863097&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'OSDuk_TQqFMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/71711R2722003173.pdf" class=yC1E>Event detection models using 2d-BN and CRFs</a></h3><div class="gs_a">T Wang, J Li, W Hu, X Tong, <a href="/citations?user=KCurmvwAAAAJ&amp;hl=en&amp;oi=sra">Y Zhang</a>&hellip; - Advances in Multimedia  &hellip;, 2006 - Springer</div><div class="gs_rs">In this paper, we propose two novel semantic event detection models, ie, Two-dependence <br>Bayesian Network (2d-BN) and Conditional Random Fields (CRFs). 2d-BN is a simplified <br>Bayesian Network classifier which can characterize the feature relationships well and be <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:IMJnlffZ90gJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/5D/50/RN201122604.html?source=googlescholar" class="gs_nph" class=yC1F>BL Direct</a> <a href="/scholar?cluster=5257910747365098016&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'IMJnlffZ90gJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB120" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW120"><a href="http://cdn.intechopen.com/pdfs/36063/InTech-Semantic_based_sport_video_browsing.pdf" class=yC21><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from intechopen.com</span><span class="gs_ggsS">intechopen.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://cdn.intechopen.com/pdfs/36063/InTech-Semantic_based_sport_video_browsing.pdf" class=yC20>Semantic Based Sport Video Browsing</a></h3><div class="gs_a">X Qian - cdn.intechopen.com</div><div class="gs_rs">In this chapter, we focus our attention on semantic based sport video highlights detection <br>and semantic based sport video browsing. Users are more interested in sport video <br>highlights than the normal kicks. They site before their TV sets to enjoy the exciting <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:hsYqnuJErsIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'hsYqnuJErsIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md120', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md120" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:hsYqnuJErsIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/7781k870l23877m7.pdf" class=yC22>Multimodal feature extraction and fusion for semantic mining of soccer video: a survey</a></h3><div class="gs_a">P Oskouie, <a href="/citations?user=uMQQwdQAAAAJ&amp;hl=en&amp;oi=sra">S Alipour</a>&hellip; - Artificial Intelligence  &hellip;, 2012 - Springer</div><div class="gs_rs">Abstract This paper presents a classified review of soccer video analysis works. The existing <br>approaches in the aspects of highlight event detection, video summarization and retrieval <br>based on video stream, ball and player tracking for provision of match statistics, technical <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:w0Y2pJaiQDYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'w0Y2pJaiQDYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB122" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW122"><a href="http://umu.diva-portal.org/smash/get/diva2:308457/FULLTEXT01" class=yC24><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from diva-portal.org</span><span class="gs_ggsS">diva-portal.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://umu.diva-portal.org/smash/record.jsf?pid=diva2:308457" class=yC23>Expressing emotions through vibration for perception and control</a></h3><div class="gs_a">S ur RÃ©hman - 2010 - umu.diva-portal.org</div><div class="gs_rs">ABSTRACT This thesis addresses a challenging problem:âhow to let the visually impaired <br>&#39;see&#39;others emotionsâ. We, human beings, are heavily dependent on facial expressions to <br>express ourselves. A smile shows that the person you are talking to is pleased, amused, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:--JsppXcXUIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4782220914637726459&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'--JsppXcXUIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB123" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW123"><a href="http://www.jdl.ac.cn/doc/2011/2012711811332222_a46-zhang.pdf" class=yC26><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from jdl.ac.cn</span><span class="gs_ggsS">jdl.ac.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2168760" class=yC25>A Generic Approach for Systematic Analysis of Sports Videos</a></h3><div class="gs_a">N Zhang, LY Duan, L Li, Q Huang, J Du&hellip; - ACM Transactions on  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract Various innovative and original works have been applied and proposed in the field <br>of sports video analysis. However, individual works have focused on sophisticated <br>methodologies with particular sport types and there has been a lack of scalable and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:YnL9tBR-SNgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15584845137916555874&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'YnL9tBR-SNgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Play-Creator</h3><div class="gs_a">E Record</div><div class="gs_fl"><a href="/scholar?q=related:n3ghuFMlz54J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'n3ghuFMlz54J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB125" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW125"><a href="http://scholarbank.nus.sg/bitstream/handle/10635/14885/Wang_Dehong_Thesis.pdf?sequence=1" class=yC28><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.sg</span><span class="gs_ggsS">nus.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://scholarbank.nus.sg/handle/10635/14885" class=yC27>Semantic concept detection from visual content with statistical learning</a></h3><div class="gs_a">W DEHONG - 2005 - scholarbank.nus.sg</div><div class="gs_rs">This thesis addresses semantic concept detection from visual content with statistical learning <br>methods. The highest level semantic concept is genre, the lowest one is object. Accordingly, <br>two parts of research work have been conducted, namely sports news video genre <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:JETHyZDE0oUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9642985878293267492&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'JETHyZDE0oUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB126" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW126"><a href="http://repository.tudelft.nl/assets/uuid:ad50215b-e446-4ead-9a02-25f6f9bf7da7/thesis.pdf" class=yC2A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tudelft.nl</span><span class="gs_ggsS">tudelft.nl <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://repository.tudelft.nl/assets/uuid:ad50215b-e446-4ead-9a02-25f6f9bf7da7/thesis.pdf" class=yC29>Content Discovery from Composite Audio</a></h3><div class="gs_a">LU Lie - 2009 - repository.tudelft.nl</div><div class="gs_rs">In the age of information explosion, the amount of published information and available data <br>is rapidly increasing. As the amount of available data grows, the problem of managing the <br>information contained in this data becomes more and more difficult. Searchâto quickly find <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:gwIv1FFUntwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15897236445093364355&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'gwIv1FFUntwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md126', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md126" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:gwIv1FFUntwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4607644" class=yC2B>Personalization of media and its attention service applications</a></h3><div class="gs_a">LY Duan, C Xu - Multimedia and Expo, 2008 IEEE International  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract A wealth of information creates a poverty of attention and a need to allocate that <br>attention efficiently among the overabundance of information sources that might consume it. <br>Thus personalization systems have become an important research area. This paper gives <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:7VC_2XXYH3sJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'7VC_2XXYH3sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/N7211N77384168W5.pdf" class=yC2C>An unsupervised method for active region extraction in sports videos</a></h3><div class="gs_a">M Mentzelopoulos, <a href="/citations?user=SWn6HA0AAAAJ&amp;hl=en&amp;oi=sra">A Psarrou</a>&hellip; - Advances in Computational &hellip;, 2011 - Springer</div><div class="gs_rs">In this paper, we propose a fully automatic and computationally efficient algorithm for <br>analysis of sports videos. The goal of the proposed method is to identify regions that perform <br>certain activities in a scene. The model uses some low-level feature video processing <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:kVpo23gPLu4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17162672241707080337&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'kVpo23gPLu4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB129" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW129"><a href="http://dspace.brunel.ac.uk/bitstream/2438/3502/1/18_dexa.pdf" class=yC2E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from brunel.ac.uk</span><span class="gs_ggsS">brunel.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/CA50W478VJPTTCKF.pdf" class=yC2D>Automatic parsing of sports videos with grammars</a></h3><div class="gs_a"><a href="/citations?user=1JMwC1sAAAAJ&amp;hl=en&amp;oi=sra">F Wang</a>, K LÃ¼, JT Li, J Fan - Database and Expert Systems Applications, 2005 - Springer</div><div class="gs_rs">Motivated by the analogies between languages and sports videos, we introduce a novel <br>approach for video parsing with grammars. It utilizes compiler techniques for integrating both <br>semantic annotation and syntactic analysis to generate a semantic index of events and a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:GDPD4Zb-BNMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/1E/52/RN173219426.html?source=googlescholar" class="gs_nph" class=yC2F>BL Direct</a> <a href="/scholar?cluster=15205558165895852824&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'GDPD4Zb-BNMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB130" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW130"><a href="http://scholarbank.nus.sg/bitstream/handle/10635/14771/PhD_Thesis_YuXinguo.pdf?sequence=1" class=yC31><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.sg</span><span class="gs_ggsS">nus.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://scholarbank.nus.sg/handle/10635/14771" class=yC30>An effective trajectory-based algorithm for ball detection and tracking with application to the analysis of broadcast sports video</a></h3><div class="gs_a">YU XINGUO - 2005 - scholarbank.nus.sg</div><div class="gs_rs">This thesis is on sports video analysis and enhancement. It addresses three closely-related <br>problems. It first addresses the ball detection and tracking problem in broadcast sports <br>video. It proposes an effective trajectory-based algorithm for locating the ball in a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:K6ID80CJaqgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12135663057951236651&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'K6ID80CJaqgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> åºäºè°±åå²çè§é¢éå¤´èç±»æ¹æ³</h3><div class="gs_a">éæï¼ æè¶ï¼ èç²ï¼ çç - åäº¬èªç©ºèªå¤©å¤§å­¦å­¦æ¥, 2009</div><div class="gs_fl"><a href="/scholar?q=related:BMMtDg6JQxgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1748391773810311940&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'BMMtDg6JQxgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Detekcia potlesku GMM modelom v audiostope multimediÃ¡lnych zÃ¡znamoch</h3><div class="gs_a">J Olajec, R Jarina, D TichÃ¡</div><div class="gs_fl"><a href="/scholar?q=related:2zuqSkhdq4EJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9343664416981924827&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'2zuqSkhdq4EJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:367"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB133" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW133"><a href="http://166.111.120.193:8080/jspui/bitstream/211310/3692/1/%E7%BD%91%E7%90%83%E8%A7%86%E9%A2%91%E5%88%86%E6%9E%90%E7%9A%84%E8%BF%90%E5%8A%A8%E5%90%91%E9%87%8F%E5%9C%BA%E5%8F%98%E6%8D%A2%E7%AE%97%E6%B3%95.pdf" class=yC33><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 166.111.120.193</span><span class="gs_ggsS">166.111.120.193 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://166.111.120.193:8080/jspui/handle/211310/3692" class=yC32>ç½çè§é¢åæçè¿å¨åéåºåæ¢ç®æ³</a></h3><div class="gs_a">çé¹ï¼ è¡éï¼ æå½¬ï¼ æ¨å£«å¼º - 2005 - 166.111.120.193</div><div class="gs_rs">ç½çæ¯èµä¸­æåæºä¸çåºå¹³é¢æä¸å¾è§, å©ç¨è¿å¨ä¼°è®¡é¾ä»¥è·å¾çåççå®è·å¨ä¿¡æ¯, <br>ä¸å®¹æåå°å¤§ééæºåªå£°å¹²æ°. æ¬æåºäºéå­æåæºæ¨¡å, æåºä¸ç§è¿å¨åéåºåæ¢ç®æ³, <br>æé«åºäºè¿å¨åéåºç¹å¾åæç½çè§é¢çæ§è½. è¯¥ç®æ³å©ç¨åæ¯ç©ä½æ©è½åå¨å±è¿å¨è¡¥å¿ææ¯<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3436095829093004166&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:hjNKi_N2ry8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3436095829093004166&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'hjNKi_N2ry8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:366"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB134" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW134"><a href="http://km.meme.hokudai.ac.jp/people/akiota/pubs/pdfs/HISjournal2006.pdf" class=yC35><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hokudai.ac.jp</span><span class="gs_ggsS">hokudai.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://km.meme.hokudai.ac.jp/people/akiota/pubs/pdfs/HISjournal2006.pdf" class=yC34>å¤æ§ãªåç»é²è¦§æ¹æ³ãå¯è½ã¨ãããã¼ã«æä½æã®ã¦ã¼ã¶ã®è¡åè¦³å¯</a></h3><div class="gs_a">é«å¶ç« éï¼ å±±æ¬æ­è£&hellip; - &hellip; ã¤ã³ã¿ãã§ã¼ã¹å­¦ä¼è«æèª, 2006 - km.meme.hokudai.ac.jp</div><div class="gs_rs">Abstract We argue for a variety of interactive presentation tools for richer video experiences <br>to engage in active watching. Based on the Time-based Visual Presentation (TbVP) <br>framework, which separates presentation from content and views interaction methods as <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:PfWBw_R4egkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=682991286147478845&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'PfWBw_R4egkJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md134', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md134" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:PfWBw_R4egkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:365"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB135" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW135"><a href="https://jyx.jyu.fi/dspace/bitstream/handle/123456789/40521/Riku%20Valleala.pdf?sequence=1" class=yC37><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from jyu.fi</span><span class="gs_ggsS">jyu.fi <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="https://jyx.jyu.fi/dspace/handle/123456789/40521" class=yC36>Urheiluvideoiden sisÃ¤llÃ¶ntunnistus ja luokittelu</a></h3><div class="gs_a">R Valleala - 2008 - jyx.jyu.fi</div><div class="gs_rs">Valleala, Riku Jouni Sakari TietojÃ¤rjestelmÃ¤tieteen kandidaatintutkielma/Riku Valleala <br>JyvÃ¤skylÃ¤: JyvÃ¤skylÃ¤n yliopisto, 2008. 33 s. Urheiluvideoiden sisÃ¤llÃ¶ntunnistus ja luokittelu <br>Urheiluvideot ovat yksi nopeimmin kasvavista ja kiinnostavimmista videosisÃ¤ltÃ¶jen <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'dkyS5LDSMqoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:364"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB136" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW136"><a href="http://toubkal.imist.ma/bitstream/handle/123456789/8480/THESE_EL%20OUAZZANI.pdf?sequence=4" class=yC39><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from imist.ma</span><span class="gs_ggsS">imist.ma <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://toubkal.imist.ma/handle/123456789/8480" class=yC38>La reconnaissance et l&#39;apprentissage des Ã©vÃ©nements chauds dans la vidÃ©o de matches de football en utilisant les ModÃ¨les de Markov CachÃ©s</a></h3><div class="gs_a">R El Ouazzani - 2010 - toubkal.imist.ma</div><div class="gs_rs">Dans le cadre de cette thÃ¨se, nous proposons des techniques pour reconnaÃ®tre les <br>Ã©vÃ©nements importants dans la vidÃ©o de matches de football en utilisant les ModÃ¨les de <br>Markov CachÃ©s (MMC). Un Ã©vÃ©nement important est tout Ã©vÃ©nement qui peut intÃ©resser le <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:OQFA-iAiHPYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'OQFA-iAiHPYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
