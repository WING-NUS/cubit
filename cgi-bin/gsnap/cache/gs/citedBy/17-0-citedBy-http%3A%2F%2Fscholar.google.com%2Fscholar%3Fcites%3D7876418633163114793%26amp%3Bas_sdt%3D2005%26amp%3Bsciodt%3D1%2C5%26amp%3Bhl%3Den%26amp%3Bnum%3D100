Total results = 17
<div class="gs_r" style="z-index:400"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[BOOK]</span><span class="gs_ct2">[B]</span></span> <a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=ds6xRLdlmJgC&amp;oi=fnd&amp;pg=PR9&amp;ots=jvk_hJikWg&amp;sig=L7DiuMu50N7IF8dt_9LYey7Uops" class=yC0>Content-based image and video retrieval</a></h3><div class="gs_a"><a href="/citations?user=ZgWULzYAAAAJ&amp;hl=en&amp;oi=sra">O Marques</a>, B Furht - 2002 - books.google.com</div><div class="gs_rs">The amount of audiovisual information available in digital format has grown exponentially in <br>recent years. Gigabytes of new images, audio and video clips are generated and stored <br>everyday. Most audiovisual content can be accessed through the Internet, which is a very <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8181352041348610094&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 68</a> <a href="/scholar?q=related:LjgAv1UAinEJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8181352041348610094&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'LjgAv1UAinEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md0', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md0" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:LjgAv1UAinEJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=5138427890560917326&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1035721" class=yC1>The segmentation of news video into story units</a></h3><div class="gs_a">L Chaisorn, TS Chua, CH Lee - Multimedia and Expo, 2002.  &hellip;, 2002 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The segmentation of news video into single-story semantic units is a challenging <br>problem. This research proposes a two-level, multi-modal framework to tackle this problem. <br>The video is analyzed at the shot and story unit (or scene) levels using a variety of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16492627510664671647&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 51</a> <a href="/scholar?q=related:n7EA2laV4eQJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16492627510664671647&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'n7EA2laV4eQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.199.6634&amp;rep=rep1&amp;type=pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Pp3Xg-xg2CUC&amp;oi=fnd&amp;pg=PA95&amp;ots=PPpTE1bwak&amp;sig=NWMfPgd3BirRIBnfyOTnxV-uLmA" class=yC2>The segmentation and classification of story boundaries in news video</a></h3><div class="gs_a">L Chaisorn, TS Chua - Proceedings of the IFIP TC2/WG2, 2002 - books.google.com</div><div class="gs_rs">Abstract The segmentation and classification of news video into single-story semantic units <br>is a challenging problem. This research proposes a two-level, multi-modal framework to <br>tackle this problem. The video is analyzed at the shot and story unit (or scene) levels using <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14815142300848227144&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 21</a> <a href="/scholar?q=related:SAPsum31mc0J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14815142300848227144&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'SAPsum31mc0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://musicweb.ucsd.edu/~sdubnov/mu206/addamssurvey.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ucsd.edu</span><span class="gs_ggsS">ucsd.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1195158" class=yC4>Where does computational media aesthetics fit?</a></h3><div class="gs_a"><a href="/citations?user=kbcVlyAAAAAJ&amp;hl=en&amp;oi=sra">B Adams</a> - Multimedia, IEEE, 2003 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The huge volume of multimedia data now available calls for effective management <br>solutions. Computational media aesthetics (CMA), one response to this data-management <br>problem, attempts to handle multimedia data using domain-driven inferences. To provide <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17128265271554815217&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 18</a> <a href="/scholar?q=related:8TSv2YPSs-0J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/5C/16/RN143475746.html?source=googlescholar" class="gs_nph" class=yC6>BL Direct</a> <a href="/scholar?cluster=17128265271554815217&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'8TSv2YPSs-0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/acmmm02-wangjh.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=641055" class=yC7>A framework for video scene boundary detection</a></h3><div class="gs_a">J Wang, TS Chua - Proceedings of the tenth ACM international  &hellip;, 2002 - dl.acm.org</div><div class="gs_rs">Abstract Most current video retrieval systems use shot as the basis for information <br>organization and access. In cinematography, scene is the basic story unit that the directors <br>use to convey their ideas. This paper proposes a framework based on the concept of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2323743190817835309&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 17</a> <a href="/scholar?q=related:LQnuzR6YPyAJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2323743190817835309&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'LQnuzR6YPyAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://wing2.ddns.comp.nus.edu.sg/downloads/keyphraseCorpus/195/195.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1101153" class=yC9>Topic transition detection using hierarchical hidden Markov and semi-Markov models</a></h3><div class="gs_a"><a href="/citations?user=OtA9SwIAAAAJ&amp;hl=en&amp;oi=sra">DQ Phung</a>, <a href="/citations?user=KywMsHsAAAAJ&amp;hl=en&amp;oi=sra">TV Duong</a>, <a href="/citations?user=AEkRUQcAAAAJ&amp;hl=en&amp;oi=sra">S Venkatesh</a>&hellip; - Proceedings of the 13th  &hellip;, 2005 - dl.acm.org</div><div class="gs_rs">Abstract In this paper we introduce a probabilistic framework to exploit hierarchy, structure <br>sharing and duration information for topic transition detection in videos. Our probabilistic <br>detection framework is a combination of a shot classification step and a detection phase <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18347816260995936064&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 18</a> <a href="/scholar?q=related:QG_MsK2JoP4J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18347816260995936064&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 18 versions</a> <a onclick="return gs_ocit(event,'QG_MsK2JoP4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4118239" class=yCB>Towards theoretical performance limits of video parsing</a></h3><div class="gs_a"><a href="/citations?user=EoYbukgAAAAJ&amp;hl=en&amp;oi=sra">A Hanjalic</a> - Circuits and Systems for Video Technology, IEEE  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper unravels the problem of temporal video segmentation, or video parsing, <br>and explores the possibilities for defining theoretical limits for the expected performance of a <br>general parsing algorithm. In particular, we address the challenge of computing the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=456258932500033270&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 10</a> <a href="/scholar?q=related:9m5D7RT1VAYJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/43/3A/RN207335549.html?source=googlescholar" class="gs_nph" class=yCC>BL Direct</a> <a href="/scholar?cluster=456258932500033270&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'9m5D7RT1VAYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://www.computing.edu.au/~truongbt/papers/truong_thesis_phd.pdf" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from computing.edu.au</span><span class="gs_ggsS">computing.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.computing.edu.au/~truongbt/papers/truong_thesis_phd.pdf" class=yCD>In Search of Structural and Expressive Elements in Film Based on Visual Grammar</a></h3><div class="gs_a">BT Truong - 2004 - computing.edu.au</div><div class="gs_rs">Abstract The growing presence of multimedia data made possible by advances in storage, <br>processing and transmission technologies has triggered the need for enabling technologies <br>for multimedia content management. The most challenging problem in this area is to <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18012837698129152926&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 8</a> <a href="/scholar?q=related:nsvASXN0-vkJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18012837698129152926&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'nsvASXN0-vkJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md7', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md7" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:nsvASXN0-vkJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/visual03.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/empenryggg0alg96.pdf" class=yCF>A cinematic-based framework for scene boundary detection in video</a></h3><div class="gs_a">J Wang, TS Chua - The Visual Computer, 2003 - Springer</div><div class="gs_rs">Most current video retrieval systems use shots as the basis for information organization and <br>access. In cinematography, scene is the basic story unit that the directors use to compose <br>and convey their ideas. This paper proposes a framework based on the concept of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16541083775778629801&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 6</a> <a href="/scholar?q=related:qShDPw68jeUJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/4B/32/RN137115916.html?source=googlescholar" class="gs_nph" class=yC11>BL Direct</a> <a href="/scholar?cluster=16541083775778629801&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'qShDPw68jeUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://dro.deakin.edu.au/eserv/DU:30044651/venkatesh-narrativestructure-2002.pdf" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from deakin.edu.au</span><span class="gs_ggsS">deakin.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://dro.deakin.edu.au/eserv/DU:30044651/venkatesh-narrativestructure-2002.pdf" class=yC12>Narrative structure analysis with education and training videos for e-learning</a></h3><div class="gs_a"><a href="/citations?user=OtA9SwIAAAAJ&amp;hl=en&amp;oi=sra">QD Phung</a>, C Dorai, <a href="/citations?user=AEkRUQcAAAAJ&amp;hl=en&amp;oi=sra">S Venkatesh</a> - ICPR 2002: Proceedings of  &hellip;, 2012 - dro.deakin.edu.au</div><div class="gs_rs">This paper deals with the problem ofstructuralizing education and training videos for high-<br>level semantics extraction and nonlinear media presentation in e-learning applications. <br>Drawing guidance from production knowledge in instructional media, we propose six main <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9935321926218427306&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 6</a> <a href="/scholar?q=related:qitm_aZa4YkJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/14/40/RN126685099.html?source=googlescholar" class="gs_nph" class=yC14>BL Direct</a> <a href="/scholar?cluster=9935321926218427306&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'qitm_aZa4YkJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md9', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md9" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:qitm_aZa4YkJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://www.computing.edu.au/~phung/wiki_new/uploads/Main/phung_phd05.pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from computing.edu.au</span><span class="gs_ggsS">computing.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.computing.edu.au/~phung/wiki_new/uploads/Main/phung_phd05.pdf" class=yC15>Probabilistic and Film Grammar Based Methods for Video Content Understanding</a></h3><div class="gs_a"><a href="/citations?user=OtA9SwIAAAAJ&amp;hl=en&amp;oi=sra">DQ Phung</a> - 2005 - computing.edu.au</div><div class="gs_rs">The fast growing advances in electronics, computer, and communication technologies have <br>greatly transformed our lives in many ways. Possibly, one of the most significant outcomes is <br>the emergence of the field of &#39;multimedia&#39;âwhich, perhaps an unknown term 50 years ago, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1908865813674696631&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:t5_3C1infRoJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'t5_3C1infRoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md10', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md10" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:t5_3C1infRoJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a>  <a href="/scholar?q=info:t5_3C1infRoJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=1721789611133110712&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.93.2370&amp;rep=rep1&amp;type=pdf" class=yC18><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/md4eqkxn416gtjhd.pdf" class=yC17>Content structure discovery in educational videos using shared structures in the hierarchical hidden Markov models</a></h3><div class="gs_a"><a href="/citations?user=OtA9SwIAAAAJ&amp;hl=en&amp;oi=sra">D Phung</a>, <a href="/citations?user=mDLwSZAAAAAJ&amp;hl=en&amp;oi=sra">H Bui</a>, <a href="/citations?user=AEkRUQcAAAAJ&amp;hl=en&amp;oi=sra">S Venkatesh</a> - Structural, Syntactic, and Statistical Pattern  &hellip;, 2004 - Springer</div><div class="gs_rs">In this paper, we present an application of the hierarchical hmm for structure discovery in <br>educational videos. The hhmm has recently been extended to accommodate the concept of <br>shared structure, ie: a state might multiply inherit from more than one parents. Utilising the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=341392741241729246&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:3jCcruPevAQJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/16/52/RN154307185.html?source=googlescholar" class="gs_nph" class=yC19>BL Direct</a> <a href="/scholar?cluster=341392741241729246&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'3jCcruPevAQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://www.computing.edu.au/~phung/wiki_new/uploads/Main/Phung_el_tr05.ps" class=yC1B><span class="gs_ggsL"><span class=gs_ctg2>[PS]</span> from computing.edu.au</span><span class="gs_ggsS">computing.edu.au <span class=gs_ctg2>[PS]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PS]</span><span class="gs_ct2">[PS]</span></span> <a href="http://www.computing.edu.au/~phung/wiki_new/uploads/Main/Phung_el_tr05.ps" class=yC1A>Structural unit identification and segmentation of topical content in educational videos</a></h3><div class="gs_a"><a href="/citations?user=OtA9SwIAAAAJ&amp;hl=en&amp;oi=sra">DQ Phung</a>, <a href="/citations?user=AEkRUQcAAAAJ&amp;hl=en&amp;oi=sra">S Venkatesh</a> - computing.edu.au</div><div class="gs_rs">AbstractâAutomatically structuralising educational video is a challenging problem for <br>efficient content management and cataloging in E-learning environments. This paper <br>addresses this problem and aims to achieve two objectives. First, we propose a hierarchy <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12207634180899072347&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:W-ln1Js6aqkJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12207634180899072347&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'W-ln1Js6aqkJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md12', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md12" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:W-ln1Js6aqkJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/icme02-lekha.pdf" class=yC1D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/icme02-lekha.pdf" class=yC1C>THE SEGMENTATION OF NEWS VIDEO INTO STORY UNITS</a></h3><div class="gs_a">LCTS Chua - 137.132.145.151</div><div class="gs_rs">The segmentation of news video into single-story semantic units is a challenging problem. <br>This research proposes a twolevel, multi-modal framework to tackle this problem. The video <br>is analyzed at the shot and story unit (or scene) levels using a variety of features and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:I0iaR7YY_H8J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'I0iaR7YY_H8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://dro.deakin.edu.au/eserv/DU:30044633/venkatesh-automaticallylearning-2004.pdf" class=yC1F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from deakin.edu.au</span><span class="gs_ggsS">deakin.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1421375" class=yC1E>Automatically learning structural units in educational videos with the hierarchical hidden Markov models</a></h3><div class="gs_a"><a href="/citations?user=OtA9SwIAAAAJ&amp;hl=en&amp;oi=sra">DQ Phung</a>, <a href="/citations?user=AEkRUQcAAAAJ&amp;hl=en&amp;oi=sra">S Venkatesh</a>, <a href="/citations?user=mDLwSZAAAAAJ&amp;hl=en&amp;oi=sra">HH Bui</a> - Image Processing, 2004.  &hellip;, 2004 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper we present a coherent approach using the hierarchical HMM with <br>shared structures to extract the structural units form the building blocks of an <br>education/training video. Rather than using hand-crafted approaches to define the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:iGmLmuQjs4MJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9489968304552110472&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'iGmLmuQjs4MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://www.ideanest.com/videobench/Report.doc" class=yC21><span class="gs_ggsL"><span class=gs_ctg2>[DOC]</span> from ideanest.com</span><span class="gs_ggsS">ideanest.com <span class=gs_ctg2>[DOC]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[DOC]</span><span class="gs_ct2">[DOC]</span></span> <a href="http://www.ideanest.com/videobench/Report.doc" class=yC20>Video Bench</a></h3><div class="gs_a">J Chisan, J Cockburn, R Garner, A Jazayeri&hellip; - ideanest.com</div><div class="gs_rs">1. Background Film and video editing is hardly a new art. Without delving overmuch into <br>history, this section describes the operation of a handful of industrial video editing systems, <br>and presents some of the research in this area and other relevant fields.</div><div class="gs_fl"><a href="/scholar?q=related:ldxbtiF7s10J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'ldxbtiF7s10J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md15', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md15" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:ldxbtiF7s10J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://lms.comp.nus.edu.sg/papers/media/2002/icme02-lekha.pdf" class=yC23><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://lms.comp.nus.edu.sg/papers/media/2002/icme02-lekha.pdf" class=yC22>THE SEGMENTATION OF NEWS VIDEO INTO STORY UNITS</a></h3><div class="gs_a">LCTSC Chin, H Lee - lms.comp.nus.edu.sg</div><div class="gs_rs">The effective management of the ever-increasing amount of broadcast news video is <br>essential to support a variety of useroriented functions, including the browsing, retrieval and <br>personalization of news video. One effective way to organize video is to segment it into <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:8pSS5jUvhfsJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18123944183970567410&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'8pSS5jUvhfsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
