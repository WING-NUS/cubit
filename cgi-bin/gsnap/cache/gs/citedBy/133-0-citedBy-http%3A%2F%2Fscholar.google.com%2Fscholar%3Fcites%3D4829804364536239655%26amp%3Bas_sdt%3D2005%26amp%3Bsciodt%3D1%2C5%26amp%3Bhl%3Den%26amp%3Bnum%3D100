Total results = 133
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://cs.utsa.edu/~qitian/seminar/Fall10/09_24_10/ICCV09.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from utsa.edu</span><span class="gs_ggsS">utsa.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5459432" class=yC0>Landmark classification in large-scale image collections</a></h3><div class="gs_a"><a href="/citations?user=2vaDEYAAAAAJ&amp;hl=en&amp;oi=sra">Y Li</a>, <a href="/citations?user=8bQRH5YAAAAJ&amp;hl=en&amp;oi=sra">DJ Crandall</a>&hellip; - Computer Vision, 2009  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract With the rise of photo-sharing websites such as Facebook and Flickr has come <br>dramatic growth in the number of photographs online. Recent research in object recognition <br>has used such sites as a source of image data, but the test images have been selected <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9452140750300662136&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 61</a> <a href="/scholar?q=related:eEmqzO6_LIMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9452140750300662136&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'eEmqzO6_LIMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://www.stanford.edu/~aanjneya/mridul_files/papers/image_webs.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from stanford.edu</span><span class="gs_ggsS">stanford.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5539991" class=yC2>Image webs: Computing and exploiting connectivity in image collections</a></h3><div class="gs_a">K Heath, N Gelfand, <a href="/citations?user=0IsSPNEAAAAJ&amp;hl=en&amp;oi=sra">M Ovsjanikov</a>&hellip; - Computer Vision and &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The widespread availability of digital cameras and ubiquitous Internet access have <br>facilitated the creation of massive image collections. These collections can be highly <br>interconnected through implicit links between image pairs viewing the same or similar <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5660115619391276442&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 37</a> <a href="/scholar?q=related:mgV10SrFjE4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5660115619391276442&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'mgV10SrFjE4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://wwwconference.org/proceedings/www2010/www/p401.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from wwwconference.org</span><span class="gs_ggsS">wwwconference.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1772732" class=yC4>Equip tourists with knowledge mined from travelogues</a></h3><div class="gs_a"><a href="/citations?user=WxAtmSEAAAAJ&amp;hl=en&amp;oi=sra">Q Hao</a>, <a href="/citations?user=6WCyi64AAAAJ&amp;hl=en&amp;oi=sra">R Cai</a>, C Wang, <a href="/citations?user=Zb5wT08AAAAJ&amp;hl=en&amp;oi=sra">R Xiao</a>, <a href="/citations?user=mhw3i-EAAAAJ&amp;hl=en&amp;oi=sra">JM Yang</a>&hellip; - Proceedings of the 19th &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract With the prosperity of tourism and Web 2.0 technologies, more and more people <br>have willingness to share their travel experiences on the Web (eg, weblogs, forums, or Web <br>2.0 communities). These so-called travelogues contain rich information, particularly <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9105049711506817953&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 34</a> <a href="/scholar?q=related:oQOj1HiiW34J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9105049711506817953&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'oQOj1HiiW34J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://cvlab-9.epfl.ch/~yunli/publications/papers/localization_eccv2010.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from epfl.ch</span><span class="gs_ggsS">epfl.ch <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/u71701621l917222.pdf" class=yC6>Location recognition using prioritized feature matching</a></h3><div class="gs_a"><a href="/citations?user=2vaDEYAAAAAJ&amp;hl=en&amp;oi=sra">Y Li</a>, <a href="/citations?user=Db4BCX8AAAAJ&amp;hl=en&amp;oi=sra">N Snavely</a>, <a href="/citations?user=q16KVs0AAAAJ&amp;hl=en&amp;oi=sra">D Huttenlocher</a> - Computer VisionâECCV 2010, 2010 - Springer</div><div class="gs_rs">We present a fast, simple location recognition and image localization method that leverages <br>feature correspondence and geometry estimated from large Internet photo collections. Such <br>recovered structure contains a significant amount of useful information about images and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1260948008864147266&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 36</a> <a href="/scholar?q=related:QmeVhIjJfxEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1260948008864147266&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'QmeVhIjJfxEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.citeulike.org/group/12430/article/8766290" class=yC8>Cluster-based landmark and event detection on tagged photo collections</a></h3><div class="gs_a"><a href="/citations?user=GuhyORoAAAAJ&amp;hl=en&amp;oi=sra">S Papadopoulos</a>, C Zigkolis, <a href="/citations?user=Nr7smP8AAAAJ&amp;hl=en&amp;oi=sra">Y Kompatsiaris</a>&hellip; - IEEE Multimedia, 2010 - citeulike.org</div><div class="gs_rs">Abstract The massive amounts of pictorial content that is generated and uploaded online in <br>Social Web applications, such as Flickr, raises the need for automated content organization <br>techniques in order to improve retrieval and browsing within very large image collections. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2690665928297559296&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 26</a> <a href="/scholar?q=related:ADVs8WcqVyUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2690665928297559296&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'ADVs8WcqVyUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md4', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md4" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:ADVs8WcqVyUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://jmyang.info/papers/mm_2010_photo2trip.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from jmyang.info</span><span class="gs_ggsS">jmyang.info <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1873972" class=yC9>Photo2trip: generating travel routes from geo-tagged photos for trip planning</a></h3><div class="gs_a">X Lu, C Wang, <a href="/citations?user=mhw3i-EAAAAJ&amp;hl=en&amp;oi=sra">JM Yang</a>, Y Pang, <a href="/citations?user=fIlGZToAAAAJ&amp;hl=en&amp;oi=sra">L Zhang</a> - Proceedings of the  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract Travel route planning is an important step for a tourist to prepare his/her trip. As a <br>common scenario, a tourist usually asks the following questions when he/she is planning <br>his/her trip in an unfamiliar place: 1) Are there any travel route suggestions for a one-day <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10496334267532823773&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 29</a> <a href="/scholar?q=related:3cwNhGd4qpEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10496334267532823773&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'3cwNhGd4qpEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://www.cse.wustl.edu/~kilian/papers/wsmc2009-specificity.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from wustl.edu</span><span class="gs_ggsS">wustl.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1631139" class=yCB>Reliable tags using image similarity: mining specificity and expertise from large-scale multimedia databases</a></h3><div class="gs_a">L Kennedy, M Slaney, <a href="/citations?user=jsxk8vsAAAAJ&amp;hl=en&amp;oi=sra">K Weinberger</a> - &hellip;  of the 1st workshop on Web- &hellip;, 2009 - dl.acm.org</div><div class="gs_rs">Abstract This paper describes an approach for finding image descriptors or tags that are <br>highly reliable and specific. Reliable, in this work, means that the tags are related to the <br>image&#39;s visual content, which we verify by finding two or more real people who agree that <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12082211675241529115&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 19</a> <a href="/scholar?q=related:Gz_ZG4GjrKcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12082211675241529115&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'Gz_ZG4GjrKcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1873973" class=yCD>Retrieving landmark and non-landmark images from community photo collections</a></h3><div class="gs_a"><a href="/citations?user=AF2SxG0AAAAJ&amp;hl=en&amp;oi=sra">Y Avrithis</a>, <a href="/citations?user=QJZQgN8AAAAJ&amp;hl=en&amp;oi=sra">Y Kalantidis</a>, <a href="/citations?user=e765N80AAAAJ&amp;hl=en&amp;oi=sra">G Tolias</a>, <a href="/citations?user=oc3UFyMAAAAJ&amp;hl=en&amp;oi=sra">E Spyrou</a> - Proceedings of the  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract State of the art data mining and image retrieval in community photo collections <br>typically focus on popular subsets, eg images containing landmarks or associated to <br>Wikipedia articles. We propose an image clustering scheme that, seen as vector <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18244330247050681542&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 20</a> <a href="/scholar?q=related:xtxedLLhMP0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'xtxedLLhMP0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="https://www1.ethz.ch/igp/photogrammetry/education/lehrveranstaltungen/PCV_HS12/content_folder/PCV-HS2012-paper-snavely-communityphoto.pdf" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ethz.ch</span><span class="gs_ggsS">ethz.ch <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5483186" class=yCE>Scene reconstruction and visualization from community photo collections</a></h3><div class="gs_a"><a href="/citations?user=Db4BCX8AAAAJ&amp;hl=en&amp;oi=sra">N Snavely</a>, <a href="/citations?user=pKqwl3wAAAAJ&amp;hl=en&amp;oi=sra">I Simon</a>, <a href="/citations?user=56UhAooAAAAJ&amp;hl=en&amp;oi=sra">M Goesele</a>&hellip; - Proceedings of the  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract There are billions of photographs on the Internet, representing an extremely large, <br>rich, and nearly comprehensive visual record of virtually every famous place on Earth. <br>Unfortunately, these massive community photo collections are almost completely <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17375258463020506650&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 21</a> <a href="/scholar?q=related:Gt7vmINRIfEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17375258463020506650&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'Gt7vmINRIfEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://www.eurecom.fr/~troncy/Publications/Troncy-icmr11.pdf" class=yC11><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from eurecom.fr</span><span class="gs_ggsS">eurecom.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1992054" class=yC10>Finding media illustrating events</a></h3><div class="gs_a"><a href="/citations?user=-BFEdeMAAAAJ&amp;hl=en&amp;oi=sra">X Liu</a>, <a href="/citations?user=1BxhcigAAAAJ&amp;hl=en&amp;oi=sra">R Troncy</a>, <a href="/citations?user=KdPSGmAAAAAJ&amp;hl=en&amp;oi=sra">B Huet</a> - Proceedings of the 1st ACM International  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract We present a method combining semantic inferencing and visual analysis for <br>finding automatically media (photos and videos) illustrating events. We report on <br>experiments validating our heuristic for mining media sharing platforms and large event <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4393278562019656302&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 20</a> <a href="/scholar?q=related:bkKFWJMP-DwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4393278562019656302&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'bkKFWJMP-DwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://lms.comp.nus.edu.sg/papers/media/2010/mm10-gaoyue.pdf" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1873970" class=yC12>W2go: a travel guidance system by automatic landmark ranking</a></h3><div class="gs_a">Y Gao, <a href="/citations?user=ByBLlEwAAAAJ&amp;hl=en&amp;oi=sra">J Tang</a>, <a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, Q Dai, TS Chua&hellip; - Proceedings of the  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we present a travel guidance system W2Go (Where to Go), which can <br>automatically recognize and rank the landmarks for travellers. In this system, a novel <br>Automatic Landmark Ranking (ALR) method is proposed by utilizing the tag and geo-tag <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14138977723431265510&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 20</a> <a href="/scholar?q=related:5iRI9FO9N8QJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14138977723431265510&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'5iRI9FO9N8QJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="https://www.informatik.uni-augsburg.de/de/lehrstuehle/mmc/publications/reports/MMC27/TR-2011-07.pdf" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uni-augsburg.de</span><span class="gs_ggsS">uni-augsburg.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1743402" class=yC14>Multimodal ranking for image search on community databases</a></h3><div class="gs_a">F Richter, S Romberg, E HÃ¶rster&hellip; - Proceedings of the  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract Searching for relevant images given a query term is an important task in nowadays <br>large-scale community databases. The image ranking approach presented in this work <br>represents an image collection as a graph that is built using a multimodal similarity <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16211534966080976531&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 15</a> <a href="/scholar?q=related:k7YUxSjx-uAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16211534966080976531&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'k7YUxSjx-uAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/418R5103V3Q12986.pdf" class=yC16>Geotagging in multimedia and computer visionâa survey</a></h3><div class="gs_a"><a href="/citations?user=CcbnBvgAAAAJ&amp;hl=en&amp;oi=sra">J Luo</a>, <a href="/citations?user=TYmV4V8AAAAJ&amp;hl=en&amp;oi=sra">D Joshi</a>, J Yu, <a href="/citations?user=-RFj-kYAAAAJ&amp;hl=en&amp;oi=sra">A Gallagher</a> - Multimedia Tools and Applications, 2011 - Springer</div><div class="gs_rs">Abstract Geo-tagging is a fast-emerging trend in digital photography and community photo <br>sharing. The presence of geographically relevant metadata with images and videos has <br>opened up interesting research avenues within the multimedia and computer vision <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9460450507726227898&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 22</a> <a href="/scholar?q=related:uokv-JxFSoMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9460450507726227898&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'uokv-JxFSoMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://bib.dbvis.de/uploadedFiles/17.pdf" class=yC18><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from dbvis.de</span><span class="gs_ggsS">dbvis.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1823897" class=yC17>P-DBSCAN: a density based clustering algorithm for exploration and analysis of attractive areas using collections of geo-tagged photos</a></h3><div class="gs_a">S Kisilevich, <a href="/citations?user=_r0VrR8AAAAJ&amp;hl=en&amp;oi=sra">F Mansmann</a>, D Keim - Proceedings of the 1st International  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract The rapid spread of location-based devices and cheap storage mechanisms, as <br>well as fast development of Internet technology, allowed collection and distribution of huge <br>amounts of user-generated data, such as people&#39;s movement or geo-tagged photos. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3790247128455125162&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 14</a> <a href="/scholar?q=related:qhiDhq6pmTQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3790247128455125162&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'qhiDhq6pmTQJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md13', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md13" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:qhiDhq6pmTQJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=1452617973353425983&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="https://oda.hio.no/jspui/bitstream/10642/517/2/543484post.pdf" class=yC1A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hio.no</span><span class="gs_ggsS">hio.no <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/W23478Q1N7V7Q718.pdf" class=yC19>Where was that photo taken? Deriving geographical information from image collections based on temporal exposure attributes</a></h3><div class="gs_a"><a href="/citations?user=N9OuegkAAAAJ&amp;hl=en&amp;oi=sra">FE Sandnes</a> - Multimedia systems, 2010 - Springer</div><div class="gs_rs">Abstract This paper demonstrates a novel strategy for inferring approximate geographical <br>information from the exposure information and temporal patterns of outdoor images in image <br>collections. Image exposure is reliant on light and most photographs are therefore taken in <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8403849716736900519&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 14</a> <a href="/scholar?q=related:p73et8p4oHQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8403849716736900519&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'p73et8p4oHQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://comminfo.rutgers.edu/~mor/publications/NaamanMTAP10socialMultimedia.pdf" class=yC1C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from rutgers.edu</span><span class="gs_ggsS">rutgers.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/V836432078K27014.pdf" class=yC1B>Social multimedia: highlighting opportunities for search and mining of multimedia data in social media applications</a></h3><div class="gs_a"><a href="/citations?user=IeqjwlIAAAAJ&amp;hl=en&amp;oi=sra">M Naaman</a> - Multimedia Tools and Applications, 2012 - Springer</div><div class="gs_rs">Abstract In recent years, various Web-based sharing and community services such as Flickr <br>and YouTube have made a vast and rapidly growing amount of multimedia content available <br>online. Uploaded by individual participants, content in these immense pools of content is <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10786183381739155064&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 13</a> <a href="/scholar?q=related:eK7IVqM4sJUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10786183381739155064&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'eK7IVqM4sJUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://research.microsoft.com/en-us/um/people/yongrui/ps/11IJCV_Lingyu.pdf" class=yC1E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from microsoft.com</span><span class="gs_ggsS">microsoft.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/T61403X16L0340V3.pdf" class=yC1D>Location discriminative vocabulary coding for mobile landmark search</a></h3><div class="gs_a"><a href="/citations?user=lRSD7PQAAAAJ&amp;hl=en&amp;oi=sra">R Ji</a>, LY Duan, J Chen, H Yao, J Yuan, <a href="/citations?user=uOJH_AEAAAAJ&amp;hl=en&amp;oi=sra">Y Rui</a>&hellip; - International journal of  &hellip;, 2012 - Springer</div><div class="gs_rs">Abstract With the popularization of mobile devices, recent years have witnessed an <br>emerging potential for mobile landmark search. In this scenario, the user experience heavily <br>depends on the efficiency of query transmission over a wireless link. As sending a query <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17314084196907029199&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 16</a> <a href="/scholar?q=related:zxLZ19f7R_AJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17314084196907029199&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'zxLZ19f7R_AJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/543M12LP54H23360.pdf" class=yC1F>Viral: Visual image retrieval and localization</a></h3><div class="gs_a"><a href="/citations?user=QJZQgN8AAAAJ&amp;hl=en&amp;oi=sra">Y Kalantidis</a>, <a href="/citations?user=e765N80AAAAJ&amp;hl=en&amp;oi=sra">G Tolias</a>, <a href="/citations?user=AF2SxG0AAAAJ&amp;hl=en&amp;oi=sra">Y Avrithis</a>, M Phinikettos&hellip; - Multimedia Tools and  &hellip;, 2011 - Springer</div><div class="gs_rs">Abstract New applications are emerging every day exploiting the huge data volume in <br>community photo collections. Most focus on popular subsets, eg, images containing <br>landmarks or associated to Wikipedia articles. In this work we are concerned with the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16892044061664725739&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 11</a> <a href="/scholar?q=related:68rFgZOYbOoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16892044061664725739&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'68rFgZOYbOoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB18" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW18"><a href="http://kusu.comp.nus.edu/proceedings/mm09/ls-mmrm/p81.pdf" class=yC21><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu</span><span class="gs_ggsS">nus.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://kusu.comp.nus.edu/proceedings/mm09/ls-mmrm/p81.pdf" class=yC20>Unsupervised image ranking</a></h3><div class="gs_a">E HÃ¶rster, M Slaney, <a href="/citations?user=NbXF7T8AAAAJ&amp;hl=en&amp;oi=sra">M Ranzato</a>&hellip; - Proceedings of the  &hellip;, 2009 - kusu.comp.nus.edu</div><div class="gs_rs">ABSTRACT In the paper, we propose and test an unsupervised approach for image ranking. <br>Prior solutions are based on image content and the similarity graph connecting images. We <br>generalize this idea by directly estimating the likelihood of each photo in a feature space. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4504531819595638284&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 9</a> <a href="/scholar?q=related:DCZx6tJPgz4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4504531819595638284&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'DCZx6tJPgz4J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md18', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md18" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:DCZx6tJPgz4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="https://www.cs.unc.edu/~rraguram/papers/ISPRS2010.pdf" class=yC23><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unc.edu</span><span class="gs_ggsS">unc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0924271610000833" class=yC22>Fast robust large-scale mapping from video and internet photo collections</a></h3><div class="gs_a"><a href="/citations?user=3YOe4NMAAAAJ&amp;hl=en&amp;oi=sra">JM Frahm</a>, <a href="/citations?user=YYH0BjEAAAAJ&amp;hl=en&amp;oi=sra">M Pollefeys</a>, <a href="/citations?user=xKOEaRoAAAAJ&amp;hl=en&amp;oi=sra">S Lazebnik</a>, <a href="/citations?user=W51KTpcAAAAJ&amp;hl=en&amp;oi=sra">D Gallup</a>&hellip; - ISPRS Journal of  &hellip;, 2010 - Elsevier</div><div class="gs_rs">This paper presents a system approaching fully automatic 3D modeling of large-scale <br>environments. Our system takes as input either a video stream or collection of photographs <br>obtained from Internet photo sharing web-sites such as Flickr. The system achieves high <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17421032244697986236&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 9</a> <a href="/scholar?q=related:vHTZpYbww_EJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17421032244697986236&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 17 versions</a> <a onclick="return gs_ocit(event,'vHTZpYbww_EJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S1077314210002419" class=yC24>Summarizing tourist destinations by mining user-generated travelogues and photos</a></h3><div class="gs_a">Y Pang, <a href="/citations?user=WxAtmSEAAAAJ&amp;hl=en&amp;oi=sra">Q Hao</a>, Y Yuan, T Hu, R Cai, <a href="/citations?user=fIlGZToAAAAJ&amp;hl=en&amp;oi=sra">L Zhang</a> - Computer Vision and  &hellip;, 2011 - Elsevier</div><div class="gs_rs">Automatically summarizing tourist destinations with both textual and visual descriptions is <br>highly desired for online services such as travel planning, to facilitate users to understand <br>the local characteristics of tourist destinations. Travelers are contributing a great deal of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16328412154120321787&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 11</a> <a href="/scholar?q=related:-zqDsFcsmuIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16328412154120321787&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'-zqDsFcsmuIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="https://oda.hio.no/jspui/bitstream/10642/1092/1/846820post.pdf" class=yC26><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hio.no</span><span class="gs_ggsS">hio.no <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/W71444Q414322248.pdf" class=yC25>Determining the geographical location of image scenes based on object shadow lengths</a></h3><div class="gs_a"><a href="/citations?user=N9OuegkAAAAJ&amp;hl=en&amp;oi=sra">FE Sandnes</a> - Journal of Signal Processing Systems, 2011 - Springer</div><div class="gs_rs">Abstract Many studies have addressed various applications of geo-spatial image tagging <br>such as image retrieval, image organisation and browsing. Geo-spatial image tagging can <br>be done manually or automatically with GPS enabled cameras that allow the current <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2882363066942080410&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 6</a> <a href="/scholar?q=related:msXJHvA1ACgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2882363066942080410&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'msXJHvA1ACgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/pdf/10.1007/s11042-010-0553-8" class=yC27>Inferring photographic location using geotagged web images</a></h3><div class="gs_a"><a href="/citations?user=TYmV4V8AAAAJ&amp;hl=en&amp;oi=sra">D Joshi</a>, <a href="/citations?user=-RFj-kYAAAAJ&amp;hl=en&amp;oi=sra">A Gallagher</a>, J Yu, <a href="/citations?user=CcbnBvgAAAAJ&amp;hl=en&amp;oi=sra">J Luo</a> - Multimedia Tools and Applications, 2012 - Springer</div><div class="gs_rs">Abstract Geotagging has become a recent phenomenon that allows users to visualize and <br>manage photo collections in many new and interesting ways. Unfortunately, manual <br>geotagging of a large collection of pictures on the globe is still a time-consuming and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15245776365906745368&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 8</a> <a href="/scholar?q=related:GNjqRtTgk9MJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15245776365906745368&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'GNjqRtTgk9MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB23" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW23"><a href="http://downloads.hindawi.com/journals/mpe/2012/856523.pdf" class=yC29><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hindawi.com</span><span class="gs_ggsS">hindawi.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.hindawi.com/journals/mpe/2012/856523/abs/" class=yC28>Key issues in modeling of complex 3D structures from video sequences</a></h3><div class="gs_a">S Chen, Y Wang, C Cattani - Mathematical Problems in Engineering, 2011 - hindawi.com</div><div class="gs_rs">Construction of three-dimensional structures from video sequences has wide applications <br>for intelligent video analysis. This paper summarizes the key issues of the theory and <br>surveys the recent advances in the state of the art. Reconstruction of a scene object from <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16943028265025707035&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 22</a> <a href="/scholar?q=related:G5xCZHC6IesJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16943028265025707035&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'G5xCZHC6IesJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md23', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md23" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:G5xCZHC6IesJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6126361" class=yC2A>Discovering favorite views of popular places with iconoid shift</a></h3><div class="gs_a"><a href="/citations?user=US56Kw8AAAAJ&amp;hl=en&amp;oi=sra">T Weyand</a>, <a href="/citations?user=ZcULDB0AAAAJ&amp;hl=en&amp;oi=sra">B Leibe</a> - Computer Vision (ICCV), 2011 IEEE  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose a novel algorithm for automatic landmark building <br>discovery in large, unstructured image collections. In contrast to other approaches which aim <br>at a hard clustering, we regard the task as a mode estimation problem. Our algorithm <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13390943128527092359&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 6</a> <a href="/scholar?q=related:h7pQv9Mv1rkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13390943128527092359&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'h7pQv9Mv1rkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB25" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW25"><a href="http://www.nmis.isti.cnr.it/falchi/publications/Falchi-2010-MMEDIA.pdf" class=yC2C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cnr.it</span><span class="gs_ggsS">cnr.it <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5501609" class=yC2B>Recognizing Landmarks Using Automated Classification Techniques: Evaluation of Various Visual Features</a></h3><div class="gs_a">G Amato, <a href="/citations?user=4Vr1dSQAAAAJ&amp;hl=en&amp;oi=sra">F Falchi</a>, P Bolettieri - Advances in Multimedia ( &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, the performance of several visual features is evaluated in <br>automatically recognizing landmarks (monuments, statues, buildings, etc.) in pictures. A <br>number of landmarks were selected for the test. Pictures taken from a test set were <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15786296839038889225&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 9</a> <a href="/scholar?q=related:Ce3I8VUxFNsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15786296839038889225&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'Ce3I8VUxFNsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB26" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW26"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.174.8583&amp;rep=rep1&amp;type=pdf" class=yC2E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1874302" class=yC2D>ClustTour: city exploration by use of hybrid photo clustering</a></h3><div class="gs_a"><a href="/citations?user=GuhyORoAAAAJ&amp;hl=en&amp;oi=sra">S Papadopoulos</a>, C Zigkolis, S Kapiris&hellip; - Proceedings of the  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract We present a technical demonstration of an online city exploration application that <br>helps users identify interesting spots in a city by use of photo clusters corresponding to <br>landmarks and events. Our application, called ClustTour, is based on an efficient <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10620061529375846577&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 5</a> <a href="/scholar?q=related:sTA9h7EJYpMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10620061529375846577&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'sTA9h7EJYpMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB27" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW27"><a href="https://nzdis.org/projects/attachments/download/324/makadia10eccv.pdf" class=yC30><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nzdis.org</span><span class="gs_ggsS">nzdis.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/U6837830K76447QP.pdf" class=yC2F>Feature tracking for wide-baseline image retrieval</a></h3><div class="gs_a">A Makadia - Computer VisionâECCV 2010, 2010 - Springer</div><div class="gs_rs">We address the problem of large scale image retrieval in a wide-baseline setting, where for <br>any query image all the matching database images will come from very different viewpoints. <br>In such settings traditional bag-of-visual-words approaches are not equipped to handle <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12822885840310424551&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 6</a> <a href="/scholar?q=related:59MWs7sK9LEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12822885840310424551&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'59MWs7sK9LEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB28" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW28"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/ZhaZJ_C01_Mining%20Travel%20Patterns%20from%20GPS-Tagged%20Photos.pdf" class=yC32><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/Q81M3X5314LX524Q.pdf" class=yC31>Mining travel patterns from GPS-tagged photos</a></h3><div class="gs_a">YT Zheng, Y Li, ZJ Zha, TS Chua - Advances in Multimedia Modeling, 2011 - Springer</div><div class="gs_rs">The phenomenal advances of photo-sharing services, such as Flickr TM, have led to <br>voluminous community-contributed photos with socially generated textual, temporal and <br>geographical metadata on the Internet. The photos, together with their time-and geo-<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17511605319113938690&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 5</a> <a href="/scholar?q=related:Apeg3EG4BfMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17511605319113938690&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'Apeg3EG4BfMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2072372" class=yC33>Towards low bit rate mobile visual search with multiple-channel coding</a></h3><div class="gs_a"><a href="/citations?user=lRSD7PQAAAAJ&amp;hl=en&amp;oi=sra">R Ji</a>, LY Duan, J Chen, H Yao, <a href="/citations?user=uOJH_AEAAAAJ&amp;hl=en&amp;oi=sra">Y Rui</a>&hellip; - Proceedings of the 19th &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we propose a multiple-channel coding scheme to extract compact <br>visual descriptors for low bit rate mobile visual search. Different from previous visual search <br>scenarios that send the query image, we make use of the ever growing mobile <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15388005700890529107&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 11</a> <a href="/scholar?q=related:Uw1E46ctjdUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Uw1E46ctjdUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB30" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW30"><a href="http://weegee.vision.ucmerced.edu/papers/Newsam_IEEEMult10_Crowdsourcing.pdf" class=yC35><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ucmerced.edu</span><span class="gs_ggsS">ucmerced.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://weegee.vision.ucmerced.edu/papers/Newsam_IEEEMult10_Crowdsourcing.pdf" class=yC34>Knowledge Discovery from Community-Contributed Multimedia</a></h3><div class="gs_a">S Newsam - 2010 - weegee.vision.ucmerced.edu</div><div class="gs_rs">1070-986X/10/$26.00 c 2010 IEEE Published by the IEEE Computer Society 36 as Figure <br>1a (next page) shows. This is particularly useful for images captured using GPS-enabled <br>cameras, as the system-generated annotations allow the images to be organized and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11521838955049178325&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 5</a> <a href="/scholar?q=related:1dT2-nvL5Z8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11521838955049178325&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'1dT2-nvL5Z8J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md30', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md30" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:1dT2-nvL5Z8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB31" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW31"><a href="http://www.nmis.isti.cnr.it/falchi/publications/Falchi-2010-SISAP.pdf" class=yC37><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cnr.it</span><span class="gs_ggsS">cnr.it <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1862360" class=yC36>kNN based image classification relying on local feature similarity</a></h3><div class="gs_a">G Amato, <a href="/citations?user=4Vr1dSQAAAAJ&amp;hl=en&amp;oi=sra">F Falchi</a> - Proceedings of the Third International Conference on &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we propose a novel image classification approach, derived from the <br>kNN classification strategy, that is particularly suited to be used when classifying images <br>described by local features. Our proposal relies on the possibility of performing similarity <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4860395941497393192&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 5</a> <a href="/scholar?q=related:KNCzeFuYc0MJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4860395941497393192&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'KNCzeFuYc0MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1992061" class=yC38>City exploration by use of spatio-temporal analysis and clustering of user contributed photos</a></h3><div class="gs_a"><a href="/citations?user=GuhyORoAAAAJ&amp;hl=en&amp;oi=sra">S Papadopoulos</a>, C Zigkolis, S Kapiris&hellip; - Proceedings of the 1st  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract We present a technical demonstration of an online city exploration application that <br>helps users identify interesting spots in a city by use of spatio-temporal analysis and <br>clustering of user contributed photos. Our framework analyzes the spatial distribution of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2739688447138508924&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 4</a> <a href="/scholar?q=related:fLDujiBUBSYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'fLDujiBUBSYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:367"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB33" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW33"><a href="http://cs.unc.edu/~lazebnik/publications/ijcv09.pdf" class=yC3A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unc.edu</span><span class="gs_ggsS">unc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/23J2Q075Q622113M.pdf" class=yC39>Modeling and recognition of landmark image collections using iconic scene graphs</a></h3><div class="gs_a"><a href="/citations?user=iHJLHq8AAAAJ&amp;hl=en&amp;oi=sra">R Raguram</a>, <a href="/citations?user=XPIelF0AAAAJ&amp;hl=en&amp;oi=sra">C Wu</a>, <a href="/citations?user=3YOe4NMAAAAJ&amp;hl=en&amp;oi=sra">JM Frahm</a>, <a href="/citations?user=xKOEaRoAAAAJ&amp;hl=en&amp;oi=sra">S Lazebnik</a> - International journal of  &hellip;, 2011 - Springer</div><div class="gs_rs">Abstract This article presents an approach for modeling landmarks based on large-scale, <br>heavily contaminated image collections gathered from the Internet. Our system efficiently <br>combines 2D appearance and 3D geometric constraints to extract scene summaries and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10620367391603263567&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 4</a> <a href="/scholar?q=related:T4inoN8fY5MJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10620367391603263567&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'T4inoN8fY5MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:366"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB34" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW34"><a href="http://tev.fbk.eu/marmota/files/cvmp2009.pdf" class=yC3C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from fbk.eu</span><span class="gs_ggsS">fbk.eu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5430065" class=yC3B>Collective photography</a></h3><div class="gs_a">P Chippendale, <a href="/citations?user=0YpxMN4AAAAJ&amp;hl=en&amp;oi=sra">M Zanin</a>&hellip; - Visual Media Production,  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper offers the reader an insight into how photography and home video <br>production could evolve in the near future through the evolution of geo-tagging (adding <br>location and orientation parameters to an object). Technological advances in portable <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4082306026740748176&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 4</a> <a href="/scholar?q=related:kI9RzLNDpzgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4082306026740748176&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'kI9RzLNDpzgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:365"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB35" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW35"><a href="https://oda.hio.no/jspui/bitstream/10642/496/2/543513RED.pdf" class=yC3E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hio.no</span><span class="gs_ggsS">hio.no <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5551803" class=yC3D>Unsupervised and fast continent classification of digital image collections using time</a></h3><div class="gs_a"><a href="/citations?user=N9OuegkAAAAJ&amp;hl=en&amp;oi=sra">FE Sandnes</a> - System Science and Engineering (ICSSE), 2010  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Advances in storage capacity means that digital cameras can store huge collections <br>of digital photographs. Typically such images are given non-descriptive filenames names <br>such as a unique identifier, often an integer. Consequently it is time-consuming and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16308752372374545635&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 3</a> <a href="/scholar?q=related:46QxDeBTVOIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16308752372374545635&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'46QxDeBTVOIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:364"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/3GHP84T317G10Q23.pdf" class=yC3F>Architectural style classification of building facade windows</a></h3><div class="gs_a">G Shalunts, <a href="/citations?user=3SzlfM0AAAAJ&amp;hl=en&amp;oi=sra">Y Haxhimusa</a>, R Sablatnig - Advances in Visual Computing, 2011 - Springer</div><div class="gs_rs">Building facade classification by architectural styles allows categorization of large databases <br>of building images into semantic categories belonging to certain historic periods, regions <br>and cultural influences. Image databases sorted by architectural styles permit effective <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18153675331542324637&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 3</a> <a href="/scholar?q=related:nRVaIIjP7vsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18153675331542324637&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'nRVaIIjP7vsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:363"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB37" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW37"><a href="ftp://ftp.esat.kuleuven.ac.be/pub/psi/visics/tingdahl/publications/gammeter_eccv_2010.pdf" class=yC41><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from kuleuven.ac.be</span><span class="gs_ggsS">kuleuven.ac.be <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/W6K437386R005J66.pdf" class=yC40>Size does matter: improving object recognition and 3D reconstruction with cross-media analysis of image clusters</a></h3><div class="gs_a">S Gammeter, <a href="/citations?user=D3xWHUUAAAAJ&amp;hl=en&amp;oi=sra">T Quack</a>, D Tingdahl&hellip; - Computer VisionâECCV  &hellip;, 2010 - Springer</div><div class="gs_rs">Most of the recent work on image-based object recognition and 3D reconstruction has <br>focused on improving the underlying algorithms. In this paper we present a method to <br>automatically improve the quality of the reference database, which, as we will show, also <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2755831343182640495&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 3</a> <a href="/scholar?q=related:b_VJbwGuPiYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2755831343182640495&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'b_VJbwGuPiYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:362"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB38" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW38"><a href="http://infoscience.epfl.ch/record/149438/files/Ivanov_201201_MTAP2012.pdf?version=1" class=yC43><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from epfl.ch</span><span class="gs_ggsS">epfl.ch <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/pdf/10.1007/s11042-010-0570-7" class=yC42>Geotag propagation in social networks based on user trust model</a></h3><div class="gs_a">I Ivanov, P Vajda, JS Lee, L Goldmann&hellip; - Multimedia Tools and  &hellip;, 2012 - Springer</div><div class="gs_rs">Abstract In the past few years sharing photos within social networks has become very <br>popular. In order to make these huge collections easier to explore, images are usually <br>tagged with representative keywords such as persons, events, objects, and locations. In <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18250001085666785318&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 7</a> <a href="/scholar?q=related:JnipdUsHRf0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18250001085666785318&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'JnipdUsHRf0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:361"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB39" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW39"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/ZhaZJ_J02_Research%20and%20applications%20on%20georeferenced%20multimedia%20-%20a%20survey.pdf" class=yC45><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/v4un20747w066180.pdf" class=yC44>Research and applications on georeferenced multimedia: a survey</a></h3><div class="gs_a">YT Zheng, ZJ Zha, TS Chua - Multimedia Tools and Applications, 2011 - Springer</div><div class="gs_rs">Abstract In recent years, the emergence of georeferenced media, like geotagged photos, on <br>the Internet has opened up a new world of possibilities for geographic related research and <br>applications. Despite of its short history, georeferenced media has been attracting <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13036216831352044747&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 5</a> <a href="/scholar?q=related:y_y0pyPy6bQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13036216831352044747&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'y_y0pyPy6bQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:360"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/X42M4572W07P4PR6.pdf" class=yC46>A Survey on Social Image Mining</a></h3><div class="gs_a">Z Liu - Intelligent Computing and Information Science, 2011 - Springer</div><div class="gs_rs">With the rapid development of Web2. 0 technology, we have witnessed great interest and <br>promise in social image mining as a hot research field. Discovering and summarizing <br>knowledge from these multimedia data enables us to mine useful information from the real <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1876316196454526388&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 3</a> <a href="/scholar?q=related:tO37t6MDChoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1876316196454526388&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'tO37t6MDChoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:359"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB41" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW41"><a href="http://www.idiap.ch/~gatica/publications/NegoescuGatica-book10.pdf" class=yC48><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from idiap.ch</span><span class="gs_ggsS">idiap.ch <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.idiap.ch/~gatica/publications/NegoescuGatica-book10.pdf" class=yC47>Internet multimedia search and mining</a></h3><div class="gs_a"><a href="/citations?user=6G-l4o0AAAAJ&amp;hl=en&amp;oi=sra">XS Hua</a>, <a href="/citations?user=pdu8f3sAAAAJ&amp;hl=en&amp;oi=sra">M Worring</a>, TS Chua - Internet Multimedia Search and Mining, 2010 - idiap.ch</div><div class="gs_rs">Abstract: We present in this chapter a review of current work that leverages on large online <br>social networks&#39; meta-information, in particular Flickr Groups. We briefly present this hugely <br>successful feature in Flickr and discuss the various ways in which metadata stemming <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5011184445285179392&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 3</a> <a href="/scholar?q=related:AKAv3bNNi0UJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5011184445285179392&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'AKAv3bNNi0UJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md41', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md41" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:AKAv3bNNi0UJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:358"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5495247" class=yC49>Exploring user image tags for geo-location inference</a></h3><div class="gs_a"><a href="/citations?user=TYmV4V8AAAAJ&amp;hl=en&amp;oi=sra">D Joshi</a>, <a href="/citations?user=-RFj-kYAAAAJ&amp;hl=en&amp;oi=sra">A Gallagher</a>, J Yu, <a href="/citations?user=CcbnBvgAAAAJ&amp;hl=en&amp;oi=sra">J Luo</a> - Acoustics Speech and  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Geotagging has become a recent phenomenon that allows users to visualize and <br>manage photo collections in many new and interesting ways. Unfortunately, manual <br>geotagging of a large collection of pictures on the globe is still a time-consuming and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7954607039398397972&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 5</a> <a href="/scholar?q=related:FMgp__RwZG4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7954607039398397972&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'FMgp__RwZG4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:357"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB43" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW43"><a href="http://vision.cs.utexas.edu/projects/location-estimation/location_cvpr2011.pdf" class=yC4B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from utexas.edu</span><span class="gs_ggsS">utexas.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5995412" class=yC4A>Clues from the beaten path: Location estimation with bursty sequences of tourist photos</a></h3><div class="gs_a">CY Chen, K Grauman - Computer Vision and Pattern  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Image-based location estimation methods typically recognize every photo <br>independently, and their resulting reliance on strong visual feature matches makes them <br>most suited for distinctive landmark scenes. We observe that when touring a city, people <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15884381570423431402&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 5</a> <a href="/scholar?q=related:6qDZFeGocNwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15884381570423431402&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'6qDZFeGocNwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:356"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB44" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW44"><a href="http://www.jdl.ac.cn/doc/2011/20116301544736222_augmenting%20image%20processing%20with%20social%20tag%20mining%20for%20landmark%20recognition.pdf" class=yC4D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from jdl.ac.cn</span><span class="gs_ggsS">jdl.ac.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/1J7117813M8800J5.pdf" class=yC4C>Augmenting image processing with social tag mining for landmark recognition</a></h3><div class="gs_a">A Mahapatra, X Wan, Y Tian, <a href="/citations?user=Y4J5SOwAAAAJ&amp;hl=en&amp;oi=sra">J Srivastava</a> - Advances in Multimedia  &hellip;, 2011 - Springer</div><div class="gs_rs">Social Multimedia computing is a new approach which combines the contextual information <br>available in the social networks with available multimedia content to achieve greater <br>accuracy in traditional multimedia problems like face and landmark recognition. Tian et al.[<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17596592952253034588&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 2</a> <a href="/scholar?q=related:XDAvMA-oM_QJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17596592952253034588&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'XDAvMA-oM_QJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:355"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB45" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW45"><a href="https://oda.hio.no/jspui/bitstream/10642/488/2/543489post.pdf" class=yC4F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hio.no</span><span class="gs_ggsS">hio.no <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/08112277GUJ757H1.pdf" class=yC4E>A simple content-based strategy for estimating the geographical location of a webcam</a></h3><div class="gs_a"><a href="/citations?user=N9OuegkAAAAJ&amp;hl=en&amp;oi=sra">F Sandnes</a> - Advances in Multimedia Information Processing-PCM  &hellip;, 2010 - Springer</div><div class="gs_rs">This study proposes a strategy for determining the approximate geographical location of a <br>webcam based on a sequence of images taken at regular intervals. For a time-stamped <br>image sequence spanning 24 hours the approximate sunrise and sunset times are <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11823876230545496584&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 2</a> <a href="/scholar?q=related:CFrZPcnYFqQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11823876230545496584&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'CFrZPcnYFqQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:354"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB46" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW46"><a href="http://www.di.ens.fr/~josef/publications/torii11.pdf" class=yC51><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ens.fr</span><span class="gs_ggsS">ens.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6130230" class=yC50>Visual localization by linear combination of image descriptors</a></h3><div class="gs_a"><a href="/citations?user=73bI_HoAAAAJ&amp;hl=en&amp;oi=sra">A Torii</a>, <a href="/citations?user=NCtKHnQAAAAJ&amp;hl=en&amp;oi=sra">J Sivic</a>, <a href="/citations?user=gnR4zf8AAAAJ&amp;hl=en&amp;oi=sra">T Pajdla</a> - Computer Vision Workshops (ICCV  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We seek to predict the GPS location of a query image given a database of images <br>localized on a map with known GPS locations. The contributions of this work are three-<br>fold:(1) we formulate the image-based localization problem as a regression on an image <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9000286794565709886&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 2</a> <a href="/scholar?q=related:PnC6cidx53wJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9000286794565709886&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'PnC6cidx53wJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:353"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1877919" class=yC52>Rich location-driven tag cloud suggestions based on public, community, and personal sources</a></h3><div class="gs_a"><a href="/citations?user=TYmV4V8AAAAJ&amp;hl=en&amp;oi=sra">D Joshi</a>, <a href="/citations?user=CcbnBvgAAAAJ&amp;hl=en&amp;oi=sra">J Luo</a>, J Yu, P Lei, <a href="/citations?user=-RFj-kYAAAAJ&amp;hl=en&amp;oi=sra">A Gallagher</a> - Proceedings of the 1st ACM  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract Recent research has shown the power of geotagging for many multimedia <br>applications. In this paper, we present an integrated and intuitive system for suggesting <br>location-driven tags for a geotagged photo. Potential tags from multiple sources are <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2477362886674519925&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 2</a> <a href="/scholar?q=related:dZf4d2tcYSIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'dZf4d2tcYSIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:352"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2072624" class=yC53>Near2me: An authentic and personalized social media-based recommender for travel destinations</a></h3><div class="gs_a"><a href="/citations?user=Fhmp7lQAAAAJ&amp;hl=en&amp;oi=sra">C Kofler</a>, L Caballero, M Menendez&hellip; - Proceedings of the 3rd  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract This paper presents Near2me, a prototype system implementing a travel <br>recommender concept that generates recommendations that are not only personalized, but <br>also authentic. Exploitation of implicit situational knowledge makes it possible for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13803078418417272198&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 2</a> <a href="/scholar?q=related:hkWfkLBijr8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13803078418417272198&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'hkWfkLBijr8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:351"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6015557" class=yC54>Web image and video mining towards universal and robust age estimator</a></h3><div class="gs_a"><a href="/citations?user=V9W87PYAAAAJ&amp;hl=en&amp;oi=sra">B Ni</a>, Z Song, <a href="/citations?user=DNuiPHwAAAAJ&amp;hl=en&amp;oi=sra">S Yan</a> - Multimedia, IEEE Transactions on, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present an automatic web image and video mining framework with <br>the ultimate goal of building a universal human age estimator based on facial information, <br>which is applicable to all ethnic groups and various image qualities. On one hand, a large <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8773046440811670866&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 3</a> <a href="/scholar?q=related:Uq2VnkEfwHkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8773046440811670866&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'Uq2VnkEfwHkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:350"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/N21847588J044140.pdf" class=yC55>Using geotags to derive rich tag-clouds for image annotation</a></h3><div class="gs_a"><a href="/citations?user=TYmV4V8AAAAJ&amp;hl=en&amp;oi=sra">D Joshi</a>, <a href="/citations?user=CcbnBvgAAAAJ&amp;hl=en&amp;oi=sra">J Luo</a>, J Yu, P Lei, <a href="/citations?user=-RFj-kYAAAAJ&amp;hl=en&amp;oi=sra">A Gallagher</a> - Social Media Modeling and  &hellip;, 2011 - Springer</div><div class="gs_rs">Geotagging has become popular for many multimedia applications. In this chapter, we <br>present an integrated and intuitive system for location-driven tag suggestion, in the form of <br>tag-clouds, for geotagged photos. Potential tags from multiple sources are extracted and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2395410329543870766&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 2</a> <a href="/scholar?q=related:LonD1wA1PiEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2395410329543870766&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'LonD1wA1PiEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:349"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6208137" class=yC56>Classification of gothic and baroque architectural elements</a></h3><div class="gs_a">G Shalunts, <a href="/citations?user=3SzlfM0AAAAJ&amp;hl=en&amp;oi=sra">Y Haxhimusa</a>&hellip; - Systems, Signals and  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Architectural elements are the components and details of buildings. Their unique <br>set, combination, design, construction technique form the architectural style of buildings. <br>Building facade classification by architectural styles is viewed as a task of classifying <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2395162858066170004&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 2</a> <a href="/scholar?q=related:lFA-5u1TPSEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'lFA-5u1TPSEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:348"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/p6k788848x52w340.pdf" class=yC57>Grouping and summarizing scene images from web collections</a></h3><div class="gs_a">H Yang, Q Wang - Advances in Visual Computing, 2009 - Springer</div><div class="gs_rs">Abstract. This paper presents an efficient approach to group and summarize the large-scale <br>image dataset gathered from the internet. Our method firstly employs the bag-of-visual-<br>words model which has been successfully used in image retrieval applications to give the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13158728309496097287&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 2</a> <a href="/scholar?q=related:Bypk960xnbYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13158728309496097287&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'Bypk960xnbYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:347"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB53" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW53"><a href="http://www.slaney.org/malcolm/yahoo/Kennedy2009-ReliableTags.pdf" class=yC59><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from slaney.org</span><span class="gs_ggsS">slaney.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.slaney.org/malcolm/yahoo/Kennedy2009-ReliableTags.pdf" class=yC58>Reliable tags using image similarity</a></h3><div class="gs_a">LS Kennedy, M Slaney, <a href="/citations?user=jsxk8vsAAAAJ&amp;hl=en&amp;oi=sra">K Weinberger</a> - Proc. of ACM MM Workshop on  &hellip;, 2009 - slaney.org</div><div class="gs_rs">ABSTRACT This paper describes an approach for finding image descriptors or tags that are <br>highly reliable and specific. Reliable, in this work, means that the tags are related to the <br>image&#39;s visual content, which we verify by finding two or more real people who agree that <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18029991787727489697&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:oQq1AgFmN_oJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'oQq1AgFmN_oJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md53', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md53" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:oQq1AgFmN_oJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:346"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6054059" class=yC5A>Web Video Geolocation by Geotagged Social Resources</a></h3><div class="gs_a">YC Song, YD Zhang, J Cao, T Xia&hellip; - &hellip; , IEEE Transactions on, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper considers the problem of web video geolocation: we hope to determine <br>where on the Earth a web video was taken. By analyzing a 6.5-million geotagged web video <br>dataset, we observe that there exist inherent geography intimacies between a video with <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16118331446845832162&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:4vtAZQ3Rr98J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16118331446845832162&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'4vtAZQ3Rr98J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:345"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB55" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW55"><a href="http://www.ifp.illinois.edu/~cao4/papers/MINet_charu_chapter_2010.pdf" class=yC5C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from illinois.edu</span><span class="gs_ggsS">illinois.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/v07440308727n270.pdf" class=yC5B>Multimedia Information Networks in Social Media</a></h3><div class="gs_a"><a href="/citations?user=S-hBSfIAAAAJ&amp;hl=en&amp;oi=sra">L Cao</a>, <a href="/citations?user=Nut-uvoAAAAJ&amp;hl=en&amp;oi=sra">GJ Qi</a>, SF Tsai, MH Tsai, AD Pozo&hellip; - Social Network Data  &hellip;, 2011 - Springer</div><div class="gs_rs">The popularity of personal digital cameras and online photo/video sharing community has <br>lead to an explosion of multimedia information. Unlike traditional multimedia data, many new <br>multimedia datasets are organized in a structural way, incorporating rich information such <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2044083149590388455&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:516yZssKXhwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2044083149590388455&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'516yZssKXhwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:344"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2072620" class=yC5D>IM2MAP: deriving maps from georeferenced community contributed photo collections</a></h3><div class="gs_a">L Xie, S Newsam - Proceedings of the 3rd ACM SIGMM international  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract This paper investigates georeferenced social multimedia for geographic discovery. <br>We propose a novel framework wherein large collections of community contributed photo <br>collections are used to map phenomena not easily observable through other means. We <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3848388014401656540&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:3BZIbII4aDUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'3BZIbII4aDUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:343"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB57" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW57"><a href="http://www.jdl.ac.cn/doc/2011/2011122914473078910_geoidf_lingyu.pdf" class=yC5F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from jdl.ac.cn</span><span class="gs_ggsS">jdl.ac.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5946967" class=yC5E>When codeword frequency meets geographical location</a></h3><div class="gs_a"><a href="/citations?user=lRSD7PQAAAAJ&amp;hl=en&amp;oi=sra">R Ji</a>, LY Duan, J Chen, H Yao&hellip; - Acoustics, Speech and  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract When codeword frequency meets geographical location in landmark search <br>applications, is it still discriminative for the search procedure? In this paper, we give a <br>systematic investigation about how geographical location affects the effectiveness of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13566708268656647970&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:Il-idEqhRrwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13566708268656647970&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'Il-idEqhRrwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:342"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB58" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW58"><a href="http://202.114.89.42/resource/pdf/5543.pdf" class=yC61><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 202.114.89.42</span><span class="gs_ggsS">202.114.89.42 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S1047320310000982" class=yC60>Design and implementation of geo-tagged video search framework</a></h3><div class="gs_a">SH Kim, S Arslan Ay, <a href="/citations?user=IDREwXEAAAAJ&amp;hl=en&amp;oi=sra">R Zimmermann</a> - Journal of Visual Communication  &hellip;, 2010 - Elsevier</div><div class="gs_rs">User generated video content is experiencing significant growth which is expected to <br>continue and further accelerate. As an example, users are currently uploading 20h of video <br>per minute to YouTube. Making such video archives effectively searchable is one of the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9511952519873010639&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:z5tpm2s-AYQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9511952519873010639&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'z5tpm2s-AYQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:341"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2335452" class=yC62>What makes Paris look like Paris?</a></h3><div class="gs_a">C Doersch, <a href="/citations?user=L7fTK1MAAAAJ&amp;hl=en&amp;oi=sra">S Singh</a>, <a href="/citations?user=bqL73OkAAAAJ&amp;hl=en&amp;oi=sra">A Gupta</a>, <a href="/citations?user=NCtKHnQAAAAJ&amp;hl=en&amp;oi=sra">J Sivic</a>&hellip; - ACM Transactions on  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract Given a large repository of geotagged imagery, we seek to automatically find visual <br>elements, eg windows, balconies, and street signs, that are most distinctive for a certain geo-<br>spatial area, for example the city of Paris. This is a tremendously difficult task as the visual <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9322234129462991672&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 2</a> <a href="/scholar?q=related:OBuqp4w6X4EJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9322234129462991672&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'OBuqp4w6X4EJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:340"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.scientific.net/AMR.430-432.1068" class=yC63>A Novel Approach to Mine Knowledge from Social Images</a></h3><div class="gs_a">FC Wang - Advanced Materials Research, 2012 - Trans Tech Publ</div><div class="gs_rs">Abstract With the popularity of various social media website, currently, lots of social images <br>attached with different kinds of metadata have been uploaded to social media websites. <br>Mining useful knowledge from social images has been an emerging important research <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16897672445515243789&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:DaHXvY-XgOoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'DaHXvY-XgOoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:339"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB61" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW61"><a href="http://enl.usc.edu/~om_p/annotation-asc10.pdf" class=yC65><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from usc.edu</span><span class="gs_ggsS">usc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://enl.usc.edu/~om_p/annotation-asc10.pdf" class=yC64>Collaborative Image Annotation Using Image Webs</a></h3><div class="gs_a">Z Wang, <a href="/citations?user=1INvq7wAAAAJ&amp;hl=en&amp;oi=sra">O Gnawali</a>, K Heath, LJ Guibas - proceedings of the Army  &hellip;, 2010 - enl.usc.edu</div><div class="gs_rs">ABSTRACT The widespread availability of hand-held devices equipped with cameras has <br>facilitated the creation of massive image collections. Our method links together image <br>regions containing instances of the same object to form a graph called an Image Web. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=299164984339243803&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:G6PG3PfYJgQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=299164984339243803&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'G6PG3PfYJgQJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md61', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md61" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:G6PG3PfYJgQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:338"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB62" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW62"><a href="http://www.csee.usf.edu/~abrahmac/VIEW-CLUSTER_v2.pdf" class=yC67><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from usf.edu</span><span class="gs_ggsS">usf.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6134727" class=yC66>View Clustering of Wide-Baseline N-Views for Photo Tourism</a></h3><div class="gs_a">AS Brahmachari, <a href="/citations?user=xX2D9FQAAAAJ&amp;hl=en&amp;oi=sra">S Sarkar</a> - Graphics, Patterns and Images ( &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The problem of view clustering is concerned with finding connected sets of <br>overlapping views in a collection of photographs. The view clusters can be used to organize <br>a photo collection, traverse through a collection, or for 3D structure estimation. For large <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6089512813386836085&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:dagc4aNLglQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6089512813386836085&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'dagc4aNLglQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:337"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB63" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW63"><a href="https://www.mmp.rwth-aachen.de/publications/pdf/weyand-landmarkdiscovery-rmle10.pdf" class=yC69><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from rwth-aachen.de</span><span class="gs_ggsS">rwth-aachen.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="https://www.mmp.rwth-aachen.de/publications/pdf/weyand-landmarkdiscovery-rmle10.pdf" class=yC68>An evaluation of two automatic landmark building discovery algorithms for city reconstruction</a></h3><div class="gs_a"><a href="/citations?user=US56Kw8AAAAJ&amp;hl=en&amp;oi=sra">T Weyand</a>, J Hosang, <a href="/citations?user=ZcULDB0AAAAJ&amp;hl=en&amp;oi=sra">B Leibe</a> - Proc. Reconstruction and  &hellip;, 2010 - mmp.rwth-aachen.de</div><div class="gs_rs">Abstract. An important part of large-scale city reconstruction systems is an image clustering <br>algorithm that divides a set of images into groups that should cover only one building each. <br>Those groups then serve as input for structure from motion systems. A variety of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10699174308947343390&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:HrjK6lgae5QJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10699174308947343390&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'HrjK6lgae5QJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md63', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md63" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:HrjK6lgae5QJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:336"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB64" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW64"><a href="https://piwik.dbvis.de/uploadedFiles/239.pdf" class=yC6B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from dbvis.de</span><span class="gs_ggsS">dbvis.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="https://piwik.dbvis.de/uploadedFiles/239.pdf" class=yC6A>Towards acquisition of semantics of places and events by multi-perspective analysis of geotagged photo collections</a></h3><div class="gs_a">S Kisilevich, D Keim, <a href="/citations?user=t8LK29QAAAAJ&amp;hl=en&amp;oi=sra">N Andrienko</a>, <a href="/citations?user=R370BREAAAAJ&amp;hl=en&amp;oi=sra">G Andrienko</a> - 2010 - piwik.dbvis.de</div><div class="gs_rs">Abstract Due to the pervasiveness of positioning technology combined with the proliferation <br>of social-oriented web sites, community-contributed spatiotemporal data of people&#39;s <br>historical positions are available today in large amounts. The analysis of these data is <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6660783712109674727&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 2</a> <a href="/scholar?q=related:50AB7n7bb1wJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6660783712109674727&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'50AB7n7bb1wJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md64', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md64" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:50AB7n7bb1wJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:335"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB65" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW65"><a href="http://cvit.iiit.ac.in/papers/Jayaguru2012Heritage.pdf" class=yC6D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from iiit.ac.in</span><span class="gs_ggsS">iiit.ac.in <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://cvit.iiit.ac.in/papers/Jayaguru2012Heritage.pdf" class=yC6C>Heritage app: Annotating images on mobile phones</a></h3><div class="gs_a">J Panda, S Sharma, <a href="/citations?user=U9dH-DoAAAAJ&amp;hl=en&amp;oi=sra">CV Jawahar</a> - Indian Conference on Vision,  &hellip;, 2012 - cvit.iiit.ac.in</div><div class="gs_rs">ABSTRACT In this paper, we demonstrate a computer vision application on mobile phones. <br>One can take a picture at a heritage site/monument and obtain associated annotations on a <br>mid-end mobile phone instantly. This does not require any communication of images or <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15230929697856953630&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a onclick="return gs_ocit(event,'Hh22_9whX9MJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md65', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md65" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Hh22_9whX9MJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:334"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB66" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW66"><a href="https://oda.hio.no/jspui/bitstream/10642/651/2/511853.pdf" class=yC6F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hio.no</span><span class="gs_ggsS">hio.no <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="https://oda.hio.no/jspui/handle/10642/651" class=yC6E>A Non-Visual Photo Collection Browser based on Automatically Generated Text Descriptions</a></h3><div class="gs_a"><a href="/citations?user=N9OuegkAAAAJ&amp;hl=en&amp;oi=sra">FE Sandnes</a> - Proceedings of 3rd International Conference on  &hellip;, 2010 - oda.hio.no</div><div class="gs_rs">This study presents a textual photo collection browser that automatically and quickly <br>analyses large personal photo collections and produces textual reports that can be <br>accessed by blind users using either text-to-speech or Braille output devices. The textual <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9679210082615552830&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:PuutmEl2U4YJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9679210082615552830&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'PuutmEl2U4YJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:333"><div class="gs_ri"><h3 class="gs_rt"><a href="http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=731921" class=yC70>Personal photo album summarization for global and local photo annotation</a></h3><div class="gs_a">M Broilo, FGB De Natale - IS&amp;T/SPIE  &hellip;, 2011 - proceedings.spiedigitallibrary.org</div><div class="gs_rs">abstract Although content-based media retrieval tools are continuously improving, <br>personalized image annotation is still one of the most reliable ways to index large image <br>archives. Unfortunately, it is also a time consuming and repetitive operation. Using content <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:CuvdARY3GqwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12401285091578211082&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'CuvdARY3GqwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md67', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md67" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:CuvdARY3GqwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:332"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB68" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW68"><a href="http://www.doc.ic.ac.uk/~ej09/Publications/E_Johns_ICCV_2011.pdf" class=yC72><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ic.ac.uk</span><span class="gs_ggsS">ic.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6126328" class=yC71>From images to scenes: Compressing an image cluster into a single scene model for place recognition</a></h3><div class="gs_a">E Johns, GZ Yang - Computer Vision (ICCV), 2011 IEEE  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The recognition of a place depicted in an image typically adopts methods from <br>image retrieval in large-scale databases. First, a query image is described as a âbag-of-<br>featuresâ and compared to every image in the database. Second, the most similar images <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:bXTbA2KG9WgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7563098904768246893&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'bXTbA2KG9WgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:331"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> LocGo: A Dynamic Generation of Travel Guides by Automatic Landmark Ranking</h3><div class="gs_a">Y Gao, <a href="/citations?user=ByBLlEwAAAAJ&amp;hl=en&amp;oi=sra">J Tang</a>, <a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, TS Chua, R Jain</div><div class="gs_fl"><a href="/scholar?q=related:icucBxPswYUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'icucBxPswYUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:330"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0306457312000945" class=yC73>Multifaceted conceptual image indexing on the world wide web</a></h3><div class="gs_a">F Fauzi, M Belkhatir - Information Processing &amp; Management, 2012 - Elsevier</div><div class="gs_rs">In this paper, we describe a user-centered design of an automated multifaceted concept-<br>based indexing framework which analyzes the semantics of the Web image contextual <br>information and classifies it into five broad semantic concept facets: signal, object, abstract<b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'1C0mDJ9wcyoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:329"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2307656" class=yC74>Satellites in our pockets: an object positioning system using smartphones</a></h3><div class="gs_a"><a href="/citations?user=FsPsLw0AAAAJ&amp;hl=en&amp;oi=sra">JG Manweiler</a>, <a href="/citations?user=4Y6Mvo0AAAAJ&amp;hl=en&amp;oi=sra">P Jain</a>, <a href="/citations?user=dq2wG-AAAAAJ&amp;hl=en&amp;oi=sra">R Roy Choudhury</a> - Proceedings of the 10th  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract This paper attempts to solve the following problem: can a distant object be localized <br>by looking at it through a smartphone. As an example use-case, while driving on a highway <br>entering New York, we want to look at one of the skyscrapers through the smartphone <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12042874194077880240&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 2</a> <a href="/scholar?q=related:sA-7DEbiIKcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'sA-7DEbiIKcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:328"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB72" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW72"><a href="http://hpc.isti.cnr.it/~rossano/files/papers/ECIR2012.pdf" class=yC76><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cnr.it</span><span class="gs_ggsS">cnr.it <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/2080751703368528.pdf" class=yC75>How random walks can help tourism</a></h3><div class="gs_a"><a href="/citations?user=bdoG6ScAAAAJ&amp;hl=en&amp;oi=sra">C Lucchese</a>, <a href="/citations?user=T371ouoAAAAJ&amp;hl=en&amp;oi=sra">R Perego</a>, <a href="/citations?user=pi985dQAAAAJ&amp;hl=en&amp;oi=sra">F Silvestri</a>, H Vahabi&hellip; - Advances in Information  &hellip;, 2012 - Springer</div><div class="gs_rs">On-line photo sharing services allow users to share their touristic experiences. Tourists can <br>publish photos of interesting locations or monuments visited, and they can also share <br>comments, annotations, and even the GPS traces of their visits. By analyzing such data, it <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2174641611213925985&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 2</a> <a href="/scholar?q=related:YW4wDgbhLR4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2174641611213925985&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'YW4wDgbhLR4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:327"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB73" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW73"><a href="http://ame2.asu.edu/faculty/hs/pubs/2012/2012_IEEEP-mmdc-yrl-pn-xlx.pdf" class=yC78><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from asu.edu</span><span class="gs_ggsS">asu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://ame2.asu.edu/faculty/hs/pubs/2012/2012_IEEEP-mmdc-yrl-pn-xlx.pdf" class=yC77>Multimedia Semantics: Interactions between Content and Community</a></h3><div class="gs_a"><a href="/citations?user=Ade_7YoAAAAJ&amp;hl=en&amp;oi=sra">A Natsev</a> - ame2.asu.edu</div><div class="gs_rs">AbstractâThis paper reviews the state of the art and some emerging issues in research <br>areas related to pattern analysis and monitoring of web-based social communities. This <br>research area is important for several reasons. The presence of near ubiquitous low-cost <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'kip9EdBe6SsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md73', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md73" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:kip9EdBe6SsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:326"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB74" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW74"><a href="http://www.stanford.edu/class/cs224w/upload/cs224w-020-final.pdf" class=yC7A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from stanford.edu</span><span class="gs_ggsS">stanford.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.stanford.edu/class/cs224w/upload/cs224w-020-final.pdf" class=yC79>Who and Where: People and Location Co-Clustering</a></h3><div class="gs_a">Z Wang - stanford.edu</div><div class="gs_rs">ABSTRACT The goal of the image clustering is to group semantically related images <br>together. This task is very important, particularly in the era with an immense volume of user <br>uploaded online photos. In this paper, we consider the clustering problem on images <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'yh68GvxhagwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md74', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md74" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:yh68GvxhagwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:325"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2324796.2324865" class=yC7B>Cluster-based photo browsing and tagging on the go</a></h3><div class="gs_a"><a href="/citations?user=GuhyORoAAAAJ&amp;hl=en&amp;oi=sra">S Papadopoulos</a>, J Bakalli, <a href="/citations?user=Nr7smP8AAAAJ&amp;hl=en&amp;oi=sra">Y Kompatsiaris</a>&hellip; - Proceedings of the 2nd  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract We present a technical demonstration of a novel smartphone application that <br>enables efficient browsing and tagging of landmark and event photos. The application <br>employs a hierarchical mode of exploration enabling zooming from the level of a city, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:UO-PG264RiYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'UO-PG264RiYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:324"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5652600" class=yC7C>Landmark recognition: A unary approach</a></h3><div class="gs_a">H Shu, CY Chen, T Chen - Image Processing (ICIP), 2010 17th  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we consider the problem of automatic landmark image recognition. <br>Specifically, we identify a fundamental issue that lurks in such applications as modern <br>landmark recognition that arises as a natural consequence of a current state-of-the-art <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:HGxGINHcjwkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=689012058758736924&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'HGxGINHcjwkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:323"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB77" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW77"><a href="http://data.icg.tugraz.at/~dieter/publications/Schmalstieg_224.pdf" class=yC7E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tugraz.at</span><span class="gs_ggsS">tugraz.at <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://data.icg.tugraz.at/~dieter/publications/Schmalstieg_224.pdf" class=yC7D>Challenges of Large-Scale Augmented Reality on Smartphones</a></h3><div class="gs_a">C Arth, D Schmalstieg - data.icg.tugraz.at</div><div class="gs_rs">ABSTRACT Smartphones have been identified as most promising future devices for an <br>Augmented Reality (AR) mass market. However, their use puts considerable constraints on <br>the design and composition of AR applications. The key problem is to find a registration <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:WuxeI2VrcpYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10840845335163497562&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'WuxeI2VrcpYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md77', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md77" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:WuxeI2VrcpYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:322"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB78" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW78"><a href="http://gvv.mpi-inf.mpg.de/files/ECCV2012/SupplMat.pdf" class=yC80><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mpg.de</span><span class="gs_ggsS">mpg.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://gvv.mpi-inf.mpg.de/files/ECCV2012/SupplMat.pdf" class=yC7F>Supplementary Material for âMatch Graph Construction for Large Image Databasesâ</a></h3><div class="gs_a">KI Kim, J Tompkin, M Theobald, J Kautz, <a href="/citations?user=eIWg8NMAAAAJ&amp;hl=en&amp;oi=sra">C Theobalt</a> - gvv.mpi-inf.mpg.de</div><div class="gs_rs">This appendix presents additional discussion on several aspects of the proposed algorithm. <br>Sec. A presents a modification of our algorithm which enables users to reflect local <br>connectivity in link prediction. The remaining sections focus on the label propagation <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:CT4nJ2UeStcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15513245286228508169&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'CT4nJ2UeStcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md78', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md78" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:CT4nJ2UeStcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:321"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2396343" class=yC81>DLMSearch: diversified landmark search by photo</a></h3><div class="gs_a">J Ye, J Chen, Z Chen, Y Zhu, S Bao, Z Su&hellip; - Proceedings of the 20th  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract This paper focuses on the problem of searching for diversified landmarks with <br>photos. More particularly, we propose a system called DLMSearch which handles image <br>query, searches for diversified landmarks and provides representative visual summaries. <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'7hydKTIPnYUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:320"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/W7551P868018T881.pdf" class=yC82>Destination board system based on photographs</a></h3><div class="gs_a">T Nakada - Knowledge-Based and Intelligent Information and  &hellip;, 2010 - Springer</div><div class="gs_rs">A destination board is a board that is often placed on the door of a room to notify visitors of <br>the user&#39;s current location. The system proposed in this paper is as follows: A user who <br>wants to notify other people of his/her location takes a photograph of his/her current <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:prYHNKY4wRQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1495538837752362662&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'prYHNKY4wRQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:319"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1995428" class=yC83>Geometric consistency checks for kNN based image classification relying on local features</a></h3><div class="gs_a">G Amato, <a href="/citations?user=4Vr1dSQAAAAJ&amp;hl=en&amp;oi=sra">F Falchi</a>, <a href="/citations?user=sbFBI4IAAAAJ&amp;hl=en&amp;oi=sra">C Gennaro</a> - Proceedings of the Fourth International  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract Applications of image content recognition, as for instance landmark recognition, can <br>be obtained by using techniques of kNN classifications based on the use of local image <br>features, such as SIFT or SURF. Quality of image classification can be improved by <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3868752317459300595&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:84AhNryRsDUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'84AhNryRsDUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:318"><div class="gs_ri"><h3 class="gs_rt"><a href="http://japanlinkcenter.org/JST.JSTAGE/ipsjtcva/3.44?from=Google" class=yC84>Scene Reconstruction and Visualization from Internet Photo Collections: A Survey</a></h3><div class="gs_a"><a href="/citations?user=Db4BCX8AAAAJ&amp;hl=en&amp;oi=sra">N Snavely</a> - IPSJ Transactions on Computer Vision and  &hellip;, 2011 - J-STAGE</div><div class="gs_rs">The Internet has become an unprecedented source of visual information about our world, <br>with millions of people uploading photos and videos to media-sharing sites at staggering <br>rates. Virtually all of the world&#39;s famous landmarks and cities (and many not-so-famous <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15334356707448291953&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:cYKVNi6UztQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15334356707448291953&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'cYKVNi6UztQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:317"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB83" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW83"><a href="http://www.cmlab.csie.ntu.edu.tw/~zenic/Download/ICME2012/Workshops/data/4729a540.pdf" class=yC86><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntu.edu.tw</span><span class="gs_ggsS">ntu.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6266441" class=yC85>Trip Mining and Recommendation from Geo-tagged Photos</a></h3><div class="gs_a">H Yin, C Wang, N Yu, <a href="/citations?user=fIlGZToAAAAJ&amp;hl=en&amp;oi=sra">L Zhang</a> - Multimedia and Expo  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Trip planning is generally a very time-consuming task due to the complex trip <br>requirements and the lack of convenient tools/systems to assist the planning. In this paper, <br>we propose a travel path search system based on geo-tagged photos to facilitate tourists&#39; <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:j5bfONGYOZUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10752793609693533839&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'j5bfONGYOZUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:316"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/V28541L1473431V7.pdf" class=yC87>A Survey of Landmark Recognition Using the Bag-of-Words Framework</a></h3><div class="gs_a">P Bhattacharya, M Gavrilova - Intelligent Computer Graphics 2012 - Springer</div><div class="gs_rs">Recent years have seen an exponential increase in the use of mobile devices. Since many <br>of the mobile devices are equipped with a camera and are connected to the internet, <br>localization in an urban environment using landmark images is gaining popularity. The <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:79wAOmaRUWUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'79wAOmaRUWUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:315"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB85" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW85"><a href="http://www.willfulwreckords.com/GinsuScience/CVPR2012/data/papers/454_P3C-26.pdf" class=yC89><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from willfulwreckords.com</span><span class="gs_ggsS">willfulwreckords.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6248104" class=yC88>3D visual phrases for landmark recognition</a></h3><div class="gs_a"><a href="/citations?user=WxAtmSEAAAAJ&amp;hl=en&amp;oi=sra">Q Hao</a>, <a href="/citations?user=6WCyi64AAAAJ&amp;hl=en&amp;oi=sra">R Cai</a>, Z Li, <a href="/citations?user=fIlGZToAAAAJ&amp;hl=en&amp;oi=sra">L Zhang</a>, Y Pang&hellip; - Computer Vision and  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we study the problem of landmark recognition and propose to <br>leverage 3D visual phrases to improve the performance. A 3D visual phrase is a triangular <br>facet on the surface of a reconstructed 3D landmark model. In contrast to existing 2D <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:0efmPFPC8dkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15704547038377469905&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'0efmPFPC8dkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:314"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB86" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW86"><a href="http://uu.diva-portal.org/smash/get/diva2:431588/FULLTEXT01" class=yC8B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from diva-portal.org</span><span class="gs_ggsS">diva-portal.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://uu.diva-portal.org/smash/record.jsf?pid=diva2:431588" class=yC8A>Recognizing Art Pieces in Subway using Computer Vision</a></h3><div class="gs_a">T Cai - 2011 - uu.diva-portal.org</div><div class="gs_rs">With the industrial miniaturization of cameras and mobile devices, the generation of and <br>access to digital visual information has become ubiquitous. Today, most high resolution <br>cameras are sold within mobile phones such as HTC, Sony Ericsson. With the mobile <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:gSJvPfCEqKcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'gSJvPfCEqKcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:313"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB87" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW87"><a href="https://oda.hio.no/jspui/bitstream/10642/882/2/829601post.pdf" class=yC8D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hio.no</span><span class="gs_ggsS">hio.no <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/W270318N76W53652.pdf" class=yC8C>A configurable photo browser framework for large image collections</a></h3><div class="gs_a"><a href="/citations?user=N9OuegkAAAAJ&amp;hl=en&amp;oi=sra">F Sandnes</a> - Human-Computer Interaction. Design and  &hellip;, 2011 - Springer</div><div class="gs_rs">Image collections are growing at an exponential rate due to the wide availability of <br>inexpensive digital cameras and storage. Current browsers organize photos mostly <br>chronologically, or according to manual tags. For very large collections acquired over <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:7X-lQOBLC9UJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15351447181351813101&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'7X-lQOBLC9UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:312"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/pdf/10.1007/s11042-010-0554-7" class=yC8E>Leveraging community metadata for multimodal image ranking</a></h3><div class="gs_a">F Richter, S Romberg, E HÃ¶rster, <a href="/citations?user=eKQPhGgAAAAJ&amp;hl=en&amp;oi=sra">R Lienhart</a> - Multimedia Tools and  &hellip;, 2012 - Springer</div><div class="gs_rs">Abstract Searching for relevant images given a query term is an important task in nowadays <br>large-scale community databases. The image ranking approach presented in this work <br>represents an image collection as a graph that is built using a multimodal similarity <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:W0ubQw_jO1sJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6574097735775636315&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'W0ubQw_jO1sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:311"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB89" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW89"><a href="http://www.cs.unc.edu/~jtighe/Papers/BMVC12/jtighe-bmvc12.pdf" class=yC90><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unc.edu</span><span class="gs_ggsS">unc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.cs.unc.edu/~jtighe/Papers/BMVC12/jtighe-bmvc12.pdf" class=yC8F>Improved Geometric Verification for Large Scale Landmark Image Collections</a></h3><div class="gs_a"><a href="/citations?user=iHJLHq8AAAAJ&amp;hl=en&amp;oi=sra">R Raguram</a>, <a href="/citations?user=TJo2_hAAAAAJ&amp;hl=en&amp;oi=sra">J Tighe</a>, <a href="/citations?user=3YOe4NMAAAAJ&amp;hl=en&amp;oi=sra">JM Frahm</a> - cs.unc.edu</div><div class="gs_rs">Abstract In this work, we address the issue of geometric verification, with a focus on <br>modeling large-scale landmark image collections gathered from the internet. In particular, <br>we show that we can compute and learn descriptive statistics pertaining to the image <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:TqMMRMbsN7EJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12769935604721689422&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'TqMMRMbsN7EJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md89', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md89" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:TqMMRMbsN7EJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:310"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB90" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW90"><a href="http://infoscience.epfl.ch/record/176934/files/Ivanov_201210_SMR2013.pdf" class=yC92><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from epfl.ch</span><span class="gs_ggsS">epfl.ch <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=p81-pnyjODAC&amp;oi=fnd&amp;pg=PA283&amp;ots=F0awKIDhuP&amp;sig=abhvaFUIacdUxBhbeeYYsja8RBc" class=yC91>Geotag Propagation with User Trust Modeling</a></h3><div class="gs_a">I Ivanov, P Vajda, JS Lee, <a href="/citations?user=vSRZIvUAAAAJ&amp;hl=en&amp;oi=sra">P Korshunov</a>&hellip; - Social Media  &hellip; - books.google.com</div><div class="gs_rs">Abstract The amount of information that people share on social networks is constantly <br>increasing. People also comment, annotate, and tag their own content (videos, photos, <br>notes, etc.), as well as the content of others. In many cases, the content is tagged manually<b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'WJPkSHvA0KsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:309"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB91" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW91"><a href="http://www.mirlab.org/conference_papers/International_Conference/ICASSP%202012/pdfs/0002333.pdf" class=yC94><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mirlab.org</span><span class="gs_ggsS">mirlab.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6288382" class=yC93>Unified hypergraph for image ranking in a multimodal context</a></h3><div class="gs_a">J Xu, V Singh, <a href="/citations?user=mSJcQwYAAAAJ&amp;hl=en&amp;oi=sra">Z Guan</a>&hellip; - Acoustics, Speech and  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Image ranking has long been studied, yet it remains a very challenging problem. <br>Increasingly, online images come with additional metadata such as user annotations and <br>geographic coordinates. They provide rich complementary information. We propose to <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:SoQOVCQ4ih4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2200633096604124234&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'SoQOVCQ4ih4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:308"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB92" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW92"><a href="http://libque.cityu.edu.hk/bitstream/2031/6211/1/abstract.html" class=yC96><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cityu.edu.hk</span><span class="gs_ggsS">cityu.edu.hk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://libque.cityu.edu.hk/handle/2031/6211" class=yC95>Video hyperlinking for multimedia search</a></h3><div class="gs_a">HK Tan - 2010 - libque.cityu.edu.hk</div><div class="gs_rs">ï»¿ With the spread of Web 2.0, web videos have become prevalent online. There is a growing <br>need for effective modeling and organization of video data to facilitate browsing or retrieval. <br>Meanwhile, the modeling of web pages through hyperlink graph has seen tremendous <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:gk0oVGtrZrQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12999195483169115522&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'gk0oVGtrZrQJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md92', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md92" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:gk0oVGtrZrQJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=16418393280767177700&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:307"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/Q2361K265014U5M4.pdf" class=yC97>Landmark Recognition in VISITO Tuscany</a></h3><div class="gs_a">G Amato, <a href="/citations?user=4Vr1dSQAAAAJ&amp;hl=en&amp;oi=sra">F Falchi</a>, F Rabitti - Multimedia for Cultural Heritage, 2012 - Springer</div><div class="gs_rs">This paper discusses and compares various approach to automatic landmark recognition in <br>pictures, based upon image content analysis and classification. The paper first compares <br>various visual features and image similarity functions based on local features. Finally it <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:XFTZWEVUGsMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14058641843610539100&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'XFTZWEVUGsMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:306"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/E3583H3KT0371264.pdf" class=yC98>CAPIRE: a context-aware points of interest REcognition system using a CBIR approach</a></h3><div class="gs_a">I Minetti, S Dellepiane, <a href="/citations?user=AyKP8bQAAAAJ&amp;hl=en&amp;oi=sra">M Valla</a> - Future Multimedia Networking, 2010 - Springer</div><div class="gs_rs">This paper describes CAPIRE, a service for Points Of Interest (POI) recognition from mobile <br>user-generated photos to provide relevant touristic information. The goal is achieved <br>through the combination of positioning information with image processing and Content-<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:_7eqWspOTAcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=525881887507003391&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'_7eqWspOTAcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:305"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6351180" class=yC99>Geolocation of photographs by means of horizon matching with digital elevation models</a></h3><div class="gs_a">SW Pritt - &hellip;  and Remote Sensing Symposium (IGARSS), 2012  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Geolocation is the process of assigning geographic coordinates to photographs. It <br>is important in counter terrorism, photo tourism, community remote sensing, and robot <br>navigation. Prior work has focused on matching photographs against a database of <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'lNt9XoH7CIkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:304"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB96" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW96"><a href="http://www.cs.cornell.edu/~yuli/papers/global_pose.pdf" class=yC9B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cornell.edu</span><span class="gs_ggsS">cornell.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.cs.cornell.edu/~yuli/papers/global_pose.pdf" class=yC9A>Worldwide Pose Estimation using 3D Point Clouds</a></h3><div class="gs_a"><a href="/citations?user=2vaDEYAAAAAJ&amp;hl=en&amp;oi=sra">Y Li</a>, <a href="/citations?user=Db4BCX8AAAAJ&amp;hl=en&amp;oi=sra">N Snavely</a>, <a href="/citations?user=q16KVs0AAAAJ&amp;hl=en&amp;oi=sra">D Huttenlocher</a>, <a href="/citations?user=kzFmAkYAAAAJ&amp;hl=en&amp;oi=sra">P Fua</a> - cs.cornell.edu</div><div class="gs_rs">Abstract. We address the problem of determining where a photo was taken by estimating a <br>full 6-DOF-plus-intrincs camera pose with respect to a large geo-registered 3D point cloud, <br>bringing together research on image localization, landmark recognition, and 3D pose <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:HkK1X8vkkQsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=833698968175460894&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'HkK1X8vkkQsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md96', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md96" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:HkK1X8vkkQsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:303"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2396542" class=yC9C>GeoMM&#39;12: ACM international workshop on geotagging and its applications in multimedia</a></h3><div class="gs_a"><a href="/citations?user=S-hBSfIAAAAJ&amp;hl=en&amp;oi=sra">L Cao</a>, <a href="/citations?user=iBl-QgEAAAAJ&amp;hl=en&amp;oi=sra">G Friedland</a>, <a href="/citations?user=eIiM958AAAAJ&amp;hl=en&amp;oi=sra">M Larson</a> - &hellip;  of the 20th ACM international conference &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract Geotagging is the process of adding geographical identification metadata to various <br>media files such as photos, videos, websites, messages, and tweets. It is not limited to GPS <br>sensor data but an extension of current multimedia files with a wide variety of location-<b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'qHfHZvJGaMsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:302"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5951749" class=yC9D>Integrated Content and Context Analysis for Mobile Landmark Recognition</a></h3><div class="gs_a"><a href="/citations?user=w3OoFL0AAAAJ&amp;hl=en&amp;oi=sra">T Chen</a>, <a href="/citations?user=nr86m98AAAAJ&amp;hl=en&amp;oi=sra">KH Yap</a>, <a href="/citations?user=MYREIH0AAAAJ&amp;hl=en&amp;oi=sra">LP Chau</a> - Circuits and Systems for Video  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper proposes a new approach for mobile landmark recognition based on <br>integrated content and context analysis. Conventional scene/landmark recognition methods <br>focus mainly on nonmobile desktop/PC platform, where content analysis alone is used to <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:wmUZaNz7STsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4272222645595497922&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'wmUZaNz7STsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:301"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB99" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW99"><a href="http://137.132.145.151/lms/sites/default/files/mmm11-yiliang.pdf" class=yC9F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/7235707443x66m69.pdf" class=yC9E>Generating representative views of landmarks via scenic theme detection</a></h3><div class="gs_a">YL Zhao, YT Zheng, <a href="/citations?user=QUrLihYAAAAJ&amp;hl=en&amp;oi=sra">X Zhou</a>, TS Chua - Advances in Multimedia Modeling, 2011 - Springer</div><div class="gs_rs">Visual summarization of landmarks is an interesting and non-trivial task with the availability <br>of gigantic community-contributed resources. In this work, we investigate ways to generate <br>representative and distinctive views of landmarks by automatically discovering the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:JIEScPkSyzMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3732097578743005476&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'JIEScPkSyzMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
