Total results = 15
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://lms.comp.nus.edu.sg/papers/media/2010/mmm10-richang.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/925p41335j22184n.pdf" class=yC0>Mediapedia: Mining web knowledge to construct multimedia encyclopedia</a></h3><div class="gs_a"><a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, <a href="/citations?user=ByBLlEwAAAAJ&amp;hl=en&amp;oi=sra">J Tang</a>, ZJ Zha, <a href="/citations?user=0UkdiUT1ooUC&amp;hl=en&amp;oi=sra">Z Luo</a>, TS Chua - Advances in Multimedia  &hellip;, 2010 - Springer</div><div class="gs_rs">Abstract. In recent years, we have witnessed the blooming of Web 2.0 content such as <br>Wikipedia, Flickr and YouTube, etc. How might we benefit from such rich media resources <br>available on the internet? This paper presents a novel concept called Mediapedia, a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14978197780089934046&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15">Cited by 13</a> <a href="/scholar?q=related:3hDO6YU_3c8J:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14978197780089934046&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'3hDO6YU_3c8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/acmmm09-chua.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1631069" class=yC2>From text question-answering to multimedia QA on web-scale media resources</a></h3><div class="gs_a">TS Chua, <a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, G Li, <a href="/citations?user=ByBLlEwAAAAJ&amp;hl=en&amp;oi=sra">J Tang</a> - Proceedings of the First ACM workshop &hellip;, 2009 - dl.acm.org</div><div class="gs_rs">Abstract With the proliferation of text and multimedia information, users are now able to find <br>answers to almost any questions on the Web. Meanwhile, they are also bewildered by the <br>huge amount of information routinely presented to them. Question-answering (QA) is a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18090986418949307243&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15">Cited by 10</a> <a href="/scholar?q=related:a7vjQUwYEPsJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18090986418949307243&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'a7vjQUwYEPsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://vireo.cs.cityu.edu.hk/papers/beyond%20search%20event%20driven%20summarization%20for%20web%20videos_acmtmm10.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cityu.edu.hk</span><span class="gs_ggsS">cityu.edu.hk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2043613" class=yC4>Beyond search: Event-driven summarization for web videos</a></h3><div class="gs_a"><a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, <a href="/citations?user=ByBLlEwAAAAJ&amp;hl=en&amp;oi=sra">J Tang</a>, HK Tan, <a href="/citations?user=jk5DWVMAAAAJ&amp;hl=en&amp;oi=sra">CW Ngo</a>, <a href="/citations?user=DNuiPHwAAAAJ&amp;hl=en&amp;oi=sra">S Yan</a>&hellip; - ACM Transactions on  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract The explosive growth of Web videos brings out the challenge of how to efficiently <br>browse hundreds or even thousands of videos at a glance. Given an event-driven query, <br>social media Web sites usually return a large number of videos that are diverse and noisy <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4403112343352155411&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15">Cited by 13</a> <a href="/scholar?q=related:E52k-1j_Gj0J:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4403112343352155411&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'E52k-1j_Gj0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/civr10-hongrichang.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1816055" class=yC6>Exploring large scale data for multimedia QA: an initial study</a></h3><div class="gs_a"><a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, G Li, L Nie, <a href="/citations?user=ByBLlEwAAAAJ&amp;hl=en&amp;oi=sra">J Tang</a>, TS Chua - Proceedings of the ACM  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract With the explosive growth of multimedia contents on the internet, multimedia search <br>has become more and more important. However, users are often bewildered by the vast <br>quantity of information content returned by the search engines. In this scenario, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4416393598065709541&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15">Cited by 8</a> <a href="/scholar?q=related:5REEEZQuSj0J:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4416393598065709541&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'5REEEZQuSj0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://vireo.cs.cityu.edu.hk/papers/csvt-hktan_10.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cityu.edu.hk</span><span class="gs_ggsS">cityu.edu.hk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5580060" class=yC8>Efficient mining of multiple partial near-duplicate alignments by temporal network</a></h3><div class="gs_a">HK Tan, <a href="/citations?user=jk5DWVMAAAAJ&amp;hl=en&amp;oi=sra">CW Ngo</a>, TS Chua - Circuits and Systems for Video  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper considers the mining and localization of near-duplicate segments at <br>arbitrary positions of partial near-duplicate videos in a corpus. Temporal network is <br>proposed to model the visual-temporal consistency between video sequence by <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11479758725924382753&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15">Cited by 4</a> <a href="/scholar?q=related:IejpJb1LUJ8J:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11479758725924382753&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'IejpJb1LUJ8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1874112" class=yCA>Topic discovery of web video using star-structured k-partite graph</a></h3><div class="gs_a"><a href="/citations?user=VUN-9cQAAAAJ&amp;hl=en&amp;oi=sra">J Shao</a>, W Yin, S Ma, Y Zhuang - Proceedings of the international  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract As the explosive growth of web videos on video-shared sites like YouTube, the <br>discovery of video topics has become a hot research area. In order to utilize all kinds of <br>characteristics in web video such as visual features (SIFT, shape or color) and contextual <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9017139601398692697&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15">Cited by 4</a> <a href="/scholar?q=related:Wft5T7FQI30J:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Wft5T7FQI30J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://lms.comp.nus.edu.sg/papers/media/2010/mmm10-guangda.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/16032402R4608815.pdf" class=yCB>Learning cooking techniques from youtube</a></h3><div class="gs_a">G Li, <a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, YT Zheng, <a href="/citations?user=DNuiPHwAAAAJ&amp;hl=en&amp;oi=sra">S Yan</a>, TS Chua - Advances in Multimedia  &hellip;, 2010 - Springer</div><div class="gs_rs">Abstract. Cooking is a human activity with sophisticated process. Underlying the multitude of <br>culinary recipes, there exist a set of fundamental and general cooking techniques, such as <br>cutting, braising, slicing, and sauntering, etc. These skills are hard to learn through <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2877317809657764576&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15">Cited by 3</a> <a href="/scholar?q=related:4FqOnk1J7icJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2877317809657764576&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'4FqOnk1J7icJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://www.scholarpedia.org/article/Multimedia_Question_Answering" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from scholarpedia.org</span><span class="gs_ggsS">scholarpedia.org <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[HTML]</span><span class="gs_ct2">[HTML]</span></span> <a href="http://www.scholarpedia.org/article/Multimedia_Question_Answering" class=yCD>Multimedia question answering</a></h3><div class="gs_a">C Tat-Seng, <a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, J Tang - Scholarpedia, 2010 - scholarpedia.org</div><div class="gs_rs">With the proliferation of text and multimedia information, users are now able to find answers <br>to almost any questions on the Web. Meanwhile, they are also bewildered by the huge <br>amount of information routinely presented to them. Question-answering (QA) is a natural <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13904536500342593696&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15">Cited by 1</a> <a href="/scholar?q=related:oJhfFUfW9sAJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'oJhfFUfW9sAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md7', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md7" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:oJhfFUfW9sAJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6135507" class=yCF>Event Driven Web Video Summarization by Tag Localization and Key-Shot Identification</a></h3><div class="gs_a"><a href="/citations?user=rHagaaIAAAAJ&amp;hl=en&amp;oi=sra">M Wang</a>, <a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, G Li, ZJ Zha, <a href="/citations?user=DNuiPHwAAAAJ&amp;hl=en&amp;oi=sra">S Yan</a>&hellip; - &hellip; , IEEE Transactions on, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract With the explosive growth of web videos on the Internet, it becomes challenging to <br>efficiently browse hundreds or even thousands of videos. When searching an event query, <br>users are often bewildered by the vast quantity of web videos returned by search engines. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17159319909387631227&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=15">Cited by 6</a> <a href="/scholar?q=related:e3pWKosmIu4J:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'e3pWKosmIu4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0925231212001518" class=yC10>Exploring multi-modality structure for cross domain adaptation in video concept annotation</a></h3><div class="gs_a">S Xu, S Tang, Y Zhang, J Li, YT Zheng - Neurocomputing, 2012 - Elsevier</div><div class="gs_rs">Domain adaptive video concept detection and annotation has recently received significant <br>attention, but in existing video adaptation processes, all the features are treated as one <br>modality, while multi-modalities, the unique and important property of video data, is <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:02zCLL48PksJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5421837788893048019&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'02zCLL48PksJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://libque.cityu.edu.hk/bitstream/2031/6211/1/abstract.html" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cityu.edu.hk</span><span class="gs_ggsS">cityu.edu.hk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://libque.cityu.edu.hk/handle/2031/6211" class=yC11>Video hyperlinking for multimedia search</a></h3><div class="gs_a">HK Tan - 2010 - libque.cityu.edu.hk</div><div class="gs_rs">ï»¿ With the spread of Web 2.0, web videos have become prevalent online. There is a growing <br>need for effective modeling and organization of video data to facilitate browsing or retrieval. <br>Meanwhile, the modeling of web pages through hyperlink graph has seen tremendous <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:gk0oVGtrZrQJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12999195483169115522&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'gk0oVGtrZrQJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md10', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md10" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:gk0oVGtrZrQJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=16418393280767177700&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Tat-Seng CHUA et al.(2009), Scholarpedia, 5 (5): 9546. doi: 10.4249/scholarpedia. 9546 revision# 91536 [link to/cite this article]</h3><div class="gs_a"><a href="/citations?user=6G-l4o0AAAAJ&amp;hl=en&amp;oi=sra">XS Hua</a>, <a href="/citations?user=jk5DWVMAAAAJ&amp;hl=en&amp;oi=sra">CW Ngo</a></div><div class="gs_fl"><a href="/scholar?q=related:1IxXY7WSOosJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'1IxXY7WSOosJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/470T3394G5101W71.pdf" class=yC13>Video Reference: A Video Question Answering Engine</a></h3><div class="gs_a"><a href="/citations?user=bOKmjf8AAAAJ&amp;hl=en&amp;oi=sra">L Gao</a>, G Li, YT Zheng, <a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, TS Chua - Advances in Multimedia  &hellip;, 2010 - Springer</div><div class="gs_rs">Community-based question answering systems have become very popular for providing <br>answers to a wide variety ofâ how-toâ questions. However, most such systems present only <br>textual answers. In many cases, users would prefer visual answers such as videos which <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:5A7YdD9KBhIJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1298807178946678500&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'5A7YdD9KBhIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0165168412002204" class=yC14>Multimedia encyclopedia construction by mining web knowledge</a></h3><div class="gs_a"><a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, ZJ Zha, Y Gao, TS Chua, X Wu - Signal Processing, 2012 - Elsevier</div><div class="gs_rs">Abstract In recent years, we have witnessed the blooming of Web 2.0 content such as <br>Wikipedia, Flickr and YouTube, etc. How might we benefit from such rich media resources <br>available on the internet? This paper presents a novel concept called Mediapedia, a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:-PXgd9tRpOoJ:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'-PXgd9tRpOoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://eprints.ucm.es/12662/1/T32908.pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ucm.es</span><span class="gs_ggsS">ucm.es <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://eprints.ucm.es/12662/" class=yC15>Uso de grafos semÃ¡nticos en la generaciÃ³n automÃ¡tica de resÃºmenes y estudio de su aplicaciÃ³n en distintos dominios: biomedicina, periodismo y turismo</a></h3><div class="gs_a"><a href="/citations?user=BDN9_RMAAAAJ&amp;hl=en&amp;oi=sra">L Plaza Morales</a> - 2011 - eprints.ucm.es</div><div class="gs_rs">En la sociedad en la que vivimos, la informaciÃ³n se ha convertido en un bien necesario, a la <br>vez que altamente cotizado, que nos acompaÃ±a en todas y cada una de nuestras <br>actividades sociales, culturales y econÃ³micas cotidianas. Sin embargo, el crecimiento <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:zGukuNUYxI8J:scholar.google.com/&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10359432349063867340&amp;hl=en&amp;num=15&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'zGukuNUYxI8J')" href="#" class="gs_nph">Cite</a></div></div></div>
