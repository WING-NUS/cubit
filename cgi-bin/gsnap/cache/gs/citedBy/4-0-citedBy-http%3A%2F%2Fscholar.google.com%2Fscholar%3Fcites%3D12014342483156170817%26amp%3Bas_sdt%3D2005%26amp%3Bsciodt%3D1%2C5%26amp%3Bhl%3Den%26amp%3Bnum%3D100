Total results = 4
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www-nlpir.nist.gov/projects/tvpubs/tv10.papers/nus-lms.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nist.gov</span><span class="gs_ggsS">nist.gov <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www-nlpir.nist.gov/projects/tvpubs/tv10.papers/nus-lms.pdf" class=yC0>TRECVID 2010 Known-item Search by NUS</a></h3><div class="gs_a">XY Chen, J Yuan, L Nie, ZJ Zha, <a href="/citations?user=DNuiPHwAAAAJ&amp;hl=en&amp;oi=sra">S Yan</a>&hellip; - TRECVID  &hellip;, 2010 - www-nlpir.nist.gov</div><div class="gs_rs">Abstract. This paper describes our system for auto search and interactive search in the <br>known-item search (KIS) task in TRECVID 2010. KIS task aims to find an unique video <br>answer for each text query. The shift from traditional video search has prompted a series <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12664714192218118309&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4">Cited by 3</a> <a href="/scholar?q=related:pVgCEXUawq8J:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'pVgCEXUawq8J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md0', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md0" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:pVgCEXUawq8J:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/VisionGo-%20Towards%20video%20retrieval%20with%20joint%20exploration%20of%20human%20and%20computer.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0020025511002672" class=yC2>VisionGo: towards video retrieval with joint exploration of human and computer</a></h3><div class="gs_a">H Luan, YT Zheng, <a href="/citations?user=rHagaaIAAAAJ&amp;hl=en&amp;oi=sra">M Wang</a>, TS Chua - Information Sciences, 2011 - Elsevier</div><div class="gs_rs">Abstract This paper introduces an effective interactive video retrieval system named <br>VisionGo. It jointly explores human and computer to accomplish video retrieval with high <br>effectiveness and efficiency. It assists the interactive video retrieval process in different <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15423134762805473061&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4">Cited by 2</a> <a href="/scholar?q=related:Ja__-1n7CdYJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15423134762805473061&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'Ja__-1n7CdYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://mcg.ict.ac.cn/download/pdf/paper/2008/29.VisionGo%20A%20High-performance%20and%20Multifunctional.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ict.ac.cn</span><span class="gs_ggsS">ict.ac.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://mcg.ict.ac.cn/download/pdf/paper/2008/29.VisionGo%20A%20High-performance%20and%20Multifunctional.pdf" class=yC4>VisionGo: A High-performance and Multi-functional Interactive Video Retrieval System</a></h3><div class="gs_a">H Luan, S Lin, Y Zhang, SY Neo, TS Chua - mcg.ict.ac.cn</div><div class="gs_rs">Abstract One of the most critical tasks in multimedia retrieval is the interactive video search. <br>This paper proposes an effective interactive video retrieval system named VisionGo to <br>improve the overall search performance. VisionGo provides three key functions to assist <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'D5KOBLqaupIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md2', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md2" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:D5KOBLqaupIJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://mclab.sogang.ac.kr/edb2009/submit/papers/%5Bmohan%5DNVideoCube.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from sogang.ac.kr</span><span class="gs_ggsS">sogang.ac.kr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://mclab.sogang.ac.kr/edb2009/submit/papers/%5Bmohan%5DNVideoCube.pdf" class=yC6>A New Data Cube System for the Multi-dimensional Analysis of News Videos</a></h3><div class="gs_a">H Lee, J Yu, H Jung, Y Im, D Park - mclab.sogang.ac.kr</div><div class="gs_rs">Abstractâ To devise a new paradigm for the analysis of news videos which can provide the <br>multi-dimensional analysis of a topic in a new video, we propose a novel data cube model, <br>viz., NVideoCube, which is able to manage systematically a news topic and analyze the <b> ...</b> </div><div class="gs_fl"><a href="/scholar?q=related:zuvWvcSz-K0J:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'zuvWvcSz-K0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md3', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md3" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:zuvWvcSz-K0J:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
