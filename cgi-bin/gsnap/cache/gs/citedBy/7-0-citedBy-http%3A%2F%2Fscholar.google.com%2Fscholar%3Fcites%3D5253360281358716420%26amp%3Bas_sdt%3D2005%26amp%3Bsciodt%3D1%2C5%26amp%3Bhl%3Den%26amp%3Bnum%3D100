Total results = 7
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://152.2.128.56/~sachin/papers/Berg-ISRR2011.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 152.2.128.56</span><span class="gs_ggsS">152.2.128.56 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://152.2.128.56/~sachin/papers/Berg-ISRR2011.pdf" class=yC0>Motion planning under uncertainty using differential dynamic programming in belief space</a></h3><div class="gs_a"><a href="/citations?user=VjsNXysAAAAJ&amp;hl=en&amp;oi=sra">J van den Berg</a>, <a href="/citations?user=zhUgtnAAAAAJ&amp;hl=en&amp;oi=sra">S Patil</a>, R Alterovitz - Int. Symp. on Robotics Research  &hellip;, 2011 - 152.2.128.56</div><div class="gs_rs">Abstract We present an approach to motion planning under motion and sensing uncertainty, <br>formally described as a continuous partially-observable Markov decision process (POMDP). <br>Our approach is designed for non-linear dynamics and observation models, and follows <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3969865721117438744&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7">Cited by 6</a> <a href="/scholar?q=related:GHM0EdfLFzcJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3969865721117438744&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'GHM0EdfLFzcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md0', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md0" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:GHM0EdfLFzcJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="https://www1.comp.nus.edu.sg/~leews/publications/rss11.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Ziy81kH3KfUC&amp;oi=fnd&amp;pg=PA1&amp;ots=ZYezt-4q6S&amp;sig=okrX4NgLqr0j_YZ15B09npXEhX8" class=yC2>Unmanned aircraft collision avoidance using continuous-state POMDPs</a></h3><div class="gs_a"><a href="/citations?user=ho595lUAAAAJ&amp;hl=en&amp;oi=sra">H Bai</a>, <a href="/citations?user=S9LHLKEAAAAJ&amp;hl=en&amp;oi=sra">D Hsu</a>, MJ Kochenderfer&hellip; - Robotics: Science and  &hellip;, 2012 - books.google.com</div><div class="gs_rs">AbstractâAn effective collision avoidance system for unmanned aircraft will enable them to <br>fly in civil airspace and greatly expand their applications. One promising approach is to <br>model aircraft collision avoidance as a partially observable Markov decision process (<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4705016597772573552&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7">Cited by 5</a> <a href="/scholar?q=related:cBuN3KqTS0EJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4705016597772573552&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'cBuN3KqTS0EJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://arl.cs.utah.edu/pubs/AAAI2012.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from utah.edu</span><span class="gs_ggsS">utah.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/viewPDFInterstitial/5159/5340" class=yC4>Efficient approximate value iteration for continuous Gaussian POMDPs</a></h3><div class="gs_a"><a href="/citations?user=VjsNXysAAAAJ&amp;hl=en&amp;oi=sra">J van den Berg</a>, <a href="/citations?user=zhUgtnAAAAAJ&amp;hl=en&amp;oi=sra">S Patil</a>, R Alterovitz - 26th AAAI conference on artificial  &hellip;, 2012 - aaai.org</div><div class="gs_rs">Abstract We introduce a highly efficient method for solving continuous partially-observable <br>Markov decision processes (POMDPs) in which beliefs can be modeled using Gaussian <br>distributions over the state space. Our method enables fast solutions to sequential <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14130097962501276761&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7">Cited by 1</a> <a href="/scholar?q=related:WQRcgDsxGMQJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14130097962501276761&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'WQRcgDsxGMQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://web.mit.edu/tirtha/Public/www/research/IntentionAware/wafr12iamp.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://web.mit.edu/tirtha/Public/www/research/IntentionAware/wafr12iamp.pdf" class=yC6>Intention aware motion planning</a></h3><div class="gs_a">T Bandyopadhyay, KS Won, <a href="/citations?user=8JGG3KcAAAAJ&amp;hl=en&amp;oi=sra">E Frazzoli</a>, <a href="/citations?user=S9LHLKEAAAAJ&amp;hl=en&amp;oi=sra">D Hsu</a>&hellip; - &hellip;  Foundations of Robotics &hellip;, 2012 - mit.edu</div><div class="gs_rs">Abstract As robots venture into new application domains as autonomous vehicles on the <br>road or as domestic helpers at home, they must recognize human intentions and behaviors <br>in order to operate effectively. This paper investigates a new class of motion planning <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5034716446994528123&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7">Cited by 1</a> <a onclick="return gs_ocit(event,'e_fs9-7n3kUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md3', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md3" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:e_fs9-7n3kUJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="https://www-new.comp.nus.edu.sg/~leews/publications/nips2011.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="https://www-new.comp.nus.edu.sg/~leews/publications/nips2011.pdf" class=yC8>Monte Carlo Value Iteration with Macro-Actions</a></h3><div class="gs_a">ZW Lim, <a href="/citations?user=S9LHLKEAAAAJ&amp;hl=en&amp;oi=sra">D Hsu</a>, <a href="/citations?user=8PCrLgwAAAAJ&amp;hl=en&amp;oi=sra">WS Lee</a> - www-new.comp.nus.edu.sg</div><div class="gs_rs">Abstract POMDP planning faces two major computational challenges: large state spaces <br>and long planning horizons. The recently introduced Monte Carlo Value Iteration (MCVI) can <br>tackle POMDPs with very large discrete state spaces or continuous state spaces, but its <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5079403010652539591&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7">Cited by 1</a> <a href="/scholar?q=related:x4r-WCCqfUYJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5079403010652539591&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'x4r-WCCqfUYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md4', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md4" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:x4r-WCCqfUYJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://arl.cs.utah.edu/pubs/IJRR2012-2.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from utah.edu</span><span class="gs_ggsS">utah.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ijr.sagepub.com/content/31/11/1263.short" class=yCA>Motion planning under uncertainty using iterative local optimization in belief space</a></h3><div class="gs_a"><a href="/citations?user=VjsNXysAAAAJ&amp;hl=en&amp;oi=sra">J van den Berg</a>, <a href="/citations?user=zhUgtnAAAAAJ&amp;hl=en&amp;oi=sra">S Patil</a>, R Alterovitz - The International Journal of  &hellip;, 2012 - ijr.sagepub.com</div><div class="gs_rs">Abstract We present a new approach to motion planning under sensing and motion <br>uncertainty by computing a locally optimal solution to a continuous partially observable <br>Markov decision process (POMDP). Our approach represents beliefs (the distributions of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8361653230193294661&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7">Cited by 2</a> <a href="/scholar?q=related:RT2rmE-PCnQJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8361653230193294661&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'RT2rmE-PCnQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://bigbird.comp.nus.edu.sg/~hannakur/papers/auro11_gcs.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/a04672558021t177.pdf" class=yCC>Global motion planning under uncertain motion, sensing, and environment map</a></h3><div class="gs_a"><a href="/citations?user=JkjFXbAAAAAJ&amp;hl=en&amp;oi=sra">H Kurniawati</a>, T Bandyopadhyay, <a href="/citations?user=cAaRCiUAAAAJ&amp;hl=en&amp;oi=sra">NM Patrikalakis</a> - Autonomous Robots, 2012 - Springer</div><div class="gs_rs">Abstract Uncertainty in motion planning is often caused by three main sources: motion error, <br>sensing error, and imperfect environment map. Despite the significant effect of all three <br>sources of uncertainty to motion planning problems, most planners take into account only <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7958919829216667751&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7">Cited by 3</a> <a href="/scholar?q=related:Z6hFoGrDc24J:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7958919829216667751&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">All 17 versions</a> <a onclick="return gs_ocit(event,'Z6hFoGrDc24J')" href="#" class="gs_nph">Cite</a></div></div></div>
