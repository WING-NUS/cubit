Total results = 11
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.comp.nus.edu.sg/~wangye/papers/3.Applications_in_Edutainment_(e-Learning)/2008_Application_Specific_Music_Transcription_for_Tutoring.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4623948" class=yC0>Application-specific music transcription for tutoring</a></h3><div class="gs_a">Y Wang, B Zhang - Multimedia, IEEE, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Automatic music transcription (AMT) refers to the ability of computers to write note <br>information, such as the pitch, onset time, duration, and source of each sound, after listening <br>to the music. Our application scenario is computer-assisted, musical-instrument tutoring, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=176626421973561276&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11">Cited by 5</a> <a href="/scholar?q=related:vK-ug8uAcwIJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=176626421973561276&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 18 versions</a> <a onclick="return gs_ocit(event,'vK-ug8uAcwIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="https://www1.comp.nus.edu.sg/~wangye/papers/3.Applications_in_Edutainment_(e-Learning)/2008_iDVT-An_Interactive_Digital_Violin_Tutoring_System_Based_on_Audio-Visual_Fusion.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="https://www1.comp.nus.edu.sg/~wangye/papers/3.Applications_in_Edutainment_(e-Learning)/2008_iDVT-An_Interactive_Digital_Violin_Tutoring_System_Based_on_Audio-Visual_Fusion.pdf" class=yC2>iDVT: an interactive digital violin tutoring system based on audio-visual fusion</a></h3><div class="gs_a">H Lu, B Zhang, Y Wang, WK Leow - Austria Association for  &hellip;, 2008 - comp.nus.edu.sg</div><div class="gs_rs">Computer-assisted musical instrumental tutoring (CAMIT) is catching eyes of many <br>researchers and musicologist in recent years. Projects providing general instructions are of <br>special interest since they are intended for self-learning and practice, the most frequent <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1454424884974841411&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11">Cited by 4</a> <a href="/scholar?q=related:Q-5pHbonLxQJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1454424884974841411&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 20 versions</a> <a onclick="return gs_ocit(event,'Q-5pHbonLxQJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md1', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md1" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Q-5pHbonLxQJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www.icsi.berkeley.edu/pubs/speech/educationalmultimedia08.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from berkeley.edu</span><span class="gs_ggsS">berkeley.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4623944" class=yC4>Educational Multimedia</a></h3><div class="gs_a"><a href="/citations?user=iBl-QgEAAAAJ&amp;hl=en&amp;oi=sra">G Friedland</a>, W Hurst, L Knipping - Multimedia, IEEE, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Making education more engaging, more enjoyable, and, in the end, more effective <br>through the use of multimedia technology has been the goal of many researchers during the <br>past few years. Encouraging results have been achieved so far. There are many examples <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16346699668437120009&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11">Cited by 5</a> <a href="/scholar?q=related:CbQwa70k2-IJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16346699668437120009&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'CbQwa70k2-IJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://numediart.org/docs/numediart_2009_s07_p1_report.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from numediart.org</span><span class="gs_ggsS">numediart.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://numediart.org/docs/numediart_2009_s07_p1_report.pdf" class=yC6>Multimodal Guitar: Performance Toolbox and Study Workbench</a></h3><div class="gs_a">C Frisson, L ReboursiÃ¨re, WY Chu&hellip; - QPSR of the numediart &hellip;, 2009 - numediart.org</div><div class="gs_rs">ABSTRACT This project aims at studying how recent interactive and interaction technologies <br>would help extend how we play the guitar, thus defining the âmultimodal guitarâ. We <br>investigate two axes, 1)âA gestural/polyphonic sensing/processing toolbox to augment <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3723913816448989750&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11">Cited by 3</a> <a href="/scholar?q=related:Nnqcy-L_rTMJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3723913816448989750&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'Nnqcy-L_rTMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md3', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md3" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Nnqcy-L_rTMJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/3056/1/TRA7-09.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="https://dl.comp.nus.edu.sg/dspace/handle/1900.100/3056" class=yC8>Automatic music transcription using audio-visual fusion for violin practice in home environment</a></h3><div class="gs_a">B Zhang, Y Wang - 2009 - dl.comp.nus.edu.sg</div><div class="gs_rs">Abstract: Violin practice in a home environment, where there is often no teacher available, <br>can benefit from automatic music transcription to provide feedback to the student. This paper <br>describes a high performance violin transcription system with three main contributions. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15951167519198165592&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11">Cited by 2</a> <a href="/scholar?q=related:WDqOhljuXd0J:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15951167519198165592&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'WDqOhljuXd0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://tuprints.ulb.tu-darmstadt.de/2797/" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from tu-darmstadt.de</span><span class="gs_ggsS">tu-darmstadt.de <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[HTML]</span><span class="gs_ct2">[HTML]</span></span> <a href="http://tuprints.ulb.tu-darmstadt.de/2797/" class=yCA>Sensor-Based Feedback for Piano Pedagogy</a></h3><div class="gs_a">A Hadjakos - 2011 - tuprints.ulb.tu-darmstadt.de</div><div class="gs_rs">Recent advances in sensor technology provide new opportunities for applications that utilize <br>the user&#39;s movement as an input source. This thesis focuses on movement analysis, which is <br>a sub-area of a larger field concerned with the interpretation of sensor signals of human <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1431005494359207476&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11">Cited by 1</a> <a href="/scholar?q=related:NK7pUurz2xMJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'NK7pUurz2xMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md5', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md5" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:NK7pUurz2xMJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a>  <a href="/scholar?q=info:NK7pUurz2xMJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=10198542924567585597&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://www.cmlab.csie.ntu.edu.tw/~zenic/Download/ICME2012/Workshops/data/4729a163.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntu.edu.tw</span><span class="gs_ggsS">ntu.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6266249" class=yCC>Real-Time Pitch Training System for Violin Learners</a></h3><div class="gs_a">JH Wang, SA Wang, WC Chen&hellip; - Multimedia and Expo &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper specifically targets violin learners who are working on their pitch <br>accuracy. We employ a pitch tracking algorithm to extract the pitch played. Through volume <br>thresholding and region detection, only parts of frames are processed. So our system can <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:gMp1DiddLkkJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5273254636025137792&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'gMp1DiddLkkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://137.132.14.55/bitstream/handle/10635/20949/ZhangBJ.pdf?sequence=1" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.14.55</span><span class="gs_ggsS">137.132.14.55 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://137.132.14.55/handle/10635/20949" class=yCE>Adaptive multimodal fusion based similarity measures in music information retrieval</a></h3><div class="gs_a">Z BINGJUN - 2010 - 137.132.14.55</div><div class="gs_rs">In the field of music information retrieval (MIR), one fundamental research problem is the <br>measuring of the similarity between music documents. Based on a viable similarity measure, <br>MIR systems can be made more effective to help users retrieve relevant music information. <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:9FjpHoxTlRIJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1339068325491726580&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'9FjpHoxTlRIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.172.3219&amp;rep=rep1&amp;type=pdf#page=26" class=yC11><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.172.3219&amp;rep=rep1&amp;type=pdf#page=26" class=yC10>Project# 03 Multimodal Guitar: Performance Toolbox and Study Workbench</a></h3><div class="gs_a">C Frisson, L Reboursiere, WY Chu, O LÃ¤hdeoja&hellip; - on Multimodal Interfaces &hellip;, 2009 - Citeseer</div><div class="gs_rs">AbstractâThis project aims at studying how recent interactive and interaction technologies <br>would help extend how we play the guitar, thus defining the âmultimodal guitarâ. We <br>investigate two axes, 1)âA gestural/polyphonic sensing/processing toolbox to augment <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:9IzfhnW3LSQJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'9IzfhnW3LSQJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md8', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md8" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:9IzfhnW3LSQJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.actapress.com/PDFViewer.aspx?paperId=452988" class=yC12>A Context-based Emotion-Analyzer for Teaching Tonality in Music Courses</a></h3><div class="gs_a">A Ichinose, S Kurabayashi, Y Kiyoki - Technology for Education/758:  &hellip;, 2011 - actapress.com</div><div class="gs_rs">ABSTRACT This paper presents a context-based emotion-analyzer dedicated for supporting <br>to learn tonality in music courses. This emotion-analyzer realizes a new music retrieval <br>environment to find and visualize music items with considering genre dependent <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:0297oUbKgIgJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9836083990882906067&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'0297oUbKgIgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://www.lps.usp.br/~magno/papers/SBGames10.pdf" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from usp.br</span><span class="gs_ggsS">usp.br <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.lps.usp.br/~magno/papers/SBGames10.pdf" class=yC13>Rainbow Strings: Jogo para aprendizado de violino com processamento de audio</a></h3><div class="gs_a">PRR Vianna, R Nakamura, EMF Mesquita, <a href="/citations?user=1W7daz4AAAAJ&amp;hl=en&amp;oi=sra">MTM Silva</a>&hellip; - lps.usp.br</div><div class="gs_rs">Resumo Neste artigo discute-se o desenvolvimento do jogo âRainbow Stringsâ, com <br>finalidades lÃºdica e didÃ¡tica. Trata-se de um jogo para computadores que apresenta uma <br>partitura musical simplificada, ao mesmo tempo em que o som de um violino tocado pelo <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:mHNpPmXYeEgJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5222161697286484888&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'mHNpPmXYeEgJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md10', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md10" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:mHNpPmXYeEgJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
