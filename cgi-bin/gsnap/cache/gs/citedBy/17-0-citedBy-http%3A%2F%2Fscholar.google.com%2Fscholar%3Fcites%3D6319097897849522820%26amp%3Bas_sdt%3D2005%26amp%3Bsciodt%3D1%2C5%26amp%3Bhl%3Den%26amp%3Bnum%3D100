Total results = 17
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://ericmyl.sg1003.myweb.hinet.net/Statistical%20sequential%20analysis%20for%20real-time%20video%20scene%20change%20detection%20on%20compressed%20multimedia%20bitstream.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hinet.net</span><span class="gs_ggsS">hinet.net <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1196740" class=yC0>Statistical sequential analysis for real-time video scene change detection on compressed multimedia bitstream</a></h3><div class="gs_a">D Lelescu, <a href="/citations?user=3czLfNYAAAAJ&amp;hl=en&amp;oi=sra">D Schonfeld</a> - Multimedia, IEEE Transactions on, 2003 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The increased availability and usage of multimedia information have created a <br>critical need for efficient multimedia processing algorithms. These algorithms must offer <br>capabilities related to browsing, indexing, and retrieval of relevant data. A crucial step in <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11319092489533464324&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 85</a> <a href="/scholar?q=related:BB9v6qV-FZ0J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/12/38/RN138892279.html?source=googlescholar" class="gs_nph" class=yC2>BL Direct</a> <a href="/scholar?cluster=11319092489533464324&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'BB9v6qV-FZ0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.527&amp;rep=rep1&amp;type=pdf" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.527&amp;rep=rep1&amp;type=pdf" class=yC3>A match and tiling approach to content-based video retrieval</a></h3><div class="gs_a">L Chen, TS Chua - IEEE Int&#39;l Conf. on Multimedia and Expo, 2001 - Citeseer</div><div class="gs_rs">Abstract This paper presents a novel match-and-tiling approach to retrieve video sequences. <br>The approach considers video similarity matching at two levels--the shot and sequence <br>levels. At the shot level, we transform the matching of similar shots into a problem of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12598180052345091908&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 67</a> <a href="/scholar?q=related:RPdwdAK61a4J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12598180052345091908&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'RPdwdAK61a4J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md1', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md1" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:RPdwdAK61a4J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/mmm05-young.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1385976" class=yC5>Retrieval of news video using video sequence matching</a></h3><div class="gs_a">Y Kim, TS Chua - &hellip; , 2005. MMM 2005. Proceedings of the 11th  &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose a new algorithm to find video clips with different temporal <br>durations and some spatial variations. We adopt a longest common sub-sequence (LCS) <br>matching technique for measuring the temporal similarity between video clips. Based on <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3349308960069176840&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 43</a> <a href="/scholar?q=related:CM7098Aiey4J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3349308960069176840&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'CM7098Aiey4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.17.9790&amp;rep=rep1&amp;type=pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.17.9790&amp;rep=rep1&amp;type=pdf" class=yC7>Cinematic-based model for scene boundary detection</a></h3><div class="gs_a">J Wang, TS Chua, L Chen - The Eight Conference on Multimedia Modeling, 2001 - Citeseer</div><div class="gs_rs">Most current video retrieval systems use shot as the basic unit for information organization <br>and access. A shot, however, models only a visually contiguous sequence of video frames <br>with no coherent semantic meanings. On the other hand, viewers tend to âviewâ video <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7876418633163114793&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 17</a> <a href="/scholar?q=related:KYn0CwSpTm0J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7876418633163114793&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'KYn0CwSpTm0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md3', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md3" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:KYn0CwSpTm0J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/acmmm02-wangjh.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=641055" class=yC9>A framework for video scene boundary detection</a></h3><div class="gs_a">J Wang, TS Chua - Proceedings of the tenth ACM international  &hellip;, 2002 - dl.acm.org</div><div class="gs_rs">Abstract Most current video retrieval systems use shot as the basis for information <br>organization and access. In cinematography, scene is the basic story unit that the directors <br>use to convey their ideas. This paper proposes a framework based on the concept of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2323743190817835309&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 17</a> <a href="/scholar?q=related:LQnuzR6YPyAJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2323743190817835309&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'LQnuzR6YPyAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.68.8466&amp;rep=rep1&amp;type=pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1246855" class=yCB>Frame difference normalization: an approach to reduce error rates of cut detection algorithms for MPEG videos</a></h3><div class="gs_a">R Ewerth, B Freisleben - Image Processing, 2003. ICIP 2003.  &hellip;, 2003 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The segmentation of video sequences into shots is the first step towards video <br>content analysis. Two kinds of shot boundaries can be distinguished: abrupt scene changes <br>(&quot; cuts&quot;) and gradual transitions. In this paper, we present a technique to reduce the error <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18258367474768066799&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 10</a> <a href="/scholar?q=related:77gYOHvAYv0J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18258367474768066799&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'77gYOHvAYv0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://pdf.aminer.org/000/346/640/improving_cut_detection_in_mpeg_videos_by_gop_oriented_frame.pdf" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aminer.org</span><span class="gs_ggsS">aminer.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1334381" class=yCD>Improving cut detection in MPEG videos by GOP-oriented frame difference normalization</a></h3><div class="gs_a">R Ewerth, B Freisleben - &hellip; , 2004. ICPR 2004. Proceedings of the &hellip;, 2004 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The detection of abrupt shot changes (&quot; cuts&quot;) in videos is a basic step in video <br>content analysis. Many cut detection algorithms based on histogram differences have been <br>proposed in the literature, and it has been shown for the MPEG (moving picture experts <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1233150834724594396&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 10</a> <a href="/scholar?q=related:3GI8kiYIHREJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1233150834724594396&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'3GI8kiYIHREJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/visual03.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/empenryggg0alg96.pdf" class=yCF>A cinematic-based framework for scene boundary detection in video</a></h3><div class="gs_a">J Wang, TS Chua - The Visual Computer, 2003 - Springer</div><div class="gs_rs">Most current video retrieval systems use shots as the basis for information organization and <br>access. In cinematography, scene is the basic story unit that the directors use to compose <br>and convey their ideas. This paper proposes a framework based on the concept of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16541083775778629801&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 6</a> <a href="/scholar?q=related:qShDPw68jeUJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/4B/32/RN137115916.html?source=googlescholar" class="gs_nph" class=yC11>BL Direct</a> <a href="/scholar?cluster=16541083775778629801&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'qShDPw68jeUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.58.7472&amp;rep=rep1&amp;type=pdf" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.58.7472&amp;rep=rep1&amp;type=pdf" class=yC12>Video transition: modelling and prediction</a></h3><div class="gs_a">W Ren, S Singh - Pattern Analysis and Neural Networks, PANN, http:// &hellip;, 2003 - Citeseer</div><div class="gs_rs">Abstract This paper uses a neural network and a k-nearest neighbor classifier for modelling <br>transitions in video based on a number of statistical measures derived from video images. <br>The transitions modelled include: cut, fade in, fade out, dissolve, tilt up, tilt down, pan left <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14210284765712708075&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 2</a> <a href="/scholar?q=related:63FzgbQSNcUJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14210284765712708075&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'63FzgbQSNcUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md8', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md8" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:63FzgbQSNcUJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/48JN17X68303Q822.pdf" class=yC14>Unsupervised Detection of Gradual Video Shot Changes with Motion-Based False Alarm Removal</a></h3><div class="gs_a">R Ewerth, B Freisleben - Advanced Concepts for Intelligent Vision Systems, 2009 - Springer</div><div class="gs_rs">The temporal segmentation of a video into shots is a fundamental prerequisite for video <br>retrieval. There are two types of shot boundaries: abrupt shot changes (âcutsâ) and gradual <br>transitions. Several high-quality algorithms have been proposed for detecting cuts, but the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5992289900683083630&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:bj9gierjKFMJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5992289900683083630&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'bj9gierjKFMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.103.3254&amp;rep=rep1&amp;type=pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.103.3254&amp;rep=rep1&amp;type=pdf" class=yC15>Wavelet Based Video Segmentation and Indexing</a></h3><div class="gs_a">K Murmu, V Kumar - EE678 Wavelets Application Assignment (April 2005) - Citeseer</div><div class="gs_rs">Abstract Video segmentation is a basic step in many video processing applications and <br>automatic video indexing is an important feature in the design of a video database. Wavelet <br>transform has emerged as a powerful tool for analysis and efficient compression of visual <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16406589311735986447&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:D3m-nQ3qr-MJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16406589311735986447&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'D3m-nQ3qr-MJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md10', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md10" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:D3m-nQ3qr-MJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.113.7552&amp;rep=rep1&amp;type=pdf" class=yC18><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.113.7552&amp;rep=rep1&amp;type=pdf" class=yC17>A Multi-Level Approach for Video Temporal Segmentation based on Adaptive Examples</a></h3><div class="gs_a">RB Yeganeh - 2006 - Citeseer</div><div class="gs_rs">Abstract Over the past decade, various methods for video shot boundary detection and <br>classification have been proposed and implemented by numerous researchers. <br>Nonetheless, many of these techniques are specific to the type of transition or they are <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18355740368023288414&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:XnpToZywvP4J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18355740368023288414&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'XnpToZywvP4J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md11', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md11" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:XnpToZywvP4J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://hostmaster.icaci.org/files/documents/ICC_proceedings/ICC2011/Oral%20Presentations%20PDF/E2-Generalisation%20-%20geovisualisation/CO-451.pdf" class=yC1A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from icaci.org</span><span class="gs_ggsS">icaci.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://hostmaster.icaci.org/files/documents/ICC_proceedings/ICC2011/Oral%20Presentations%20PDF/E2-Generalisation%20-%20geovisualisation/CO-451.pdf" class=yC19>TIMELINE: A tool for the video analysis and visualisation of geographic phenomena over time</a></h3><div class="gs_a">M Kuhn, S Pfister, I Vontobel, C Willi&hellip; - &hellip;  of the ICC, 2011 - hostmaster.icaci.org</div><div class="gs_rs">ABSTRACT The growing number of webcams and their rapidly improving quality provide the <br>researchers in Cartography and in other fields of Geography with a valuable source of <br>information, ie webcam recordings can be used to study many kinds of geographic <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1978000170618225723&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:O4Rc36xEcxsJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1978000170618225723&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'O4Rc36xEcxsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md12', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md12" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:O4Rc36xEcxsJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532651" class=yC1B>Software libraries of intelligent transportation system based on GIS</a></h3><div class="gs_a">L Mei - Cognitive Informatics, 2005.(ICCI 2005). Fourth IEEE  &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The intelligent vehicle monitor system based on GIS was experimentally studied. <br>This paper describes the development of a new GIS library that is aimed at providing a rich <br>and powerful environment for the development of GIS research. The motivation for this <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:LMnRODwqyZgJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11009377202223565100&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'LMnRODwqyZgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> CONTENT-BASED RETRIEVAL OF VIDEO SEQUENCES</h3><div class="gs_a">L CHEN, TS CHUA</div><div class="gs_fl"><a href="/scholar?q=related:f0b9WjOur0EJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4733193268982793855&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'f0b9WjOur0EJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://www.ceaj.org/Jweb_gcyyy/EN/article/downloadArticleFile.do?attachType=PDF&amp;id=23784" class=yC1D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ceaj.org</span><span class="gs_ggsS">ceaj.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ceaj.org/Jweb_gcyyy/EN/article/downloadArticleFile.do?attachType=PDF&amp;id=23784" class=yC1C>åºäºé«æç²¾ç¡®çæå¤§å¬å±å­åºåçè§é¢çæ®µå¹é</a></h3><div class="gs_a">å¼ çè£ï¼ è°¢æ§ - Computer Engineering and Applications, 2010 - ceaj.org</div><div class="gs_rs">æè¦: ä¸ºè§é¢åºåå¹éæåºä¸ä¸ªé«æç²¾ç¡®çæå¤§å¬å±å­åºå(Efficient and Effective Longest <br>Common Subsequence, EELCS) ç®æ³. é¦å, å©ç¨ç¢ééå(Vector Quantization, VQ) <br>å°å¤ç»´æå¤§å¬å±å­åºåç®æ³(Multi-dimensional LCS, MLCS) ä¸­åç´ å¯¹å¹éè¿ç¨ä¸­çå®éè·ç¦»<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:7kYmNKLfbvwJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18189721832748631790&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'7kYmNKLfbvwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md15', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md15" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:7kYmNKLfbvwJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/97360a/200416/10371179.html" class=yC1E>åºäºç»è®¡æ¨¡åçè§é¢åå²æ£æµç®æ³</a></h3><div class="gs_a">ççï¼ æ¾è´µåï¼ å¾æ­£å¨ - ç°ä»£çµå­ææ¯, 2004 - cqvip.com</div><div class="gs_rs">è§é¢åå²æ¯è§é¢ç»æååæ£ç´¢çéè¦ææ¯, ç®åä¸»è¦éè¿éå¤´åå²å¾å°. æ¬æåºäºç»è®¡æ¨¡åæåº<br>äºä¸ç§æ¹è¿çç®æ³, å¹¶å°ç®æ³åºç¨äºéåç¼©åä¸­è¿è¡è§é¢åå², å¾åºäºä¸ç§ç®åä¸å®æ½æ§é«ç<br>è§é¢åå²æ¹æ³, å¹¶ç¨Matlab è½¯ä»¶æ¥å®ç°äºä¸ä¸ªè§é¢åå²çå®ä¾. ä»å®éªå¯ä»¥çåº, æ¬æ¹æ³å¨<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:P_bauaWc8hcJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1725613842837993023&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'P_bauaWc8hcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
