Total results = 8
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www1.i2r.a-star.edu.sg/~yzheng/papers/visiongo-civr09.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from a-star.edu.sg</span><span class="gs_ggsS">a-star.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1646396.1646456" class=yC0>Visiongo: towards true interactivity</a></h3><div class="gs_a">YT Zheng, SY Neo, X Chen, TS Chua - Proceedings of the ACM  &hellip;, 2009 - dl.acm.org</div><div class="gs_rs">Abstract This paper presents our interactive video retrieval system VisionGo. To achieve <br>high interactivity, the system is fitted with a mouse stroke labeling interface, in which users <br>can use mouse to draw the bounding box of target object via a simple mouse stroke. To <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10651626172402820200&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 10</a> <a href="/scholar?q=related:aORSrpEt0pMJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10651626172402820200&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'aORSrpEt0pMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1386430" class=yC2>Visiongo: bridging users and multimedia video retrieval</a></h3><div class="gs_a">SY Neo, H Luan, Y Zheng, HK Goh&hellip; - Proceedings of the 2008  &hellip;, 2008 - dl.acm.org</div><div class="gs_rs">Abstract This paper describes our system VisionGo which provides an interactive platform <br>for video retrieval. The system is fitted with an intuitive interface and an automated backend <br>recommender that recommends users the optimal feedback technique during retrieval.</div><div class="gs_fl"><a href="/scholar?cites=8634606947918588603&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 6</a> <a href="/scholar?q=related:u6rOYUVJ1HcJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8634606947918588603&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'u6rOYUVJ1HcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/civr10-yuanjin.pdf" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1816041.1816053" class=yC3>Utilizing related samples to learn complex queries in interactive concept-based video search</a></h3><div class="gs_a">J Yuan, ZJ Zha, Z Zhao, <a href="/citations?user=QUrLihYAAAAJ&amp;hl=en&amp;oi=sra">X Zhou</a>, TS Chua - Proceedings of the ACM  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract One of the main challenges in interactive concept-based video search is the <br>insufficient relevant sample problem, especially for queries with complex semantics. To <br>address this problem, in this paper, we propose to utilize&quot; related samples&quot; to learn the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9335504255283517338&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 7</a> <a href="/scholar?q=related:mldSl6hfjoEJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9335504255283517338&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'mldSl6hfjoEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://www-nlpir.nist.gov/projects/tvpubs/tv10.papers/nus-lms.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nist.gov</span><span class="gs_ggsS">nist.gov <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www-nlpir.nist.gov/projects/tvpubs/tv10.papers/nus-lms.pdf" class=yC5>TRECVID 2010 Known-item Search by NUS</a></h3><div class="gs_a">XY Chen, J Yuan, L Nie, ZJ Zha, <a href="/citations?user=DNuiPHwAAAAJ&amp;hl=en&amp;oi=sra">S Yan</a>&hellip; - TRECVID  &hellip;, 2010 - www-nlpir.nist.gov</div><div class="gs_rs">Abstract. This paper describes our system for auto search and interactive search in the <br>known-item search (KIS) task in TRECVID 2010. KIS task aims to find an unique video <br>answer for each text query. The shift from traditional video search has prompted a series <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12664714192218118309&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 3</a> <a href="/scholar?q=related:pVgCEXUawq8J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'pVgCEXUawq8J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md3', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md3" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:pVgCEXUawq8J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="https://www.ee.ucr.edu/~amitrc/accv10.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ucr.edu</span><span class="gs_ggsS">ucr.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/BM2622607J482374.pdf" class=yC7>Interactive event search through transfer learning</a></h3><div class="gs_a">A Lam, <a href="/citations?user=hfgwx0oAAAAJ&amp;hl=en&amp;oi=sra">A Roy-Chowdhury</a>, <a href="/citations?user=9xbbxGcAAAAJ&amp;hl=en&amp;oi=sra">C Shelton</a> - Computer VisionâACCV 2010, 2011 - Springer</div><div class="gs_rs">Activity videos are widespread on the Internet but current video search is limited to text tags <br>due to limitations in recognition systems. One of the main reasons for this limitation is the <br>wide variety of activities users could query. Thus codifying knowledge for all queries <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12240885240099215932&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 1</a> <a href="/scholar?q=related:PJpvWEVc4KkJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12240885240099215932&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'PJpvWEVc4KkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://scholarbank.nus.edu.sg/bitstream/handle/10635/15902/thesis.pdf?sequence=1" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://scholarbank.nus.edu.sg/handle/10635/15902" class=yC9>Multi-graph based active learning for interactive video retrieval</a></h3><div class="gs_a">Z XIAOMING - 2009 - scholarbank.nus.edu.sg</div><div class="gs_rs">Active learning and semi-supervised learning are important machine learning techniques <br>when labeled data is scarce or expensive to obtain. We employ a graph based semi-<br>supervised learning method where a node in the graph represents a video shot and they <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:QucDPVEHpPEJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17412050104818591554&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'QucDPVEHpPEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://rlair.cs.ucr.edu/papers/docs/alam-phd.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ucr.edu</span><span class="gs_ggsS">ucr.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://rlair.cs.ucr.edu/papers/docs/alam-phd.pdf" class=yCB>Learning Ranking Functions for Video Search on the Web</a></h3><div class="gs_a">AM Lam - 2010 - rlair.cs.ucr.edu</div><div class="gs_rs">Doing a PhD has been a challenging but very rewarding experience. In my years as a <br>student, I have had the good fortune of having many kind and supportive people in my life. <br>First of all, I would like to thank my advisors Dr. Christian R. Shelton and Dr. Amit K. Roy-<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:-IL7ikUNFzMJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3681425812734313208&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'-IL7ikUNFzMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md6', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md6" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:-IL7ikUNFzMJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a>  <a href="/scholar?q=info:-IL7ikUNFzMJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=3370132156388906206&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://www.ijmt.org/Download.aspx?ID=75" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ijmt.org</span><span class="gs_ggsS">ijmt.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.ijmt.org/paperInfo.aspx?ID=75" class=yCD>A High-Level Survey of Video Annotation and Retrieval Systems</a></h3><div class="gs_a">R Sorschag - International Journal of Multimedia Technology, 2012 - ijmt.org</div><div class="gs_rs">Abstract: Videos are an integral part of current information technologies and the web. The <br>demand for efficient retrieval rises with the increasing number of videos, which is equally <br>true for video annotation techniques as matadata is the primary source of most retrieval <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'DtrwzmdipQcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
