Total results = 18
<div class="gs_r" style="z-index:400"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6200340" class=yC0>3-D Object Retrieval and Recognition With Hypergraph Analysis</a></h3><div class="gs_a">Y Gao, <a href="/citations?user=rHagaaIAAAAJ&amp;hl=en&amp;oi=sra">M Wang</a>, D Tao, <a href="/citations?user=lRSD7PQAAAAJ&amp;hl=en&amp;oi=sra">R Ji</a>&hellip; - Image Processing, IEEE  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract View-based 3-D object retrieval and recognition has become popular in practice, <br>eg, in computer aided design. It is difficult to precisely estimate the distance between two <br>objects represented by multiple views. Thus, current view-based 3-D object retrieval and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12532053764025911332&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 11</a> <a href="/scholar?q=related:JIjcLoDM6q0J:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12532053764025911332&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'JIjcLoDM6q0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6212356" class=yC1>Visual-Textual Joint Relevance Learning for Tag-Based Social Image Search</a></h3><div class="gs_a">Y Gao, <a href="/citations?user=rHagaaIAAAAJ&amp;hl=en&amp;oi=sra">M Wang</a>, ZJ Zha, <a href="/citations?user=d3h-zScAAAAJ&amp;hl=en&amp;oi=sra">J Shen</a>, X Li, X Wu - 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract With the popularity of social media websites, extensive research efforts have been <br>dedicated to tag-based social image search. Both visual information and tags have been <br>investigated in the research field. However, most existing methods use tags and visual <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3875216273605194683&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 4</a> <a href="/scholar?q=related:u_MMSKuIxzUJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3875216273605194683&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'u_MMSKuIxzUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0020025512000217" class=yC2>k-Partite graph reinforcement and its application in multimedia information retrieval</a></h3><div class="gs_a">Y Gao, <a href="/citations?user=rHagaaIAAAAJ&amp;hl=en&amp;oi=sra">M Wang</a>, <a href="/citations?user=lRSD7PQAAAAJ&amp;hl=en&amp;oi=sra">R Ji</a>, Z Zha, <a href="/citations?user=d3h-zScAAAAJ&amp;hl=en&amp;oi=sra">J Shen</a> - Information Sciences, 2012 - Elsevier</div><div class="gs_rs">In many example-based information retrieval tasks, example query actually contains multiple <br>sub-queries. For example, in 3D object retrieval, the query is an object described by multiple <br>views. In content-based video retrieval, the query is a video clip that contains multiple <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11226411520702169103&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 4</a> <a href="/scholar?q=related:D0DOScw5zJsJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11226411520702169103&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'D0DOScw5zJsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0165168412001120" class=yC3>3D face recognition using local binary patterns</a></h3><div class="gs_a">H Tang, B Yin, Y Sun, Y Hu - Signal Processing, 2012 - Elsevier</div><div class="gs_rs">Abstract It is well recognized that expressions can significantly change facial geometry that <br>results in a severe problem for robust 3D face recognition. So it is crucial for many <br>applications that how to extract expression-robust features to describe 3D faces. In this <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6718963713126592870&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 1</a> <a href="/scholar?q=related:ZnGmA-aNPl0J:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'ZnGmA-aNPl0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0925231212009046" class=yC4>Richang Hong, Linxie Tang, Jun Hu, Guanda Li, Jiang-Guo Jiang</a></h3><div class="gs_a"><a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, L Tang, J Hu, G Li, JG Jiang - Neurocomputing, 2013 - Elsevier</div><div class="gs_rs">Abstract We have witnessed the booming of contextual video advertising recent years. <br>However, those advertisement systems solely take the metadata into account, such as titles, <br>descriptions and tags. This kind of text-based contextual advertising reveals a number of <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'qWujGb64isAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0925231212001798" class=yC5>Shape-based retrieval and analysis of 3D models using fuzzy weighted symmetrical depth images</a></h3><div class="gs_a">KS Zou, CK Chan, SX Peng, A Luximon, ZQ Chen&hellip; - Neurocomputing, 2012 - Elsevier</div><div class="gs_rs">With the rapid development of 3D scanners, graphic accelerated hardware and 3D modeling <br>tools, the application of 3D model databases is growing in both numbers and sizes, eg 3D <br>body scans, head model and virtual mannequins. There is a pressing need for effective <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:-WIdIgLqUWkJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7589104141979181817&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'-WIdIgLqUWkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/3814073404146268.pdf" class=yC6>A novel 3D model retrieval approach using combined shape distribution</a></h3><div class="gs_a">KS Zou, WH Ip, CH Wu, ZQ Chen, KL Yung&hellip; - Multimedia Tools and  &hellip;, 2012 - Springer</div><div class="gs_rs">Abstract With the rapid development of 3D digital shape information, content-based 3D <br>model retrieval has become an important research field. 3D models are likely to be as <br>prevalent as other multimedia data types in the future. There is a pressing need for <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:95NzMkXAtEwJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'95NzMkXAtEwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://arxiv.org/pdf/1208.3670" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arxiv.org</span><span class="gs_ggsS">arxiv.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://arxiv.org/abs/1208.3670" class=yC7>A Survey of Recent View-based 3D Model Retrieval Methods</a></h3><div class="gs_a">Q Liu - arXiv preprint arXiv:1208.3670, 2012 - arxiv.org</div><div class="gs_rs">Abstract: Extensive research efforts have been dedicated to 3D model retrieval in recent <br>decades. Recently, view-based methods have attracted much research attention due to the <br>high discriminative property of multi-views for 3D object representation. In this report, we <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:RIjJQt9Ul0MJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4870454839899424836&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'RIjJQt9Ul0MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6169948" class=yC9>Cross-View Down/Up-Sampling Method for Multiview Depth Video Coding</a></h3><div class="gs_a">Q Liu, Y Yang, <a href="/citations?user=lRSD7PQAAAAJ&amp;hl=en&amp;oi=sra">R Ji</a>, Y Gao, L Yu - Signal Processing Letters,  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this letter, we propose a cross-view down/up-sampling (CDU) method for the <br>framework of reduced resolution multiview depth video coding, which exploits cross-view <br>information to assist the up-sampling at the decoder. In the down-sampling procedure of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14719902236864679726&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 2</a> <a href="/scholar?q=related:Lg_MVBiZR8wJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14719902236864679726&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'Lg_MVBiZR8wJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://dx.plos.org/10.1371/journal.pone.0047041" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from plos.org</span><span class="gs_ggsS">plos.org <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[HTML]</span><span class="gs_ct2">[HTML]</span></span> <a href="http://dx.plos.org/10.1371/journal.pone.0047041" class=yCA>Dynamic 3D Scene Depth Reconstruction via Optical Flow Field Rectification</a></h3><div class="gs_a">Y Yang, Q Liu, <a href="/citations?user=lRSD7PQAAAAJ&amp;hl=en&amp;oi=sra">R Ji</a>, Y Gao - PloS one, 2012 - dx.plos.org</div><div class="gs_rs">In this paper, we propose a depth propagation scheme based on optical flow field <br>rectification towards more accurate depth reconstruction. In depth reconstruction, the <br>occlusions and low-textural regions easily result in optical flow field errors, which lead <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'PWh2ZSNOuyMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md9', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md9" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:PWh2ZSNOuyMJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://www.cmlab.csie.ntu.edu.tw/~zenic/Download/ICME2012/Conference/data/4711a344.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntu.edu.tw</span><span class="gs_ggsS">ntu.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6298421" class=yCC>Activity Recognition from RGB-D Camera with 3D Local Spatio-temporal Features</a></h3><div class="gs_a">Y Ming, Q Ruan, <a href="/citations?user=Py54GcEAAAAJ&amp;hl=en&amp;oi=sra">AG Hauptmann</a> - Multimedia and Expo (ICME), &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Kinect, as a 3D digital capturing device, can collect the RGB and depth information <br>of human activities rapidly. We study fusing the depth and RGB information for activity <br>recognition. We introduce histogram color-based image thresholding to detect skin on <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:NzRmcTo9rFgJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6389549292551812151&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'NzRmcTo9rFgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0165168412002204" class=yCE>Multimedia encyclopedia construction by mining web knowledge</a></h3><div class="gs_a"><a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, ZJ Zha, Y Gao, TS Chua, X Wu - Signal Processing, 2012 - Elsevier</div><div class="gs_rs">Abstract In recent years, we have witnessed the blooming of Web 2.0 content such as <br>Wikipedia, Flickr and YouTube, etc. How might we benefit from such rich media resources <br>available on the internet? This paper presents a novel concept called Mediapedia, a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:-PXgd9tRpOoJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'-PXgd9tRpOoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S1047320312001010" class=yCF>Rapid 3D face reconstruction by fusion of SFS and Local Morphable Model</a></h3><div class="gs_a">H Liao, Q Chen, Q Zhou, L Guo - Journal of Visual Communication and  &hellip;, 2012 - Elsevier</div><div class="gs_rs">Various modeling methodologies have been proposed to model the human face realistically. <br>However, despite the fact that these methods can give high-quality results, the time, cost, <br>and labor required to generate such models by these methods are often high. In this paper<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:5761hBl4zeQJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16486965861869272807&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'5761hBl4zeQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0262885612000650" class=yC10>Robust sparse bounding sphere for 3D face recognition</a></h3><div class="gs_a">Y Ming, Q Ruan - Image and Vision Computing, 2012 - Elsevier</div><div class="gs_rs">A robust sparse bounding sphere representation (RSBSR) is proposed to analyze 3D facial <br>data. There are many obstacles to distinguishing facial differences, such as large pose and <br>expression variations, hair occlusions and noise corruptions. In our framework, 3D point <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10081006966156047641&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 1</a> <a href="/scholar?q=related:GTX4m2zu5osJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10081006966156047641&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'GTX4m2zu5osJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0165168412001211" class=yC11>Îµâisometry based shape approximation for image content representation</a></h3><div class="gs_a">S Hao, J Jiang, Y Guo, S Zhan - Signal Processing, 2012 - Elsevier</div><div class="gs_rs">Abstract Shape approximation is usually a prerequisite step to image content analysis and <br>understanding and has been well studied in the passed decades. However, those <br>approaches show their deficiencies while facing the factors such as the representation <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Fbzvpzk7gK8J:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Fbzvpzk7gK8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://arxiv.org/pdf/1207.7244" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arxiv.org</span><span class="gs_ggsS">arxiv.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://arxiv.org/abs/1207.7244" class=yC12>Visual Vocabulary Learning and Its Application to 3D and Mobile Visual Search</a></h3><div class="gs_a">L Cao - arXiv preprint arXiv:1207.7244, 2012 - arxiv.org</div><div class="gs_rs">Abstract: In this technical report, we review related works and recent trends in visual <br>vocabulary based web image search, object recognition, mobile visual search, and 3D <br>object retrieval. Especial focuses would be also given for the recent trends in supervised/<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:E6aIwLQgnuAJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16185410071512524307&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'E6aIwLQgnuAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6180038" class=yC14>Semi-global depth estimation algorithm for mobile 3-D video applications</a></h3><div class="gs_a">Q Liu, H Xiao - Tsinghua Science and Technology, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Three-dimensional (3-D) video applications, such as 3-D cinema, 3DTV, and Free <br>Viewpoint Video (FVV) are attracting more attention both from the industry and in the <br>literature. High accuracy of depth video is a fundamental prerequisite for most 3-D <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:uHrZwXUjxiEJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'uHrZwXUjxiEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=2647&amp;context=sis_research" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from smu.edu.sg</span><span class="gs_ggsS">smu.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2396341" class=yC15>View-based 3D object retrieval by bipartite graph matching</a></h3><div class="gs_a">Y Wen, Y Gao, <a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, H Luan, Q Liu&hellip; - Proceedings of the 20th  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract Bipartite graph matching has been investigated in multiple view matching for 3D <br>object retrieval. However, existing methods employ one-to-one vertex matching scheme <br>while more than two views may share close semantic meanings in practice. In this work, <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'maV4-2-aO98J')" href="#" class="gs_nph">Cite</a></div></div></div>
