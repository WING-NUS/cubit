Total results = 27
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.ee.columbia.edu/~dpwe/ismir2004/CRFILES/paper183.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from columbia.edu</span><span class="gs_ggsS">columbia.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ee.columbia.edu/~dpwe/ismir2004/CRFILES/paper183.pdf" class=yC0>Automatic detection of vocal segments in popular songs</a></h3><div class="gs_a">TL Nwe, Y Wang - Proc. ISMIR, 2004 - ee.columbia.edu</div><div class="gs_rs">ABSTRACT This paper presents a technique for the automatic classification of vocal and <br>non-vocal regions in an acoustic musical signal. The proposed technique uses acoustic <br>features which are suitable to distinguish vocal and non-vocal signals. We employ the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1029789852324898212&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 38</a> <a href="/scholar?q=related:pKUgJWqMSg4J:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1029789852324898212&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 24 versions</a> <a onclick="return gs_ocit(event,'pKUgJWqMSg4J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md0', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md0" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:pKUgJWqMSg4J:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.4854&amp;rep=rep1&amp;type=pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1394661" class=yC2>Unsupervised classification of music genre using hidden markov model</a></h3><div class="gs_a">X Shao, C Xu, MS Kankanhalli - Multimedia and Expo, 2004.  &hellip;, 2004 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Music genre classification can be of great utility to musical database management. <br>Most current classification methods are supervised and tend to be based on contrived <br>taxonomies. However, due to the ambiguities and inconsistencies in the chosen <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15760396199656712232&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 38</a> <a href="/scholar?q=related:KGj0Z9csuNoJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15760396199656712232&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'KGj0Z9csuNoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www1.i2r.a-star.edu.sg/~hli/papers/101109TASL2006876756.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from a-star.edu.sg</span><span class="gs_ggsS">a-star.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4067048" class=yC4>Exploring vibrato-motivated acoustic features for singer identification</a></h3><div class="gs_a">TL Nwe, <a href="/citations?user=z8_x7C8AAAAJ&amp;hl=en&amp;oi=sra">H Li</a> - Audio, Speech, and Language Processing, IEEE &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Vibrato is a slightly tremulous effect imparted to vocal or instrumental tone for added <br>warmth and expressiveness through slight variation in pitch. It corresponds to a periodic <br>fluctuation of the fundamental frequency. It is common for a singer to develop a vibrato <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11242109298055456239&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 32</a> <a href="/scholar?q=related:7yW25Nf-A5wJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/03/0A/RN204606041.html?source=googlescholar" class="gs_nph" class=yC6>BL Direct</a> <a href="/scholar?cluster=11242109298055456239&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'7yW25Nf-A5wJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://www.comp.nus.edu.sg/~wangye/papers/1.Audio_and_Music_Analysis_and_Retrieval/2004_Singing_Voice_Detection_in_Popular_Music.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1027602" class=yC7>Singing voice detection in popular music</a></h3><div class="gs_a">TL Nwe, A Shenoy, Y Wang - Proceedings of the 12th annual ACM  &hellip;, 2004 - dl.acm.org</div><div class="gs_rs">Abstract We propose a novel technique for the automatic classification of vocal and non-<br>vocal regions in an acoustic musical signal. Our technique uses a combination of harmonic <br>content attenuation using higher level musical knowledge of key followed by sub-band <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3838002631248715374&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 34</a> <a href="/scholar?q=related:bh6Y-g5TQzUJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3838002631248715374&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 22 versions</a> <a onclick="return gs_ocit(event,'bh6Y-g5TQzUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://nguyendangbinh.org/Proceedings/ICPR/2004/DATA/V22_3_18.PDF" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nguyendangbinh.org</span><span class="gs_ggsS">nguyendangbinh.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1334225" class=yC9>Singer identification based on vocal and instrumental models</a></h3><div class="gs_a">NC Maddage, C Xu, Y Wang - Pattern Recognition, 2004. ICPR  &hellip;, 2004 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We propose a novel method to identify the singer of a query song from the audio <br>database. The database contains over 100 popular songs of solo singers. The rhythm <br>structure of the song is analyzed using our proposed rhythm tracking method and the song <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13399553054584102202&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 22</a> <a href="/scholar?q=related:Ol18X4LG9LkJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13399553054584102202&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'Ol18X4LG9LkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://ohm.fing.edu.uy/publicaciones/2007/RH07/RH07.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from fing.edu.uy</span><span class="gs_ggsS">fing.edu.uy <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://ohm.fing.edu.uy/publicaciones/2007/RH07/RH07.pdf" class=yCB>Comparing audio descriptors for singing voice detection in music audio files</a></h3><div class="gs_a">M Rocamora, <a href="/citations?user=x4X0Ia8AAAAJ&amp;hl=en&amp;oi=sra">P Herrera</a> - &hellip;  on Computer Music, 11th. San Pablo,  &hellip;, 2007 - ohm.fing.edu.uy</div><div class="gs_rs">Abstract. Given the relevance of the singing voice in popular western music, a system able to <br>reliable identify those portions of a music audio file containing vocals would be very useful. <br>In this work, we explore already used descriptors to perform this task and compare the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4597348268454176119&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 23</a> <a href="/scholar?q=related:d-X3ceQPzT8J:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4597348268454176119&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'d-X3ceQPzT8J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md5', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md5" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:d-X3ceQPzT8J:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.98.1526&amp;rep=rep1&amp;type=pdf" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/j1h044n4v1767603.pdf" class=yCD>Automatic lyrics alignment for Cantonese popular music</a></h3><div class="gs_a">CH Wong, WM Szeto, KH Wong - Multimedia Systems, 2007 - Springer</div><div class="gs_rs">Abstract From lyrics-display on electronic music players and Karaoke videos to surtitles for <br>live Chinese opera performance, one feature is common to all these everyday functionalities <br>temporal: synchronization of the written text and its corresponding musical phrase. Our <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=782808755015182321&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 16</a> <a href="/scholar?q=related:8ee-SWoY3QoJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/5E/5A/RN202853430.html?source=googlescholar" class="gs_nph" class=yCF>BL Direct</a> <a href="/scholar?cluster=782808755015182321&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'8ee-SWoY3QoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md6', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md6" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:8ee-SWoY3QoJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=18158445423803726775&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.107.9357&amp;rep=rep1&amp;type=pdf" class=yC11><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.107.9357&amp;rep=rep1&amp;type=pdf" class=yC10>Effective singing voice detection in popular music using arma filtering</a></h3><div class="gs_a">H Lukashevich, M Gruhne, C Dittmar - &hellip;  on Digital Audio Effects (DAFx&#39;07), 2007 - Citeseer</div><div class="gs_rs">ABSTRACT Locating singing voice segments is essential for convenient indexing, browsing <br>and retrieval large music archives and catalogues. Furthermore, it is beneficial for automatic <br>music transcription and annotations. The approach described in this paper uses Mel-<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10073944982425662572&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 17</a> <a href="/scholar?q=related:bHRPZJbXzYsJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10073944982425662572&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'bHRPZJbXzYsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md7', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md7" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:bHRPZJbXzYsJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://www.tsi.enst.fr/~grichard/Publications/Icassp08_ramona.pdf" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from enst.fr</span><span class="gs_ggsS">enst.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4518002" class=yC12>Vocal detection in music with support vector machines</a></h3><div class="gs_a">M Ramona, G Richard, B David - Acoustics, Speech and Signal  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We propose a statistical learning approach for the automatic detection of vocal <br>regions in a polyphonic musical signal. A support vector model, based on a large feature set, <br>is employed to discriminate accompanied singing voice from pure instrumental regions. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8183329524968948919&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 17</a> <a href="/scholar?q=related:t4S9h9gGkXEJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8183329524968948919&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'t4S9h9gGkXEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="https://www1.comp.nus.edu.sg/~wangye/papers/1.Audio_and_Music_Analysis_and_Retrieval/2005_Singing_Voice_Detection_for_Karaoke_Application.pdf" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=876255" class=yC14>Singing voice detection for karaoke application</a></h3><div class="gs_a">A Shenoy, Y Wu, Y Wang - Visual  &hellip;, 2005 - proceedings.spiedigitallibrary.org</div><div class="gs_rs">abstract We present a framework to detect the regions of singing voice in musical audio <br>signals. This work is oriented towards the development of a robust transcriber of lyrics for <br>karaoke applications. The technique leverages on a combination of low-level audio <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12185904537651465050&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 11</a> <a href="/scholar?q=related:WkuJAZ0HHakJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/3A/63/RN177222664.html?source=googlescholar" class="gs_nph" class=yC16>BL Direct</a> <a href="/scholar?cluster=12185904537651465050&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 17 versions</a> <a onclick="return gs_ocit(event,'WkuJAZ0HHakJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.184.6676&amp;rep=rep1&amp;type=pdf" class=yC18><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.184.6676&amp;rep=rep1&amp;type=pdf" class=yC17>Singing voice detection in monophonic and polyphonic contexts</a></h3><div class="gs_a">H Lachambre, R AndrÃ©-Obrecht, <a href="/citations?user=mYnnVlgAAAAJ&amp;hl=en&amp;oi=sra">J Pinquier</a> - 15th European Signal  &hellip;, 2009 - Citeseer</div><div class="gs_rs">ABSTRACT In this article, we present an improvement of a previous singing voice detector. <br>This new detector is in two steps. First, we distinguish monophonies from polyphonies. This <br>distinction is based on the fact that the pitch estimated in a monophony is more reliable <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5372869133989633961&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 2</a> <a href="/scholar?q=related:qd8cvAJEkEoJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5372869133989633961&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'qd8cvAJEkEoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md10', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md10" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:qd8cvAJEkEoJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://hal.archives-ouvertes.fr/docs/00/45/75/22/PDF/These_Helene_Lachambre.pdf" class=yC1A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://hal.archives-ouvertes.fr/tel-00457522/" class=yC19>CaractÃ©risation de l&#39;environnement musical dans les documents audiovisuels</a></h3><div class="gs_a">H Lachambre - 2009 - hal.archives-ouvertes.fr</div><div class="gs_rs">Depuis plusieurs dizaines d&#39;annÃ©es, l&#39;indexation par le contenu des documents <br>audiovisuels fait l&#39;objet de travaux de la part de nombreuses Ã©quipes de recherche:âLe mot <br>Â«audiovisuelÂ» fait rÃ©fÃ©rencea un contenu Â«multimÃ©diaÂ» qui regroupea la fois des donnÃ©es <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7844252019198893922&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 4</a> <a href="/scholar?q=related:Yp_9nKZh3GwJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7844252019198893922&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'Yp_9nKZh3GwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md11', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md11" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:Yp_9nKZh3GwJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=3531827526069817499&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Singing Phoneme Class Detection In Polyphonic Music Recordings</h3><div class="gs_a">V Ourania - 2008 - magistrska naloga, Univerza  &hellip;</div><div class="gs_fl"><a href="/scholar?cites=11653457682537027000&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 1</a> <a href="/scholar?q=related:uJWqBAVmuaEJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11653457682537027000&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'uJWqBAVmuaEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/t3086h1747710650.pdf" class=yC1B>Impulsive Environment Sound Detection by Neural Classification of Spectrogram and Mel-Frequency Coefficient Images</a></h3><div class="gs_a">P Khunarsa, C Lursinsap, T Raicharoen - Advances in Neural Network  &hellip;, 2010 - Springer</div><div class="gs_rs">The problem of automatic detecting impulsive sounds such as human sound (screams, <br>shout), gun shots, machine gun, thunder, fire alarm, and car horn are useful for hearing <br>impairment person. In this paper, instead of filtering the frequency of each sound for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14750481687401604342&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 1</a> <a href="/scholar?q=related:9iR6e_E8tMwJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14750481687401604342&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'9iR6e_E8tMwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5381403" class=yC1C>Vocal characteristics classification of audio segments: An investigation of the influence of accompaniment music on low-level features</a></h3><div class="gs_a">D Gartner, C Dittmar - Machine Learning and Applications,  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The characteristics of vocal segments in music are an important cue for automatic, <br>content-based music recommendation, especially in the urban genre. In this paper, we <br>investigate the classification of audio segments into singing and rap, using low-level <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12508796570039367462&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 1</a> <a href="/scholar?q=related:JjfSvDQsmK0J:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12508796570039367462&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'JjfSvDQsmK0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://tel.archives-ouvertes.fr/docs/00/52/93/31/PDF/main.pdf" class=yC1E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://tel.archives-ouvertes.fr/pastel-00529331/" class=yC1D>Classification automatique de flux radiophoniques par Machines Ã  Vecteurs de Support</a></h3><div class="gs_a">M Ramona - 2010 - tel.archives-ouvertes.fr</div><div class="gs_rs">1.1 Vers une radio numÃ©rique......................... 9 1.2 Applications de l&#39;indexation audio pour la <br>radio............ 10 1.3 Â«Qu&#39;est-ce que la musique?Â»...................... 11 1.4 Classification par <br>Machines Ã  Vecteurs de Support.......... 12 1.5 ProblÃ©matiques................................ 13 1.6 <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13344670493018324694&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 1</a> <a href="/scholar?q=related:1n7-PBzLMbkJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13344670493018324694&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'1n7-PBzLMbkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=huAzfJQhXDcC&amp;oi=fnd&amp;pg=PA99&amp;ots=_G5BM4g0fk&amp;sig=0B5R75tcSxDCFKy3Gq_DFBejE8Y" class=yC1F>Content-Based Music Summarization and Classification</a></h3><div class="gs_a">JS Jin - Managing Multimedia Semantics, 2005 - books.google.com</div><div class="gs_rs">ABSTRACT This chapter aims to provide a comprehensive survey of the technical <br>achievements in the area of content-based music summarization and classification and to <br>present our recent achievements. In order to give a full picture of the current status, the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:rJdeESIOowoJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'rJdeESIOowoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://tel.archives-ouvertes.fr/docs/00/68/74/75/PDF/these.pdf" class=yC21><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://tel.archives-ouvertes.fr/tel-00687475/" class=yC20>Localisation, caractÃ©risation et reconnaissance de voix chantÃ©es</a></h3><div class="gs_a">L Regnier - 2012 - tel.archives-ouvertes.fr</div><div class="gs_rs">Many auditors have a remarkable ability to identify the singer of a new song as long as they <br>have already heard some songs performed by the same singer. When the singer is <br>unfamiliar it is common for listeners to attempt to characterize the singer&#39;s voice by finding <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ObV6dGA6ysYJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14324325750750754105&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'ObV6dGA6ysYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Singing Voice Detection in Western Popular Music</h3><div class="gs_a">W Yuansheng</div><div class="gs_fl"><a href="/scholar?q=related:dx-cdoqIEO4J:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'dx-cdoqIEO4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="http://www.ee.columbia.edu/~dpwe/e6820/proposals/felix.pdf" class=yC23><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from columbia.edu</span><span class="gs_ggsS">columbia.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ee.columbia.edu/~dpwe/e6820/proposals/felix.pdf" class=yC22>Identifying singing segments in music</a></h3><div class="gs_a">FS Garcia - ee.columbia.edu</div><div class="gs_rs">Page 1. Identifying singing segments in music Felix Sanchez Garcia Page 2. Objective â¢<br>Given a music sample, identify singing segments Page 3. Difficulties â¢ It is hard to<br>model singing voice, it differs from normal speech â Mixed <b>...</b> </div><div class="gs_fl"><a href="/scholar?q=related:_vPzlY0xKEAJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4622999501671756798&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'_vPzlY0xKEAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md19', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md19" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:_vPzlY0xKEAJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB20" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW20"><a href="http://hal.inria.fr/docs/00/68/74/75/PDF/these.pdf" class=yC25><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from inria.fr</span><span class="gs_ggsS">inria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://hal.inria.fr/docs/00/68/74/75/PDF/these.pdf" class=yC24>L&#39;UNIVERSITE PIERRE ET MARIE CURIE</a></h3><div class="gs_a">ML Regnier - hal.inria.fr</div><div class="gs_rs">Many auditors have a remarkable ability to identify the singer of a new song as long as they <br>have already heard some songs performed by the same singer. When the singer is <br>unfamiliar it is common for listeners to attempt to characterize the singer&#39;s voice by finding <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:0HDPonzwK1wJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'0HDPonzwK1wJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md20', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md20" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:0HDPonzwK1wJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="https://repository.library.georgetown.edu/bitstream/handle/10822/552965/henryMichael.pdf?sequence=1" class=yC27><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from georgetown.edu</span><span class="gs_ggsS">georgetown.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="https://repository.library.georgetown.edu/handle/10822/552965" class=yC26>Learning techniques for identifying vocal regions in music using the wavelet transformation version 1.0</a></h3><div class="gs_a">M Henry - 2012 - repository.library.georgetown.edu</div><div class="gs_rs">Abstract In this research I present a machine learning method for the automatic detection of <br>vocal regions in music. I employ the wavelet transformation to extract wavelet coefficients, <br>from which I build feature sets capable of constructing a model that can distinguish <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:PpPPvEB0KowJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10100012935726207806&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'PpPPvEB0KowJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md21', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md21" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:PpPPvEB0KowJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=12517843942992201336&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5948861" class=yC28>Research and Realization of a SVS Algorithm based on STFT and NDFT</a></h3><div class="gs_a">R Chen, Z Luo, Y Zhong, X Luo, <a href="/citations?user=Hvlm8b4AAAAJ&amp;hl=en&amp;oi=sra">Y Gao</a>&hellip; - &hellip;  Security (NCIS), 2011  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, a singing voice splitting (SVS) system is researched and implemented <br>by short-time Fourier transform (STFT) and Nonuniform Discrete Fourier Transform (NDFT). <br>Specifically, there are four processes: TF decomposition, main pitch detection, TF <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:r-Zd3Mb1Y9EJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15088173411070764719&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'r-Zd3Mb1Y9EJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB23" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW23"><a href="http://www.mirlab.org/conference_papers/International_Conference/ISMIR%202011/papers/PS2-11.pdf" class=yC2A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mirlab.org</span><span class="gs_ggsS">mirlab.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.mirlab.org/conference_papers/International_Conference/ISMIR%202011/papers/PS2-11.pdf" class=yC29>Timbre and Melody Features for the Recognition of Vocal Activity and Instrumental Solos in Polyphonic Music</a></h3><div class="gs_a"><a href="/citations?user=_gfIN8AAAAAJ&amp;hl=en&amp;oi=sra">M Mauch</a>, H Fujihara, <a href="/citations?user=QaNTClUAAAAJ&amp;hl=en&amp;oi=sra">K Yoshii</a>, <a href="/citations?user=4JJCMq8AAAAJ&amp;hl=en&amp;oi=sra">M Goto</a> - 2011 - mirlab.org</div><div class="gs_rs">ABSTRACT We propose the task of detecting instrumental solos in polyphonic music <br>recordings, and the usage of a set of four audio features for vocal and instrumental activity <br>detection. Three of the features are based on the prior extraction of the predominant <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:6QHZ-0g_n38J:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9196138546809340393&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'6QHZ-0g_n38J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md23', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md23" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:6QHZ-0g_n38J:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB24" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW24"><a href="http://www.atiam.ircam.fr/Archives/Stages0708/Regnier.pdf" class=yC2C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ircam.fr</span><span class="gs_ggsS">ircam.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.atiam.ircam.fr/Archives/Stages0708/Regnier.pdf" class=yC2B>DÃ©tection de la voix chantÃ©e dans un morceau de musique</a></h3><div class="gs_a">L REGNIER - atiam.ircam.fr</div><div class="gs_rs">RÃ©sumÃ© De tous les Ã©lÃ©ments constitutifs d&#39;un morceau de musique, la voix est sans <br>conteste celui qui focalise le plus l&#39;attention de l&#39;auditeur. Ceci provient du fait que la voix est <br>porteuse d&#39;un message (le texte) et d&#39;une identitÃ© (celle du chanteur). Pour ces raisons, de <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:klX7IkhpWdMJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15229319373475501458&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'klX7IkhpWdMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md24', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md24" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:klX7IkhpWdMJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/95659x/200905/30314191.html" class=yC2D>åºäºé«æ¯æ··åæ¨¡åæµè¡é³ä¹ä¸­æ­å±é¨åçæºè½æ£æµ</a></h3><div class="gs_a">æä¸½å¨ï¼ å¶èï¼ èµµæ¬£ - å°åå¾®åè®¡ç®æºç³»ç», 2009 - cqvip.com</div><div class="gs_rs">ææå°æ£æµåºæµè¡é³ä¹ä¸­çæ­å±é¨åå¯¹å¨æµ·éæ°æ®åºä¸­è¿è¡é³ä¹æ£ç´¢, æµè§, å½ç±», <br>ä»¥åæå¾æååæ­å±å®¶è¯å«ç­æè¾å¤§çä»·å¼. æ¬æä½¿ç¨å¨è¯­é³ä¿¡å·å¤çä¸­å¹¿æ³ä½¿ç¨çåºäºæ¢å°<br>é¢ççåè°±ç³»æ°(MFCC) ä½ä¸ºè¯­é³ç¹å¾æ¥åææè¦å¤ççé³ä¹ä¿¡å·, å¹¶éç¨é«æ¯æ··åæ¨¡å(<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:10Pnsd-bS1QJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6074119907503981527&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'10Pnsd-bS1QJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB26" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW26"><a href="http://www.ceaj.org/Jweb_gcyyy/EN/article/downloadArticleFile.do?attachType=PDF&amp;id=18706" class=yC2E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ceaj.org</span><span class="gs_ggsS">ceaj.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> åºäº SVM çæµè¡é³ä¹ä¸­äººå£°çè¯å«</h3><div class="gs_a">ç³èªå¼ºï¼ ææµ·å³°ï¼ å­ä½³é³ - Computer Engineering and Applications, 2008</div><div class="gs_fl"><a href="/scholar?q=related:wZEV1WsZ3HMJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8348575760165212609&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'wZEV1WsZ3HMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
