Total results = 7
<div class="gs_r" style="z-index:400"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5674049" class=yC0>Richardson-lucy deblurring for scenes under a projective motion path</a></h3><div class="gs_a"><a href="/citations?user=nFhLmFkAAAAJ&amp;hl=en&amp;oi=sra">YW Tai</a>, <a href="/citations?user=XhyKVFMAAAAJ&amp;hl=en&amp;oi=sra">P Tan</a>, <a href="/citations?user=Gv1QGSMAAAAJ&amp;hl=en&amp;oi=sra">MS Brown</a> - Pattern Analysis and Machine  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper addresses how to model and correct image blur that arises when a <br>camera undergoes ego motion while observing a distant scene. In particular, we discuss <br>how the blurred image can be modeled as an integration of the clear scene under a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6756811280393294026&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7">Cited by 40</a> <a href="/scholar?q=related:ytAxdg8ExV0J:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6756811280393294026&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'ytAxdg8ExV0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://www.ruf.rice.edu/~mobile/publications/chen09mm.pdf" class=yC2><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from rice.edu</span><span class="gs_ggsS">rice.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1631272.1631325" class=yC1>SaVE: sensor-assisted motion estimation for efficient h. 264/AVC video encoding</a></h3><div class="gs_a">X Chen, Z Zhao, <a href="/citations?user=4doUW6cAAAAJ&amp;hl=en&amp;oi=sra">A Rahmati</a>, Y Wang&hellip; - Proceedings of the 17th  &hellip;, 2009 - dl.acm.org</div><div class="gs_rs">Abstract Motion estimation is a key component of modern video encoding and is very <br>compute-intensive. We present a novel Sensor-assisted Video Encoding (SaVE) method to <br>reduce the computational complexity of motion estimation in H. 264/AVC encoders, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17973198601551588498&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7">Cited by 8</a> <a href="/scholar?q=related:kqwH6-agbfkJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17973198601551588498&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'kqwH6-agbfkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Sensor-assisted Camera Motion Analysis and Motion Estimation Improvement for H. 264/AVC Video Encoding</h3><div class="gs_a"><a href="/citations?user=MQWQLZMAAAAJ&amp;hl=en&amp;oi=sra">G Wang</a>, H Ma, B Seo, <a href="/citations?user=IDREwXEAAAAJ&amp;hl=en&amp;oi=sra">R Zimmermann</a> - 22nd ACM NOSSDAV workshop, 2012</div><div class="gs_fl"><a href="/scholar?cites=18358231779999823421&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7">Cited by 2</a> <a href="/scholar?q=related:PTYtr4mKxf4J:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'PTYtr4mKxf4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="https://www1.comp.nus.edu.sg/~wangye/papers/4.Perception-Aware_Low-Power_Media_Processing_for_Portable_Devices/2011_Sensor-Assisted_Video_Encoding_for_Mobile_Devicesin_Real-World_Environments.pdf" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5711656" class=yC3>Sensor-Assisted Video Encoding for Mobile Devices in Real-World Environments</a></h3><div class="gs_a">X Chen, Z Zhao, <a href="/citations?user=4doUW6cAAAAJ&amp;hl=en&amp;oi=sra">A Rahmati</a>, Y Wang&hellip; - Circuits and Systems  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present a comprehensive study on sensor-assisted video <br>encoding (SaVE) schemes for video capturing on mobile devices in real-world <br>environments. Our purpose is to reduce the computational complexity of video encoding <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4307259926522247552&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7">Cited by 1</a> <a href="/scholar?q=related:gDmiExV2xjsJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4307259926522247552&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'gDmiExV2xjsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="https://www1.comp.nus.edu.sg/~wangye/papers/4.Perception-Aware_Low-Power_Media_Processing_for_Portable_Devices/2010_Perception-Aware_Low-Power_Media_Processing_for_Portable_Devices_.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="https://www1.comp.nus.edu.sg/~wangye/papers/4.Perception-Aware_Low-Power_Media_Processing_for_Portable_Devices/2010_Perception-Aware_Low-Power_Media_Processing_for_Portable_Devices_.pdf" class=yC5>Perception-Aware Low-Power Media Processing for Portable Devices</a></h3><div class="gs_a">Y Wang - comp.nus.edu.sg</div><div class="gs_rs">Smart mobile devices are proliferating, at increasingly smaller sizes. Many of these are <br>capable of capturing and playing a significant quantity of audio and video, as well as <br>uploading and downloading media to social networks. However, there has been relatively <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:mtWyFK_ygCYJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2774484204240688538&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'mtWyFK_ygCYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md4', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md4" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:mtWyFK_ygCYJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://scien.stanford.edu/pages/labsite/2010/ee398a/projects/reports/andy.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from stanford.edu</span><span class="gs_ggsS">stanford.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://scien.stanford.edu/pages/labsite/2010/ee398a/projects/reports/andy.pdf" class=yC7>Using Sensors for Efficient Video Coding in Hand-held Devices</a></h3><div class="gs_a">AL Lin - scien.stanford.edu</div><div class="gs_rs">One key challenge in video coding consists of minimizing computation, especially in hand-<br>held devices. The sensors which are already present in hand-held devices can help simplify <br>motion vector search and video coding. Keywords-motion estimation; mobile video coding<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:0i3hkw-ULfcJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17811054895946608082&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'0i3hkw-ULfcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md5', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md5" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:0i3hkw-ULfcJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.187.404&amp;rep=rep1&amp;type=pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.187.404&amp;rep=rep1&amp;type=pdf" class=yC9>Richardson-Lucy Deblurring for Scenes Under A Projective Motion Path</a></h3><div class="gs_a">YWTPT Michael, S Brown - Citeseer</div><div class="gs_rs">AbstractâThis paper addresses how to model and correct image blur that arises when a <br>camera undergoes ego motion while observing a distant scene. In particular, we discuss <br>how the blurred image can be modeled as an integration of the clear scene under a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:MZO2zVCuwBsJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1999789896624411441&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'MZO2zVCuwBsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md6', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md6" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:MZO2zVCuwBsJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
