Total results = 26
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://eprints.pascal-network.org/archive/00006965/01/whyte10.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from pascal-network.org</span><span class="gs_ggsS">pascal-network.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5540175" class=yC0>Non-uniform deblurring for shaken images</a></h3><div class="gs_a"><a href="/citations?user=EVdWS-4AAAAJ&amp;hl=en&amp;oi=sra">O Whyte</a>, <a href="/citations?user=NCtKHnQAAAAJ&amp;hl=en&amp;oi=sra">J Sivic</a>, A Zisserman&hellip; - Computer Vision and  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Blur from camera shake is mostly due to the 3D rotation of the camera, resulting in a <br>blur kernel that can be significantly non-uniform across the image. However, most current <br>deblurring methods model the observed image as a convolution of a sharp image with a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16088782951790269271&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 65</a> <a href="/scholar?q=related:V9PRRdrWRt8J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16088782951790269271&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 23 versions</a> <a onclick="return gs_ocit(event,'V9PRRdrWRt8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://www.kyb.tue.mpg.de/publications/attachments/vobd_paper_mpitechreport_6328%5B0%5D.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mpg.de</span><span class="gs_ggsS">mpg.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5540158" class=yC2>Efficient filter flow for space-variant multiframe blind deconvolution</a></h3><div class="gs_a">M Hirsch, <a href="/citations?user=eyCw9goAAAAJ&amp;hl=en&amp;oi=sra">S Sra</a>, <a href="/citations?user=DZ-fHPgAAAAJ&amp;hl=en&amp;oi=sra">B Scholkopf</a>&hellip; - Computer Vision and  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Ultimately being motivated by facilitating space-variant blind deconvolution, we <br>present a class of linear transformations, that are expressive enough for space-variant filters, <br>but at the same time especially designed for efficient matrix-vector-multiplications. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3735366258557430132&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 33</a> <a href="/scholar?q=related:dKlLQ9Kv1jMJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3735366258557430132&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 22 versions</a> <a onclick="return gs_ocit(event,'dKlLQ9Kv1jMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5674049" class=yC4>Richardson-lucy deblurring for scenes under a projective motion path</a></h3><div class="gs_a"><a href="/citations?user=nFhLmFkAAAAJ&amp;hl=en&amp;oi=sra">YW Tai</a>, <a href="/citations?user=XhyKVFMAAAAJ&amp;hl=en&amp;oi=sra">P Tan</a>, <a href="/citations?user=Gv1QGSMAAAAJ&amp;hl=en&amp;oi=sra">MS Brown</a> - Pattern Analysis and Machine  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper addresses how to model and correct image blur that arises when a <br>camera undergoes ego motion while observing a distant scene. In particular, we discuss <br>how the blurred image can be modeled as an integration of the clear scene under a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6756811280393294026&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 40</a> <a href="/scholar?q=related:ytAxdg8ExV0J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6756811280393294026&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'ytAxdg8ExV0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://www.merl.com/papers/docs/TR2010-029.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from merl.com</span><span class="gs_ggsS">merl.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5540161" class=yC5>Optimal coded sampling for temporal super-resolution</a></h3><div class="gs_a"><a href="/citations?user=Q3puGtcAAAAJ&amp;hl=en&amp;oi=sra">A Agrawal</a>, <a href="/citations?user=Y3wdd8oAAAAJ&amp;hl=en&amp;oi=sra">M Gupta</a>, <a href="/citations?user=tI-oUmsAAAAJ&amp;hl=en&amp;oi=sra">A Veeraraghavan</a>&hellip; - Computer Vision and &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Conventional low frame rate cameras result in blur and/or aliasing in images while <br>capturing fast dynamic events. Multiple low speed cameras have been used previously with <br>staggered sampling to increase the temporal resolution. However, previous approaches <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9584157751514783426&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 21</a> <a href="/scholar?q=related:wl5YKrLEAYUJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9584157751514783426&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 17 versions</a> <a onclick="return gs_ocit(event,'wl5YKrLEAYUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.187.9855&amp;rep=rep1&amp;type=pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5539935" class=yC7>Coded exposure imaging for projective motion deblurring</a></h3><div class="gs_a"><a href="/citations?user=nFhLmFkAAAAJ&amp;hl=en&amp;oi=sra">YW Tai</a>, N Kong, S Lin, SY Shin - Computer Vision and Pattern  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We propose a method for deblurring of spatially variant object motion. A principal <br>challenge of this problem is how to estimate the point spread function (PSF) of the spatially <br>variant blur. Based on the projective motion blur model of, we present a blur estimation <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=888212621617048567&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 20</a> <a href="/scholar?q=related:96uAZKyQUwwJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=888212621617048567&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'96uAZKyQUwwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://web.media.mit.edu/~dlanman/research/EG%20STAR%202011/ComputationalPlenopticImaging-CGF.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2011.02073.x/full" class=yC9>Computational plenoptic imaging</a></h3><div class="gs_a"><a href="/citations?user=VOf45S0AAAAJ&amp;hl=en&amp;oi=sra">G Wetzstein</a>, I Ihrke, <a href="/citations?user=-qncsGYAAAAJ&amp;hl=en&amp;oi=sra">D Lanman</a>&hellip; - Computer Graphics  &hellip;, 2011 - Wiley Online Library</div><div class="gs_rs">Abstract The plenoptic function is a ray-based model for light that includes the colour <br>spectrum as well as spatial, temporal and directional variation. Although digital light sensors <br>have greatly evolved in the last years, one fundamental limitation remains: all standard <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11334601594932820163&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 4</a> <a href="/scholar?q=related:w_iL6BiYTJ0J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11334601594932820163&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'w_iL6BiYTJ0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6072265" class=yCB>Robust image deblurring with an inaccurate blur kernel</a></h3><div class="gs_a">H Ji, K Wang - Image Processing, IEEE Transactions on, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Most existing nonblind image deblurring methods assume that the blur kernel is <br>free of error. However, it is often unavoidable in practice that the input blur kernel is <br>erroneous to some extent. Sometimes, the error could be severe, eg, for images degraded <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7806765353175325716&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 2</a> <a href="/scholar?q=related:FJzXCLozV2wJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7806765353175325716&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'FJzXCLozV2wJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://dev.ipol.im/~morel/Dossier_MVA_2011_Cours_Transparents_Documents/2011_Cours6_Cours_Flutter_Shutter.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ipol.im</span><span class="gs_ggsS">ipol.im <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://dev.ipol.im/~morel/Dossier_MVA_2011_Cours_Transparents_Documents/2011_Cours6_Cours_Flutter_Shutter.pdf" class=yCC>The Flutter Shutter Paradox</a></h3><div class="gs_a">Y Tendero, <a href="/citations?user=BlEbdeEAAAAJ&amp;hl=en&amp;oi=sra">JM Morel</a>, B RougÃ© - Submittted to SIAM Journal on Imaging  &hellip;, 2012 - dev.ipol.im</div><div class="gs_rs">1 Abstract Acquiring good quality images of moving objects by a digital camera remains a <br>valid question, particularly if the velocity of the photographed object is only partially known, it <br>is virtually impossible to tune an optimal exposure time. The same question arises when a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18214240903874807717&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 4</a> <a href="/scholar?q=related:pQfZUJn7xfwJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'pQfZUJn7xfwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md7', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md7" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:pQfZUJn7xfwJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://yuwing.kaist.ac.kr/papers/tr_motionmatting.pdf" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from kaist.ac.kr</span><span class="gs_ggsS">kaist.ac.kr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5766000" class=yCE>Motion regularization for matting motion blurred objects</a></h3><div class="gs_a"><a href="/citations?user=uZU1uIkAAAAJ&amp;hl=en&amp;oi=sra">HT Lin</a>, <a href="/citations?user=nFhLmFkAAAAJ&amp;hl=en&amp;oi=sra">YW Tai</a>, <a href="/citations?user=Gv1QGSMAAAAJ&amp;hl=en&amp;oi=sra">MS Brown</a> - Pattern Analysis and Machine  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper addresses the problem of matting motion blurred objects from a single <br>image. Existing single image matting methods are designed to extract static objects that <br>have fractional pixel occupancy. This arises because the physical scene object has a finer <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11809057006402897030&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 4</a> <a href="/scholar?q=related:hoT7vscy4qMJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11809057006402897030&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'hoT7vscy4qMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://dev.ipol.im/~tendero/these_11_compressed.pdf" class=yC11><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ipol.im</span><span class="gs_ggsS">ipol.im <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://dev.ipol.im/~tendero/these_11_compressed.pdf" class=yC10>Mathematical theory of the flutter shutter</a></h3><div class="gs_a">Y TENDERO - 2012 - dev.ipol.im</div><div class="gs_rs">RÃ©sumÃ© Cette thÃ¨se apporte des solutions thÃ©oriques et pratiques Ã  deux problÃ¨mes <br>soulevÃ©s par la photographie numÃ©rique en prÃ©sence de mouvement, et par la <br>photographie infrarouge. La photographie d&#39;objets en mouvement semblait ne pouvoir se <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9674913492171921593&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 1</a> <a href="/scholar?q=related:uZiKrY8yRIYJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9674913492171921593&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'uZiKrY8yRIYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md9', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md9" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:uZiKrY8yRIYJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="ftp://ftp.math.ucla.edu/pub/camreport/cam12-01.pdf" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ucla.edu</span><span class="gs_ggsS">ucla.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="ftp://ftp.math.ucla.edu/pub/camreport/cam12-01.pdf" class=yC12>A dynamic texture model for imaging through turbulence</a></h3><div class="gs_a">M Micheli, <a href="/citations?user=iCiUflEAAAAJ&amp;hl=en&amp;oi=sra">Y Lou</a>, <a href="/citations?user=VJPRn1oAAAAJ&amp;hl=en&amp;oi=sra">AL Bertozzi</a> - UCLA CAM report, 2012 - math.ucla.edu</div><div class="gs_rs">Abstract In this paper we address the problem of recovering an image from a sequence of <br>distorted versions of it, where the distortion is caused by what is commonly referred to as <br>ground-level turbulence. In mathematical terms, such distortion can be seen as the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18251494519790454228&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 1</a> <a href="/scholar?q=related:1EUZsJBVSv0J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18251494519790454228&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'1EUZsJBVSv0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md10', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md10" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:1EUZsJBVSv0J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://yuwing.kaist.ac.kr/papers/cvpr12_deblurCRF.pdf" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from kaist.ac.kr</span><span class="gs_ggsS">kaist.ac.kr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6247654" class=yC14>Nonlinear camera response functions and image deblurring</a></h3><div class="gs_a">S Kim, <a href="/citations?user=nFhLmFkAAAAJ&amp;hl=en&amp;oi=sra">YW Tai</a>, <a href="/citations?user=1F2czKYAAAAJ&amp;hl=en&amp;oi=sra">SJ Kim</a>, <a href="/citations?user=Gv1QGSMAAAAJ&amp;hl=en&amp;oi=sra">MS Brown</a>&hellip; - Computer Vision and  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper investigates the role that nonlinear camera response functions (CRFs) <br>have on image deblurring. In particular, we show how nonlinear CRFs can cause a spatially <br>invariant blur to behave as a spatially varying blur. This can result in noticeable ringing <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16737363147650588224&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 1</a> <a href="/scholar?q=related:QF5tvBoPR-gJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16737363147650588224&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'QF5tvBoPR-gJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://yuwing.kaist.ac.kr/papers/tr_projectivedeblur.pdf" class=yC17><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from kaist.ac.kr</span><span class="gs_ggsS">kaist.ac.kr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://yuwing.kaist.ac.kr/papers/tr_projectivedeblur.pdf" class=yC16>Richardson-Lucy Deblurring for Scenes under Projective Motion Path</a></h3><div class="gs_a">YWTPT Long, GMS Brown - yuwing.kaist.ac.kr</div><div class="gs_rs">AbstractâThis paper addresses the problem of modeling and correcting image blur caused <br>by camera motion that follows a projective motion path. We introduce a new Projective <br>Motion Blur Model that treats the blurred image as an integration of a clear scene under a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:DIA9CegnGtMJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15211514568938192908&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'DIA9CegnGtMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md12', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md12" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:DIA9CegnGtMJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://japanlinkcenter.org/JST.JSTAGE/imt/7.306?from=Google" class=yC18>Ringing Detector for Deblurring based on Frequency Analysis of PSF</a></h3><div class="gs_a">C Inoshita, <a href="/citations?user=oI5TxzsAAAAJ&amp;hl=en&amp;oi=sra">Y Mukaigawa</a>, <a href="/citations?user=byuA_UEAAAAJ&amp;hl=en&amp;oi=sra">Y Yagi</a> - Information and Media Technologies, 2012 - J-STAGE</div><div class="gs_rs">Many deblurring techniques have been proposed to restore blurred images resulting from <br>camera motion. A major problem in the restoration process is that the deblurred images <br>often include wave-like artifacts called ringing. In this paper, we propose a ringing detector <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'yFdlKnMP3moJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/288N24550646X84V.pdf" class=yC19>An overview of computational photography</a></h3><div class="gs_a"><a href="/citations?user=e4lel8QAAAAJ&amp;hl=en&amp;oi=sra">JL Suo</a>, XY Ji, QH Dai - Science China Information sciences, 2012 - Springer</div><div class="gs_rs">Abstract Computational photography is an emerging multidisciplinary field. Over the last two <br>decades, it has integrated studies across computer vision, computer graphics, signal <br>processing, applied optics and related disciplines. Researchers are exploring new ways <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12642278297654111551&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 1</a> <a href="/scholar?q=related:P61NSyFlcq8J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12642278297654111551&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'P61NSyFlcq8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/xgm5348xx13060r5.pdf" class=yC1A>Non-blind Image Deblurring from a Single Image</a></h3><div class="gs_a">B Zhao, W Zhang, H Ding, H Wang - Cognitive Computation, 2012 - Springer</div><div class="gs_rs">Abstract Conventional non-blind image deblurring algorithms often involve in maximum a <br>posteriori (MAP) estimation and natural image priors. However, MAP estimation has several <br>disadvantages which limit its application. To address these issues, we propose to use <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:WWdCT7nLHC8J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'WWdCT7nLHC8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://www.cse.ust.hk/~psander/pg2012proc/pg/pdf/v31i7pp2019-2028.pdf" class=yC1C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ust.hk</span><span class="gs_ggsS">ust.hk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.cse.ust.hk/~psander/pg2012proc/pg/pdf/v31i7pp2019-2028.pdf" class=yC1B>Performance Capture of High-Speed Motion Using Staggered Multi-View Recording</a></h3><div class="gs_a">C Bregler, <a href="/citations?user=GIToYFwAAAAJ&amp;hl=en&amp;oi=sra">P Sander</a>, <a href="/citations?user=pPLc_DoAAAAJ&amp;hl=en&amp;oi=sra">M Wimmer</a> - 2012 - cse.ust.hk</div><div class="gs_rs">Abstract We present a markerless performance capture system that can acquire the motion <br>and the texture of human actors performing fast movements using only commodity hardware. <br>To this end we introduce two novel concepts: First, a staggered surround multi-view <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:QYNQVYjQcT8J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4571664380723233601&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'QYNQVYjQcT8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S1877705812019674" class=yC1D>Fast Blur Kernel Estimation with Texture Preserving DRD for Motion Deblur</a></h3><div class="gs_a">S Govindan, S Saravanakumar - Procedia Engineering, 2012 - Elsevier</div><div class="gs_rs">The paper presents a novel technique to restore motion blurred images. Motion blur <br>generally appears due to camera shake and exposure time. The blur parameters being the <br>motion blur length and angle are estimated in a fast way using radon transform with less <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:R_jgczlxC2oJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'R_jgczlxC2oJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2087800" class=yC1E>Motion deblurring from a single image using gradient enhancement</a></h3><div class="gs_a">J Chen, Z Xie, B Sheng, L Ma - &hellip;  of the 10th International Conference on  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract Motion deblurring is one of the recovery problems in image restoration, which <br>remains several challenges in kernel estimation and blind deconvolution. This paper <br>proposes a new optimization method for estimating the blurring kernel by gradient <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ItH1fJIP_WkJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'ItH1fJIP_WkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6104389" class=yC1F>Depth From Motion and Optical Blur With an Unscented Kalman Filter</a></h3><div class="gs_a">C Paramanand, AN Rajagopalan - Image Processing, IEEE  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Space-variantly blurred images of a scene contain valuable depth information. In <br>this paper, our objective is to recover the 3-D structure of a scene from motion blur/optical <br>defocus. In the proposed approach, the difference of blur between two observations is <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12183265230940297978&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 1</a> <a href="/scholar?q=related:-lqQhi2nE6kJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12183265230940297978&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'-lqQhi2nE6kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB20" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW20"><a href="http://www.eecis.udel.edu/~jye/lab_research/ECCV/eccv12-CRF.pdf" class=yC21><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from udel.edu</span><span class="gs_ggsS">udel.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.eecis.udel.edu/~jye/lab_research/ECCV/eccv12-CRF.pdf" class=yC20>A Theoretical Analysis of Camera Response Functions in Image Deblurring</a></h3><div class="gs_a">X Chen, <a href="/citations?user=1bzFZ7cAAAAJ&amp;hl=en&amp;oi=sra">F Li</a>, J Yang, <a href="/citations?user=R9L_AfQAAAAJ&amp;hl=en&amp;oi=sra">J Yu</a> - eecis.udel.edu</div><div class="gs_rs">Abstract. Motion deblurring is a long standing problem in computer vision and image <br>processing. In most previous approaches, the blurred image is modeled as the convolution <br>of a latent intensity image with a blur kernel. However, for images captured by a real <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:t9T3qYljN_oJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18029989076114330807&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'t9T3qYljN_oJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md20', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md20" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:t9T3qYljN_oJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6175123" class=yC22>Modeling the Performance of Image Restoration from Motion Blur</a></h3><div class="gs_a"><a href="/citations?user=lBa_mnYAAAAJ&amp;hl=en&amp;oi=sra">G Boracchi</a>, <a href="/citations?user=zBmF3ZAAAAAJ&amp;hl=en&amp;oi=sra">A Foi</a> - Image Processing, IEEE Transactions on, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract When dealing with motion blur, there is an inevitable tradeoff between the amount <br>of blur and the amount of noise in the acquired images. The effectiveness of any restoration <br>algorithm typically depends on these amounts, and it is difficult to find their best balance in <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10884248903005249002&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 1</a> <a href="/scholar?q=related:6h2QxrWeDJcJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10884248903005249002&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'6h2QxrWeDJcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB22" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW22"><a href="http://tel.archives-ouvertes.fr/docs/00/75/24/09/PDF/Tendero2012.pdf" class=yC24><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://tel.archives-ouvertes.fr/tel-00752409/" class=yC23>ThÃ©orie mathÃ©matique du Flutter Shutter: ses paradoxes et leur solution</a></h3><div class="gs_a">Y Tendero - 2012 - tel.archives-ouvertes.fr</div><div class="gs_rs">RÃ©sumÃ© Cette thÃ¨se apporte des solutions thÃ©oriques et pratiques Ã  deux problÃ¨mes <br>soulevÃ©s par la photographie numÃ©rique en prÃ©sence de mouvement, et par la <br>photographie infrarouge. La photographie d&#39;objets en mouvement semblait ne pouvoir se <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'cMikydsELEwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB23" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW23"><a href="http://www.joics.com/publishedpapers/2012_9_16_4997_5004.pdf" class=yC26><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from joics.com</span><span class="gs_ggsS">joics.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.joics.com/publishedpapers/2012_9_16_4997_5004.pdf" class=yC25>Research on Light Field Capturing and Reconstruction Algorithm Based on Wavelet Baseâ</a></h3><div class="gs_a">H JIANG, RGAO Di FANGa - 2012 - joics.com</div><div class="gs_rs">Abstract In this paper, we propose a novel coded aperture and two associated algorithm for <br>making up the defect of traditional aperture such as the depth of scene, quality and the <br>limitation of dimension. In sampling, combining with the sampling characteristics of <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'rsE80PoOtcwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md23', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md23" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:rsE80PoOtcwJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6331542" class=yC27>Non-Parametric Super-Resolution Using a Bi-Sensor Camera</a></h3><div class="gs_a">F Salem, A Yagle - 2013 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Multiframe super-resolution is the problem of reconstructing a single high-resolution <br>(HR) image from several low-resolution (LR) versions of it. We assume that the original HR <br>image undergoes different linear transforms, where each transform can be approximated <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'W7117swoqLgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB25" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW25"><a href="http://www.am.sanken.osaka-u.ac.jp/~mukaigaw/papers/TCVA2011-RingingDetector.pdf" class=yC29><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from osaka-u.ac.jp</span><span class="gs_ggsS">osaka-u.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://japanlinkcenter.org/JST.JSTAGE/ipsjtcva/3.236?from=Google" class=yC28>Ringing Detector for Deblurring based on Frequency Analysis of PSF</a></h3><div class="gs_a">C Inoshita, <a href="/citations?user=oI5TxzsAAAAJ&amp;hl=en&amp;oi=sra">Y Mukaigawa</a>, <a href="/citations?user=byuA_UEAAAAJ&amp;hl=en&amp;oi=sra">Y Yagi</a> - IPSJ Transactions on Computer Vision  &hellip;, 2011 - J-STAGE</div><div class="gs_rs">Many deblurring techniques have been proposed to restore blurred images resulting from <br>camera motion. A major problem in the restoration process is that the deblurred images <br>often include wave-like artifacts called ringing. In this paper, we propose a ringing detector <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Tp769pSbfcMJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14086586273585864270&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'Tp769pSbfcMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
