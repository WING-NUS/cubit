Total results = 8
<div class="gs_r" style="z-index:400"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1989260" class=yC0>GPU-based fast motion estimation for on-the-fly encoding of computer-generated video streams</a></h3><div class="gs_a">J Taibo, VM Gulias, P Montero, S Rivas - Proceedings of the 21st  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract Motion estimation is known to be one of the most expensive tasks in video coding <br>as it is usually performed through blind search-based methods. However, in the particular <br>case of computer-generated video, the rendering stage provides useful information to <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7102625788766334062&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 1</a> <a href="/scholar?q=related:bizyB4aYkWIJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'bizyB4aYkWIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Sensor-assisted Camera Motion Analysis and Motion Estimation Improvement for H. 264/AVC Video Encoding</h3><div class="gs_a"><a href="/citations?user=MQWQLZMAAAAJ&amp;hl=en&amp;oi=sra">G Wang</a>, H Ma, B Seo, <a href="/citations?user=IDREwXEAAAAJ&amp;hl=en&amp;oi=sra">R Zimmermann</a> - 22nd ACM NOSSDAV workshop, 2012</div><div class="gs_fl"><a href="/scholar?cites=18358231779999823421&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 2</a> <a href="/scholar?q=related:PTYtr4mKxf4J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'PTYtr4mKxf4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www.ruf.rice.edu/~mobile/publications/lin10reflex.pdf" class=yC2><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from rice.edu</span><span class="gs_ggsS">rice.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ruf.rice.edu/~mobile/publications/lin10reflex.pdf" class=yC1>Reflex: managing sensor data processing in mobile systems</a></h3><div class="gs_a">X Lin, <a href="/citations?user=hJPN-G8AAAAJ&amp;hl=en&amp;oi=sra">L Zhong</a> - 2010 - ruf.rice.edu</div><div class="gs_rs">Abstract Many emerging mobile services leverage sensors available on mobile systems to <br>acquire information regarding the physical world through sensory data processing, in order <br>to serve human users intelligently and ubiquitously. While the sensors themselves can be <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13780278315092772031&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 1</a> <a href="/scholar?q=related:v4Qf1R1iPb8J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13780278315092772031&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'v4Qf1R1iPb8J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md2', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md2" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:v4Qf1R1iPb8J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="https://www1.comp.nus.edu.sg/~wangye/papers/4.Perception-Aware_Low-Power_Media_Processing_for_Portable_Devices/2011_Sensor-Assisted_Video_Encoding_for_Mobile_Devicesin_Real-World_Environments.pdf" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5711656" class=yC3>Sensor-Assisted Video Encoding for Mobile Devices in Real-World Environments</a></h3><div class="gs_a">X Chen, Z Zhao, <a href="/citations?user=4doUW6cAAAAJ&amp;hl=en&amp;oi=sra">A Rahmati</a>, Y Wang&hellip; - Circuits and Systems  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present a comprehensive study on sensor-assisted video <br>encoding (SaVE) schemes for video capturing on mobile devices in real-world <br>environments. Our purpose is to reduce the computational complexity of video encoding <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4307259926522247552&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 1</a> <a href="/scholar?q=related:gDmiExV2xjsJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4307259926522247552&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'gDmiExV2xjsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="https://www1.comp.nus.edu.sg/~wangye/papers/4.Perception-Aware_Low-Power_Media_Processing_for_Portable_Devices/2010_Perception-Aware_Low-Power_Media_Processing_for_Portable_Devices_.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="https://www1.comp.nus.edu.sg/~wangye/papers/4.Perception-Aware_Low-Power_Media_Processing_for_Portable_Devices/2010_Perception-Aware_Low-Power_Media_Processing_for_Portable_Devices_.pdf" class=yC5>Perception-Aware Low-Power Media Processing for Portable Devices</a></h3><div class="gs_a">Y Wang - comp.nus.edu.sg</div><div class="gs_rs">Smart mobile devices are proliferating, at increasingly smaller sizes. Many of these are <br>capable of capturing and playing a significant quantity of audio and video, as well as <br>uploading and downloading media to social networks. However, there has been relatively <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:mtWyFK_ygCYJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2774484204240688538&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'mtWyFK_ygCYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md4', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md4" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:mtWyFK_ygCYJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5961220" class=yC7>Image Pixel Comparison Using Block Based Positioning Subtraction Technique for Motion Estimation</a></h3><div class="gs_a">S Jitvinder, SSS Ranjit, KC Lim&hellip; - &hellip; Symposium (AMS), 2011 &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Images are usually consists of motion translation from one frame to another frame. <br>Motion translation is represented by the pixels value changes based on the pixel density. <br>The motion transition process from one frame to another frame is called motion estimation. <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:e6lCGTkD-PcJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17868035065364261243&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'e6lCGTkD-PcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://ijcit.com/archives/volume2/issue1/Paper020125.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ijcit.com</span><span class="gs_ggsS">ijcit.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://ijcit.com/archives/volume2/issue1/Paper020125.pdf" class=yC8>Medical Images Inter Frame Motion Analysis via Block Positioning Pixel Subtraction Technique</a></h3><div class="gs_a">SSS Ranjit, H Jitvinder, KC Lim, SA Anas - analysis, 2013 - ijcit.com</div><div class="gs_rs">AbstractâThis paper presents a study on image pixels using block positioning pixel <br>subtraction technique to analyse the changes that occur in that region of interest. The <br>changes that happen in the pixels represent the motion translation. Processing a whole <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'F8toOe9UEjUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md6', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md6" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:F8toOe9UEjUJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://scien.stanford.edu/pages/labsite/2010/ee398a/projects/reports/andy.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from stanford.edu</span><span class="gs_ggsS">stanford.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://scien.stanford.edu/pages/labsite/2010/ee398a/projects/reports/andy.pdf" class=yCA>Using Sensors for Efficient Video Coding in Hand-held Devices</a></h3><div class="gs_a">AL Lin - scien.stanford.edu</div><div class="gs_rs">One key challenge in video coding consists of minimizing computation, especially in hand-<br>held devices. The sensors which are already present in hand-held devices can help simplify <br>motion vector search and video coding. Keywords-motion estimation; mobile video coding<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:0i3hkw-ULfcJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17811054895946608082&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'0i3hkw-ULfcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md7', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md7" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:0i3hkw-ULfcJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
