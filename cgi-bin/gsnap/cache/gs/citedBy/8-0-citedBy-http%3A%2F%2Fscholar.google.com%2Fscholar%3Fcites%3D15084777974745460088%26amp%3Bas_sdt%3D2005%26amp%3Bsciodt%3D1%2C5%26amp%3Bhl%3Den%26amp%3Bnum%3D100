Total results = 8
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://islab.ulsan.ac.kr/files/announcement/371/Automatic%20video%20logo%20detection%20and%20removal.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ulsan.ac.kr</span><span class="gs_ggsS">ulsan.ac.kr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/u174127513743665.pdf" class=yC0>Automatic video logo detection and removal</a></h3><div class="gs_a">WQ Yan, <a href="/citations?user=wIE1tY4AAAAJ&amp;hl=en&amp;oi=sra">J Wang</a>, MS Kankanhalli - Multimedia Systems, 2005 - Springer</div><div class="gs_rs">Most commercial television channels use video logos, which can be considered a form of <br>visible watermark, as a declaration of intellectual property ownership. They are also used as <br>a symbol of authorization to rebroadcast when original logos are used in conjunction with <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=258263373480998434&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 31</a> <a href="/scholar?q=related:IjbUeiuJlQMJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/57/5A/RN175366189.html?source=googlescholar" class="gs_nph" class=yC2>BL Direct</a> <a href="/scholar?cluster=258263373480998434&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'IjbUeiuJlQMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.2.5349&amp;rep=rep1&amp;type=pdf" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1199144" class=yC3>A hierarchical framework for face tracking using state vector fusion for compressed video</a></h3><div class="gs_a"><a href="/citations?user=wIE1tY4AAAAJ&amp;hl=en&amp;oi=sra">J Wang</a>, <a href="/citations?user=lc2HaZwAAAAJ&amp;hl=en&amp;oi=sra">R Achanta</a>, M Kankanhalli&hellip; - &hellip; , Speech, and Signal  &hellip;, 2003 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Faces usually are the most interesting objects in certain categories of video, like <br>home videos and news clips. A novel sensor fusion based face tracking system is presented <br>that tracks faces in compressed video, and aids automatic video indexing. Tracking is <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11264289586256855251&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 8</a> <a href="/scholar?q=related:08D4q7LLUpwJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11264289586256855251&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 18 versions</a> <a onclick="return gs_ocit(event,'08D4q7LLUpwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.100.4397&amp;rep=rep1&amp;type=pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.100.4397&amp;rep=rep1&amp;type=pdf" class=yC5>Detecting and tracking human faces in compressed domain for content based video indexing</a></h3><div class="gs_a">W JUN - 2002 - Citeseer</div><div class="gs_rs">SUMMARY With recent advances in broadband networks, image/video compression <br>standards (JPEG/MPEG) and consumer electronics (including amateur digital video <br>cameras), video data now ranges from simple home videos to sophisticated movie <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13215178019421024498&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 3</a> <a href="/scholar?q=related:8vAjQ2S-ZbcJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13215178019421024498&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'8vAjQ2S-ZbcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md2', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md2" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:8vAjQ2S-ZbcJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://www.wseas.us/e-library/conferences/2007corfu/papers/540-346.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from wseas.us</span><span class="gs_ggsS">wseas.us <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.wseas.us/e-library/conferences/2007corfu/papers/540-346.pdf" class=yC7>Face region detection using DCT and homomorphic filter</a></h3><div class="gs_a">K Baek, <a href="/citations?user=FMiwSFYAAAAJ&amp;hl=en&amp;oi=sra">Y Chang</a>, D Kim, Y Kim, B Lee&hellip; - Proceedings of the 6th  &hellip;, 2007 - wseas.us</div><div class="gs_rs">Abstract:-This paper proposes a new approach for the detection of face regions where the <br>facial features such as eyes, nose, and mouth may exist with very high probability. It uses the <br>characteristic of DCT (discrete cosine transformation) that concentrates the energy of an <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12895463048815030792&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 3</a> <a href="/scholar?q=related:CLLL3lHj9bIJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12895463048815030792&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'CLLL3lHj9bIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md3', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md3" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:CLLL3lHj9bIJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/95290x/200405/10335693.html" class=yC9>ä¸ç§ç¨äº DCT åç¼©åçäººè¸æ£æµç®æ³</a></h3><div class="gs_a">ç°å·ï¼ é»ç¥¥æï¼ æ²å°èª - æµæ§ææ¯, 2004 - cqvip.com</div><div class="gs_rs">æçç»´æ®: å¸æ·ä½é¢; åå¼è®°å½; ä¸è½½è®°å½; æçæ¶è. è´­ç©è½¦; åå¼; å®¢æ. é¦é¡µ | æåå¤§å¨ | å¨çº¿åºç |<br>å¨çº¿èè¯ | ä¼ä¸ææ¥é¦ | å­¦èç©ºé´ | å­¦æ¯æºæ | è®ºæåè¡¨ | EIæ£ç´¢ä¼è®® |. æ¨çä½ç½®ï¼ç½ç«é¦é¡µ &gt;<br>ãä¸­æç§ææåæ°æ®åºã &gt; å·¥ç¨ææ¯ &gt; çµå­çµä¿¡ &gt; éä¿¡ &gt; æè¦. ä¸ç§ç¨äºDCTåç¼©åçäººè¸æ£æµç®æ³ <b>...</b> </div><div class="gs_fl"><a href="/scholar?cites=14615945696028557172&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 2</a> <a href="/scholar?q=related:dH8uBCxF1soJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14615945696028557172&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'dH8uBCxF1soJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://ict.ewi.tudelft.nl/pub/marcel/Wang05e.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tudelft.nl</span><span class="gs_ggsS">tudelft.nl <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://ict.ewi.tudelft.nl/pub/marcel/Wang05e.pdf" class=yCA>A Sensor Fusion Based Approach for Tracking Faces in Compressed Video</a></h3><div class="gs_a"><a href="/citations?user=wIE1tY4AAAAJ&amp;hl=en&amp;oi=sra">J Wang</a>, <a href="/citations?user=lc2HaZwAAAAJ&amp;hl=en&amp;oi=sra">R Achanta</a>, MS Kankanhalli, <a href="/citations?user=lzOX9lkAAAAJ&amp;hl=en&amp;oi=sra">MJT Reinders</a> - ict.ewi.tudelft.nl</div><div class="gs_rs">Abstract Faces probably are the most interesting objects in certain categories of video like <br>home video and news clips. In this paper we present a novel sensor fusion based face <br>tracking system that tracks faces completely in compressed MPEG videos for the purpose <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:yqqnFxG56zIJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'yqqnFxG56zIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md5', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md5" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:yqqnFxG56zIJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://www.comp.nus.edu.sg/~mohan/papers/videologo.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.comp.nus.edu.sg/~mohan/papers/videologo.pdf" class=yCC>Automatic location and removal of video logos</a></h3><div class="gs_a">W Yan, <a href="/citations?user=wIE1tY4AAAAJ&amp;hl=en&amp;oi=sra">J Wang</a>, MS Kankanhalli - 2008 - comp.nus.edu.sg</div><div class="gs_rs">Abstract. Most commercial television channels utilize video logos, which can be considered <br>as a form of a visible watermark, as a declaration of intellectual property ownership. They <br>are also used as a symbol of authorization to rebroadcast when original logos are used in <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:4aH5kHiEJb0J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13629445500669895137&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'4aH5kHiEJb0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md6', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md6" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:4aH5kHiEJb0J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://arxiv.org/pdf/1204.1679" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arxiv.org</span><span class="gs_ggsS">arxiv.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://arxiv.org/abs/1204.1679" class=yCE>Clustering and Bayesian network for image of faces classification</a></h3><div class="gs_a">K Jayech, MA Mahjoub - arXiv preprint arXiv:1204.1679, 2012 - arxiv.org</div><div class="gs_rs">Abstract: In a content based image classification system, target images are sorted by feature <br>similarities with respect to the query (CBIR). In this paper, we propose to use new approach <br>combining distance tangent, k-means algorithm and Bayesian network for image <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:h8Gv2LDfADsJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4251643998880383367&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'h8Gv2LDfADsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
