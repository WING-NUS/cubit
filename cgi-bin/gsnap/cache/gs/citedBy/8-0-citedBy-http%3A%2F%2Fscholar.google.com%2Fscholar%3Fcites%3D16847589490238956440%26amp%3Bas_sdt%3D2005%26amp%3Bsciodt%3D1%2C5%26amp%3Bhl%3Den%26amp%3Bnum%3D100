Total results = 8
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://strum.googlecode.com/svn-history/r41/trunk/Research/CAMIT.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from googlecode.com</span><span class="gs_ggsS">googlecode.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1290156" class=yC0>Effective use of multimedia for computer-assisted musical instrument tutoring</a></h3><div class="gs_a"><a href="/citations?user=xCnDkXAAAAAJ&amp;hl=en&amp;oi=sra">G Percival</a>, Y Wang, <a href="/citations?user=yPgxxpwAAAAJ&amp;hl=en&amp;oi=sra">G Tzanetakis</a> - Proceedings of the international  &hellip;, 2007 - dl.acm.org</div><div class="gs_rs">Abstract This paper presents a survey of recent work in computer-assisted musical <br>instrumental tutoring and outlines several questions to consider when developing future <br>projects. In particular, we suggest that the area ingreatest need of computer assistance is <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=963958909237274801&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 18</a> <a href="/scholar?q=related:sSgpS4WrYA0J:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=963958909237274801&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 21 versions</a> <a onclick="return gs_ocit(event,'sSgpS4WrYA0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://www.mirlab.org/conference_papers/International_Conference/ISMIR%202008/papers/ISMIR2008_127.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mirlab.org</span><span class="gs_ggsS">mirlab.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.mirlab.org/conference_papers/International_Conference/ISMIR%202008/papers/ISMIR2008_127.pdf" class=yC2>Multiple-feature fusion based onset detection for solo singing voice</a></h3><div class="gs_a">CC Toh, B Zhang, Y Wang - &hellip;  of the International Conference on Music  &hellip;, 2008 - mirlab.org</div><div class="gs_rs">ABSTRACT Onset detection is a challenging problem in automatic singing transcription. In <br>this paper, we address singing onset detection with three main contributions. First, we <br>outline the nature of a singing voice and present a new singing onset detection approach <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15227144802269224493&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 14</a> <a href="/scholar?q=related:LV6xUoWvUdMJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15227144802269224493&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 18 versions</a> <a onclick="return gs_ocit(event,'LV6xUoWvUdMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md1', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md1" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:LV6xUoWvUdMJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="https://www1.comp.nus.edu.sg/~wangye/papers/3.Applications_in_Edutainment_(e-Learning)/2007_Educational_Violin_Transcription_by_Fusing_Multimedia_Streams.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1290154" class=yC4>Educational violin transcription by fusing multimedia streams</a></h3><div class="gs_a">Y Wang, B Zhang, O Schleusing - Proceedings of the international  &hellip;, 2007 - dl.acm.org</div><div class="gs_rs">Abstract Computer-assisted violin tutoring requires accurate violin transcription. For pitched <br>non-percussive (PNP) sounds such as from the violin, note segmentation is a much more <br>difficult task than pitch detection. This issue is accentuated when the audio is recorded <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1988379198861831619&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 11</a> <a href="/scholar?q=related:w23vslgkmBsJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1988379198861831619&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'w23vslgkmBsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.76.5003&amp;rep=rep1&amp;type=pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.76.5003&amp;rep=rep1&amp;type=pdf" class=yC6>Low level descriptors for automatic violin transcription</a></h3><div class="gs_a">A Loscos, Y Wang, WJJ Boo - Proc. of ISMIR2006, 2006 - Citeseer</div><div class="gs_rs">Abstract On top of previous work in automatic violin transcription we present a set of straight <br>forward low level descriptors for assisting the transcription techniques and saving <br>computational cost. Proposed descriptors have been tested against a database of 1500 <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6048571281452756955&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 12</a> <a href="/scholar?q=related:2--epYjX8FMJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6048571281452756955&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 25 versions</a> <a onclick="return gs_ocit(event,'2--epYjX8FMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md3', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md3" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:2--epYjX8FMJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4959552" class=yC8>Transcription and expressiveness detection system for violin music</a></h3><div class="gs_a"><a href="/citations?user=9afPq5gAAAAJ&amp;hl=en&amp;oi=sra">I Barbancho</a>, C de la Bandera&hellip; - &hellip; , Speech and Signal  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, a transcription system for music played by violin is presented. The <br>transcription system not only detects the pitch and duration of the notes but also identifies <br>successfully the employed technique to play each note: detache with and without accent <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3008434865180239413&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 9</a> <a href="/scholar?q=related:Neb3DJIbwCkJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3008434865180239413&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'Neb3DJIbwCkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://www.comp.nus.edu.sg/~wangye/papers/3.Applications_in_Edutainment_(e-Learning)/2008_Application_Specific_Music_Transcription_for_Tutoring.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4623948" class=yC9>Application-specific music transcription for tutoring</a></h3><div class="gs_a">Y Wang, B Zhang - Multimedia, IEEE, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Automatic music transcription (AMT) refers to the ability of computers to write note <br>information, such as the pitch, onset time, duration, and source of each sound, after listening <br>to the music. Our application scenario is computer-assisted, musical-instrument tutoring, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=176626421973561276&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 5</a> <a href="/scholar?q=related:vK-ug8uAcwIJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=176626421973561276&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 18 versions</a> <a onclick="return gs_ocit(event,'vK-ug8uAcwIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/Q7771330VV042511.pdf" class=yCB>What signal processing can do for the music</a></h3><div class="gs_a"><a href="/citations?user=9afPq5gAAAAJ&amp;hl=en&amp;oi=sra">I Barbancho</a>, <a href="/citations?user=ezjciQ4AAAAJ&amp;hl=en&amp;oi=sra">L TardÃ³n</a>, <a href="/citations?user=wLOu-1kAAAAJ&amp;hl=en&amp;oi=sra">A Barbancho</a>, A Ortiz&hellip; - Exploring Music  &hellip;, 2011 - Springer</div><div class="gs_rs">In this paper, several examples of what signal processing can do in the music context will be <br>presented. In this contribution, music content includes not only the audio files but also the <br>scores. Using advanced signal processing techniques, we have developed new tools that <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:iAYTxWLb-FsJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6627288068935321224&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'iAYTxWLb-FsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="https://www1.comp.nus.edu.sg/~wangye/papers/1.Audio_and_Music_Analysis_and_Retrieval/2008_Onset_Detection_in_Piteched_Non-Percussive_Music_Using_Warping_Compensated_Correlation.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4517560" class=yCC>Onset detection in pitched non-percussive music using warping-compensated correlation</a></h3><div class="gs_a">O Schleusing, B Zhang, Y Wang - Acoustics, Speech and  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Automatically extracting temporal information from musical recordings is inarguably <br>one of the most critical subtasks of many music information retrieval systems. In this paper <br>we present a system for automatic note onset detection in pitched non-percussive (PNP) <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Iyh_8psTDngJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8650873494734579747&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'Iyh_8psTDngJ')" href="#" class="gs_nph">Cite</a></div></div></div>
