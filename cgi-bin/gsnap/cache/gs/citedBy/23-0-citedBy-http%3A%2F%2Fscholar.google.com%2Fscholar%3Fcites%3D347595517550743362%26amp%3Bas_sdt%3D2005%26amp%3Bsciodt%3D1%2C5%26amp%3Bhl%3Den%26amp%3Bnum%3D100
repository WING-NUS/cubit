Total results = 23
<div class="gs_r" style="z-index:400"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/418R5103V3Q12986.pdf" class=yC0>Geotagging in multimedia and computer visionâa survey</a></h3><div class="gs_a"><a href="/citations?user=CcbnBvgAAAAJ&amp;hl=en&amp;oi=sra">J Luo</a>, <a href="/citations?user=TYmV4V8AAAAJ&amp;hl=en&amp;oi=sra">D Joshi</a>, J Yu, <a href="/citations?user=-RFj-kYAAAAJ&amp;hl=en&amp;oi=sra">A Gallagher</a> - Multimedia Tools and Applications, 2011 - Springer</div><div class="gs_rs">Abstract Geo-tagging is a fast-emerging trend in digital photography and community photo <br>sharing. The presence of geographically relevant metadata with images and videos has <br>opened up interesting research avenues within the multimedia and computer vision <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9460450507726227898&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 22</a> <a href="/scholar?q=related:uokv-JxFSoMJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9460450507726227898&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'uokv-JxFSoMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://www.cs.usc.edu/Research/09-911.pdf" class=yC2><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from usc.edu</span><span class="gs_ggsS">usc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/G02645R5X257448J.pdf" class=yC1>Relevance ranking in georeferenced video search</a></h3><div class="gs_a">S Arslan Ay, <a href="/citations?user=IDREwXEAAAAJ&amp;hl=en&amp;oi=sra">R Zimmermann</a>, SH Kim - Multimedia systems, 2010 - Springer</div><div class="gs_rs">Abstract The rapid adoption and deployment of ubiquitous video cameras has led to the <br>collection of voluminous amounts of media data. However, indexing and searching of large <br>video databases remain a very challenging task. Recently, some recorded video data are <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12963256978801281778&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 5</a> <a href="/scholar?q=related:8sqNOYq95rMJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12963256978801281778&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'8sqNOYq95rMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1631476" class=yC3>GRVS: a georeferenced video search engine</a></h3><div class="gs_a">S Arslan Ay, L Zhang, SH Kim, M He&hellip; - Proceedings of the 17th  &hellip;, 2009 - dl.acm.org</div><div class="gs_rs">Abstract An increasing number of recorded videos are being tagged with geographic <br>properties of the camera scenes. This meta-data is of significant use for storing, indexing <br>and searching large collections of videos. By considering video related meta-information, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7678646024530967886&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 5</a> <a href="/scholar?q=related:Tj0iSOAHkGoJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7678646024530967886&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'Tj0iSOAHkGoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://eiger.ddns.comp.nus.edu.sg/pubs/vectormodel-acmmmsys10.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1730866" class=yC4>Vector model in support of versatile georeferenced video search</a></h3><div class="gs_a">SH Kim, SA Ay, B Yu, <a href="/citations?user=IDREwXEAAAAJ&amp;hl=en&amp;oi=sra">R Zimmermann</a> - &hellip;  of the first annual ACM SIGMM  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract Increasingly geographic properties are being associated with videos, especially <br>those captured from mobile cameras. The meta data from camera-attached sensors can be <br>used to model the coverage area of the scene as a spatial object such that videos can be <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10757803832644613079&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 4</a> <a href="/scholar?q=related:1zMeqJZlS5UJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10757803832644613079&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'1zMeqJZlS5UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://www-bcf.usc.edu/~seonkim/papers/ACM-GIS-2010.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from usc.edu</span><span class="gs_ggsS">usc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1869830" class=yC6>Generating synthetic meta-data for georeferenced video management</a></h3><div class="gs_a">SA Ay, SH Kim, <a href="/citations?user=IDREwXEAAAAJ&amp;hl=en&amp;oi=sra">R Zimmermann</a> - Proceedings of the 18th SIGSPATIAL  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract Recently various sensors, such as GPS and compass devices, can be cost-<br>effectively manufactured and this allows their deployment in conjunction with mobile video <br>cameras. Hence, recorded clips can automatically be annotated with geospatial <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10293010622013707622&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 4</a> <a href="/scholar?q=related:ZhVzQqAe2I4J:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10293010622013707622&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'ZhVzQqAe2I4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://www-bcf.usc.edu/~seonkim/papers/ACM-MM-2011.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from usc.edu</span><span class="gs_ggsS">usc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2072312" class=yC8>Automatic tag generation and ranking for sensor-rich outdoor videos</a></h3><div class="gs_a"><a href="/citations?user=DNxId4IAAAAJ&amp;hl=en&amp;oi=sra">Z Shen</a>, S Arslan Ay, SH Kim&hellip; - Proceedings of the 19th  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract Video tag annotations have become a useful and powerful feature to facilitate video <br>search in many social media and web applications. The majority of tags assigned to videos <br>are supplied by users-a task which is time consuming and may result in annotations that <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16996359001532237434&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 4</a> <a href="/scholar?q=related:eoZXGXYy3-sJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16996359001532237434&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'eoZXGXYy3-sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="https://eiger.ddns.comp.nus.edu.sg/pubs/presentationofgeorefvideos-acmsmvc10.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1878090" class=yCA>Presentation of geo-referenced videos with google earth</a></h3><div class="gs_a">L Zhang, <a href="/citations?user=IDREwXEAAAAJ&amp;hl=en&amp;oi=sra">R Zimmermann</a>, <a href="/citations?user=MQWQLZMAAAAJ&amp;hl=en&amp;oi=sra">G Wang</a> - &hellip;  of the 2010 ACM workshop on  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract Geo-tagging is becoming increasingly common as location information is <br>associated with various data that is collected from a variety of sources. In the field of media, <br>images and most recently videos, can be automatically tagged with the geographic <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3243138006076590687&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 2</a> <a href="/scholar?q=related:X4rDadXwAS0J:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3243138006076590687&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'X4rDadXwAS0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Metadata Organization and Query Optimization for Large-scale Geo-tagged Video Collections. NUS</h3><div class="gs_a">H Ma, S Arslan Ay, <a href="/citations?user=IDREwXEAAAAJ&amp;hl=en&amp;oi=sra">R Zimmermann</a>, SH Kim - 2011 - SoC Technical Report TR10/11,  &hellip;</div><div class="gs_fl"><a href="/scholar?cites=7936800042687050535&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 1</a> <a href="/scholar?q=related:J7OqfZYtJW4J:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'J7OqfZYtJW4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://202.114.89.42/resource/pdf/5543.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 202.114.89.42</span><span class="gs_ggsS">202.114.89.42 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S1047320310000982" class=yCC>Design and implementation of geo-tagged video search framework</a></h3><div class="gs_a">SH Kim, S Arslan Ay, <a href="/citations?user=IDREwXEAAAAJ&amp;hl=en&amp;oi=sra">R Zimmermann</a> - Journal of Visual Communication  &hellip;, 2010 - Elsevier</div><div class="gs_rs">User generated video content is experiencing significant growth which is expected to <br>continue and further accelerate. As an example, users are currently uploading 20h of video <br>per minute to YouTube. Making such video archives effectively searchable is one of the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9511952519873010639&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 1</a> <a href="/scholar?q=related:z5tpm2s-AYQJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9511952519873010639&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'z5tpm2s-AYQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2393347.2396461" class=yCE>DVS: a dynamic multi-video summarization system of sensor-rich videos in geo-space</a></h3><div class="gs_a">Y Zhang, <a href="/citations?user=IDREwXEAAAAJ&amp;hl=en&amp;oi=sra">R Zimmermann</a> - Proceedings of the 20th ACM international  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract It is now very easy to produce user generated videos (UGV) due to progress in <br>camera and recording technologies on mobile devices, such as smartphones. Additionally, <br>the ubiquitous, built-in sensors in digital devices can greatly enrich these videos with <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5585196494140551410&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 1</a> <a onclick="return gs_ocit(event,'8jABqp6agk0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Sensor-assisted Camera Motion Analysis and Motion Estimation Improvement for H. 264/AVC Video Encoding</h3><div class="gs_a"><a href="/citations?user=MQWQLZMAAAAJ&amp;hl=en&amp;oi=sra">G Wang</a>, H Ma, B Seo, <a href="/citations?user=IDREwXEAAAAJ&amp;hl=en&amp;oi=sra">R Zimmermann</a> - 22nd ACM NOSSDAV workshop, 2012</div><div class="gs_fl"><a href="/scholar?cites=18358231779999823421&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 2</a> <a href="/scholar?q=related:PTYtr4mKxf4J:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'PTYtr4mKxf4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2155565" class=yCF>Multi-video summary and skim generation of sensor-rich videos in geo-space</a></h3><div class="gs_a">Y Zhang, <a href="/citations?user=MQWQLZMAAAAJ&amp;hl=en&amp;oi=sra">G Wang</a>, B Seo, <a href="/citations?user=IDREwXEAAAAJ&amp;hl=en&amp;oi=sra">R Zimmermann</a> - Proceedings of the 3rd  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract User-generated videos have become increasingly popular in recent years. Due to <br>advances in camera technology it is now very easy and convenient to record videos with <br>mobile devices, such as smartphones. Here we consider an application where users <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6337616702448700513&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 2</a> <a href="/scholar?q=related:YYwJENC881cJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'YYwJENC881cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2071926" class=yC10>Keyframe presentation for browsing of user-generated videos on map interfaces</a></h3><div class="gs_a">J Hao, <a href="/citations?user=MQWQLZMAAAAJ&amp;hl=en&amp;oi=sra">G Wang</a>, B Seo, <a href="/citations?user=IDREwXEAAAAJ&amp;hl=en&amp;oi=sra">R Zimmermann</a> - Proceedings of the 19th ACM  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract To present user-generated videos that relate to geographic areas for easy access <br>and browsing it is often natural to use maps as interfaces. A common approach is to place <br>thumbnail images of video keyframes in appropriate locations. Here we consider the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3609923633500420771&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 3</a> <a href="/scholar?q=related:o3oUIWsGGTIJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3609923633500420771&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'o3oUIWsGGTIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://www-bcf.usc.edu/~seonkim/papers/ACM-MMSys-2011.pdf" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from usc.edu</span><span class="gs_ggsS">usc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www-bcf.usc.edu/~seonkim/papers/ACM-MMSys-2011.pdf" class=yC11>Energy-efficient mobile video management using smartphones</a></h3><div class="gs_a">J Hao, SH Kim, SA Ay&hellip; - Proceedings of the second  &hellip;, 2011 - www-bcf.usc.edu</div><div class="gs_rs">ABSTRACT Mobile devices are increasingly popular for the versatile capture and delivery of <br>video content. However, the acquisition and transmission of large amounts of video data on <br>mobile devices face fundamental challenges such as power and wireless bandwidth <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:dsz7IqBVz5MJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10650825790024567926&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'dsz7IqBVz5MJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md13', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md13" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:dsz7IqBVz5MJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://www-bcf.usc.edu/~seonkim/papers/ACM-MM-Demo-2011.pdf" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from usc.edu</span><span class="gs_ggsS">usc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2072444" class=yC13>SRV-TAGS: An Automatic TAGging and Search System for Sensor-Rich Outdoor Videos</a></h3><div class="gs_a"><a href="/citations?user=DNxId4IAAAAJ&amp;hl=en&amp;oi=sra">Z Shen</a>, S Arslan Ay, SH Kim - Proceedings of the 19th ACM international &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract Tagging facilitates video search in many social media and web applications. While <br>manual tagging is time consuming, subjective and sometimes inaccurate, auto-tagging <br>facilitated by content-based techniques is compute-intensive and challenging to apply <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:MVHgOl_W6zgJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4101607590148985137&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'MVHgOl_W6zgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://eiger.ddns.comp.nus.edu.sg/pubs/automaticgpsdatacorrection-acmgis12.pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2424392" class=yC15>Automatic positioning data correction for sensor-annotated mobile videos</a></h3><div class="gs_a"><a href="/citations?user=MQWQLZMAAAAJ&amp;hl=en&amp;oi=sra">G Wang</a>, B Seo, <a href="/citations?user=IDREwXEAAAAJ&amp;hl=en&amp;oi=sra">R Zimmermann</a> - Proceedings of the 20th International  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract Video associated positioning data has become a useful contextual feature to <br>facilitate analysis and management of media assets in GIS and social media applications. <br>Moreover, with today&#39;s sensor-equipped mobile devices, the location of a camera can be <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'1wOuaNSAKHsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S092523121200817X" class=yC17>Discovering hot topics from geo-tagged video</a></h3><div class="gs_a">K Liu, J Xu, L Zhang, Z Ding, M Li - Neurocomputing, 2012 - Elsevier</div><div class="gs_rs">Abstract As video data generated by users boom continuously, making sense of large scale <br>data archives is considered as a critical challenge for data management. Most existing <br>learning techniques that extract signal-level contents from video data struggle to scale due <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'vCzqd49L2EAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://eiger.ddns.comp.nus.edu.sg/pubs/hugvid-uncertaingeotaggedvideos-acmgis12.pdf" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2424362" class=yC18>HUGVid: handling, indexing and querying of uncertain geo-tagged videos</a></h3><div class="gs_a">H Ma, <a href="/citations?user=IDREwXEAAAAJ&amp;hl=en&amp;oi=sra">R Zimmermann</a>, SH Kim - &hellip;  of the 20th International Conference on  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract GIS applications now increasingly make use of geo-located multimedia data such <br>as images and videos. Furthermore, the wide-spread availablity of smartphones allows the <br>acquisition of user-generated videos that are annotated with geo-properties. The sensor <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'wXFrhOvqlmUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB18" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW18"><a href="http://www.comp.nus.edu.sg/~yuy/gcp006-yu.pdf" class=yC1B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.comp.nus.edu.sg/~yuy/gcp006-yu.pdf" class=yC1A>Automatic Music Soundtrack Generation for Outdoor Videos from Contextual Sensor Information</a></h3><div class="gs_a">Y Yu, <a href="/citations?user=DNxId4IAAAAJ&amp;hl=en&amp;oi=sra">Z Shen</a>, <a href="/citations?user=IDREwXEAAAAJ&amp;hl=en&amp;oi=sra">R Zimmermann</a> - comp.nus.edu.sg</div><div class="gs_rs">ABSTRACT We present a system to automatically generate soundtracks for user-generated <br>outdoor videos (UGV) based on concurrently captured contextual sensor information with <br>mobile apps for the ACM Multimedia 2012 Google challenge: Automatic Music Video <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:BzK5jkVNi8gJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'BzK5jkVNi8gJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md18', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md18" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:BzK5jkVNi8gJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="http://eiger.ddns.comp.nus.edu.sg/pubs/motiontypecharacterization-demo-acmmm12.pdf" class=yC1D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://eiger.ddns.comp.nus.edu.sg/pubs/motiontypecharacterization-demo-acmmm12.pdf" class=yC1C>Motch: An Automatic Motion Type Characterization System for Sensor-rich Videos</a></h3><div class="gs_a"><a href="/citations?user=MQWQLZMAAAAJ&amp;hl=en&amp;oi=sra">G Wang</a>, B Seo, <a href="/citations?user=IDREwXEAAAAJ&amp;hl=en&amp;oi=sra">R Zimmermann</a> - eiger.ddns.comp.nus.edu.sg</div><div class="gs_rs">ABSTRACT Camera motion information facilitates higher-level semantic description <br>inference in many video applications, eg, video retrieval. However, an efficient and accurate <br>methodology for annotating videos with camera motion information is still an elusive goal. <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:fNTzu3yuZLEJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'fNTzu3yuZLEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md19', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md19" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:fNTzu3yuZLEJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/7045578526714M22.pdf" class=yC1E>A Grid-Based Index and Queries for Large-Scale Geo-tagged Video Collections</a></h3><div class="gs_a">H Ma, S Arslan Ay, <a href="/citations?user=IDREwXEAAAAJ&amp;hl=en&amp;oi=sra">R Zimmermann</a>, S Kim - Database Systems for  &hellip;, 2012 - Springer</div><div class="gs_rs">Currently a large number of user-generated videos are produced on a daily basis. It is <br>further increasingly common to combine videos with a variety of meta-data that increase <br>their usefulness. In our prior work we have created a framework for integrated, sensor-rich <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:K8fs5nAVvzoJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4233125749406353195&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'K8fs5nAVvzoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2339775" class=yC1F>GeoSearch: georeferenced video retrieval system</a></h3><div class="gs_a">Y Kim, J Kim, <a href="/citations?user=LbrCa7EAAAAJ&amp;hl=en&amp;oi=sra">H Yu</a> - Proceedings of the 18th ACM SIGKDD international  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract Conventional video search systems, to find relevant videos, rely on textual data <br>such as video titles, annotations, and text around the video. Nowadays, video recording <br>devices such as ameras, smartphones and car blackboxes are equipped with GPS <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ZzZB7jdVVsQJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'ZzZB7jdVVsQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB22" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW22"><a href="http://wise.ajou.ac.kr:8080/pdfs/pdffile27539.pdf" class=yC21><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ajou.ac.kr</span><span class="gs_ggsS">ajou.ac.kr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1869828" class=yC20>Annotating and navigating tourist videos</a></h3><div class="gs_a">B Zhang, Q Li, H Chao, B Chen, <a href="/citations?user=UvirJPEAAAAJ&amp;hl=en&amp;oi=sra">E Ofek</a>&hellip; - Proceedings of the 18th  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract Due to the rapid increase in video capture technology, more and more tourist <br>videos are captured every day, creating a challenge for organization and association with <br>metadata. In this paper, we present a novel system for annotating and navigating tourist <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3106233056762717051&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 2</a> <a href="/scholar?q=related:e-Pq8YGOGysJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3106233056762717051&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'e-Pq8YGOGysJ')" href="#" class="gs_nph">Cite</a></div></div></div>
