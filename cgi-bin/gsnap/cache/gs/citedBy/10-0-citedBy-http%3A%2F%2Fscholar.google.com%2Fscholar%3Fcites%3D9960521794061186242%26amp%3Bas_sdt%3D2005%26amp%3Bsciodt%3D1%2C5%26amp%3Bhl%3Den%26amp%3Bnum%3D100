Total results = 10
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://wing2.ddns.comp.nus.edu.sg/downloads/keyphraseCorpus/195/195.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1101153" class=yC0>Topic transition detection using hierarchical hidden Markov and semi-Markov models</a></h3><div class="gs_a"><a href="/citations?user=OtA9SwIAAAAJ&amp;hl=en&amp;oi=sra">DQ Phung</a>, <a href="/citations?user=KywMsHsAAAAJ&amp;hl=en&amp;oi=sra">TV Duong</a>, <a href="/citations?user=AEkRUQcAAAAJ&amp;hl=en&amp;oi=sra">S Venkatesh</a>&hellip; - Proceedings of the 13th  &hellip;, 2005 - dl.acm.org</div><div class="gs_rs">Abstract In this paper we introduce a probabilistic framework to exploit hierarchy, structure <br>sharing and duration information for topic transition detection in videos. Our probabilistic <br>detection framework is a combination of a shot classification step and a detection phase <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18347816260995936064&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 18</a> <a href="/scholar?q=related:QG_MsK2JoP4J:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18347816260995936064&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 18 versions</a> <a onclick="return gs_ocit(event,'QG_MsK2JoP4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4959994" class=yC2>A detection-based approach to broadcast news video story segmentation</a></h3><div class="gs_a">C Ma, B Byun, I Kim, CH Lee - Acoustics, Speech and Signal  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract A detection-based paradigm decomposes a complex system into small pieces, <br>solves each subproblem one by one, and combines the collected evidence to obtain a final <br>solution. In this study of video story segmentation, a set of key events are first detected <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1864104719358796898&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 12</a> <a href="/scholar?q=related:YqSCpV2h3hkJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1864104719358796898&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'YqSCpV2h3hkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1647779" class=yC3>Building a smart meeting room: from infrastructure to the video gap (research and open issues)</a></h3><div class="gs_a">A Jaimes, J Miyazaki - Data Engineering Workshops, 2005.  &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract At FXPAL Japan we have built an (experimental) Smart Conference Room (SCR) <br>that contains multiple cameras, microphones, displays, and capture devices. Based on our <br>experience, in this paper we discuss research and open issues in constructing SCRs like <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=212441614377225038&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 10</a> <a href="/scholar?q=related:Tgt30IW-8gIJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=212441614377225038&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'Tgt30IW-8gIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://www.dcs.gla.ac.uk/~hemant/NewsStorySegmentation_MMM09.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from gla.ac.uk</span><span class="gs_ggsS">gla.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/f26r1411ql135143.pdf" class=yC4>Tv news story segmentation based on semantic coherence and content similarity</a></h3><div class="gs_a">H Misra, <a href="/citations?user=tiASHnwAAAAJ&amp;hl=en&amp;oi=sra">F Hopfgartner</a>, A Goyal, P Punitha&hellip; - Advances in Multimedia  &hellip;, 2010 - Springer</div><div class="gs_rs">Abstract. In this paper, we introduce and evaluate two novel approaches, one using video <br>stream and the other using close-caption text stream, for segmenting TV news into stories. <br>The segmentation of the video stream into stories is achieved by detecting anchor person <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12915148785805740031&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 10</a> <a href="/scholar?q=related:_8dEr2TTO7MJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12915148785805740031&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'_8dEr2TTO7MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1180658" class=yC6>Atomic topical segments detection for instructional videos</a></h3><div class="gs_a">Y Li, Y Park, C Dorai - Proceedings of the 14th annual ACM international  &hellip;, 2006 - dl.acm.org</div><div class="gs_rs">Abstract This paper presents our latest work on structuring instructional videos into units of <br>atomic topical segment so as to facilitate topic-based video browsing and offer efficient video <br>authoring. Specifically, we developed a comprehensive text analysis component to first <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16275868989232287036&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 4</a> <a href="/scholar?q=related:PI38yZyA3-EJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16275868989232287036&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'PI38yZyA3-EJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://smartech.gatech.edu/jspui/bitstream/1853/33889/1/ma_chengyuan_201005_phd.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from gatech.edu</span><span class="gs_ggsS">gatech.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://smartech.gatech.edu/handle/1853/33889" class=yC7>A detection-based pattern recognition framework and its applications</a></h3><div class="gs_a">C Ma - 2010 - smartech.gatech.edu</div><div class="gs_rs">The objective of this dissertation is to present a detection-based pattern recognition <br>framework and demonstrate its applications in automatic speech recognition and broadcast <br>news video story segmentation. Inspired by the studies of modern cognitive psychology <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8118894574215641883&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 4</a> <a href="/scholar?q=related:Gzv4eJkbrHAJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8118894574215641883&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'Gzv4eJkbrHAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md5', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md5" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:Gzv4eJkbrHAJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=9235294807336651394&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.google.com/patents?hl=en&amp;lr=&amp;vid=USPAT7305128&amp;id=S-ufAAAAEBAJ&amp;oi=fnd&amp;printsec=abstract" class=yC9>Anchor person detection for television news segmentation based on audiovisual features</a></h3><div class="gs_a">SH Lee, CH Yeh, HH Shih, <a href="/citations?user=81d60okAAAAJ&amp;hl=en&amp;oi=sra">CC Kuo</a> - US Patent 7,305,128, 2007 - Google Patents</div><div class="gs_rs">A video segmentation method for segmenting video clips according to content of the video <br>clips is disclosed. The method comprises scanning pixels of video frames with a first <br>horizontal scan line to determine if colors of the pixels fall within a predetermined color <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4353990292221850942&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 1</a> <a href="/scholar?q=related:PvVhMxp7bDwJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4353990292221850942&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'PvVhMxp7bDwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://domino.watson.ibm.com/library/CyberDig.nsf/papers/20E3D0C29A0C87C4852573380050BD15/$File/rc24319.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ibm.com</span><span class="gs_ggsS">ibm.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4338345" class=yCA>Semantic Analysis for Topical Segmentation of Videos</a></h3><div class="gs_a">Y Park, Y Li - &hellip; , 2007. ICSC 2007. International Conference on, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Topic segmentation of videos enables topic-based categorization, retrieval and <br>browsing and also facilitates efficient video authoring. Existing video topic segmentation <br>techniques, however, are domain specific to news or narrative videos while generic <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:HqnLcW2bX98J:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16095754487608355102&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'HqnLcW2bX98J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://nmlab.korea.ac.kr/publication/rejected%20papers/2008/2008%20-%20Design%20of%20News%20Video%20Story%20Parsing%20System%20-%20TCSVT.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from korea.ac.kr</span><span class="gs_ggsS">korea.ac.kr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://nmlab.korea.ac.kr/publication/rejected%20papers/2008/2008%20-%20Design%20of%20News%20Video%20Story%20Parsing%20System%20-%20TCSVT.pdf" class=yCC>Design of News Video Story Parsing System</a></h3><div class="gs_a">H Lee, Y Im, MS Kim, J Park, D Park - nmlab.korea.ac.kr</div><div class="gs_rs">AbstractâAlthough considerable progress was recently made in the field of news video <br>story parsing, it is still an active and challenging task in a news video library system. In this <br>paper, we introduce a lightweight and fast news video story parsing system with high <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:aZN0dv-qKswJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'aZN0dv-qKswJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md8', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md8" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:aZN0dv-qKswJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://scholarbank.nus.edu/bitstream/handle/10635/14600/XiaoJ.pdf?sequence=1" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu</span><span class="gs_ggsS">nus.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://scholarbank.nus.edu/handle/10635/14600" class=yCE>Global rule induction for information extraction</a></h3><div class="gs_a">X JING - 2005 - scholarbank.nus.edu</div><div class="gs_rs">Information Extraction (IE) is designed to extract specific data from high volumes of text, <br>using robust means. Pattern rule induction is one kind of techniques which have been <br>widely used in IE. This thesis focuses on pattern rule induction for IE on both semi-<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:l76ZzZHb0CsJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3157264758052863639&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'l76ZzZHb0CsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
