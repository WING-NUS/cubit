Total results = 26
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://webfiles.uci.edu/jehan/research/pubs/mm04.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uci.edu</span><span class="gs_ggsS">uci.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1027537" class=yC0>Privacy protecting data collection in media spaces</a></h3><div class="gs_a">J Wickramasuriya, M Datt, <a href="/citations?user=MTZaRW4AAAAJ&amp;hl=en&amp;oi=sra">S Mehrotra</a>&hellip; - Proceedings of the 12th &hellip;, 2004 - dl.acm.org</div><div class="gs_rs">Abstract Around the world as both crime and technology become more prevalent, officials <br>find themselves relying more and more on video surveillance as a cure-all in the name of <br>public safety. Used properly, video cameras help expose wrongdoing but typically come at <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14121808074253518051&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 74</a> <a href="/scholar?q=related:48QffJ-9-sMJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14121808074253518051&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 18 versions</a> <a onclick="return gs_ocit(event,'48QffJ-9-sMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://www.comp.nus.edu.sg/~mohan/papers/fusion_survey.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/E31M71152774R630.pdf" class=yC2>Multimodal fusion for multimedia analysis: a survey</a></h3><div class="gs_a"><a href="/citations?user=2s3sftgAAAAJ&amp;hl=en&amp;oi=sra">PK Atrey</a>, <a href="/citations?user=Qq4AAT4AAAAJ&amp;hl=en&amp;oi=sra">MA Hossain</a>, <a href="/citations?user=VcOjgngAAAAJ&amp;hl=en&amp;oi=sra">A El Saddik</a>, MS Kankanhalli - Multimedia Systems, 2010 - Springer</div><div class="gs_rs">Abstract This survey aims at providing multimedia researchers with a state-of-the-art <br>overview of fusion strategies, which are used for combining multiple modalities in order to <br>accomplish various multimedia analysis tasks. The existing literature on multimodal fusion <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2303959858949282248&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 65</a> <a href="/scholar?q=related:yFlu6UhP-R8J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2303959858949282248&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'yFlu6UhP-R8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="https://doc.freeband.nl/dsweb/Get/Version-18550/Video%20content%20representation%20on%20tiny%20devices.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from freeband.nl</span><span class="gs_ggsS">freeband.nl <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1394583" class=yC4>Video content representation on tiny devices</a></h3><div class="gs_a"><a href="/citations?user=wIE1tY4AAAAJ&amp;hl=en&amp;oi=sra">J Wang</a>, <a href="/citations?user=lzOX9lkAAAAJ&amp;hl=en&amp;oi=sra">MJT Reinders</a>, <a href="/citations?user=nFYok08AAAAJ&amp;hl=en&amp;oi=sra">RL Lagendijk</a>&hellip; - Multimedia and Expo &hellip;, 2004 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The perceptual satisfaction of a user watching video on a tiny mobile device is <br>constrained by the display capability and network bandwidth. To maximize the user&#39;s <br>perceptual satisfaction in this constrained environment, we propose a new method to <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13126842475039566488&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 34</a> <a href="/scholar?q=related:mCo-m67pK7YJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13126842475039566488&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 25 versions</a> <a onclick="return gs_ocit(event,'mCo-m67pK7YJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://www.sis.pitt.edu/~mlewis/surveillance/robocup10/FXPAL-PR-07-411.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from pitt.edu</span><span class="gs_ggsS">pitt.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1291332" class=yC6>DOTS: support for effective video surveillance</a></h3><div class="gs_a"><a href="/citations?user=Dz6O99EAAAAJ&amp;hl=en&amp;oi=sra">A Girgensohn</a>, D Kimber, J Vaughan, <a href="/citations?user=BCxFU0EAAAAJ&amp;hl=en&amp;oi=sra">T Yang</a>&hellip; - Proceedings of the 15th &hellip;, 2007 - dl.acm.org</div><div class="gs_rs">Abstract DOTS (Dynamic Object Tracking System) is an indoor, real-time, multi-camera <br>surveillance system, deployed in a real office setting. DOTS combines video analysis and <br>user interface components to enable security personnel to effectively monitor views of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10047317751510695380&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 35</a> <a href="/scholar?q=related:1H1FFEM-b4sJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10047317751510695380&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'1H1FFEM-b4sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.62.6369&amp;rep=rep1&amp;type=pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1128949" class=yC8>Advanced virtual reality technologies for surveillance and security applications</a></h3><div class="gs_a">R Ott, M GutiÃ©rrez, <a href="/citations?user=GPusciUAAAAJ&amp;hl=en&amp;oi=sra">D Thalmann</a>, F Vexo - Proceedings of the 2006 ACM  &hellip;, 2006 - dl.acm.org</div><div class="gs_rs">Abstract We present a system that exploits advanced Virtual Reality technologies to create a <br>surveillance and security system. Surveillance cameras are carried by a mini Blimp which is <br>tele-operated using an innovative Virtual Reality interface with haptic feedback. An <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12076999013734651580&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 23</a> <a href="/scholar?q=related:vJZlxp0emqcJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12076999013734651580&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'vJZlxp0emqcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://eprints.ucl.ac.uk/13464/1/13464.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ucl.ac.uk</span><span class="gs_ggsS">ucl.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1703508" class=yCA>Experiential sampling in multimedia systems</a></h3><div class="gs_a">MS Kankanhalli, <a href="/citations?user=wIE1tY4AAAAJ&amp;hl=en&amp;oi=sra">J Wang</a>, R Jain - &hellip; , IEEE Transactions on, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Multimedia systems must deal with multiple data streams. Each data stream usually <br>contains significant volume of redundant noisy data. In many real-time applications, it is <br>essential to focus the computing resources on a relevant subset of data streams at any <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11124570279645081716&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 20</a> <a href="/scholar?q=related:dPAclbppYpoJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/45/63/RN197726464.html?source=googlescholar" class="gs_nph" class=yCC>BL Direct</a> <a href="/scholar?cluster=11124570279645081716&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 22 versions</a> <a onclick="return gs_ocit(event,'dPAclbppYpoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="https://webfiles.uci.edu/jehan/research/pubs/spierti05.pdf" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uci.edu</span><span class="gs_ggsS">uci.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=857928" class=yCD>Privacy-protecting video surveillance</a></h3><div class="gs_a">J Wickramasuriya, M Alhazzazi&hellip; - Electronic  &hellip;, 2005 - proceedings.spiedigitallibrary.org</div><div class="gs_rs">abstract Forms of surveillance are very quickly becoming an integral part of crime control <br>policy, crisis management, social control theory and community consciousness. In turn, it <br>has been used as a simple and effective solution to many of these problems. However, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14395287718588773440&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 19</a> <a href="/scholar?q=related:QPQGGulVxscJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14395287718588773440&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'QPQGGulVxscJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://nguyendangbinh.org/Proceedings/CHI/2007/docs/p1167.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nguyendangbinh.org</span><span class="gs_ggsS">nguyendangbinh.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1240624.1240801" class=yCF>Effects of presenting geographic context on tracking activity between cameras</a></h3><div class="gs_a"><a href="/citations?user=Dz6O99EAAAAJ&amp;hl=en&amp;oi=sra">A Girgensohn</a>, <a href="/citations?user=w0hg2MoAAAAJ&amp;hl=en&amp;oi=sra">F Shipman</a>, T Turner&hellip; - Proceedings of the SIGCHI  &hellip;, 2007 - dl.acm.org</div><div class="gs_rs">Abstract A common video surveillance task is to keep track of people moving around the <br>space being monitored. It is often difficult to track activity between cameras because <br>locations such as hallways in office buildings can look quite similar and do not indicate the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13614524450091768320&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 18</a> <a href="/scholar?q=related:ABqXwdqB8LwJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/42/3A/RN211396100.html?source=googlescholar" class="gs_nph" class=yC11>BL Direct</a> <a href="/scholar?cluster=13614524450091768320&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'ABqXwdqB8LwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://fxpal.com/publications/FXPAL-PR-06-380.pdf" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from fxpal.com</span><span class="gs_ggsS">fxpal.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1178787" class=yC12>Support for effective use of multiple video streams in security</a></h3><div class="gs_a"><a href="/citations?user=Dz6O99EAAAAJ&amp;hl=en&amp;oi=sra">A Girgensohn</a>, <a href="/citations?user=w0hg2MoAAAAJ&amp;hl=en&amp;oi=sra">F Shipman</a>, A Dunnigan&hellip; - Proceedings of the 4th  &hellip;, 2006 - dl.acm.org</div><div class="gs_rs">Abstract Video surveillance systems have become common across a wide number of <br>environments. While these installations have included more video streams, they have been <br>also placed in contexts with limited personnel for monitoring the video feeds. In such <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5092562635395894273&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 10</a> <a href="/scholar?q=related:AQwzP7xqrEYJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5092562635395894273&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'AQwzP7xqrEYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://www.mirlab.org/conference_papers/International_Conference/ICICS_PCM%202003/PDFFILES/PAPERS/2C13P0906.PDF" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mirlab.org</span><span class="gs_ggsS">mirlab.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1292638" class=yC14>Adaptive monitoring for video surveillance</a></h3><div class="gs_a"><a href="/citations?user=wIE1tY4AAAAJ&amp;hl=en&amp;oi=sra">J Wang</a>, WQ Yan, MS Kankanhalli&hellip; - &hellip; , 2003 and Fourth  &hellip;, 2003 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Adaptability is one of the key issues in the important area of surveillance systems. <br>Based on attention and sensor samples, the experiential sampling technique provides a <br>general framework for analyzing video data. In this paper, we present a scheme for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5994628161929859462&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 10</a> <a href="/scholar?q=related:htFhaI0yMVMJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5994628161929859462&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 31 versions</a> <a onclick="return gs_ocit(event,'htFhaI0yMVMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://ra.cps.unizar.es:8080/PUBLICATIONS/attachedFiles/document/momm2010.pdf" class=yC17><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unizar.es</span><span class="gs_ggsS">unizar.es <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1971569" class=yC16>A location-aware system for monitoring sport events</a></h3><div class="gs_a"><a href="/citations?user=0xFk1WYAAAAJ&amp;hl=en&amp;oi=sra">S Ilarri</a>, <a href="/citations?user=nrYfN2AAAAAJ&amp;hl=en&amp;oi=sra">E Mena</a>, A Illarramendi, G Marcos - Proceedings of the 8th  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract Nowadays it is widely recognized the need of developing a new generation of <br>professional equipment for broadcasting that allows a considerable reduction of productions <br>costs in different scenarios. We consider mobile multimedia scenarios where the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17279474237912875338&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 5</a> <a href="/scholar?q=related:SoFP0EQGze8J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17279474237912875338&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'SoFP0EQGze8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://www.ojs.academypublisher.com/index.php/jmm/article/viewFile/06010313/2822" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from academypublisher.com</span><span class="gs_ggsS">academypublisher.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5597323" class=yC18>A framework for an event driven video surveillance system</a></h3><div class="gs_a">D Kieran, WQ Yan - Advanced Video and Signal Based  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper we present an event driven surveillance system. The purpose of this <br>system is to enable thorough exploration of surveillance events. The system uses a client-<br>server web architecture as this provides scalability for further development of the system <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3758270923986382115&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 4</a> <a href="/scholar?q=related:Iy3jQX4PKDQJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3758270923986382115&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'Iy3jQX4PKDQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/K321031521TG71T8.pdf" class=yC1A>Effective multimedia surveillance using a human-centric approach</a></h3><div class="gs_a"><a href="/citations?user=2s3sftgAAAAJ&amp;hl=en&amp;oi=sra">PK Atrey</a>, <a href="/citations?user=VcOjgngAAAAJ&amp;hl=en&amp;oi=sra">A El Saddik</a>, MS Kankanhalli - Multimedia Tools and  &hellip;, 2011 - Springer</div><div class="gs_rs">Abstract Large-scale multimedia surveillance installations usually consist of a number of <br>spatially distributed video cameras that are installed in a premise and are connected to a <br>central control station, where human operators (eg, security personnel) remotely monitor <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7812036976678325742&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 4</a> <a href="/scholar?q=related:7s0ghz3uaWwJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7812036976678325742&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'7s0ghz3uaWwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.google.com/patents?hl=en&amp;lr=&amp;vid=USPATAPP11580775&amp;id=NfCoAAAAEBAJ&amp;oi=fnd&amp;printsec=abstract" class=yC1B>Interface for browsing and viewing video from multiple cameras simultaneously that conveys spatial and temporal proximity</a></h3><div class="gs_a"><a href="/citations?user=Dz6O99EAAAAJ&amp;hl=en&amp;oi=sra">A Girgensohn</a>, AE Dunnigan, <a href="/citations?user=w0hg2MoAAAAJ&amp;hl=en&amp;oi=sra">FM Shipman</a>&hellip; - US Patent App. 11/ &hellip;, 2006 - Google Patents</div><div class="gs_rs">An interface and display of video from multiple fixed-position cameras is provided. A main <br>video stream captured by a camera is selected to be the main video stream and is displayed <br>to the interface. Video streams captured by the set of cameras and the main camera that <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8477563174851091946&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 3</a> <a href="/scholar?q=related:6p3uncpapnUJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8477563174851091946&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'6p3uncpapnUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.64.4317&amp;rep=rep1&amp;type=pdf" class=yC1D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1198307" class=yC1C>Multimedia simplification for optimized MMS synthesis</a></h3><div class="gs_a">WQ Yan, MS Kankanhalli - ACM Transactions on Multimedia Computing &hellip;, 2007 - dl.acm.org</div><div class="gs_rs">Abstract We propose a novel transcoding technique called multimedia simplification which is <br>based on experiential sampling. Multimedia simplification helps optimize the synthesis of <br>MMS (multimedia messaging service) messages for mobile phones. Transcoding is useful <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6272608690979916157&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 3</a> <a href="/scholar?q=related:fcni6F7IDFcJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6272608690979916157&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'fcni6F7IDFcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ri"><h3 class="gs_rt"><a href="http://iospress.metapress.com/index/Q227VQ65168V8351.pdf" class=yC1E>A friendly location-aware system to facilitate the work of technical directors when broadcasting sport events</a></h3><div class="gs_a"><a href="/citations?user=0xFk1WYAAAAJ&amp;hl=en&amp;oi=sra">S Ilarri</a>, <a href="/citations?user=nrYfN2AAAAAJ&amp;hl=en&amp;oi=sra">E Mena</a>, A Illarramendi, R Yus, M Laka&hellip; - Mobile Information  &hellip;, 2012 - IOS Press</div><div class="gs_rs">The production costs of broadcasting sport events that require tracking moving objects are <br>continuously increasing. Although those events are very demanded by the audience, <br>broadcasting organizations have economical difficulties to afford them. For that reason, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5685814448561401392&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 4</a> <a href="/scholar?q=related:MC5JwR0S6E4J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5685814448561401392&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'MC5JwR0S6E4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> A framework for multimedia surveillance</h3><div class="gs_a"><a href="/citations?user=2s3sftgAAAAJ&amp;hl=en&amp;oi=sra">PK Atrey</a> - 2004 - PhD Thesis, School of Computing,  &hellip;</div><div class="gs_fl"><a href="/scholar?cites=10263597146751954787&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 1</a> <a href="/scholar?q=related:Y-_c4Tmfb44J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Y-_c4Tmfb44J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[BOOK]</span><span class="gs_ct2">[B]</span></span> <a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=j0vy1nxh2AwC&amp;oi=fnd&amp;pg=PR5&amp;ots=I_0Wh4ovfE&amp;sig=yW_Rkx2PoM5RZfx8h9mGUz7hvLM" class=yC1F>The Era of Interactive Media</a></h3><div class="gs_a">JS Jin, C Xu, M Xu - 2012 - books.google.com</div><div class="gs_rs">Interactive Media is a new research field and a landmark in multimedia development. The <br>Era of Interactive Media is an edited volume contributed from world experts working in <br>academia, research institutions and industry. The Era of Interactive Media focuses mainly <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:-cavPlJxc-EJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16245452878908475129&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'-cavPlJxc-EJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Finding Added/Removed Object From Scene</h3><div class="gs_a">J Shin, R Green</div><div class="gs_fl"><a href="/scholar?q=related:-LwkQTCz6CAJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'-LwkQTCz6CAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="https://doc.novay.nl/dsweb/Get/Version-21777/Experiental%20Sampling%20for%20Monitoring.pdf" class=yC21><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from novay.nl</span><span class="gs_ggsS">novay.nl <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="https://doc.novay.nl/dsweb/Get/Version-21777/Experiental%20Sampling%20for%20Monitoring.pdf" class=yC20>Experiential Sampling for Monitoring</a></h3><div class="gs_a">WQYMS Kankanhalli, WJMJT Reinders - 2003 - doc.novay.nl</div><div class="gs_rs">ABSTRACT This demonstration presents a novel prototype of experiential sampling for <br>monitoring in a multi-camera setting. The system utilizes the experiential sampling technique <br>to compute the importance of each frame in multiple video streams, and selects the most <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:zlllQRWCoc0J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14817267276828727758&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'zlllQRWCoc0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md19', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md19" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:zlllQRWCoc0J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1581013" class=yC22>2D dimension, location and speed descriptors from surveillance video</a></h3><div class="gs_a">A Sugama, S Emmanuel&hellip; - Signal Processing and Its  &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">ABSTRACT Use of video surveillance systems are on the rise for various applications such <br>as protecting the personnel property, law enforcement and traffic management. In <br>surveillance applications; it is necessary to automatically extract actual 2D dimension, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:xTKcSYR3w-AJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'xTKcSYR3w-AJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=982484.982497" class=yC23>Experiential sampling for monitoring</a></h3><div class="gs_a">WQ Yan, MS Kankanhalli, J Wang&hellip; - Proceedings of the 2003  &hellip;, 2003 - dl.acm.org</div><div class="gs_rs">Abstract This demonstration presents a novel prototype of experiential sampling for <br>monitoring in a multi-camera setting. The system utilizes the experiential sampling technique <br>to compute the importance of each frame in multiple video streams, and selects the most <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:VaVPYpYnYI0J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10187185883960026453&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'VaVPYpYnYI0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB22" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW22"><a href="http://www.comp.nus.edu.sg/~mohan/papers/mmas.pdf" class=yC25><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/ANUKC34M23G9MBJH.pdf" class=yC24>Multimedia analysis and synthesis</a></h3><div class="gs_a">M Kankanhalli - AI 2003: Advances in Artificial Intelligence, 2003 - Springer</div><div class="gs_rs">We describe novel approaches to multimedia analysis and synthesis problems. We first <br>present the experiential sampling technique which has the ability to focus on the analysis <br>task by making use of the contextual information. Sensor samples are used to gather <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:t5HWlg4ROjIJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/18/3A/RN141850840.html?source=googlescholar" class="gs_nph" class=yC26>BL Direct</a> <a href="/scholar?cluster=3619224004903473591&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'t5HWlg4ROjIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB23" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW23"><a href="http://137.132.14.55/bitstream/handle/10635/23028/PhD%20Thesis%20-%20Pradeep%20Kumar%20Atrey%20-%202006.pdf?sequence=1" class=yC28><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.14.55</span><span class="gs_ggsS">137.132.14.55 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://137.132.14.55/handle/10635/23028" class=yC27>Information assimilation in Multimedia surveillance systems</a></h3><div class="gs_a"><a href="/citations?user=2s3sftgAAAAJ&amp;hl=en&amp;oi=sra">PK ATREY</a> - 2007 - 137.132.14.55</div><div class="gs_rs">Most multimedia surveillance systems nowadays utilize multiple types of sensors to detect <br>events of interest as and when they occur in the environment. However, due to the <br>asynchrony among and diversity of sensors, information assimilation, ie how to combine <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:qAMSwNgggb4J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13727289254509413288&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'qAMSwNgggb4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.google.com/patents?hl=en&amp;lr=&amp;vid=USPAT7489334&amp;id=z4-zAAAAEBAJ&amp;oi=fnd&amp;printsec=abstract" class=yC29>Method and system for reducing the cost of sampling a moving image</a></h3><div class="gs_a">JB Pickering, PG Wiloughby, GM Blue - US Patent 7,489,334, 2009 - Google Patents</div><div class="gs_rs">An energy-efficient and cost-reducing method and system to enable the successful sampling <br>of a moving image are disclosed. The method and system use movement detection and <br>analysis within a feedback loop to control subsequent sensor movement/lighting/radiation <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:2I2qzzrk8IwJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10155868100963765720&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'2I2qzzrk8IwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB25" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW25"><a href="http://etd.lib.metu.edu.tr/upload/12613755/index.pdf" class=yC2B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from metu.edu.tr</span><span class="gs_ggsS">metu.edu.tr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://etd.lib.metu.edu.tr/upload/12613755/index.pdf" class=yC2A>EVENT BOUNDARY DETECTION USING WEB-CASTING TEXTS AND AUDIO-VISUAL FEATURES</a></h3><div class="gs_a">M BAYAR - 2011 - etd.lib.metu.edu.tr</div><div class="gs_rs">We propose a method to detect events and event boundaries in soccer videos by using web-<br>casting texts and audio-visual features. The events and their inaccurate time information <br>given in web-casting texts need to be aligned with the visual content of the video. Most <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ogrL2Y3XJ0AJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'ogrL2Y3XJ0AJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md25', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md25" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:ogrL2Y3XJ0AJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
