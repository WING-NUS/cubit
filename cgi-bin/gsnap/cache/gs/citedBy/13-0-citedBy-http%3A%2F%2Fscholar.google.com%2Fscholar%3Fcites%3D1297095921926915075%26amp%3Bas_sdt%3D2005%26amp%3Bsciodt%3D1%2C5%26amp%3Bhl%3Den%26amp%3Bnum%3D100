Total results = 13
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://acl-arc.comp.nus.edu.sg/lrec08.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://acl-arc.comp.nus.edu.sg/lrec08.pdf" class=yC0>The acl anthology reference corpus: A reference dataset for bibliographic research in computational linguistics</a></h3><div class="gs_a"><a href="/citations?user=xoyloJAAAAAJ&amp;hl=en&amp;oi=sra">S Bird</a>, <a href="/citations?user=eEGwJ1kAAAAJ&amp;hl=en&amp;oi=sra">R Dale</a>, <a href="/citations?user=jSjEWosAAAAJ&amp;hl=en&amp;oi=sra">BJ Dorr</a>, B Gibson&hellip; - Proc. of the 6th  &hellip;, 2008 - acl-arc.comp.nus.edu.sg</div><div class="gs_rs">Abstract The ACL Anthology is a digital archive of conference and journal papers in natural <br>language processing and computational linguistics. Its primary purpose is to serve as a <br>reference repository of research results, but we believe that it can also be an object of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9005986271216968617&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13">Cited by 59</a> <a href="/scholar?q=related:qaPuQ8yw-3wJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9005986271216968617&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">All 54 versions</a> <a onclick="return gs_ocit(event,'qaPuQ8yw-3wJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md0', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md0" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:qaPuQ8yw-3wJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://www.aclweb.org/anthology/E/E09/E09-1096.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aclweb.org</span><span class="gs_ggsS">aclweb.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1609067.1609161" class=yC2>Feature-based method for document alignment in comparable news corpora</a></h3><div class="gs_a">T Vu, AT Aw, M Zhang - Proceedings of the 12th Conference of the  &hellip;, 2009 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we present a feature-based method to align documents with similar <br>content across two sets of bilingual comparable corpora from daily news texts. We evaluate <br>the contribution of each individual feature and investigate the incorporation of these <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2574272966839177482&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13">Cited by 9</a> <a href="/scholar?q=related:ChFXz5-nuSMJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2574272966839177482&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'ChFXz5-nuSMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.164.7752&amp;rep=rep1&amp;type=pdf#page=33" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1690346" class=yC4>Active learning of extractive reference summaries for lecture speech summarization</a></h3><div class="gs_a">JJ Zhang, <a href="/citations?user=QEMJWzEAAAAJ&amp;hl=en&amp;oi=sra">P Fung</a> - Proceedings of the 2nd Workshop on Building and  &hellip;, 2009 - dl.acm.org</div><div class="gs_rs">Abstract We propose using active learning for tagging extractive reference summary of <br>lecture speech. The training process of feature-based summarization model usually requires <br>a large amount of training data with high-quality reference summaries. Human production <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16313623435177994067&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13">Cited by 3</a> <a href="/scholar?q=related:U6dFvRSiZeIJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16313623435177994067&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">All 19 versions</a> <a onclick="return gs_ocit(event,'U6dFvRSiZeIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5363633" class=yC6>Automatic generation of learning channels by using semantic relations among lecture slides and recorded videos for self-learning systems</a></h3><div class="gs_a">Y Wang, D Kitayama, R Lee&hellip; - Multimedia, 2009. ISM&#39;09. &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We present a method of automatically generating learning channels by using the <br>semantic relations that implicitly exist in slides of a lecture that has accompanying recorded <br>video. These days, many lecture videos with presentation files are shared over the Web <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7873730291682767191&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13">Cited by 3</a> <a href="/scholar?q=related:V_H7xPsbRW0J:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7873730291682767191&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'V_H7xPsbRW0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5373269" class=yC7>Extractive speech summarization by active learning</a></h3><div class="gs_a">JJ Zhang, RHY Chan, <a href="/citations?user=QEMJWzEAAAAJ&amp;hl=en&amp;oi=sra">P Fung</a> - Automatic Speech Recognition  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose an active learning approach for feature-based extractive <br>summarization of lecture speech. Most state-of-the-art speech summarization systems are <br>trained by using a large amount of human reference summaries. Active learning targets to <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4983788774649796226&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13">Cited by 3</a> <a href="/scholar?q=related:gpaUPHz5KUUJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'gpaUPHz5KUUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://www.dl.kuis.kyoto-u.ac.jp/~adam/wi11.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from kyoto-u.ac.jp</span><span class="gs_ggsS">kyoto-u.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2052422" class=yC8>Measuring Comprehensibility of Web Pages Based on Link Analysis</a></h3><div class="gs_a">K Akamatsu, N Pattanasri, <a href="/citations?user=l2vn9GoAAAAJ&amp;hl=en&amp;oi=sra">A Jatowt</a>&hellip; - Proceedings of the 2011  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract We put forward a hypothesis that if there is a link from one page to another, it is <br>likely that comprehensibility of the two pages is similar. To investigate whether this <br>hypothesis is true or not, we conduct experiments using existing readability measures. We <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5503128683377331970&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13">Cited by 1</a> <a href="/scholar?q=related:Ag_4dWEKX0wJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5503128683377331970&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'Ag_4dWEKX0wJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/Q7H386635416N671.pdf" class=yCA>Skeleton Generation for Presentation Slides Based on Expression Styles</a></h3><div class="gs_a">Y Wang, K Sumiya - Intelligent Interactive Multimedia: Systems and  &hellip;, 2012 - Springer</div><div class="gs_rs">With the advent of PowerPoint and Keynote that can effectively create attractive presentation <br>slides, people can use them to exchange and discuss ideas together. However, because it is <br>necessary to prepare many slides to enable audiences to understand the content, authors <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6211901817961219246&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13">Cited by 1</a> <a href="/scholar?q=related:roQul8obNVYJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'roQul8obNVYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/3372KJUH66430134.pdf" class=yCB>Relevant piece of information extraction from presentation slide page for slide information retrieval system</a></h3><div class="gs_a">T Hayama, S Kunifuji - Knowledge, Information, and Creativity Support  &hellip;, 2011 - Springer</div><div class="gs_rs">An approach to create a slide-data reuse system is to provide minimum information needed <br>from a slide page to meet users&#39; needs. Previous techniques for slide data processing have <br>not handled each piece of information within a slide page accurately: some ruled out <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:sWLaK5FEe6wJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12428602986955694769&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'sWLaK5FEe6wJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://db-event.jpn.org/deim2012/proceedings/final-pdf/d5-3.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from jpn.org</span><span class="gs_ggsS">jpn.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://db-event.jpn.org/deim2012/proceedings/final-pdf/d5-3.pdf" class=yCC>Generating Slide Skeletons based on Expression Styles for Presentation Contents</a></h3><div class="gs_a">Y WANG, K SUMIYA - db-event.jpn.org</div><div class="gs_rs">Abstract By using PowerPoint or Keynote that can effectively create attractive presentation <br>slides, a presentation-based communication environment can now be created in which <br>people can use these presentation slides to exchange and discuss ideas together. <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:7oZ2XfDA3F4J:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'7oZ2XfDA3F4J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md8', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md8" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:7oZ2XfDA3F4J:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://wing.comp.nus.edu.sg/publications/theses/2008/GuoMin_HYP.pdf" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://wing.comp.nus.edu.sg/publications/theses/2008/GuoMin_HYP.pdf" class=yCE>SLIDIR: Slide Image Retrieval</a></h3><div class="gs_a">LG Min - wing.comp.nus.edu.sg</div><div class="gs_rs">Abstract Current retrieval techniques concentrate wholly on single modalities such as text <br>documents and videos. This inability to retrieve useful mixed media results can hamper <br>information seeking tasks in digital libraries. In this report, we consider the task of slide <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:YgqWXjFhI9AJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14997938048742066786&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'YgqWXjFhI9AJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md9', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md9" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:YgqWXjFhI9AJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2093155" class=yC10>Active learning with semi-automatic annotation for extractive speech summarization</a></h3><div class="gs_a">JJ Zhang, <a href="/citations?user=QEMJWzEAAAAJ&amp;hl=en&amp;oi=sra">P Fung</a> - ACM Transactions on Speech and Language  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract We propose using active learning for extractive speech summarization in order to <br>reduce human effort in generating reference summaries. Active learning chooses a selective <br>set of samples to be labeled. We propose a combination of informativeness and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:AzJ9asvWLUcJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'AzJ9asvWLUcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/H677418X3K773525.pdf" class=yC11>Retrieving System of Presentation Contents Based on User&#39;s Operations and Semantic Contexts</a></h3><div class="gs_a">D Kitayama, K Sumiya - Database Systems for Advanced Applications, 2010 - Springer</div><div class="gs_rs">More and more presentation contents, which consist of heterogeneous media such as <br>videos and slides, have recently been recorded and viewed. In e-Learning, we often use <br>presentation contents archives. However, if there is a slide that includes a keyword that <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:UTgUrio8Kq8J:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12621967059666090065&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'UTgUrio8Kq8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="https://dspace.jaist.ac.jp/dspace/bitstream/10119/9215/1/16010.pdf" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from jaist.ac.jp</span><span class="gs_ggsS">jaist.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="https://dspace.jaist.ac.jp/dspace/handle/10119/9215" class=yC12>ãã¬ã¼ã³ãã¼ã·ã§ã³ã¹ã©ã¤ãæå ±æ¤ç´¢ã®ããã®ã¹ã©ã¤ããã¼ã¸ããã®è¦æ±é¢é£æå ±æ½åº</a></h3><div class="gs_a">ç¾½å±±å¾¹å½©ï¼ åè¤é² - 2010 - dspace.jaist.ac.jp</div><div class="gs_rs">æé²: è¿å¹´ã®é»å­åãã¬ã¼ã³ãã¼ã·ã§ã³ã®æ®åã«ãã, å¤ãã®å ´é¢ã§é»å­çãªãã¬ã¼ã³ãã¼ã·ã§ã³è³æ <br>(ã¹ã©ã¤ã) ãå©ç¨ãã, èç©ããã¦ãã. èç©ãããã¹ã©ã¤ããã¼ã¿ã¯è¨å¤§ãªç¥è­è³æºã¨ãªãã¤ã¤ãã<br>ãã, ãã®æå ±ã¢ã¯ã»ã¹æ§ãé«ããæ¢ç´¢æè¡ãæ±ãããã¦ãã. ã¹ã©ã¤ãã«å«ã¾ããæå ±ã®<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:rvU6T9vaihsJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1984639221272081838&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'rvU6T9vaihsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
