Total results = 12
<div class="gs_r" style="z-index:400"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1412201" class=yC0>Watch-and-comment as a paradigm toward ubiquitous interactive video editing</a></h3><div class="gs_a">RG Cattelan, C Teixeira, <a href="/citations?user=6lc68RgAAAAJ&amp;hl=en&amp;oi=sra">R Goularte</a>&hellip; - ACM Transactions on  &hellip;, 2008 - dl.acm.org</div><div class="gs_rs">Abstract The literature reports research efforts allowing the editing of interactive TV <br>multimedia documents by end-users. In this article we propose complementary contributions <br>relative to end-user generated interactive video, video tagging, and collaboration. In <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=121517305252272357&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12">Cited by 54</a> <a href="/scholar?q=related:5difZVi3rwEJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=121517305252272357&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'5difZVi3rwEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/A4MHUL4149HH2145.pdf" class=yC1>Ubiquitous interactive video editing via multimodal annotations</a></h3><div class="gs_a"><a href="/citations?user=2z--uNYAAAAJ&amp;hl=en&amp;oi=sra">M da GraÃ§a C. Pimentel</a>, <a href="/citations?user=6lc68RgAAAAJ&amp;hl=en&amp;oi=sra">R Goularte</a>, R Cattelan&hellip; - Changing Television  &hellip;, 2008 - Springer</div><div class="gs_rs">Considering that, when users watch a video with someone else, they are used to make <br>comments regarding its contentsâsuch as a comment with respect to someone appearing in <br>the videoâin previous work we exploited ubiquitous computing concepts to propose the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18093578734102098745&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12">Cited by 17</a> <a href="/scholar?q=related:ObO3qf5NGfsJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/56/03/RN232340111.html?source=googlescholar" class="gs_nph" class=yC2>BL Direct</a> <a href="/scholar?cluster=18093578734102098745&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'ObO3qf5NGfsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4475972" class=yC3>Enhancing multimodal annotations with pen-based information</a></h3><div class="gs_a"><a href="/citations?user=2z--uNYAAAAJ&amp;hl=en&amp;oi=sra">MG Pimentel</a>, <a href="/citations?user=6lc68RgAAAAJ&amp;hl=en&amp;oi=sra">R Goularte</a>, RG Cattelan&hellip; - &hellip; , 2007. ISMW&#39;07.  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Ubiquitous computing aims at providing services to users without taking their <br>attention from their main task. Considering that, when users watch a video with someone <br>else, they are used to make comments with respect to its contents, we propose the capture <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3692022280511044219&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12">Cited by 14</a> <a href="/scholar?q=related:ezqw9LOyPDMJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3692022280511044219&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'ezqw9LOyPDMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/38230447661335H8.pdf" class=yC4>Metadata in the audiovisual media production process</a></h3><div class="gs_a">W Bailer, P Schallauer - Multimedia SemanticsâThe Role of Metadata, 2008 - Springer</div><div class="gs_rs">This chapter examines the role of metadata in the production process of audiovisual media. <br>We analyse the role of metadata in this process and discuss strengths and weaknesses of <br>relevant standards wrt metadata involved in the process. As no single standard fulfills all <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9065299209449588159&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12">Cited by 10</a> <a href="/scholar?q=related:v0Xf2Zlpzn0J:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9065299209449588159&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'v0Xf2Zlpzn0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://hal.archives-ouvertes.fr/docs/00/18/93/40/PDF/SADPI-Caillet.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1283880.1283887" class=yC5>Engineering multimedia applications on the basis of multi-structured descriptions of audiovisual contents</a></h3><div class="gs_a">M Caillet, J Carrive, C Roisin, F Yvon - Proceedings of the 2007  &hellip;, 2007 - dl.acm.org</div><div class="gs_rs">Abstract We focus our interest on the engineering of multimedia applications whose purpose <br>is to exploit and make best use of the audiovisual heritage by means of prospective <br>exploration of virtual access to audiovisual documents through multi-structured <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12328278989006841427&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12">Cited by 3</a> <a href="/scholar?q=related:UyaqJ2zYFqsJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12328278989006841427&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'UyaqJ2zYFqsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://www.di.unito.it/~rossana/concorso_ROMA/pagina_pubblicazioni/HSI-IIHCI2010.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unito.it</span><span class="gs_ggsS">unito.it <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5447518" class=yC7>An intelligent tool for narrative-based video annotation and editing</a></h3><div class="gs_a"><a href="/citations?user=2cjRsjQAAAAJ&amp;hl=en&amp;oi=sra">V Lombardo</a>, <a href="/citations?user=lqYzhzwAAAAJ&amp;hl=en&amp;oi=sra">R Damiano</a> - Complex, Intelligent and Software  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Recently, there has been much development in the annotation and automatic <br>editing of video segments. The major issue has been the re-use of segments through a <br>number of different editing processes. However, the annotation of the story progression <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14389675072024296640&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12">Cited by 3</a> <a href="/scholar?q=related:wDxN_TxlsscJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14389675072024296640&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'wDxN_TxlsscJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/343670318160P031.pdf" class=yC9>Semantic annotation of narrative media objects</a></h3><div class="gs_a"><a href="/citations?user=2cjRsjQAAAAJ&amp;hl=en&amp;oi=sra">V Lombardo</a>, <a href="/citations?user=lqYzhzwAAAAJ&amp;hl=en&amp;oi=sra">R Damiano</a> - Multimedia Tools and Applications, 2012 - Springer</div><div class="gs_rs">Abstract This paper addresses the annotation of the narrative features of media objects. <br>Based on a relevant narratological and computational background, we introduce an <br>ontologyâbased model called Drammar, an annotation schema for the narrative features <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8649602427362983114&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12">Cited by 1</a> <a href="/scholar?q=related:yrxTg5SPCXgJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8649602427362983114&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'yrxTg5SPCXgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/T684277148273118.pdf" class=yCA>Narrative annotation and editing of video</a></h3><div class="gs_a"><a href="/citations?user=2cjRsjQAAAAJ&amp;hl=en&amp;oi=sra">V Lombardo</a>, <a href="/citations?user=lqYzhzwAAAAJ&amp;hl=en&amp;oi=sra">R Damiano</a> - Interactive Storytelling, 2010 - Springer</div><div class="gs_rs">Narratives are widespread in multimedia, especially in linear audiovisuals. However, rare <br>are the approaches that deal with video annotation and editing with respect to the narrative <br>content. In this paper, we introduce an annotation schema for the narrative features of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2436333328197631844&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12">Cited by 1</a> <a href="/scholar?q=related:ZD-q9UCYzyEJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2436333328197631844&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'ZD-q9UCYzyEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://oaj.unsri.ac.id/files/jucs/jucs_13_10_1411_1433_sioutas_oaj_unsri.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unsri.ac.id</span><span class="gs_ggsS">unsri.ac.id <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://jucs.org/jucs_13_10/efficient_access_methods_for/jucs_13_10_1411_1433_sioutas.pdf" class=yCB>Efficient Access Methods for Temporal Interval Queries of Video Metadata</a></h3><div class="gs_a">S Sioutas, K Tsichlas, B Vassiliadis, D Tsolis - Journal of Universal  &hellip;, 2007 - jucs.org</div><div class="gs_rs">Abstract: Indexing video content is one of the most important problems in video databases. <br>In this paper we present linear time and space algorithms for handling video metadata that <br>represent objects or events present in various frames of the video sequence. To <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:7zxMBgAjR8EJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13927138855679180015&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'7zxMBgAjR8EJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5662593" class=yCD>Implementation of an Internet Broadcasting System with Video Advertisement Insertion Based on Audience Comments</a></h3><div class="gs_a">Y Saito, Y Murayama - P2P, Parallel, Grid, Cloud and Internet  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In recent years, mid-roll advertisements which insert a video advertisement at the <br>middle of the video content appear gradually. However, the mid-roll advertisements usually <br>interrupt video viewing because it inserts a video advertisement at the fixed or random <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:0jrMDYld_EUJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5043008525971503826&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'0jrMDYld_EUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> A Complete Bibliography of ACM Transactions on Multimedia Computing, Communications and Applications</h3><div class="gs_a">NHF Beebe - 2008</div><div class="gs_fl"><a href="/scholar?q=related:3PRXMWShABgJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1729559708606919900&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'3PRXMWShABgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://hci.rwth-aachen.de/materials/publications/lee2007e.pdf" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from rwth-aachen.de</span><span class="gs_ggsS">rwth-aachen.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[BOOK]</span><span class="gs_ct2">[B]</span></span> <a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=YFEWhvhWAkwC&amp;oi=fnd&amp;pg=PR19&amp;ots=2WeOAHiaRH&amp;sig=CQbRWn389l3K1F3o0jZWMXrddpk" class=yCE>A Semantic Time Framework for Interactive Media Systems</a></h3><div class="gs_a">E Lee - 2007 - books.google.com</div><div class="gs_rs">Abstract Despite continuing advancements in computer technology, interaction with time-<br>based media such as audio and video remain predominantly limited to the 1960s tape <br>recorder metaphors of âplayâ,âpauseâ,âfast-forwardâ and ârewindâ. These metaphors restrict <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:acA8yvtx7ZgJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11019589189489180777&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'acA8yvtx7ZgJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md11', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md11" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:acA8yvtx7ZgJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=11526826576594265177&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
