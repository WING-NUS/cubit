Total results = 7
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://koasas.kaist.ac.kr/bitstream/10203/23072/1/31.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from kaist.ac.kr</span><span class="gs_ggsS">kaist.ac.kr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4064552" class=yC0>A music summarization scheme using tempo tracking and two stage clustering</a></h3><div class="gs_a">S Kim, S Kim, S Kwon, H Kim - Multimedia Signal Processing,  &hellip;, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present effective methods for music summarization which <br>automatically extract a representative portion of the music by signal processing technology. <br>Our proposed method uses 2-dimensional similarity matrix, tempo tracking, and clustering <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3745868000617663939&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7">Cited by 3</a> <a href="/scholar?q=related:w41RoBn_-zMJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3745868000617663939&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'w41RoBn_-zMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5404218" class=yC2>Automatic Music Mood Detection through Musical Structure Analysis</a></h3><div class="gs_a">JI Lee, DG Yeo, BM Kim, HY Lee - Computer Science and its  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">AbstractâSince music has a close relation with people emotion, many researchers have <br>studied on detecting music mood. Usually, they manually selected the representative <br>segment of music and classified its mood. Although such manual approaches correctly <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17673215250074995566&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=7">Cited by 1</a> <a href="/scholar?q=related:bou8G6LfQ_UJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'bou8G6LfQ_UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/FT671731J0403662.pdf" class=yC3>A Survey of Music Structure Analysis Techniques for Music Applications</a></h3><div class="gs_a">N Maddage, <a href="/citations?user=z8_x7C8AAAAJ&amp;hl=en&amp;oi=sra">H Li</a>, M Kankanhalli - Recent Advances in Multimedia Signal  &hellip;, 2009 - Springer</div><div class="gs_rs">Music carries multilayer information which forms different structures. The information <br>embedded in the music can be categorized into time information, harmony/melody, music <br>regions, music similarities, song structures and music semantics. In this chapter, we first <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:3vo8SvZRZuUJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16529989600559299294&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'3vo8SvZRZuUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.freepatentsonline.com/EP1818837.html" class=yC4>System for a speech-driven selection of an audio file and method therefor</a></h3><div class="gs_a">D Gerl, S Franz, D Willett, R Brueckner - EP Patent  &hellip;, 2009 - freepatentsonline.com</div><div class="gs_rs">XI SHAO ET AL:&quot; Automatic Music Summarization Based on Music Structure Analysis&quot; <br>ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, 2005. PROCEEDINGS.(ICASSP&#39;05). <br>IEEE INTERNATIONAL CONFERENCE ON PHILADELPHIA, PENNSYLVANIA, USA <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:YSbmUYkBgX8J:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'YSbmUYkBgX8J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md3', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md3" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:YSbmUYkBgX8J:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://www.waset.ac.nz/journals/waset/v26/v26-122.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from waset.ac.nz</span><span class="gs_ggsS">waset.ac.nz <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.waset.ac.nz/journals/waset/v26/v26-122.pdf" class=yC5>Effective Digital Music Retrieval System through Content-based Features</a></h3><div class="gs_a">B Sung, K Koo, J Kim, MB Jung, J Kwon, I Ko - waset.ac.nz</div><div class="gs_rs">AbstractâIn this paper, we propose effective system for digital music retrieval. We divided <br>proposed system into Client and Server. Client part consists of pre-processing and Content-<br>based feature extraction stages. In pre-processing stage, we minimized Time code Gap <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:qQo4ijocdLIJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12858933873802218153&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'qQo4ijocdLIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md4', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md4" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:qQo4ijocdLIJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="https://files.nyu.edu/jb2843/public/Publications_files/NietoHumphrey_ISMIR2012.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nyu.edu</span><span class="gs_ggsS">nyu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="https://files.nyu.edu/jb2843/public/Publications_files/NietoHumphrey_ISMIR2012.pdf" class=yC7>COMPRESSING MUSIC RECORDINGS INTO AUDIO SUMMARIES</a></h3><div class="gs_a">O Nieto, <a href="/citations?user=kzS_Xd4AAAAJ&amp;hl=en&amp;oi=sra">EJ Humphrey</a>, JP Bello - files.nyu.edu</div><div class="gs_rs">ABSTRACT We present a criterion to generate audible summaries of music recordings that <br>optimally explain a given track with mutually disjoint segments of itself. We represent audio <br>as sequences of beat-synchronous harmonic features and use an exhaustive search to <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ANKItA4TlQUJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=402248695598862848&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'ANKItA4TlQUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md5', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md5" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:ANKItA4TlQUJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.dbpia.co.kr/view/ar_view.asp?arid=1084784" class=yC9>ëíêµ¬ê°ì ìì í¹ì§ì ê¸°ë°í ìì ì¥ë¥´ ë¶ë¥</a></h3><div class="gs_a">ê¹ë³ë§ - ì ë³´ê³¼ííë¼ë¬¸ì§: ìíí¸ì¨ì´ ë° ìì©, 2008 - dbpia.co.kr</div><div class="gs_rs">ì¼ë¶ ìì ì¥ë¥´ ë¶ë¥ì ê´í ê¸°ì¡´ ì°êµ¬ììë í¹ì§ ì¶ì¶ì ìí êµ¬ê° ì í ì ì¬ëì´ ì§ì  ê³¡ì <br>ì£¼ì êµ¬ê°ì ì§ì íë ë°©ë²ì ì¬ì©íìë¤. ì´ë¬í ë°©ë²ì ë¶ë¥ ì±ë¥ì´ ì¢ì ë°ë©´ ìììì¼ë¡ <br>ì¸í ë¶ë´ì¼ë¡ ìë¡­ê² ë±ë¡ëë ììë¤ì ëí´ ì§ìì ì¼ë¡ ì ì©íê¸°ê° ê³¤ëíë¤. ììì <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:AdKO922gXiUJ:scholar.google.com/&amp;hl=en&amp;num=7&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'AdKO922gXiUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
