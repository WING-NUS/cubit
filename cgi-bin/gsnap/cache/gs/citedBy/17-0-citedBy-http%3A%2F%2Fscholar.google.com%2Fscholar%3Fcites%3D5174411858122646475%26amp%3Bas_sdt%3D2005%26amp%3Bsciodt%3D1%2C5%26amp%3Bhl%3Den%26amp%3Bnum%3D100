Total results = 17
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.loria.fr/~tombre/tombre-das02-slides.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from loria.fr</span><span class="gs_ggsS">loria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/pf1urq7lw2jy9h94.pdf" class=yC0>Text/graphics separation revisited</a></h3><div class="gs_a">K Tombre, S Tabbone, L PÃ©lissier, <a href="/citations?user=aFZTrIEAAAAJ&amp;hl=en&amp;oi=sra">B Lamiroy</a>&hellip; - &hellip;  Analysis Systems V, 2002 - Springer</div><div class="gs_rs">Text/graphics separation aims at segmenting the document into two layers: a layer assumed <br>to contain text and a layer containing graphical objects. In this paper, we present a <br>consolidation of a method proposed by Fletcher and Kasturi, with a number of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8135942394728713832&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 68</a> <a href="/scholar?q=related:aI7YfoCs6HAJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/00/40/RN118897717.html?source=googlescholar" class="gs_nph" class=yC2>BL Direct</a> <a href="/scholar?cluster=8135942394728713832&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 20 versions</a> <a onclick="return gs_ocit(event,'aI7YfoCs6HAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="https://www.comp.nus.edu/~kanmy/dossier/papers/Fei_1568986414.pdf" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu</span><span class="gs_ggsS">nus.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/8263j7l252747456.pdf" class=yC3>NPIC: Hierarchical synthetic image classification using image search and generic features</a></h3><div class="gs_a">F Wang, <a href="/citations?user=aNVcd3EAAAAJ&amp;hl=en&amp;oi=sra">MY Kan</a> - Image and Video Retrieval, 2006 - Springer</div><div class="gs_rs">Abstract. We introduce NPIC, an image classification system that focuses on synthetic (eg, <br>non-photographic) images. We use class-specific keywords in an image search engine to <br>create a noisily labeled training corpus of images for each class. NPIC then extracts both <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14492532737300662511&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 10</a> <a href="/scholar?q=related:74iGZr3RH8kJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/57/5E/RN192552446.html?source=googlescholar" class="gs_nph" class=yC5>BL Direct</a> <a href="/scholar?cluster=14492532737300662511&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 18 versions</a> <a onclick="return gs_ocit(event,'74iGZr3RH8kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://hal.inria.fr/docs/00/30/80/09/PDF/paper-pouderoux07b.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from inria.fr</span><span class="gs_ggsS">inria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4378766" class=yC6>Toponym recognition in scanned color topographic maps</a></h3><div class="gs_a">J Pouderoux, JC Gonzato, A Pereira&hellip; - &hellip; and Recognition, 2007 &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Topographic paper maps are a common support for geographical information. In <br>the field of document analysis of this kind of support, this paper proposes an automatic <br>approach to extract and recognize toponyms. We present a technique based on image <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11516225680831380163&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 11</a> <a href="/scholar?q=related:w3ovuz3a0Z8J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11516225680831380163&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'w3ovuz3a0Z8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://www.cvc.uab.es/icdar2009/papers/3725a768.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uab.es</span><span class="gs_ggsS">uab.es <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5277504" class=yC8>Page rule-line removal using linear subspaces in monochromatic handwritten arabic documents</a></h3><div class="gs_a">W Abd-Almageed, <a href="/citations?user=23b1se4AAAAJ&amp;hl=en&amp;oi=sra">J Kumar</a>&hellip; - Document Analysis and  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper we present a novel method for removing page rule lines in <br>monochromatic handwritten Arabic documents using subspace methods with minimal effect <br>on the quality of the foreground text. We use moment and histogram properties to extract <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17107279258347019841&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 6</a> <a href="/scholar?q=related:QZ4u49hDae0J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17107279258347019841&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'QZ4u49hDae0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://www.icdar2011.org/fileup/PDF/4520a734.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from icdar2011.org</span><span class="gs_ggsS">icdar2011.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6065408" class=yCA>Text/Graphics Segmentation in Architectural Floor Plans</a></h3><div class="gs_a">S Ahmed, <a href="/citations?user=_UBXhWYAAAAJ&amp;hl=en&amp;oi=sra">M Weber</a>, <a href="/citations?user=n1Y4zq4AAAAJ&amp;hl=en&amp;oi=sra">M Liwicki</a>&hellip; - Document Analysis and  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose an improved method for text/graphics segmentation. <br>Text/graphics separation is a crucial preprocessing step in document analysis before further <br>analysis and recognition can be applied. Our proposed system extends the method of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15610650528581967330&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 4</a> <a href="/scholar?q=related:4l3kbPIrpNgJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15610650528581967330&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'4l3kbPIrpNgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://www.scholarbank.nus.edu.sg/bitstream/handle/10635/14556/PhDThesis-LooPohKok.pdf?sequence=1" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.scholarbank.nus.edu.sg/handle/10635/14556" class=yCC>Document image processing using irregular pyramid structure</a></h3><div class="gs_a">LOOPOH KOK - 2005 - scholarbank.nus.edu.sg</div><div class="gs_rs">This thesis will present our research in the use of a new irregular pyramid structure in <br>document image processing. The focus is in the segmentation of textual components from <br>binary, gray scale and color document images with mixed texts/graphics. The thesis <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5958240527368237188&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:hLAeCDHsr1IJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5958240527368237188&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'hLAeCDHsr1IJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://www.comp.nus.edu.sg/~tancl/publications/c2007/ICDAR07_huang_LocateChart.pdf" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4378722" class=yCE>Locating Charts from Scanned Document Pages</a></h3><div class="gs_a">W Huang, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - &hellip; and Recognition, 2007. ICDAR 2007. Ninth &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents our work on automatically locating charts from document <br>pages, which is an important stage in our chart image recognition and understanding system <br>currently being developed. To achieve this, there are two sub-goals to be reached: <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3806351058099554089&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:Kcd01B7g0jQJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3806351058099554089&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 17 versions</a> <a onclick="return gs_ocit(event,'Kcd01B7g0jQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://www.isa.ru/proceedings/images/documents/2009-45/159-173.pdf" class=yC11><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from isa.ru</span><span class="gs_ggsS">isa.ru <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.isa.ru/proceedings/images/documents/2009-45/159-173.pdf" class=yC10>Cognitive PDF/AâÑÐµÑÐ½Ð¾Ð»Ð¾Ð³Ð¸Ñ Ð¾ÑÐ¸ÑÑÐ¾Ð²ÐºÐ¸ ÑÐµÐºÑÑÐ¾Ð²ÑÑ Ð´Ð¾ÐºÑÐ¼ÐµÐ½ÑÐ¾Ð² Ð´Ð»Ñ Ð¿ÑÐ±Ð»Ð¸ÐºÐ°ÑÐ¸Ð¸ Ð² ÐÐ½ÑÐµÑÐ½ÐµÑÐµ Ð¸ Ð´Ð¾Ð»Ð³Ð¾Ð²ÑÐµÐ¼ÐµÐ½Ð½Ð¾Ð³Ð¾ Ð°ÑÑÐ¸Ð²Ð½Ð¾Ð³Ð¾ ÑÑÐ°Ð½ÐµÐ½Ð¸Ñ</a></h3><div class="gs_a">CÐ Ð£ÑÐ¸Ð»Ð¸Ð½, ÐÐ ÐÐ¸ÐºÐ¾Ð»Ð°ÐµÐ², ÐÐ ÐÐ¾ÑÑÐ½Ð¸ÐºÐ¾Ð² - Ð¢ÑÑÐ´Ñ, 2009 - isa.ru</div><div class="gs_rs">Ð ÑÐ°Ð±Ð¾ÑÐµ ÑÐ°ÑÑÐ¼Ð°ÑÑÐ¸Ð²Ð°ÑÑÑÑ Ð²Ð¾Ð¿ÑÐ¾ÑÑ Ð¿ÐµÑÐµÐ²Ð¾Ð´Ð° Ð±ÑÐ¼Ð°Ð¶Ð½ÑÑ Ð´Ð¾ÐºÑÐ¼ÐµÐ½ÑÐ¾Ð² Ð² ÑÐ»ÐµÐºÑÑÐ¾Ð½Ð½ÑÑ <br>Ð²Ð¸Ð´. ÐÑÐµÐ´Ð»Ð°Ð³Ð°ÐµÑÑÑ Ð¾ÑÐ¸Ð³Ð¸Ð½Ð°Ð»ÑÐ½Ð°Ñ ÑÐµÑÐ½Ð¾Ð»Ð¾Ð³Ð¸Ñ Ð¾ÑÐ¸ÑÑÐ¾Ð²ÐºÐ¸, Ð²ÐºÐ»ÑÑÐ°ÑÑÐ°Ñ ÑÐ¶Ð°ÑÐ¸Ðµ, <br>ÑÐ°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ Ð¸ ÑÐ¿Ð°ÐºÐ¾Ð²ÐºÑ ÑÐµÐºÑÑÐ¾Ð²ÑÑ Ð´Ð¾ÐºÑÐ¼ÐµÐ½ÑÐ¾Ð² ÑÐ¿Ð¾ÑÐ¾Ð±Ð¾Ð¼, Ð¿ÑÐ¸Ð³Ð¾Ð´Ð½ÑÐ¼ Ð´Ð»Ñ <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15736666725586125602&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:IkNFrwLfY9oJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15736666725586125602&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'IkNFrwLfY9oJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md7', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md7" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:IkNFrwLfY9oJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6208388" class=yC12>Text extraction from digital English comic image using two blobs extraction method</a></h3><div class="gs_a">M Sundaresan, S Ranjini - Pattern Recognition, Informatics and  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Text extraction from image is one of the complicated areas in digital image <br>processing. It is a complex process to detect and recognize the text from comic image due to <br>their various size, gray scale values, complex backgrounds and different styles of font. <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:hHKZHlbS74wJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'hHKZHlbS74wJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Toponym Recognition in Scanned Color Topographic Maps</h3><div class="gs_a">JPA Pereira, JCGP Guitton - 2006</div><div class="gs_fl"><a href="/scholar?q=related:oF7wKsk8usMJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14103652017770618528&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'oF7wKsk8usMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5305624" class=yC13>A Character Extraction and Recognition Method for Line Drawings</a></h3><div class="gs_a">F Su, S Cai - Image and Signal Processing, 2009. CISP&#39;09. 2nd  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Character segmentation and recognition are two difficult key steps in extracting <br>literal information from images. This paper proposes a method for effective segmentation <br>and recognition of characters in complicated graphical contexts of line drawings. Text <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10192040111920805582&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:znaSZ3tmcY0J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'znaSZ3tmcY0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6108921" class=yC14>Suppression of non-text components in handwritten document images</a></h3><div class="gs_a"><a href="/citations?user=bDj0BUEAAAAJ&amp;hl=en&amp;oi=sra">R Sarkar</a>, S Moulik, N Das, <a href="/citations?user=IfMtyuYAAAAJ&amp;hl=en&amp;oi=sra">S Basu</a>&hellip; - Image Information  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Document layout analysis is a pre-processing step to convert handwritten/printed <br>documents into electronic form through Optical Character Recognition (OCR) system. <br>Handwritten documents are usually unstructured ie they do not have a specific layout and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:9YGiasWMYYcJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'9YGiasWMYYcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=1021&amp;context=archengdiss" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unl.edu</span><span class="gs_ggsS">unl.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://digitalcommons.unl.edu/archengdiss/21/" class=yC15>An Innovative Solution Set Of Algorithm For Converting Architectural Drawings To Vector-based Computer Graphics</a></h3><div class="gs_a">Y Peng - 2012 - digitalcommons.unl.edu</div><div class="gs_rs">Abstract Appraisal Floor Plan Sketch (AFPS) as a simplified architectural floor plan shows <br>the bird&#39;s eye view of a building&#39;s spatial arrangement. An efficient automated vectorization <br>system of AFPS not only fulfills AFPS&#39;s preservation and dissemination purposes but also <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:cnj6nADz_cQJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'cnj6nADz_cQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6195392" class=yC17>Extraction of Text Touching Graphics Using SURF</a></h3><div class="gs_a">S Ahmed, <a href="/citations?user=n1Y4zq4AAAAJ&amp;hl=en&amp;oi=sra">M Liwicki</a>, A Dengel - Document Analysis Systems ( &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper we propose a novel part-based method for the extraction of text <br>touching graphic components. The Speeded Up Robust Features (SURF) are used to <br>localize the text components and distinguish them from graphics. We introduce several <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17623177093660500664&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:uGJv8TEakvQJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17623177093660500664&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'uGJv8TEakvQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://wing.comp.nus.edu.sg/publications/theses/feiWangThesis.pdf" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://wing.comp.nus.edu.sg/publications/theses/feiWangThesis.pdf" class=yC18>Synthetic Image Categorization</a></h3><div class="gs_a">W Fei - 2006 - wing.comp.nus.edu.sg</div><div class="gs_rs">Abstract We introduce NPIC, an image classification system that focuses on synthetic (eg, <br>non-photographic) images. We use class-specific keywords in an image search engine to <br>create a noisily labeled training corpus of images for each class. NPIC then extracts both <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:VRtZ96Z6rCUJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2714679532930538325&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'VRtZ96Z6rCUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md14', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md14" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:VRtZ96Z6rCUJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://thesis.lib.ncu.edu.tw/ETD-db/ETD-search-c/view_etd?URN=965202069" class=yC1B><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from ncu.edu.tw</span><span class="gs_ggsS">ncu.edu.tw <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[HTML]</span><span class="gs_ct2">[HTML]</span></span> <a href="http://thesis.lib.ncu.edu.tw/ETD-db/ETD-search-c/view_etd?URN=965202069" class=yC1A>Application of An Improvement Empirical Mode Decomposition Method to Eliminate Unwanted Illumination Effects in Document Images</a></h3><div class="gs_a">CL Chen - 2009 - thesis.lib.ncu.edu.tw</div><div class="gs_rs">æè¦(ä¸­) æ¬ç¯è«æéå°å³çµ±çç¶é©æ¨¡æåè§£æ³(Empirical Mode Decomposition, EMD) <br>æåºä¸åæ¹è¯çæ¹æ³. ä¸åæ¼å³çµ±çç¶é©æ¨¡æåè§£æ³, æ¬ç ç©¶ææåºçæ¹æ³å¯ç¯çå¤§éçè¨ç®<br>æé, å°å¶æç¨å¨åå½±ä¸åçå½±åå¼·åæ, å¹¾ä¹å¯éå°å³çµ±çç¶é©æ¨¡æåè§£æ³æè½éå°çææ.</div><div class="gs_fl"><a href="/scholar?q=related:Ob2gT_J8k10J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Ob2gT_J8k10J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md15', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md15" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Ob2gT_J8k10J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://cybertesis.uni.edu.pe/uni/2007/ayala_cg/pdf/ayala_cg.pdf" class=yC1D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uni.edu.pe</span><span class="gs_ggsS">uni.edu.pe <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://cybertesis.uni.edu.pe/uni/2007/ayala_cg/pdf/ayala_cg.pdf" class=yC1C>UNIVERSIDAD NACIONAL DE INGENIERÃA</a></h3><div class="gs_a">RÃDEC DE PLACAS, ETDEP DE AUTOMÃVILES&hellip; - cybertesis.uni.edu.pe</div><div class="gs_rs">SUMARIO El presente trabajo propone el desarrollo de un sistema reconocedor de <br>caracteres de placas de automÃ³viles a partir de una imagen fija que puede provenir de una <br>cÃ¡mara fotogrÃ¡fica o de video. El esquema de trabajo estÃ¡ estructurado por etapas, por <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:V9TZWoK4zWMJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'V9TZWoK4zWMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
