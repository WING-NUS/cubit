Total results = 21
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="https://www1.comp.nus.edu.sg/~wangye/papers/1.Audio_and_Music_Analysis_and_Retrieval/2009_Comprehensive_Query-Dependent_Fusion_using_Regression-on-Folksonomies-A_Case_Study_of_Multimodal_Music_Search.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1631303" class=yC0>Comprehensive query-dependent fusion using regression-on-folksonomies: a case study of multimodal music search</a></h3><div class="gs_a">B Zhang, Q Xiang, H Lu, <a href="/citations?user=d3h-zScAAAAJ&amp;hl=en&amp;oi=sra">J Shen</a>, Y Wang - Proceedings of the 17th ACM  &hellip;, 2009 - dl.acm.org</div><div class="gs_rs">Abstract The combination of heterogeneous knowledge sources has been widely regarded <br>as an effective approach to boost retrieval accuracy in many information retrieval domains. <br>While various technologies have been recently developed for information retrieval, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9683550243293838679&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21">Cited by 11</a> <a href="/scholar?q=related:Vz0tAKThYoYJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9683550243293838679&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'Vz0tAKThYoYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1993038" class=yC2>Exploring the music similarity space on the web</a></h3><div class="gs_a"><a href="/citations?user=TQR8qIEAAAAJ&amp;hl=en&amp;oi=sra">M Schedl</a>, T Pohle, <a href="/citations?user=MtyaO2cAAAAJ&amp;hl=en&amp;oi=sra">P Knees</a>, <a href="/citations?user=dyGS5YYAAAAJ&amp;hl=en&amp;oi=sra">G Widmer</a> - ACM Transactions on  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract This article comprehensively addresses the problem of similarity measurement <br>between music artists via text-based features extracted from Web pages. To this end, we <br>present a thorough evaluation of different term-weighting strategies, normalization <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13881054233771343108&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21">Cited by 11</a> <a href="/scholar?q=related:BH3f10dpo8AJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13881054233771343108&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'BH3f10dpo8AJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www.comp.nus.edu.sg/~wangye/papers/1.Audio_and_Music_Analysis_and_Retrieval/2010_Large-scale_Music_Tag_Recommendation_with_Explicit_Multiple_Attributes.pdf" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1874006" class=yC3>Large-scale music tag recommendation with explicit multiple attributes</a></h3><div class="gs_a">Z Zhao, <a href="/citations?user=zGrcW00AAAAJ&amp;hl=en&amp;oi=sra">X Wang</a>, Q Xiang, AM Sarroff, <a href="/citations?user=TF8WdBMAAAAJ&amp;hl=en&amp;oi=sra">Z Li</a>&hellip; - Proceedings of the  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract Social tagging can provide rich semantic information for large-scale retrieval in <br>music discovery. Such collaborative intelligence, however, also generates a high degree of <br>tags unhelpful to discovery, some of which obfuscate critical information. Towards <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2245211175045706678&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21">Cited by 8</a> <a href="/scholar?q=related:tjNWBquXKB8J:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2245211175045706678&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'tjNWBquXKB8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://www.biomedcentral.com/1471-2105/11/423/" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from biomedcentral.com</span><span class="gs_ggsS">biomedcentral.com <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[HTML]</span><span class="gs_ct2">[HTML]</span></span> <a href="http://www.biomedcentral.com/1471-2105/11/423/" class=yC5>Ranked retrieval of Computational Biology models</a></h3><div class="gs_a">R Henkel, <a href="/citations?user=CKGJDlYAAAAJ&amp;hl=en&amp;oi=sra">L Endler</a>, A Peters, <a href="/citations?user=8zY7k_cAAAAJ&amp;hl=en&amp;oi=sra">N Le NovÃ¨re</a>&hellip; - BMC  &hellip;, 2010 - biomedcentral.com</div><div class="gs_rs">Background The study of biological systems demands computational support. If targeting a <br>biological problem, the reuse of existing computational models can save time and effort. <br>Deciding for potentially suitable models, however, becomes more challenging with the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7722153844040451823&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21">Cited by 9</a> <a href="/scholar?q=related:78by5gGaKmsJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7722153844040451823&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'78by5gGaKmsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md3', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md3" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:78by5gGaKmsJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://research.microsoft.com/en-us/um/people/xshua/publications/pdf/2010_sigir_musictagging.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from microsoft.com</span><span class="gs_ggsS">microsoft.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1835555" class=yC7>Effective music tagging through advanced statistical modeling</a></h3><div class="gs_a"><a href="/citations?user=d3h-zScAAAAJ&amp;hl=en&amp;oi=sra">J Shen</a>, <a href="/citations?user=rHagaaIAAAAJ&amp;hl=en&amp;oi=sra">W Meng</a>, S Yan, HH Pang, <a href="/citations?user=6G-l4o0AAAAJ&amp;hl=en&amp;oi=sra">X Hua</a> - Proceeding of the 33rd  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract Music information retrieval (MIR) holds great promise as a technology for managing <br>large music archives. One of the key components of MIR that has been actively researched <br>into is music tagging. While significant progress has been achieved, most of the existing <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16835438204165849581&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21">Cited by 5</a> <a href="/scholar?q=related:7YFYRdl9o-kJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16835438204165849581&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'7YFYRdl9o-kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="https://www1.comp.nus.edu.sg/~wangye/papers/1.Audio_and_Music_Analysis_and_Retrieval/2009_CompositeMap-A_Novel_Music_Similarity_Measure_for_Personalized_Multimodal_Music_Search.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1631474" class=yC9>CompositeMap: a novel music similarity measure for personalized multimodal music search</a></h3><div class="gs_a">B Zhang, Q Xiang, Y Wang, <a href="/citations?user=d3h-zScAAAAJ&amp;hl=en&amp;oi=sra">J Shen</a> - Proceedings of the 17th ACM  &hellip;, 2009 - dl.acm.org</div><div class="gs_rs">Abstract How to measure and model the similarity between different music items is one of <br>the most fundamental yet challenging research problems in music information retrieval. This <br>paper demonstrates a novel multimodal and adaptive music similarity measure (<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11157778316519248774&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21">Cited by 4</a> <a href="/scholar?q=related:hpOvLkNk2JoJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11157778316519248774&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'hpOvLkNk2JoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://posgrado.escom.ipn.mx/biblioteca/Personalized%20video%20similarity%20measure.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ipn.mx</span><span class="gs_ggsS">ipn.mx <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/K6112U27W8235M32.pdf" class=yCB>Personalized video similarity measure</a></h3><div class="gs_a"><a href="/citations?user=d3h-zScAAAAJ&amp;hl=en&amp;oi=sra">J Shen</a>, Z Cheng - Multimedia systems, 2011 - Springer</div><div class="gs_rs">Abstract As an effective technique to manage and explore large scale of video collections, <br>personalized video search has received great attentions in recent years. One of the key <br>problems in the related technique development is how to design and evaluate the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11102164182707503178&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21">Cited by 4</a> <a href="/scholar?q=related:SoBYnIDPEpoJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11102164182707503178&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'SoBYnIDPEpoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://www.cp.jku.at/research/papers/Schedl_Knees_amr_2011.pdf" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from jku.at</span><span class="gs_ggsS">jku.at <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.cp.jku.at/research/papers/Schedl_Knees_amr_2011.pdf" class=yCD>Personalization in Multimodal Music Retrieval</a></h3><div class="gs_a"><a href="/citations?user=TQR8qIEAAAAJ&amp;hl=en&amp;oi=sra">M Schedl</a>, <a href="/citations?user=MtyaO2cAAAAJ&amp;hl=en&amp;oi=sra">P Knees</a> - Proc. AMR, 2011 - cp.jku.at</div><div class="gs_rs">Abstract. This position paper provides an overview of current research endeavors and <br>existing solutions in multimodal music retrieval, where the term âmultimodalâ relates to two <br>aspects. The first one is taking into account the music context of a piece of music or an <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=459546190501085749&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21">Cited by 2</a> <a href="/scholar?q=related:NYKzUtOiYAYJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=459546190501085749&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'NYKzUtOiYAYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md7', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md7" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:NYKzUtOiYAYJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://drops.dagstuhl.de/opus/volltexte/2012/3470/pdf/9.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from dagstuhl.de</span><span class="gs_ggsS">dagstuhl.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://drops.dagstuhl.de/opus/volltexte/2012/3470/" class=yCF>User-Aware Music Retrieval</a></h3><div class="gs_a"><a href="/citations?user=TQR8qIEAAAAJ&amp;hl=en&amp;oi=sra">M Schedl</a>, S Stober, <a href="/citations?user=09PV4lsAAAAJ&amp;hl=en&amp;oi=sra">E GÃ³mez</a>, N Orio&hellip; - Multimodal Music  &hellip;, 2012 - drops.dagstuhl.de</div><div class="gs_rs">Abstract Personalized and user-aware systems for retrieving multimedia items are becoming <br>increasingly important as the amount of available multimedia data has been spiraling. A <br>personalized system is one that incorporates information about the user into its data <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2546703736898816094&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21">Cited by 1</a> <a href="/scholar?q=related:XogDQo61VyMJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2546703736898816094&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'XogDQo61VyMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://www.comp.nus.edu.sg/~wangye/papers/1.Audio_and_Music_Analysis_and_Retrieval/2011_Document_Dependent_Fusion_in_Multimodal_Music_Retrieval.pdf" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2071949" class=yC11>Document dependent fusion in multimodal music retrieval</a></h3><div class="gs_a"><a href="/citations?user=TF8WdBMAAAAJ&amp;hl=en&amp;oi=sra">Z Li</a>, B Zhang, Y Wang - Proceedings of the 19th ACM international  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we propose a novel multimodal fusion framework, document <br>dependent fusion (DDF), which derives the optimal combination strategy for each individual <br>document in the fusion process. For each document, we derive a document weight vector <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:JyU9BhZI5j4J:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4532389334426133799&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'JyU9BhZI5j4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6103017" class=yC13>An Interactive Music Learning System in Ensemble Performance Class</a></h3><div class="gs_a">K Takano, S Sasaki - Broadband and Wireless Computing,  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract It is a significant research area in computer-assisted music learning to develop <br>interactive learning materials to cultivate learner&#39;s performing abilities of musical <br>instruments. Especially in the ensemble lesson at school, it is pointed out that not only the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:z3l8C9DS4_sJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18150582714220968399&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'z3l8C9DS4_sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5580673" class=yC14>Dictionary based inverted index for music information retrieval</a></h3><div class="gs_a">XH Yang, QC Chen, XL Wang - Machine Learning and  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract With the rapid progress in data storage and communication technology, there has <br>been an explosive growth of music information. As the traditional metadata-based search <br>engine can not provide natural and intuitive way to retrieve music, content-based music <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:93d5DN3i9sMJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'93d5DN3i9sMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://137.132.14.55/bitstream/handle/10635/20949/ZhangBJ.pdf?sequence=1" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.14.55</span><span class="gs_ggsS">137.132.14.55 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://137.132.14.55/handle/10635/20949" class=yC15>Adaptive multimodal fusion based similarity measures in music information retrieval</a></h3><div class="gs_a">Z BINGJUN - 2010 - 137.132.14.55</div><div class="gs_rs">In the field of music information retrieval (MIR), one fundamental research problem is the <br>measuring of the similarity between music documents. Based on a viable similarity measure, <br>MIR systems can be made more effective to help users retrieve relevant music information. <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:9FjpHoxTlRIJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1339068325491726580&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'9FjpHoxTlRIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://137.132.14.55/bitstream/handle/10635/19070/ZhaoWEI.pdf?sequence=1" class=yC18><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.14.55</span><span class="gs_ggsS">137.132.14.55 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://137.132.14.55/handle/10635/19070" class=yC17>Utilizing EEG Signal in Music Information Retrieval</a></h3><div class="gs_a">Z WEI - 2010 - 137.132.14.55</div><div class="gs_rs">Despite significant progresses in the field of music information retrieval (MIR), grand <br>challenges such as the intention gap and the semantic gap still exist. Inspired by the current <br>successes in the Brain Computer Interface (BCI), how to utilize electroencephalography (<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:646kKzTsLiAJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2319050566957043435&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'646kKzTsLiAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://hub.hku.hk/bitstream/10722/131820/1/FullText.pdf?accept=1" class=yC1A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hku.hk</span><span class="gs_ggsS">hku.hk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> <a href="http://hub.hku.hk/handle/10722/131820" class=yC19>Third-order tensor decomposition for search in social</a></h3><div class="gs_a">B Biï¼ é­å½¬ - SIAM Review, 2009 - hub.hku.hk</div><div class="gs_rs">1.1 Background We are witnessing the recent proliferation of the World Wide Web. As online <br>popularity increased, an increasing number of electronic documents started appearing on <br>the web. Google announced that its crawler found 1 trillion unique URLs and that the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:7lPTPNlJ5_4J:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'7lPTPNlJ5_4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://ismir2012.ismir.net/event/papers/385-ismir-2012.pdf" class=yC1C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ismir.net</span><span class="gs_ggsS">ismir.net <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://ismir2012.ismir.net/event/papers/385-ismir-2012.pdf" class=yC1B>PUTTING THE USER IN THE CENTER OF MUSIC INFORMATION RETRIEVAL</a></h3><div class="gs_a"><a href="/citations?user=TQR8qIEAAAAJ&amp;hl=en&amp;oi=sra">M Schedl</a>, <a href="/citations?user=QOqXxssAAAAJ&amp;hl=en&amp;oi=sra">A Flexer</a> - ismir2012.ismir.net</div><div class="gs_rs">ABSTRACT Personalized and context-aware music retrieval and recommendation <br>algorithms ideally provide music that perfectly fits the individual listener in each imaginable <br>situation and for each of her information or entertainment need. Although first steps <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3578351814707982434&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21">Cited by 1</a> <a href="/scholar?q=related:YjALPQTcqDEJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3578351814707982434&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'YjALPQTcqDEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md15', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md15" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:YjALPQTcqDEJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/J816R27044174R55.pdf" class=yC1D>Effective bitmap indexing for non-metric similarities</a></h3><div class="gs_a">C Jensen, E Mungure, <a href="/citations?user=XGzPuKEAAAAJ&amp;hl=en&amp;oi=sra">T Pedersen</a>, K SÃ¸rensen&hellip; - Database and Expert  &hellip;, 2010 - Springer</div><div class="gs_rs">An increasing number of applications include recommender systems that have to perform <br>search in a non-metric similarity space, thus creating an increasing demand for efficient yet <br>flexible indexing techniques to facilitate similarity search. This demand is further fueled by <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2233744829008427956&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21">Cited by 1</a> <a href="/scholar?q=related:tLvpSxbb_x4J:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2233744829008427956&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'tLvpSxbb_x4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2043705" class=yC1E>Probabilistic indexing of media sequences</a></h3><div class="gs_a"><a href="/citations?user=d3h-zScAAAAJ&amp;hl=en&amp;oi=sra">J Shen</a>, <a href="/citations?user=rHagaaIAAAAJ&amp;hl=en&amp;oi=sra">M Wang</a>, <a href="/citations?user=DNuiPHwAAAAJ&amp;hl=en&amp;oi=sra">S Yan</a>, <a href="/citations?user=61b6eYkAAAAJ&amp;hl=en&amp;oi=sra">Q Tian</a> - Proceedings of the Third International  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract Accurate and fast nearest neighbor search is often required in applications <br>involving media sequences, such as duplicate detection in video collections, music retrieval <br>in digital libraries, and event discovery in streaming documents. Among various related <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:d05zk1V1wT0J:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4449966917225238135&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'d05zk1V1wT0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S016516841200326X" class=yC1F>A query by humming system based on locality sensitive hashing indexes</a></h3><div class="gs_a">Q Wang, Z Guo, J Guo, G Liu - Signal Processing, 2012 - Elsevier</div><div class="gs_rs">Abstract Recently developed query by humming (QBH) system, which uses the humming <br>clip to find the wanted song, has become a hot topic in the area of music retrieval. At present, <br>the challenging issue is how to quickly and accurately find the song in a large scale <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:hWsu3YHBNz0J:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'hWsu3YHBNz0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2348346" class=yC20>Modeling concept dynamics for large scale music search</a></h3><div class="gs_a"><a href="/citations?user=d3h-zScAAAAJ&amp;hl=en&amp;oi=sra">J Shen</a>, HH Pang, <a href="/citations?user=rHagaaIAAAAJ&amp;hl=en&amp;oi=sra">M Wang</a>, <a href="/citations?user=DNuiPHwAAAAJ&amp;hl=en&amp;oi=sra">S Yan</a> - &hellip;  of the 35th international ACM SIGIR  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract Continuing advances in data storage and communication technologies have led to <br>an explosive growth in digital music collections. To cope with their increasing scale, we <br>need effective Music Information Retrieval (MIR) capabilities like tagging, concept search <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:xMPb53iszVQJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'xMPb53iszVQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.tandfonline.com/doi/abs/10.1080/09298215.2012.749919" class=yC21>Algorithmic Prediction of Inter-song Similarity in Western Popular Music</a></h3><div class="gs_a">A Novello, S van de Par, MMF McKinney&hellip; - Journal of New Music  &hellip;, 2013 - Taylor &amp; Francis</div><div class="gs_rs">Abstract We investigate a method for automatic extraction of inter-song similarity for songs <br>selected from several genres of Western popular music. The specific purpose of this <br>approach is to evaluate the predictive power of different feature extraction sets based on <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'LhCy8ME4uaQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
