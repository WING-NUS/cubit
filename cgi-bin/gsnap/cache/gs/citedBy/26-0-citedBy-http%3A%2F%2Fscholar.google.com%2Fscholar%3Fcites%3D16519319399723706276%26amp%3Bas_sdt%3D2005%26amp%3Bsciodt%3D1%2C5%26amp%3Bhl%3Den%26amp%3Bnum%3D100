Total results = 26
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://brutal.googlecode.com/svn/trunk/A%20Formal%20Study%20of%20Shot%20Boundary%20Detection.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from googlecode.com</span><span class="gs_ggsS">googlecode.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4079667" class=yC0>A formal study of shot boundary detection</a></h3><div class="gs_a">J Yuan, H Wang, L Xiao, W Zheng, J Li&hellip; - Circuits and Systems &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper conducts a formal study of the shot boundary detection problem. First, a <br>general formal framework of shot boundary detection techniques is proposed. Three critical <br>techniques, ie, the representation of visual content, the construction of continuity signal <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9807406730883968179&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 163</a> <a href="/scholar?q=related:sywdunXoGogJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/0D/39/RN203487883.html?source=googlescholar" class="gs_nph" class=yC2>BL Direct</a> <a href="/scholar?cluster=9807406730883968179&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'sywdunXoGogJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1035721" class=yC3>The segmentation of news video into story units</a></h3><div class="gs_a">L Chaisorn, TS Chua, CH Lee - Multimedia and Expo, 2002.  &hellip;, 2002 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The segmentation of news video into single-story semantic units is a challenging <br>problem. This research proposes a two-level, multi-modal framework to tackle this problem. <br>The video is analyzed at the shot and story unit (or scene) levels using a variety of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16492627510664671647&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 51</a> <a href="/scholar?q=related:n7EA2laV4eQJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16492627510664671647&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'n7EA2laV4eQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/JWWW03-lekha.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/VL11P38010523613.pdf" class=yC4>A multi-modal approach to story segmentation for news video</a></h3><div class="gs_a">L Chaisorn, TS Chua, CH Lee - World Wide Web, 2003 - Springer</div><div class="gs_rs">This research proposes a two-level, multi-modal framework to perform the segmentation and <br>classification of news video into single-story semantic units. The video is analyzed at the <br>shot and story unit (or scene) levels using a variety of features and techniques. At the shot <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6108549097289369038&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 35</a> <a href="/scholar?q=related:zkX3HArtxVQJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/5E/44/RN130983315.html?source=googlescholar" class="gs_nph" class=yC6>BL Direct</a> <a href="/scholar?cluster=6108549097289369038&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'zkX3HArtxVQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://pdf.aminer.org/000/893/979/video_modeling_using_strata_based_annotation.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aminer.org</span><span class="gs_ggsS">aminer.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=839313" class=yC7>Video modeling using strata-based annotation</a></h3><div class="gs_a">MS Kankanhalli, TS Chua - Multimedia, IEEE, 2000 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Our project on digital video modeling aims to achieve efficient browsing and <br>retrieval. Video is not merely a huge collection of still images, it is a complex temporal <br>medium capturing high-level semantic ideas. For almost a decade researchers have <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16019540471568062465&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 32</a> <a href="/scholar?q=related:AdjOCC_XUN4J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/03/19/RN077309202.html?source=googlescholar" class="gs_nph" class=yC9>BL Direct</a> <a href="/scholar?cluster=16019540471568062465&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'AdjOCC_XUN4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://www.mirlab.org/conference_papers/International_Conference/ACM%202005/docs/mir121.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mirlab.org</span><span class="gs_ggsS">mirlab.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1101847" class=yCA>A new general framework for shot boundary detection and key-frame extraction</a></h3><div class="gs_a">H Feng, W Fang, S Liu, Y Fang - Proceedings of the 7th ACM SIGMM  &hellip;, 2005 - dl.acm.org</div><div class="gs_rs">Abstract Video shot boundary detection is an important step in many video applications. <br>Since the rapid development of video editing technology, especially, the extensive use of <br>sub-window in news video, the original method of video segmentation cannot efficiently <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=748634592546759526&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 26</a> <a href="/scholar?q=related:ZqNRCzKvYwoJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=748634592546759526&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'ZqNRCzKvYwoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://lms.comp.nus.edu.sg/papers/media/2002/MTAP02~1.PDF" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/m2911q0732955g43.pdf" class=yCC>Stratification approach to modeling video</a></h3><div class="gs_a">TS Chua, L Chen, J Wang - Multimedia Tools and Applications, 2002 - Springer</div><div class="gs_rs">The explosive growth of audiovisual information in the last few years has made the <br>development of advanced video modeling and management tools an urgent task. In this <br>research, we investigate the use of stratification approach to model the contextual <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13358721049472749966&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 23</a> <a href="/scholar?q=related:jlFbVwS2Y7kJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/3A/61/RN108177950.html?source=googlescholar" class="gs_nph" class=yCE>BL Direct</a> <a href="/scholar?cluster=13358721049472749966&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'jlFbVwS2Y7kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.199.6634&amp;rep=rep1&amp;type=pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Pp3Xg-xg2CUC&amp;oi=fnd&amp;pg=PA95&amp;ots=PPpTE29vfm&amp;sig=gFBiFQVZGtNHSUq4A_Mbam6mwyo" class=yCF>The segmentation and classification of story boundaries in news video</a></h3><div class="gs_a">L Chaisorn, TS Chua - Proceedings of the IFIP TC2/WG2, 2002 - books.google.com</div><div class="gs_rs">Abstract The segmentation and classification of news video into single-story semantic units <br>is a challenging problem. This research proposes a two-level, multi-modal framework to <br>tackle this problem. The video is analyzed at the shot and story unit (or scene) levels using <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14815142300848227144&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 21</a> <a href="/scholar?q=related:SAPsum31mc0J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14815142300848227144&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'SAPsum31mc0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://trec.nist.gov/pubs/trec10/papers/clips-imag-bin.pdf" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nist.gov</span><span class="gs_ggsS">nist.gov <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://trec.nist.gov/pubs/trec10/papers/clips-imag-bin.pdf" class=yC11>TREC-10 shot boundary detection task: CLIPS system description and evaluation</a></h3><div class="gs_a">GM QuÃ©not - Proceedings of TREC-2001, Gaithersburg, Maryland, 2001 - trec.nist.gov</div><div class="gs_rs">Abstract This paper presents the system used by CLIPS-IMAG to perform the Shot Boundary <br>Detection (SBD) task of the Video track of the TREC-10 conference. Cut detection is <br>performed by computing image difference after motion compensation. Dissolve detection <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5580595570752915567&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 20</a> <a href="/scholar?q=related:b4jYtRpCck0J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/58/42/RN119431980.html?source=googlescholar" class="gs_nph" class=yC13>BL Direct</a> <a href="/scholar?cluster=5580595570752915567&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'b4jYtRpCck0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md7', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md7" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:b4jYtRpCck0J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.24.7345&amp;rep=rep1&amp;type=pdf" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.24.7345&amp;rep=rep1&amp;type=pdf" class=yC14>A General Frame Work for Video Segmentation Based on Temporal Multi-resolution Analysis</a></h3><div class="gs_a">TS Chua, M Kankanhalli, Y Lin - Int&#39;l Workshop on Advanced Image  &hellip;, 2000 - Citeseer</div><div class="gs_rs">ABSTRACT Video segmentation is an important step in many video processing applications. <br>By observing that the video shot boundary is a multi-(temporal)-resolution edge <br>phenomenon in the feature space, we develop a general framework to handle all types of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6319097897849522820&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 17</a> <a href="/scholar?q=related:hAo93g7ysVcJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6319097897849522820&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'hAo93g7ysVcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md8', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md8" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:hAo93g7ysVcJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1614812" class=yC16>A new general framework for shot boundary detection based on SVM</a></h3><div class="gs_a">H Feng, W Fang, S Liu, Y Fang - Neural Networks and Brain,  &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Video shot boundary detection is an important step in many video applications. <br>Since the rapid development of video editing technology, especially, the extensive use of <br>subwindow in news video, the original method of video segmentation cannot efficiently <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12810456654246656691&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 14</a> <a href="/scholar?q=related:szrpTnTix7EJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'szrpTnTix7EJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://db.csail.mit.edu/pubs/ArrayVersioning.pdf" class=yC18><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6228152" class=yC17>Efficient versioning for scientific array databases</a></h3><div class="gs_a">A Seering, <a href="/citations?user=NpccCXwAAAAJ&amp;hl=en&amp;oi=sra">P Cudre-Mauroux</a>, <a href="/citations?user=a1ngrCIAAAAJ&amp;hl=en&amp;oi=sra">S Madden</a>&hellip; - &hellip;  (ICDE), 2012 IEEE  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we describe a versioned database storage manager we are <br>developing for the SciDB scientific database. The system is designed to efficiently store and <br>retrieve array-oriented data, exposing a&quot; no-overwrite&quot; storage model in which each <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7523738674112265396&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 4</a> <a href="/scholar?q=related:tHxULXawaWgJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7523738674112265396&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'tHxULXawaWgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4297119" class=yC19>Research on video segmentation via active learning</a></h3><div class="gs_a">W Tan, S Teng, W Zhang - Image and Graphics, 2007. ICIG  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We propose a method to video segmentation via active learning. Shot segmentation <br>is an essential first step to video segmentation. The color histogram-based shot boundary <br>detection algorithm is one of the most reliable variants of histogram-based detection <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13588511729189889707&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 2</a> <a href="/scholar?q=related:q6aXNGwXlLwJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13588511729189889707&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'q6aXNGwXlLwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Extracting Story Units in News Video</h3><div class="gs_a">L Chaisorn, TS Chua, CH Lee - Proceedings of IWAIT, 2003</div><div class="gs_fl"><a href="/scholar?cites=1474656682461943625&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 2</a> <a href="/scholar?q=related:SdfMi3AIdxQJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1474656682461943625&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'SdfMi3AIdxQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://trec.nist.gov/pubs/trec11/papers/nus.video.pdf" class=yC1B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nist.gov</span><span class="gs_ggsS">nist.gov <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://trec.nist.gov/pubs/trec11/papers/nus.video.pdf" class=yC1A>Temporal multi-resolution framework for shot boundary detection and keyframe extraction</a></h3><div class="gs_a">A Chandrashekhara, HM Feng, TS Chua - TREC (Text REtrieval  &hellip;, 2002 - trec.nist.gov</div><div class="gs_rs">Abstract Video shot boundary detection and keyframe extraction is an important step in <br>many video-processing applications. We observe that video shot boundary is a multi-<br>resolution edge phenomenon in the feature space. In this experiment, we expanded our <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10224002469184902575&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 2</a> <a href="/scholar?q=related:r5V7nhP04o0J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/31/5F/RN136216649.html?source=googlescholar" class="gs_nph" class=yC1C>BL Direct</a> <a href="/scholar?cluster=10224002469184902575&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 17 versions</a> <a onclick="return gs_ocit(event,'r5V7nhP04o0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md13', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md13" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:r5V7nhP04o0J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5647081" class=yC1D>Shot boundary detection and TV commercial retrieval</a></h3><div class="gs_a">L Meng, F Yuan, G Chen&hellip; - Image and Signal  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Shot boundary detection is a pre-requisite process for content-based video <br>indexing and retrieval. A robust algorithm is proposed for shot boundary detection and <br>adopted into the TV commercial retrieval system in this paper. First of all, the HSV color <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:MAE9Ca8ONFwJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'MAE9Ca8ONFwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1614751" class=yC1E>Story Segmentation in News video</a></h3><div class="gs_a">H Feng, X Zhai, J Fan, Y Fang - Neural Networks and Brain,  &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents a two-level framework for news video segmentation. Our <br>system is established based upon a similar framework as in [Chaisorn et al. 2002]. We <br>extended the original framework by adding rule-based pre-segmentation module and new <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:9XZLM-aFhFMJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'9XZLM-aFhFMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/icme02-lekha.pdf" class=yC20><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/icme02-lekha.pdf" class=yC1F>THE SEGMENTATION OF NEWS VIDEO INTO STORY UNITS</a></h3><div class="gs_a">LCTS Chua - 137.132.145.151</div><div class="gs_rs">The segmentation of news video into single-story semantic units is a challenging problem. <br>This research proposes a twolevel, multi-modal framework to tackle this problem. The video <br>is analyzed at the shot and story unit (or scene) levels using a variety of features and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:I0iaR7YY_H8J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'I0iaR7YY_H8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=_OUwpaTN40AC&amp;oi=fnd&amp;pg=PA283&amp;ots=reIFY1yF4K&amp;sig=bnNd58MLPyZ1b_xusfssMb7h_ok" class=yC21>An Overview of Video Information Retrieval Techniques</a></h3><div class="gs_a">S Deb, Y Zhang - Video Data Management And Information  &hellip;, 2004 - books.google.com</div><div class="gs_rs">ABSTRACT Video information retrieval is currently a very important topic of research in the <br>area of multimedia databases. Plenty of research work has been undertaken in the past <br>decade to design efficient video information retrieval techniques from the video or <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:TaK2V1TThL0J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13656272329296486989&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'TaK2V1TThL0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Keyframe Extraction</h3><div class="gs_a">A Chandrashekhara, HM Feng, TS Chua</div><div class="gs_fl"><a href="/scholar?q=related:xcsBed-gMBoJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1887185125536549829&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'xcsBed-gMBoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="http://137.132.14.55/bitstream/handle/10635/14402/thesis.pdf?sequence=1" class=yC23><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.14.55</span><span class="gs_ggsS">137.132.14.55 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://137.132.14.55/handle/10635/14402" class=yC22>Event detection in soccer video based on audio/visual keywords</a></h3><div class="gs_a">K YULIN - 2004 - 137.132.14.55</div><div class="gs_rs">In this thesis, we propose a multi-modal two-level event detection framework and <br>demonstrate it on soccer videos. We use a mid-level representation called Audio and Visual <br>Keyword (AVK) that can be learned and detected in video segments. AVKs are intended to <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:8u8rejdXeoUJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9618095849987633138&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'8u8rejdXeoUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ukpmc.ac.uk/abstract/CIT/606668" class=yC24>TREC-10 Shot Boundary Detection Task</a></h3><div class="gs_a">GM Quenot - ukpmc.ac.uk</div><div class="gs_rs">This paper presents the system used by CLIPS-IMAG to perform the Shot Boundary <br>Detection (SBD) task of the Video track of the TREC-10 conference. Cut detection is <br>performedby computing image dierence after motion compensation. Dissolve detection is <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:cXUOpuBRxB8J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2289044535911544177&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'cXUOpuBRxB8J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md20', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md20" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:cXUOpuBRxB8J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="http://mrim.imag.fr/georges.quenot/articles/cbmi99a.pdf" class=yC26><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from imag.fr</span><span class="gs_ggsS">imag.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://mrim.imag.fr/georges.quenot/articles/cbmi99a.pdf" class=yC25>Two Systems for Temporal video Segmentation</a></h3><div class="gs_a">G Qu&#39;enot12, P Mulhem - mrim.imag.fr</div><div class="gs_rs">Abstract. This paper presents two different temporal video segmentation systems and their <br>performance evaluation using a standard test corpus. The first system uses two separate <br>detection subsystems respectively based on color histogram comparison and on rough <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:GMT_wPrPFqYJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11967981735670432792&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'GMT_wPrPFqYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md21', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md21" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:GMT_wPrPFqYJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB22" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW22"><a href="http://biblioweb.u-cergy.fr/theses/07CERG0380.pdf" class=yC28><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from u-cergy.fr</span><span class="gs_ggsS">u-cergy.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://biblioweb.u-cergy.fr/theses/07CERG0380.pdf" class=yC27>ANÃLISE DE CONTEÃDO DE VÃDEO POR MEIO DO APRENDIZADO ATIVO</a></h3><div class="gs_a">GC Chavez - 2007 - biblioweb.u-cergy.fr</div><div class="gs_rs">Video data is becoming increasingly important in many commercial and scientific areas with <br>the advent of applications such as digital broadcasting, interactive-TV, video-on-demand, <br>computer-based training, video-conferencing and multimedia processing tools, and with <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:UnqbzfttuHgJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8698823608519850578&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'UnqbzfttuHgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB23" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW23"><a href="http://lms.comp.nus.edu.sg/papers/media/2002/icme02-lekha.pdf" class=yC2A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://lms.comp.nus.edu.sg/papers/media/2002/icme02-lekha.pdf" class=yC29>THE SEGMENTATION OF NEWS VIDEO INTO STORY UNITS</a></h3><div class="gs_a">LCTSC Chin, H Lee - lms.comp.nus.edu.sg</div><div class="gs_rs">The effective management of the ever-increasing amount of broadcast news video is <br>essential to support a variety of useroriented functions, including the browsing, retrieval and <br>personalization of news video. One effective way to organize video is to segment it into <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:8pSS5jUvhfsJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18123944183970567410&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'8pSS5jUvhfsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB24" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW24"><a href="http://www.scholarbank.nus.edu.sg/bitstream/handle/10635/13136/Thesis_XU_Huaxin_HT016894E.pdf?sequence=1" class=yC2C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.scholarbank.nus.edu.sg/handle/10635/13136" class=yC2B>Integrated analysis of audiovisual signals and external information sources for event detection in team sports video</a></h3><div class="gs_a">H Xu - 2007 - scholarbank.nus.edu.sg</div><div class="gs_rs">Audiovisual signals and external information sources (news reports, live commentaries, Web <br>casts, etc.) are found to have complementary strengths for detecting events in sports video. <br>This thesis reports research on integrated analysis of them, focusing on tackling the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:M-BY-RAX2tkJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15697884812823552051&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'M-BY-RAX2tkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB25" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW25"><a href="http://dspace.mit.edu/bitstream/handle/1721.1/66705/757142733.pdf?sequence=1" class=yC2E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dspace.mit.edu/handle/1721.1/66705" class=yC2D>Efficient storage of versioned matrices</a></h3><div class="gs_a">AB Seering - 2011 - dspace.mit.edu</div><div class="gs_rs">Versioned-matrix storage is increasingly important in scientific applications. Various <br>computer-based scientific research, from astronomy observations to weather predictions to <br>mechanical finite-element analyses, results in the generation of large matrices that must <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:zspS_BAe6h0J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2155568429951797966&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'zspS_BAe6h0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md25', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md25" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:zspS_BAe6h0J:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=1653275814415851492&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
