Total results = 12
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://ippr.csie.ntu.edu.tw/Publication%5C1999C%5CNew%20Calibration-free%20Approach.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntu.edu.tw</span><span class="gs_ggsS">ntu.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=791194" class=yC0>New calibration-free approach for augmented reality based on parameterized cuboid structure</a></h3><div class="gs_a"><a href="/citations?user=WKk6fIQAAAAJ&amp;hl=en&amp;oi=sra">CS Chen</a>, CK Yu, YP Hung - Computer Vision, 1999. The  &hellip;, 1999 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract A new method called PCS (parameterized cuboid structure) is presented for <br>augmented reality. In particular, our method can insert animated virtual objects into a static <br>scene, with geometric consistency, and also allow the user to interactively position and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13276652242721049003&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12">Cited by 58</a> <a href="/scholar?q=related:qwnIPd8kQLgJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13276652242721049003&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 17 versions</a> <a onclick="return gs_ocit(event,'qwnIPd8kQLgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.184.74&amp;rep=rep1&amp;type=pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=854794" class=yC2>A semi-automatic method for resolving occlusion in augmented reality</a></h3><div class="gs_a"><a href="/citations?user=stx-TZwAAAAJ&amp;hl=en&amp;oi=sra">V Lepetit</a>, MO Berger - Computer Vision and Pattern  &hellip;, 2000 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Realistic merging of virtual and real objects requires that the augmented patterns <br>be correctly occluded by foreground objects. In this paper we propose a semi-automatic <br>method for resolving occlusion in augmented reality which makes use of key-views. Once <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6365849815987354108&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12">Cited by 54</a> <a href="/scholar?q=related:_HlpD64KWFgJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/01/03/RN082179951.html?source=googlescholar" class="gs_nph" class=yC4>BL Direct</a> <a href="/scholar?cluster=6365849815987354108&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 17 versions</a> <a onclick="return gs_ocit(event,'_HlpD64KWFgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://infoscience.epfl.ch/record/146942/files/lepetit_isar00.pdf?version=1" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from epfl.ch</span><span class="gs_ggsS">epfl.ch <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=880937" class=yC5>Handling occlusion in augmented reality systems: a semi-automatic method</a></h3><div class="gs_a"><a href="/citations?user=stx-TZwAAAAJ&amp;hl=en&amp;oi=sra">V Lepetit</a>, MO Berger - Augmented Reality, 2000.(ISAR 2000).  &hellip;, 2000 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We present a semi-automatic approach to solve occlusion in AR systems. Once the <br>occluding objects have been segmented by hand in selected views called key-frames, the <br>occluding boundary is computed automatically in the intermediate views. To do that, the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5177199867758256382&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12">Cited by 28</a> <a href="/scholar?q=related:_iDuiNkb2UcJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5177199867758256382&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 21 versions</a> <a onclick="return gs_ocit(event,'_iDuiNkb2UcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://www.crpit.com/confpapers/CRPITV50Pang.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from crpit.com</span><span class="gs_ggsS">crpit.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1151760" class=yC7>A markerless registration method for augmented reality based on affine properties</a></h3><div class="gs_a">Y Pang, ML Yuan, AYC Nee, SK Ong&hellip; - Proceedings of the 7th  &hellip;, 2006 - dl.acm.org</div><div class="gs_rs">Abstract This paper presents a markerless registration approach for Augmented Reality (AR) <br>systems based on the Kanade-Lucas-Tomasi (KLT) natural feature tracker and the affine <br>reconstruction and reprojection techniques. First, the KLT tracker is used to track the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1732889658617372137&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12">Cited by 21</a> <a href="/scholar?q=related:6R3WmPZ1DBgJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1732889658617372137&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'6R3WmPZ1DBgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1640409" class=yC9>Handling occlusions in real-time augmented reality: dealing with movable real and virtual objects</a></h3><div class="gs_a">P Fortin, P Hebert - Computer and Robot Vision, 2006. The 3rd  &hellip;, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Realistic rendering in real-time augmented reality applications leads one to <br>consider physical interactions between real and virtual worlds. One of these interactions is <br>mutual occlusions in the rendered viewpoint. This paper presents two approaches for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11109331380310146580&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12">Cited by 12</a> <a href="/scholar?q=related:FH581wdGLJoJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11109331380310146580&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'FH581wdGLJoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://cvlab-9.epfl.ch/~lepetit/papers/lepetit_ismr01.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from epfl.ch</span><span class="gs_ggsS">epfl.ch <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://cvlab-9.epfl.ch/~lepetit/papers/lepetit_ismr01.pdf" class=yCA>An intuitive tool for outlining objetcs in video sequences: applications to augmented and diminished reality</a></h3><div class="gs_a"><a href="/citations?user=stx-TZwAAAAJ&amp;hl=en&amp;oi=sra">V Lepetit</a>, MO Berger - tC, 2001 - cvlab-9.epfl.ch</div><div class="gs_rs">Abstract In this paper, we present an efficient and easy to use method for outlining objects <br>over a sequence. Applications of this algorithm are presented and special emphasis is made <br>on diminished reality applications. Video sequences of our results can be seen at URL <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11320728639768089518&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12">Cited by 11</a> <a href="/scholar?q=related:rtP307dOG50J:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11320728639768089518&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'rtP307dOG50J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md5', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md5" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:rtP307dOG50J:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://www.mdpi.com/1424-8220/10/4/2885/htm" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from mdpi.com</span><span class="gs_ggsS">mdpi.com <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[HTML]</span><span class="gs_ct2">[HTML]</span></span> <a href="http://www.mdpi.com/1424-8220/10/4/2885/htm" class=yCC>Real-time occlusion handling in augmented reality based on an object tracking approach</a></h3><div class="gs_a">Y Tian, T Guan, C Wang - Sensors, 2010 - mdpi.com</div><div class="gs_rs">Abstract: To produce a realistic augmentation in Augmented Reality, the correct relative <br>positions of real objects and virtual objects are very important. In this paper, we propose a <br>novel real-time occlusion handling method based on an object tracking approach. Our <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18201104039695562985&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=12">Cited by 5</a> <a href="/scholar?q=related:6Tj7xbBPl_wJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18201104039695562985&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'6Tj7xbBPl_wJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md6', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md6" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:6Tj7xbBPl_wJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://rebar.ecn.purdue.edu/crc2012/papers/pdfs/-410.pdf" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from purdue.edu</span><span class="gs_ggsS">purdue.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ascelibrary.org/doi/pdf/10.1061/9780784412329.138" class=yCE>Rendering Stereoscopic Augmented Reality Scenes with Occlusions using Depth from Stereo and Texture Mapping</a></h3><div class="gs_a">J Louis, J Martinez, SMD West - &hellip;  2012@ sConstruction Challenges in a Flat &hellip; - ascelibrary.org</div><div class="gs_rs">Abstract Augmented Reality (AR) is commonly used in the construction industry to visualize <br>proposed structures and/or operations in their real world environment as it greatly enhances <br>the realism of the viewing experience without having to construct 3D models of complex <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:80zosA_h73wJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9002661637645683955&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'80zosA_h73wJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.emeraldinsight.com/journals.htm?articleid=1865104&amp;show=abstract" class=yC10>An automatic occlusion handling method in augmented reality</a></h3><div class="gs_a">Y Tian, T Guan, C Wang - Sensor Review, 2010 - emeraldinsight.com</div><div class="gs_rs">PurposeâTo make an augmented image realistic, the virtual objects should be correctly <br>occluded by foreground objects. The purpose of this paper is to propose a new approach <br>that resolves occlusion problems in augmented reality (AR). The main interest is that it can <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:TMS79ko2w_cJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17853173043421758540&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'TMS79ko2w_cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/91788a/20052/12198845.0.html" class=yC11>åºäº demons ç®æ³çéåæ§éåçæ¹è¿</a></h3><div class="gs_a">æ¨åºé - ä¿¡æ¯ææ¯, 2005 - cqvip.com</div><div class="gs_rs">æè¦: å®ç°äºä¸ç§åºäºdemons ç®æ³çå»å­¦å¾è±¡éåæ§éåæ¹æ³, ä½æ¯, ä¼ ç»çdemons <br>ç®æ³åªè½å¨å°åéä¸å®ç°éåæ§éå, å®éªç»æè¡¨æ, éè¿å¯è°æ»¤æ³¢å¨æ¥ä¼°ç®å¾å¹éå¾è±¡çæè½¬<br>è§åº¦, æ§éå. å½å¾éåå¾åæè½¬40 åº¦æ¶, éåææå°±å¾å·®äº. å®ç°å¨å¤§åéæ¡ä»¶ä¸çåºäº<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:nv-IHVv11zEJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3591608999537606558&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'nv-IHVv11zEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://tel.archives-ouvertes.fr/docs/00/34/20/29/PDF/THESE_ONLINEVERSION.pdf" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://tel.archives-ouvertes.fr/tel-00342029/" class=yC12>ReprÃ©sentations optmisÃ©es pour l&#39;accÃ©lÃ©ration des requÃªtes d&#39;affichage et de collision</a></h3><div class="gs_a">E Eisemann - 2008 - tel.archives-ouvertes.fr</div><div class="gs_rs">Many people deserve thanks for helping me. I want to mention my family first, my parents <br>Freya, Hans and my siblings Martin and Almuth Eisemann, for coping, supporting and <br>helping my throughout all these years. A special thanks goes to Hedlena Maria de <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:XE5OuB8puHwJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8986978272630689372&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'XE5OuB8puHwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md10', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md10" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:XE5OuB8puHwJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=4924286889462284431&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://hal.archives-ouvertes.fr/docs/00/34/11/08/PDF/CIFA_06.pdf" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://hal.archives-ouvertes.fr/hal-00341108/" class=yC14>RÃ©alitÃ© augmentÃ©e Ã  partir d&#39;une sÃ©quence vidÃ©o en utilisant la stÃ©rÃ©oscopie dense.</a></h3><div class="gs_a">N Zenati, K Achour, N Zerhouni - &hellip;  d&#39;Automatique, CIFA&#39;06., 2006 - hal.archives-ouvertes.fr</div><div class="gs_rs">RÃ©sumÃ©:âCet article s&#39; intÃ©resse Ã  la rÃ©alitÃ© augmentÃ©e, c&#39;est Ã  dire Ã  l&#39;intÃ©gration d&#39;objets <br>virtuels gÃ©nÃ©rÃ©s par ordinateur dans une sÃ©quence d&#39;images en gÃ©rant les occultations. <br>L&#39;occultation est l&#39;un des problÃ¨mes cruciaux en rÃ©alitÃ© augmentÃ©e. Il consiste Ã  tenir <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Pb__67rixQQJ:scholar.google.com/&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=343930239014911805&amp;hl=en&amp;num=12&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'Pb__67rixQQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
