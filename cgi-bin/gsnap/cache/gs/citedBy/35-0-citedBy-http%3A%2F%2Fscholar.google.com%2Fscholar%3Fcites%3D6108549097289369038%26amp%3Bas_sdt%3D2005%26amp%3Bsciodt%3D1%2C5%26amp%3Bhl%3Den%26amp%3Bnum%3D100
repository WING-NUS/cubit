Total results = 35
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.comp.nus.edu.sg/~mohan/papers/fusion_survey.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/E31M71152774R630.pdf" class=yC0>Multimodal fusion for multimedia analysis: a survey</a></h3><div class="gs_a"><a href="/citations?user=2s3sftgAAAAJ&amp;hl=en&amp;oi=sra">PK Atrey</a>, <a href="/citations?user=Qq4AAT4AAAAJ&amp;hl=en&amp;oi=sra">MA Hossain</a>, <a href="/citations?user=VcOjgngAAAAJ&amp;hl=en&amp;oi=sra">A El Saddik</a>, MS Kankanhalli - Multimedia Systems, 2010 - Springer</div><div class="gs_rs">Abstract This survey aims at providing multimedia researchers with a state-of-the-art <br>overview of fusion strategies, which are used for combining multiple modalities in order to <br>accomplish various multimedia analysis tasks. The existing literature on multimodal fusion <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2303959858949282248&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=35">Cited by 65</a> <a href="/scholar?q=related:yFlu6UhP-R8J:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2303959858949282248&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'yFlu6UhP-R8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="https://www.ee.columbia.edu/~xlx/research/papers/pieee-events.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from columbia.edu</span><span class="gs_ggsS">columbia.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4468738" class=yC2>Event mining in multimedia streams</a></h3><div class="gs_a"><a href="/citations?user=u0xUDSoAAAAJ&amp;hl=en&amp;oi=sra">L Xie</a>, <a href="/citations?user=Z962IGQAAAAJ&amp;hl=en&amp;oi=sra">H Sundaram</a>, <a href="/citations?user=8rykXfcAAAAJ&amp;hl=en&amp;oi=sra">M Campbell</a> - Proceedings of the IEEE, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Events are real-world occurrences that unfold over space and time. Event mining <br>from multimedia streams improves the access and reuse of large media collections, and it <br>has been an active area of research with notable progress. This paper contains a survey <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17740260980691592677&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=35">Cited by 31</a> <a href="/scholar?q=related:5WXYuF4RMvYJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/55/30/RN226708441.html?source=googlescholar" class="gs_nph" class=yC4>BL Direct</a> <a href="/scholar?cluster=17740260980691592677&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'5WXYuF4RMvYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4130383" class=yC5>Efficient short video repeat identification with application to news video structure analysis</a></h3><div class="gs_a">XF Yang, <a href="/citations?user=HJt0niEAAAAJ&amp;hl=en&amp;oi=sra">Q Tian</a>, P Xue - Multimedia, IEEE Transactions on, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper aims at repeat clip mining and knowledge discovery from video data. A <br>unified approach is proposed to detect both unknown video repeats and known video clips <br>of arbitrary length. Two detectors in a cascade structure are employed to achieve fast and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14000409111552932969&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=35">Cited by 21</a> <a href="/scholar?q=related:aTxB3OhxS8IJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14000409111552932969&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'aTxB3OhxS8IJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1421545" class=yC6>News sports video shot classification with sports play field and motion features</a></h3><div class="gs_a">DH Wang, <a href="/citations?user=HJt0niEAAAAJ&amp;hl=en&amp;oi=sra">Q Tian</a>, S Gao&hellip; - Image Processing, 2004.  &hellip;, 2004 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper a novel sports news video shot classification method has been <br>proposed. First two features based on motion and color are constructed and extracted from <br>video shots: play field color ratio for specific types of sports, background motion and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13296515698416067966&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=35">Cited by 15</a> <a href="/scholar?q=related:fqV-apS2hrgJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13296515698416067966&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'fqV-apS2hrgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://kusu.comp.nus.edu/proceedings/icme05/defevent/papers/cr1742.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu</span><span class="gs_ggsS">nus.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1521680" class=yC7>A probabilistic framework for TV-news stories detection and classification</a></h3><div class="gs_a"><a href="/citations?user=zfD1yBUAAAAJ&amp;hl=en&amp;oi=sra">F Colace</a>, P Foggia&hellip; - Multimedia and Expo, 2005 &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper we face the problem of partitioning the news videos into stories, and of <br>their classification according to a predefined set of categories. In particular, we propose to <br>employ a multi-level probabilistic framework based on the hidden Markov models and the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1850790752146050382&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=35">Cited by 9</a> <a href="/scholar?q=related:Tk0-F2JUrxkJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1850790752146050382&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'Tk0-F2JUrxkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://nerone.diiie.unisa.it/zope/mivia/publications/advanced_search/risultato_query/anni/pdfs/Shot%20Classification.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unisa.it</span><span class="gs_ggsS">unisa.it <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/4kqavjr4t6hmupcc.pdf" class=yC9>A multi-expert approach for shot classification in news videos</a></h3><div class="gs_a"><a href="/citations?user=h9tkpyYAAAAJ&amp;hl=en&amp;oi=sra">M De Santo</a>, <a href="/citations?user=Uhn4uusAAAAJ&amp;hl=en&amp;oi=sra">G Percannella</a>, <a href="/citations?user=jv-X8F8AAAAJ&amp;hl=en&amp;oi=sra">C Sansone</a>&hellip; - Image Analysis and  &hellip;, 2004 - Springer</div><div class="gs_rs">In this paper we propose a multi-expert approach for anchor shot detection in news videos. <br>The proposed Multi-Expert System (MES) combines three algorithms selected among those <br>presented in the literature that are model-free and do not require a specific training phase. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5518830382620755496&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=35">Cited by 9</a> <a href="/scholar?q=related:KEa-M_7SlkwJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/1A/21/RN157281778.html?source=googlescholar" class="gs_nph" class=yCB>BL Direct</a> <a href="/scholar?cluster=5518830382620755496&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'KEa-M_7SlkwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://nerone.diiie.unisa.it/zope/mivia/publications/advanced_search/risultato_query/anni/pdfs/Versione%20Springer.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unisa.it</span><span class="gs_ggsS">unisa.it <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/NYVLUNB4QN3R47GT.pdf" class=yCC>Combining experts for anchorperson shot detection in news videos</a></h3><div class="gs_a"><a href="/citations?user=h9tkpyYAAAAJ&amp;hl=en&amp;oi=sra">M De Santo</a>, <a href="/citations?user=Uhn4uusAAAAJ&amp;hl=en&amp;oi=sra">G Percannella</a>, <a href="/citations?user=jv-X8F8AAAAJ&amp;hl=en&amp;oi=sra">C Sansone</a>&hellip; - Pattern Analysis &amp;  &hellip;, 2004 - Springer</div><div class="gs_rs">Automatic classification of shots extracted by news videos plays an important role in the <br>context of news video segmentation, which is an essential step towards effective indexing of <br>broadcasters&#39; digital databases. In spite of the efforts reported by the researchers involved <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15449623454194744348&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=35">Cited by 8</a> <a href="/scholar?q=related:HDzSDK0WaNYJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/24/46/RN173152966.html?source=googlescholar" class="gs_nph" class=yCE>BL Direct</a> <a href="/scholar?cluster=15449623454194744348&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'HDzSDK0WaNYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://nerone.diiie.unisa.it/zope/mivia/publications/advanced_search/risultato_query/anni/pdfs/Segmentation%20of%20News%20Videos.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unisa.it</span><span class="gs_ggsS">unisa.it <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/K756266127453426.pdf" class=yCF>Segmentation of news videos based on audio-video information</a></h3><div class="gs_a"><a href="/citations?user=h9tkpyYAAAAJ&amp;hl=en&amp;oi=sra">M De Santo</a>, <a href="/citations?user=Uhn4uusAAAAJ&amp;hl=en&amp;oi=sra">G Percannella</a>, <a href="/citations?user=jv-X8F8AAAAJ&amp;hl=en&amp;oi=sra">C Sansone</a>&hellip; - Pattern Analysis &amp;  &hellip;, 2007 - Springer</div><div class="gs_rs">Abstract In this paper, we propose an innovative architecture to segment a news video into <br>the so-called âstoriesâ by both using the included video and audio information. Segmentation <br>of news into stories is one of the key issues for achieving efficient treatment of news-based <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6093987994379968543&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=35">Cited by 8</a> <a href="/scholar?q=related:H2CDJssxklQJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/16/07/RN207273970.html?source=googlescholar" class="gs_nph" class=yC11>BL Direct</a> <a href="/scholar?cluster=6093987994379968543&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'H2CDJssxklQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://idb.korea.ac.kr/publication/kr/inter_sbd_asd.pdf" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from korea.ac.kr</span><span class="gs_ggsS">korea.ac.kr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/A3702J613894033W.pdf" class=yC12>A unified scheme of shot boundary detection and anchor shot detection in news video story parsing</a></h3><div class="gs_a">H Lee, J Yu, Y Im, JM Gil, D Park - Multimedia Tools and Applications, 2011 - Springer</div><div class="gs_rs">Abstract In this paper, we propose an efficient one-pass algorithm for shot boundary <br>detection and a cost-effective anchor shot detection method with search space reduction, <br>which are unified scheme in news video story parsing. First, we present the desired <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10036053005043997658&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=35">Cited by 10</a> <a href="/scholar?q=related:2puj6Ag5R4sJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10036053005043997658&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'2puj6Ag5R4sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://nerone.diiie.unisa.it/zope/mivia/publications/advanced_search/risultato_query/List%20all%20publications/pdfs/SSPR.pdf" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unisa.it</span><span class="gs_ggsS">unisa.it <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/re6b792dpunag2vw.pdf" class=yC14>A comparison of unsupervised shot classification algorithms for news video segmentation</a></h3><div class="gs_a"><a href="/citations?user=h9tkpyYAAAAJ&amp;hl=en&amp;oi=sra">M De Santo</a>, <a href="/citations?user=Uhn4uusAAAAJ&amp;hl=en&amp;oi=sra">G Percannella</a>, <a href="/citations?user=jv-X8F8AAAAJ&amp;hl=en&amp;oi=sra">C Sansone</a>&hellip; - Structural, Syntactic, and  &hellip;, 2004 - Springer</div><div class="gs_rs">Automatic classification of shots extracted by news video plays an important role in the <br>context of news video segmentation. In spite of the efforts of the researchers involved in this <br>field, a definite solution for the shot classification problem does not yet exist. Moreover, the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9976453984728781249&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=35">Cited by 6</a> <a href="/scholar?q=related:wRHKpQp8c4oJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/50/0C/RN154306156.html?source=googlescholar" class="gs_nph" class=yC16>BL Direct</a> <a href="/scholar?cluster=9976453984728781249&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'wRHKpQp8c4oJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://www.hindawi.com/journals/ijdmb/aip/486487/" class=yC18><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from hindawi.com</span><span class="gs_ggsS">hindawi.com <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[HTML]</span><span class="gs_ct2">[HTML]</span></span> <a href="http://www.hindawi.com/journals/ijdmb/aip/486487/" class=yC17>Multimodal Indexing of Multilingual News Video</a></h3><div class="gs_a"><a href="/citations?user=XUwiadkAAAAJ&amp;hl=en&amp;oi=sra">H Ghosh</a>, <a href="/citations?user=2OsvtvgAAAAJ&amp;hl=en&amp;oi=sra">SK Kopparapu</a>, <a href="/citations?user=ugI69q0AAAAJ&amp;hl=en&amp;oi=sra">T Chattopadhyay</a>&hellip; - International Journal of &hellip;, 2010 - hindawi.com</div><div class="gs_rs">The problems associated with automatic analysis of news telecasts are more severe in a <br>country like India, where there are many national and regional language channels, besides <br>English. In this paper, we present a framework for multimodal analysis of multilingual <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6322536354863597187&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=35">Cited by 3</a> <a href="/scholar?q=related:g0YjB1EpvlcJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6322536354863597187&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'g0YjB1EpvlcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md10', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md10" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:g0YjB1EpvlcJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://eproceedings.worldscinet.com/9789812702135/9789812702135_0010.html" class=yC19>An Unsupervised Shot Classification System for News Video Story Detection</a></h3><div class="gs_a"><a href="/citations?user=h9tkpyYAAAAJ&amp;hl=en&amp;oi=sra">M De Santo</a>, <a href="/citations?user=Uhn4uusAAAAJ&amp;hl=en&amp;oi=sra">G Percannella</a>&hellip; - Multimedia  &hellip;, 2005 - eproceedings.worldscinet.com</div><div class="gs_rs">Abstract: Automatic classification of shots extracted by news video plays an important role in <br>the context of news video segmentation, which is an essential step towards effective <br>indexing of broadcasters&#39; digital databases. In this paper, we propose a system for news <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14431724022824467294&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=35">Cited by 3</a> <a href="/scholar?q=related:XnvsRInIR8gJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14431724022824467294&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'XnvsRInIR8gJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://nerone.diiie.unisa.it/zope/mivia/publications/advanced_search/risultato_query/anni/pdfs/Versione%20LNCS.pdf" class=yC1B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unisa.it</span><span class="gs_ggsS">unisa.it <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/P4657044514N2780.pdf" class=yC1A>An improved algorithm for anchor shot detection</a></h3><div class="gs_a"><a href="/citations?user=h9tkpyYAAAAJ&amp;hl=en&amp;oi=sra">M De Santo</a>, <a href="/citations?user=Uhn4uusAAAAJ&amp;hl=en&amp;oi=sra">G Percannella</a>, <a href="/citations?user=jv-X8F8AAAAJ&amp;hl=en&amp;oi=sra">C Sansone</a>&hellip; - Image Analysis and  &hellip;, 2005 - Springer</div><div class="gs_rs">Abstract. Segmentation of news videos into stories is among key issues for achieving <br>efficient treatment of news-based digital libraries. Indeed, anchor shot detection is a <br>fundamental step for segmenting news into stories. In this paper we present an improved <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10929140852971418581&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=35">Cited by 3</a> <a href="/scholar?q=related:1TOSYbMbrJcJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/11/44/RN174315393.html?source=googlescholar" class="gs_nph" class=yC1C>BL Direct</a> <a href="/scholar?cluster=10929140852971418581&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'1TOSYbMbrJcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.153.4267&amp;rep=rep1&amp;type=pdf" class=yC1E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/L430L012V407J8GX.pdf" class=yC1D>Extracting semantics from multimedia content: challenges and solutions</a></h3><div class="gs_a"><a href="/citations?user=u0xUDSoAAAAJ&amp;hl=en&amp;oi=sra">L Xie</a>, <a href="/citations?user=NIIQFrEAAAAJ&amp;hl=en&amp;oi=sra">R Yan</a> - Multimedia Content Analysis, 2009 - Springer</div><div class="gs_rs">Multimedia content accounts for over 60% of traffic in the current Internet [74]. With many <br>users willing to spend their leisure time watching videos on YouTube or browsing photos <br>through Flickr, sifting through large multimedia collections for useful information, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9102153946033487200&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=35">Cited by 3</a> <a href="/scholar?q=related:YP0-5MlYUX4J:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9102153946033487200&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'YP0-5MlYUX4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://cvsp.cs.ntua.gr/publications/jpubl%2Bbchap/Maragos-et-al_Chapter-of-Book_MPIAVT_Springer2008_preprint.pdf" class=yC20><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntua.gr</span><span class="gs_ggsS">ntua.gr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/N671Q25150J3X133.pdf" class=yC1F>Cross-modal integration for performance improving in multimedia: A review</a></h3><div class="gs_a">P Maragos, P Gros, <a href="/citations?user=S08iCqYAAAAJ&amp;hl=en&amp;oi=sra">A Katsamanis</a>&hellip; - &hellip; Processing and Interaction, 2008 - Springer</div><div class="gs_rs">Our surrounding world is abundant with multimodal stimuli which emit multisensory <br>information in the form of analog signals. Humans perceive the natural world in a multimodal <br>way: vision, hearing, touch. Nowadays, propelled by our digital technology, we are also <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17983145527240553794&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=35">Cited by 2</a> <a href="/scholar?q=related:QvVTB5T3kPkJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17983145527240553794&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'QvVTB5T3kPkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://www.hindawi.com/journals/ijdmb/aip/732514/" class=yC22><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from hindawi.com</span><span class="gs_ggsS">hindawi.com <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[HTML]</span><span class="gs_ct2">[HTML]</span></span> <a href="http://www.hindawi.com/journals/ijdmb/aip/732514/" class=yC21>Automatic Story Segmentation for TV News Video Using Multiple Modalities</a></h3><div class="gs_a">Ã Dumont, G QuÃ©not - International Journal of Digital Multimedia  &hellip;, 2012 - hindawi.com</div><div class="gs_rs">While video content is often stored in rather large files or broadcasted in continuous streams, <br>users are often interested in retrieving only a particular passage on a topic of interest to <br>them. It is, therefore, necessary to split video documents or streams into shorter segments <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6254370804616678151&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=35">Cited by 1</a> <a href="/scholar?q=related:B0vAFhz9y1YJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6254370804616678151&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'B0vAFhz9y1YJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md15', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md15" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:B0vAFhz9y1YJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=eT4V2TBhE6UC&amp;oi=fnd&amp;pg=PA311&amp;ots=BW3rV-Lf1c&amp;sig=Qk5YBSI-GtsnHt1zvliLEIFLfsE" class=yC23>15.1 Evolution of Mobile Multimedia</a></h3><div class="gs_a">S Siltanen, C Woodward, S Valli&hellip; - &hellip; : Audio, Video, Text, 2008 - books.google.com</div><div class="gs_rs">Multimedia applications have existed as long as there have been personal computers <br>supporting the playback of audiovisual (AV) content. Especially after PCs were equipped <br>with a network access for downloading content, the development of multimedia <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14200121506104112256&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=35">Cited by 1</a> <a href="/scholar?q=related:gHS4Okb3EMUJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'gHS4Okb3EMUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://nerone.diiie.unisa.it/zope/mivia/publications/advanced_search/risultato_query/autori/pdfs/Combining%20audio-based.pdf" class=yC25><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unisa.it</span><span class="gs_ggsS">unisa.it <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/yn9lvebqu0euhfyx.pdf" class=yC24>Combining audio-based and video-based shot classification systems for news videos segmentation</a></h3><div class="gs_a"><a href="/citations?user=h9tkpyYAAAAJ&amp;hl=en&amp;oi=sra">M De Santo</a>, <a href="/citations?user=Uhn4uusAAAAJ&amp;hl=en&amp;oi=sra">G Percannella</a>, <a href="/citations?user=jv-X8F8AAAAJ&amp;hl=en&amp;oi=sra">C Sansone</a>&hellip; - Multiple Classifier  &hellip;, 2005 - Springer</div><div class="gs_rs">In this paper we propose an innovative combination strategy for a system using video and <br>audio stream of a news video to automatically segment it into stories. In our approach, the <br>segmentation is performed in two steps: first, shots are classified by combining three <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12761769671295265101&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=35">Cited by 1</a> <a href="/scholar?q=related:TWnouubpGrEJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12761769671295265101&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'TWnouubpGrEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Multimodal Indexing of Multilingual News Video</h3><div class="gs_a">G Hiranmay, <a href="/citations?user=2OsvtvgAAAAJ&amp;hl=en&amp;oi=sra">K Sunil Kumar</a>&hellip; - International  &hellip;, 2010 - Hindawi Publishing Corporation</div><div class="gs_fl"><a href="/scholar?cites=3748672000631884928&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=35">Cited by 1</a> <a href="/scholar?q=related:gMwdwVL1BTQJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3748672000631884928&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'gMwdwVL1BTQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> A framework for multimedia surveillance</h3><div class="gs_a"><a href="/citations?user=2s3sftgAAAAJ&amp;hl=en&amp;oi=sra">PK Atrey</a> - 2004 - PhD Thesis, School of Computing,  &hellip;</div><div class="gs_fl"><a href="/scholar?cites=10263597146751954787&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=35">Cited by 1</a> <a href="/scholar?q=related:Y-_c4Tmfb44J:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Y-_c4Tmfb44J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB20" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW20"><a href="http://www.commit-nl.nl/sites/default/files/675955_survey_mm-search-optimization.pdf" class=yC27><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from commit-nl.nl</span><span class="gs_ggsS">commit-nl.nl <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.commit-nl.nl/sites/default/files/675955_survey_mm-search-optimization.pdf" class=yC26>A Survey on Multimedia Search Optimization based on Multimodal Information Resources</a></h3><div class="gs_a"><a href="/citations?user=Fhmp7lQAAAAJ&amp;hl=en&amp;oi=sra">C Kofler</a>, M Larson, <a href="/citations?user=EoYbukgAAAAJ&amp;hl=en&amp;oi=sra">A Hanjalic</a> - commit-nl.nl</div><div class="gs_rs">Abstract. This survey constitutes a literature study that overviews the state-of-the-art in <br>multimedia search. Techniques that are covered include multimodal re-ranking, pseudo-<br>relevance feedback, query classification and query suggestion. Discussion of the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:1DJ7H6YdmWsJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'1DJ7H6YdmWsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md20', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md20" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:1DJ7H6YdmWsJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="http://tosca-mp.eu/wp-content/uploads/2012/10/TOSCAMP-D3.1-v1.1.pdf" class=yC29><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tosca-mp.eu</span><span class="gs_ggsS">tosca-mp.eu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://tosca-mp.eu/wp-content/uploads/2012/10/TOSCAMP-D3.1-v1.1.pdf" class=yC28>State of the art on semantic retrieval of AV content beyond text resources</a></h3><div class="gs_a"><a href="/citations?user=O9hYMUUAAAAJ&amp;hl=en&amp;oi=sra">MF Moens</a>, GJ Poulisse, MM VRT - 2012 - tosca-mp.eu</div><div class="gs_rs">1 Executive Summary This deliverable describes the state of the art in the area of semantic <br>retrieval of multimedia (audiovisual) content beyond text resources, ie, considering the <br>nature of the content to be retrieved. In this line, the characteristics of images, video and <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'KCcTKOqj1VYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md21', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md21" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:KCcTKOqj1VYJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB22" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW22"><a href="http://bi.snu.ac.kr/~bdlee/publications/1st_int_conf_workshop_bdlee_nips_npbayes_final.pdf" class=yC2B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from snu.ac.kr</span><span class="gs_ggsS">snu.ac.kr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://bi.snu.ac.kr/~bdlee/publications/1st_int_conf_workshop_bdlee_nips_npbayes_final.pdf" class=yC2A>Video Streams Semantic Segmentation utilizing Multiple Channels with Different Time Granularity</a></h3><div class="gs_a">HSS Bado Lee, <a href="/citations?user=sYTUOu8AAAAJ&amp;hl=en&amp;oi=sra">BT Zhang</a> - bi.snu.ac.kr</div><div class="gs_rs">Abstract This paper deals with a semantic segmentation in video streams. The proposed <br>method aims to detect story segments in an episode of a TV drama. For reliable story <br>segmentation, the challenge is to build a robust model capable of capturing the underlying <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:svZwKK6tUvsJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'svZwKK6tUvsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md22', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md22" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:svZwKK6tUvsJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=_OUwpaTN40AC&amp;oi=fnd&amp;pg=PA283&amp;ots=reIFY1tC2D&amp;sig=0HNZzoQ-nfKsqK9c6sVA79bY2ZY" class=yC2C>An Overview of Video Information Retrieval Techniques</a></h3><div class="gs_a">S Deb, Y Zhang - Video Data Management And Information  &hellip;, 2004 - books.google.com</div><div class="gs_rs">ABSTRACT Video information retrieval is currently a very important topic of research in the <br>area of multimedia databases. Plenty of research work has been undertaken in the past <br>decade to design efficient video information retrieval techniques from the video or <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:TaK2V1TThL0J:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13656272329296486989&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'TaK2V1TThL0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB24" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW24"><a href="http://nmlab.korea.ac.kr/publication/rejected%20papers/2008/2008%20-%20Design%20of%20News%20Video%20Story%20Parsing%20System%20-%20TCSVT.pdf" class=yC2E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from korea.ac.kr</span><span class="gs_ggsS">korea.ac.kr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://nmlab.korea.ac.kr/publication/rejected%20papers/2008/2008%20-%20Design%20of%20News%20Video%20Story%20Parsing%20System%20-%20TCSVT.pdf" class=yC2D>Design of News Video Story Parsing System</a></h3><div class="gs_a">H Lee, Y Im, MS Kim, J Park, D Park - nmlab.korea.ac.kr</div><div class="gs_rs">AbstractâAlthough considerable progress was recently made in the field of news video <br>story parsing, it is still an active and challenging task in a news video library system. In this <br>paper, we introduce a lightweight and fast news video story parsing system with high <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:aZN0dv-qKswJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'aZN0dv-qKswJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md24', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md24" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:aZN0dv-qKswJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB25" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW25"><a href="http://137.132.14.55/bitstream/handle/10635/14402/thesis.pdf?sequence=1" class=yC30><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.14.55</span><span class="gs_ggsS">137.132.14.55 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://137.132.14.55/handle/10635/14402" class=yC2F>Event detection in soccer video based on audio/visual keywords</a></h3><div class="gs_a">K YULIN - 2004 - 137.132.14.55</div><div class="gs_rs">In this thesis, we propose a multi-modal two-level event detection framework and <br>demonstrate it on soccer videos. We use a mid-level representation called Audio and Visual <br>Keyword (AVK) that can be learned and detected in video segments. AVKs are intended to <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:8u8rejdXeoUJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9618095849987633138&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'8u8rejdXeoUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB26" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW26"><a href="http://www.tkl.iis.u-tokyo.ac.jp/top/modules/newdb/extract/1210/data/2012-MDDE-A%20Multimodal%20Fusion%20Approach%20By%20Exploiting%20Concept%20Interactions%20for%20Ef%3Fcient%20Multimedia%20Analysis.pdf" class=yC32><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from u-tokyo.ac.jp</span><span class="gs_ggsS">u-tokyo.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.tkl.iis.u-tokyo.ac.jp/top/modules/newdb/extract/1210/data/2012-MDDE-A%20Multimodal%20Fusion%20Approach%20By%20Exploiting%20Concept%20Interactions%20for%20Ef%3Fcient%20Multimedia%20Analysis.pdf" class=yC31>A Multimodal Fusion Approach By Exploiting Concept Interactions for Efficient Multimedia Analysis</a></h3><div class="gs_a">E Gulen, <a href="/citations?user=u3GoN7wAAAAJ&amp;hl=en&amp;oi=sra">T Yilmaz</a>, A Yazici - tkl.iis.u-tokyo.ac.jp</div><div class="gs_rs">ABSTRACT Multimedia data intrinsically contains multimodal information in it. In order to <br>obtain a successful multimedia analysis, all available information should be utilized by <br>following a multimodal approach. In addition, the interaction between concepts is another <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:s_r5mFKCQn0J:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9025919894469343923&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'s_r5mFKCQn0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md26', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md26" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:s_r5mFKCQn0J:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB27" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW27"><a href="http://nerone.diiie.unisa.it/zope/mivia/publications/advanced_search/risultato_query/anni/pdfs/Automatic%20Indexing.pdf" class=yC34><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unisa.it</span><span class="gs_ggsS">unisa.it <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/9GQ2BTT2F6MHPD06.pdf" class=yC33>Automatic indexing of news videos through text classification techniques</a></h3><div class="gs_a"><a href="/citations?user=Uhn4uusAAAAJ&amp;hl=en&amp;oi=sra">G Percannella</a>, D Sorrentino, <a href="/citations?user=3PwXGpgAAAAJ&amp;hl=en&amp;oi=sra">M Vento</a> - Pattern Recognition and Image  &hellip;, 2005 - Springer</div><div class="gs_rs">Abstract. In this paper we discuss about the applicability of text classification techniques for <br>automatic content recognition of the scenes from news videos. In particular, the news scenes <br>are classified according to a predefined set of six categories (National Politics, National <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:1-AsxkaE0hQJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/0A/3B/RN173594208.html?source=googlescholar" class="gs_nph" class=yC35>BL Direct</a> <a href="/scholar?cluster=1500407065375203543&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'1-AsxkaE0hQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=UkXhfJD1maoC&amp;oi=fnd&amp;pg=PA157&amp;ots=5XqFWkycQM&amp;sig=6600rPYl_W6-zdk9-Q_A__TKNlY" class=yC36>TV Program Structuring Techniques</a></h3><div class="gs_a">AE Abduraman, SA Berrani&hellip; - TV Content Analysis:  &hellip;, 2012 - books.google.com</div><div class="gs_rs">158â  TV ContentAnalysis: Techniques and Applications 6.4 Conclusion.....................................<br>........................... 174 References....................................................................... 175 6.1 Introduction <br>The objective of this chapter is to present the problem of TV program structuring and its <b> ...</b> </div><div class="gs_fl"><a href="/scholar?q=related:Q_cM1J21ZxMJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Q_cM1J21ZxMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB29" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW29"><a href="http://www.cmlab.csie.ntu.edu.tw/~zenic/Download/ICME2012/Conference/data/4711a973.pdf" class=yC38><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntu.edu.tw</span><span class="gs_ggsS">ntu.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6298529" class=yC37>A local temporal context-based approach for TV news story segmentation</a></h3><div class="gs_a">E Dumont, G QuÃ©not - Multimedia and Expo (ICME), 2012 IEEE &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Users are often interested in retrieving only a particular passage on a topic of <br>interest to them. It is therefore necessary to split videos into shorter segments corresponding <br>to appropriate retrieval units. We propose here a method based on a local temporal <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:0E-s6P95Te8J:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17243572688298725328&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'0E-s6P95Te8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6123389" class=yC39>Efficient and Language Independent News Story Segmentation for Telecast News Videos</a></h3><div class="gs_a">A Jindal, A Tiwari, <a href="/citations?user=XUwiadkAAAAJ&amp;hl=en&amp;oi=sra">H Ghosh</a> - Multimedia (ISM), 2011 IEEE  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract A TV news program comprises a continuous video stream containing a number of <br>news stories, interspersed with commercials and headlines. This paper presents a method <br>to detect the story boundaries and to separate out the stories from the other components <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:TeNg6qHsZLcJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13214947386777985869&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'TeNg6qHsZLcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB31" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW31"><a href="http://dissertacao-danilo-icmc.googlecode.com/svn-history/r23/trunk/dissert_danilo.pdf" class=yC3B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from googlecode.com</span><span class="gs_ggsS">googlecode.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://dissertacao-danilo-icmc.googlecode.com/svn-history/r23/trunk/dissert_danilo.pdf" class=yC3A>IdentificaÃ§ao de transiÃ§ao de cenas em telejornais utilizando multimodalidades</a></h3><div class="gs_a">DB Coimbra - dissertacao-danilo-icmc.googlecode &hellip;</div><div class="gs_rs">Resumo A evoluÃ§ao tecnolÃ³gica, juntamente com o crescimento e desenvolvimento da <br>Web, requisitam maneiras eficazes de manipulaÃ§ao e gerenciamento de informaÃ§oes. <br>Embora a tendÃªncia das aplicaÃ§oes computacionais seja satisfazer do melhor modo a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:0ry0NvvZt4YJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9707467194798226642&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'0ry0NvvZt4YJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md31', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md31" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:0ry0NvvZt4YJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> åºäºè¯å¸è¯è¯­éåå³ç³»çä¸­æææ¬åå²æ¹æ³</h3><div class="gs_a">Z Mao0sheng, HU Yi, LIU Lei - Computer Engineering and Applications, 2008</div><div class="gs_fl"><a href="/scholar?q=related:XlTQQiGs0X0J:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'XlTQQiGs0X0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:367"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB33" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW33"><a href="http://idb.korea.ac.kr/publication/kr/kr_newsdetect.pdf" class=yC3D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from korea.ac.kr</span><span class="gs_ggsS">korea.ac.kr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://idb.korea.ac.kr/publication/kr/kr_newsdetect.pdf" class=yC3C>í¹ì´ê° ë¶í´ì ì ì¦ì  í´ë¬ì¤í°ë§ì ì´ì©íë´ì¤ ë¹ëì¤ ì· ê²½ê³ íì§</a></h3><div class="gs_a">ì´íì±ï¼ ììí¬ï¼ ë°ëí¬ï¼ ì´ì±í - ì ë³´ê³¼ííë¼ë¬¸ì§: ìíí¸ì¨ì´ ë°  &hellip;, 2009 - idb.korea.ac.kr</div><div class="gs_rs">ì ì½ ë³¸ ë¼ë¬¸ììë ë´ì¤ ê¸°ì¬ ë¶í  ê´ì ìì, ë´ì¤ ë¹ëì¤ ì· ê²½ê³ íì§ ìê³ ë¦¬ì¦ì í¹ì±ì <br>ê³ ë ¤íë¤ìê³¼ ê°ì ì¤ê³ ê¸°ì¤ì ì ìíê³ , ì´ë¥¼ ëª¨ë ë§ì¡±íë ìë¡ì´ ì· ê²½ê³ íì§ ìê³ ë¦¬ì¦ì <br>ì ìíê³ ì íë¤. 1) ë´ì¤ ë¹ëì¤ ì· ê²½ê³ íì§ì ì¬íì¨ì ëìì¼ë¡ì¨, ìµì»¤ ì· íì§ ë¨ê³ìì <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:xjHkZcMK3M0J:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14833743106995925446&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'xjHkZcMK3M0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md33', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md33" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:xjHkZcMK3M0J:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:366"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/90452x/200918/30645240.html" class=yC3E>ä¸ç§åºäºèç±»çä¸»æäººéå¤´æ£æµç®æ³</a></h3><div class="gs_a">è£å®¶çï¼ é»ç³ç³ - å¾®è®¡ç®æºä¿¡æ¯, 2009 - cqvip.com</div><div class="gs_rs">éçæ°å­è§é¢çå¹¿æ³åºç¨, è§é¢æ°æ®åºç³»ç»å·²æä¸ºåºäºåå®¹çè§é¢æ£ç´¢é¢åçä¸ä¸ªç ç©¶ç­ç¹. <br>å¨å»ºç«è§é¢æ°æ®åºçè¿ç¨ä¸­, ä¸»æäººéå¤´çæ£æµæ¯ä¸ä¸ªéè¦èåé¾ä»¥è§£å³çé®é¢. <br>æ¬æåå¨éå¤´çº§å«å¯¹è§é¢æåä¸ç³»åçæ¶ååç©ºåç¹å¾, å¦äººè¸ç¹å¾, å½©è²çº¹çç¹å¾, éå¤´æ¶é´<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:5D7_svr528QJ:scholar.google.com/&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14185206306473721572&amp;hl=en&amp;num=35&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'5D7_svr528QJ')" href="#" class="gs_nph">Cite</a></div></div></div>
