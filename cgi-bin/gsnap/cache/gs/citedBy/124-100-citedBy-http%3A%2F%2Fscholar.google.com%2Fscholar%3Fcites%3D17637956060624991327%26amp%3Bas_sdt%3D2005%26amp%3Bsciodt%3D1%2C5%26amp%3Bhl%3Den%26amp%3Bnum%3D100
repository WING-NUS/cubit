<div class="gs_r" style="z-index:400"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> A New Content-Based Video Retrieval System-Data Model and Query Processing</h3><div class="gs_a">PJ Cheng, WP Yang - Proc. of ICS&#39;98, 1998</div><div class="gs_fl"><a href="/scholar?q=related:hHcSSLtQ4DsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4314537208319211396&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'hHcSSLtQ4DsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB101" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW101"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.20.1465&amp;rep=rep1&amp;type=pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.20.1465&amp;rep=rep1&amp;type=pdf" class=yC0>An Object-based Video Data Model for Multimedia Systems</a></h3><div class="gs_a">DA Tran, KA Hua, K Vu - 2001 - Citeseer</div><div class="gs_rs">A multimedia database management system is critical to the development and deployment <br>of largescale multimedia applications. Modeling video data, however, poses a great <br>challenge since they do not have as clear an underlying structure as traditional databases <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:_VwNUOU_OxcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1674001940621384957&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'_VwNUOU_OxcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md101', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md101" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:_VwNUOU_OxcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB102" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW102"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.36.8166&amp;rep=rep1&amp;type=pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.36.8166&amp;rep=rep1&amp;type=pdf" class=yC2>Department of Computing The Hong Kong Polytechnic University Hung Hom, Kowloon Hong Kong</a></h3><div class="gs_a">A Si, RWH Lau, <a href="/citations?user=D1LEg-YAAAAJ&amp;hl=en&amp;oi=sra">Q Li</a>, HV Leong - Citeseer</div><div class="gs_rs">Video objects are temporal in nature. A video object is com- posed of a set of video frames which <br>are related in a total time ordering. By imposing additional timing constraints among video <br>frames, various presentation operators on video objects could be de ned. A core set of <b> ...</b> </div><div class="gs_fl"><a href="/scholar?q=related:IY3AXWyC6m8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'IY3AXWyC6m8J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md102', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md102" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:IY3AXWyC6m8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB103" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW103"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.46.8779&amp;rep=rep1&amp;type=pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.46.8779&amp;rep=rep1&amp;type=pdf" class=yC4>LTCS {Report</a></h3><div class="gs_a">C Decleir, MS d Hacid, J Kouloumdjian - Citeseer</div><div class="gs_rs">Abstract Indexing video data is essential for providing content based access. In this paper, <br>we consider how database technology can o er an integrated framework for modeling and <br>querying video data. As many concerns in video (eg, modeling and querying) are also <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:TCAsYebO2jMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3736526329725329484&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'TCAsYebO2jMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md103', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md103" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:TCAsYebO2jMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB104" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW104"><a href="https://doc.telin.nl/dsweb/Get/Document-8267/GigaCE-Profile-based%20moving%20storyboards.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from telin.nl</span><span class="gs_ggsS">telin.nl <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="https://doc.telin.nl/dsweb/Get/Document-8267/GigaCE-Profile-based%20moving%20storyboards.pdf" class=yC6>Profile-Based Moving Storyboards</a></h3><div class="gs_a">GC Van den Eijkel, PAP Porskamp, M van Setten&hellip; - Telematica  &hellip;, 1999 - doc.telin.nl</div><div class="gs_rs">ABSTRACT Moving storyboards are a novel approach to content-based video retrieval and <br>combine the advantages of video segmentation techniques with intuitive and user-friendly <br>presentation mechanisms on the basis of user, system and context profiles.</div><div class="gs_fl"><a href="/scholar?q=related:6ffXZkQpsy8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3437136314373765097&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'6ffXZkQpsy8J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md104', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md104" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:6ffXZkQpsy8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.google.com/patents?hl=en&amp;lr=&amp;vid=USPAT7643597&amp;id=RcrOAAAAEBAJ&amp;oi=fnd&amp;printsec=abstract" class=yC8>Methods for selecting a subsequence of video frames from a sequence of video frames</a></h3><div class="gs_a">T Liu, JR Kender - US Patent 7,643,597, 2010 - Google Patents</div><div class="gs_rs">A method for selecting a subsequence of video frames (72-84) from a sequence of video <br>frames (70) comprising defining a distance function between video frames (72-84) in the <br>sequence of video frames (70). An optimization criterion is defined to express a feature of <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:o0Q2bXxct80J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14823418387991250083&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'o0Q2bXxct80J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB106" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW106"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.51.6414&amp;rep=rep1&amp;type=pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.51.6414&amp;rep=rep1&amp;type=pdf" class=yC9>Multi-channel video segmentation Pascal Faudemay, Liming Chen 2, Claude MontaciÃ© 3, Marie-JosÃ© Caraty 3, Christine Maloigne 2, XiaoWei Tu 2, Mohsen  &hellip;</a></h3><div class="gs_a">P Faudemay - Citeseer</div><div class="gs_rs">ABSTRACT A video is a multimedia document which is structured in scenes and shots. <br>Scenes are lists of consecutive shots characterized by common visual and audio features. <br>Shots are sets of consecutive frames separated by cuts, which can be easily recognized <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:l5XEguvzuQAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'l5XEguvzuQAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md106', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md106" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:l5XEguvzuQAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.google.com/patents?hl=en&amp;lr=&amp;vid=USPAT7962482&amp;id=lAjnAQAAEBAJ&amp;oi=fnd&amp;printsec=abstract" class=yCB>Methods and systems for utilizing contextual feedback to generate and modify playlists</a></h3><div class="gs_a">EF Handman, TJ Conrad, JJ Kennedy&hellip; - US Patent  &hellip;, 2011 - Google Patents</div><div class="gs_rs">Systems and methods of generating and modifying a playlist using contextual information <br>are disclosed. For example, a user may provide an input seed such as a song name or artist <br>name. The input seed is compared to database items and a playlist is generated as a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:RIt4mbuKdowJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10121429750900099908&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'RIt4mbuKdowJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB108" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW108"><a href="http://www.is.inf.uni-due.de/courses/dortmund/courses/mmis/sigir98/litlist.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uni-due.de</span><span class="gs_ggsS">uni-due.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.is.inf.uni-due.de/courses/dortmund/courses/mmis/sigir98/litlist.pdf" class=yCC>Literature on MM IR</a></h3><div class="gs_a"><a href="/citations?user=p53Ht7UAAAAJ&amp;hl=en&amp;oi=sra">N Fuhr</a> - is.inf.uni-due.de</div><div class="gs_rs">Surveys on multimedia information systems are given eg in the articles [Furht 94],[Fox <br>91],[Narasimhalu 96] and the books [SchÃ¤uble 97],[Apers et al. 97],[Nwosu et al. <br>96],[Subrahmanian &amp; Jajodia 96],[Subrahmanian 98][Furht &amp; Milenkovic 95].</div><div class="gs_fl"><a href="/scholar?q=related:y0nJnrSqOuIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16301529493955758539&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'y0nJnrSqOuIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md108', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md108" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:y0nJnrSqOuIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB109" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW109"><a href="http://arxiv.org/pdf/1207.4259" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arxiv.org</span><span class="gs_ggsS">arxiv.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://arxiv.org/abs/1207.4259" class=yCE>Content Based Multimedia Information Retrieval to Support Digital Libraries</a></h3><div class="gs_a"><a href="/citations?user=AJy07UIAAAAJ&amp;hl=en&amp;oi=sra">MN Almunawar</a> - arXiv preprint arXiv:1207.4259, 2012 - arxiv.org</div><div class="gs_rs">Abstract: Content-based multimedia information retrieval is an interesting research area <br>since it allows retrieval based on inherent characteristic of multimedia objects. For example <br>retrieval based on visual characteristics such as colour, shapes or textures of objects in <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:H3xppDdREhIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1302192541686922271&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'H3xppDdREhIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB110" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW110"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.109.3574&amp;rep=rep1&amp;type=pdf" class=yC11><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.109.3574&amp;rep=rep1&amp;type=pdf" class=yC10>Video Data Modelling To Support Hybrid Query</a></h3><div class="gs_a">LS Affendey, A Mamat, H Ibrahim, F Ahmad - IJCSNS, 2007 - Citeseer</div><div class="gs_rs">Summary Information contained in unstructured video data needs to be extracted and must <br>be appropriately modeled in order to support storage and content retrieval. A video data <br>model should be expressive enough to capture several characteristics inherent to video. <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:FFNBp2IUSVAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5785177610279539476&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'FFNBp2IUSVAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md110', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md110" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:FFNBp2IUSVAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=8zkpgvRzmFIC&amp;oi=fnd&amp;pg=PA174&amp;ots=vTlwvA3-2U&amp;sig=TthYEjHbHnJMeYy1hQ2WOjEkar4" class=yC12>Effectiveness Studies On Content-Based Video Retrieval Systems</a></h3><div class="gs_a">I Krishnatnurthi, S Raman - Knowledge Based Computer  &hellip;, 2000 - books.google.com</div><div class="gs_rs">Abstract In today&#39;s multimedia databases, the traditional way of retrieving data that is based <br>on attributes, will not suffice. We need mechanisms to effectively represent and then to <br>efficiently retrieve the contents of these multimedia data types. In this work, we focus on <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:NPI2qZWceFQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'NPI2qZWceFQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB112" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW112"><a href="http://edirlei.3dgb.com.br/artigos/Edirlei_ICME_2012.pdf" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 3dgb.com.br</span><span class="gs_ggsS">3dgb.com.br <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6298502" class=yC13>Automatic Video Editing For Video-Based Interactive Storytelling</a></h3><div class="gs_a"><a href="/citations?user=zUgWz14AAAAJ&amp;hl=en&amp;oi=sra">ES Lima</a>, B FeijÃ³, AL Furtado, A Ciarlini&hellip; - Multimedia and Expo  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The development of interactive narratives with the quality of feature films is the <br>central challenge of what we can name Video-Based Interactive Storytelling. A promising <br>approach to this question is the use of prerecorded videos with real actors. Amongst <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:sNH70ASJPoQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9529204515341586864&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'sNH70ASJPoQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/gxf7h1j8er4jfgef.pdf" class=yC15>Spatial-Temporal Semantic Grouping of Instructional Video Content</a></h3><div class="gs_a">L Tiecheng, J Kender - Image and Video Retrieval, 2003 - Springer</div><div class="gs_rs">This paper presents a new approach for content analysis and semantic summarization of <br>instructional videos of blackboard presentations. We first use low-level image processing <br>techniques to segment frames into board content regions, regions occluded by instructors, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:h5Fr1aWKyw0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'h5Fr1aWKyw0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Similarity Based Retrieval of Videos</h3><div class="gs_a">APSC Yu&hellip; - &hellip; : April 7-11, 1997,  &hellip;, 1997 - IEEE Computer Society Press</div><div class="gs_fl"><a href="/scholar?q=related:TG2m4wLEi0cJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5155429715143978316&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'TG2m4wLEi0cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB115" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW115"><a href="http://scholarbank.nus.edu/bitstream/handle/10635/13633/Zhao_Yunlong_PhD_thesis.pdf?sequence=1" class=yC17><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu</span><span class="gs_ggsS">nus.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://scholarbank.nus.edu/handle/10635/13633" class=yC16>Automatic extraction and tracking of face sequences in MPEG video</a></h3><div class="gs_a">Z Yunlong - 2004 - scholarbank.nus.edu</div><div class="gs_rs">This PhD work focuses on the problem of extracting multiple face sequences from MPEG <br>video based on face detection and tracking. It aims to facilitate the strata-based digital video <br>modelling to achieve efficient video retrieval and browsing. The research includes the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:LWH47rNLYawJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12421292483445023021&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'LWH47rNLYawJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Hybrid Query for Video Database System</h3><div class="gs_a">LS Affendey, A Mamat, H Ibrahim, F Ahmad</div><div class="gs_fl"><a href="/scholar?q=related:fhDg77F6YpAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'fhDg77F6YpAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> A Mask Matching Approach for Video Segmentation on Compressed Data</h3><div class="gs_a">ALP Chen, TCT Kuo</div><div class="gs_fl"><a href="/scholar?q=related:iniB-Vwk7vIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17504968783377299594&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'iniB-Vwk7vIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><a href="http://onlinelibrary.wiley.com/doi/10.1002/9780470050118.ecse576/full" class=yC18>Video Databases</a></h3><div class="gs_a"><a href="/citations?user=D1LEg-YAAAAJ&amp;hl=en&amp;oi=sra">L Qing</a>, W Xiao, N ChongâWah - Wiley Encyclopedia of  &hellip;, 2009 - Wiley Online Library</div><div class="gs_rs">Video is a sequence of consecutive still images, one after another, to represent scenes in <br>motion, which was originally developed for television systems. As bandwidth accessible to <br>average users is increasing, video is becoming one of the fastest-growing types of data on <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:jbnZ-9ljtCUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'jbnZ-9ljtCUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB119" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW119"><a href="https://www.repositorioceme.ufrgs.br/bitstream/handle/10183/3074/000331605.pdf?sequence=1" class=yC1A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ufrgs.br</span><span class="gs_ggsS">ufrgs.br <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="https://www.repositorioceme.ufrgs.br/handle/10183/3074" class=yC19>Um Estudo de um sistema de informaÃ§Ãµes hipermÃ­dia: caso particular da AssemblÃ©ia Legislativa do Rio Grande do Sul</a></h3><div class="gs_a">NG Fischer - 1998 - repositorioceme.ufrgs.br</div><div class="gs_rs">O presente trabalho se insere dentro de uma aplicaÃ§Ã£o real na AssemblÃ©ia Legislativa do <br>Rio Grande do Sul (ALERGS), desenvolvida no Departamento de Sistemas de InformaÃ§Ãµes, <br>aproveitando-se do Sistema PRIMA/VÃ­deoâum sistema de veiculaÃ§Ã£o interna de sinais de <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:dPGELUMxcjYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3923252389989380468&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'dPGELUMxcjYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> ä¸ç§å¿«éç DCT å MPEG-2 å° MPEG-1 ä¸éæ ·è½¬ç ææ¯</h3><div class="gs_a">æä¼ä¸ï¼ è¡å®å¦®ï¼ å­æ¯é³ - 2006 - ä¸­å½å­¦æ¯æåç½ç»åºçæ»åº</div><div class="gs_fl"><a href="/scholar?q=related:9ip9NLByiB8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'9ip9NLByiB8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/92040x/200608/22472008.html" class=yC1B>åºäºç±»ååç±»é´æå¤±çåºæ¯æé æ¹æ³</a></h3><div class="gs_a">æºæï¼ è¡å®å¦® - å¾®çµå­å­¦ä¸è®¡ç®æº, 2006 - cqvip.com</div><div class="gs_rs">ä¸ºäºä¾¿äºå¨ä¸åç»æå±æ¬¡ä¸å¯¹è§é¢è¿è¡æ£ç´¢åæµè§. å¯ä»¥æè§é¢åºååä¸ºä¸åå±æ¬¡çé»è¾åå. <br>é»è¾ååçå±æ¬¡ç±ä¸å°ä¸å¯ä»¥åæåºå, åºæ¯, éå¤´åå¸§. å¶ä¸­åºæ¯æ¯æ¶é´ä¸å·æä¸å®é¡ºåºå³ç³»ç<br>ç¸ä¼¼éå¤´çéå. æç« æåºäºåºäºç±»ååç±»é´æå¤±çåºæ¯æé ç®æ³. é¦åå©ç¨æ¶é´çº¦æåé¢è²<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:X_81QbUOitQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15315069654472720223&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'X_81QbUOitQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB122" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW122"><a href="http://artemis-new.cslab.ece.ntua.gr:8080/jspui/bitstream/123456789/6013/1/PD2009-0046.pdf" class=yC1D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntua.gr</span><span class="gs_ggsS">ntua.gr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://artemis-new.cslab.ece.ntua.gr:8080/jspui/handle/123456789/6013" class=yC1C>Î£Î·Î¼ÎµÎ¹Î¿Î³ÏÎ±ÏÎ¯Î± ÎÎ¹Î½Î·Î¼Î±ÏÎ¿Î³ÏÎ¬ÏÎ¿Ï&quot; directornotation&quot; ÎÎ±Î¹ ÎÎ»Î³Î¿ÏÎ¹Î¸Î¼Î¹ÎºÏÏ ÎÎ½ÏÏÎ¹Î±ÎºÏÏ Î ÏÎ¿Î³ÏÎ±Î¼Î¼Î±ÏÎ¹ÏÎ¼ÏÏ&quot; thoughtorientedprogramming&quot;</a></h3><div class="gs_a">Î ÎÎ¹Î±Î½Î½ÏÏÎ¿ÏÎ»Î¿Ï - 2009 - artemis-new.cslab.ece.ntua.gr</div><div class="gs_rs">Î ÎµÏÎ¯Î»Î·ÏÎ·-Î¤Î¿ Â«DirectorNotationÂ» ÎµÎ¯Î½Î±Î¹ Î¼Î¹Î± ÏÏÎ¼Î²Î¿Î»Î¹ÎºÎ® Î³Î»ÏÏÏÎ± ÏÏÎµÎ´Î¹Î±ÏÎ¼Î­Î½Î· Î³Î¹Î± Î½Î± ÎµÎºÏÏÎ¬ÏÎµÎ¹ ÏÎ¿ <br>ÏÎµÏÎ¹ÎµÏÏÎ¼ÎµÎ½Î¿ Î¼Î¹Î±Ï ÏÎ±Î¹Î½Î¯Î±Ï (ÏÏ ÎºÎ¹Î½Î·Î¼Î±ÏÎ¿Î³ÏÎ±ÏÎ¹ÎºÏ Î­ÏÎ³Î¿), ÏÏÏÏ Î¿Î¹ Î½ÏÏÎµÏ ÏÎ±ÏÎ­ÏÎ¿ÏÎ½ Î¼Î¹Î± Î³Î»ÏÏÏÎ± <br>Î³Î¹Î± ÏÎ·Î½ ÎºÎ±ÏÎ±Î³ÏÎ±ÏÎ® ÏÎ·Ï Î¼Î¿ÏÏÎ¹ÎºÎ®Ï. ÎÏÏÎ¹, Î±ÏÎ¿ÏÎµÎ»ÎµÎ¯ Î¼Î¹Î± Î½Î­Î± ÏÏÎ¿ÏÎ­Î³Î³Î¹ÏÎ· ÏÏÎ· Î´Î·Î¼Î¹Î¿ÏÏÎ³Î¹ÎºÎ® <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:fFStYuZodIYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'fFStYuZodIYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB123" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW123"><a href="http://liris.cnrs.fr/yannick.prie/these/these99.pdf" class=yC1F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cnrs.fr</span><span class="gs_ggsS">cnrs.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://liris.cnrs.fr/yannick.prie/these/these99.pdf" class=yC1E>ÃÃ Ã</a></h3><div class="gs_a">DED LE GRADE - liris.cnrs.fr</div><div class="gs_rs">Mes remerciementd vont tout d&#39;abord aux membres du jury et en particulier aux rapporteurs: <br>je remercie Marie-France Bruandet et Marc Nanard d&#39;avoir bien voulu accepter de rapporter <br>cette thÃ¨se dans des dÃ©lais relativement courts, ainsi que des nombreuses marques d&#39;<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:5z2ovlXsAzIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3603983979841600999&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'5z2ovlXsAzIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md123', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md123" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:5z2ovlXsAzIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
