Total results = 43
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.micc.unifi.it/nunziati/files/civr2006_nunziati.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unifi.it</span><span class="gs_ggsS">unifi.it <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/X56H18RL80X6P4M4.pdf" class=yC0>Video clip matching using mpeg-7 descriptors and edit distance</a></h3><div class="gs_a"><a href="/citations?user=SBm9ZpYAAAAJ&amp;hl=en&amp;oi=sra">M Bertini</a>, <a href="/citations?user=bf2ZrFcAAAAJ&amp;hl=en&amp;oi=sra">A Del Bimbo</a>, <a href="/citations?user=UuE08jUAAAAJ&amp;hl=en&amp;oi=sra">W Nunziati</a> - Image and video retrieval, 2006 - Springer</div><div class="gs_rs">Abstract. Video databases require that clips are represented in a compact and discriminative <br>way, in order to perform efficient matching and retrieval of documents of interest. We present <br>a method to obtain a video representation suitable for this task, and show how to use this <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7647083156503608338&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 45</a> <a href="/scholar?q=related:EjxFZ53lH2oJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/12/4B/RN192552106.html?source=googlescholar" class="gs_nph" class=yC2>BL Direct</a> <a href="/scholar?cluster=7647083156503608338&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'EjxFZ53lH2oJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.123.5212&amp;rep=rep1&amp;type=pdf" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1160939.1160947" class=yC3>A fast shot matching strategy for detecting duplicate sequences in a television stream</a></h3><div class="gs_a">X Naturel, P Gros - Proceedings of the 2nd international workshop on  &hellip;, 2005 - dl.acm.org</div><div class="gs_rs">Abstract This article presents a method for detecting duplicate sequences in a continuous <br>television stream. This is of interest to many applications, including commercials monitoring <br>and video indexing. Repetitions can also be used as a way of structuring television <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11453528189119705795&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 42</a> <a href="/scholar?q=related:wzJnYTQb854J:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11453528189119705795&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'wzJnYTQb854J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4107247" class=yC5>Image signature robust to caption superimposition for video sequence identification</a></h3><div class="gs_a">K Iwamoto, E Kasutani&hellip; - Image Processing, 2006  &hellip;, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper proposes an image signature robust to caption superimposition for video <br>sequence identification. A new image signature which is a set of local features is developed <br>for a high-speed frame-by-frame matching of video sequences. The signature of a frame is <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7489886809574645983&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 27</a> <a href="/scholar?q=related:36CUxF5s8WcJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7489886809574645983&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'36CUxF5s8WcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://lbmedia.ece.ucsb.edu/resources/ref/civr09.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ucsb.edu</span><span class="gs_ggsS">ucsb.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1646449" class=yC6>Video copy detection by fast sequence matching</a></h3><div class="gs_a">MC Yeh, <a href="/citations?user=-SgpaF8AAAAJ&amp;hl=en&amp;oi=sra">KT Cheng</a> - Proceedings of the ACM International Conference  &hellip;, 2009 - dl.acm.org</div><div class="gs_rs">Abstract Sequence matching techniques are effective for comparing two videos. However, <br>existing approaches suffer from demanding computational costs and thus are not scalable <br>for large-scale applications. In this paper we view video copy detection as a local <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16107993121078883153&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 25</a> <a href="/scholar?q=related:UbNXWmYWi98J:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16107993121078883153&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'UbNXWmYWi98J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://dro.deakin.edu.au/eserv/DU:30023258/tjondronegoro-contentbased-2005.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from deakin.edu.au</span><span class="gs_ggsS">deakin.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1101362" class=yC8>Content-based video indexing for sports applications using integrated multi-modal approach</a></h3><div class="gs_a"><a href="/citations?user=_OblDDgAAAAJ&amp;hl=en&amp;oi=sra">D Tjondronegoro</a>, <a href="/citations?user=Vt5edEkAAAAJ&amp;hl=en&amp;oi=sra">YPP Chen</a>, B Pham - Proceedings of the 13th annual  &hellip;, 2005 - dl.acm.org</div><div class="gs_rs">Abstract To sustain an ongoing rapid growth of video information, there is an emerging <br>demand for a sophisticated content-based video indexing system. However, current video <br>indexing solutions are still immature and lack of any standard. This doctoral consists of a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6490305720990925273&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 24</a> <a href="/scholar?q=related:2YFZh6oyEloJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6490305720990925273&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 18 versions</a> <a onclick="return gs_ocit(event,'2YFZh6oyEloJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md4', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md4" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:2YFZh6oyEloJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=15416151159179791011&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://hal.inria.fr/docs/00/00/11/54/PDF/paper.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from inria.fr</span><span class="gs_ggsS">inria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/F417V67462M89067.pdf" class=yCA>Detecting repeats for video structuring</a></h3><div class="gs_a">X Naturel, P Gros - Multimedia Tools and Applications, 2008 - Springer</div><div class="gs_rs">Abstract Television daily produces massive amounts of videos. Digital video is unfortunately <br>an unstructured document in which it is very difficult to find any information. Television <br>streams have however a strong and stable but hidden structure that we want to discover <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14891065714541801155&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 15</a> <a href="/scholar?q=related:wy5DAl-xp84J:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/13/59/RN228573873.html?source=googlescholar" class="gs_nph" class=yCC>BL Direct</a> <a href="/scholar?cluster=14891065714541801155&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'wy5DAl-xp84J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1386375" class=yCD>Clip based video summarization and ranking</a></h3><div class="gs_a">Y Gao, QH Dai - Proceedings of the 2008 international conference on  &hellip;, 2008 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we present a new algorithm for video clip summarization and ranking, <br>which is mainly based on a clip based video similarity measure and the affinity propagation <br>clustering (AP) algorithm. We propose a proportional max-weighted bipartite matching <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8036333654932049436&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 15</a> <a href="/scholar?q=related:HM69fuHKhm8J:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8036333654932049436&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'HM69fuHKhm8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/8k58781wh5664454.pdf" class=yCE>A clustering technique for video copy detection</a></h3><div class="gs_a">N Guil, J GonzÃ¡lez-Linares, J CÃ³zar&hellip; - Pattern Recognition and  &hellip;, 2007 - Springer</div><div class="gs_rs">In this work, a new method for detecting copies of a query video in a videos database is <br>proposed. It includes a new clustering technique that groups frames with similar visual <br>content, maintaining their temporal order. Applying this technique, a keyframe is extracted <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11541693176220462540&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 13</a> <a href="/scholar?q=related:zK0rE8tULKAJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/1D/5A/RN210335211.html?source=googlescholar" class="gs_nph" class=yCF>BL Direct</a> <a href="/scholar?cluster=11541693176220462540&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'zK0rE8tULKAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1666100" class=yC10>Video news classification for automatic content personalization: a genetic algorithm based approach</a></h3><div class="gs_a">MG Manzato, <a href="/citations?user=6lc68RgAAAAJ&amp;hl=en&amp;oi=sra">R Goularte</a> - Proceedings of the 14th Brazilian Symposium  &hellip;, 2008 - dl.acm.org</div><div class="gs_rs">Abstract With the development of content-based multimedia services, the personalization <br>task has become increasingly important. There is a need for semantic information <br>knowledge, extracted from multimedia streams, in order to achieve the benefits of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1746700291121830334&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 8</a> <a href="/scholar?q=related:vlljDamGPRgJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'vlljDamGPRgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0957417409010495" class=yC11>Effective content-based video retrieval using pattern-indexing and matching techniques</a></h3><div class="gs_a">JH Su, YT Huang, HH Yeh, VS Tseng - Expert Systems with Applications, 2010 - Elsevier</div><div class="gs_rs">Recently, multimedia data grows rapidly due to the advanced multimedia capturing devices, <br>such as digital video recorder, mobile camera and so on. Since conventional query-by-text <br>retrieval cannot satisfy users&#39; requirements in finding the desired videos effectively, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2320724708510518206&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 9</a> <a href="/scholar?q=related:vss9oNPeNCAJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2320724708510518206&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'vss9oNPeNCAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://www.cecs.uci.edu/~papers/icme06/pdfs/0001785.pdf" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uci.edu</span><span class="gs_ggsS">uci.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4036967" class=yC12>Learning-based interactive video retrieval system</a></h3><div class="gs_a">CJ Wu, HC Zeng, S Huang, <a href="/citations?user=LlybOXQAAAAJ&amp;hl=en&amp;oi=sra">SH Lai</a>&hellip; - Multimedia and Expo,  &hellip;, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents an interactive video event retrieval system based on improved <br>adaboost learning. This system consists of three main steps. Firstly, a long video sequence <br>is partitioned into several video clips by using a distribution-based approach instead of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18120851319311552082&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 6</a> <a href="/scholar?q=related:Us47O0QyevsJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18120851319311552082&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'Us47O0QyevsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://www.cecs.uci.edu/~papers/icme06/pdfs/0001065.pdf" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uci.edu</span><span class="gs_ggsS">uci.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4036787" class=yC14>Counting of video clip repetitions using a modified bmh algorithm: Preliminary results</a></h3><div class="gs_a">SJF Guimaraes, RKR Coelho&hellip; - Multimedia and Expo,  &hellip;, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this work, we cope with the problem of identifying the number of repetitions of a <br>specific video clip in a target video clip. Generally, the methods that deal with this problem <br>can be subdivided into methods that use:(i) video signatures afterward the step of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10794620492864970956&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 7</a> <a href="/scholar?q=related:zGBeWiUyzpUJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10794620492864970956&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'zGBeWiUyzpUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1509218" class=yC16>Query by shots: Retrieving meaningful events using multiple queries and rough set theory</a></h3><div class="gs_a">K Shirahama, K Uehara - Proceedings of the 9th International Workshop  &hellip;, 2008 - dl.acm.org</div><div class="gs_rs">Abstract In videos, even if events have the same semantic content (eg conversation, battle, <br>chase and so on), they are presented in different ways. So, these events have significantly <br>different properties. For example, one battle event is characterized by a large sound <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3890508457788071558&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 4</a> <a href="/scholar?q=related:hl4cXtTc_TUJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3890508457788071558&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'hl4cXtTc_TUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1562728" class=yC17>A content-based broadcasted sports video retrieval system using multiple modalities: SportBR</a></h3><div class="gs_a">L Huayong, Z Hui - &hellip;  Technology, 2005. CIT 2005. The Fifth  &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, an advanced content-based broadcasted sports video retrieval <br>system, SportBR, is proposed. Its main features include event-based sports video browsing <br>and keyword-based sports video retrieval. The paper first defines the framework of our <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1190730365708184950&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 4</a> <a href="/scholar?q=related:dq1Od_VShhAJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1190730365708184950&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'dq1Od_VShhAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1509217" class=yC18>Efficient content-based video retrieval by mining temporal patterns</a></h3><div class="gs_a">JH Su, YT Huang, VS Tseng - &hellip;  of the 9th International Workshop on  &hellip;, 2008 - dl.acm.org</div><div class="gs_rs">Abstract In recent years, multimedia content processing has become a hot topic with the <br>rapid development of information technology and popularity of World Wide Web. Among the <br>emerging research topics, content-based video retrieval is an attractive and challenging <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2220664872367490089&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 5</a> <a href="/scholar?q=related:KQSnku9i0R4J:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2220664872367490089&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'KQSnku9i0R4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://finishstrike.googlecode.com/svn/arquivo/artigos/nao-lidos/grafo%20por%20objeto3.pdf" class=yC1A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from googlecode.com</span><span class="gs_ggsS">googlecode.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4368177" class=yC19>Bipartite graph matching for video clip localization</a></h3><div class="gs_a">ZKG do Patrocinio, SJF Guimaraes&hellip; - &hellip;  Graphics and Image  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Video clip localization consists in identifying real positions of a specific video clip in <br>a video stream. To cope with this problem, we propose a new approach considering the <br>maximum cardinality matching of a bipartite graph to measure video clip similarity with a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11159585346463023720&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 4</a> <a href="/scholar?q=related:aEKVIL_P3poJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11159585346463023720&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'aEKVIL_P3poJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1527838" class=yC1B>A sports video browsing and retrieval system based on multimodal analysis: SportsBR</a></h3><div class="gs_a">HY Liu, H Zhang - &hellip;  and Cybernetics, 2005. Proceedings of 2005 &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract An advanced sports video browsing and retrieval system based on multimodal <br>analysis, SportsBR, is proposed in this work. Its main features include event-based sports <br>video browsing and keyword-based sports video retrieval. The paper first defines the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16404772856357390601&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 2</a> <a href="/scholar?q=related:CQknJP91qeMJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'CQknJP91qeMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ri"><h3 class="gs_rt"><a href="http://inderscience.metapress.com/index/0j9q452368824814.pdf" class=yC1C>Evaluation of video news classification techniques for automatic content personalisation</a></h3><div class="gs_a">MG Manzato, <a href="/citations?user=tJAsNzYAAAAJ&amp;hl=en&amp;oi=sra">AA Macedo</a>, <a href="/citations?user=6lc68RgAAAAJ&amp;hl=en&amp;oi=sra">R Goularte</a> - International Journal of  &hellip;, 2009 - Inderscience</div><div class="gs_rs">Personalisation tasks require the use of semantic information, extracted from multimedia <br>streams, in order to achieve the benefits of automatic matching user preferences with <br>multimedia content meaning. Text-based classification techniques may be used in closed-<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17206623871651077725&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 2</a> <a href="/scholar?q=related:Xd6EJT81yu4J:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17206623871651077725&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'Xd6EJT81yu4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB18" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW18"><a href="http://lbmedia.ece.ucsb.edu/resources/ref/ITMM.pdf" class=yC1E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ucsb.edu</span><span class="gs_ggsS">ucsb.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5643930" class=yC1D>Fast visual retrieval using accelerated sequence matching</a></h3><div class="gs_a">MC Yeh, <a href="/citations?user=-SgpaF8AAAAJ&amp;hl=en&amp;oi=sra">KT Cheng</a> - Multimedia, IEEE Transactions on, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We present an approach to represent, match, and index various types of visual <br>data, with the primary goal of enabling effective and computationally efficient searches. In <br>this approach, an image/video is represented by an ordered list of feature descriptors. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15228864623161878652&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 4</a> <a href="/scholar?q=related:fKgTVLDLV9MJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15228864623161878652&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'fKgTVLDLV9MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.159.3330&amp;rep=rep1&amp;type=pdf" class=yC20><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.159.3330&amp;rep=rep1&amp;type=pdf" class=yC1F>TRECVID 2008 NOTEBOOK PAPER: interactive search using multiple queries and rough set theory</a></h3><div class="gs_a">A Mizui, K Shirahama, K Uehara - Proc. of TRECVID, 2008 - Citeseer</div><div class="gs_rs">ABSTRACT For the TRECVID2008 submitted runs, cs24 kobe team participated in the <br>interactive search task and we submitted two different runs:â¢ 1 b 1 cs24 kobe2 2: we run the <br>search approach based only on ASR/MT transcripts by using pseudo relevance feedback.<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16486140295847261491&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 2</a> <a href="/scholar?q=related:M7U6c0CJyuQJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16486140295847261491&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'M7U6c0CJyuQJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md19', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md19" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:M7U6c0CJyuQJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB20" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW20"><a href="http://www.lbd.dcc.ufmg.br/colecoes/webmedia/2010/18_webmi_c.pdf" class=yC22><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ufmg.br</span><span class="gs_ggsS">ufmg.br <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.lbd.dcc.ufmg.br/colecoes/webmedia/2010/18_webmi_c.pdf" class=yC21>Identification and analysis of video subsequence using bipartite graph matching</a></h3><div class="gs_a">SJF GuimarÃ£es, ZKG do PatrocÃ­nio Jr - 16th WebMedia Brazilian  &hellip;, 2010 - lbd.dcc.ufmg.br</div><div class="gs_rs">ABSTRACT Subsequence identification consists in identifying real positions of a specific <br>video clip in a video stream together with the operations that may be used to transform the <br>former into a subsequence from the latter. To cope with this problem, we propose a new <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17493697883867763223&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 1</a> <a href="/scholar?q=related:F9LwL4oZxvIJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17493697883867763223&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'F9LwL4oZxvIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md20', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md20" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:F9LwL4oZxvIJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="http://server.cs.ucf.edu/~vision/papers/theses/yun_theses.pdf" class=yC24><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ucf.edu</span><span class="gs_ggsS">ucf.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://server.cs.ucf.edu/~vision/papers/theses/yun_theses.pdf" class=yC23>Video content extraction: Scene segmentation, linking and attention detection</a></h3><div class="gs_a"><a href="/citations?user=tQKD7T8AAAAJ&amp;hl=en&amp;oi=sra">Y Zhai</a> - 2006 - server.cs.ucf.edu</div><div class="gs_rs">Abstract In this fast paced digital age, a vast amount of videos are produced every day, such <br>as movies, TV programs, personal home videos, surveillance video, etc. This places a high <br>demand for effective video data analysis and management techniques. In this dissertation, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9386446955899964095&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 1</a> <a href="/scholar?q=related:v8p2XcZbQ4IJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9386446955899964095&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 17 versions</a> <a onclick="return gs_ocit(event,'v8p2XcZbQ4IJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md21', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md21" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:v8p2XcZbQ4IJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB22" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW22"><a href="http://ivpl.eecs.northwestern.edu/system/files/Liu_Li.pdf" class=yC26><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from northwestern.edu</span><span class="gs_ggsS">northwestern.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://ivpl.eecs.northwestern.edu/system/files/Liu_Li.pdf" class=yC25>In-sequence video duplicate detection with fast point-to-line matching</a></h3><div class="gs_a"><a href="/citations?user=2Fe93n8AAAAJ&amp;hl=en&amp;oi=sra">B Liu</a>, Z Li, <a href="/citations?user=rHagaaIAAAAJ&amp;hl=en&amp;oi=sra">M Wang</a>&hellip; - Proc. IEEE Int. Conf.  &hellip;, 2010 - ivpl.eecs.northwestern.edu</div><div class="gs_rs">ABSTRACT A computational geometry approach is developed to detect video duplicate with <br>mild transformations. We model the video sequence as a trajectory after scaling and <br>projection. Through interpolation and equal curve length sampling, part of the frame points <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18083235794624367593&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 1</a> <a href="/scholar?q=related:6cs2aCWP9PoJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18083235794624367593&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'6cs2aCWP9PoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md22', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md22" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:6cs2aCWP9PoJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ri"><h3 class="gs_rt"><a href="http://gala.gre.ac.uk/4319/" class=yC27>Efficient and effective state-based framework for news video retrieval</a></h3><div class="gs_a">A Zheng, J Ma, X Zhou, B Luo - International Journal of  &hellip;, 2010 - gala.gre.ac.uk</div><div class="gs_rs">In this paper, an efficient and effective framework is proposed for news video retrieval. <br>Firstly, the 64-dimensional colour histogram is extracted as the feature vector. Then the pair <br>quantizer is adopted to transfer the news video retrieval problem into multi-dimensional <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15839962500505065362&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 1</a> <a href="/scholar?q=related:ktcccvjZ0tsJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15839962500505065362&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'ktcccvjZ0tsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md23', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md23" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:ktcccvjZ0tsJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB24" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW24"><a href="http://campus.lostfocus.org/dikshie/computer.org/multimedia-2011-issue-3/05765921.pdf" class=yC29><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from lostfocus.org</span><span class="gs_ggsS">lostfocus.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://campus.lostfocus.org/dikshie/computer.org/multimedia-2011-issue-3/05765921.pdf" class=yC28>Real-Time Video Copy-Location Detection in Large-Scale Repositories</a></h3><div class="gs_a"><a href="/citations?user=2Fe93n8AAAAJ&amp;hl=en&amp;oi=sra">B Liu</a>, Z Li, <a href="/citations?user=cvgKxDQAAAAJ&amp;hl=en&amp;oi=sra">L Yang</a>, <a href="/citations?user=rHagaaIAAAAJ&amp;hl=en&amp;oi=sra">M Wang</a>, X Tian - extraction, 2011 - campus.lostfocus.org</div><div class="gs_rs">Video copy-detection, the purpose of which is to find a video copy in a repository, is <br>important for many applications. 1-3 Our research focuses on locating video clips that are <br>copied but maintain frame correspondence. Although this issue has been investigated for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5045497114331945316&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 2</a> <a href="/scholar?q=related:ZJkDr-Q0BUYJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5045497114331945316&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'ZJkDr-Q0BUYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md24', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md24" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:ZJkDr-Q0BUYJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4566377" class=yC2A>A method of news caption location based on C-mean clustering and edge detection</a></h3><div class="gs_a">Z Lan, J Zhao - Image and Signal Processing, 2008. CISP&#39;08.  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Using edge detection to do news video retrieval may cause the caption location <br>inaccurately. A method of news caption location is proposed in the paper, using C-mean <br>clustering to extract the caption, then using vertical differential coefficient and median filter <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=583064254700616693&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 1</a> <a href="/scholar?q=related:9Xuottl1FwgJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=583064254700616693&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'9Xuottl1FwgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/90911a/200902/29749574.html" class=yC2B>åºäºåå®¹çè§é¢çæ®µæ£ç´¢ææ¯ç ç©¶</a></h3><div class="gs_a">èµµäºç´ï¼ æ±èº - ç°ä»£è®¡ç®æº: ä¸åæç, 2009 - cqvip.com</div><div class="gs_rs">æ·±å¥åæåæ»ç»äºçæ®µæ£ç´¢æ¹æ³çå³é®ææ¯, ä¸»è¦åæ¬è§é¢çæ®µçè¡¨è¾¾, çæ®µçç¸ä¼¼æ§åº¦é, <br>ç¸ä¼¼çæ®µçèªå¨åå²åç¸ä¼¼çæ®µçæåº, ä»ç»ç®åå·²æççæ®µæ£ç´¢æ¹æ³åå¶åèªçä¼ç¼ºç¹, <br>æåºä¸äºè¿ä¸é¢åçé¾ç¹åå¼å¾è¿ä¸æ­¥ç ç©¶çé®é¢.</div><div class="gs_fl"><a href="/scholar?cites=7632784175061201178&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 1</a> <a href="/scholar?q=related:GvG-WcQY7WkJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7632784175061201178&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'GvG-WcQY7WkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5542904" class=yC2C>The optimal temporal common subsequence</a></h3><div class="gs_a">A Zheng, X Zhou, J Ma&hellip; - Software Engineering and  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Based on a formal characterization of time-series and state-sequences, this paper <br>proposes a new algorithm named the Optimal Temporal Common Subsequence (OTCS) to <br>measure the similarity between state-sequences. Distinguishing from the conventional <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:cba-H9dHvK4J:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12591017647497197169&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'cba-H9dHvK4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6120716" class=yC2D>Semantic Video Retrieval by Integrating Concept-and Content-Aware Mining</a></h3><div class="gs_a">BW Wang, JH Su, CL Chou&hellip; - &hellip;  and Applications of  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Video retrieval has been a hot topic due to the prevalence of video capturing <br>devices and media-sharing services such as YouTube. Until now, few past studies has <br>focused on querying the videos by images due to the semantic gap between images and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ZNP4NSyyllkJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6455543018835989348&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'ZNP4NSyyllkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Far East Journal of Experimental and Theoretical Artificial Intelligence</h3><div class="gs_a">ZJ Lee, FK Chang</div><div class="gs_fl"><a href="/scholar?q=related:NhBzPb7iId0J:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15934266263316140086&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'NhBzPb7iId0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB30" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW30"><a href="http://eprints.qut.edu.au/archive/00002199/01/PhDThesis_Tjondronegoro.pdf" class=yC2F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from qut.edu.au</span><span class="gs_ggsS">qut.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://eprints.qut.edu.au/archive/00002199" class=yC2E>PhD Thesis:&quot; Content-based Video Indexing for Sports Applications using Multi-modal approach&quot;</a></h3><div class="gs_a"><a href="/citations?user=_OblDDgAAAAJ&amp;hl=en&amp;oi=sra">DW Tjondronegoro</a> - 2005 - eprints.qut.edu.au</div><div class="gs_rs">Triggered by technology innovations, there has been a huge increase in the utilization of <br>video, as one of the most preferred types of media due to its content richness, for many <br>significant applications. To sustain an ongoing rapid growth of video information, there is <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:k7wHTZYfh10J:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6739390097781144723&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'k7wHTZYfh10J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ri"><h3 class="gs_rt"><a href="http://tkuir.lib.tku.edu.tw/dspace/handle/987654321/55116" class=yC30>An Adaptive Video Shot Boundary Detection Method and Application to Soccer Video</a></h3><div class="gs_a">S Yen, W Tsai, H Lin - 2009 - tkuir.lib.tku.edu.tw</div><div class="gs_rs">This paper presents a shot boundary detection algorithm using morphological opening with <br>structuring elements consistent to the acute level of a shot. By this way, the difficulty on <br>indistinctness of gradual transitions is solved. The algorithm is applied to soccer video and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:HIwXVjMKBXgJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8648329875038899228&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'HIwXVjMKBXgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB32" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW32"><a href="http://dspace.mit.edu/bitstream/handle/1721.1/46523/413972487.pdf?sequence=1" class=yC32><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dspace.mit.edu/handle/1721.1/46523" class=yC31>Low-latency network coding for streaming video multicast</a></h3><div class="gs_a">KK Tay - 2008 - dspace.mit.edu</div><div class="gs_rs">Network coding has been successfully employed to increase throughput for data transfers. <br>However, coding inherently introduces packet inter-dependencies and adds decoding <br>delays which increase latency. This makes it difficult to apply network coding to real-time <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:vJbOWgmzaW4J:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7956087069486257852&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'vJbOWgmzaW4J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md32', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md32" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:vJbOWgmzaW4J:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=14463184245653277240&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:367"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/T7K141K02728174G.pdf" class=yC33>Identification of video subsequence using bipartite graph matching</a></h3><div class="gs_a">SJF GuimarÃ£es, ZKG do PatrocÃ­nio - Journal of the Brazilian Computer  &hellip;, 2011 - Springer</div><div class="gs_rs">Abstract Subsequence identification consists of identifying real positions of a specific video <br>clip in a video stream together with the operations that may be used to transform the former <br>into a subsequence from the latter. To cope with this problem, we propose a new <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1177396498437034925&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 1</a> <a href="/scholar?q=related:rdMgkeDzVhAJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1177396498437034925&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'rdMgkeDzVhAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:366"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB34" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW34"><a href="http://www.iitg.ernet.in/iciss2012/pdf/Tutorials/Sanjoy_Saha.pdf" class=yC35><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from iitg.ernet.in</span><span class="gs_ggsS">iitg.ernet.in <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.iitg.ernet.in/iciss2012/pdf/Tutorials/Sanjoy_Saha.pdf" class=yC34>Content Based Video Copy Detection: Issues and Practices</a></h3><div class="gs_a">SK Saha - iitg.ernet.in</div><div class="gs_rs">With the rapid development in the field of multimedia technology, it has become easier to <br>access and store video data of huge volume. It is well reflected in the availability of such <br>data on various sites like video blogs and Web-TV. Sharing and distribution of video over <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'KiTOqt9KgyMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md34', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md34" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:KiTOqt9KgyMJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:365"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5209253" class=yC36>News Video Clip Retrieval Based on Topic Caption Text and Audio Information</a></h3><div class="gs_a">Z Yaqin, Z Jiaqiang, Z Hongping - Intelligent Systems, 2009.  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents a novel scheme for news video structure indexing and news <br>story clip retrieving. Instead of using low-level features, the method is built upon the <br>combination of topic content and visual features. First of all, a new method of topic caption <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:7-Aor3k6FrgJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13264854046770520303&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'7-Aor3k6FrgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:364"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5718621" class=yC37>Discovering Inconsistency in Multimedia News Based on a Material-Opinion Model</a></h3><div class="gs_a">L Xu, T Yumoto, S Aoki, Q Ma&hellip; - &hellip;  (HICSS), 2011 44th  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The advantages of the multimedia make the video news presented believable and <br>impressed to the viewers when the personal opinions and ideological perspectives hidden <br>in the contents still cause the effect. To reduce the risk of the misleading, based on a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:8wKvuvii41YJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6261027096142742259&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'8wKvuvii41YJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:363"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB37" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW37"><a href="http://ir.lib.nthu.edu.tw/bitstream/987654321/18035/1/2030227030019.pdf" class=yC39><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nthu.edu.tw</span><span class="gs_ggsS">nthu.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ir.lib.nthu.edu.tw/handle/987654321/18035" class=yC38>Learning-Based Interactive Video Retrieval System</a></h3><div class="gs_a">CJWHC Zeng, SHHSH Lai, WH Wang - ir.lib.nthu.edu.tw</div><div class="gs_rs">This paper presents an interactive video event retrieval system based on improved adaboost <br>learning. This system consists of three main steps. Firstly, a long video sequence is <br>partitioned into several video clips by using a distribution-based approach instead of <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:L8-q0axbJFIJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5918956608081809199&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'L8-q0axbJFIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:362"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4284767" class=yC3A>An Error-Tolerant Video Retrieval Method Based on the Shot Composition Sequence in a Scene</a></h3><div class="gs_a">I Kondo, S Shimada, M Morimoto - Multimedia and Expo, 2007  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents an error-tolerant video retrieval method based on the shot <br>composition sequence in a scene. Conventional video players in the home can not access <br>interesting scenes directly because they offer only play, fast-forward, and rewind. What is <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:26lS5N6HRWgJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7513560944720652763&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'26lS5N6HRWgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:361"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5583860" class=yC3B>Efficient video duplicate detection via compact curve matching</a></h3><div class="gs_a"><a href="/citations?user=2Fe93n8AAAAJ&amp;hl=en&amp;oi=sra">B Liu</a>, Z Li, <a href="/citations?user=rHagaaIAAAAJ&amp;hl=en&amp;oi=sra">M Wang</a> - Multimedia and Expo (ICME), 2010 IEEE  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Efficient video duplicate detection is of great practical significance in many <br>applications. In this paper, we propose a computational geometry approach for video <br>duplicate detection. In the proposed scheme, video clips are modeled as curves in a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Q4Bm8jmrs4cJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9778347481319768131&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'Q4Bm8jmrs4cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:360"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/J595H473086T0057.pdf" class=yC3C>Compact Descriptor for Video Sequence Matching in the Context of Large Scale 3D Reconstruction</a></h3><div class="gs_a">R Parys, F Liefers, <a href="/citations?user=0uEkSPQAAAAJ&amp;hl=en&amp;oi=sra">A Schilling</a> - Multimedia and Internet Systems: Theory and  &hellip; - Springer</div><div class="gs_rs">One of the key problems in the large scale reconstruction of 3D scenes from images is how <br>to efficiently compute image relations in large databases. Finding images depicting the <br>same 3D geometry is the pre-requisite for camera calibration and 3D reconstruction. In <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11647843288184364248&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 1</a> <a href="/scholar?q=related:2Jyl98FzpaEJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'2Jyl98FzpaEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:359"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB41" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW41"><a href="http://www.ceaj.org/Jweb_gcyyy/EN/article/downloadArticleFile.do?attachType=PDF&amp;id=23784" class=yC3E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ceaj.org</span><span class="gs_ggsS">ceaj.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ceaj.org/Jweb_gcyyy/EN/article/downloadArticleFile.do?attachType=PDF&amp;id=23784" class=yC3D>åºäºé«æç²¾ç¡®çæå¤§å¬å±å­åºåçè§é¢çæ®µå¹é</a></h3><div class="gs_a">å¼ çè£ï¼ è°¢æ§ - Computer Engineering and Applications, 2010 - ceaj.org</div><div class="gs_rs">æè¦: ä¸ºè§é¢åºåå¹éæåºä¸ä¸ªé«æç²¾ç¡®çæå¤§å¬å±å­åºå(Efficient and Effective Longest <br>Common Subsequence, EELCS) ç®æ³. é¦å, å©ç¨ç¢ééå(Vector Quantization, VQ) <br>å°å¤ç»´æå¤§å¬å±å­åºåç®æ³(Multi-dimensional LCS, MLCS) ä¸­åç´ å¯¹å¹éè¿ç¨ä¸­çå®éè·ç¦»<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:7kYmNKLfbvwJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18189721832748631790&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'7kYmNKLfbvwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md41', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md41" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:7kYmNKLfbvwJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:358"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/93416x/201005/33909807.html" class=yC3F>åºäºå­å¹çæ°é»è§é¢æ£ç´¢ç®æ³</a></h3><div class="gs_a">èç§åï¼ æ¢æ°¸å¿  - å¹¿æ­ä¸çµè§ææ¯, 2010 - cqvip.com</div><div class="gs_rs">æ°é»è§é¢ä¸­çå­å¹æ¯æ°é»è§é¢æ°æ®ä¸­çåºæä¿¡æ¯. å©ç¨æ°é»å­å¹è¿è¡è§é¢æ£ç´¢å·²ç»æä¸ºæ°é»è§é¢<br>æ£ç´¢çä¸»è¦æ¹æ³. æç« å°C-åå¼èç±»åå²ç®æ³åºç¨äºè§é¢å­å¹çåå², å©ç¨çºµåå¾®ååä¸­å¼æ»¤æ³¢<br>å®ç°å¨å°½å¯è½å®æ´ä¿çå­å¹æ¡åç´è¾¹ç¼ä¿¡æ¯çåæ¶æå¤§å°åå¼±å¾åèæ¯åå¤§é¨åçåªå£°å¹²æ°, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:F3eMfhlpMqsJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12336037887539443479&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'F3eMfhlpMqsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
