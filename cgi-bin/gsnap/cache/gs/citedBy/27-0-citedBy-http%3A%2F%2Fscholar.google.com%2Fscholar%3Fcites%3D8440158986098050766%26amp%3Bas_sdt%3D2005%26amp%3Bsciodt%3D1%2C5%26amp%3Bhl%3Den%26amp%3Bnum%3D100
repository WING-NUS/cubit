Total results = 27
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="https://www1.comp.nus.edu.sg/~leews/publications/rss08.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="https://www1.comp.nus.edu.sg/~leews/publications/rss08.pdf" class=yC0>SARSOP: Efficient point-based POMDP planning by approximating optimally reachable belief spaces</a></h3><div class="gs_a"><a href="/citations?user=JkjFXbAAAAAJ&amp;hl=en&amp;oi=sra">H Kurniawati</a>, <a href="/citations?user=S9LHLKEAAAAJ&amp;hl=en&amp;oi=sra">D Hsu</a>, <a href="/citations?user=8PCrLgwAAAAJ&amp;hl=en&amp;oi=sra">WS Lee</a> - Proc. Robotics: Science and  &hellip;, 2008 - comp.nus.edu.sg</div><div class="gs_rs">AbstractâMotion planning in uncertain and dynamic environments is an essential capability <br>for autonomous robots. Partially observable Markov decision processes (POMDPs) provide <br>a principled mathematical framework for solving such problems, but they are often <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8180099410284475373&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 152</a> <a href="/scholar?q=related:7XNj2RKNhXEJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8180099410284475373&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 28 versions</a> <a onclick="return gs_ocit(event,'7XNj2RKNhXEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md0', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md0" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:7XNj2RKNhXEJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://typesetter.ucoz.com/_ld/0/1_2Dq.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ucoz.com</span><span class="gs_ggsS">ucoz.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ijr.sagepub.com/content/29/8/1053.short" class=yC2>Planning under uncertainty for robotic tasks with mixed observability</a></h3><div class="gs_a">SCW Ong, <a href="/citations?user=wZy6aw0AAAAJ&amp;hl=en&amp;oi=sra">SW Png</a>, <a href="/citations?user=S9LHLKEAAAAJ&amp;hl=en&amp;oi=sra">D Hsu</a>, <a href="/citations?user=8PCrLgwAAAAJ&amp;hl=en&amp;oi=sra">WS Lee</a> - The International Journal of  &hellip;, 2010 - ijr.sagepub.com</div><div class="gs_rs">Abstract Partially observable Markov decision processes (POMDPs) provide a principled, <br>general framework for robot motion planning in uncertain and dynamic environments. They <br>have been applied to various robotic tasks. However, solving POMDPs exactly is <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6039740786761352353&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 48</a> <a href="/scholar?q=related:oURZ4j540VMJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6039740786761352353&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 23 versions</a> <a onclick="return gs_ocit(event,'oURZ4j540VMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www.comp.nus.edu/~leews/publications/icra08.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu</span><span class="gs_ggsS">nus.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4543611" class=yC4>A point-based POMDP planner for target tracking</a></h3><div class="gs_a"><a href="/citations?user=S9LHLKEAAAAJ&amp;hl=en&amp;oi=sra">D Hsu</a>, <a href="/citations?user=8PCrLgwAAAAJ&amp;hl=en&amp;oi=sra">WS Lee</a>, N Rong - Robotics and Automation, 2008.  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Target tracking has two variants that are often studied independently with different <br>approaches: target searching requires a robot to find a target initially not visible, and target <br>following requires a robot to maintain visibility on a target initially visible. In this work, we <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16753723891220523405&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 32</a> <a href="/scholar?q=related:jaksMR0vgegJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16753723891220523405&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 19 versions</a> <a onclick="return gs_ocit(event,'jaksMR0vgegJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://bigbird.comp.nus.edu.sg/~hannakur/papers/ijrr10_migs.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ijr.sagepub.com/content/30/3/308.short" class=yC6>Motion planning under uncertainty for robotic tasks with long time horizons</a></h3><div class="gs_a"><a href="/citations?user=JkjFXbAAAAAJ&amp;hl=en&amp;oi=sra">H Kurniawati</a>, Y Du, <a href="/citations?user=S9LHLKEAAAAJ&amp;hl=en&amp;oi=sra">D Hsu</a>, <a href="/citations?user=8PCrLgwAAAAJ&amp;hl=en&amp;oi=sra">WS Lee</a> - The International Journal of  &hellip;, 2011 - ijr.sagepub.com</div><div class="gs_rs">Abstract Motion planning with imperfect state information is a crucial capability for <br>autonomous robots to operate reliably in uncertain and dynamic environments. Partially <br>observable Markov decision processes (POMDPs) provide a principled general <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11769708948916864549&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 25</a> <a href="/scholar?q=related:JQbtMe5nVqMJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11769708948916864549&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 36 versions</a> <a onclick="return gs_ocit(event,'JQbtMe5nVqMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://eprints.pascal-network.org/archive/00007408/01/olop.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from pascal-network.org</span><span class="gs_ggsS">pascal-network.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://eprints.pascal-network.org/archive/00007408/" class=yC8>Open loop optimistic planning</a></h3><div class="gs_a"><a href="/citations?user=V2Y1L4sAAAAJ&amp;hl=en&amp;oi=sra">S Bubeck</a>, <a href="/citations?user=OvKEnVwAAAAJ&amp;hl=en&amp;oi=sra">R Munos</a> - 2010 - eprints.pascal-network.org</div><div class="gs_rs">Abstract We consider the problem of planning in a stochastic and discounted environment <br>with a limited numerical budget. More precisely, we investigate strategies exploring the set <br>of possible sequences of actions, so that, once all available numerical resources (eg CPU <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16916794687409573616&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 16</a> <a href="/scholar?q=related:8E5DoSOHxOoJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16916794687409573616&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 20 versions</a> <a onclick="return gs_ocit(event,'8E5DoSOHxOoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://arxiv.org/pdf/1205.2659" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arxiv.org</span><span class="gs_ggsS">arxiv.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1795114.1795122" class=yCA>Deterministic POMDPs revisited</a></h3><div class="gs_a"><a href="/citations?user=fyzG5LQAAAAJ&amp;hl=en&amp;oi=sra">B Bonet</a> - Proceedings of the Twenty-Fifth Conference on  &hellip;, 2009 - dl.acm.org</div><div class="gs_rs">Abstract We study a subclass of POMDPs, called Deterministic POMDPs, that is <br>characterized by deterministic actions and observations. These models do not provide the <br>same generality of POMDPs yet they capture a number of interesting and challenging <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11948201767398962522&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 10</a> <a href="/scholar?q=related:WnWCAjSK0KUJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11948201767398962522&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'WnWCAjSK0KUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://dspace.mit.edu/openaccess-disseminate/1721.1/61341" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dspace.mit.edu/handle/1721.1/61341" class=yCC>Collision avoidance for unmanned aircraft using Markov decision processes</a></h3><div class="gs_a"><a href="/citations?user=4b2I74MAAAAJ&amp;hl=en&amp;oi=sra">S Temizer</a>, MJ Kochenderfer, LP Kaelbling&hellip; - 2010 - dspace.mit.edu</div><div class="gs_rs">Before unmanned aircraft can fly safely in civil airspace, robust airborne collision avoidance <br>systems must be developed. Instead of hand-crafting a collision avoidance algorithm for <br>every combination of sensor and aircraft con guration, we investigate the automatic <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3668851976713193092&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 10</a> <a href="/scholar?q=related:hMZ6NW9h6jIJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3668851976713193092&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'hMZ6NW9h6jIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/p3366g21n2862818.pdf" class=yCE>A sampling hyperbelief optimization technique for stochastic systems</a></h3><div class="gs_a">J Davidson, <a href="/citations?user=-JPZ21IAAAAJ&amp;hl=en&amp;oi=sra">S Hutchinson</a> - Algorithmic Foundation of Robotics VIII, 2009 - Springer</div><div class="gs_rs">Uncertainty plays a dramatic role not only on the quality of the optimal solution of POMDP <br>system, but also on the computational complexity of finding the optimal solution, with a worst <br>case running time that is exponential in the length of the time horizon for the exact solution<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3213896025248320588&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 6</a> <a href="/scholar?q=related:TEz3MWgNmiwJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3213896025248320588&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'TEz3MWgNmiwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://cmsassets.comp.nus.edu.sg/~leews/publications/wafr10.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/T354565W23354206.pdf" class=yCF>Monte Carlo value iteration for continuous-state POMDPs</a></h3><div class="gs_a"><a href="/citations?user=ho595lUAAAAJ&amp;hl=en&amp;oi=sra">H Bai</a>, <a href="/citations?user=S9LHLKEAAAAJ&amp;hl=en&amp;oi=sra">D Hsu</a>, <a href="/citations?user=8PCrLgwAAAAJ&amp;hl=en&amp;oi=sra">W Lee</a>, V Ngo - Algorithmic Foundations of Robotics IX, 2011 - Springer</div><div class="gs_rs">Partially observable Markov decision processes (POMDPs) have been successfully applied <br>to various robot motion planning tasks under uncertainty. However, most existing POMDP <br>algorithms assume a discrete state space, while the natural state space of a robot is often <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5253360281358716420&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 7</a> <a href="/scholar?q=related:BE6Ip1ev50gJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5253360281358716420&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 18 versions</a> <a onclick="return gs_ocit(event,'BE6Ip1ev50gJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://hal.archives-ouvertes.fr/docs/00/53/55/59/PDF/ictai10.pdf" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5671411" class=yC11>A closer look at MOMDPs</a></h3><div class="gs_a"><a href="/citations?user=52foGUkAAAAJ&amp;hl=en&amp;oi=sra">M Araya-LÃ³pez</a>, V Thomas, O Buffet&hellip; - Tools with Artificial  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The difficulties encountered in sequential decision-making problems under <br>uncertainty are often linked to the large size of the state space. Exploiting the structure of the <br>problem, for example by employing a factored representation, is usually an efficient <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1277154956140805618&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 5</a> <a href="/scholar?q=related:8v3me6pduREJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1277154956140805618&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'8v3me6pduREJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://www-cvr.ai.uiuc.edu/~seth/ResPages/pdfs/icra10a.pdf" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uiuc.edu</span><span class="gs_ggsS">uiuc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5509494" class=yC13>Exploiting domain knowledge in planning for uncertain robot systems modeled as POMDPs</a></h3><div class="gs_a"><a href="/citations?user=BDgbhmEAAAAJ&amp;hl=en&amp;oi=sra">S Candido</a>, J Davidson&hellip; - Robotics and Automation ( &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We propose a planning algorithm that allows user-supplied domain knowledge to <br>be exploited in the synthesis of information feedback policies for systems modeled as <br>partially observable Markov decision processes (POMDPs). POMDP models, which are <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1908798138939759472&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 4</a> <a href="/scholar?q=related:cFtuS8tpfRoJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1908798138939759472&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'cFtuS8tpfRoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://dspace.mit.edu/bitstream/handle/1721.1/64487/727063332.pdf?sequence=1" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dspace.mit.edu/handle/1721.1/64487" class=yC15>Planning under uncertainty for dynamic collision avoidance</a></h3><div class="gs_a"><a href="/citations?user=4b2I74MAAAAJ&amp;hl=en&amp;oi=sra">S Temizer</a> - 2011 - dspace.mit.edu</div><div class="gs_rs">We approach dynamic collision avoidance problem from the perspective of designing <br>collision avoidance systems for unmanned aerial vehicles. Before unmanned aircraft can fly <br>safely in civil airspace, robust airborne collision avoidance systems must be developed. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16640102387310719042&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 3</a> <a href="/scholar?q=related:QvDITfWE7eYJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16640102387310719042&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'QvDITfWE7eYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md11', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md11" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:QvDITfWE7eYJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=16819422701663093285&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/ft_gateway.cfm?id=2133623&amp;ftid=1128026&amp;dwn=1" class=yC17>Quantitative access control with partially-observable Markov decision processes</a></h3><div class="gs_a">F Martinelli, <a href="/citations?user=9VIn7xoAAAAJ&amp;hl=en&amp;oi=sra">C Morisset</a> - Proceedings of the second ACM conference on  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract This paper presents a novel access control framework reducing the access control <br>problem to a traditional decision problem, thus allowing a policy designer to reuse tools and <br>techniques from the decision theory. We propose here to express, within a single <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8747879879621086691&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 4</a> <a href="/scholar?q=related:4w2a-ma2ZnkJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'4w2a-ma2ZnkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://tel.archives-ouvertes.fr/docs/00/55/14/01/PDF/manuscrit_these_SarahFilippi_depotlegal.pdf" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://tel.archives-ouvertes.fr/tel-00551401/" class=yC18>StratÃ©gies optimistes en apprentissage par renforcement</a></h3><div class="gs_a">S Filippi - 2010 - tel.archives-ouvertes.fr</div><div class="gs_rs">Cette thÃ¨se a Ã©tÃ© effectuÃ©e au sein du Laboratoire Traitement et Communication de <br>l&#39;Information (LTCI), une UnitÃ© Mixte de Recherche du CNRS et de TÃ©lÃ©com ParisTech. Elle <br>a Ã©tÃ© financÃ©e par Orange Labs dans le cadre d&#39;un contrat de recherche externe portant <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18183325068027317574&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 2</a> <a href="/scholar?q=related:Rk05W88lWPwJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18183325068027317574&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'Rk05W88lWPwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://home.ustc.edu.cn/~zzz/download/ZhangLittmanChen-AAAI2012.pdf" class=yC1B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ustc.edu.cn</span><span class="gs_ggsS">ustc.edu.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/download/4906/5343" class=yC1A>Covering Number as a Complexity Measure for POMDP Planning and Learning</a></h3><div class="gs_a">Z Zhang, <a href="/citations?user=Jj00ksMAAAAJ&amp;hl=en&amp;oi=sra">M Littman</a>, X Chen - Proceedings of the Twenty-Sixth AAAI  &hellip;, 2012 - aaai.org</div><div class="gs_rs">Abstract Finding a meaningful way of characterizing the difficulty of partially observable <br>Markov decision processes (POMDPs) is a core theoretical problem in POMDP research. <br>State-space size is often used as a proxy for POMDP difficulty, but it is a weak metric at <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2484594352663288298&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 1</a> <a href="/scholar?q=related:6tlvWWYNeyIJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2484594352663288298&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'6tlvWWYNeyIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6406602" class=yC1C>Monte Carlo Tree Search for Bayesian Reinforcement Learning</a></h3><div class="gs_a">NA Vien, W Ertel - Machine Learning and Applications (ICMLA), &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Bayesian model-based reinforcement learning can be formulated as a partially <br>observable Markov decision process (POMDP) to provide a principled framework for <br>optimally balancing exploitation and exploration. Then, a POMDP solver can be used to <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'K37QLCDwle4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="https://www.ideals.illinois.edu/bitstream/handle/2142/34400/Davidson_James.pdf?sequence=1" class=yC1E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from illinois.edu</span><span class="gs_ggsS">illinois.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="https://www.ideals.illinois.edu/handle/2142/34400" class=yC1D>Exploiting insensitivity in stochastic systems to learn approximately optimal policies</a></h3><div class="gs_a"><a href="/citations?user=-JPZ21IAAAAJ&amp;hl=en&amp;oi=sra">S Hutchinson</a>, E Amir, M Raginsky, E Zhou - 2012 - ideals.illinois.edu</div><div class="gs_rs">Abstract: How does uncertainty affect a robot when attempting to generate a control policy to <br>achieve some objective? How sensitive is the obtained control policy to perturbations? <br>These are the central questions addressed in this dissertation. For most real-world robotic <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:W4uwNc16GnAJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'W4uwNc16GnAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://pratikac.scripts.mit.edu/wordpress/wp-content/uploads/sm_thesis.pdf" class=yC20><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://pratikac.scripts.mit.edu/wordpress/wp-content/uploads/sm_thesis.pdf" class=yC1F>Incremental Sampling based Algorithms for State Estimation</a></h3><div class="gs_a"><a href="/citations?user=c_z5hWEAAAAJ&amp;hl=en&amp;oi=sra">P Chaudhari</a> - 2012 - pratikac.scripts.mit.edu</div><div class="gs_rs">Abstract Perception is a crucial aspect of the operation of autonomous vehicles. With a <br>multitude of different sources of sensor data, it becomes important to have algorithms which <br>can process the available information quickly and provide a timely solution. Also, an <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:f5rvRhEXgL8J:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13799054621235190399&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'f5rvRhEXgL8J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md17', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md17" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:f5rvRhEXgL8J:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB18" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW18"><a href="http://www.nus.edu.sg/nurop/2009/SoC/DuYanzhu(U053705R)_Improving_POMDP_Solver_Performance.pdf" class=yC22><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.nus.edu.sg/nurop/2009/SoC/DuYanzhu(U053705R)_Improving_POMDP_Solver_Performance.pdf" class=yC21>IMPROVING POMDP SOLVER PERFORMANCE</a></h3><div class="gs_a">DU YANZHU, D HSU - nus.edu.sg</div><div class="gs_rs">ABSTRACT POMDP can model a wide range of real world problem. However POMDP <br>solver&#39;s performance is the bottleneck that limits its real world application. Currently leading <br>POMDP solver ZMDP is used as the code base for this project. This project improves the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:IX3iaSfSTI0J:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'IX3iaSfSTI0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md18', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md18" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:IX3iaSfSTI0J:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="https://www.comp.nus.edu.sg/~leews/publications/rss09.pdf" class=yC24><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="https://www.comp.nus.edu.sg/~leews/publications/rss09.pdf" class=yC23>POMDPs for Robotic Tasks with Mixed Observability</a></h3><div class="gs_a"><a href="/citations?user=wZy6aw0AAAAJ&amp;hl=en&amp;oi=sra">SCWOSW Png</a>, DHWS Lee - comp.nus.edu.sg</div><div class="gs_rs">AbstractâPartially observable Markov decision processes (POMDPs) provide a principled <br>mathematical framework for motion planning of autonomous robots in uncertain and <br>dynamic environments. They have been successfully applied to various robotic tasks, but <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:7GNDdaNJREoJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5351483223618839532&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'7GNDdaNJREoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md19', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md19" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:7GNDdaNJREoJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB20" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW20"><a href="http://sites.google.com/site/anrexplora/deliverables/report_task3.pdf" class=yC26><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from google.com</span><span class="gs_ggsS">google.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://sites.google.com/site/anrexplora/deliverables/report_task3.pdf" class=yC25>Report on Task 3: Fondations thÃ©oriques des bandits hiÃ©rarchiques</a></h3><div class="gs_a"><a href="/citations?user=OvKEnVwAAAAJ&amp;hl=en&amp;oi=sra">R Munos</a> - 2011 - sites.google.com</div><div class="gs_rs">Abstract We consider a generalization of stochastic bandit problems where the set of arms, <br>X, is allowed to be a generic topological space. We constraint the mean-payoff function with <br>a dissimilarity function over X in a way that is more general than Lipschitz. We construct an <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:m-_sgbGxyswJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'m-_sgbGxyswJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md20', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md20" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:m-_sgbGxyswJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="http://upcommons.upc.edu/e-prints/bitstream/2117/8686/1/guillem.pdf" class=yC28><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from upc.edu</span><span class="gs_ggsS">upc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://upcommons.upc.edu/handle/2117/8686" class=yC27>Planning stacking operations with an unknown number of objects</a></h3><div class="gs_a">L Trilla Romero, <a href="/citations?user=-ndXYyoAAAAJ&amp;hl=en&amp;oi=sra">G AlenyÃ  Ribas</a> - 2010 - upcommons.upc.edu</div><div class="gs_rs">A planning framework is proposed for the task of cleaning a table and stack an unknown <br>number of objects of different size on a tray. We propose to divide this problem in two, and <br>combine two different planning algorithms. One, plan hand motions in the euclidean <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:xtOmkw3QiVEJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5875455945611858886&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'xtOmkw3QiVEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB22" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW22"><a href="http://infosci.otago.ac.nz/assets/ispg/IS-PostGradDay-2011/ISPG-Day-2011-proceedings.pdf#page=44" class=yC2A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from otago.ac.nz</span><span class="gs_ggsS">otago.ac.nz <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://infosci.otago.ac.nz/assets/ispg/IS-PostGradDay-2011/ISPG-Day-2011-proceedings.pdf#page=44" class=yC29>Lifelong Reinforcement Learning over Life-logging Data</a></h3><div class="gs_a">T Kolasa, <a href="/citations?user=whY65YMAAAAJ&amp;hl=en&amp;oi=sra">M Nowostawski</a> - Postgraduate Day, 2011 - infosci.otago.ac.nz</div><div class="gs_rs">ABSTRACT The purpose of this paper is to present an early stage of PhD work on lifelong <br>reinforcement learning and life-logging. Recording and storing data about the past has <br>always been the key to understand the present and only way to try to grasp the future. With <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:N-xWn8RO8YAJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9291294112635874359&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'N-xWn8RO8YAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md22', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md22" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:N-xWn8RO8YAJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB23" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW23"><a href="http://bigbird.comp.nus.edu.sg/~hannakur/papers/auro11_gcs.pdf" class=yC2C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/a04672558021t177.pdf" class=yC2B>Global motion planning under uncertain motion, sensing, and environment map</a></h3><div class="gs_a"><a href="/citations?user=JkjFXbAAAAAJ&amp;hl=en&amp;oi=sra">H Kurniawati</a>, T Bandyopadhyay, <a href="/citations?user=cAaRCiUAAAAJ&amp;hl=en&amp;oi=sra">NM Patrikalakis</a> - Autonomous Robots, 2012 - Springer</div><div class="gs_rs">Abstract Uncertainty in motion planning is often caused by three main sources: motion error, <br>sensing error, and imperfect environment map. Despite the significant effect of all three <br>sources of uncertainty to motion planning problems, most planners take into account only <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7958919829216667751&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 3</a> <a href="/scholar?q=related:Z6hFoGrDc24J:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7958919829216667751&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 17 versions</a> <a onclick="return gs_ocit(event,'Z6hFoGrDc24J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB24" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW24"><a href="http://hal.inria.fr/docs/00/55/14/01/PDF/manuscrit_these_SarahFilippi_depotlegal.pdf" class=yC2E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from inria.fr</span><span class="gs_ggsS">inria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://hal.inria.fr/docs/00/55/14/01/PDF/manuscrit_these_SarahFilippi_depotlegal.pdf" class=yC2D>Sarah Filippi</a></h3><div class="gs_a">JYA Rapporteurs - 2011 - hal.inria.fr</div><div class="gs_rs">Cette thÃ¨se a Ã©tÃ© effectuÃ©e au sein du Laboratoire Traitement et Communication de <br>l&#39;Information (LTCI), une UnitÃ© Mixte de Recherche du CNRS et de TÃ©lÃ©com ParisTech. Elle <br>a Ã©tÃ© financÃ©e par Orange Labs dans le cadre d&#39;un contrat de recherche externe portant <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:BMKJRkv1VgwJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=889167680107037188&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'BMKJRkv1VgwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md24', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md24" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:BMKJRkv1VgwJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB25" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW25"><a href="http://d-nb.info/1000057259/34" class=yC30><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from d-nb.info</span><span class="gs_ggsS">d-nb.info <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://d-nb.info/1000057259/34" class=yC2F>Graphische Modelle im natÃ¼rlichsprachlichen Mensch-Maschine-Dialog</a></h3><div class="gs_a">S SchwÃ¤rzler - 2009 - d-nb.info</div><div class="gs_rs">Die vorliegende Arbeit ist das Ergebnis meiner ForschungstÃ¤tigkeit als wissenschaftlicher <br>Assistent am Lehrstuhl fÃ¼r Mensch-Maschine-Kommunikation der Technischen UniversitÃ¤t <br>MÃ¼nchen. Dem Leiter dieses Lehrstuhls, Herrn Prof. Dr.-Ing. habil. Gerhard Rigoll danke <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:HY4_bke-3OkJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16851553119715167773&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'HY4_bke-3OkJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md25', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md25" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:HY4_bke-3OkJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Planification multiagent sous incertitude orientÃ©e interactions: modele et algorithmes.</h3><div class="gs_a">GVD de Recherches ONERA, B Patin, C de Projet</div><div class="gs_fl"><a href="/scholar?q=related:c-xd-ZIVugoJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'c-xd-ZIVugoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
