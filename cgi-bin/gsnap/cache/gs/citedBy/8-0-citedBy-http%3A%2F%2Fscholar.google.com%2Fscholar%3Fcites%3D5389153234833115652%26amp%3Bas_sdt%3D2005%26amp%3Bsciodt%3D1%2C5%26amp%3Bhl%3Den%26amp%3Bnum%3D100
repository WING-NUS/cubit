Total results = 8
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://pdf.aminer.org/000/032/002/tree_model_of_symbolic_music_for_tonality_guessing.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aminer.org</span><span class="gs_ggsS">aminer.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://pdf.aminer.org/000/032/002/tree_model_of_symbolic_music_for_tonality_guessing.pdf" class=yC0>Tree model of symbolic music for tonality guessing</a></h3><div class="gs_a">D Rizo, JM Inesta, PJP de LeÃ³n&hellip; - &hellip; of the IASTED Int. Conf. on &hellip;, 2006 - pdf.aminer.org</div><div class="gs_rs">ABSTRACT Most of the western tonal music is based on the concept of tonality or key. It is <br>often desirable to know the tonality of a song stored in a symbolic format (digital scores), <br>both for content based management and musicological studies to name just two <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2362415194151189151&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 15</a> <a href="/scholar?q=related:n_pdOxr8yCAJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2362415194151189151&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'n_pdOxr8yCAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md0', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md0" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:n_pdOxr8yCAJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://hal.archives-ouvertes.fr/docs/00/51/14/52/PDF/Papadopoulos_LocalKey_DAFX_2009.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://hal.archives-ouvertes.fr/hal-00511452/" class=yC2>Local key estimation based on harmonic and metric structures</a></h3><div class="gs_a">H Papadopoulos, G Peeters - Proceedings of the  &hellip;, 2009 - hal.archives-ouvertes.fr</div><div class="gs_rs">ABSTRACT In this paper, we present a method for estimating the local keys of an audio <br>signal. We propose to address the problem of local key finding by investigating the possible <br>combination and extension of different previous proposed global key estimation <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15872313996596424563&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 9</a> <a href="/scholar?q=related:cy-XGnzJRdwJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15872313996596424563&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'cy-XGnzJRdwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.104.7685&amp;rep=rep1&amp;type=pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.104.7685&amp;rep=rep1&amp;type=pdf" class=yC4>Tree symbolic music representation for key finding</a></h3><div class="gs_a">D Rizo, J IÃ±esta - Extended Abstracts of the 1st Annual Music Information &hellip;, 2005 - Citeseer</div><div class="gs_rs">In music theory, the tonality is defined as the quality by which all tones of a composition are heard <br>in relation to a central tone called the keynote or tonic. The majority of works that model the tonality <br>of a song use linear sequences of notes (Zhu and Kankanhalli (2004), Temperley (2002)). <b> ...</b> </div><div class="gs_fl"><a href="/scholar?cites=8269812089444068861&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 4</a> <a href="/scholar?q=related:_W2LrkdGxHIJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8269812089444068861&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'_W2LrkdGxHIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md2', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md2" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:_W2LrkdGxHIJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://hal.inria.fr/docs/00/54/89/52/PDF/Papadopoulos_Thesis.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from inria.fr</span><span class="gs_ggsS">inria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://hal.inria.fr/docs/00/54/89/52/PDF/Papadopoulos_Thesis.pdf" class=yC6>Joint estimation of musical content information from an audio signal</a></h3><div class="gs_a">H Papadopoulos - 2010 - hal.inria.fr</div><div class="gs_rs">RÃ©sumÃ© Dans cette these, nous nous intÃ©ressons au probleme de l&#39;extraction automatique <br>d&#39;informations de contenu d&#39;un signal audio de musique. La plupart des travaux existants <br>abordent ce probleme en considÃ©rant les attributs musicaux de maniere indÃ©pendante les <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5504565459161893914&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 4</a> <a href="/scholar?q=related:Gsw65B4lZEwJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Gsw65B4lZEwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md3', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md3" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Gsw65B4lZEwJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a>  <a href="/scholar?q=info:Gsw65B4lZEwJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=14696771562731948953&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4557880" class=yC8>Extraction of Emotional Content from Music Data</a></h3><div class="gs_a">M Bartoszewski, H Kwasnicka&hellip; - &hellip; , 2008. CISIM&#39;08. 7th, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents the system for automatic emotion detection from music data <br>stored in MIDI format files. First, the piece of music is divided into independent segments that <br>potentially represent different emotional states. For this task the method of segmentation is <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10701301163608364449&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 1</a> <a href="/scholar?q=related:odVZ27WogpQJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10701301163608364449&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'odVZ27WogpQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://hal.archives-ouvertes.fr/docs/00/65/57/81/PDF/PapadopoulosPeeters_LcalKey_IEEE_2011.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6074928" class=yC9>Local Key Estimation from an Audio Signal Relying on Harmonic and Metrical Structures</a></h3><div class="gs_a">H Papadopoulos, G Peeters - Audio, Speech, and Language  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present a method for estimating the progression of musical key <br>from an audio signal. We address the problem of local key finding by investigating the <br>possible combination and extension of different previously proposed approaches for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6634530592485010227&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 1</a> <a href="/scholar?q=related:M-uHMGyWElwJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6634530592485010227&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'M-uHMGyWElwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://tel.archives-ouvertes.fr/docs/00/54/89/52/PDF/Papadopoulos_Thesis.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://tel.archives-ouvertes.fr/tel-00548952/" class=yCB>Estimation conjointe d&#39;information de contenu musical d&#39;un signal audio</a></h3><div class="gs_a">H Papadopoulos - 2010 - tel.archives-ouvertes.fr</div><div class="gs_rs">RÃ©sumÃ© Dans cette these, nous nous intÃ©ressons au probleme de l&#39;extraction automatique <br>d&#39;informations de contenu d&#39;un signal audio de musique. La plupart des travaux existants <br>abordent ce probleme en considÃ©rant les attributs musicaux de maniere indÃ©pendante les <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:B-SObITZT2wJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7804695842036573191&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'B-SObITZT2wJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> VILNIAUS GEDIMINO TECHNIKOS UNIVERSITETAS</h3><div class="gs_a">D DISERTACIJA</div><div class="gs_fl"><a href="/scholar?q=related:spRGsrXXbtAJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'spRGsrXXbtAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
