Total results = 47
<div class="gs_r" style="z-index:400"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=895972" class=yC0>Content-based image retrieval at the end of the early years</a></h3><div class="gs_a"><a href="/citations?user=03svEqcAAAAJ&amp;hl=en&amp;oi=sra">AWM Smeulders</a>, <a href="/citations?user=pdu8f3sAAAAJ&amp;hl=en&amp;oi=sra">M Worring</a>, S Santini&hellip; - Pattern Analysis and  &hellip;, 2000 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Presents a review of 200 references in content-based image retrieval. The paper <br>starts with discussing the working conditions of content-based retrieval: patterns of use, <br>types of pictures, the role of semantics, and the sensory gap. Subsequent sections discuss <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18147604438637778816&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 4443</a> <a href="/scholar?q=related:gJdOORY-2fsJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/25/19/RN088683201.html?source=googlescholar" class="gs_nph" class=yC1>BL Direct</a> <a href="/scholar?cluster=18147604438637778816&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 22 versions</a> <a onclick="return gs_ocit(event,'gJdOORY-2fsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=790428" class=yC2>Similarity measures</a></h3><div class="gs_a">S Santini, R Jain - Pattern Analysis and Machine Intelligence,  &hellip;, 1999 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract With complex multimedia data, we see the emergence of database systems in <br>which the fundamental operation is similarity assessment. Before database issues can be <br>addressed, it is necessary to give a definition of similarity as an operation. We develop a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7476650092381854821&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 567</a> <a href="/scholar?q=related:ZdxPYqVlwmcJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/5C/26/RN067135829.html?source=googlescholar" class="gs_nph" class=yC3>BL Direct</a> <a href="/scholar?cluster=7476650092381854821&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'ZdxPYqVlwmcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://csnotes.upm.edu.my/kelasmaya/web.nsf/0/2674bfdc54248add482575eb0028cfda/$FILE/Similarity%20Search.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from upm.edu.my</span><span class="gs_ggsS">upm.edu.my <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[BOOK]</span><span class="gs_ct2">[B]</span></span> <a href="http://csnotes.upm.edu.my/kelasmaya/web.nsf/0/2674bfdc54248add482575eb0028cfda/$FILE/Similarity%20Search.pdf" class=yC4>Similarity search</a></h3><div class="gs_a"><a href="/citations?user=EHIdRAYAAAAJ&amp;hl=en&amp;oi=sra">P Zezula</a>, G Amato, <a href="/citations?user=Vmj26i4AAAAJ&amp;hl=en&amp;oi=sra">V Dohnal</a>, <a href="/citations?user=9lJtRiMAAAAJ&amp;hl=en&amp;oi=sra">M Batko</a> - 2006 - csnotes.upm.edu.my</div><div class="gs_rs">âAn ability to assess similarity lies close to the core of cognition. The sense of sameness is <br>the very keel and backbone of our thinking. An understanding of problem solving, <br>categorization, memory retrieval, inductive reasoning, and other cognitive processes <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15646165867187964618&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 447</a> <a href="/scholar?q=related:yoqUkvVYItkJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15646165867187964618&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 17 versions</a> <a onclick="return gs_ocit(event,'yoqUkvVYItkJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md2', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md2" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:yoqUkvVYItkJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a>  <a href="/scholar?q=info:yoqUkvVYItkJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=8525114705426159281&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0167865500001185" class=yC6>Performance evaluation in content-based image retrieval: Overview and proposals</a></h3><div class="gs_a"><a href="/citations?user=UEZ9RlUAAAAJ&amp;hl=en&amp;oi=sra">H MÃ¼ller</a>, W MÃ¼ller, DMG Squire&hellip; - Pattern Recognition  &hellip;, 2001 - Elsevier</div><div class="gs_rs">Evaluation of retrieval performance is a crucial problem in content-based image retrieval <br>(CBIR). Many different methods for measuring the performance of a system have been <br>created and used by researchers. This article discusses the advantages and shortcomings <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4994033405468149430&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 301</a> <a href="/scholar?q=related:tgZdOexeTkUJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4994033405468149430&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'tgZdOexeTkUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://arantxa.ii.uam.es/~ssantini/work/papers/cited/integrated.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uam.es</span><span class="gs_ggsS">uam.es <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=879766" class=yC7>Integrated browsing and querying for image databases</a></h3><div class="gs_a">S Santini, R Jain - Multimedia, IEEE, 2000 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The image database system El Nino uses a new interaction model that aims to <br>overcome the problem of the semantic gap where the meaning that the user has in mind for <br>an image is at a higher semantic level than the features on which the database operates. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9249278876805423720&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 131</a> <a href="/scholar?q=related:aOKCOCIKXIAJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/48/01/RN085406863.html?source=googlescholar" class="gs_nph" class=yC9>BL Direct</a> <a href="/scholar?cluster=9249278876805423720&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 26 versions</a> <a onclick="return gs_ocit(event,'aOKCOCIKXIAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://www-i6.informatik.rwth-aachen.de/publications/download/34/The%20IAPR%20Benchmark:%20A%20New%20Evaluation%20Resource%20for%20Visual%20Information%20Systems.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from rwth-aachen.de</span><span class="gs_ggsS">rwth-aachen.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www-i6.informatik.rwth-aachen.de/publications/download/34/The%20IAPR%20Benchmark:%20A%20New%20Evaluation%20Resource%20for%20Visual%20Information%20Systems.pdf" class=yCA>The iapr tc-12 benchmark: A new evaluation resource for visual information systems</a></h3><div class="gs_a">M Grubinger, P Clough&hellip; - International  &hellip;, 2006 - www-i6.informatik.rwth-aachen.de</div><div class="gs_rs">Abstract In this paper, we describe an image collection created for the CLEF cross-language <br>image retrieval track (ImageCLEF). This image retrieval benchmark (referred to as the IAPR <br>TC-12 Benchmark) has developed from an initiative started by the Technical Committee <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8629826244666887171&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 123</a> <a href="/scholar?q=related:A4y2Kj9Nw3cJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8629826244666887171&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 19 versions</a> <a onclick="return gs_ocit(event,'A4y2Kj9Nw3cJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md5', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md5" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:A4y2Kj9Nw3cJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://www.ivl.disco.unimib.it/Teaching/corso-SIM%2010/01-paper.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unimib.it</span><span class="gs_ggsS">unimib.it <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ivl.disco.unimib.it/Teaching/corso-SIM%2010/01-paper.pdf" class=yCC>A survey of methods for colour image indexing and retrieval in image databases</a></h3><div class="gs_a"><a href="/citations?user=O4TctG0AAAAJ&amp;hl=en&amp;oi=sra">R Schettini</a>, <a href="/citations?user=TGlCj_sAAAAJ&amp;hl=en&amp;oi=sra">G Ciocca</a>, S Zuffi - Color Imaging Science:  &hellip;, 2001 - ivl.disco.unimib.it</div><div class="gs_rs">ABSTRACT Color is a feature of the great majority of content-based image retrieval systems. <br>However the robustness, effectiveness, and efficiency of its use in image indexing are still <br>open issues. This paper provides a comprehensive survey of the methods for color image <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2096362079550078122&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 119</a> <a href="/scholar?q=related:qnwuUDTGFx0J:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2096362079550078122&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 23 versions</a> <a onclick="return gs_ocit(event,'qnwuUDTGFx0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0306457399000217" class=yCE>A relevance feedback mechanism for content-based image retrieval</a></h3><div class="gs_a"><a href="/citations?user=TGlCj_sAAAAJ&amp;hl=en&amp;oi=sra">G Ciocca</a>, <a href="/citations?user=O4TctG0AAAAJ&amp;hl=en&amp;oi=sra">R Schettini</a> - Information processing &amp; management, 1999 - Elsevier</div><div class="gs_rs">Content-based image retrieval systems require the development of relevance feedback <br>mechanisms that allow the user to progressively refine the system&#39;s response to a query. In <br>this paper a new relevance feedback mechanism is described which evaluates the feature <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17701294610222765626&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 103</a> <a href="/scholar?q=related:Olbdmqmhp_UJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/03/5B/RN066663735.html?source=googlescholar" class="gs_nph" class=yCF>BL Direct</a> <a href="/scholar?cluster=17701294610222765626&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'Olbdmqmhp_UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://cgit.nutn.edu.tw:8080/cgit/PaperDL/gyt_080904214332.pdf" class=yC11><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nutn.edu.tw</span><span class="gs_ggsS">nutn.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0262885601000609" class=yC10>Color-based image retrieval using spatial-chromatic histograms</a></h3><div class="gs_a">L Cinque, <a href="/citations?user=TGlCj_sAAAAJ&amp;hl=en&amp;oi=sra">G Ciocca</a>, S Levialdi, A Pellicano&hellip; - Image and Vision  &hellip;, 2001 - Elsevier</div><div class="gs_rs">The paper describes a new indexing methodology for image databases integrating color <br>and spatial information for content-based image retrieval. This methodology, called Spatial-<br>Chromatic Histogram (SCH), synthesizing in few values information about the location of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16679969077224186592&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 69</a> <a href="/scholar?q=related:4KJyYIAne-cJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16679969077224186592&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'4KJyYIAne-cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.33.1965&amp;rep=rep1&amp;type=pdf" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=738360" class=yC12>Automatic composition techniques for video production</a></h3><div class="gs_a">G Ahanger, <a href="/citations?user=dj6XyGcAAAAJ&amp;hl=en&amp;oi=sra">TDC Little</a> - Knowledge and Data Engineering,  &hellip;, 1998 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Video production involves the process of capturing, editing and composing video <br>segments for delivery to a consumer. A composition must yield a coherent presentation of an <br>event or narrative. This process can be automated if appropriate domain-specific <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=982491626681337034&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 62</a> <a href="/scholar?q=related:ygQj0-2Cog0J:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/1A/2E/RN054722072.html?source=googlescholar" class="gs_nph" class=yC14>BL Direct</a> <a href="/scholar?cluster=982491626681337034&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 24 versions</a> <a onclick="return gs_ocit(event,'ygQj0-2Cog0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://cs-people.bu.edu/mp/rfine/p192-amato.pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from bu.edu</span><span class="gs_ggsS">bu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=763693.763696" class=yC15>Region proximity in metric spaces and its use for approximate similarity search</a></h3><div class="gs_a">G Amato, F Rabitti, P Savino, <a href="/citations?user=EHIdRAYAAAAJ&amp;hl=en&amp;oi=sra">P Zezula</a> - ACM Transactions on  &hellip;, 2003 - dl.acm.org</div><div class="gs_rs">Abstract Similarity search structures for metric data typically bound object partitions by ball <br>regions. Since regions can overlap, a relevant issue is to estimate the proximity of regions in <br>order to predict the number of objects in the regions&#39; intersection. This paper analyzes the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9712240838905938344&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 51</a> <a href="/scholar?q=related:qMEH2JXPyIYJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/58/32/RN130904865.html?source=googlescholar" class="gs_nph" class=yC17>BL Direct</a> <a href="/scholar?cluster=9712240838905938344&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'qMEH2JXPyIYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/W2LGWVCDFAVF7RBQ.pdf" class=yC18>Benchmarking for content-based visual information search</a></h3><div class="gs_a">C Leung, <a href="/citations?user=RkGFFUkAAAAJ&amp;hl=en&amp;oi=sra">H Ip</a> - Advances in Visual Information Systems, 2000 - Springer</div><div class="gs_rs">The importance of the visual information search problem has given rise to a large number of <br>systems and prototypes being built to perform such search. While different systems clearly <br>have their particular strengths, they tend to use different collections to highlight the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5611384976775325917&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 49</a> <a href="/scholar?q=related:3Sio7uek300J:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/0B/06/RN086194016.html?source=googlescholar" class="gs_nph" class=yC19>BL Direct</a> <a href="/scholar?cluster=5611384976775325917&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'3Sio7uek300J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://www.sim.hcuge.ch/medgift/publications/cmig2004.pdf" class=yC1B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hcuge.ch</span><span class="gs_ggsS">hcuge.ch <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.sim.hcuge.ch/medgift/publications/cmig2004.pdf" class=yC1A>A reference data set for the evaluation of medical image retrieval systems</a></h3><div class="gs_a"><a href="/citations?user=UEZ9RlUAAAAJ&amp;hl=en&amp;oi=sra">H MÃ¼ller</a>, A Rosset, JP VallÃ©e, F Terrier&hellip; - &hellip;  Medical Imaging and  &hellip;, 2004 - sim.hcuge.ch</div><div class="gs_rs">Abstract Contentâbased image retrieval is starting to become an increasingly important <br>factor in medical imaging research and image management systems. Several retrieval <br>systems and methodologies exist and are used in a large variety of applications from <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16693420869769356739&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 45</a> <a href="/scholar?q=related:w-Wx5NXxqucJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16693420869769356739&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'w-Wx5NXxqucJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md12', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md12" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:w-Wx5NXxqucJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320300000558" class=yC1C>Content-based similarity retrieval of trademarks using relevance feedback</a></h3><div class="gs_a"><a href="/citations?user=TGlCj_sAAAAJ&amp;hl=en&amp;oi=sra">G Ciocca</a>, <a href="/citations?user=O4TctG0AAAAJ&amp;hl=en&amp;oi=sra">R Schettini</a> - Pattern Recognition, 2001 - Elsevier</div><div class="gs_rs">This paper addresses the problem of how to efficiently and effectively retrieve images similar <br>to a query from a trademark database purely on the basis of low-level feature analysis. It <br>investigates the hypothesis that the low-level image features used to index the trademark <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13830889284205818051&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 42</a> <a href="/scholar?q=related:wzDYWIYw8b8J:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/1A/5A/RN098580414.html?source=googlescholar" class="gs_nph" class=yC1D>BL Direct</a> <a href="/scholar?cluster=13830889284205818051&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'wzDYWIYw8b8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/rhat6kc3wjg1tx2h.pdf" class=yC1E>Using a relevance feedback mechanism to improve content-based image retrieval</a></h3><div class="gs_a"><a href="/citations?user=TGlCj_sAAAAJ&amp;hl=en&amp;oi=sra">G Ciocca</a>, <a href="/citations?user=O4TctG0AAAAJ&amp;hl=en&amp;oi=sra">R Schettini</a> - Visual information and information systems, 1999 - Springer</div><div class="gs_rs">the paper describes a new relevance feedback mechanism that evaluates the distribution of <br>the features of images judged relevant or not relevant by the user, and dynamically updates <br>both the similarity measure and query in order to accurately represent the user&#39;s particular <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16169328557449883109&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 41</a> <a href="/scholar?q=related:5S1he6f-ZOAJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/44/44/RN062836568.html?source=googlescholar" class="gs_nph" class=yC1F>BL Direct</a> <a href="/scholar?cluster=16169328557449883109&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'5S1he6f-ZOAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://vision.unige.ch/publications/postscript/2001/MuellerHMuellerWSquireMarchandPun_icme2001.pdf" class=yC21><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unige.ch</span><span class="gs_ggsS">unige.ch <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://vision.unige.ch/publications/postscript/2001/MuellerHMuellerWSquireMarchandPun_icme2001.pdf" class=yC20>Automated benchmarking in content-based image retrieval</a></h3><div class="gs_a"><a href="/citations?user=UEZ9RlUAAAAJ&amp;hl=en&amp;oi=sra">H MÃ¼ller</a>, W MÃ¼ller, <a href="/citations?user=dkPjyqIAAAAJ&amp;hl=en&amp;oi=sra">S Marchand-Maillet</a>, DM Squire&hellip; - ICME 2001, 2001 - vision.unige.ch</div><div class="gs_rs">ABSTRACT Benchmarking has always been a crucial problem in content-based image <br>retrieval (CBIR). A key issue is the lack of a common access method to retrieval systems, <br>such as SQL for relational databases. The Multimedia Retrieval Mark-up Language (<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2340786818313648346&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 34</a> <a href="/scholar?q=related:2niAkDUlfCAJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2340786818313648346&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 20 versions</a> <a onclick="return gs_ocit(event,'2niAkDUlfCAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md15', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md15" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:2niAkDUlfCAJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.87.2521&amp;rep=rep1&amp;type=pdf" class=yC23><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0306437902000200" class=yC22>Advanced feature extraction for keyblock-based image retrieval</a></h3><div class="gs_a">L Zhu, A Rao, <a href="/citations?user=O8XxkE4AAAAJ&amp;hl=en&amp;oi=sra">A Zhang</a> - Information Systems, 2002 - Elsevier</div><div class="gs_rs">Keyblock, which is a new framework we proposed for content-based image retrieval, is a <br>generalization of the text-based information retrieval technology in the image domain. In this <br>framework, keyblocks, which are analogous to keywords in text document retrieval, can be <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13489652133926182679&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 31</a> <a href="/scholar?q=related:F59CAiXfNLsJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13489652133926182679&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'F59CAiXfNLsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://research.rmutp.ac.th/research/reference/Content-based%20color%20image%20retrieval%20with%20relevance%20feedback.pdf" class=yC25><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from rmutp.ac.th</span><span class="gs_ggsS">rmutp.ac.th <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=817072" class=yC24>Content-based color image retrieval with relevance feedback</a></h3><div class="gs_a"><a href="/citations?user=O4TctG0AAAAJ&amp;hl=en&amp;oi=sra">R Schettini</a>, <a href="/citations?user=TGlCj_sAAAAJ&amp;hl=en&amp;oi=sra">G Ciocca</a>, I Gagliardi - Image Processing, 1999.  &hellip;, 1999 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We describe the main features of Quicklook, a prototype system that allows the user <br>to query an image database and progressively refine the system&#39;s response by indicating <br>the relevance, or nonrelevance of the retrieved items. Our experience with Quicklook <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10576949812225391052&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 28</a> <a href="/scholar?q=related:zDnUrNDfyJIJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10576949812225391052&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'zDnUrNDfyJIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB18" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW18"><a href="http://saadatmand.synthasite.com/resources/Journal0004_Full.pdf" class=yC27><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from synthasite.com</span><span class="gs_ggsS">synthasite.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4067088" class=yC26>A novel evolutionary approach for optimizing content-based image indexing algorithms</a></h3><div class="gs_a">M Saadatmand-Tarzjan&hellip; - Systems, Man, and  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Optimization of content-based image indexing and retrieval (CBIR) algorithms is a <br>complicated and time-consuming task since each time a parameter of the indexing algorithm <br>is changed, all images in the database should be indexed again. In this paper, a novel <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17795814205886129547&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 26</a> <a href="/scholar?q=related:i2Wx5rtu9_YJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/4A/2B/RN204971832.html?source=googlescholar" class="gs_nph" class=yC28>BL Direct</a> <a href="/scholar?cluster=17795814205886129547&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'i2Wx5rtu9_YJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="http://raidlab.cs.purdue.edu/cs641/reviews/review-yuhui.pdf" class=yC2A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from purdue.edu</span><span class="gs_ggsS">purdue.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1017731" class=yC29>A method for measuring the complexity of image databases</a></h3><div class="gs_a">A Rao, <a href="/citations?user=Uttu9kkAAAAJ&amp;hl=en&amp;oi=sra">RK Srihari</a>, L Zhu&hellip; - &hellip; , IEEE Transactions on, 2002 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We present a framework for measuring the complexity of image databases, which <br>characterizes the databases for image retrieval. Motivated from the concept of text corpus <br>perplexity, the complexity of image databases is formulated based on image database <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17780532755673307732&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 18</a> <a href="/scholar?q=related:VNoaA1YkwfYJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/24/64/RN116443703.html?source=googlescholar" class="gs_nph" class=yC2B>BL Direct</a> <a href="/scholar?cluster=17780532755673307732&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'VNoaA1YkwfYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/g7072761g9143xv2.pdf" class=yC2C>A framework for benchmarking in CBIR</a></h3><div class="gs_a"><a href="/citations?user=UEZ9RlUAAAAJ&amp;hl=en&amp;oi=sra">H MÃ¼ller</a>, W MÃ¼ller, <a href="/citations?user=dkPjyqIAAAAJ&amp;hl=en&amp;oi=sra">S Marchand-Maillet</a>, <a href="/citations?user=sR12P9MAAAAJ&amp;hl=en&amp;oi=sra">T Pun</a>&hellip; - Multimedia Tools and  &hellip;, 2003 - Springer</div><div class="gs_rs">Content-based image retrieval (CBIR) has been a very active research area for more than <br>ten years. In the last few years the number of publications and retrieval systems produced <br>has become larger and larger. Despite this, there is still no agreed objective way in which <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16110060311960713756&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 18</a> <a href="/scholar?q=related:HHqJvH9ukt8J:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16110060311960713756&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'HHqJvH9ukt8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.26.281&amp;rep=rep1&amp;type=pdf" class=yC2E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.26.281&amp;rep=rep1&amp;type=pdf" class=yC2D>Evaluation vademecum for visual information systems</a></h3><div class="gs_a">S Santini - Proc. of SPIE, 2000 - Citeseer</div><div class="gs_rs">ABSTRACT This paper presents some methodological observations on the measurement of <br>performance in Visual Information Retrieval (VIR) systems. The paper identifies three <br>different types of measures two of which (Physical Performance and Contextual <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=731455062194401475&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 17</a> <a href="/scholar?q=related:wzBC74CmJgoJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/00/4D/RN073067674.html?source=googlescholar" class="gs_nph" class=yC2F>BL Direct</a> <a href="/scholar?cluster=731455062194401475&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'wzBC74CmJgoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md21', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md21" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:wzBC74CmJgoJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB22" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW22"><a href="http://ir.shef.ac.uk/cloughie/papers/visual2004.pdf" class=yC31><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from shef.ac.uk</span><span class="gs_ggsS">shef.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://ir.shef.ac.uk/cloughie/papers/visual2004.pdf" class=yC30>Benchmarking image retrieval applications</a></h3><div class="gs_a"><a href="/citations?user=UEZ9RlUAAAAJ&amp;hl=en&amp;oi=sra">H MÃ¼ller</a>, <a href="/citations?user=FZStnUEAAAAJ&amp;hl=en&amp;oi=sra">A Geissbuhler</a>, <a href="/citations?user=dkPjyqIAAAAJ&amp;hl=en&amp;oi=sra">S Marchand-Maillet</a>&hellip; - proceedings of the  &hellip;, 2004 - ir.shef.ac.uk</div><div class="gs_rs">ABSTRACT Contentâbased visual information retrieval is an important research topic in the <br>computer vision field sind the early 1990s. A large number of systems have been developed <br>as research prototypes as well as commercial and open source systems. Still, there has <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17463386880485316441&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 16</a> <a href="/scholar?q=related:WVeLwtdpWvIJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17463386880485316441&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'WVeLwtdpWvIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md22', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md22" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:WVeLwtdpWvIJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.ingentaconnect.com/content/klu/mtap/2003/00000021/00000001/05140132" class=yC32>A Framework for Benchmarking in CBIR</a></h3><div class="gs_a"><a href="/citations?user=UEZ9RlUAAAAJ&amp;hl=en&amp;oi=sra">H Muller</a>, W Muller, <a href="/citations?user=dkPjyqIAAAAJ&amp;hl=en&amp;oi=sra">S Marchand-Maillet</a>&hellip; - Multimedia Tools  &hellip;, 2003 - ingentaconnect.com</div><div class="gs_rs">Abstract: Content-based image retrieval (CBIR) has been a very active research area for <br>more than ten years. In the last few years the number of publications and retrieval systems <br>produced has become larger and larger. Despite this, there is still no agreed objective <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10707406292837265852&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 15</a> <a href="/scholar?q=related:vPFYBktZmJQJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/57/22/RN135848249.html?source=googlescholar" class="gs_nph" class=yC33>BL Direct</a> <a href="/scholar?cluster=10707406292837265852&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'vPFYBktZmJQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB24" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW24"><a href="http://wise.ajou.ac.kr:8080/pdfs/pdffile12648.pdf" class=yC35><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ajou.ac.kr</span><span class="gs_ggsS">ajou.ac.kr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=500933.500949" class=yC34>A web-based evaluation system for CBIR</a></h3><div class="gs_a"><a href="/citations?user=UEZ9RlUAAAAJ&amp;hl=en&amp;oi=sra">H MÃ¼ller</a>, W MÃ¼ller, D Squire - Proceedings of the 2001 ACM workshops  &hellip;, 2001 - dl.acm.org</div><div class="gs_rs">Abstract This papers describes a benchmark test for content-based image retrieval systems <br>(CBIRSs) with the query by example (QBE) query paradigm. This benchmark is accessible <br>via the Internet and thus allows to evaluate any CBIRS which is compliant with Multimedia <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10110422638245610549&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 14</a> <a href="/scholar?q=related:NYSyedJvT4wJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10110422638245610549&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'NYSyedJvT4wJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB25" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW25"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.123.3291&amp;rep=rep1&amp;type=pdf" class=yC37><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=956104" class=yC36>A query model to synthesize answer intervals from indexed video units</a></h3><div class="gs_a"><a href="/citations?user=1ck-IxAAAAAJ&amp;hl=en&amp;oi=sra">S Pradhan</a>, K Tajima, K Tanaka - Knowledge and Data  &hellip;, 2001 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract While a query result in a traditional database is a subset of the database, in a video <br>database, it is a set of subintervals extracted from the raw video sequence. It is very hard, if <br>not impossible, to predetermine all the queries that will be issued in the future, and all the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4583533250358028943&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 15</a> <a href="/scholar?q=related:jyrI4zT7mz8J:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/44/63/RN102388197.html?source=googlescholar" class="gs_nph" class=yC38>BL Direct</a> <a href="/scholar?cluster=4583533250358028943&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 21 versions</a> <a onclick="return gs_ocit(event,'jyrI4zT7mz8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB26" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW26"><a href="http://hornad.fei.tuke.sk/~genci/Vyucba/OOBDS/Archiv/Podklady/Multimedia/Image%20Databases.pdf#page=353" class=yC3A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tuke.sk</span><span class="gs_ggsS">tuke.sk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=KwZCnpjdDtoC&amp;oi=fnd&amp;pg=PA345&amp;ots=LQxd-v2mRD&amp;sig=n_rUMDDWw5PWJWYY9i5oK3oIFE4" class=yC39>13 Shape Representation for Image Retrieval</a></h3><div class="gs_a">BB Kimia - Image databases: search and retrieval of digital  &hellip;, 2002 - books.google.com</div><div class="gs_rs">The humanâmachine interface is evolving at an incredible pace, surpassing the traditional <br>text-based boundaries. A driving force motivating this development is the need to endow <br>computers with capabilities that parallel our perceptual abilities. Vision is arguably our <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=402140888508072730&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 13</a> <a href="/scholar?q=related:GgMv6QGxlAUJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=402140888508072730&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'GgMv6QGxlAUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=797712" class=yC3B>Similarity retrieval of trademark images</a></h3><div class="gs_a"><a href="/citations?user=TGlCj_sAAAAJ&amp;hl=en&amp;oi=sra">G Ciocca</a>, <a href="/citations?user=O4TctG0AAAAJ&amp;hl=en&amp;oi=sra">R Schettini</a> - Image Analysis and Processing, 1999.  &hellip;, 1999 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We investigate the hypothesis that the low-level image features used to index the <br>trademark images can be correlated with image contents by applying a relevance feedback <br>mechanism that evaluates the feature distributions of the images judged relevant, or not <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10209980455992321052&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 8</a> <a href="/scholar?q=related:HGQaQyEjsY0J:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10209980455992321052&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'HGQaQyEjsY0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB28" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW28"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.26.1823&amp;rep=rep1&amp;type=pdf" class=yC3D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.26.1823&amp;rep=rep1&amp;type=pdf" class=yC3C>The use of psychological similarity measure for queries in image databases</a></h3><div class="gs_a">S Santini, R Jain - 1996 - Citeseer</div><div class="gs_rs">Abstract With complex multimedia data, we see the emergence of database systems in <br>which the fundamental operation is similarity assessment. Before database issues can be <br>addressed, it is necessary to give a definition of similarity as an operation. In this paper we <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5811195156235284854&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 8</a> <a href="/scholar?q=related:dvHfnzSDpVAJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5811195156235284854&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'dvHfnzSDpVAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md28', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md28" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:dvHfnzSDpVAJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=817603" class=yC3E>An occupancy model for image retrieval and similarity evaluation</a></h3><div class="gs_a">DA Adjeroh, MC Lee - Image Processing, IEEE Transactions  &hellip;, 2000 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The analysis of visual information often involves the manipulation of enormous <br>volumes of data. If some tolerance is allowed in the results, orders of magnitude <br>improvement in efficiency can be achieved in such analysis by appropriate selective <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16622166652614737126&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 8</a> <a href="/scholar?q=related:5vxxpoDMreYJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/10/5C/RN073206844.html?source=googlescholar" class="gs_nph" class=yC3F>BL Direct</a> <a href="/scholar?cluster=16622166652614737126&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'5vxxpoDMreYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1180758" class=yC40>Efficient benchmarking of content-based image retrieval via resampling</a></h3><div class="gs_a"><a href="/citations?user=d3h-zScAAAAJ&amp;hl=en&amp;oi=sra">J Shen</a>, J Shepherd - Proceedings of the 14th annual ACM international  &hellip;, 2006 - dl.acm.org</div><div class="gs_rs">Abstract While content-based image retrieval (CBIR) is an expanding field, and new <br>approaches to ever more effective retrieval are frequently proposed, relatively little attention <br>has so far been paid to the process of evaluating the effectiveness of CBIR methods. Most <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16229983832131978134&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 4</a> <a href="/scholar?q=related:lkOPIE58POEJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16229983832131978134&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'lkOPIE58POEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ri"><h3 class="gs_rt"><a href="http://search.ieice.org/bin/summary.php?id=e82-d_1_34" class=yC41>Organization and retrieval of video data</a></h3><div class="gs_a">K Tanaka, Y Ariki, K Uehara - IEICE TRANSACTIONS on  &hellip;, 1999 - search.ieice.org</div><div class="gs_rs">This paper focuses on the problems how to organize and retrieve video data in an effective <br>manner. First we identify several issues to be solved for the problems. Next, we overview our <br>current research results together with a brief survey in the research area of video <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11527999626753271033&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 4</a> <a href="/scholar?q=related:-eR2I5Wu-58J:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/05/04/RN057149450.html?source=googlescholar" class="gs_nph" class=yC42>BL Direct</a> <a href="/scholar?cluster=11527999626753271033&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'-eR2I5Wu-58J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB32" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW32"><a href="http://128.197.53.93/pubs/papers/1998/TR-09-02-98.pdf" class=yC44><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 128.197.53.93</span><span class="gs_ggsS">128.197.53.93 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://128.197.53.93/pubs/papers/1998/TR-09-02-98.pdf" class=yC43>Automatic digital video production concepts</a></h3><div class="gs_a">G Ahanger, <a href="/citations?user=dj6XyGcAAAAJ&amp;hl=en&amp;oi=sra">TDC Little</a> - &hellip;  on Internet and Multimedia Systems and  &hellip;, 1998 - 128.197.53.93</div><div class="gs_rs">AbstractâVideo production involves conceiving a story, shooting raw video footage, and <br>editing the final piece. Editing involves manually cutting frames and frame sequences from <br>the raw video and composing the sequences with special effects to render the production <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3159409787030323686&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 4</a> <a href="/scholar?q=related:5sHVR3Z62CsJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3159409787030323686&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'5sHVR3Z62CsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md32', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md32" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:5sHVR3Z62CsJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:367"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB33" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW33"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.107.4926&amp;rep=rep1&amp;type=pdf" class=yC46><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.107.4926&amp;rep=rep1&amp;type=pdf" class=yC45>TRECVID as a re-usable test-collection for video retrieval</a></h3><div class="gs_a">T Westerveld - Proceedings of the Multimedia Information Retrieval  &hellip;, 2005 - Citeseer</div><div class="gs_rs">ABSTRACT TRECVID has been running as a video retrieval benchmarking platform for a <br>number of years now. Some progress seems to be made in the area of video retrieval, but <br>also it has been shown that many of the differences in scores between tested approaches <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1231795105401240588&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 3</a> <a href="/scholar?q=related:DHyBPR83GBEJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1231795105401240588&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'DHyBPR83GBEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md33', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md33" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:DHyBPR83GBEJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:366"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S003040180400447X" class=yC47>Spectral similarity measure based on fuzzy feature contrast model</a></h3><div class="gs_a">H Tang, T Fang, P Shi - Optics communications, 2004 - Elsevier</div><div class="gs_rs">In the famous feature contrast model (FCM), the similarity measure is a linear combination of <br>the common (similar) features and the distinctive (dissimilar) features. Because of the <br>combination, FCM is better than other similarity models in explaining human perception <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17455521090293893757&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 4</a> <a href="/scholar?q=related:fYpOxPJ3PvIJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17455521090293893757&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'fYpOxPJ3PvIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:365"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB35" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW35"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.40.7876&amp;rep=rep1&amp;type=pdf" class=yC49><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.40.7876&amp;rep=rep1&amp;type=pdf" class=yC48>Techniques for automatic digital video composition</a></h3><div class="gs_a">G Ahanger - 1999 - Citeseer</div><div class="gs_rs">Abstract Recent developments in digital technology have enabled a class of video-based <br>applications that were not previously viable. However, digital video production systems face <br>the challenge of accessing the inherently linear and time-dependent media of audio and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17285810972688848443&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 3</a> <a href="/scholar?q=related:Oxar2X6J4-8J:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17285810972688848443&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'Oxar2X6J4-8J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md35', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md35" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Oxar2X6J4-8J:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a>  <a href="/scholar?q=info:Oxar2X6J4-8J:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=17488132757965390683&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:364"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB36" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW36"><a href="http://www.sim.hcuge.ch/medgift/publications/imageCLEF2004.pdf" class=yC4B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hcuge.ch</span><span class="gs_ggsS">hcuge.ch <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/bmawnnujg2k5utfm.pdf" class=yC4A>How to visually retrieve images from the St. Andrews collection using GIFT</a></h3><div class="gs_a"><a href="/citations?user=UEZ9RlUAAAAJ&amp;hl=en&amp;oi=sra">H MÃ¼ller</a>, A GeissbÃ¼hler - Multilingual Information Access for Text, Speech  &hellip;, 2005 - Springer</div><div class="gs_rs">The ImageCLEF task of CLEF has a main goal in the retrieval of images from multiâlingual <br>collections. The 2003 imageCLEF saw no group using the visual information of images, <br>which is inherently language independent. The query topics of the St. Andrews collection <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11259159674190529525&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 2</a> <a href="/scholar?q=related:9YOH8RGSQJwJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/0E/06/RN172063327.html?source=googlescholar" class="gs_nph" class=yC4C>BL Direct</a> <a href="/scholar?cluster=11259159674190529525&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'9YOH8RGSQJwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:363"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/K51V66QV184031K1.pdf" class=yC4D>Knowledge based multimodal result fusion for distributed and heterogeneous multimedia environments: concept and ideas</a></h3><div class="gs_a">F Stegmaier, T BÃ¼rger, M DÃ¶ller, <a href="/citations?user=WnWkNTsAAAAJ&amp;hl=en&amp;oi=sra">H Kosch</a> - Adaptive Multimedia Retrieval.  &hellip;, 2011 - Springer</div><div class="gs_rs">Distributed multimedia retrieval (DMR) is a key issue in today&#39;s information systems. One <br>problem in DMR is the fusion of results retrieved from multiple locations, which is required in <br>order to present the results in an integrated, consolidated and aligned form. This paper <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7301960289198884812&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 1</a> <a href="/scholar?q=related:zEe1ETLGVWUJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7301960289198884812&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'zEe1ETLGVWUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:362"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB38" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW38"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.90.8886&amp;rep=rep1&amp;type=pdf" class=yC4F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.90.8886&amp;rep=rep1&amp;type=pdf" class=yC4E>Keyblock: an approach for content-based image retrieval</a></h3><div class="gs_a">L Zhu - 2001 - Citeseer</div><div class="gs_rs">Abstract The success in text-based information retrieval motivates us to investigate <br>analogous techniques which can support querying and browsing of image data. However, <br>images are greatly different from text both syntactically and semantically in representing <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7832727232626635943&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 1</a> <a href="/scholar?q=related:pzQ9I-tvs2wJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7832727232626635943&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'pzQ9I-tvs2wJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md38', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md38" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:pzQ9I-tvs2wJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:361"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB39" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW39"><a href="http://repository.lib.polyu.edu.hk/jspui/bitstream/10397/3435/2/b20592565_ir.pdf" class=yC51><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from polyu.edu.hk</span><span class="gs_ggsS">polyu.edu.hk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://repository.lib.polyu.edu.hk/jspui/handle/10397/3435" class=yC50>Use of intelligent system techniques for storage and retrieval of biometrics data with application to personal identification</a></h3><div class="gs_a">K Cheung - 2006 - repository.lib.polyu.edu.hk</div><div class="gs_rs">Biometrics (or biometric recognition) refers to the technology recognizing individuals based <br>on their physiological and/or behavioral characteristics. It has advantages over token-based <br>and knowledge-based personal recognition technologies. The important biometric <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3260433207066641800&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 1</a> <a href="/scholar?q=related:iEUYMbpiPy0J:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3260433207066641800&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'iEUYMbpiPy0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md39', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md39" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:iEUYMbpiPy0J:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=15519149683106361434&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:360"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB40" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW40"><a href="http://clef.isti.cnr.it/2004/working_notes/WorkingNotes2004/58.pdf" class=yC53><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cnr.it</span><span class="gs_ggsS">cnr.it <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://clef.isti.cnr.it/2004/working_notes/WorkingNotes2004/58.pdf" class=yC52>Report on the imageCLEF Experiment: How to visually retrieve images from the St. Andrews collection using GIFT</a></h3><div class="gs_a"><a href="/citations?user=UEZ9RlUAAAAJ&amp;hl=en&amp;oi=sra">H MÃ¼ller</a>, <a href="/citations?user=FZStnUEAAAAJ&amp;hl=en&amp;oi=sra">A Geissbuhler</a>, <a href="/citations?user=nHAeeXcAAAAJ&amp;hl=en&amp;oi=sra">P Ruch</a> - 2005 - clef.isti.cnr.it</div><div class="gs_rs">Abstract The imageCLEF task of the Cross Language Evaluation forum has as its main goal <br>the retrieval of images from multiâlingual test collections, or retrieval of images where the <br>query is in a different language than the collection itself. The 2003 imageCLEF task saw <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5854031492129683945&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 1</a> <a href="/scholar?q=related:6flWSKCyPVEJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5854031492129683945&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'6flWSKCyPVEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:359"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB41" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW41"><a href="http://users.encs.concordia.ca/~kosseim/Publications/2005cai.pdf" class=yC55><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from concordia.ca</span><span class="gs_ggsS">concordia.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/J4R9834YC4K8FNCM.pdf" class=yC54>Generating adaptive multimedia presentations based on a semiotic framework</a></h3><div class="gs_a">O El Demerdash, <a href="/citations?user=o4FjPMIAAAAJ&amp;hl=en&amp;oi=sra">S Bergler</a>, L Kosseim&hellip; - Advances in Artificial  &hellip;, 2005 - Springer</div><div class="gs_rs">We describe a prototype for generating adaptive multimedia presentations through the <br>dynamic selection of files from a large data repository. The presentation is generated based <br>on a conceptual framework encompassing the technical (syntactic), semantic and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5217808405264732125&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=47">Cited by 1</a> <a href="/scholar?q=related:3Q_adRlhaUgJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5217808405264732125&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'3Q_adRlhaUgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:358"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Semantic Retrieval by Color, Shape and Spatial Relationships: A Study with Color Logo Retrieval via Object-oriented FrameworkÂ· Wâ eOÃ¿rÃ© b_â rÃ®TzzÃ´Ã² &hellip;</h3><div class="gs_a">CK Tung</div><div class="gs_fl"><a href="/scholar?q=related:UymvULQ2IQwJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=874039950762256723&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'UymvULQ2IQwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:357"><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=GcO4HGbMi7UC&amp;oi=fnd&amp;pg=PA322&amp;ots=0oeM1PJBan&amp;sig=KMBlLVSHiy-Q2u7Pj5lPpu94Viw" class=yC56>Mind the gap: content-based image retrieval and the user interface</a></h3><div class="gs_a">CC Venters, RJ Hartley, WT Hewitt - Multimedia systems and  &hellip;, 2004 - books.google.com</div><div class="gs_rs">ABSTRACT The user interface is the principal component responsible for facilitating <br>humancomputer interaction in an information retrieval system and provides the medium <br>between the end user and the system. Query formulation is a core activity in the process of <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:b3wMXMjU_nsJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8934812667752512623&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'b3wMXMjU_nsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:356"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB44" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW44"><a href="http://www.csse.monash.edu.au/~davids/publications/postscript/2000/MuellerHMuellerWSquireMarchandPun_prl2000.pdf" class=yC58><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from monash.edu.au</span><span class="gs_ggsS">monash.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.csse.monash.edu.au/~davids/publications/postscript/2000/MuellerHMuellerWSquireMarchandPun_prl2000.pdf" class=yC57>Performance Evaluation in Content-Based Image Retrieval: Overview and Proposals</a></h3><div class="gs_a"><a href="/citations?user=dkPjyqIAAAAJ&amp;hl=en&amp;oi=sra">S Marchand-Maillet</a>, <a href="/citations?user=sR12P9MAAAAJ&amp;hl=en&amp;oi=sra">T Pun</a> - csse.monash.edu.au</div><div class="gs_rs">Abstract Evaluation of retrieval performance is a crucial problem in content-based image <br>retrieval (CBIR). Many different methods for measuring the performance of a system have <br>been created and used by researchers. This article discusses the advantages and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:t6yHnv4zXV0J:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'t6yHnv4zXV0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md44', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md44" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:t6yHnv4zXV0J:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:355"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB45" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW45"><a href="http://www.cs.virginia.edu/~xj3a/research/publications/TR03.pdf" class=yC5A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from virginia.edu</span><span class="gs_ggsS">virginia.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.cs.virginia.edu/~xj3a/research/publications/TR03.pdf" class=yC59>Using Multiple Image Representations to Improve the Quality of Content-Based Image Retrieval</a></h3><div class="gs_a">JCFWN Martin, JVSWJ Xiangyu - cs.virginia.edu</div><div class="gs_rs">ABSTRACT Content-based image retrieval (CBIR) has been the object of considerable <br>study since the early 90&#39;s. Much effort has gone into characterizing the âcontentâ of an image <br>for the purpose of subsequent retrieval. The present study seeks to capitalize on this work <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:5lvxvbrLLw0J:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=950202049309531110&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'5lvxvbrLLw0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md45', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md45" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:5lvxvbrLLw0J:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:354"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB46" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW46"><a href="http://users.encs.concordia.ca/~kosseim/Publications/2005ammr.pdf" class=yC5C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from concordia.ca</span><span class="gs_ggsS">concordia.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/217R2212K791W829.pdf" class=yC5B>Developing AMIE: an adaptive multimedia integrated environment</a></h3><div class="gs_a">O El Demerdash, <a href="/citations?user=o4FjPMIAAAAJ&amp;hl=en&amp;oi=sra">S Bergler</a>, L Kosseim&hellip; - &hellip;  Retrieval: User, Context,  &hellip;, 2006 - Springer</div><div class="gs_rs">Large multimedia repositories can be used more effectively by providing a hybrid <br>environment for accomplishing common tasks, such as searching, browsing, presenting and <br>indexing of the material. In order to achieve this end, the semantic and relational <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:cd46w8lBvyIJ:scholar.google.com/&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/3E/27/RN183647168.html?source=googlescholar" class="gs_nph" class=yC5D>BL Direct</a> <a href="/scholar?cluster=2503792252660932209&amp;hl=en&amp;num=47&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'cd46w8lBvyIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
