Total results = 40
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.cs.clemson.edu/~jzwang/1201863/mm2010/p25-liu.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from clemson.edu</span><span class="gs_ggsS">clemson.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/ft_gateway.cfm?id=1873958&amp;type=pdf" class=yC0>Unified tag analysis with multi-edge graph</a></h3><div class="gs_a"><a href="/citations?user=NvU30c4AAAAJ&amp;hl=en&amp;oi=sra">D Liu</a>, <a href="/citations?user=DNuiPHwAAAAJ&amp;hl=en&amp;oi=sra">S Yan</a>, <a href="/citations?user=uOJH_AEAAAAJ&amp;hl=en&amp;oi=sra">Y Rui</a>, HJ Zhang - vertex, 2010 - dl.acm.org</div><div class="gs_rs">ABSTRACT Image tags have become a key intermediate vehicle to organize, index and <br>search the massive online image repositories. Extensive research has been conducted on <br>different yet related tag analysis tasks, eg, tag refinement, tag-to-region assignment, and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15209635009575387589&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=40">Cited by 20</a> <a href="/scholar?q=related:xQEWBXV6E9MJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15209635009575387589&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'xQEWBXV6E9MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://research.microsoft.com/en-us/um/people/jingdw/searchbyconceptsketch/fp83-xu.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from microsoft.com</span><span class="gs_ggsS">microsoft.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1835497" class=yC2>Image search by concept map</a></h3><div class="gs_a">H Xu, <a href="/citations?user=z5SPCmgAAAAJ&amp;hl=en&amp;oi=sra">J Wang</a>, <a href="/citations?user=6G-l4o0AAAAJ&amp;hl=en&amp;oi=sra">XS Hua</a>, <a href="/citations?user=2sQYtYwAAAAJ&amp;hl=en&amp;oi=sra">S Li</a> - Proceedings of the 33rd international ACM  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we present a novel image search system, image search by concept <br>map. This system enables users to indicate not only what semantic concepts are expected to <br>appear but also how these concepts are spatially distributed in the desired images. To this <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14783224873089761908&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=40">Cited by 18</a> <a href="/scholar?q=related:dAI8e7KQKM0J:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14783224873089761908&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'dAI8e7KQKM0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www.ee.columbia.edu/~dongliu/Papers/Survey.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from columbia.edu</span><span class="gs_ggsS">columbia.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/341820526WVG768J.pdf" class=yC4>Content-based tag processing for internet social images</a></h3><div class="gs_a"><a href="/citations?user=NvU30c4AAAAJ&amp;hl=en&amp;oi=sra">D Liu</a>, <a href="/citations?user=6G-l4o0AAAAJ&amp;hl=en&amp;oi=sra">XS Hua</a>, HJ Zhang - Multimedia Tools and Applications, 2011 - Springer</div><div class="gs_rs">Abstract Online social media services such as Flickr and Zooomr allow users to share their <br>images with the others for social interaction. An important feature of these services is that the <br>users manually annotate their images with the freely-chosen tags, which can be used as <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9560297346392626769&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=40">Cited by 14</a> <a href="/scholar?q=related:UZbXrsj_rIQJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9560297346392626769&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'UZbXrsj_rIQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="ftp://ftp.umiacs.umd.edu/pub/chenxi/Project%20FTP/OLD/Submodular/tag_local_cvpr_2011_yangyang.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from umd.edu</span><span class="gs_ggsS">umd.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5995499" class=yC6>Tag localization with spatial correlations and joint group sparsity</a></h3><div class="gs_a"><a href="/citations?user=PVv2xDYAAAAJ&amp;hl=en&amp;oi=sra">Y Yang</a>, <a href="/citations?user=RMSuNFwAAAAJ&amp;hl=en&amp;oi=sra">Y Yang</a>, Z Huang, <a href="/citations?user=krryaDkAAAAJ&amp;hl=en&amp;oi=sra">HT Shen</a>&hellip; - Computer Vision and  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Nowadays numerous social images have been emerging on the Web. How to <br>precisely label these images is critical to image retrieval. However, traditional image-level <br>tagging methods may become less effective because global image matching approaches <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15533505240160265369&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=40">Cited by 14</a> <a href="/scholar?q=related:meRrRLcYktcJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15533505240160265369&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'meRrRLcYktcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://archive.itee.uq.edu.au/~uqyyan10/papers/wwwj.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uq.edu.au</span><span class="gs_ggsS">uq.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/732M8G373RV73181.pdf" class=yC8>Mining multi-tag association for image tagging</a></h3><div class="gs_a"><a href="/citations?user=PVv2xDYAAAAJ&amp;hl=en&amp;oi=sra">Y Yang</a>, Z Huang, <a href="/citations?user=krryaDkAAAAJ&amp;hl=en&amp;oi=sra">HT Shen</a>, <a href="/citations?user=y6m820wAAAAJ&amp;hl=en&amp;oi=sra">X Zhou</a> - World Wide Web, 2011 - Springer</div><div class="gs_rs">Abstract Automatic media tagging plays a critical role in modern tag-based media retrieval <br>systems. Existing tagging schemes mostly perform tag assignment based on community <br>contributed media resources, where the tags are provided by users interactively. However, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14467407038118961623&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=40">Cited by 12</a> <a href="/scholar?q=related:1yERsAyOxsgJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14467407038118961623&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'1yERsAyOxsgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5540033" class=yCA>Nonparametric label-to-region by search</a></h3><div class="gs_a">X Liu, <a href="/citations?user=DNuiPHwAAAAJ&amp;hl=en&amp;oi=sra">S Yan</a>, <a href="/citations?user=CcbnBvgAAAAJ&amp;hl=en&amp;oi=sra">J Luo</a>, <a href="/citations?user=ByBLlEwAAAAJ&amp;hl=en&amp;oi=sra">J Tang</a>&hellip; - Computer Vision and  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this work, we investigate how to propagate annotated labels for a given single <br>image from the image-level to their corresponding semantic regions, namely Label-to-<br>Region (L2R), by utilizing the auxiliary knowledge from Internet image search with the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8081740356259420413&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=40">Cited by 8</a> <a href="/scholar?q=related:_RjI_QgcKHAJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8081740356259420413&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'_RjI_QgcKHAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5756484" class=yCB>Tag tagging: towards more descriptive keywords of image content</a></h3><div class="gs_a"><a href="/citations?user=g2gAY_0AAAAJ&amp;hl=en&amp;oi=sra">K Yang</a>, <a href="/citations?user=6G-l4o0AAAAJ&amp;hl=en&amp;oi=sra">XS Hua</a>, <a href="/citations?user=rHagaaIAAAAJ&amp;hl=en&amp;oi=sra">M Wang</a>&hellip; - &hellip; , IEEE Transactions on, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Tags have been demonstrated to be effective and efficient for organizing and <br>searching social image content. However, these human-provided keywords are far from a <br>comprehensive description of the image content, which limits their effectiveness in tag-<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6046709255871788737&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=40">Cited by 4</a> <a href="/scholar?q=related:wfZNCAg66lMJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6046709255871788737&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'wfZNCAg66lMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://vipl.ict.ac.cn/sites/default/files/papers/files/2010_ACMMM_zpwu_Vicept_%20Link%20Visual%20Features%20to%20Concepts%20for%20Large-scale%20Image%20Understanding.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ict.ac.cn</span><span class="gs_ggsS">ict.ac.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1874059" class=yCC>Vicept: link visual features to concepts for large-scale image understanding</a></h3><div class="gs_a">Z Wu, <a href="/citations?user=4Rvn-ykAAAAJ&amp;hl=en&amp;oi=sra">S Jiang</a>, L Li, P Cui, Q Huang&hellip; - Proceedings of the  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract On noticing the paradox of visual polysemia and concept poly-morphism, this paper <br>proposes a new perspective called&quot; Vicept&quot; to associate elementary visual features and <br>cognitive concepts. Firstly, a carefully prepared large image dataset and associate <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15314954435448674535&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=40">Cited by 6</a> <a href="/scholar?q=related:5xg2vOqlidQJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15314954435448674535&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'5xg2vOqlidQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1816084" class=yCE>Beyond tag relevance: integrating visual attention model and multi-instance learning for tag saliency ranking</a></h3><div class="gs_a">S Feng, C Lang, D Xu - &hellip;  of the ACM International Conference on Image  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract Tag ranking has emerged as an important research topic recently due to its <br>potential application on web image search. Conventional tag ranking approaches mainly <br>rank the tags according to their relevance levels with respect to a given image. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15015146307116709129&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=40">Cited by 6</a> <a href="/scholar?q=related:CbU1PgOEYNAJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'CbU1PgOEYNAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://c2inet.sce.ntu.edu.sg/ivor/publication/MLGSc.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntu.edu.sg</span><span class="gs_ggsS">ntu.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5995454" class=yCF>Multi-layer group sparse codingâFor concurrent image classification and annotation</a></h3><div class="gs_a"><a href="/citations?user=fe-1v0MAAAAJ&amp;hl=en&amp;oi=sra">S Gao</a>, <a href="/citations?user=Eeolw80AAAAJ&amp;hl=en&amp;oi=sra">LT Chia</a>, <a href="/citations?user=rJMOlVsAAAAJ&amp;hl=en&amp;oi=sra">IWH Tsang</a> - Computer Vision and Pattern  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We present a multi-layer group sparse coding framework for concurrent image <br>classification and annotation. By leveraging the dependency between image class label and <br>tags, we introduce a multi-layer group sparse structure of the reconstruction coefficients. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7762187774515327005&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=40">Cited by 6</a> <a href="/scholar?q=related:HbDds6fUuGsJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7762187774515327005&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'HbDds6fUuGsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1873951.1874164" class=yC11>Automatic image tagging via category label and web data</a></h3><div class="gs_a"><a href="/citations?user=fe-1v0MAAAAJ&amp;hl=en&amp;oi=sra">S Gao</a>, <a href="/citations?user=43G9x0YAAAAJ&amp;hl=en&amp;oi=sra">Z Wang</a>, <a href="/citations?user=Eeolw80AAAAJ&amp;hl=en&amp;oi=sra">LT Chia</a>, <a href="/citations?user=rJMOlVsAAAAJ&amp;hl=en&amp;oi=sra">IWH Tsang</a> - Proceedings of the international  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract Image tagging is an important technique for the image content understanding and <br>text based image processing. Given a selection of images, how to tag these images <br>efficiently and effectively is an interesting problem. In this paper, a novel semi-auto image <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=562064742947459082&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=40">Cited by 3</a> <a href="/scholar?q=related:CpAn4OfazAcJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'CpAn4OfazAcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6093776" class=yC12>Objectbook construction for large-scale semantic-aware image retrieval</a></h3><div class="gs_a">S Zhang, <a href="/citations?user=61b6eYkAAAAJ&amp;hl=en&amp;oi=sra">Q Tian</a>, Q Huang&hellip; - &hellip;  Signal Processing (MMSP) &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Automatic image annotation assigns semantic labels to images thus presents great <br>potential to achieve semantic-aware image retrieval. However, existing annotation <br>algorithms are not scalable to this emerging need, both in terms of computational <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12834020192616975733&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=40">Cited by 1</a> <a href="/scholar?q=related:dQ0gHV6ZG7IJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'dQ0gHV6ZG7IJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6123341" class=yC13>Exploiting of flickr note and its applications for social image sharing and search</a></h3><div class="gs_a">JW Jeong, HK Hong, DH Lee - Multimedia (ISM), 2011 IEEE  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present analytical information about Flickr notes and propose <br>further directions of note based image search. Compared to a tag that is used for traditional <br>social image search, Flickr note is a kind of text directly assigned on the image regions. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14258767627540012516&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=40">Cited by 1</a> <a href="/scholar?q=related:5J1cbpxR4cUJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14258767627540012516&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'5J1cbpxR4cUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0925231211003791" class=yC14>Combining visual attention model with multi-instance learning for tag ranking</a></h3><div class="gs_a">S Feng, H Bao, C Lang, D Xu - Neurocomputing, 2011 - Elsevier</div><div class="gs_rs">Tag ranking has emerged as an important research topic recently due to its potential <br>application on web image search. Existing tag relevance ranking approaches mainly rank <br>the tags according to their relevance levels with respect to a given image. Nonetheless, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17861901088999897677&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=40">Cited by 1</a> <a href="/scholar?q=related:TXoAb2c44vcJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17861901088999897677&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'TXoAb2c44vcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://grid.hust.edu.cn/xbliu/papers/mmfct05883_liu.pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hust.edu.cn</span><span class="gs_ggsS">hust.edu.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1873951.1873968" class=yC15>Image segmentation with patch-pair density priors</a></h3><div class="gs_a">X Liu, <a href="/citations?user=Q8iay0gAAAAJ&amp;hl=en&amp;oi=sra">J Feng</a>, <a href="/citations?user=DNuiPHwAAAAJ&amp;hl=en&amp;oi=sra">S Yan</a>, <a href="/citations?user=o02W0aEAAAAJ&amp;hl=en&amp;oi=sra">H Jin</a> - Proceedings of the international conference  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we investigate how an unlabeled image corpus can facilitate the <br>segmentation of any given image. A simple yet efficient multi-task joint sparse representation <br>model is presented to augment the patch-pair similarities by harnessing the newly <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12183432951448136122&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=40">Cited by 4</a> <a href="/scholar?q=related:uuna_7c_FKkJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12183432951448136122&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'uuna_7c_FKkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://c2inet.sce.ntu.edu.sg/ivor/publication/KSR.pdf" class=yC18><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntu.edu.sg</span><span class="gs_ggsS">ntu.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://c2inet.sce.ntu.edu.sg/ivor/publication/KSR.pdf" class=yC17>Sparse Representation with Kernels</a></h3><div class="gs_a">S Gaoab, <a href="/citations?user=rJMOlVsAAAAJ&amp;hl=en&amp;oi=sra">IWH Tsanga</a>, LT Chiaa - 2012 - c2inet.sce.ntu.edu.sg</div><div class="gs_rs">AbstractâRecent research has shown the initial success of sparse coding (Sc) in solving <br>many computer vision tasks. Motivated by the fact that kernel trick can capture the nonlinear <br>similarity of features, which helps find a sparse representation of nonlinear features, we <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:hf50ALhfq6MJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'hf50ALhfq6MJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md15', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md15" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:hf50ALhfq6MJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://groups.inf.ed.ac.uk/calvin/Publications/kuettel-mmm12.pdf" class=yC1A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ed.ac.uk</span><span class="gs_ggsS">ed.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/2635522026JQ1073.pdf" class=yC19>Combining Image-Level and Segment-Level Models for Automatic Annotation</a></h3><div class="gs_a">D Kuettel, <a href="/citations?user=jFdZ8s4AAAAJ&amp;hl=en&amp;oi=sra">M Guillaumin</a>, <a href="/citations?user=4QvYJ00AAAAJ&amp;hl=en&amp;oi=sra">V Ferrari</a> - Advances in Multimedia Modeling, 2012 - Springer</div><div class="gs_rs">For the task of assigning labels to an image to summarize its contents, many early attempts <br>use segment-level information and try to determine which parts of the images correspond to <br>which labels. Best performing methods use global image similarity and nearest neighbor <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=843966214950888002&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=40">Cited by 1</a> <a href="/scholar?q=related:QiKUDM1etgsJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=843966214950888002&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'QiKUDM1etgsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://www.nlpr.ia.ac.cn/2011papers/gjhy/gh33.pdf" class=yC1C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ia.ac.cn</span><span class="gs_ggsS">ia.ac.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6116130" class=yC1B>One step beyond bags of features: Visual categorization using components</a></h3><div class="gs_a">J Liu, C Zhang, <a href="/citations?user=61b6eYkAAAAJ&amp;hl=en&amp;oi=sra">Q Tian</a>, C Xu, H Lu&hellip; - Image Processing (ICIP), &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The bag-of-visual-words (BoW) representation has received wide application and <br>public acceptance for visual categorization. However, the histogram based image <br>representation ignores the spatial information and correlations among visual words. To <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12189994038282073721&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=40">Cited by 1</a> <a href="/scholar?q=related:ebbuEf6OK6kJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12189994038282073721&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'ebbuEf6OK6kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB18" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW18"><a href="http://c2inet.sce.ntu.edu.sg/ivor/publication/MLLperf.pdf" class=yC1E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntu.edu.sg</span><span class="gs_ggsS">ntu.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6378455" class=yC1D>Objective-guided Image Annotation</a></h3><div class="gs_a">Q Mao, <a href="/citations?user=rJMOlVsAAAAJ&amp;hl=en&amp;oi=sra">IWH Tsang</a>, <a href="/citations?user=fe-1v0MAAAAJ&amp;hl=en&amp;oi=sra">S Gao</a> - 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Automatic image annotation, which is usually formulated as a multi-label <br>classification problem, is one of major tools to enhance the semantic understanding of web <br>images. Many multimedia applications (eg, tag-based image retrieval) can greatly benefit <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'b5dAJc4Grw0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="http://users.cis.fiu.edu/~lli003/pub/multimedia.pdf" class=yC20><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from fiu.edu</span><span class="gs_ggsS">fiu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/T3H5145346124054.pdf" class=yC1F>A multimedia information fusion framework for web image categorization</a></h3><div class="gs_a">W Lu, <a href="/citations?user=b8sYKJIAAAAJ&amp;hl=en&amp;oi=sra">L Li</a>, J Li, <a href="/citations?user=_SuhcLEAAAAJ&amp;hl=en&amp;oi=sra">T Li</a>, H Zhang, J Guo - Multimedia Tools and Applications, 2012 - Springer</div><div class="gs_rs">Abstract With the rapid development of technologies for fast Internet access and the <br>popularization of digital cameras, an enormous number of digital images are posted and <br>shared online everyday. Web images are usually organized by topic and are often <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:_zQ_Kin3fcoJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14591090123924780287&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'_zQ_Kin3fcoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB20" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW20"><a href="http://www4.comp.polyu.edu.hk/~csshzhong/MTA2011.pdf" class=yC22><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from polyu.edu.hk</span><span class="gs_ggsS">polyu.edu.hk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/H0W0005H734NQ728.pdf" class=yC21>Region level annotation by fuzzy based contextual cueing label propagation</a></h3><div class="gs_a">S Zhong, Y Liu, Y Liu, F Chung - Multimedia Tools and Applications, 2012 - Springer</div><div class="gs_rs">Abstract This paper investigates the challenging issue of assigning given image-level <br>annotations to precise regions on images. We propose a novel label to region assignment <br>(LRA) technique called Fuzzy-based Contextual-cueing Label Propagation (FCLP) with <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:xZbaLn9k_SMJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2593339457844975301&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'xZbaLn9k_SMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/ZhaZJ_Chapter_Text%20Mining%20in%20Multimedia.pdf" class=yC24><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/L65T405M346055V8.pdf" class=yC23>Text Mining in Multimedia</a></h3><div class="gs_a">ZJ Zha, M Wang, <a href="/citations?user=d3h-zScAAAAJ&amp;hl=en&amp;oi=sra">J Shen</a>, TS Chua - Mining Text Data, 2012 - Springer</div><div class="gs_rs">A large amount of multimedia data (eg, image and video) is now available on the Web. A <br>multimedia entity does not appear in isolation, but is accompanied by various forms of <br>metadata, such as surrounding text, user tags, ratings, and comments etc. Mining these <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:VB61TlfctuwJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17057062906253090388&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'VB61TlfctuwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/1241H063352T5218.pdf" class=yC25>Interactive search in image retrieval: a survey</a></h3><div class="gs_a">B Thomee, MS Lew - International Journal of Multimedia Information  &hellip;, 2012 - Springer</div><div class="gs_rs">Abstract We are living in an Age of Information where the amount of accessible data from <br>science and culture is almost limitless. However, this also means that finding an item of <br>interest is increasingly difficult, a digital needle in the proverbial haystack. In this article, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17773798055170681003&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=40">Cited by 2</a> <a href="/scholar?q=related:qyj6Wyk3qfYJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17773798055170681003&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'qyj6Wyk3qfYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB23" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW23"><a href="http://www.cmlab.csie.ntu.edu.tw/~zenic/Download/ICME2012/Workshops/data/4729a236.pdf" class=yC27><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntu.edu.tw</span><span class="gs_ggsS">ntu.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6266261" class=yC26>Social Attribute Annotation for Personal Photo Collection</a></h3><div class="gs_a">Z Wu, K Aizawa - &hellip;  and Expo Workshops (ICMEW), 2012 IEEE  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Social attributes for photos, which simply refer to a set of labels {Who, When, <br>Where, What}, are intrinsic attributes of an image. For instance, given a scenery photo <br>without human bodies or faces, we cannot say the photo has no relation with social <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:A2d3c9-VD00J:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5552821652518561539&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'A2d3c9-VD00J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2333120" class=yC28>Assistive tagging: A survey of multimedia tagging with human-computer joint exploration</a></h3><div class="gs_a"><a href="/citations?user=rHagaaIAAAAJ&amp;hl=en&amp;oi=sra">M Wang</a>, <a href="/citations?user=V9W87PYAAAAJ&amp;hl=en&amp;oi=sra">B Ni</a>, <a href="/citations?user=6G-l4o0AAAAJ&amp;hl=en&amp;oi=sra">XS Hua</a>, TS Chua - ACM Computing Surveys (CSUR), 2012 - dl.acm.org</div><div class="gs_rs">Abstract Along with the explosive growth of multimedia data, automatic multimedia tagging <br>has attracted great interest of various research communities, such as computer vision, <br>multimedia, and information retrieval. However, despite the great progress achieved in the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9840991510067465628&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=40">Cited by 4</a> <a href="/scholar?q=related:nM00e6M5kogJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'nM00e6M5kogJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB25" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW25"><a href="http://www.cmlab.csie.ntu.edu.tw/~zenic/Download/ICME2012/Conference/data/4711a266.pdf" class=yC2A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntu.edu.tw</span><span class="gs_ggsS">ntu.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6298245" class=yC29>Noisy Tag Alignment with Image Regions</a></h3><div class="gs_a">Y Liu, J Liu, Z Li, H Lu - Multimedia and Expo (ICME), 2012  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract With the permeation of Web 2.0, large-scale user contributed images with tags are <br>easily available on social websites. How to align these social tags with image regions is a <br>challenging task while no additional human intervention is considered, but a valuable one <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Y3TCk5nBmAcJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=547400220078666851&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'Y3TCk5nBmAcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB26" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW26"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.188.6683&amp;rep=rep1&amp;type=pdf" class=yC2C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.188.6683&amp;rep=rep1&amp;type=pdf" class=yC2B>Automatic Image Tagging via Category Label and Web Data</a></h3><div class="gs_a">ZW ShenghuaGao, IWHT Liang-TienChia - 2010 - Citeseer</div><div class="gs_rs">ABSTRACT Image tagging is an important technique for the image content understanding <br>and text based image processing. Given a selection of images, how to tag these images <br>efficiently and effectively is an interesting problem. In this paper, a novel semi-auto image <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:0oPTlD8uzbAJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12739889771515708370&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'0oPTlD8uzbAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md26', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md26" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:0oPTlD8uzbAJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/ft_gateway.cfm?id=1937729&amp;type=pdf" class=yC2D>Fuzzy Based Contextual Cueing for Region Level Annotation</a></h3><div class="gs_a">S Zhong, Y Liu, Y Liu, F Chung - 2010 - dl.acm.org</div><div class="gs_rs">ABSTRACT This paper investigates the challenging issue of assigning given image-level <br>annotations to precise regions on natural images. We propose a novel label to region <br>assignment (LRA) technique called Fuzzy-based Contextual-cueing Label Propagation (<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:bRGImGolvzgJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'bRGImGolvzgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB28" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW28"><a href="http://www.ijert.org/browse/december-2012-edition?download=1851%3Aa-survey-on-image-parsing&amp;start=90" class=yC2F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ijert.org</span><span class="gs_ggsS">ijert.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ijert.org/browse/december-2012-edition?download=1851%3Aa-survey-on-image-parsing&amp;start=90" class=yC2E>A Survey on Image Parsing</a></h3><div class="gs_a">R Sumathi, D Narmadha - International Journal of Engineering, 2012 - ijert.org</div><div class="gs_rs">Abstract Image parsing aims to decompose an image into semantically consistent regions, it <br>is basically a challenging problem. In the earlier days parsing is used for text annotation. <br>Nowadays an effective image parsing facilitates many higher level image processing <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'tRJPneA-JK8J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md28', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md28" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:tRJPneA-JK8J:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6380623" class=yC30>Video-to-Shot Tag Propagation by Graph Sparse Group Lasso</a></h3><div class="gs_a">X Zhu, Z Huang, J Cui, <a href="/citations?user=krryaDkAAAAJ&amp;hl=en&amp;oi=sra">H Shen</a> - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Traditional approaches to video tagging are designed to propagate tags at the <br>same level, such as generating tags for the test video when the training videos are <br>associated with the tags at the video-level or assigning tags to the test shot when given a <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'0c5mnwWSqk0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320312004608" class=yC31>Local image tagging via graph regularized joint group sparsity</a></h3><div class="gs_a"><a href="/citations?user=ftiJp4kAAAAJ&amp;hl=en&amp;oi=sra">Y Yang</a>, Z Huang, <a href="/citations?user=ImSq_AoAAAAJ&amp;hl=en&amp;oi=sra">Y Yang</a>, J Liu, H Tao Shen, <a href="/citations?user=CcbnBvgAAAAJ&amp;hl=en&amp;oi=sra">J Luo</a> - Pattern Recognition, 2012 - Elsevier</div><div class="gs_rs">In recent years, massive amounts of web image data have been emerging on the web. How <br>to precisely label these images is critical and challenging to modern image search engines. <br>Due to the fact that web image contents are more and more complex, existing image-level <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'7yUHsOvDnbgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.dbpia.co.kr/view/ar_view.asp?arid=1837079" class=yC32>A New Connected Coherence Tree Algorithm For Image Segmentation</a></h3><div class="gs_a">Z Jin - KSII Transactions on Internet and Information Systems ( &hellip;, 2012 - dbpia.co.kr</div><div class="gs_rs">&amp;nbsp; &amp;nbsp; In this paper, we propose a new multi-scale connected coherence tree <br>algorithm (MCCTA) by improving the connected coherence tree algorithm (CCTA). In <br>contrast to many multi-scale image processing algorithms, MCCTA works on multiple <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:1wBOxiqMsD4J:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'1wBOxiqMsD4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB32" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW32"><a href="http://www.ami-lab.org/uploads/Publications/Journal/WP4/28_Weakly-Supervised%20Graph%20Propagation%20Towards%20Collective%20Image%20Parsing.pdf" class=yC34><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ami-lab.org</span><span class="gs_ggsS">ami-lab.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6069864" class=yC33>Weakly Supervised Graph Propagation Towards Collective Image Parsing</a></h3><div class="gs_a">S Liu, <a href="/citations?user=DNuiPHwAAAAJ&amp;hl=en&amp;oi=sra">S Yan</a>, <a href="/citations?user=9sCGe-gAAAAJ&amp;hl=en&amp;oi=sra">T Zhang</a>, C Xu, J Liu&hellip; - &hellip; , IEEE Transactions on, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this work, we propose a weakly supervised graph propagation method to <br>automatically assign the annotated labels at image level to those contextually derived <br>semantic regions. The graph is constructed with the over-segmented patches of the image <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:cQDRytL_94kJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9941695983254569073&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'cQDRytL_94kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:367"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2379792" class=yC35>Label-to-region with continuity-biased bi-layer sparsity priors</a></h3><div class="gs_a">X Liu, <a href="/citations?user=DNuiPHwAAAAJ&amp;hl=en&amp;oi=sra">S Yan</a>, B Cheng, <a href="/citations?user=ByBLlEwAAAAJ&amp;hl=en&amp;oi=sra">J Tang</a>, TS Chua&hellip; - ACM Transactions on  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract In this work, we investigate how to reassign the fully annotated labels at image level <br>to those contextually derived semantic regions, namely Label-to-Region (L2R), in a <br>collective manner. Given a set of input images with label annotations, the basic idea of our <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'ZIYQ6xvd2r4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:366"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2072050" class=yC36>Video-to-shot tag allocation by weighted sparse group lasso</a></h3><div class="gs_a">X Zhu, Z Huang, <a href="/citations?user=krryaDkAAAAJ&amp;hl=en&amp;oi=sra">HT Shen</a> - Proceedings of the 19th ACM international  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract Traditional shot tagging techniques are focused on learning and propagating the <br>tags at the same level, that is from labeled training shots to the unknown test shots. Due to <br>the lack of sufficient labeled video shots, effective shot tagging remains challenging. By <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1168820004343897510&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=40">Cited by 1</a> <a href="/scholar?q=related:pt1J7Zl7OBAJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1168820004343897510&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'pt1J7Zl7OBAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:365"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2396331" class=yC37>Social tag alignment with image regions by sparse reconstructions</a></h3><div class="gs_a">Y Liu, J Liu, Z Li, B Niu, H Lu - Proceedings of the 20th ACM international &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract How to align social tags with image regions without additional human intervention <br>is a challenging but a valuable task since it can provide more detailed image semantic <br>information and improve the accuracy of image retrieval. To this end, we propose a novel <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'4Ds4-ISvCIgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:364"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/90976x/201202/40870905.html" class=yC38>åºäºç½ç»ç¼ç äº¤æ¢ç³»ç»ä»¿çå¹³å°çè®¾è®¡ä¸å®ç°</a></h3><div class="gs_a">æ´å¯ï¼ è®¸è¤é¾ï¼ æææ - è®¡ç®æºåºç¨ä¸è½¯ä»¶, 2012 - cqvip.com</div><div class="gs_rs">ç½ç»ç¼ç å·²è¢«è¯æå¯ä»¥ä¼åäº¤æ¢ç³»ç»ä¼ è¾æç, ç¶èä¸è¢«ä¼ ç»äº¤æ¢ç³»ç»çç»æææ¯æ. <br>åºäºæµè¡çCrossbar ç»æ, éç¨æ¨¡ååè®¾è®¡æ¹æ³, å®ç°äºåºäºç½ç»ç¼ç äº¤æ¢ç³»ç»ä»¿çå¹³å°â<br>NCSPS (Network-Cod ing based S imu lation P latform for Sw itches). è¯¥å¹³å°å®ç°äºè¾å¥, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7602750408650972207&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=40">Cited by 1</a> <a href="/scholar?q=related:L9yYLzdlgmkJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7602750408650972207&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'L9yYLzdlgmkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:363"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB37" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW37"><a href="https://openaccess.leidenuniv.nl/bitstream/handle/1887/16108/Thesis+Final+Submission.pdf?sequence=1" class=yC3A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from leidenuniv.nl</span><span class="gs_ggsS">leidenuniv.nl <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="https://openaccess.leidenuniv.nl/handle/1887/16108" class=yC39>A picture is worth a thousand words: content-based image retrieval techniques</a></h3><div class="gs_a">B ThomÃ©e - 2010 - openaccess.leidenuniv.nl</div><div class="gs_rs">In my dissertation I investigate techniques for improving the state of the art in content-based <br>image retrieval. To place my work into context, I highlight the current trends and challenges <br>in my field by analyzing over 200 recent articles. Next, I propose a novel paradigm called &#39;<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:8okDs3CrpVEJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'8okDs3CrpVEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md37', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md37" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:8okDs3CrpVEJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=13697509785451488659&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:362"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/90976x/201202/40870900.html" class=yC3B>åºäº EM çéçç£å¾åå¤æ ç­¾åºåæ å®ç®æ³</a></h3><div class="gs_a">æ»èï¼ é­è·é£ - è®¡ç®æºåºç¨ä¸è½¯ä»¶, 2012 - cqvip.com</div><div class="gs_rs">æåºä¸ä¸ªåºäºEM è¿­ä»£çéçç£å¾åå¤æ ç­¾åºåæ å®ç®æ³, å®è½å¤éå¸¸ææå°å°åºäºå¨å¾çæ ç­¾<br>èªå¨æ å®å°å¾åçå¯¹åºå±é¨åºåä¸. é¦åå¯¹ææå¾åè¿è¡SIFT ç¹å¾ç¹çå¯ééæ ·, <br>ç¶åå¯¹ææçSIFT ç¹å¾ç¹è¿è¡Km eans èç±», è·å¾è¯å¸, åæé EM è¿­ä»£è¿ç¨è®¡ç®åºæ¯å¹å¾å<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:hQI91FAtnlAJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5809130394535920261&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'hQI91FAtnlAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:361"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.dbpia.co.kr/Journal/ArticleDetail/1521805" class=yC3C>ìì ë¯¸ëì´ ê²ìì ìí Flickr Note ì ë¶ì ë° ìì©ì ê´í ì°êµ¬</a></h3><div class="gs_a">ì ì§ì°ï¼ ííê¸°ï¼ ì´ëí¸ - íêµ­ì ë³´ê³¼íí íì ë°íë¼ë¬¸ì§, 2011 - dbpia.co.kr</div><div class="gs_rs">ë³¸ ì°êµ¬ììë Flickr ìì ì ê³µíë ì´ë¸íì´ì ê¸°ë² ì¤ Note ìë¹ì¤ì ëí ë¤ìí ë¶ì <br>ê²°ê³¼ë¥¼ ì ê³µíê³ , ì´ë¥¼ ê¸°ë°ì¼ë¡ ìì ë¯¸ëì´ ê²ìì ìí Flickr Note ì ìì© ë°©ìì ì ìíë¤. <br>Flickr Note ë ê¸°ì¡´ì íê·¸ ê¸°ë° ê²ììì íì©ëë íê·¸ìë ë¬ë¦¬ ì´ë¯¸ì§ì í¹ì  ìì­ ìì <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:hcjM98VQCzEJ:scholar.google.com/&amp;hl=en&amp;num=40&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'hcjM98VQCzEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
