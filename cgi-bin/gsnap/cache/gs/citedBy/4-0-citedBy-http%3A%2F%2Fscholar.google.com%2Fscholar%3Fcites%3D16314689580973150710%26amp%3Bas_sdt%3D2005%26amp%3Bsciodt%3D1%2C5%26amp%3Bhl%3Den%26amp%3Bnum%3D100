Total results = 4
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="https://www.iscs.nus.edu.sg/~sugiyama/papers/CICling09Sugiyama.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/G7665418G7532U59.pdf" class=yC0>Semi-supervised clustering for word instances and its effect on word sense disambiguation</a></h3><div class="gs_a"><a href="/citations?user=BYXCheYAAAAJ&amp;hl=en&amp;oi=sra">K Sugiyama</a>, M Okumura - Computational Linguistics and Intelligent Text  &hellip;, 2009 - Springer</div><div class="gs_rs">Abstract. We propose a supervised word sense disambiguation (WSD) system that uses <br>features obtained from clustering results of word instances. Our approach is novel in that we <br>employ semi-supervised clustering that controls the fluctuation of the centroid of a cluster, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8627022273865755304&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=4">Cited by 1</a> <a href="/scholar?q=related:qKom1wxXuXcJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8627022273865755304&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'qKom1wxXuXcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6022245" class=yC2>Semi-supervised Chinese contextual polarity classification with automatic feature selection</a></h3><div class="gs_a">G Xu, H Wang - Natural Computation (ICNC), 2011 Seventh  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Common approaches to the tasks of sentiment analysis start with a list of words with <br>prior polarities, which are context-free. However, a word can exhibit different polarities in <br>different contexts, which are termed as contextual polarities. In this paper, viewing <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:u5T6hZ1dDkAJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4615729599240377531&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'u5T6hZ1dDkAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/C115M1821149576K.pdf" class=yC3>Macro Features Based Text Categorization</a></h3><div class="gs_a">D Wang, Q Chen, X Wang, B Tang - Neural Information Processing, 2011 - Springer</div><div class="gs_rs">Text Categorization (TC) is one of the key techniques in web information processing. A lot of <br>approaches have been proposed to do TC; most of them are based on the text <br>representation using the distributions and relationships of terms, few of them take the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:gNd5i4xEySwJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'gNd5i4xEySwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://arxiv.org/pdf/1112.0611" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arxiv.org</span><span class="gs_ggsS">arxiv.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://arxiv.org/abs/1112.0611" class=yC4>Information-Maximization Clustering based on Squared-Loss Mutual Information</a></h3><div class="gs_a"><a href="/citations?user=GkYIrlIAAAAJ&amp;hl=en&amp;oi=sra">M Sugiyama</a>, M Yamada, M Kimura&hellip; - arXiv preprint arXiv: &hellip;, 2011 - arxiv.org</div><div class="gs_rs">Abstract: Information-maximization clustering learns a probabilistic classifier in an <br>unsupervised manner so that mutual information between feature vectors and cluster <br>assignments is maximized. A notable advantage of this approach is that it only involves <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:d224sBiAOZUJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10752766428856216951&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'d224sBiAOZUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
