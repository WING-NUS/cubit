Total results = 39
<div class="gs_r" style="z-index:400"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1180699" class=yC0>Live sports event detection based on broadcast video and web-casting text</a></h3><div class="gs_a">C Xu, J Wang, K Wan, Y Li, L Duan - Proceedings of the 14th annual  &hellip;, 2006 - dl.acm.org</div><div class="gs_rs">Abstract Event detection is essential for sports video summarization, indexing and retrieval <br>and extensive research efforts have been devoted to this area. However, the previous <br>approaches are heavily relying on video content itself and require the whole video content <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10303468019780515411&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 85</a> <a href="/scholar?q=related:U3ad6ZJF_Y4J:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10303468019780515411&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'U3ad6ZJF_Y4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://avss2012.org/2008papers/gjkw/gk8.pdf" class=yC2><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from avss2012.org</span><span class="gs_ggsS">avss2012.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4469885" class=yC1>A novel framework for semantic annotation and personalized retrieval of sports video</a></h3><div class="gs_a">C Xu, J Wang, H Lu, Y Zhang - Multimedia, IEEE Transactions  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Sports video annotation is important for sports video semantic analysis such as <br>event detection and personalization. In this paper, we propose a novel approach for sports <br>video semantic annotation and personalized retrieval. Different from the state of the art <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9150671654910331118&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 70</a> <a href="/scholar?q=related:7ogqR2O3_X4J:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/1A/16/RN226783660.html?source=googlescholar" class="gs_nph" class=yC3>BL Direct</a> <a href="/scholar?cluster=9150671654910331118&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'7ogqR2O3_X4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://nlpr-web.ia.ac.cn/2008papers/gjkw/gk9.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ia.ac.cn</span><span class="gs_ggsS">ia.ac.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4668533" class=yC4>Using webcast text for semantic event detection in broadcast sports video</a></h3><div class="gs_a">C Xu, YF Zhang, G Zhu, <a href="/citations?user=uOJH_AEAAAAJ&amp;hl=en&amp;oi=sra">Y Rui</a>, H Lu&hellip; - &hellip; , IEEE Transactions on, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Sports video semantic event detection is essential for sports video summarization <br>and retrieval. Extensive research efforts have been devoted to this area in recent years. <br>However, the existing sports video event detection approaches heavily rely on either <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10746102338593290273&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 44</a> <a href="/scholar?q=related:IfjYQyTTIZUJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10746102338593290273&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'IfjYQyTTIZUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://www.mirlab.org/conference_papers/International_Conference/ACM%202005/docs/mm735.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mirlab.org</span><span class="gs_ggsS">mirlab.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1101309" class=yC6>Automatic generation of personalized music sports video</a></h3><div class="gs_a">J Wang, C Xu, <a href="/citations?user=FJodrCcAAAAJ&amp;hl=en&amp;oi=sra">E Chng</a>, L Duan, K Wan&hellip; - Proceedings of the 13th  &hellip;, 2005 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we propose a novel automatic approach for personalized music sports <br>video generation. Two research challenges, semantic sports video content selection and <br>automatic video composition, are addressed. For the first challenge, we propose to use <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3258662872762225524&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 35</a> <a href="/scholar?q=related:dBO_HZ4YOS0J:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3258662872762225524&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'dBO_HZ4YOS0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/acm-tomccap06-xuhx.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1126007" class=yC8>Fusion of AV features and external information sources for event detection in team sports video</a></h3><div class="gs_a">H Xu, TS Chua - ACM Transactions on Multimedia Computing,  &hellip;, 2006 - dl.acm.org</div><div class="gs_rs">Abstract The use of AV features alone is insufficient to induce high-level semantics. This <br>article proposes a framework that utilizes both internal AV features and various types of <br>external information sources for event detection in team sports video. Three schemes are <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9085544146769579941&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 27</a> <a href="/scholar?q=related:pY9Uo0NWFn4J:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9085544146769579941&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'pY9Uo0NWFn4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://www.cdvp.dcu.ie/Papers/mir414-Smeaton.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from dcu.ie</span><span class="gs_ggsS">dcu.ie <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1178709" class=yCA>Automatically selecting shots for action movie trailers</a></h3><div class="gs_a"><a href="/citations?user=o7xnW2MAAAAJ&amp;hl=en&amp;oi=sra">AF Smeaton</a>, B Lehane, <a href="/citations?user=_i78M7gAAAAJ&amp;hl=en&amp;oi=sra">NE O&#39;Connor</a>, C Brady&hellip; - Proceedings of the 8th  &hellip;, 2006 - dl.acm.org</div><div class="gs_rs">Abstract Movie trailers, or previews, are an important method of advertising movies. They are <br>extensively shown before movies in cinemas, as well as on television and increasingly, over <br>the Internet. Making a trailer is a creative process, in which a number of shots from a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12917884886436129283&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 19</a> <a href="/scholar?q=related:A6ppwdyLRbMJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12917884886436129283&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'A6ppwdyLRbMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://pdf.aminer.org/000/330/915/an_event_model_and_its_implementation_for_multimedia_information_representation.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aminer.org</span><span class="gs_ggsS">aminer.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1623899" class=yCC>{rm E}-A Generic Event Model for Event-Centric Multimedia Data Management in eChronicle Applications</a></h3><div class="gs_a">U Westermann, R Jain - Data Engineering Workshops, 2006.  &hellip;, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract eChronicle applications are inherently event-centric, enabling users to find and <br>explore important events in an application domain and providing unified access to any <br>media that document them. Today&#39;s multimedia data management components such as <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11156058407957076146&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 19</a> <a href="/scholar?q=related:spjKwwNI0poJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11156058407957076146&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'spjKwwNI0poJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://cmlab.csie.org/new_cml_website/media/publications/Chu-2007-ESE.pdf" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from csie.org</span><span class="gs_ggsS">csie.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/X6284571425R8J36.pdf" class=yCE>Explicit semantic events detection and development of realistic applications for broadcasting baseball videos</a></h3><div class="gs_a"><a href="/citations?user=DcltNjQAAAAJ&amp;hl=en&amp;oi=sra">WT Chu</a>, JL Wu - Multimedia Tools and Applications, 2008 - Springer</div><div class="gs_rs">Abstract This paper presents a framework that explicitly detects events in broadcasting <br>baseball videos and facilitates the development of many practical applications. Three <br>phases of contributions are included in this work: reliable shot classification, explicit event <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17180811152707944918&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 18</a> <a href="/scholar?q=related:1gE6LreAbu4J:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/2F/21/RN226239466.html?source=googlescholar" class="gs_nph" class=yC10>BL Direct</a> <a href="/scholar?cluster=17180811152707944918&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'1gE6LreAbu4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://www.nlpr.ia.ac.cn/2007papers/gjhy/gh33.pdf" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ia.ac.cn</span><span class="gs_ggsS">ia.ac.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1290126" class=yC11>Personalized retrieval of sports video</a></h3><div class="gs_a">Y Zhang, X Zhang, C Xu, H Lu - Proceedings of the international  &hellip;, 2007 - dl.acm.org</div><div class="gs_rs">Abstract There has been a growing demand for effective access to video information from <br>media archives in recent years. Personalized video retrieval is one of the most challenging <br>issues and has spurred a significant interest in many research communities. In this paper, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1704961240761289856&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 9</a> <a href="/scholar?q=related:gMxiFzc9qRcJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1704961240761289856&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'gMxiFzc9qRcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://kusu.comp.nus.edu/proceedings/icme05/defevent/papers/cr1688.pdf" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu</span><span class="gs_ggsS">nus.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1521653" class=yC13>Fusion of multiple asynchronous information sources for event detection in soccer video</a></h3><div class="gs_a">H Xu, TH Fong, TS Chua - &hellip;  and Expo, 2005. ICME 2005. IEEE  &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Our previous research shows that the use of multiple sources of information based <br>on intrinsic AV features and external knowledge helps to detect events in soccer video. To <br>make the system scalable, we process each source of information independently before <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9377140747617797136&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 8</a> <a href="/scholar?q=related:EISZ5tNLIoIJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9377140747617797136&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'EISZ5tNLIoIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://ipv6.willab.fi/kostas/mobicon-arch.pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from willab.fi</span><span class="gs_ggsS">willab.fi <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=1273493" class=yC15>A mobile phone-based context-aware video management application</a></h3><div class="gs_a">J Lahti, M Palola, J Korva&hellip; - Electronic  &hellip;, 2006 - proceedings.spiedigitallibrary.org</div><div class="gs_rs">abstract We present a video management system comprising a video server and a mobile <br>camera-phone application called MobiCon, which allows users to capture videos, annotate <br>them with metadata, specify digital rights management (DRM) settings, upload the videos <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=834990746452538913&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 9</a> <a href="/scholar?q=related:IbYK8ah7lgsJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/25/45/RN186865363.html?source=googlescholar" class="gs_nph" class=yC17>BL Direct</a> <a href="/scholar?cluster=834990746452538913&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'IbYK8ah7lgsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/G3106576751P3156.pdf" class=yC18>Bayesian belief network based broadcast sports video indexing</a></h3><div class="gs_a">MH Kolekar - Multimedia Tools and Applications, 2011 - Springer</div><div class="gs_rs">Abstract This paper presents a probabilistic Bayesian belief network (BBN) method for <br>automatic indexing of excitement clips of sports video sequences. The excitement clips from <br>sports video sequences are extracted using audio features. The excitement clips are <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14178600211348549160&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 7</a> <a href="/scholar?q=related:KG61UcWBxMQJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14178600211348549160&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'KG61UcWBxMQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://dent.cecs.uci.edu/~papers/icme05/defevent/papers/cr1616.pdf" class=yC1A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uci.edu</span><span class="gs_ggsS">uci.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1521617" class=yC19>Replay scene classification in soccer video using web broadcast text</a></h3><div class="gs_a">J Dai, L Duan, X Tong, C Xu, <a href="/citations?user=HJt0niEAAAAJ&amp;hl=en&amp;oi=sra">Q Tian</a>&hellip; - Multimedia and Expo, &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The automatic extraction of sports video highlights is a typical kind of personalized <br>media production process. Many ways have been studied from the viewpoints of low-level <br>audio/visual processing (eg detection of excited commentator speech), event detection (<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3739351228692672043&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 6</a> <a href="/scholar?q=related:K66lbCHY5DMJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3739351228692672043&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'K66lbCHY5DMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/V258377477378775.pdf" class=yC1B>Semantic concept mining in cricket videos for automated highlight generation</a></h3><div class="gs_a">MH Kolekar, S Sengupta - Multimedia Tools and Applications, 2010 - Springer</div><div class="gs_rs">Abstract This paper presents a novel approach towards automated highlight generation of <br>broadcast sports video sequences from its extracted events and semantic concepts. A sports <br>video is hierarchically divided into temporal partitions namely, megaslots, slots, and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6478082446755480149&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 7</a> <a href="/scholar?q=related:VcKNuKnF5lkJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6478082446755480149&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'VcKNuKnF5lkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://personal.ee.surrey.ac.uk/Personal/R.Ren/pdfs/mobile2006.pdf" class=yC1D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from surrey.ac.uk</span><span class="gs_ggsS">surrey.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1374330" class=yC1C>Attention guided football video content recommendation on mobile devices</a></h3><div class="gs_a">R Ren, <a href="/citations?user=ERvFJGkAAAAJ&amp;hl=en&amp;oi=sra">JM Jose</a> - Proceedings of the 2nd international conference on  &hellip;, 2006 - dl.acm.org</div><div class="gs_rs">Abstract Live football video is the major content genre in 3G mobile service. In this paper, we <br>introduce a realtime general highlight detection algorithm based on attention analysis. It <br>combines attention-related media modalities into role-based attention curves, namely <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18332617382407299778&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 4</a> <a href="/scholar?q=related:wuKJAWGKav4J:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18332617382407299778&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'wuKJAWGKav4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/m352155341187004.pdf" class=yC1E>Personalized sports video customization for mobile devices</a></h3><div class="gs_a">C Liang, Y Jiang, <a href="/citations?user=o8PT69EAAAAJ&amp;hl=en&amp;oi=sra">J Cheng</a>, C Xu, X Luo, <a href="/citations?user=7_BkyxEAAAAJ&amp;hl=en&amp;oi=sra">J Wang</a>&hellip; - Advances in Multimedia  &hellip;, 2010 - Springer</div><div class="gs_rs">Abstract. In this paper, we have designed and implement a mobile personalized sports video <br>customization system, which aims to provide mobile users with interesting video clips <br>according to their personalized preferences. With the B/S architecture, the whole system <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=851461106747205603&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 4</a> <a href="/scholar?q=related:42e6h13_0AsJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=851461106747205603&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'42e6h13_0AsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://140.112.29.131/new_cml_website/media/publications/Chu-2006-DRA.pdf" class=yC20><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 140.112.29.131</span><span class="gs_ggsS">140.112.29.131 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1651296" class=yC1F>Development of realistic applications based on explicit event detection in broadcasting baseball videos</a></h3><div class="gs_a"><a href="/citations?user=DcltNjQAAAAJ&amp;hl=en&amp;oi=sra">WT Chu</a>, JL Wu - Multi-Media Modelling Conference  &hellip;, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents a framework that explicitly detects events in broadcasting <br>baseball videos and facilitates the development of various extended applications. Three <br>phases are included: reliable shot classification, explicit event detection, and elaborate <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14522957330861712027&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 3</a> <a href="/scholar?q=related:m-IqGr_oi8kJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14522957330861712027&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'m-IqGr_oi8kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1386416" class=yC21>An instant semantics acquisition system of live soccer video with application to live event alert and on-the-fly language selection</a></h3><div class="gs_a">X Yu, X Yan, L Li, HW Leong - &hellip;  of the 2008 international conference on  &hellip;, 2008 - dl.acm.org</div><div class="gs_rs">Abstract Automatic indexing of recorded sports video is a hard problem, even more so for <br>live sports video, though a lot of advances have been achieved in the recent years. This <br>paper presents a semi-automatic instant semantics generation system of live soccer video <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2021064417472605362&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 3</a> <a href="/scholar?q=related:suyiL2FDDBwJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'suyiL2FDDBwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4665148" class=yC22>Highlight detection in soccer video using web-casting text</a></h3><div class="gs_a">XF Ding, YJ Miao, F Bu, LF Sun&hellip; - &hellip; Signal Processing, 2008 &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Highlight detection is a challenge task in soccer video analysis. Using Web-casting <br>text as external knowledge is proved to be a short cut to achieve both efficiency and <br>effectiveness. Based on the previous framework using Web-casting text, we have <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=77297618300392894&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 3</a> <a href="/scholar?q=related:vlXHOMadEgEJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'vlXHOMadEgEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="http://doras.dcu.ie/387/1/kamc_2007.pdf" class=yC24><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from dcu.ie</span><span class="gs_ggsS">dcu.ie <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://doras.dcu.ie/387/" class=yC23>An architecture for mining resources complementary to audio-visual streams</a></h3><div class="gs_a">J Nemrava, <a href="/citations?user=aDJBCh4AAAAJ&amp;hl=en&amp;oi=sra">P Buitelaar</a>, T Declerck, <a href="/citations?user=E6iKStUAAAAJ&amp;hl=en&amp;oi=sra">V SvÃ¡tek</a>, J PetrÃ¡k&hellip; - 2007 - doras.dcu.ie</div><div class="gs_rs">In this paper we attempt to characterize resources of information complementary to audio-<br>visual (A/V) streams and propose their usage for enriching A/V data with semantic concepts <br>in order to bridge the gap between low-level video detectors and high-level analysis. Our <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10443804851142254564&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 3</a> <a href="/scholar?q=related:5N_Vry3Z75AJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10443804851142254564&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 18 versions</a> <a onclick="return gs_ocit(event,'5N_Vry3Z75AJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/8J73771071118870.pdf" class=yC25>A comprehensive study of visual event computing</a></h3><div class="gs_a">WQ Yan, DF Kieran, S Rafatirad, R Jain - Multimedia Tools and  &hellip;, 2011 - Springer</div><div class="gs_rs">Abstract This paper contains a survey on aspects of visual event computing. We start by <br>presenting events and their classifications, and continue with discussing the problem of <br>capturing events in terms of photographs, videos, etc, as well as the methodologies for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16788029034595160657&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 3</a> <a href="/scholar?q=related:URL9zXUP--gJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16788029034595160657&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'URL9zXUP--gJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S1047320308001193" class=yC26>Interactive broadcast services for live soccer video based on instant semantics acquisition</a></h3><div class="gs_a">X Yu, L Li, HW Leong - Journal of Visual Communication and Image  &hellip;, 2009 - Elsevier</div><div class="gs_rs">This paper presents a system for providing interactive broadcast services for live soccer <br>video that is based on instant semantics acquisition. Currently, we have implemented two <br>such interactive services: live event alert and on-the-fly language selection. The live event <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11905948295710460944&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 3</a> <a href="/scholar?q=related:EEz9_-RsOqUJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11905948295710460944&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'EEz9_-RsOqUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB22" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW22"><a href="http://cjc.ict.ac.cn/quanwenjiansuo/2008-7/txf.zip" class=yC28><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ict.ac.cn</span><span class="gs_ggsS">ict.ac.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://cjc.ict.ac.cn/quanwenjiansuo/2008-7/txf.zip" class=yC27>ä½è²è§é¢åæ</a></h3><div class="gs_a">ç«¥æå³°ï¼ åéå±±ï¼ å¢æ±æ¸ - è®¡ç®æºå­¦æ¥, 2008 - cjc.ict.ac.cn</div><div class="gs_rs">æè¦ä½è²è§é¢å ä¸ºæ¥ææ°éåºå¤§çåä¼ç¾¤ä½åå·¨å¤§çåä¸åºç¨åæ¯èå¤åç ç©¶èåå·¥ä¸çç<br>å³æ³¨. æä¸­ä»åºå±ç¹å¾æå, ä¸­çº§å³é®å­çæ, é«çº§è¯­ä¹æ¨ç, ç¸å³åºç¨ç ç©¶åååç³»ç»å¼åç­<br>æ¹é¢, ç»¼è¿°äºè¿å¹´æ¥ä½è²è§é¢åæçç ç©¶è¿å±ä»¥åå¯è½çåå±è¶å¿. å³é®è¯ä½è²è§é¢åæ; è¯­ä¹<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15070747761267103782&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 6</a> <a href="/scholar?q=related:JtjWmT0NJtEJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15070747761267103782&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'JtjWmT0NJtEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md22', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md22" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:JtjWmT0NJtEJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB23" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW23"><a href="http://www3.ntu.edu.sg/home/aseschng/SpeechTechWeb/members/Conformation_theses/Thesis_Wang_Jinjun_20071007.pdf" class=yC2A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntu.edu.sg</span><span class="gs_ggsS">ntu.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www3.ntu.edu.sg/home/aseschng/SpeechTechWeb/members/Conformation_theses/Thesis_Wang_Jinjun_20071007.pdf" class=yC29>Content-Based Sports Video Analysis and Composition</a></h3><div class="gs_a">W Jinjun - 2006 - ntu.edu.sg</div><div class="gs_rs">Abstract This thesis proposes solutions for content-based sports video analysis, including <br>multimodal feature extraction, middle-level representation and semantic event detection. In <br>addition, solutions for sports video composition and personalization are also examined. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8897660065604983548&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 2</a> <a href="/scholar?q=related:_FqQFrDWensJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8897660065604983548&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'_FqQFrDWensJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md23', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md23" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:_FqQFrDWensJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4607579" class=yC2B>Tool-aided semantics acquisition for live soccer video</a></h3><div class="gs_a">X Yu, X Yan, Y Li - Multimedia and Expo, 2008 IEEE  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The semantics of live sports video has big value in catering the services demanded <br>by users (eg live event alert and on-the-fly language selection). This paper develops a tool-<br>aided approach to acquire semantics for live soccer video. First, we develop a gamelog <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7997601806808596868&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 2</a> <a href="/scholar?q=related:hEHZXXgw_W4J:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'hEHZXXgw_W4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB25" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW25"><a href="http://pages.cs.brandeis.edu/~marc/misc/proceedings/lrec-2008/workshops/W3_Proceedings.pdf#page=41" class=yC2D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from brandeis.edu</span><span class="gs_ggsS">brandeis.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://pages.cs.brandeis.edu/~marc/misc/proceedings/lrec-2008/workshops/W3_Proceedings.pdf#page=41" class=yC2C>Text Mining Support for Semantic Indexing and Analysis of A/V Streams</a></h3><div class="gs_a">J Nemrava, <a href="/citations?user=aDJBCh4AAAAJ&amp;hl=en&amp;oi=sra">P Buitelaar</a>, <a href="/citations?user=E6iKStUAAAAJ&amp;hl=en&amp;oi=sra">V SvÃ¡tek</a>&hellip; - Workshop  &hellip;, 2008 - pages.cs.brandeis.edu</div><div class="gs_rs">Abstract The work described here concerns the use of complementary resources in sports <br>video analysis; soccer in our case. Structured web data such as match tables with teams, <br>player names, score goals, substitutions, etc. and multiple, unstructured, textual web data <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14340975494733499585&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 1</a> <a href="/scholar?q=related:wQwsEDthBccJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14340975494733499585&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'wQwsEDthBccJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md25', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md25" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:wQwsEDthBccJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB26" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW26"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.143.1669&amp;rep=rep1&amp;type=pdf" class=yC2F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.143.1669&amp;rep=rep1&amp;type=pdf" class=yC2E>Text mining as support for semantic video indexing and analysis</a></h3><div class="gs_a">J Nemrava, <a href="/citations?user=E6iKStUAAAAJ&amp;hl=en&amp;oi=sra">V SvÃ¡tek</a>, <a href="/citations?user=aDJBCh4AAAAJ&amp;hl=en&amp;oi=sra">P Buitelaar</a>&hellip; - &hellip;  of the 2nd K-space PhD  &hellip;, 2008 - Citeseer</div><div class="gs_rs">ABSTRACT This paper presents our work in the field of semantic multimedia annotation and <br>indexing with the use of complementary textual resources analysis. We describe the <br>advantages of complementary sources of information as a support for annotation and test <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3324677229814710891&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 1</a> <a href="/scholar?q=related:a4LvW1OgIy4J:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3324677229814710891&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'a4LvW1OgIy4J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md26', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md26" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:a4LvW1OgIy4J:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB27" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW27"><a href="http://downloads.hindawi.com/journals/ijdmb/2010/836357.pdf" class=yC31><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hindawi.com</span><span class="gs_ggsS">hindawi.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.hindawi.com/journals/ijdmb/2010/836357/abs/" class=yC30>Personalized sports video customization using content and context analysis</a></h3><div class="gs_a">C Liang, C Xu, H Lu - International Journal of Digital Multimedia  &hellip;, 2010 - hindawi.com</div><div class="gs_rs">We present an integrated framework on personalized sports video customization, which <br>addresses three research issues: semantic video annotation, personalized video retrieval <br>and summarization, and system adaptation. Sports video annotation serves as the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9839189406217011968&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 1</a> <a href="/scholar?q=related:AANae6LSi4gJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9839189406217011968&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'AANae6LSi4gJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md27', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md27" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:AANae6LSi4gJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6290490" class=yC32>Learning the fusion of audio and video aggression assessment by meta-information from human annotations</a></h3><div class="gs_a"><a href="/citations?user=gLYiYy4AAAAJ&amp;hl=en&amp;oi=sra">I Lefter</a>, <a href="/citations?user=zN6afwwAAAAJ&amp;hl=en&amp;oi=sra">GJ Burghouts</a>&hellip; - &hellip;  Fusion (FUSION), 2012  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The focus of this paper is finding a method to predict aggression using a multimodal <br>system, given multiple unimodal features. The mechanism underlying multimodal sensor <br>fusion is complex and not completely clear. We try to understand the process of fusion and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3833135276521496295&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 3</a> <a href="/scholar?q=related:5x4VpTkIMjUJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'5x4VpTkIMjUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB29" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW29"><a href="http://www.nlpr.ia.ac.cn/2009papers/gjhy/gh113.pdf" class=yC34><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ia.ac.cn</span><span class="gs_ggsS">ia.ac.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/6116h02751828401.pdf" class=yC33>A Hierarchical Semantics-Matching Approach for Sports Video Annotation</a></h3><div class="gs_a">C Liang, Y Zhang, C Xu, <a href="/citations?user=7_BkyxEAAAAJ&amp;hl=en&amp;oi=sra">J Wang</a>, H Lu - Advances in Multimedia  &hellip;, 2009 - Springer</div><div class="gs_rs">Abstract. Text facilitated sports video analysis has achieved extensive success in video <br>indexing, retrieval and summarization. A commonly adopted basis in previous work is the <br>separate alignment of timestamps between sports video and game text, which isn&#39;ta robust <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11873063040964981707&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 1</a> <a href="/scholar?q=related:y3OJ-O2XxaQJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11873063040964981707&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'y3OJ-O2XxaQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/g445282622103777.pdf" class=yC35>Sports Video Analysis: From Semantics to Tactics</a></h3><div class="gs_a">G Zhu, C Xu, Q Huang - Multimedia Content Analysis, 2009 - Springer</div><div class="gs_rs">Sports content is expected to be a key driver for compelling new infotainment applications <br>and services because of its mass appeal and inherent structures that are amenable for <br>automatic processing. Due to its wide viewership and tremendous commercial value, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:DY3_P2qwst0J:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15975024798623304973&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'DY3_P2qwst0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB31" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW31"><a href="http://www.tmrfindia.org/ijcsa/v7i33.pdf" class=yC37><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tmrfindia.org</span><span class="gs_ggsS">tmrfindia.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.tmrfindia.org/ijcsa/v7i33.pdf" class=yC36>Structure based feature extraction in basketball zone-defense strategies</a></h3><div class="gs_a">A Zheng, J Ma, M Petridis, J Tang, B Luo - International Journal of  &hellip;, 2010 - tmrfindia.org</div><div class="gs_rs">Abstract: This paper proposes a framework for structure-based feature extraction in <br>basketball zonedefense strategies. Firstly, a graphical representation for key-frames <br>extracted from zone-defense video clips is introduced, where each key-frame is expressed <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Wc2fRPwDRHEJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8161652806720146777&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'Wc2fRPwDRHEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md31', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md31" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Wc2fRPwDRHEJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5630661" class=yC38>Personalized Sports Video Customization Based on Multi-modal Analysis for Mobile Devices</a></h3><div class="gs_a">H Xu, X Luo, C Liang - Electrical and Control Engineering ( &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper we have implemented a mobile personalized sports video <br>customization system for mobile users by using a novel approach. The system is based on <br>the B/S architecture, with this architecture, the whole system can be divided into two parts: <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:sqFhS6AhYIEJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9322488201000100274&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'sqFhS6AhYIEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:367"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB33" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW33"><a href="http://doras.dcu.ie/306/1/samt_2007.pdf" class=yC3A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from dcu.ie</span><span class="gs_ggsS">dcu.ie <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://doras.dcu.ie/306/" class=yC39>Architecture for enhancing video analysis results using complementary resources</a></h3><div class="gs_a">J Nemrava, <a href="/citations?user=aDJBCh4AAAAJ&amp;hl=en&amp;oi=sra">P Buitelaar</a>, T Declerck, <a href="/citations?user=E6iKStUAAAAJ&amp;hl=en&amp;oi=sra">V SvÃ¡tek</a>, J PetrÃ¡k&hellip; - 2007 - doras.dcu.ie</div><div class="gs_rs">In this paper we present different sources of information complementary to audio-visual (A/V) <br>streams and propose their usage for enriching A/V data with semantic concepts in order to <br>bridge the gap between low-level video analysis and high-level analysis. Our aim is to <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:WpxDpop6QKwJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12412055308946611290&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'WpxDpop6QKwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:366"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4607644" class=yC3B>Personalization of media and its attention service applications</a></h3><div class="gs_a">LY Duan, C Xu - Multimedia and Expo, 2008 IEEE International  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract A wealth of information creates a poverty of attention and a need to allocate that <br>attention efficiently among the overabundance of information sources that might consume it. <br>Thus personalization systems have become an important research area. This paper gives <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:7VC_2XXYH3sJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'7VC_2XXYH3sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:365"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/V6186W67W14273V5.pdf" class=yC3C>Aggression Detection in Speech Using Sensor and Semantic Information</a></h3><div class="gs_a"><a href="/citations?user=gLYiYy4AAAAJ&amp;hl=en&amp;oi=sra">I Lefter</a>, <a href="/citations?user=YPXhqgUAAAAJ&amp;hl=en&amp;oi=sra">L Rothkrantz</a>, <a href="/citations?user=zN6afwwAAAAJ&amp;hl=en&amp;oi=sra">G Burghouts</a> - Text, Speech and Dialogue, 2012 - Springer</div><div class="gs_rs">By analyzing a multimodal (audio-visual) database with aggressive incidents in trains, we <br>have observed that there are no trivial fusion algorithms to successfully predict multimodal <br>aggression based on unimodal sensor inputs. We proposed a fusion framework that <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7724547347738639258&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 1</a> <a href="/scholar?q=related:mrul6OIaM2sJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'mrul6OIaM2sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:364"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/87685x/200804/29647667.html" class=yC3D>ä¸ç§ Web æ°é»è§é¢åå®¹è¯­ä¹åæ</a></h3><div class="gs_a">ç¦é»å°ï¼ å°åæ°ï¼ ä½ææï¼ æéªé¾ - åäº¬çµå­ç§æå­¦é¢å­¦æ¥, 2009 - cqvip.com</div><div class="gs_rs">è§é¢åå®¹å®å¨åæ, æ¯å¤åªä½åå®¹å®å¨çéè¦ç ç©¶é¢ååç­ç¹é®é¢. æ¬ææåºä¸ç§Web <br>æ°é»è§é¢åå®¹è¯­ä¹åææ¹æ³, è¯¥æ¹æ³å¨æ°é»è§é¢æäºåååå²çåºç¡ä¸, æ ¹æ®ASR (Automatic <br>Speech Recognition) è¯å«çèæ¬å¨è¯­é³ä¸çç¸ä¼¼æ§, éè¿è®¡ç®æ¼é³ç¸ä¼¼åº¦çæ¹æ³æ¥è·åè¯­ä¹<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:CE4xFjKsFvsJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18092837884128218632&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'CE4xFjKsFvsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:363"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/87685x/200804/29647665.html" class=yC3E>å¯ç å­¦æåå½æ°åå¶åºç¨</a></h3><div class="gs_a">å¼ æ ï¼ ææ¢¦ä¸ï¼ èé¹ï¼ å½­ç¨å¹ - åäº¬çµå­ç§æå­¦é¢å­¦æ¥, 2009 - cqvip.com</div><div class="gs_rs">æçç»´æ®: æçå¸æ·; æçæ¶èå¤¹; æçä½å; æçç²¾éè¾. è´­ç©è½¦; åå¼ä¸­å¿; å®¢æä¸­å¿.<br>é¦é¡µ | æåå¤§å¨ | å¨çº¿åºç | å¨çº¿èè¯ | ä¼ä¸ææ¥é¦ | å­¦èç©ºé´ | å­¦æ¯æºæ | ç­ç¹ä¸é¢ |<br>å­¦æ¯è®ºå | è®ºæåè¡¨ | EIæ£ç´¢ä¼è®® | æè²å¹è®­. é«çº§æç´¢ | ä¸ä¸æ£ç´¢. <b>...</b> </div><div class="gs_fl"><a href="/scholar?q=related:Fa3RKFLZZzsJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4280628917734321429&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'Fa3RKFLZZzsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:362"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/97390x/200808/27954679.html" class=yC3F>åºäºå¨æè§åèåå¤æ¨¡æçè¶³çè§é¢äºä»¶åæ</a></h3><div class="gs_a">æ¨é¢ï¼ æå®åï¼ å¼ åä¸ï¼ åè - è®¡ç®æºè¾å©è®¾è®¡ä¸å¾å½¢å­¦å­¦æ¥, 2008 - cqvip.com</div><div class="gs_rs">ä¸ºäºæ´å¥½å°æ»¡è¶³ç¨æ·æµè§åæ£ç´¢è§é¢çéè¦, æåºä¸ç§èåææ¬çè¶³çè§é¢äºä»¶åææ¡æ¶. <br>åå«ä»ææ¬åè§é¢ä¸­æåäºä»¶ä¿¡æ¯, éç¨å¨æè§åçç®æ³å¯¹2 ç§ä¿¡æ¯è¿è¡å¨å±å¹é, <br>å¯¹äºæªå¹éçææ¬äºä»¶ä¿¡æ¯, éç¨ä¸ä¸ªå¨å±æ¦çæ¨¡åä¼°è®¡å¶å¨è§é¢ä¸­çäºä»¶è¾¹ç. éè¿å¯»æ¾<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13442708907840251894&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 2</a> <a href="/scholar?q=related:9ifMdocYjroJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13442708907840251894&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'9ifMdocYjroJ')" href="#" class="gs_nph">Cite</a></div></div></div>
