Total results = 9
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.comp.nus.edu.sg/~mohan/papers/fusion_survey.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/E31M71152774R630.pdf" class=yC0>Multimodal fusion for multimedia analysis: a survey</a></h3><div class="gs_a"><a href="/citations?user=2s3sftgAAAAJ&amp;hl=en&amp;oi=sra">PK Atrey</a>, <a href="/citations?user=Qq4AAT4AAAAJ&amp;hl=en&amp;oi=sra">MA Hossain</a>, <a href="/citations?user=VcOjgngAAAAJ&amp;hl=en&amp;oi=sra">A El Saddik</a>, MS Kankanhalli - Multimedia Systems, 2010 - Springer</div><div class="gs_rs">Abstract This survey aims at providing multimedia researchers with a state-of-the-art <br>overview of fusion strategies, which are used for combining multiple modalities in order to <br>accomplish various multimedia analysis tasks. The existing literature on multimodal fusion <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2303959858949282248&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9">Cited by 65</a> <a href="/scholar?q=related:yFlu6UhP-R8J:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2303959858949282248&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'yFlu6UhP-R8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://eprints.ucl.ac.uk/13464/1/13464.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ucl.ac.uk</span><span class="gs_ggsS">ucl.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1703508" class=yC2>Experiential sampling in multimedia systems</a></h3><div class="gs_a">MS Kankanhalli, <a href="/citations?user=wIE1tY4AAAAJ&amp;hl=en&amp;oi=sra">J Wang</a>, R Jain - &hellip; , IEEE Transactions on, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Multimedia systems must deal with multiple data streams. Each data stream usually <br>contains significant volume of redundant noisy data. In many real-time applications, it is <br>essential to focus the computing resources on a relevant subset of data streams at any <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11124570279645081716&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9">Cited by 20</a> <a href="/scholar?q=related:dPAclbppYpoJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/45/63/RN197726464.html?source=googlescholar" class="gs_nph" class=yC4>BL Direct</a> <a href="/scholar?cluster=11124570279645081716&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">All 22 versions</a> <a onclick="return gs_ocit(event,'dPAclbppYpoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://webhotel2.tut.fi/emmi/forum/sites/webhotel2.tut.fi.emmi.forum/files/2009a/entries/08%20E2E%20(Environment-to-Environment)%20Communication%20Systems/Article_with_technical_details_of_E2E_paradigm.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tut.fi</span><span class="gs_ggsS">tut.fi <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/amk2230115354362.pdf" class=yC5>Towards environment-to-environment (E2E) multimedia communication systems</a></h3><div class="gs_a"><a href="/citations?user=Ef1hJ8IAAAAJ&amp;hl=en&amp;oi=sra">VK Singh</a>, <a href="/citations?user=c9XXy4MAAAAJ&amp;hl=en&amp;oi=sra">H Pirsiavash</a>, I Rishabh, R Jain - Multimedia Tools and  &hellip;, 2009 - Springer</div><div class="gs_rs">Abstract We present an approach to connect multiple remote environments over web for <br>natural interaction among people and objects. Focus of current communication and <br>telepresence systems severely restrict user affordances in terms of movement, interaction, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17482436362275261601&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9">Cited by 8</a> <a href="/scholar?q=related:oQzK3T4XnvIJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17482436362275261601&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'oQzK3T4XnvIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/F24013228W144422.pdf" class=yC7>Exploiting class-specific features in multi-feature dissimilarity space for efficient querying of images</a></h3><div class="gs_a"><a href="/citations?user=u3GoN7wAAAAJ&amp;hl=en&amp;oi=sra">T Yilmaz</a>, A Yazici, Y Yildirim - Flexible Query Answering Systems, 2011 - Springer</div><div class="gs_rs">Combining multiple features is an empirically validated approach in the literature, which <br>increases the accuracy in querying. However, it entails processing intrinsic high-<br>dimensionality of features and complicates realizing an efficient system. Two primary <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2542066816334926241&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9">Cited by 3</a> <a href="/scholar?q=related:oZHzDk08RyMJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2542066816334926241&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'oZHzDk08RyMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/N2N6326693361026.pdf" class=yC8>Experiential sampling for object detection in video</a></h3><div class="gs_a">P Anandathirtha, KR Ramakrishnan, SK Raja&hellip; - Multimedia Content  &hellip;, 2009 - Springer</div><div class="gs_rs">There are robust, supervised learning-based algorithms available for object detection in an <br>image. Object detection in videos can be performed by using such a detector on each frame <br>of the video sequence. This approach checks for the presence of an object around each <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5618277508970393821&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9">Cited by 3</a> <a href="/scholar?q=related:3TC_o6Ah-E0J:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5618277508970393821&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'3TC_o6Ah-E0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.151.5924&amp;rep=rep1&amp;type=pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4756090" class=yC9>Integrated Detect-Track Framework for Multi-view Face Detection in Video</a></h3><div class="gs_a">KR Anoop, P Anandathirtha&hellip; - &hellip;  Vision, Graphics &amp;  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract An Experiential sampling and Meanshift tracker based Multi-view face detection in <br>video is proposed in this paper. In this framework, instead of performing face detection at <br>every position in a frame, we determine certain key positions to run the multi-view face <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=381099718151897103&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9">Cited by 1</a> <a href="/scholar?q=related:DwByrCzwSQUJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=381099718151897103&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'DwByrCzwSQUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://www.tkl.iis.u-tokyo.ac.jp/top/modules/newdb/extract/1208/data/2012-ICMR-A%20RELIEF-Based%20Modality%20Weighting%20Approach%20for%20Multimodal%20Information%20Retrieval.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from u-tokyo.ac.jp</span><span class="gs_ggsS">u-tokyo.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2324858" class=yCB>A RELIEF-based modality weighting approach for multimodal information retrieval</a></h3><div class="gs_a"><a href="/citations?user=u3GoN7wAAAAJ&amp;hl=en&amp;oi=sra">T Yilmaz</a>, E Gulen, A Yazici&hellip; - Proceedings of the 2nd  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract Despite the extensive number of studies for multimodal information fusion, the issue <br>of determining the optimal modalities has not been adequately addressed yet. In this study, <br>a RELIEF-based multimodal feature selection approach (RELIEF-RDR) is proposed. The <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:-BrsfonukmwJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7823577777003305720&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'-BrsfonukmwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4685252" class=yCD>An event based web monitoring environment</a></h3><div class="gs_a">WQ Yan, R Jain - &hellip;  and Networking in China, 2008. ChinaCom  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present an event based visually monitoring system in a kitchen <br>environment. The system architecture is designed for average users to access the coffee <br>availability as well as for administrators to effectively manage and monitor the coffee pot <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:lSI4p3FhZ5QJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'lSI4p3FhZ5QJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> 19th INTERNATIONAL CONGRESS ON ACOUSTICS MADRID, 2-7 SEPTEMBER 2007</h3><div class="gs_a">A VÃ¤ljamÃ¤e, <a href="/citations?user=bh4v5sAAAAAJ&amp;hl=en&amp;oi=sra">S Soto-Faraco</a></div><div class="gs_fl"><a href="/scholar?q=related:0n9m9uapW-sJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'0n9m9uapW-sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
