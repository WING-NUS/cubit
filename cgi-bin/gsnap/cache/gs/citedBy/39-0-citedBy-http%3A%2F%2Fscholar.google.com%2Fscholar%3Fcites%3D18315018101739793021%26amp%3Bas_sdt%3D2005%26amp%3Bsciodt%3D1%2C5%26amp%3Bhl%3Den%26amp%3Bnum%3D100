Total results = 39
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.comp.nus.edu.sg/~tancl/publications/j2008/document%20annotation%20and%20retrieval%20(final%20manuscript).pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4492785" class=yC0>Document image retrieval through word shape coding</a></h3><div class="gs_a"><a href="/citations?user=Fgqq-4kAAAAJ&amp;hl=en&amp;oi=sra">S Lu</a>, L Li, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - Pattern Analysis and Machine Intelligence,  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents a document retrieval technique that is capable of searching <br>document images without optical character recognition (OCR). The proposed technique <br>retrieves document images by a new word shape coding scheme, which captures the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15535907822021277121&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 43</a> <a href="/scholar?q=related:wXXK8tmhmtcJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15535907822021277121&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'wXXK8tmhmtcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1642655" class=yC2>Font adaptive word indexing of modern printed documents</a></h3><div class="gs_a">S Marinai, E Marino, G Soda - Pattern Analysis and Machine  &hellip;, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We propose an approach for the word-level indexing of modern printed documents <br>which are difficult to recognize using current OCR engines. By means of word-level <br>indexing, it is possible to retrieve the position of words in a document, enabling queries <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14725324179830551457&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 33</a> <a href="/scholar?q=related:oTNFzVLcWswJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/10/3B/RN196221394.html?source=googlescholar" class="gs_nph" class=yC3>BL Direct</a> <a href="/scholar?cluster=14725324179830551457&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'oTNFzVLcWswJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www.csie.mcu.edu.tw/~yklee/CVGIP03/CD/Paper/PR/PR-19.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mcu.edu.tw</span><span class="gs_ggsS">mcu.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://onlinelibrary.wiley.com/doi/10.1002/ima.20063/abstract" class=yC4>Classification of leaf images</a></h3><div class="gs_a">CL Lee, SY Chen - International Journal of Imaging Systems  &hellip;, 2006 - Wiley Online Library</div><div class="gs_rs">Abstract There are tremendous content-based retrieval systems. Most of them are applied to <br>general image databases. Some were proposed for specified databases such as texture <br>databases, ancient paintings, document image databases, digital mammography, face <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15854194452252129869&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 33</a> <a href="/scholar?q=related:Tfp07tppBdwJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/5E/10/RN190472423.html?source=googlescholar" class="gs_nph" class=yC6>BL Direct</a> <a href="/scholar?cluster=15854194452252129869&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'Tfp07tppBdwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4359308" class=yC7>Script and language identification in noisy and degraded document images</a></h3><div class="gs_a"><a href="/citations?user=Fgqq-4kAAAAJ&amp;hl=en&amp;oi=sra">L Shijian</a>, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - Pattern Analysis and Machine Intelligence,  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper reports an identification technique that detects scripts and languages of <br>noisy and degraded document images. In the proposed technique, scripts and languages <br>are identified through the document vectorization, which converts each document image <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1557928597142664402&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 28</a> <a href="/scholar?q=related:0nQcCs7fnhUJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/49/15/RN222908228.html?source=googlescholar" class="gs_nph" class=yC8>BL Direct</a> <a href="/scholar?cluster=1557928597142664402&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'0nQcCs7fnhUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://www.comp.nus.edu.sg/~tancl/publications/j2008/PR-LuTan-2007.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320307004669" class=yC9>Retrieval of machine-printed Latin documents through Word Shape Coding</a></h3><div class="gs_a"><a href="/citations?user=Fgqq-4kAAAAJ&amp;hl=en&amp;oi=sra">S Lu</a>, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - Pattern Recognition, 2008 - Elsevier</div><div class="gs_rs">This paper reports a document retrieval technique that retrieves machine-printed Latin-<br>based document images through word shape coding. Adopting the idea of image <br>annotation, a word shape coding scheme is proposed, which converts each word image <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5548075066167160378&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 23</a> <a href="/scholar?q=related:Om4YsuC4_kwJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5548075066167160378&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'Om4YsuC4_kwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://cvit.iiit.ac.in/papers/Million08Matching.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from iiit.ac.in</span><span class="gs_ggsS">iiit.ac.in <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/D76093176Q324226.pdf" class=yCB>Matching word images for content-based retrieval from printed document images</a></h3><div class="gs_a">M Meshesha, <a href="/citations?user=U9dH-DoAAAAJ&amp;hl=en&amp;oi=sra">CV Jawahar</a> - &hellip; journal on document analysis and recognition, 2008 - Springer</div><div class="gs_rs">Abstract As large quantity of document images is getting archived by the digital libraries, <br>there is a need for an efficient search strategies to make them available as per users <br>information need. In this paper, we propose an effective word image matching scheme <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9745578603144312775&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 14</a> <a href="/scholar?q=related:x3cQ8xpAP4cJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9745578603144312775&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 19 versions</a> <a onclick="return gs_ocit(event,'x3cQ8xpAP4cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://www.m.cs.osakafu-u.ac.jp/cbdar2007/proceedings/papers/O2-2.pdf" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from osakafu-u.ac.jp</span><span class="gs_ggsS">osakafu-u.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.m.cs.osakafu-u.ac.jp/cbdar2007/proceedings/papers/O2-2.pdf" class=yCD>Mobile retriever-Finding document with a snapshot</a></h3><div class="gs_a">X Liu, <a href="/citations?user=RoGOW9AAAAAJ&amp;hl=en&amp;oi=sra">D Doermann</a> - Int. Workshop on Camera-Based  &hellip;, 2007 - m.cs.osakafu-u.ac.jp</div><div class="gs_rs">Abstract In this paper we describe a camera based document image retrieval system which <br>is targeted toward camera phones. Our goal is to enable the device to identify which of a <br>known set of documents it is âlooking atâ. This paper provides two key contributions 1) a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2331554156466526400&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 10</a> <a href="/scholar?q=related:wNjF9iZYWyAJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2331554156466526400&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'wNjF9iZYWyAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md6', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md6" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:wNjF9iZYWyAJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://www.comp.nus.edu.sg/~TANCL/publications/c2007/LiLL-ICDAR07.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4378677" class=yCF>A fast keyword-spotting technique</a></h3><div class="gs_a">L Li, <a href="/citations?user=Fgqq-4kAAAAJ&amp;hl=en&amp;oi=sra">S Lu</a>, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - &hellip; and Recognition, 2007. ICDAR 2007. Ninth &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In order to capture the content of an imaged document but avoid the time-<br>consuming full-scale OCR which is fragile to handle touching characters, a fast and <br>segmentation-free keyword spotting method is proposed in this paper. The keyword <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16890386027284013181&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 9</a> <a href="/scholar?q=related:fSB8S5q0ZuoJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16890386027284013181&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'fSB8S5q0ZuoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4378692" class=yC11>Document images retrieval based on multiple features combination</a></h3><div class="gs_a">G Meng, N Zheng, Y Song&hellip; - Document Analysis and  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Retrieving the relevant document images from a great number of digitized pages <br>with different kinds of artificial variations and documents quality deteriorations caused by <br>scanning and printing is a meaningful and challenging problem. We attempt to deal with <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12882190408703700843&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 8</a> <a href="/scholar?q=related:a2-6h-y7xrIJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12882190408703700843&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'a2-6h-y7xrIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/81l6v663305v4670.pdf" class=yC12>A survey of keyword spotting techniques for printed document images</a></h3><div class="gs_a">A Murugappan, B Ramachandran&hellip; - Artificial Intelligence  &hellip;, 2011 - Springer</div><div class="gs_rs">Abstract This paper attempts to provide a survey of the past researches on character based <br>as keyword based approaches used for retrieving information from document images. This <br>survey also provides insights into the strengths and weaknesses of current techniques, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4152659816115326052&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 6</a> <a href="/scholar?q=related:ZMyX3Bk2oTkJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4152659816115326052&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'ZMyX3Bk2oTkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://orpheus.ee.duth.gr/download/papers/journals/A%20Document%20Image%20Retrieval%20System.pdf" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from duth.gr</span><span class="gs_ggsS">duth.gr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0952197610000771" class=yC13>A document image retrieval system</a></h3><div class="gs_a"><a href="/citations?user=GDAL3kUAAAAJ&amp;hl=en&amp;oi=sra">K Zagoris</a>, <a href="/citations?user=uJVGw7kAAAAJ&amp;hl=en&amp;oi=sra">K Ergina</a>, <a href="/citations?user=E8a90xYAAAAJ&amp;hl=en&amp;oi=sra">N Papamarkos</a> - Engineering Applications of Artificial  &hellip;, 2010 - Elsevier</div><div class="gs_rs">In this paper, a system is presented that locates words in document image archives. This <br>technique performs the word matching directly in the document images bypassing character <br>recognition and using word images as queries. First, it makes use of document image <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2217747457466046465&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 8</a> <a href="/scholar?q=related:ARjK-48Fxx4J:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2217747457466046465&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'ARjK-48Fxx4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://oaj.unsri.ac.id/files/scipub/jcs25434-440.pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unsri.ac.id</span><span class="gs_ggsS">unsri.ac.id <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.freepatentsonline.com/article/Journal-Computer-Science/156486185.html" class=yC15>A new filtering algorithm for duplicate document based on concept analysis</a></h3><div class="gs_a">AM Hasnah - Journal of Computer Science, 2006 - freepatentsonline.com</div><div class="gs_rs">Abstract: Data bases and web pages contain currently a huge number of duplicate <br>document. It is then fundamental to have a filter which can be embedded, for instance, within <br>an information retrieval system like a search engine in order to prohibit the redundant <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3035605223984923664&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 4</a> <a href="/scholar?q=related:EATxLd6iICoJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3035605223984923664&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'EATxLd6iICoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md11', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md11" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:EATxLd6iICoJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://cvit.iiit.ac.in/thesis/millionPHD2008/millionThesis2008.pdf" class=yC18><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from iiit.ac.in</span><span class="gs_ggsS">iiit.ac.in <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://cvit.iiit.ac.in/thesis/millionPHD2008/millionThesis2008.pdf" class=yC17>Recognition and Retrieval from Document Image Collections</a></h3><div class="gs_a">M Meshesha - 2006 - cvit.iiit.ac.in</div><div class="gs_rs">Abstract The present growth of digitization of books and manuscripts demands an immediate <br>solution to access them electronically. This will enable the archived valuable materials to be <br>searchable and usable by users in order to achieve their objectives. This requires <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6537078785522049211&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 5</a> <a href="/scholar?q=related:u6DIP4VeuFoJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'u6DIP4VeuFoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md12', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md12" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:u6DIP4VeuFoJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.149.8181&amp;rep=rep1&amp;type=pdf" class=yC1A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/401w6355g6656033.pdf" class=yC19>Self-organizing maps for clustering in document image analysis</a></h3><div class="gs_a">S Marinai, E Marino, G Soda - Machine Learning in Document Analysis  &hellip;, 2008 - Springer</div><div class="gs_rs">In this chapter, we discuss the use of Self Organizing Maps (SOM) to deal with various tasks <br>in Document Image Analysis. The SOM is a particular type of artificial neural network that <br>computes, during the learning, an unsupervised clustering of the input data arranging the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3711777349529801881&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 4</a> <a href="/scholar?q=related:mZQQZNXhgjMJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3711777349529801881&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'mZQQZNXhgjMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="https://posgrado.escom.ipn.mx/biblioteca/Text%20retrieval%20from%20early%20printed%20books.pdf" class=yC1C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ipn.mx</span><span class="gs_ggsS">ipn.mx <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/A855GL8845800346.pdf" class=yC1B>Text retrieval from early printed books</a></h3><div class="gs_a">S Marinai - International journal on document analysis and  &hellip;, 2011 - Springer</div><div class="gs_rs">Abstract Retrieving text from early printed books is particularly difficult because in these <br>documents, the words are very close one to the other and, similarly to medieval manuscripts, <br>there is a large use of ligatures and abbreviations. To address these problems, we <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2897344057422586629&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 4</a> <a href="/scholar?q=related:BSPDxhFvNSgJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2897344057422586629&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'BSPDxhFvNSgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ri"><h3 class="gs_rt"><a href="http://inderscience.metapress.com/index/g04343p28gxv8m74.pdf" class=yC1D>Feature string-based intelligent information retrieval from Tamil document images</a></h3><div class="gs_a">S Abirami, D Manjula - International Journal of Computer Applications  &hellip;, 2009 - Inderscience</div><div class="gs_rs">Information Retrieval (IR) in document images has become a growing and challenging <br>problem due to its rising popularity. This paper proposes a simple and effective method to <br>extract the text and perform intelligent IR from Tamil Document Images without Optical <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=808284528493685425&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 4</a> <a href="/scholar?q=related:sWpPBn-aNwsJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=808284528493685425&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'sWpPBn-aNwsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.184.7135&amp;rep=rep1&amp;type=pdf" class=yC1F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.184.7135&amp;rep=rep1&amp;type=pdf" class=yC1E>Document Image Retrieval: An Overview</a></h3><div class="gs_a"><a href="/citations?user=L5vYHPkAAAAJ&amp;hl=en&amp;oi=sra">MB Kokare</a>, MS Shirdhonkar - International Journal of Computer  &hellip;, 2010 - Citeseer</div><div class="gs_rs">ABSTRACT The economic feasibility of creating a large database of document image has <br>left a tremendous need for robust ways to access the information. Printed documents are <br>scanned for archiving or in an attempt to move towards a paperless office and are stored <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1340064328863007046&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 4</a> <a href="/scholar?q=related:RkENOmjdmBIJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1340064328863007046&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'RkENOmjdmBIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md16', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md16" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:RkENOmjdmBIJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://oaj.unsri.ac.id/files/wwwijcaonline/journal/number7/pxc387274.pdf" class=yC20><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unsri.ac.id</span><span class="gs_ggsS">unsri.ac.id <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Document Image Retrieval: An Overview</h3><div class="gs_a">MS Shirdhonkar, <a href="/citations?user=L5vYHPkAAAAJ&amp;hl=en&amp;oi=sra">MB Kokare</a> - International  &hellip;, 2010 - Foundation of Computer Science  &hellip;</div><div class="gs_fl"><a href="/scholar?cites=4818304879540611727&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 3</a> <a href="/scholar?q=related:j6qMbMIO3kIJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4818304879540611727&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'j6qMbMIO3kIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/93758x/20093/30902188.0.html" class=yC21>åºäº OCR ä¸è¯å½¢ç¶ç¼ç çè±ææ«æææ¡£æ£ç´¢</a></h3><div class="gs_a">å¤åï¼ æ´æ±ä¸ºï¼ èæåï¼ çæ¥æ - æ¨¡å¼è¯å«ä¸äººå·¥æºè½, 2009 - cqvip.com</div><div class="gs_rs">æè¦: åæå½åå¸¸ç¨çä¸¤ç±»æ«æææ¡£æ£ç´¢æ¹æ³: åºäºOCR ååºäºè¯å½¢ç¶ç¼ç çæ¹æ³. <br>æåºåºäºè¯å«ä¿¡åº¦å°ä¸¤ç§æ¹æ³è¿è¡ææºç»åçæè·¯. åºäºææ¡£æå­ç¹æ§åç¬ç»ç¹å¾, <br>è¿æåºä¸ç§è¯å½¢ç¶ç¼ç æ¹æ³, å¯¹å­ä½æè¾å¼ºçå®¹å¿æ§. éå¯¹åç§æ å¼æ¹æ³è¿è¡å³é®è¯æ£ç´¢å¯¹æ¯<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3141428776127416886&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 4</a> <a href="/scholar?q=related:NspD8NOYmCsJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3141428776127416886&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'NspD8NOYmCsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="http://icpr2010.org/pdfs/icpr2010_TuBCT9.35.pdf" class=yC23><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from icpr2010.org</span><span class="gs_ggsS">icpr2010.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5597262" class=yC22>Shape code based word-image matching for retrieval of Indian multi-lingual documents</a></h3><div class="gs_a">A Tarafdar, <a href="/citations?user=QMmbyQkAAAAJ&amp;hl=en&amp;oi=sra">R Mondal</a>, S Pal, <a href="/citations?user=2_z_CogAAAAJ&amp;hl=en&amp;oi=sra">U Pal</a>&hellip; - &hellip;  (ICPR), 2010 20th  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In the current scenario retrieving information from document images is a <br>challenging problem. In this paper we propose a shape code based word-image matching <br>(word-spotting) technique for retrieval of multilingual documents written in Indian <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16001967394304733812&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 2</a> <a href="/scholar?q=related:dLLqJJBoEt4J:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16001967394304733812&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'dLLqJJBoEt4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB20" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW20"><a href="http://asiair.asia.edu.tw/bitstream/310904400/2065/1/06.pdf" class=yC25><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from asia.edu.tw</span><span class="gs_ggsS">asia.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://asiair.asia.edu.tw/bitstream/310904400/2065/1/06.pdf" class=yC24>Graph/image legend retrieval</a></h3><div class="gs_a">YW Huang, CC Liu, SY Chen - Asian Journal of Health and  &hellip;, 2007 - asiair.asia.edu.tw</div><div class="gs_rs">ABSTRACT There are many content-based retrieval methods for image databases, <br>however, none of them have coped with both graph and image simultaneously. Moreover, <br>existing graph retrieval methods handle either a silhouette or a graph component rather <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14791602554683492380&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 2</a> <a href="/scholar?q=related:HIireidURs0J:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14791602554683492380&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'HIireidURs0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md20', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md20" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:HIireidURs0J:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="http://e-collection.library.ethz.ch/eserv/eth:30795/eth-30795-02.pdf" class=yC27><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ethz.ch</span><span class="gs_ggsS">ethz.ch <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> <a href="http://e-collection.library.ethz.ch/view/eth:30795" class=yC26>Real-time spotting of human activities in industrial environments</a></h3><div class="gs_a">T Stiefmeier - 2008 - e-collection.library.ethz.ch</div><div class="gs_rs">Abstract Nowadays, computing technology is found in almost every workplace to support <br>people in doing their job efficiently. Desktop computers, notebooks and personal digital <br>assistants are widespread examples for this technology. However, production and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13340400416694639873&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 2</a> <a href="/scholar?q=related:AZ2Onn-fIrkJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13340400416694639873&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'AZ2Onn-fIrkJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md21', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md21" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:AZ2Onn-fIrkJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=4645421669652314872&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Word Spotting Techniques in Document Analysis and Retrieval-A Comprehensive Survey</h3><div class="gs_a">MI Shah, CY Suen - &hellip;  of Pattern Recognition and Computer Vision, 2010 - World Scientific</div><div class="gs_fl"><a href="/scholar?cites=4176118926763670575&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 2</a> <a href="/scholar?q=related:L7yIsQmO9DkJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'L7yIsQmO9DkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB23" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW23"><a href="http://www.ppgia.pucpr.br/~alekoe/Papers/ALEKOE-JUCS2011.pdf" class=yC29><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from pucpr.br</span><span class="gs_ggsS">pucpr.br <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://jucs.org/jucs_17_1/an_ocr_free_method/jucs_17_01_0048_0063_rios.pdf" class=yC28>An OCR Free Method for Word Spotting in Printed Documents: the Evaluation of Different Feature Sets</a></h3><div class="gs_a">I Rios, <a href="/citations?user=pRK8DCUAAAAJ&amp;hl=en&amp;oi=sra">A de Souza Britto Jr</a>, <a href="/citations?user=kaUy9GEAAAAJ&amp;hl=en&amp;oi=sra">AL Koerich</a>&hellip; - Journal of Universal  &hellip;, 2011 - jucs.org</div><div class="gs_rs">Abstract: An OCR free word spotting method is developed and evaluated under a strong <br>experimental protocol. Different feature sets are evaluated under the same experimental <br>conditions. In addition, a tuning process in the document segmentation step is proposed <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12835005042238415074&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 1</a> <a href="/scholar?q=related:4uD3SBUZH7IJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12835005042238415074&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'4uD3SBUZH7IJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB24" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW24"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.188.2447&amp;rep=rep1&amp;type=pdf" class=yC2B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1774099" class=yC2A>Evaluation of different feature sets in an ocr free method for word spotting in printed documents</a></h3><div class="gs_a">I Rios, <a href="/citations?user=pRK8DCUAAAAJ&amp;hl=en&amp;oi=sra">AS Britto Jr</a>, <a href="/citations?user=kaUy9GEAAAAJ&amp;hl=en&amp;oi=sra">AL Koerich</a>&hellip; - Proceedings of the 2010  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract This paper presents the evaluation of tree feature sets in an OCR free word spotting <br>method under a strong experimental protocol. Different feature sets are evaluated under the <br>same experimental conditions. In addition, a tuning process in the document <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18067988446306032530&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 1</a> <a href="/scholar?q=related:ktvue8NjvvoJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18067988446306032530&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'ktvue8NjvvoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.worldscientific.com/doi/abs/10.1142/S0218213008004345" class=yC2C>A graph based object description and recognition methodology</a></h3><div class="gs_a">N Bourbakis, P Yuan, P Kakumanu - International Journal on  &hellip;, 2008 - World Scientific</div><div class="gs_rs">This paper presents a methodology for recognizing 3D objects using synthesis of 2D views. <br>In particular, the methodology uses wavelets for rearranging the shape of the perceived 2D <br>view of an object for attaining a desirable size, local-global (LG) graphs for representing <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9222900743869280546&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=39">Cited by 1</a> <a href="/scholar?q=related:IrEDjVxT_n8J:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9222900743869280546&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'IrEDjVxT_n8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB26" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW26"><a href="http://etd.aau.edu.et/dspace/bitstream/123456789/3516/1/final%20edited1.pdf" class=yC2E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aau.edu.et</span><span class="gs_ggsS">aau.edu.et <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://etd.aau.edu.et/dspace/handle/123456789/3516" class=yC2D>FEATURE EXTRACTION AND MATCHING IN AMHARIC DOCUMENT IMAGE COLLECTIONS</a></h3><div class="gs_a">L ADANE - 2011 - etd.aau.edu.et</div><div class="gs_rs">Abstract: The ubiquity of digital computers and the boom of the Internet and World Wide Web <br>resulted in massive information explosion over the entire world. Different types of information <br>are uploaded in the Internet such as text documents, document images and other <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:3s5jD0QyDXEJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'3s5jD0QyDXEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB27" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW27"><a href="http://www.icsd.aegean.gr/lecturers/kavallieratou/publications_files/Spie_2009.pdf" class=yC30><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aegean.gr</span><span class="gs_ggsS">aegean.gr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.icsd.aegean.gr/lecturers/kavallieratou/publications_files/Spie_2009.pdf" class=yC2F>Retrieval of Historical Documents by Word Spotting</a></h3><div class="gs_a">NDE Kavallieratou - icsd.aegean.gr</div><div class="gs_rs">ABSTRACT The implementation of word spotting is not an easy procedure and it gets even <br>worse in the case of historical documents since it requires character recognition and <br>indexing of the document images. A general technique for word spotting is presented, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:S6ztFD0E0KcJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12092169659880418379&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'S6ztFD0E0KcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md27', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md27" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:S6ztFD0E0KcJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/r602137756081536.pdf" class=yC31>Text image spotting using local crowdedness and hausdorff distance</a></h3><div class="gs_a">HJ Son, SC Park, SH Kim, JS Kim, GS Lee&hellip; - Digital Libraries:  &hellip;, 2006 - Springer</div><div class="gs_rs">Abstract. This paper investigates a Hausdorff distance, which is used for measurement of <br>image similarity, to see whether it is also effective for document image retrieval. We <br>proposed a method using a local crowdedness algorithm and a modified Hausdorff <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:kvxlF0UnSmgJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/4F/33/RN200037970.html?source=googlescholar" class="gs_nph" class=yC32>BL Direct</a> <a href="/scholar?cluster=7514862105919880338&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'kvxlF0UnSmgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB29" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW29"><a href="http://staging.comp.nus.edu.sg/~tancl/publications/c2008/sigir2008.pdf" class=yC34><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1390496" class=yC33>A word shape coding method for camera-based document images</a></h3><div class="gs_a">L Li, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - Proceedings of the 31st annual international ACM  &hellip;, 2008 - dl.acm.org</div><div class="gs_rs">Abstract This paper reports a word shape coding method to facilitate retrieval of camera-<br>based document images without OCR. Due to perspective distortion, many reported word <br>shape coding methods fail on camera-based images. In this paper, the problem is <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:-JdMLg6g1mwJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7842631783879055352&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'-JdMLg6g1mwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Script and Language Identification in Noisy and Degraded Document Images</h3><div class="gs_a">SLUCLIM TAN</div><div class="gs_fl"><a href="/scholar?q=related:kH2ULuYK-YYJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'kH2ULuYK-YYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB31" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW31"><a href="http://lampsrv02.umiacs.umd.edu/pubs/TechReports/LAMP_151/LAMP_151.pdf" class=yC36><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from umd.edu</span><span class="gs_ggsS">umd.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://lampsrv02.umiacs.umd.edu/pubs/TechReports/LAMP_151/LAMP_151.pdf" class=yC35>LAMP-TR-151 November 2008 COMPUTER VISION AND IMAGE PROCESSING LARGE TECHNIQUES FOR MOBILE APPLICATIONS</a></h3><div class="gs_a">X Liu, <a href="/citations?user=RoGOW9AAAAAJ&amp;hl=en&amp;oi=sra">D Doermann</a> - lampsrv02.umiacs.umd.edu</div><div class="gs_rs">Abstract Camera phones have penetrated every corner of society and have become a focal <br>point for communications. In our research we extend the traditional use of such devices to <br>help bridge the gap between physical and digital worlds. Their combined image <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:xIYNbZmcz_sJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18144893606472550084&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'xIYNbZmcz_sJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md31', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md31" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:xIYNbZmcz_sJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6003077" class=yC37>Fast historic document retrieval by extracting document image summary</a></h3><div class="gs_a">CY Shiah, YS Yen - Multimedia Technology (ICMT), 2011  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Historic documents such as Chinese calligraphy and old newspapers usually were <br>handwritten or printed in poor quality so that an automatic optical character recognition <br>procedure for scanned document images is difficult to apply. Thus efficient pattern <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:f63dgvRiySkJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'f63dgvRiySkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:367"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB33" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW33"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.60.9197&amp;rep=rep1&amp;type=pdf" class=yC39><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.60.9197&amp;rep=rep1&amp;type=pdf" class=yC38>Indexing &amp; Retrieval of Graphic Document Images: a New System Scheme</a></h3><div class="gs_a">MDTPPE Trupina - Citeseer</div><div class="gs_rs">Abstract This draft deals with the Indexing and Retrieval (I &amp; R) of graphic document images. <br>We present first a general introduction on this topic and review then the main existing <br>systems in the literature. Based on this review, we conclude on the unadaptability of <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:n27zo9ZI_FUJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6195907274065800863&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'n27zo9ZI_FUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md33', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md33" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:n27zo9ZI_FUJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:366"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB34" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW34"><a href="http://arxiv.org/pdf/1206.1291" class=yC3B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arxiv.org</span><span class="gs_ggsS">arxiv.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://arxiv.org/abs/1206.1291" class=yC3A>Feature Weighting for Improving Document Image Retrieval System Performance</a></h3><div class="gs_a">M Keyvanpour, R Tavoli - arXiv preprint arXiv:1206.1291, 2012 - arxiv.org</div><div class="gs_rs">Abstract: Feature weighting is a technique used to approximate the optimal degree of <br>influence of individual features. This paper presents a feature weighting method for <br>Document Image Retrieval System (DIRS) based on keyword spotting. In this method, we <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:kseZuKEYxswJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14755508311991895954&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'kseZuKEYxswJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:365"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB35" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW35"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.92.3369&amp;rep=rep1&amp;type=pdf" class=yC3D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.92.3369&amp;rep=rep1&amp;type=pdf" class=yC3C>An Intelligent System for Exact Word Retrieval in Document Databases</a></h3><div class="gs_a">M Marikkannan, P Anandhakumar, A Kannan - Citeseer</div><div class="gs_rs">Abstract Automatic Information retrieval from document image databases is an important and <br>challenging task. The main challenges are font style, size and spacing between characters. <br>In order to meet the challenges, we propose a new technique for matching exact word <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:SRQdzllc0YwJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'SRQdzllc0YwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md35', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md35" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:SRQdzllc0YwJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:364"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB36" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW36"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.108.1939&amp;rep=rep1&amp;type=pdf" class=yC3F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.108.1939&amp;rep=rep1&amp;type=pdf" class=yC3E>SOM clustering for text retrieval and classification with examples on Indian scripts</a></h3><div class="gs_a">S Marinai - Proc. of Brainstorming Workshop on OCR for Indian  &hellip;, 2007 - Citeseer</div><div class="gs_rs">Abstract. In this paper, we discuss the use of Self Organizing Maps (SOM) for character and <br>word clustering. The SOM is a particular kind of artificial neural network that computes an <br>unsupervised clustering of the input data arranging the cluster centers in a lattice. After an <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ZgQi6fixoMwJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14744980862632330342&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'ZgQi6fixoMwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md36', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md36" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:ZgQi6fixoMwJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:363"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB37" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW37"><a href="http://arxiv.org/pdf/1209.2274" class=yC41><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arxiv.org</span><span class="gs_ggsS">arxiv.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://arxiv.org/abs/1209.2274" class=yC40>PCA-Based Relevance Feedback in Document Image Retrieval</a></h3><div class="gs_a">R Tavoli, F Mahmoudi - arXiv preprint arXiv:1209.2274, 2012 - arxiv.org</div><div class="gs_rs">Abstract: Research has been devoted in the past few years to relevance feedback as an <br>effective solution to improve performance of information retrieval systems. Relevance <br>feedback refers to an interactive process that helps to improve the retrieval performance. <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ebVF62a3zVIJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5966626733997536633&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'ebVF62a3zVIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:362"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB38" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW38"><a href="http://www.biblioteca.pucpr.br/tede/tde_arquivos/14/TDE-2009-06-09T153510Z-1189/Publico/Israel_Rios%20PPGIa.pdf" class=yC43><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from pucpr.br</span><span class="gs_ggsS">pucpr.br <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.biblioteca.pucpr.br/tede/tde_arquivos/14/TDE-2009-06-09T153510Z-1189/Publico/Israel_Rios%20PPGIa.pdf" class=yC42>Busca por Palavras em Imagens de Documentos: Uma Abordagem Independente de OCR</a></h3><div class="gs_a">I RIOS - 2007 - biblioteca.pucpr.br</div><div class="gs_rs">Resumo Hoje em dia, hÃ¡ um grande volume de informaÃ§Ã£o disponÃ­vel na forma digital, seja <br>em grandes empresas seja em bibliotecas digitais. Grande parte dessa informaÃ§Ã£o Ã© <br>composta de imagens de documentos digitalizados. Devido ao grande volume, existe a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:aaqgMCP6wwMJ:scholar.google.com/&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=271335431618996841&amp;hl=en&amp;num=39&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'aaqgMCP6wwMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
