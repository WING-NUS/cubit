Total results = 9
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://web.media.mit.edu/~tristan/Papers/PhD_Tristan.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://web.media.mit.edu/~tristan/Papers/PhD_Tristan.pdf" class=yC0>Creating music by listening</a></h3><div class="gs_a"><a href="/citations?user=Du8ZwMIAAAAJ&amp;hl=en&amp;oi=sra">T Jehan</a> - 2005 - media.mit.edu</div><div class="gs_rs">Abstract Machines have the power and potential to make expressive music on their own. <br>This thesis aims to computationally model the process of creating music using experience <br>from listening to examples. Our unbiased signal-based solution models the life cycle of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3214891422422111905&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9">Cited by 109</a> <a href="/scholar?q=related:oZbrKLeWnSwJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3214891422422111905&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'oZbrKLeWnSwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md0', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md0" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:oZbrKLeWnSwJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a>  <a href="/scholar?q=info:oZbrKLeWnSwJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=14624192851644529936&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://dafx04.na.infn.it/WebProc/Proc/P_345.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from infn.it</span><span class="gs_ggsS">infn.it <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://dafx04.na.infn.it/WebProc/Proc/P_345.pdf" class=yC2>Sound texture modeling and time-frequency LPC</a></h3><div class="gs_a">X Zhu, L Wyse - Proceedings of the 7th International Conference  &hellip;, 2004 - dafx04.na.infn.it</div><div class="gs_rs">ABSTRACT This paper presents a method to model and synthesize the textures of sounds <br>such as fire, footsteps and typewriters using time and frequency domain linear prediction <br>coding (TFLPC). The common character of this class of sounds is that they have a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4079621645464561490&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9">Cited by 22</a> <a href="/scholar?q=related:Uufok0W6nTgJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4079621645464561490&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'Uufok0W6nTgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://ir.lib.stut.edu.tw/bitstream/987654321/9845/1/J4_REDUP%2520A%2520Packet-Loss%2520Recovery%2520Scheme%2520for%2520Real-Time%2520Audio%2520Streaming%2520over%2520Wireless%2520IP%2520Networks.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from stut.edu.tw</span><span class="gs_ggsS">stut.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0164121204002298" class=yC4>REDUP: a packet loss recovery scheme for real-time audio streaming over wireless IP networks</a></h3><div class="gs_a">CM Huang, TH Hsu, YW Lin - Journal of Systems and Software, 2006 - Elsevier</div><div class="gs_rs">Due to the characteristics of (1) smaller bandwidth and (2) unreliable transmission media, <br>real-time audio streaming over wireless networks is not trivial. To have smooth audio <br>streaming over wireless networks, we propose a scheme called REDUP in this paper. Two <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13855516968962854540&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9">Cited by 3</a> <a href="/scholar?q=related:jI5tCkavSMAJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13855516968962854540&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'jI5tCkavSMAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://eprints.ulster.ac.uk/21380/1/sofiaics05.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ulster.ac.uk</span><span class="gs_ggsS">ulster.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://eprints.ulster.ac.uk/21380" class=yC6>Song form intelligence for streaming music across wireless bursty networks</a></h3><div class="gs_a">J Doherty, <a href="/citations?user=XuncvX4AAAAJ&amp;hl=en&amp;oi=sra">K Curran</a>, P McKevitt - Irish Conference on Artificial  &hellip;, 2005 - eprints.ulster.ac.uk</div><div class="gs_rs">Preliminary research on the development of a system for streaming audio across a wireless <br>network, whilst using Song Form Intelligence (SoFI) to correct bursty errors, is presented. <br>Current problems identified with streaming audio across wireless networks are reviewed. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13909872206727125385&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9">Cited by 1</a> <a href="/scholar?q=related:iZkMCRPLCcEJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13909872206727125385&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'iZkMCRPLCcEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.96.1292&amp;rep=rep1&amp;type=pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1386017" class=yC8>Generative Sound Models</a></h3><div class="gs_a">L Wyse - Multimedia Modelling Conference, 2005. MMM 2005.  &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract An overview of generative sound models is presented. We discuss the benefits they <br>offer in a variety of media contexts including indexing and retrieval, compression, <br>sonification, traditional media and interactive media production. We examine ways in <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1984968813591806260&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=9">Cited by 1</a> <a href="/scholar?q=related:NEFegJ4GjBsJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1984968813591806260&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'NEFegJ4GjBsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/FT671731J0403662.pdf" class=yCA>A Survey of Music Structure Analysis Techniques for Music Applications</a></h3><div class="gs_a">N Maddage, <a href="/citations?user=z8_x7C8AAAAJ&amp;hl=en&amp;oi=sra">H Li</a>, M Kankanhalli - Recent Advances in Multimedia Signal  &hellip;, 2009 - Springer</div><div class="gs_rs">Music carries multilayer information which forms different structures. The information <br>embedded in the music can be categorized into time information, harmony/melody, music <br>regions, music similarities, song structures and music semantics. In this chapter, we first <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:3vo8SvZRZuUJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16529989600559299294&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'3vo8SvZRZuUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://www.comp.nus.edu.sg/~wangye/papers/1.Audio_and_Music_Analysis_and_Retrieval/2005_A_Method_for_Separating_Drum_Objects_from_Polyphonic_Musical_Signals.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1540230" class=yCB>A method for separating drum objects from polyphonic musical signals</a></h3><div class="gs_a">W Huang, Y Wang - Applications of Signal Processing to Audio  &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract An additional coding of auditory objects for packet loss concealment has been <br>proven to be effective in music streaming applications. This paper describes a new <br>extension to our previous method in separating drum objects from polyphonic music <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:kmLNmfRrmJwJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11283887564673344146&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'kmLNmfRrmJwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://www.scis.ulster.ac.uk/~jonathan/Research/papers/JDoherty1stYrRpt.doc" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[DOC]</span> from ulster.ac.uk</span><span class="gs_ggsS">ulster.ac.uk <span class=gs_ctg2>[DOC]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[DOC]</span><span class="gs_ct2">[DOC]</span></span> <a href="http://www.scis.ulster.ac.uk/~jonathan/Research/papers/JDoherty1stYrRpt.doc" class=yCD>Song Form Intelligence with Streaming Audio</a></h3><div class="gs_a">J Doherty, P Mc Kevitt, <a href="/citations?user=XuncvX4AAAAJ&amp;hl=en&amp;oi=sra">K Curran</a> - scis.ulster.ac.uk</div><div class="gs_rs">Abstract Streaming media across the Internet is still an unreliable and poor quality medium. <br>Services such as audio-on-demand drastically increase the load on the networks therefore <br>new, robust and highly efficient coding algorithms will be necessary. One overlooked <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:BLvYyU2HRiYJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2758040589979663108&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'BLvYyU2HRiYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md7', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md7" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:BLvYyU2HRiYJ:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://eprints.ulster.ac.uk/21381/1/sofipgnet05.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ulster.ac.uk</span><span class="gs_ggsS">ulster.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://eprints.ulster.ac.uk/21381" class=yCF>Error concealment for streaming audio across wireless bursty networks</a></h3><div class="gs_a">J Doherty, <a href="/citations?user=XuncvX4AAAAJ&amp;hl=en&amp;oi=sra">K Curran</a>, P McKevitt - &hellip;  Postgraduate Symposium on  &hellip;, 2005 - eprints.ulster.ac.uk</div><div class="gs_rs">Preliminary research on the development of an application for streaming audio across a <br>wireless network, whilst using song form intelligence (SoFI) to correct bursty errors, is <br>presented. Current problems identified with streaming audio across wireless networks are <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:gbHZ6IXhRi8J:scholar.google.com/&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3406658133405839745&amp;hl=en&amp;num=9&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'gbHZ6IXhRi8J')" href="#" class="gs_nph">Cite</a></div></div></div>
