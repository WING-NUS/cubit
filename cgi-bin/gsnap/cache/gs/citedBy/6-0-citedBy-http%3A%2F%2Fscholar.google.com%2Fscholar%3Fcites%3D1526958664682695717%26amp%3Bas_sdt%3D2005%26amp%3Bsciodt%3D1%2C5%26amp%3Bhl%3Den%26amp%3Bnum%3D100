Total results = 6
<div class="gs_r" style="z-index:400"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5597319" class=yC0>Functionality delegation in distributed surveillance systems</a></h3><div class="gs_a">MK Saini, <a href="/citations?user=2s3sftgAAAAJ&amp;hl=en&amp;oi=sra">PK Atrey</a>, S Emmanuel&hellip; - Advanced Video and  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The utilization of multimedia devices is growing rapidly in surveillance and <br>monitoring applications. These multimedia surveillance systems need to process large <br>amounts of multimodal sensor data in order to detect events and objects. While <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4168310094886653168&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=6">Cited by 1</a> <a href="/scholar?q=related:8MxkV_LP2DkJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4168310094886653168&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'8MxkV_LP2DkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.morganclaypool.com/doi/abs/10.2200/S00374ED1V01Y201107DTM019" class=yC1>Managing Event Information: Modeling, Retrieval, and Applications</a></h3><div class="gs_a">A Gupta, R Jain - Synthesis Lectures on Data Management, 2011 - morganclaypool.com</div><div class="gs_rs">Abstract With the proliferation of citizen reporting, smart mobile devices, and social media, <br>an increasing number of people are beginning to generate information about events they <br>observe and participate in. A significant fraction of this information contains multimedia <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:KzssFUebLT4J:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4480407933903715115&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'KzssFUebLT4J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md1', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md1" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:KzssFUebLT4J:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=9108242276578457164&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S1077314211001433" class=yC2>Multi-camera active surveillance of an articulated human formâAn implementation strategy</a></h3><div class="gs_a">MD Mackay, RG Fenton, B Benhabib - Computer Vision and Image  &hellip;, 2011 - Elsevier</div><div class="gs_rs">This paper presents an effective framework for real-time reconfiguration of a multi-camera <br>active-vision system performing surveillance of articulated objects with time-varying <br>geometries. The proposed novel real-world strategy tangibly improves surveillance <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:lzQOf1ermvYJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17769703672025855127&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'lzQOf1ermvYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/W5K208X147HK2130.pdf" class=yC3>A semantic-guided and self-configurable framework for video analysis</a></h3><div class="gs_a"><a href="/citations?user=JNYom7oAAAAJ&amp;hl=en&amp;oi=sra">JC SanMiguel</a>, <a href="/citations?user=k_b4Fp4AAAAJ&amp;hl=en&amp;oi=sra">JM MartÃ­nez</a> - Machine Vision and Applications, 2011 - Springer</div><div class="gs_rs">Abstract This paper presents a distributed and scalable framework for video analysis that <br>automatically estimates the optimal workflow required for the analysis of different application <br>domains. It integrates several technologies related with data acquisition, visual analysis <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:YVY-ou6TEF0J:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6706022498288162401&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'YVY-ou6TEF0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5584610" class=yC4>A real-time visual action-recognition framework for time-varying-geometry objects</a></h3><div class="gs_a">M Mackay, RG Fenton&hellip; - Automation Science and  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper develops a real-world, real-time sensing-system reconfiguration <br>framework for time-varying geometry (TVG) object action recognition. Currently, a method <br>specifically tailored for sensing such objects, especially humans, does not exist. A 10-level <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:kuG-3hk8BHAJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'kuG-3hk8BHAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://sites.google.com/site/pilpage/DICTA2011_PIL_EYE.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from google.com</span><span class="gs_ggsS">google.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6128687" class=yC5>PIL-EYE: Integrated System for Sustainable Development of Intelligent Visual Surveillance Algorithms</a></h3><div class="gs_a"><a href="/citations?user=3TggrEkAAAAJ&amp;hl=en&amp;oi=sra">HJ Chang</a>, <a href="/citations?user=pr6rIJEAAAAJ&amp;hl=en&amp;oi=sra">KM Yi</a>, S Yin, SW Kim&hellip; - Digital Image  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we introduce a new platform for integrated development of visual <br>surveillance algorithms, named as PIL-EYE system. In our system, any functional modules <br>and algorithms can be added or removed, not affecting other modules. Also, functional <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:8xrW_RDQyyAJ:scholar.google.com/&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2363211200882678515&amp;hl=en&amp;num=6&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'8xrW_RDQyyAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
