Total results = 88
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www-alg.ist.hokudai.ac.jp/~thomas/publications/tcs08lzz.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hokudai.ac.jp</span><span class="gs_ggsS">hokudai.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397508001503" class=yC0>Learning indexed families of recursive languages from positive data: A survey</a></h3><div class="gs_a">S Lange, T Zeugmann, <a href="/citations?user=gkUY7QMAAAAJ&amp;hl=en&amp;oi=sra">S Zilles</a> - Theoretical Computer Science, 2008 - Elsevier</div><div class="gs_rs">In the past 40 years, research on inductive inference has developed along different lines, eg, <br>in the formalizations used, and in the classes of target concepts considered. One common <br>root of many of these formalizations is Gold&#39;s model of identification in the limit. This model <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11257453027040786320&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 39</a> <a href="/scholar?q=related:kHdpMOKBOpwJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11257453027040786320&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'kHdpMOKBOpwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397501004042" class=yC2>On the power of incremental learning</a></h3><div class="gs_a">S Lange, G Grieser - Theoretical Computer Science, 2002 - Elsevier</div><div class="gs_rs">This paper provides a systematic study of incremental learning from noise-free and from <br>noisy data. As usual, we distinguish between learning from positive data and learning from <br>positive and negative data, synonymously called learning from text and learning from <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7120450118602224885&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 27</a> <a href="/scholar?q=related:9XQsOKjr0GIJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7120450118602224885&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'9XQsOKjr0GIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0022000099916690" class=yC3>An average-case optimal one-variable pattern language learner</a></h3><div class="gs_a">R Reischuk, T Zeugmann - Journal of Computer and System Sciences, 2000 - Elsevier</div><div class="gs_rs">A new algorithm for learning one-variable pattern languages from positive data is proposed <br>and analyzed with respect to its average-case behavior. We consider the total learning time <br>that takes into account all operations till convergence to a correct hypothesis is achieved. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12015758781862556212&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 21</a> <a href="/scholar?q=related:NLKyK_OMwKYJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/26/08/RN077724011.html?source=googlescholar" class="gs_nph" class=yC4>BL Direct</a> <a href="/scholar?cluster=12015758781862556212&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 21 versions</a> <a onclick="return gs_ocit(event,'NLKyK_OMwKYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.8567&amp;rep=rep1&amp;type=pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0890540107000491" class=yC5>Results on memory-limited U-shaped learning</a></h3><div class="gs_a">L Carlucci, <a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, F Stephan - Information and Computation, 2007 - Elsevier</div><div class="gs_rs">U-shaped learning is a learning behaviour in which the learner first learns a given target <br>behaviour, then unlearns it and finally relearns it. Such a behaviour, observed by <br>psychologists, for example, in the learning of past-tenses of English verbs, has been <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1913549189572195176&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 21</a> <a href="/scholar?q=related:aPOveNlKjhoJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1913549189572195176&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 23 versions</a> <a onclick="return gs_ocit(event,'aPOveNlKjhoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://pdf.aminer.org/000/311/170/a_unified_algorithm_for_extending_classes_of_languages_identifiable_in.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aminer.org</span><span class="gs_ggsS">aminer.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://pdf.aminer.org/000/311/170/a_unified_algorithm_for_extending_classes_of_languages_identifiable_in.pdf" class=yC7>String extension learning</a></h3><div class="gs_a">J Heinz - Proceedings of the 48th annual meeting of the  &hellip;, 2010 - pdf.aminer.org</div><div class="gs_rs">Abstract This paper defines a collection of functions which define classes of languages, <br>which have the property that they are identifiable in the limit from positive data from a very <br>simple kind of learner. Furthermore these learners are always incremental, maximally <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14658967609106437475&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 19</a> <a href="/scholar?q=related:YxW_ul8db8sJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14658967609106437475&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'YxW_ul8db8sJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md4', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md4" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:YxW_ul8db8sJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://webdocs.cs.ualberta.ca/~zilles/zeugmannZ08survey.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ualberta.ca</span><span class="gs_ggsS">ualberta.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397508001400" class=yC9>Learning recursive functions: A survey</a></h3><div class="gs_a">T Zeugmann, <a href="/citations?user=gkUY7QMAAAAJ&amp;hl=en&amp;oi=sra">S Zilles</a> - Theoretical Computer Science, 2008 - Elsevier</div><div class="gs_rs">Studying the learnability of classes of recursive functions has attracted considerable interest <br>for at least four decades. Starting with Gold&#39;s (1967) model of learning in the limit, many <br>variations, modifications and extensions have been proposed. These models differ in <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17660134303999589849&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 14</a> <a href="/scholar?q=related:2f2VA5VmFfUJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17660134303999589849&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'2f2VA5VmFfUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://pdf.aminer.org/002/865/517/parsimony_hierarchies_for_inductive_inference.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aminer.org</span><span class="gs_ggsS">aminer.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://projecteuclid.org/euclid.jsl/1080938842" class=yCB>Parsimony hierarchies for inductive inference</a></h3><div class="gs_a"><a href="/citations?user=Wy0bQrwAAAAJ&amp;hl=en&amp;oi=sra">A Ambainis</a>, <a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, M Suraj - Journal of Symbolic Logic, 2004 - projecteuclid.org</div><div class="gs_rs">Abstract Freivalds defined an acceptable programming system independent criterion for <br>learning programs for functions in which the final programs were required to be both correct <br>and ânearlyâ minimal size, ie, within a computable function of being purely minimal size. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15168080914944291644&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 12</a> <a href="/scholar?q=related:PPOiazrZf9IJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/3A/3E/RN147185337.html?source=googlescholar" class="gs_nph" class=yCD>BL Direct</a> <a href="/scholar?cluster=15168080914944291644&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'PPOiazrZf9IJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.106.2291&amp;rep=rep1&amp;type=pdf" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/8xvpk1x6ce61vyqv.pdf" class=yCE>A complete and tight average-case analysis of learning monomials</a></h3><div class="gs_a">R Reischuk, T Zeugmann - STACS 99, 1999 - Springer</div><div class="gs_rs">We advocate to analyze the average complexity of learning problems. An appropriate <br>framework for this purpose is introduced. Based on it we consider the problem of learning <br>monomials and the special case of learning monotone monomials in the limit and for on-<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8439641320423901482&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 12</a> <a href="/scholar?q=related:KkmT1xChH3UJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/49/01/RN058381366.html?source=googlescholar" class="gs_nph" class=yC10>BL Direct</a> <a href="/scholar?cluster=8439641320423901482&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'KkmT1xChH3UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0022000007000797" class=yC11>Non-U-shaped vacillatory and team learning</a></h3><div class="gs_a">L Carlucci, <a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, F Stephan - Journal of Computer and System  &hellip;, 2008 - Elsevier</div><div class="gs_rs">U-shaped learning behaviour in cognitive development involves learning, unlearning and <br>relearning. It occurs, for example, in learning irregular verbs. The prior cognitive science <br>literature is occupied with how humans do it, for example, general rules versus tables of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15174229983668930833&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 11</a> <a href="/scholar?q=related:EQmrDMaxldIJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15174229983668930833&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'EQmrDMaxldIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/AM7558R84445558T.pdf" class=yC12>U-shaped, iterative, and iterative-with-counter learning</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, SE Moelius - Machine Learning, 2008 - Springer</div><div class="gs_rs">Abstract This paper solves an important problem left open in the literature by showing that U-<br>shapes are unnecessary in iterative learning from positive data. A U-shape occurs when a <br>learner first learns, then unlearns, and, finally, relearns, some target concept. Iterative <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3868849313996447409&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 13</a> <a href="/scholar?q=related:sZ5F-vPpsDUJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/14/04/RN231197058.html?source=googlescholar" class="gs_nph" class=yC13>BL Direct</a> <a href="/scholar?cluster=3868849313996447409&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'sZ5F-vPpsDUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://www.comp.nus.edu.sg/~sanjay/paps/nrec.pdf" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/BN4WUBDWE0233BPV.pdf" class=yC14>Synthesizing learners tolerating computable noisy data</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a> - Algorithmic Learning Theory, 1998 - Springer</div><div class="gs_rs">An index for an re class of languages (by definition) generates a sequence of grammars <br>defining the class. An index for an indexed family of languages (by definition) generates a <br>sequence of decision procedures defining the family. F. Stephan&#39;s model of noisy data is <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8588859833335155509&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 10</a> <a href="/scholar?q=related:NQuQP4PCMXcJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/23/15/RN051857756.html?source=googlescholar" class="gs_nph" class=yC16>BL Direct</a> <a href="/scholar?cluster=8588859833335155509&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 18 versions</a> <a onclick="return gs_ocit(event,'NQuQP4PCMXcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.127.40&amp;rep=rep1&amp;type=pdf" class=yC18><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/7NDLJGW0PUQ0N9P5.pdf" class=yC17>Non U-shaped vacillatory and team learning</a></h3><div class="gs_a">L Carlucci, <a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, F Stephan - Algorithmic Learning Theory, 2005 - Springer</div><div class="gs_rs">U-shaped learning behaviour in cognitive development involves learning, unlearning and <br>relearning. It occurs, for example, in learning irregular verbs. The prior cognitive science <br>literature is occupied with how humans do it, for example, general rules versus tables of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17320379244408874314&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 10</a> <a href="/scholar?q=related:SiUKzidZXvAJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/49/37/RN176167037.html?source=googlescholar" class="gs_nph" class=yC19>BL Direct</a> <a href="/scholar?cluster=17320379244408874314&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'SiUKzidZXvAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.111.1902&amp;rep=rep1&amp;type=pdf" class=yC1B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.111.1902&amp;rep=rep1&amp;type=pdf" class=yC1A>U-shaped learning may be necessary 3</a></h3><div class="gs_a">L Carluccia, J Caseb, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jainc</a>, F Stephand - 2005 - Citeseer</div><div class="gs_rs">Abstract U-shaped learning behaviour in cognitive development involves learning, <br>unlearning and relearning. It occurs, for example, in learning irregular verbs. The prior <br>cognitive science literature is occupied with how humans do it, for example, general rules <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1694151723058814796&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 8</a> <a href="/scholar?q=related:TF-JIATWghcJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1694151723058814796&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 20 versions</a> <a onclick="return gs_ocit(event,'TF-JIATWghcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md12', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md12" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:TF-JIATWghcJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/1r638k4x8jgt667r.pdf" class=yC1C>Memory-limited U-shaped learning</a></h3><div class="gs_a">L Carlucci, <a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, F Stephan - Learning Theory, 2006 - Springer</div><div class="gs_rs">Abstract. U-shaped learning is a learning behaviour in which the learner first learns <br>something, then unlearns it and finally relearns it. Such a behaviour, observed by <br>psychologists, for example, in the learning of past-tenses of English verbs, has been <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4199449437320713757&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 8</a> <a href="/scholar?q=related:HRa3ewNxRzoJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/1A/2C/RN191556651.html?source=googlescholar" class="gs_nph" class=yC1D>BL Direct</a> <a href="/scholar?cluster=4199449437320713757&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'HRa3ewNxRzoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://its.lnpu.edu.ua/edocs1/new_doc/en/Bunke%20H.%20(ed.),%20Kandel%20A.%20(ed.),%20Last%20M.%20(ed.)%20-%20Data%20Mining%20In%20Time%20Series%20Databases%20(2004)(en).pdf#page=114" class=yC1F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from lnpu.edu.ua</span><span class="gs_ggsS">lnpu.edu.ua <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://its.lnpu.edu.ua/edocs1/new_doc/en/Bunke%20H.%20(ed.),%20Kandel%20A.%20(ed.),%20Last%20M.%20(ed.)%20-%20Data%20Mining%20In%20Time%20Series%20Databases%20(2004)(en).pdf#page=114" class=yC1E>Change detection in classification models induced from time series data</a></h3><div class="gs_a">G Zeira, <a href="/citations?user=_ahrzOAAAAAJ&amp;hl=en&amp;oi=sra">O Maimon</a>, <a href="/citations?user=YESiQv4AAAAJ&amp;hl=en&amp;oi=sra">M Last</a>, <a href="/citations?user=makfxEUAAAAJ&amp;hl=en&amp;oi=sra">L Rokach</a> - &hellip; â, M. Last, A. Kandel, and H.  &hellip;, 2004 - its.lnpu.edu.ua</div><div class="gs_rs">Most classification methods are based on the assumption that the historic data involved in <br>building and verifying the model is the best estimator of what will happen in the future. One <br>important factor that must not be set aside is the time factor. As more data is accumulated <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6038898997529842350&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 8</a> <a href="/scholar?q=related:rpI6jqR6zlMJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6038898997529842350&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'rpI6jqR6zlMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md14', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md14" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:rpI6jqR6zlMJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397510002045" class=yC20>Iterative learning of simple external contextual languages</a></h3><div class="gs_a">L Becerra-Bonache, <a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>&hellip; - Theoretical Computer  &hellip;, 2010 - Elsevier</div><div class="gs_rs">It is investigated for which choice of a parameter q, denoting the number of contexts, the <br>class of simple external contextual languages is iteratively learnable. On the one hand, the <br>class admits, for all values of q, polynomial time learnability provided an adequate choice <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1441054131738363263&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 8</a> <a href="/scholar?q=related:f8VfCBmn_xMJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1441054131738363263&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'f8VfCBmn_xMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://www.comp.nus.edu.sg/~sanjay/paps/good.pdf" class=yC22><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397500001316" class=yC21>On the learnability of recursively enumerable languages from good examples</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, S Lange, J Nessel - Theoretical computer science, 2001 - Elsevier</div><div class="gs_rs">The present paper investigates identification of indexed families L of recursively enumerable <br>languages from good examples. We distinguish class-preserving learning from good <br>examples (the good examples have to be generated with respect to a hypothesis space <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5124833383680655013&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 7</a> <a href="/scholar?q=related:pT5ZV88QH0cJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5124833383680655013&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'pT5ZV88QH0cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://colt2010.haifa.il.ibm.com/presentation/COLT10Talk-NUTechniques.pdf" class=yC24><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ibm.com</span><span class="gs_ggsS">ibm.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://colt2010.haifa.il.ibm.com/presentation/COLT10Talk-NUTechniques.pdf" class=yC23>Strongly non-U-shaped learning results by general techniques</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, T KÃ¶tzing - Proceedings of COLT (Conference on  &hellip;, 2010 - colt2010.haifa.il.ibm.com</div><div class="gs_rs">Let N={0, 1, 2,...}, the set of all natural numbers. A language is a set Lâ N. A presentation for <br>L is essentially an (infinite) listing T of all and only the elements of L. Such a T is called a text <br>for L. We numerically name programs or grammars in some standard general hypothesis <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16271890449647034039&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 9</a> <a href="/scholar?q=related:t15I2yZe0eEJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16271890449647034039&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'t15I2yZe0eEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md17', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md17" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:t15I2yZe0eEJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB18" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW18"><a href="http://cs5235.userapi.com/u133638729/docs/ceb9e6352614/Marcus_Hutter_Algorithmic_Learning_Theory_18_co.pdf#page=60" class=yC26><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from userapi.com</span><span class="gs_ggsS">userapi.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/m13t261w8547g2w7.pdf" class=yC25>Parallelism increases iterative learning power</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, S Moelius - Algorithmic Learning Theory, 2007 - Springer</div><div class="gs_rs">Iterative learning (It It-learning) is a Gold-style learning model in which each of a learner&#39;s <br>output conjectures may depend only upon the learner&#39;s current conjecture and the current <br>input element. Two extensions of the It It-learning model are considered, each of which <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2824165430781207115&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 6</a> <a href="/scholar?q=related:S-KmCH9zMScJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/33/0B/RN216180768.html?source=googlescholar" class="gs_nph" class=yC27>BL Direct</a> <a href="/scholar?cluster=2824165430781207115&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'S-KmCH9zMScJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="http://cs5235.userapi.com/u133638729/docs/0b3b37a51a80/Ricard_Gavald_Algorithmic_Learning_Theory_14_co.pdf#page=17" class=yC29><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from userapi.com</span><span class="gs_ggsS">userapi.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/61px2eqgnaf9ugv1.pdf" class=yC28>Can learning in the limit be done efficiently?</a></h3><div class="gs_a">T Zeugmann - Algorithmic Learning Theory, 2003 - Springer</div><div class="gs_rs">Inductive inference can be considered as one of the fundamental paradigms of algorithmic <br>learning theory. We survey results recently obtained and show their impact to potential <br>applications. Since the main focus is put on the efficiency of learning, we also deal with <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11820875289918507331&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 6</a> <a href="/scholar?q=related:QwnJTXIvDKQJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/47/55/RN139774886.html?source=googlescholar" class="gs_nph" class=yC2A>BL Direct</a> <a href="/scholar?cluster=11820875289918507331&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'QwnJTXIvDKQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/F7Q6184682RG6200.pdf" class=yC2B>On the strength of incremental learning</a></h3><div class="gs_a">S Lange, G Grieser - Algorithmic Learning Theory, 1999 - Springer</div><div class="gs_rs">This paper provides a systematic study of incremental learning from noise-free and from <br>noisy data, thereby distinguishing between learning from only positive data and from both <br>positive and negative data. Our study relies on the notion of noisy data introduced in [22]. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11071798720267559072&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 7</a> <a href="/scholar?q=related:oCAsckbuppkJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11071798720267559072&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'oCAsckbuppkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="http://cs5235.userapi.com/u133638729/docs/e02780dda47c/Yoav_Freund_Algorithmic_Learning_Theory_19_conf.pdf#page=371" class=yC2D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from userapi.com</span><span class="gs_ggsS">userapi.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/e654657xu548t251.pdf" class=yC2C>Iterative learning of simple external contextual languages</a></h3><div class="gs_a">L Becerra-Bonache, <a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>&hellip; - Algorithmic Learning  &hellip;, 2008 - Springer</div><div class="gs_rs">It is investigated for which choice of a parameter q, denoting the number of contexts, the <br>class of simple external contextual languages is iteratively learnable. On one hand, the class <br>admits, for all values of q, polynomial time learnability provided an adequate choice of the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16435534324706102193&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 6</a> <a href="/scholar?q=related:scvYnWO_FuQJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16435534324706102193&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 25 versions</a> <a onclick="return gs_ocit(event,'scvYnWO_FuQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB22" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW22"><a href="http://www.cis.udel.edu/~moelius/publications/iteqnuit_mlj_preprint.pdf" class=yC2F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from udel.edu</span><span class="gs_ggsS">udel.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/K6565966X8828563.pdf" class=yC2E>U-shaped, iterative, and iterative-with-counter learning</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, S Moelius - Learning Theory, 2007 - Springer</div><div class="gs_rs">This paper solves an important problem left open in the literature by showing that U-shapes <br>are unnecessary in iterative learning. A U-shape occurs when a learner first learns, then <br>unlearns, and, finally, relearns, some target concept. Iterative learning is a Gold-style <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13027096633014401606&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 5</a> <a href="/scholar?q=related:RrqCAV6LybQJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/30/40/RN210335558.html?source=googlescholar" class="gs_nph" class=yC30>BL Direct</a> <a href="/scholar?cluster=13027096633014401606&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'RrqCAV6LybQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB23" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW23"><a href="http://eprints.lib.hokudai.ac.jp/dspace/bitstream/2115/17137/1/TCS364-1-77.pdf" class=yC32><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hokudai.ac.jp</span><span class="gs_ggsS">hokudai.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397506004919" class=yC31>From learning in the limit to stochastic finite learning</a></h3><div class="gs_a">T Zeugmann - Theoretical computer science, 2006 - Elsevier</div><div class="gs_rs">Inductive inference can be considered as one of the fundamental paradigms of algorithmic <br>learning theory. We survey results recently obtained and show their impact to potential <br>applications. Since the main focus is put on the efficiency of learning, we also deal with <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11087403400132621710&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 5</a> <a href="/scholar?q=related:jvVcGqZe3pkJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11087403400132621710&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'jvVcGqZe3pkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB24" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW24"><a href="http://www.ke.tu-darmstadt.de/m/lehre/archiv/ss06/alg-lernen/incremental-fattext-initialhyp.pdf" class=yC34><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tu-darmstadt.de</span><span class="gs_ggsS">tu-darmstadt.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/1GAC95CTA52GAPQY.pdf" class=yC33>On variants of iterative learning</a></h3><div class="gs_a">S Lange, G Grieser - Discovey Science, 1998 - Springer</div><div class="gs_rs">Within the present paper, we investigate the principal learning capabilities of iterative <br>learners in some more details. The general scenario of iterative learning is as follows. An <br>iterative learner successively takes as input one element of a text (an informant) of a target <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13431119681550054261&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 5</a> <a href="/scholar?q=related:dXOMcjDsZLoJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/2D/46/RN054920106.html?source=googlescholar" class="gs_nph" class=yC35>BL Direct</a> <a href="/scholar?cluster=13431119681550054261&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'dXOMcjDsZLoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB25" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW25"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.114.3889&amp;rep=rep1&amp;type=pdf#page=180" class=yC37><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/2781772065028428.pdf" class=yC36>Towards a better understanding of incremental learning</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, S Lange, <a href="/citations?user=gkUY7QMAAAAJ&amp;hl=en&amp;oi=sra">S Zilles</a> - Algorithmic Learning Theory, 2006 - Springer</div><div class="gs_rs">The present study aims at insights into the nature of incremental learning in the context of <br>Gold&#39;s model of identification in the limit. With a focus on natural requirements such as <br>consistency and conservativeness, incremental learning is analysed both for learning from <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17597689232025633736&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 7</a> <a href="/scholar?q=related:yMOath6NN_QJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/25/56/RN195821105.html?source=googlescholar" class="gs_nph" class=yC38>BL Direct</a> <a href="/scholar?cluster=17597689232025633736&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'yMOath6NN_QJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/L69637G3780M3J8U.pdf" class=yC39>String extension learning using lattices</a></h3><div class="gs_a">A Kasprzik, T KÃ¶tzing - Language and Automata Theory and Applications, 2010 - Springer</div><div class="gs_rs">Abstract. The class of regular languages is not identifiable from positive data in Gold&#39;s <br>language learning model. Many attempts have been made to define interesting classes that <br>are learnable in this model, preferably with the associated learner having certain <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17875595812586502097&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 6</a> <a href="/scholar?q=related:0betva7fEvgJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17875595812586502097&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'0betva7fEvgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/WW86604W658G5101.pdf" class=yC3A>Solutions to open questions for non-U-shaped learning with memory limitations</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, T KÃ¶tzing - Algorithmic Learning Theory, 2010 - Springer</div><div class="gs_rs">A U-shape occurs when a learner first learns, then unlearns, and, finally, relearns, some <br>target concept. Within the framework of Inductive Inference, previous results have shown, for <br>example, that U-shapes are unnecessary for explanatory learning, but are necessary for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12332842702605565065&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 5</a> <a href="/scholar?q=related:ibyShxgPJ6sJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12332842702605565065&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'ibyShxgPJ6sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB28" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW28"><a href="http://cs5235.userapi.com/u133638729/docs/0b3b37a51a80/Ricard_Gavald_Algorithmic_Learning_Theory_14_co.pdf#page=234" class=yC3C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from userapi.com</span><span class="gs_ggsS">userapi.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/4b58j4ktgql69ylf.pdf" class=yC3B>Learning a subclass of regular patterns in polynomial time</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, R Reischuk, F Stephan&hellip; - Algorithmic Learning  &hellip;, 2003 - Springer</div><div class="gs_rs">Presented is an algorithm (for learning a subclass of erasing regular pattern languages) <br>which can be made to run with arbitrarily high probability of success on extended regular <br>languages generated by patterns Ï of the form x 0 Î± 1 x 1... Î± mxm for unknown m but <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13302525197518435813&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 5</a> <a href="/scholar?q=related:5fXE9S8QnLgJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/20/08/RN139775026.html?source=googlescholar" class="gs_nph" class=yC3D>BL Direct</a> <a href="/scholar?cluster=13302525197518435813&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'5fXE9S8QnLgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397502001767" class=yC3E>Variants of iterative learning</a></h3><div class="gs_a">S Lange, G Grieser - Theoretical computer science, 2003 - Elsevier</div><div class="gs_rs">We investigate the principal learning capabilities of iterative learners in some more details. <br>Thereby, we confine ourselves to study the learnability of indexable concept classes. The <br>general scenario of iterative learning is as follows. An iterative learner successively takes <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7522144020785396846&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 3</a> <a href="/scholar?q=related:bvw9BCIGZGgJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7522144020785396846&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'bvw9BCIGZGgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB30" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW30"><a href="http://www.comp.nus.edu.sg/~sanjay/paps/tem.pdf" class=yC40><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397510002057" class=yC3F>Incremental learning with temporary memory</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, S Lange, SE Moelius, <a href="/citations?user=gkUY7QMAAAAJ&amp;hl=en&amp;oi=sra">S Zilles</a> - Theoretical Computer Science, 2010 - Elsevier</div><div class="gs_rs">In the inductive inference framework of learning in the limit, a variation of the bounded <br>example memory (Bem) language learning model is considered. Intuitively, the new model <br>constrains the learner&#39;s memory not only in how much data may be stored, but also in how <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14531567877095585502&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 5</a> <a href="/scholar?q=related:3nbCH_5_qskJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14531567877095585502&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'3nbCH_5_qskJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397509000668" class=yC41>Parallelism increases iterative learning power</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, SE Moelius III - Theoretical Computer Science, 2009 - Elsevier</div><div class="gs_rs">Iterative learning (It-learning) is a Gold-style learning model in which each of a learner&#39;s <br>output conjectures may depend only upon the learner&#39;s current conjecture and the current <br>input element. Two extensions of the It-learning model are considered, each of which <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8888623813914682370&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 3</a> <a href="/scholar?q=related:AmR2ykO8WnsJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8888623813914682370&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'AmR2ykO8WnsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB32" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW32"><a href="http://cs5235.userapi.com/u133638729/docs/e02780dda47c/Yoav_Freund_Algorithmic_Learning_Theory_19_conf.pdf#page=461" class=yC43><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from userapi.com</span><span class="gs_ggsS">userapi.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/H18M222XV34JT501.pdf" class=yC42>Learning with temporary memory</a></h3><div class="gs_a">S Lange, S Moelius, <a href="/citations?user=gkUY7QMAAAAJ&amp;hl=en&amp;oi=sra">S Zilles</a> - Algorithmic Learning Theory, 2008 - Springer</div><div class="gs_rs">In the inductive inference framework of learning in the limit, a variation of the bounded <br>example memory (Bem) language learning model is considered. Intuitively, the new model <br>constrains the learner&#39;s memory not only in how much data may be retained, but also in <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13833836604818541277&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 3</a> <a href="/scholar?q=related:3UoB5xip-78J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13833836604818541277&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'3UoB5xip-78J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:367"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB33" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW33"><a href="http://cs5824.userapi.com/u11728334/docs/a70c63d88f80/Hiroki_Arimura_Algorithmic_Learning_Theory_11_c.pdf#page=111" class=yC45><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from userapi.com</span><span class="gs_ggsS">userapi.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/uhq0emr1dtqgjrkx.pdf" class=yC44>Learning recursive concepts with anomalies</a></h3><div class="gs_a">G Grieser, S Lange, T Zeugmann - Algorithmic Learning Theory, 2000 - Springer</div><div class="gs_rs">This paper provides a systematic study of inductive inference of indexable concept classes <br>in learning scenarios in which the learner is successful if its final hypothesis describes a <br>finite variant of the target concept-henceforth called learning with anomalies. As usual, we <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18349215674150840937&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 3</a> <a href="/scholar?q=related:aWrK9G-Cpf4J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/41/08/RN088073472.html?source=googlescholar" class="gs_nph" class=yC46>BL Direct</a> <a href="/scholar?cluster=18349215674150840937&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 17 versions</a> <a onclick="return gs_ocit(event,'aWrK9G-Cpf4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:366"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB34" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW34"><a href="http://eprints2008.lib.hokudai.ac.jp/dspace/bitstream/2115/17138/1/TCS364-1-115.pdf" class=yC48><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hokudai.ac.jp</span><span class="gs_ggsS">hokudai.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397506004932" class=yC47>Learning a subclass of regular patterns in polynomial time</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, R Reischuk, F Stephan&hellip; - Theoretical computer  &hellip;, 2006 - Elsevier</div><div class="gs_rs">An algorithm for learning a subclass of erasing regular pattern languages is presented. On <br>extended regular pattern languages generated by patterns Ï of the form x0Î±1x1â¦ Î±mxm, <br>where x0,â¦, xm are variables and Î±1,..., Î±m strings of terminals of length c each, it runs <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5516447583130505111&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 3</a> <a href="/scholar?q=related:l0-OdtlbjkwJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5516447583130505111&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'l0-OdtlbjkwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:365"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0022000000917367" class=yC49>Synthesizing learners tolerating computable noisy data</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a> - Journal of Computer and System Sciences, 2001 - Elsevier</div><div class="gs_rs">An index for an re class of languages (by definition) generates a sequence of grammars <br>defining the class. An index for an indexed family of recursive languages (by definition) <br>generates a sequence of decision procedures defining the family. F. Stephan&#39;s model of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7171508854455950627&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 2</a> <a href="/scholar?q=related:I11qjU5RhmMJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/07/05/RN095929989.html?source=googlescholar" class="gs_nph" class=yC4A>BL Direct</a> <a href="/scholar?cluster=7171508854455950627&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'I11qjU5RhmMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:364"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB36" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW36"><a href="http://www2.cs.uregina.ca/~zilles/jainLZ07incremental.pdf" class=yC4C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uregina.ca</span><span class="gs_ggsS">uregina.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0890540107000740" class=yC4B>Some natural conditions on incremental learning</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, S Lange, <a href="/citations?user=gkUY7QMAAAAJ&amp;hl=en&amp;oi=sra">S Zilles</a> - Information and Computation, 2007 - Elsevier</div><div class="gs_rs">The present study aims at insights into the nature of incremental learning in the context of <br>Gold&#39;s model of identification in the limit. With a focus on natural requirements such as <br>consistency and conservativeness, incremental learning is analysed both for learning from <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6211599052712979839&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 2</a> <a href="/scholar?q=related:fy0ckG0INFYJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6211599052712979839&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'fy0ckG0INFYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:363"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB37" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW37"><a href="http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2937/1/TRB4-09.pdf" class=yC4E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/6813w3k86555t79h.pdf" class=yC4D>Iterative learning from texts and counterexamples using additional information</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, E Kinber - Algorithmic Learning Theory, 2009 - Springer</div><div class="gs_rs">A variant of iterative learning in the limit (cf.[LZ96]) is studied when a learner gets negative <br>examples refuting conjectures containing data in excess of the target language and uses <br>additional information of the following four types: a) memorizing up to n input elements <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17952311195222952859&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 3</a> <a href="/scholar?q=related:m0uIqOprI_kJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17952311195222952859&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'m0uIqOprI_kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:362"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> U-shaped, iterative, and iterative-with-counter learning (expanded version)</h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, SE Moelius III - 2007 - Technical report, University of  &hellip;</div><div class="gs_fl"><a href="/scholar?cites=16819677866713674713&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 2</a> <a href="/scholar?q=related:2fP3wed_a-kJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'2fP3wed_a-kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:361"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB39" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW39"><a href="http://www-alg.ist.hokudai.ac.jp/~thomas/publications/saga01z.ps.gz" class=yC50><span class="gs_ggsL"><span class=gs_ctg2>[PS]</span> from hokudai.ac.jp</span><span class="gs_ggsS">hokudai.ac.jp <span class=gs_ctg2>[PS]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/4APV7JEF2FUUCKV3.pdf" class=yC4F>Stochastic finite learning</a></h3><div class="gs_a">T Zeugmann - Stochastic Algorithms: Foundations and Applications, 2001 - Springer</div><div class="gs_rs">Recently, we have developed a learning model, called stochastic finite learning, that makes <br>a connection between concepts from PAC learning and inductive inference learning models. <br>The motivation for this work is as follows. Within Gold&#39;s (1967) model of learning in the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3911878163755603211&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 2</a> <a href="/scholar?q=related:C5VCw3bISTYJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/3A/5F/RN106686099.html?source=googlescholar" class="gs_nph" class=yC51>BL Direct</a> <a href="/scholar?cluster=3911878163755603211&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'C5VCw3bISTYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:360"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/B827045M7662102M.pdf" class=yC52>Iterative learning from positive data and counters</a></h3><div class="gs_a">T KÃ¶tzing - Algorithmic Learning Theory, 2011 - Springer</div><div class="gs_rs">We analyze iterative learning in the limit from positive data with the additional information <br>provided by a counter. The simplest type of counter provides the current iteration number <br>(counting up from 0 to infinity), which is known to improve learning power over plain <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3496968209057278535&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 2</a> <a href="/scholar?q=related:R2qx8w66hzAJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3496968209057278535&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'R2qx8w66hzAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:359"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB41" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW41"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.15.9807&amp;rep=rep1&amp;type=pdf" class=yC54><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.15.9807&amp;rep=rep1&amp;type=pdf" class=yC53>HOMO LUDENS: ON THE PLAYâ ELEMENT IN INDUCTIVE LOGIC</a></h3><div class="gs_a">A Agostini, DS Itc-irst - 2001 - Citeseer</div><div class="gs_rs">This report has been submitted forpublication outside of ITC and will probably be <br>copyrighted if accepted for publication. It has been issued as a Technical Report forearly <br>dissemination of its contents. In view of the transfert of copy right tothe outside publisher, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1990690201186605219&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 2</a> <a href="/scholar?q=related:oxiU2zBaoBsJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1990690201186605219&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'oxiU2zBaoBsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md41', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md41" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:oxiU2zBaoBsJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:358"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/K9T4732U26W2U651.pdf" class=yC55>Segmentation of Continuous Data Streams Based on a Change Detection Methodology</a></h3><div class="gs_a">G Zeira, <a href="/citations?user=YESiQv4AAAAJ&amp;hl=en&amp;oi=sra">M Last</a>, <a href="/citations?user=_ahrzOAAAAAJ&amp;hl=en&amp;oi=sra">O Maimon</a> - &hellip;  in Knowledge Discovery and Data Mining, 2005 - Springer</div><div class="gs_rs">Most data mining algorithms assume that the historic data are the best estimator of what will <br>happen in the future. As more data are accumulated in a database, one should examine <br>whether the new data agrees with the model induced from previous instances. The <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14283231407853218803&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 1</a> <a href="/scholar?q=related:8yvLJUo7OMYJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14283231407853218803&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'8yvLJUo7OMYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:357"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB43" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW43"><a href="http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1903/1/tr51-05.pdf" class=yC57><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.comp.nus.edu.sg/dspace/handle/1900.100/1903" class=yC56>Memory-Limited U-Shaped Learning</a></h3><div class="gs_a">L CARLUCCI, <a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J CASE</a>, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S JAIN</a>, F STEPHAN - 2005 - dl.comp.nus.edu.sg</div><div class="gs_rs">Abstract: U-shaped learning is a learning behaviour in which the learner first learns <br>something, then unlearns it and finally relearns it. Such a behaviour, observed by <br>psychologists, for example, in the learning of past-tenses of English verbs, has been <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12730338166427747033&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 1</a> <a href="/scholar?q=related:2QKGOB0_q7AJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12730338166427747033&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'2QKGOB0_q7AJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:356"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB44" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW44"><a href="http://www.comp.nus.edu.sg/~sanjay/paps/autofeednew.pdf" class=yC59><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/371821UW3L4225G8.pdf" class=yC58>Automatic learners with feedback queries</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, Y Ong, P Semukhin&hellip; - Models of Computation in  &hellip;, 2011 - Springer</div><div class="gs_rs">Automatic classes are classes of languages for which a finite automaton can decide whether <br>a given element is in a set given by its index. The present work studies the learnability of <br>automatic families by automatic learners which, in each round, output a hypothesis and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12510664656516969797&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 2</a> <a href="/scholar?q=related:RXW6gzjPnq0J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12510664656516969797&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 18 versions</a> <a onclick="return gs_ocit(event,'RXW6gzjPnq0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:355"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB45" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW45"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.113.356&amp;rep=rep1&amp;type=pdf" class=yC5B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.113.356&amp;rep=rep1&amp;type=pdf" class=yC5A>Models for Algorithmic Teaching</a></h3><div class="gs_a">F Balbach - 2007 - Citeseer</div><div class="gs_rs">Abstract Learning theory focuses almost entirely on the learner and its efficient realization, <br>but neglects other parts of the learning process, most importantly the teacher, which is <br>merely modeled as a passive data source. In this thesis, however, we study models in <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11363439301021558047&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 1</a> <a href="/scholar?q=related:H2UalNYLs50J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11363439301021558047&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'H2UalNYLs50J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md45', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md45" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:H2UalNYLs50J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a>  <a href="/scholar?q=info:H2UalNYLs50J:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=13940587629991336701&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:354"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB46" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW46"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.72.3587&amp;rep=rep1&amp;type=pdf" class=yC5D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.72.3587&amp;rep=rep1&amp;type=pdf" class=yC5C>A Polynomial Time Learner for a Subclass of Regular Patterns</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, R Reischuk, F Stephan&hellip; - Electronic Colloquium on  &hellip;, 2004 - Citeseer</div><div class="gs_rs">Abstract Presented is an algorithm (for learning a subclass of erasing regular pattern <br>languages) which can be made to run with arbitrarily high probability of success on <br>extended regular languages generated by patterns Ï of the form x0Î±1x1... Î±mxm for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1269431837044927135&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 1</a> <a href="/scholar?q=related:n2qisYftnREJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1269431837044927135&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 32 versions</a> <a onclick="return gs_ocit(event,'n2qisYftnREJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md46', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md46" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:n2qisYftnREJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:353"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/2e9yk3herkaudm15.pdf" class=yC5E>On Learning to Coordinate</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, F Montagna, G Simi, A Sorbi - Learning Theory and Kernel &hellip;, 2003 - Springer</div><div class="gs_rs">A mere bounded number of random bits judiciously employed by a probabilistically correct <br>algorithmic coordinator is shown to increase the power of learning to coordinate compared <br>to deterministic algorithmic coordinators. Furthermore, these probabilistic algorithmic <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13786892589963911398&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 2</a> <a href="/scholar?q=related:5qBDtcPhVL8J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/55/33/RN136584144.html?source=googlescholar" class="gs_nph" class=yC5F>BL Direct</a> <a href="/scholar?cluster=13786892589963911398&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'5qBDtcPhVL8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:352"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/e260l7477q204851.pdf" class=yC60>Incremental learning with ordinal bounded example memory</a></h3><div class="gs_a">L Carlucci - Algorithmic Learning Theory, 2009 - Springer</div><div class="gs_rs">A Bounded Example Memory learner is a learner that operates incrementally and maintains <br>a memory of finitely many data items. The paradigm is well-studied and known to coincide <br>with set-driven learning. A hierarchy of stronger and stronger learning criteria is obtained <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8978091134854266144&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 1</a> <a href="/scholar?q=related:IH0StlGWmHwJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8978091134854266144&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'IH0StlGWmHwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:351"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB49" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW49"><a href="https://qir.kyushu-u.ac.jp/dspace/bitstream/2324/3021/5/trcs153.pdf" class=yC62><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from kyushu-u.ac.jp</span><span class="gs_ggsS">kyushu-u.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="https://qir.kyushu-u.ac.jp/dspace/handle/2324/3021" class=yC61>Analyzing the average-case behavior of conjunctive learning algorithms</a></h3><div class="gs_a">R Reischuk, T Zeugmann - 153, 1998 - qir.kyushu-u.ac.jp</div><div class="gs_rs">We advocate to analyze the average complexity of learning problems. An appropriate <br>framework for this purpose is introduced. Based on it we consider the problem of learning <br>monomials and the special case of learning monotone monomials in the limit and for on-<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3767901303583600495&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 1</a> <a href="/scholar?q=related:b-_UvEVGSjQJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3767901303583600495&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'b-_UvEVGSjQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:350"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0022000004001400" class=yC63>On learning to coordinate: random bits help, insightful normal forms, and competency isomorphisms</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, F Montagna, G Simi, A Sorbi - Journal of Computer and  &hellip;, 2005 - Elsevier</div><div class="gs_rs">A mere bounded number of random bits judiciously employed by a probabilistically correct <br>algorithmic coordinator is shown to increase the power of learning to coordinate compared <br>to deterministic algorithmic coordinators. Furthermore, these probabilistic algorithmic <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4977039399005438181&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 2</a> <a href="/scholar?q=related:5cDXwvb-EUUJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4977039399005438181&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'5cDXwvb-EUUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:349"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB51" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW51"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.146.2248&amp;rep=rep1&amp;type=pdf" class=yC65><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.146.2248&amp;rep=rep1&amp;type=pdf" class=yC64>Learning with temporary memory (expanded version)</a></h3><div class="gs_a">S Lange, SE Moelius, <a href="/citations?user=gkUY7QMAAAAJ&amp;hl=en&amp;oi=sra">S Zilles</a> - 2008 - Citeseer</div><div class="gs_rs">Abstract. In the inductive inference framework of learning in the limit, a variation of the <br>bounded example memory (Bem) language learning model is considered. Intuitively, the <br>new model constrains the learner&#39;s memory not only in how much data may be retained, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11027518364955726574&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 1</a> <a href="/scholar?q=related:7lJI0YadCZkJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11027518364955726574&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'7lJI0YadCZkJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md51', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md51" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:7lJI0YadCZkJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:348"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0020019003004459" class=yC66>Incremental learning of approximations from positive data</a></h3><div class="gs_a">G Grieser, S Lange - Information processing letters, 2004 - Elsevier</div><div class="gs_rs">Three different types of incremental learning are systematically studied: iterative learning, <br>feedback inference, and bounded example-memory learning. In contrast to exact learning, <br>where a learner is required to stabilize on a correct description of the target concept, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=484423605361173773&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 1</a> <a href="/scholar?q=related:DeVd1rMEuQYJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=484423605361173773&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'DeVd1rMEuQYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:347"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB53" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW53"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.5284&amp;rep=rep1&amp;type=pdf" class=yC68><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.5284&amp;rep=rep1&amp;type=pdf" class=yC67>Hypothesis assessments as guidance for incremental and meta-learning</a></h3><div class="gs_a">G Grieser - Proc. 11th European Conference on Machine Learning &hellip;, 2000 - Citeseer</div><div class="gs_rs">Abstract. In this paper, a new decision tree learning algorithm (INCDT) is proposed: an <br>incremental one based on hypotheses assessments. INC-DT uses only a xed amount of <br>instance memory during the whole learning process. It bases its hypotheses exclusively <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9066741575949515362&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=88">Cited by 1</a> <a href="/scholar?q=related:Ynq8-GyJ030J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9066741575949515362&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'Ynq8-GyJ030J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md53', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md53" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Ynq8-GyJ030J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:346"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> 19716-2586, USA caseQcis. udel. edu 2 School of Computing, National University of Singapore, Singapore 117543 sanj ayOcomp. nus. edu. sg 3 Institute &hellip;</h3><div class="gs_a">P Time, T Zeugmann - Algorithmic Learning Theory:... Workshop, ALT...:  &hellip;, 2003 - Springer</div><div class="gs_fl"><a href="/scholar?q=related:8o0GCrQ1Q-0J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'8o0GCrQ1Q-0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:345"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/12017035066353VR.pdf" class=yC69>Resource Restricted Computability Theoretic Learning: Illustrative Topics and Problems</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a> - Computation and Logic in the Real World, 2007 - Springer</div><div class="gs_rs">Computability theoretic learning theory (machine inductive inference) typically involves <br>learning programs for languages or functions from a stream of complete data about them <br>and, importantly, allows mind changes as to conjectured programs. This theory takes into <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:MIjRDNBNqiIJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/3B/42/RN210775594.html?source=googlescholar" class="gs_nph" class=yC6A>BL Direct</a> <a href="/scholar?cluster=2497894499293956144&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'MIjRDNBNqiIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:344"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB56" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW56"><a href="http://www.cis.udel.edu/~case/papers/lncs_paper.ps" class=yC6C><span class="gs_ggsL"><span class=gs_ctg2>[PS]</span> from udel.edu</span><span class="gs_ggsS">udel.edu <span class=gs_ctg2>[PS]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PS]</span><span class="gs_ct2">[PS]</span></span> <a href="http://www.cis.udel.edu/~case/papers/lncs_paper.ps" class=yC6B>Ð§Ð² Ð¤ Ð¶Ð² Ð² Ð¬Ð³ Ð³Ð³Ð¶ Ð² Ð¸</a></h3><div class="gs_a">C Isomorphisms - cis.udel.edu</div><div class="gs_rs">Abstract. A mere bounded number of random bits judiciously employed by a probabilistically <br>correct algorithmic coordinator is shown to increase the power of learning to coordinate <br>compared to deterministic algorithmic coordinators. Furthermore, these probabilistic <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:H2iyE0DjcmQJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7238097415485679647&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'H2iyE0DjcmQJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md56', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md56" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:H2iyE0DjcmQJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:343"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB57" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW57"><a href="https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1510/1/upload.pdf" class=yC6E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="https://dl.comp.nus.edu.sg/dspace/handle/1900.100/1510" class=yC6D>U-shaped leaning may be necessary</a></h3><div class="gs_a">C Lorenzo, C John, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">J Sanjay</a>, S Frank - 2004 - dl.comp.nus.edu.sg</div><div class="gs_rs">Abstract: U-shaped learning behaviour in cognitive development involves learning, <br>unlearning and relearning. It occurs, for example, in learning irregular verbs. The prior <br>cognitive science literature is occupied with how humans do it, for example, general rules <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:aN5UGzEe8gMJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=284322922738540136&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'aN5UGzEe8gMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:342"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB58" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW58"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.88.1495&amp;rep=rep1&amp;type=pdf" class=yC70><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.88.1495&amp;rep=rep1&amp;type=pdf" class=yC6F>Some Results on U-shaped, Vacillatory and Team Learning</a></h3><div class="gs_a">L Carlucci, <a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, F Stephan - 2008 - Citeseer</div><div class="gs_rs">Abstract. U-shaped learning behaviour in cognitive development involves learning, <br>unlearning and relearning. It occurs, for example, in learning irregular verbs. The prior <br>cognitive science literature is occupied with how humans do it, for example, general rules <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:mMyKHdGlAbYJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13114945907441978520&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'mMyKHdGlAbYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md58', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md58" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:mMyKHdGlAbYJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:341"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> U-shaped learning may be necessary 3</h3><div class="gs_a">PM Siena</div><div class="gs_fl"><a href="/scholar?q=related:9zFARK7e_V8J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'9zFARK7e_V8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:340"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB60" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW60"><a href="http://www2.cs.uregina.ca/~zilles/langeMZ08TR.pdf" class=yC72><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uregina.ca</span><span class="gs_ggsS">uregina.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www2.cs.uregina.ca/~zilles/langeMZ08TR.pdf" class=yC71>Incremental Learning with Temporary Memory</a></h3><div class="gs_a">S Langea, S Zillesc - cs.uregina.ca</div><div class="gs_rs">Abstract In the inductive inference framework of learning in the limit, a variation of the <br>bounded example memory (Bem) language learning model is considered. Intuitively, the <br>new model constrains the learner&#39;s memory not only in how much data may be retained, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:MRIpRUDfVdEJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15084207994078564913&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'MRIpRUDfVdEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md60', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md60" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:MRIpRUDfVdEJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:339"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB61" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW61"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.5444&amp;rep=rep1&amp;type=pdf" class=yC74><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.5444&amp;rep=rep1&amp;type=pdf" class=yC73>Iterative concept learning from noisy data</a></h3><div class="gs_a">S en Lange, G Grieser - Citeseer</div><div class="gs_rs">Abstract In the present paper, we study iterative learning of indexable concept classes from <br>noisy data. We distinguish between learning from positive data only and learning from <br>positive and negative data; synonymously, learning from text and informant, respectively. <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:hovRSwK6TgMJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=238332349321939846&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'hovRSwK6TgMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md61', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md61" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:hovRSwK6TgMJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:338"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB62" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW62"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.5172&amp;rep=rep1&amp;type=pdf" class=yC76><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.5172&amp;rep=rep1&amp;type=pdf" class=yC75>On the power of incremental learning</a></h3><div class="gs_a">S en Langea, G Grieserb - Citeseer</div><div class="gs_rs">Abstract This paper provides a systematic study of incremental learning from noise-free and <br>from noisy data. As usual, we distinguish between learning from positive data and learning <br>from positive and negative data, synonymously called learning from text and learning from <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:xOBQUupPq0AJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4659906107266883780&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'xOBQUupPq0AJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md62', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md62" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:xOBQUupPq0AJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:337"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Deutsches Forschungszentrum f ur K unstliche Intelligenz, Stuhlsatzenhausweg 3, 66123 Saarbr ucken, Germany, Email: lange@ dfki. de b Technische  &hellip;</h3><div class="gs_a">S en Lange</div><div class="gs_fl"><a href="/scholar?q=related:3xgNVk77AAMJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'3xgNVk77AAMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:336"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB64" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW64"><a href="http://www.comp.nus.edu.sg/~sanjay/paps/bemord.pdf" class=yC78><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0022000012000876" class=yC77>Learning with ordinal-bounded memory from positive data</a></h3><div class="gs_a">L Carlucci, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, F Stephan - Journal of Computer and System Sciences, 2012 - Elsevier</div><div class="gs_rs">A bounded example memory learner operates incrementally and maintains a memory of <br>finitely many data items. The paradigm is well-studied and known to coincide with set-driven <br>learning. A hierarchy of stronger and stronger learning criteria had earlier been obtained <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:SO2jYG0s_0kJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5332029332114369864&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'SO2jYG0s_0kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:335"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB65" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW65"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.4578&amp;rep=rep1&amp;type=pdf" class=yC7A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.4578&amp;rep=rep1&amp;type=pdf" class=yC79>An Average-Case Optimal One-Variable Pattern Language Learner</a></h3><div class="gs_a">R udiger Reischuk, T Zeugmann - Citeseer</div><div class="gs_rs">Abstract A new algorithm for learning one-variable pattern languages from positive data is <br>proposed and analyzed with respect to its average-case behavior. We consider the total <br>learning time that takes into account all operations till convergence to a correct hypothesis <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:XAlbcQ9MadwJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15882309190108776796&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'XAlbcQ9MadwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md65', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md65" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:XAlbcQ9MadwJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:334"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397507002277" class=yC7B>On the data consumption benefits of accepting increased uncertainty</a></h3><div class="gs_a">E Martin, A Sharma, F Stephan - Theoretical Computer Science, 2007 - Elsevier</div><div class="gs_rs">In the context of learning paradigms of identification in the limit, we address the question: <br>why is uncertainty sometimes desirable? We use mind change bounds on the output <br>hypotheses as a measure of uncertainty and interpret &#39;desirable&#39;as reduction in data <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:YN_1eqwpL5wJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11254259814596206432&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'YN_1eqwpL5wJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:333"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB67" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW67"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.49.9565&amp;rep=rep1&amp;type=pdf" class=yC7D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.49.9565&amp;rep=rep1&amp;type=pdf" class=yC7C>A Complete and Tight Average-Case Analysis of Learning Monomials</a></h3><div class="gs_a">R udiger Reischuk, T Zeugmanny - 1998 - Citeseer</div><div class="gs_rs">Abstract We advocate to analyze the average complexity of learning problems. An <br>appropriate framework for this purpose is introduced. Based on it we consider the problem of <br>learning monomials and the special case of learning monotone monomials in the limit and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:nZDJexayAAgJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=576656561939255453&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'nZDJexayAAgJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md67', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md67" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:nZDJexayAAgJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:332"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/X524068561K52072.pdf" class=yC7E>Iterative learning from texts and counterexamples using additional information</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, E Kinber - Machine learning, 2011 - Springer</div><div class="gs_rs">Abstract A variant of iterative learning in the limit (cf. Lange and Zeugmann 1996) is studied <br>when a learner gets negative examples refuting conjectures containing data in excess of the <br>target language and uses additional information of the following four types:(a) memorizing <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:3qdCfFnTLTgJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4048124021366237150&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'3qdCfFnTLTgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:331"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB69" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW69"><a href="http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTRB/tcstr_08_4/tcstr_08_4.pdf" class=yC80><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hokudai.ac.jp</span><span class="gs_ggsS">hokudai.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTRB/tcstr_08_4/tcstr_08_4.pdf" class=yC7F>TCS Technical Report</a></h3><div class="gs_a">T Zeugmann, <a href="/citations?user=gkUY7QMAAAAJ&amp;hl=en&amp;oi=sra">S Zilles</a> - 2007 - www-alg.ist.hokudai.ac.jp</div><div class="gs_rs">AESYAISLAGFAKEGJWAEHGJLSFLLZSFC... epuv ep his le tures m inly l rifies the su je t of <br>cryptologyF qener lly spe kingD ryptology is out communication in the presence of <br>adversariesF gryptology ne diveded into two m jor p rtsD iFeFD cryptography nd <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:N39igYssHS0J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3250803483714158391&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'N39igYssHS0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md69', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md69" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:N39igYssHS0J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:330"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB70" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW70"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.6756&amp;rep=rep1&amp;type=pdf" class=yC82><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.6756&amp;rep=rep1&amp;type=pdf" class=yC81>On the strength of incremental learning</a></h3><div class="gs_a">S en Lange, G Grieser - Citeseer</div><div class="gs_rs">Abstract. This paper provides a systematic study of incremental learning from noise-free and <br>from noisy data, thereby distinguishing between learning from only positive data and from <br>both positive and negative data. Our study relies on the notion of noisy data introduced in <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:wMdDg89ZrbwJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13595621597896755136&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'wMdDg89ZrbwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md70', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md70" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:wMdDg89ZrbwJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:329"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/812361171q2264pu.pdf" class=yC83>Resource Restricted Computability Theoretic Learning: Illustrative Topics and Problems</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a> - Theory of Computing Systems, 2009 - Springer</div><div class="gs_rs">Abstract Computability theoretic learning theory (machine inductive inference) typically <br>involves learning programs for languages or functions from a stream of complete data about <br>them and, importantly, allows mind changes as to conjectured programs. This theory takes <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:cNGIg7j_YKkJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12205036158119891312&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'cNGIg7j_YKkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:328"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/6LYLFEKMFX7KTYQ4.pdf" class=yC84>On the data consumption benefits of accepting increased uncertainty</a></h3><div class="gs_a">E Martin, A Sharma, F Stephan - Algorithmic Learning Theory, 2004 - Springer</div><div class="gs_rs">In the context of learning paradigms of identification in the limit, we address the question: <br>why is uncertainty sometimes desirable? We use mind change bounds on the output <br>hypotheses as a measure of uncertainty, and interpret &#39;desirable&#39;as reduction in data <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:vahgiAbccK4J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/22/4F/RN157150765.html?source=googlescholar" class="gs_nph" class=yC85>BL Direct</a> <a href="/scholar?cluster=12569788480607004861&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'vahgiAbccK4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:327"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB73" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW73"><a href="http://www.eecis.udel.edu/~case/papers/pr2.pdf" class=yC87><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from udel.edu</span><span class="gs_ggsS">udel.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.eecis.udel.edu/~case/papers/pr2.pdf" class=yC86>On the Necessity of U-Shaped Learning</a></h3><div class="gs_a">L Carlucci, <a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a> - eecis.udel.edu</div><div class="gs_rs">Abstract. A U-shaped curve in a cognitive-developmental trajectory refers to a three-step <br>process: good performance followed by bad performance followed by good performance <br>once again. U-shaped curves have been observed in a wide variety of cognitive-<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17336137048815070431&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'32wcjMtUlvAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md73', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md73" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:326"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB74" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW74"><a href="http://eprints.lib.hokudai.ac.jp/dspace/bitstream/2115/45035/1/IC209-3_296-319.pdf" class=yC89><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hokudai.ac.jp</span><span class="gs_ggsS">hokudai.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0890540110001896" class=yC88>Teaching randomized learners with feedback</a></h3><div class="gs_a">FJ Balbach, T Zeugmann - Information and Computation, 2011 - Elsevier</div><div class="gs_rs">The present paper introduces a new model for teaching randomized learners. Our new <br>model, though based on the classical teaching dimension model, allows to study the <br>influence of the learner&#39;s memory size and of the presence or absence of feedback. <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:vdSsjvGr8NAJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15055722608268727485&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'vdSsjvGr8NAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:325"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397512009310" class=yC8A>Memory-limited non-U-shaped learning with solved open problems</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, T KÃ¶tzing - Theoretical Computer Science, 2012 - Elsevier</div><div class="gs_rs">Herein we also distinguish between semantic and syntactic U-shapes. We answer a number <br>of open questions in the prior literature as well as provide new results regarding syntactic <br>U-shapes. Importantly for cognitive science, we see more of a previously noticed pattern <b> ...</b> </div><div class="gs_fl"><a onclick="return gs_ocit(event,'zUS4nbYRNscJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:324"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB76" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW76"><a href="http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTR/tcstr_07_31/tcstr_07_31.pdf" class=yC8C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hokudai.ac.jp</span><span class="gs_ggsS">hokudai.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTR/tcstr_07_31/tcstr_07_31.pdf" class=yC8B>TCS Technical Report</a></h3><div class="gs_a">S Lange, T Zeugmann, <a href="/citations?user=gkUY7QMAAAAJ&amp;hl=en&amp;oi=sra">S Zilles</a> - 2007 - www-alg.ist.hokudai.ac.jp</div><div class="gs_rs">Abstract In the past 40 years, research on inductive inference has developed along different <br>lines, concerning different formalizations of learning models and in particular of target <br>concepts for learning. One common root of many of these is Gold&#39;s model of identification <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:uMhVpfJ4388J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14978823869208840376&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'uMhVpfJ4388J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md76', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md76" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:uMhVpfJ4388J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:323"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB77" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW77"><a href="http://rutcor.rutgers.edu/~amai/aimath04/AcceptedPapers/Lee-aimath04.pdf" class=yC8E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from rutgers.edu</span><span class="gs_ggsS">rutgers.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/J0W128K65840063R.pdf" class=yC8D>Learning via finitely many queries</a></h3><div class="gs_a">AC Lee - Annals of Mathematics and Artificial Intelligence, 2005 - Springer</div><div class="gs_rs">This work introduces a new query inference model that can access data and communicate <br>with the teacher by asking finitely many Boolean queries in a language L. In this model the <br>parameters of interest are the number of queries used and the expressive power of L. We <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:j_c9uEG18zwJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/20/20/RN174740146.html?source=googlescholar" class="gs_nph" class=yC8F>BL Direct</a> <a href="/scholar?cluster=4392053355484936079&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'j_c9uEG18zwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:322"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5366247" class=yC90>An Evolutionary Mining Model in Incremental Data Mining</a></h3><div class="gs_a">F Jiancong, L Yongquan&hellip; - &hellip;  Computation, 2009. ICNC&#39; &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Incremental data mining is very important to solve the temporal dynamic property of <br>knowledge, improve the performance of mining processes and efficiency of mining results. <br>Incremental data occurs with the passage of time. Evolutionary methods can be adopted <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:wDB-xDkMhDUJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3856220623185260736&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'wDB-xDkMhDUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:321"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/077MQYMTMHJRW1KN.pdf" class=yC91>Optimization and simulation: Sequential packing of flexible objects using evolutionary algorithms</a></h3><div class="gs_a">H Behnke, M Kolonko, U Mertins, S Schnitter - Stochastic Algorithms:  &hellip;, 2001 - Springer</div><div class="gs_rs">We want to fill a given two-dimensional closed contour as accurately as possible with a fixed <br>number of identical, flexible objects. These objects have to be packed sequentially. They <br>adapt themselves to the surface they are packed on, but their deformation can only be <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:avCi12WCx5cJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/57/2E/RN106686087.html?source=googlescholar" class="gs_nph" class=yC92>BL Direct</a> <a href="/scholar?cluster=10936853594013626474&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'avCi12WCx5cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:320"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB80" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW80"><a href="http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2317/1/TRC3-07.pdf" class=yC94><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.comp.nus.edu.sg/dspace/handle/1900.100/2317" class=yC93>Consistent and Conservative Iterative Learning</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, S Lange, <a href="/citations?user=gkUY7QMAAAAJ&amp;hl=en&amp;oi=sra">S ZILLES</a> - 2007 - dl.comp.nus.edu.sg</div><div class="gs_rs">Abstract: The present study aims at insights into the nature of incremental learning in the <br>context of Gold&#39;s model of identification in the limit. With a focus on natural requirements <br>such as consistency and conservativeness, incremental learning is analysed both for <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:g4a22neUaasJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12351566695531710083&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'g4a22neUaasJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:319"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397512007128" class=yC95>Learning in the limit with lattice-structured hypothesis spaces</a></h3><div class="gs_a">J Heinz, A Kasprzik, T KÃ¶tzing - Theoretical Computer Science, 2012 - Elsevier</div><div class="gs_rs">We define a collection of language classes which are TxtEx-learnable (learnable in the limit <br>from positive data). The learners map any data input to an element of a fixed lattice, and <br>keep the least upper bound of all lattice elements thus obtained as the current hypothesis. <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ZwsP5kjqVmoJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7662569414835768167&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'ZwsP5kjqVmoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:318"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB82" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW82"><a href="http://www.eecis.udel.edu/~case/siena/pat.pdf" class=yC97><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from udel.edu</span><span class="gs_ggsS">udel.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.eecis.udel.edu/~case/siena/pat.pdf" class=yC96>Some Information on Pattern Languages</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a> - eecis.udel.edu</div><div class="gs_rs">Much work has been done on learnability of pattern languages Ang80, Sal94a, Sal94b, <br>CJK+01, BJEG98 and finite unions thereof Shi83, Wri89, KMU95, BUV96, CJLZ99. Nix83 as <br>well as SA95 outline interesting applications of pattern inference algorithms. For example, <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'03VU6gCWWScJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md82', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md82" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:03VU6gCWWScJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:317"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB83" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW83"><a href="http://pdf.aminer.org/000/108/782/on_learning_to_coordinate_random_bits_help_insightful_normal_forms.pdf" class=yC99><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aminer.org</span><span class="gs_ggsS">aminer.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://pdf.aminer.org/000/108/782/on_learning_to_coordinate_random_bits_help_insightful_normal_forms.pdf" class=yC98>On Learning To Coordinate: Random Bits Help, Insightful Normal Forms, and</a></h3><div class="gs_a">C Isomorphisms - pdf.aminer.org</div><div class="gs_rs">Abstract. A mere bounded number of random bits udiciously employed by a probabilistically <br>correct algorithmic coordinator is shown to increase the power of learning to coordinate <br>compared to deterministic algorithmic coordinators. Furthermore, these probabilistic <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:w8cP6wx7_90J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15996639696856795075&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'w8cP6wx7_90J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md83', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md83" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:w8cP6wx7_90J:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:316"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB84" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW84"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.24.5351&amp;rep=rep1&amp;type=pdf" class=yC9B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.24.5351&amp;rep=rep1&amp;type=pdf" class=yC9A>Variants of iterative learning</a></h3><div class="gs_a">S en Langea, G Grieserb - Citeseer</div><div class="gs_rs">Abstract We investigate the principal learning capabilities of iterative learners in some more <br>details. Thereby, we con ne ourselves to study the learnability of indexable concept classes. <br>The general scenario of iterative learning is as follows. An iterative learner successively <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:DBc68Bpi7TAJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3525581951139976972&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'DBc68Bpi7TAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md84', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md84" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:DBc68Bpi7TAJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:315"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB85" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW85"><a href="http://www.comp.nus.edu.sg/~sanjay/paps/coord.pdf" class=yC9D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.comp.nus.edu.sg/~sanjay/paps/coord.pdf" class=yC9C>On Learning To Coordinate: Random Bits Help, Insightful Normal Forms, and Competency Isomorphisms</a></h3><div class="gs_a">JCSJF Montagnac, G Simic, A Sorbic - comp.nus.edu.sg</div><div class="gs_rs">Abstract A mere bounded number of random bits judiciously employed by a probabilistically <br>correct algorithmic coordinator is shown to increase the power of learning to coordinate <br>compared to deterministic algorithmic coordinators. Furthermore, these probabilistic <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:hy1_83_8liEJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2420399476234464647&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'hy1_83_8liEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md85', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md85" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:hy1_83_8liEJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:314"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB86" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW86"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.18.300&amp;rep=rep1&amp;type=pdf" class=yC9F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.18.300&amp;rep=rep1&amp;type=pdf" class=yC9E>DOI Technical Report</a></h3><div class="gs_a">R udiger Reischuk, T Zeugmann - 1997 - Citeseer</div><div class="gs_rs">Abstract We advocate to analyze the average complexity of learning problems. An <br>appropriate framework for this purpose is introduced. Based on it we consider the problem of <br>learning monomials and the special case of learning monotone monomials in the limit and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:HdiQ-g2CqaQJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11865157689834264605&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'HdiQ-g2CqaQJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md86', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md86" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:HdiQ-g2CqaQJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:313"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Auf dem Weg zum inkrementellen Lernen von Entscheidungsb aumen mit Hilfe von Hypothesenbewertungen</h3><div class="gs_a">G Grieser</div><div class="gs_fl"><a href="/scholar?q=related:TWjG9KrUJFgJ:scholar.google.com/&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6351435205215414349&amp;hl=en&amp;num=88&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'TWjG9KrUJFgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
