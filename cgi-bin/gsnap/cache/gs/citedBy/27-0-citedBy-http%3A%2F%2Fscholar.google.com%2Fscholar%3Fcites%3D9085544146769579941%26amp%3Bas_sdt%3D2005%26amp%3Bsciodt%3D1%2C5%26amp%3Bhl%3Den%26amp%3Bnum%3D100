Total results = 27
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.156.5031&amp;rep=rep1&amp;type=pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1576260" class=yC0>Concept-based video retrieval</a></h3><div class="gs_a"><a href="/citations?user=0uKdbscAAAAJ&amp;hl=en&amp;oi=sra">CGM Snoek</a>, <a href="/citations?user=pdu8f3sAAAAJ&amp;hl=en&amp;oi=sra">M Worring</a> - Foundations and Trends in Information  &hellip;, 2008 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we review 300 references on video retrieval, indicating when text-only <br>solutions are unsatisfactory and showing the promising alternatives which are in majority <br>concept-based. Therefore, central to our discussion is the notion of a semantic concept: an <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1240556430566916602&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 140</a> <a href="/scholar?q=related:-oHEN4BXNxEJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1240556430566916602&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 19 versions</a> <a onclick="return gs_ocit(event,'-oHEN4BXNxEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md0', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md0" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:-oHEN4BXNxEJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=868717410844952179&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://www.comp.nus.edu.sg/~mohan/papers/fusion_survey.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/E31M71152774R630.pdf" class=yC2>Multimodal fusion for multimedia analysis: a survey</a></h3><div class="gs_a"><a href="/citations?user=2s3sftgAAAAJ&amp;hl=en&amp;oi=sra">PK Atrey</a>, <a href="/citations?user=Qq4AAT4AAAAJ&amp;hl=en&amp;oi=sra">MA Hossain</a>, <a href="/citations?user=VcOjgngAAAAJ&amp;hl=en&amp;oi=sra">A El Saddik</a>, MS Kankanhalli - Multimedia Systems, 2010 - Springer</div><div class="gs_rs">Abstract This survey aims at providing multimedia researchers with a state-of-the-art <br>overview of fusion strategies, which are used for combining multiple modalities in order to <br>accomplish various multimedia analysis tasks. The existing literature on multimodal fusion <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2303959858949282248&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 65</a> <a href="/scholar?q=related:yFlu6UhP-R8J:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2303959858949282248&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'yFlu6UhP-R8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://nlpr-web.ia.ac.cn/2008papers/gjkw/gk9.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ia.ac.cn</span><span class="gs_ggsS">ia.ac.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4668533" class=yC4>Using webcast text for semantic event detection in broadcast sports video</a></h3><div class="gs_a">C Xu, YF Zhang, G Zhu, <a href="/citations?user=uOJH_AEAAAAJ&amp;hl=en&amp;oi=sra">Y Rui</a>, H Lu&hellip; - &hellip; , IEEE Transactions on, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Sports video semantic event detection is essential for sports video summarization <br>and retrieval. Extensive research efforts have been devoted to this area in recent years. <br>However, the existing sports video event detection approaches heavily rely on either <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10746102338593290273&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 44</a> <a href="/scholar?q=related:IfjYQyTTIZUJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10746102338593290273&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'IfjYQyTTIZUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://avss2012.org/2009papers/gjkw/gk35.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from avss2012.org</span><span class="gs_ggsS">avss2012.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4717216" class=yC6>Event tactic analysis based on broadcast sports video</a></h3><div class="gs_a">G Zhu, C Xu, Q Huang, <a href="/citations?user=uOJH_AEAAAAJ&amp;hl=en&amp;oi=sra">Y Rui</a>, <a href="/citations?user=4Rvn-ykAAAAJ&amp;hl=en&amp;oi=sra">S Jiang</a>&hellip; - Multimedia, IEEE  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Most existing approaches on sports video analysis have concentrated on semantic <br>event detection. Sports professionals, however, are more interested in tactic analysis to help <br>improve their performance. In this paper, we propose a novel approach to extract tactic <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10365539139394925456&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 24</a> <a href="/scholar?q=related:kPMKpe3K2Y8J:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10365539139394925456&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'kPMKpe3K2Y8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://www.cs.sjtu.edu.cn/~guo-my/PDF/Journals/J04.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from sjtu.edu.cn</span><span class="gs_ggsS">sjtu.edu.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5477420" class=yC8>TASA: Tag-free activity sensing using RFID tag arrays</a></h3><div class="gs_a"><a href="/citations?user=I2qCPFwAAAAJ&amp;hl=en&amp;oi=sra">D Zhang</a>, J Zhou, <a href="/citations?user=8R8FO9IAAAAJ&amp;hl=en&amp;oi=sra">M Guo</a>, J Cao&hellip; - Parallel and Distributed  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Radio Frequency IDentification (RFID) has attracted considerable attention in <br>recent years for its low cost, general availability, and location sensing functionality. Most <br>existing schemes require the tracked persons to be labeled with RFID tags. This <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3520717211878603491&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 20</a> <a href="/scholar?q=related:47qgkKYZ3DAJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3520717211878603491&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'47qgkKYZ3DAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://doras.dcu.ie/218/1/ieee_imvip_2007.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from dcu.ie</span><span class="gs_ggsS">dcu.ie <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4318145" class=yCA>Video semantic content analysis based on ontology</a></h3><div class="gs_a">L Bai, S Lao, <a href="/citations?user=YJuN_H8AAAAJ&amp;hl=en&amp;oi=sra">GJF Jones</a>&hellip; - Machine Vision and Image &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The rapid increase in the available amount of video data is creating a growing <br>demand for efficient methods for understanding and managing it at the semantic level. New <br>multimedia standards, such as MPEG-4 and MPEG-7, provide the basic functionalities in <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7734516949372888107&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 19</a> <a href="/scholar?q=related:K-SbrC-GVmsJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7734516949372888107&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'K-SbrC-GVmsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/3101450743414026.pdf" class=yCC>Automatic personalized video abstraction for sports videos using metadata</a></h3><div class="gs_a">N Nitta, Y Takahashi, N Babaguchi - Multimedia Tools and Applications, 2009 - Springer</div><div class="gs_rs">Abstract Video abstraction is defined as creating a video abstract which includes only <br>important information in the original video streams. There are two general types of video <br>abstracts, namely the dynamic and static ones. The dynamic video abstract is a 3-<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12687674915757126775&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 13</a> <a href="/scholar?q=related:d3RWGx2tE7AJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12687674915757126775&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'d3RWGx2tE7AJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1386416" class=yCD>An instant semantics acquisition system of live soccer video with application to live event alert and on-the-fly language selection</a></h3><div class="gs_a">X Yu, X Yan, L Li, HW Leong - &hellip;  of the 2008 international conference on  &hellip;, 2008 - dl.acm.org</div><div class="gs_rs">Abstract Automatic indexing of recorded sports video is a hard problem, even more so for <br>live sports video, though a lot of advances have been achieved in the recent years. This <br>paper presents a semi-automatic instant semantics generation system of live soccer video <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2021064417472605362&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 3</a> <a href="/scholar?q=related:suyiL2FDDBwJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'suyiL2FDDBwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/154047755G13402J.pdf" class=yCE>Modeling spatiotemporal relationships between moving objects for event tactics analysis in tennis videos</a></h3><div class="gs_a"><a href="/citations?user=DcltNjQAAAAJ&amp;hl=en&amp;oi=sra">WT Chu</a>, WH Tsai - Multimedia Tools and Applications, 2010 - Springer</div><div class="gs_rs">Abstract Evolution of spatial relationships between objects often provides important clues for <br>semantic video analysis. We present a symbolic representation that describes <br>spatiotemporal characteristics and facilitates tactics detection based on string matching. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2378158638378697674&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 3</a> <a href="/scholar?q=related:ysMWfK7qACEJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2378158638378697674&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'ysMWfK7qACEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4741053" class=yCF>Automatic overlaid text detection, extraction and recognition for high level event/concept identification in soccer videos</a></h3><div class="gs_a"><a href="/citations?user=vwlkEDEAAAAJ&amp;hl=en&amp;oi=sra">AA Halin</a>, <a href="/citations?user=3O9nAIoAAAAJ&amp;hl=en&amp;oi=sra">M Rajeswari</a>&hellip; - Computer and Electrical  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Overlaid text appears frequently in broadcast sports video. They provide <br>supplementary information regarding the happenings of a particular game. Examples <br>include important events of interest such as bookings and substitutions in a soccer match. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10077667440745390040&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 3</a> <a href="/scholar?q=related:2B8mwiQR24sJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10077667440745390040&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'2B8mwiQR24sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/8J73771071118870.pdf" class=yC10>A comprehensive study of visual event computing</a></h3><div class="gs_a">WQ Yan, DF Kieran, S Rafatirad, R Jain - Multimedia Tools and  &hellip;, 2011 - Springer</div><div class="gs_rs">Abstract This paper contains a survey on aspects of visual event computing. We start by <br>presenting events and their classifications, and continue with discussing the problem of <br>capturing events in terms of photographs, videos, etc, as well as the methodologies for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16788029034595160657&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 3</a> <a href="/scholar?q=related:URL9zXUP--gJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16788029034595160657&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'URL9zXUP--gJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4756060" class=yC11>A novel learning-based framework for detecting interesting events in soccer videos</a></h3><div class="gs_a">J Nisha, C Santanu, SD Roy&hellip; - &hellip;  Vision, Graphics &amp;  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We present a novel learning-based framework for detecting interesting events in <br>soccer videos. The input to the system is a raw soccer video. We have learning at three <br>levels-learning to detect interesting low-level features from image and video data using <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15951977666396352403&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 2</a> <a href="/scholar?q=related:k--EnivPYN0J:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15951977666396352403&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'k--EnivPYN0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://www.istudies.net/ojs/index.php/journal/article/viewFile/51/57" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from istudies.net</span><span class="gs_ggsS">istudies.net <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.istudies.net/ojs/index.php/journal/article/viewArticle/51" class=yC12>Automatic Segmentation, Aggregation and Indexing of Multimodal News Information from Television and the Internet</a></h3><div class="gs_a">M Montagnuolo, A Messina, R Borgotallo - International Journal of  &hellip;, 2010 - istudies.net</div><div class="gs_rs">Abstract The global diffusion of the Internet has enabled the distribution of informative <br>content through dynamic media such as RSS feeds and video blogs. At the same time, the <br>decreasing cost of electronic devices has increased the pervasive availability of the same <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18365464505895461101&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 2</a> <a href="/scholar?q=related:7aDx6Kk83_4J:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18365464505895461101&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'7aDx6Kk83_4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://essay.utwente.nl/660/1/scriptie_Poulisse.pdf" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from utwente.nl</span><span class="gs_ggsS">utwente.nl <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://essay.utwente.nl/660/" class=yC14>Exploiting inter-conceptual relationships to boost SVM classification</a></h3><div class="gs_a">GJ Poulisse - 2007 - essay.utwente.nl</div><div class="gs_rs">The initial aim of this research was to utilize the semantic relationships between some basic <br>concepts to develop a concept detector capable of recognizing an abstract concept like <br>&#39;happiness&#39; in a dataset. Such a detector proved infeasible, and the focus of this research <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12548831181130877816&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 1</a> <a href="/scholar?q=related:eMumAXlnJq4J:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12548831181130877816&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'eMumAXlnJq4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://doras.dcu.ie/16506/1/Video_Semantic_Content_Analysis_Framework_based_on_Ontology_Combined_MPEG-7.pdf" class=yC17><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from dcu.ie</span><span class="gs_ggsS">dcu.ie <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/MQ16T33541715411.pdf" class=yC16>Video semantic content analysis framework based on ontology combined MPEG-7</a></h3><div class="gs_a">L Bai, S Lao, W Zhang, <a href="/citations?user=YJuN_H8AAAAJ&amp;hl=en&amp;oi=sra">G Jones</a>, <a href="/citations?user=o7xnW2MAAAAJ&amp;hl=en&amp;oi=sra">A Smeaton</a> - &hellip;  Retrieval: Retrieval, User,  &hellip;, 2008 - Springer</div><div class="gs_rs">The rapid increase in the available amount of video data is creating a growing demand for <br>efficient methods for understanding and managing it at the semantic level. New multimedia <br>standard, MPEG-7, provides the rich functionalities to enable the generation of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12457946933426274553&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 1</a> <a href="/scholar?q=related:-UCKHbuE46wJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12457946933426274553&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'-UCKHbuE46wJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4627013" class=yC18>Overlaid Text Recognition for Matching Soccer-Concept Keywords</a></h3><div class="gs_a"><a href="/citations?user=vwlkEDEAAAAJ&amp;hl=en&amp;oi=sra">AA Halin</a>, <a href="/citations?user=3O9nAIoAAAAJ&amp;hl=en&amp;oi=sra">M Rajeswari</a>&hellip; - &hellip;  Graphics, Imaging and  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Overlaid-text appears frequently in broadcast sports video. They provide a plethora <br>of information regarding the goings-on of a particular game. Examples include important <br>events and video segments of interest such as bookings and half-time analysis, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2499805219977972465&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 1</a> <a href="/scholar?q=related:8Up0YJoXsSIJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2499805219977972465&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'8Up0YJoXsSIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://www.informatik.uni-marburg.de/~stadelmann/download/papers/CIVR_2007.pdf" class=yC1A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uni-marburg.de</span><span class="gs_ggsS">uni-marburg.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1282367" class=yC19>Semantic video analysis for psychological research on violence in computer games</a></h3><div class="gs_a">M MÃ¼hling, R Ewerth, T Stadelmann&hellip; - Proceedings of the 6th  &hellip;, 2007 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we present an automatic semantic video analysis system to support <br>interdisciplinary research efforts in the field of psychology and media science. The <br>psychological research question studied is whether and how playing violent content in <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8949048661017144478&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 1</a> <a href="/scholar?q=related:nqyc1VdoMXwJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8949048661017144478&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'nqyc1VdoMXwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://wwwconference.org/www2011/proceeding/companion/p123.pdf" class=yC1C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from wwwconference.org</span><span class="gs_ggsS">wwwconference.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1963255" class=yC1B>Harnessing the wisdom of crowds: video event detection based on synchronous comments</a></h3><div class="gs_a">X Shi, Z Yang, M Toyoda, M Kitsuregawa - Proceedings of the 20th  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract With the recent explosive growth of the number of videos on the Web, it becomes <br>more important to facilitate users&#39; demand for locating their preferred event clips in the <br>lengthy and voluminous programs. Although there has been a great deal of study on <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1988099124929726461&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 1</a> <a href="/scholar?q=related:_Yez554llxsJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1988099124929726461&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'_Yez554llxsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.google.com/patents?hl=en&amp;lr=&amp;vid=USPAT8166391&amp;id=87YNAgAAEBAJ&amp;oi=fnd&amp;printsec=abstract" class=yC1D>Template generating apparatus, image layout apparatus, modified template generating apparatus, and programs therefor</a></h3><div class="gs_a">Y Kaneko - US Patent 8,166,391, 2012 - Google Patents</div><div class="gs_rs">A template that can deal with images of various scenes is generated. Image area setting <br>means sets image areas wherein images are inserted in a layout area of a predetermined <br>size, and template file saving means saves information on the image areas laid out in the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3840600141613773755&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 1</a> <a href="/scholar?q=related:uzM0_XqNTDUJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3840600141613773755&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'uzM0_XqNTDUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ri"><h3 class="gs_rt"><a href="http://japanlinkcenter.org/JST.JSTAGE/itej/64.495?from=Google" class=yC1E>Sports Video Retrieval</a></h3><div class="gs_a">æ°ç°ç´å­ - æ åæå ±ã¡ãã£ã¢å­¦ä¼èª, 2010 - J-STAGE</div><div class="gs_rs">2.2 ã¹ãã¼ãã®è©¦åã®æ§é å¤ãã®ã¹ãã¼ãã¯ä¸ã¤ã®è©¦åãæ¨æ§é ã®ãããªå½¢ã§è¡¨ããã¨ãã§ãã. <br>ä¾ãã°éçã®è©¦åã¯, å³ 2 ã«ç¤ºãããã«, è©¦åå¨ä½ã¯è¤æ°ã®ã¤ãã³ã°ã«, åã¤ãã³ã°ã¯è¤æ°ã®æå¸­ã«<br>, åæå¸­ã¯è¤æ°ã®æçã«ããæ§æããã. ä»ã®ã¹ãã¼ãã§ã¯, ã¢ã¡ãªã«ã³ããããã¼ã«ãããã¹, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6909913213130671531&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 1</a> <a href="/scholar?q=related:q4VuAXXx5F8J:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6909913213130671531&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'q4VuAXXx5F8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB20" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW20"><a href="http://tosca-mp.eu/wp-content/uploads/2012/10/TOSCAMP-D3.1-v1.1.pdf" class=yC20><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tosca-mp.eu</span><span class="gs_ggsS">tosca-mp.eu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://tosca-mp.eu/wp-content/uploads/2012/10/TOSCAMP-D3.1-v1.1.pdf" class=yC1F>State of the art on semantic retrieval of AV content beyond text resources</a></h3><div class="gs_a"><a href="/citations?user=O9hYMUUAAAAJ&amp;hl=en&amp;oi=sra">MF Moens</a>, GJ Poulisse, MM VRT - 2012 - tosca-mp.eu</div><div class="gs_rs">1 Executive Summary This deliverable describes the state of the art in the area of semantic <br>retrieval of multimedia (audiovisual) content beyond text resources, ie, considering the <br>nature of the content to be retrieved. In this line, the characteristics of images, video and <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'KCcTKOqj1VYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md20', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md20" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:KCcTKOqj1VYJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6159070" class=yC21>Tagging Webcast Text in Baseball Videos by Video Segmentation and Text Alignment</a></h3><div class="gs_a">CY Chiu, PC Lin, SY Li, TH Tsai&hellip; - Circuits and Systems for  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Sports video annotation, an active research area in the field of multimedia content <br>understanding, is an essential process in applications, such as summarization, highlight <br>extraction, event detection, and retrieval. This paper considers the issue in relation to the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:x2OpLLmKPUwJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5493699648384754631&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'x2OpLLmKPUwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6328054" class=yC22>Multimodal and Multi-task Audio-Visual Vehicle Detection and Classification</a></h3><div class="gs_a">T Wang, <a href="/citations?user=2m-u_KoAAAAJ&amp;hl=en&amp;oi=sra">Z Zhu</a> - &hellip;  Video and Signal-Based Surveillance (AVSS), &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Moving vehicle detection and classification usingmultimodal data is a challenging <br>task in data collection, audio-visual alignment, and feature selection, andeffective vehicle <br>classification in uncontrolledenvironments. In this work, we first present a systematicway to <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'twFYg0c8baEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Noboru Babaguchi 2 and Naoko Nitta 2</h3><div class="gs_a">B Furht - Springer</div><div class="gs_fl"><a href="/scholar?q=related:NJ8Ks6vw5GUJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'NJ8Ks6vw5GUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB24" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW24"><a href="http://137.132.14.55/bitstream/handle/10635/23028/PhD%20Thesis%20-%20Pradeep%20Kumar%20Atrey%20-%202006.pdf?sequence=1" class=yC24><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.14.55</span><span class="gs_ggsS">137.132.14.55 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://137.132.14.55/handle/10635/23028" class=yC23>Information assimilation in Multimedia surveillance systems</a></h3><div class="gs_a"><a href="/citations?user=2s3sftgAAAAJ&amp;hl=en&amp;oi=sra">PK ATREY</a> - 2007 - 137.132.14.55</div><div class="gs_rs">Most multimedia surveillance systems nowadays utilize multiple types of sensors to detect <br>events of interest as and when they occur in the environment. However, due to the <br>asynchrony among and diversity of sensors, information assimilation, ie how to combine <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:qAMSwNgggb4J:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13727289254509413288&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'qAMSwNgggb4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB25" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW25"><a href="http://eprints.qut.edu.au/43479/1/WACV_266_(1).pdf" class=yC26><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from qut.edu.au</span><span class="gs_ggsS">qut.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5711541" class=yC25>Multi-modal summarization of key events and top players in sports tournament videos</a></h3><div class="gs_a"><a href="/citations?user=_OblDDgAAAAJ&amp;hl=en&amp;oi=sra">D Tjondronegoro</a>, X Tao, J Sasongko&hellip; - &hellip;  of Computer Vision ( &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract To detect and annotate the key events of live sports videos, we need to tackle the <br>semantic gaps of audio-visual information. Previous work has successfully extracted <br>semantic from the time-stamped web match reports, which are synchronized with the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8212095013843509179&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 1</a> <a href="/scholar?q=related:ux_m0ec493EJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8212095013843509179&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'ux_m0ec493EJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5973958" class=yC27>Skill and tactic analysis for table tennis matches</a></h3><div class="gs_a">Y Guan, Y Ye, J Li, J Si, H Zhang - Computer Science and  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Due to complexity, multiplicity and randomness of table tennis matches, it is <br>necessary to develop some skill and tactic diagnostic models especially an efficient scoring <br>model to get some skill and tactics data for table tennis matches. A scoring model is <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15716313696932382193&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=27">Cited by 1</a> <a href="/scholar?q=related:8cVC7AmQG9oJ:scholar.google.com/&amp;hl=en&amp;num=27&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'8cVC7AmQG9oJ')" href="#" class="gs_nph">Cite</a></div></div></div>
