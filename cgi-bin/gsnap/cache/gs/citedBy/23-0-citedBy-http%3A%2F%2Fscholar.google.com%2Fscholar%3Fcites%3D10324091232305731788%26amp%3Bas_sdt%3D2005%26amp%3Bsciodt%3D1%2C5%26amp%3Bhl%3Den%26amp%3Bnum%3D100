Total results = 23
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://cs.famaf.unc.edu.ar/~laura/llibres/wm.pdf.gz" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unc.edu.ar</span><span class="gs_ggsS">unc.edu.ar <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[BOOK]</span><span class="gs_ct2">[B]</span></span> <a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=6Mh50Uaq6AIC&amp;oi=fnd&amp;pg=PA1&amp;ots=Nvt_DNDlkj&amp;sig=u-8K0rpnKK2yhdFWcdPb6OujNQ4" class=yC0>Web data mining: exploring hyperlinks, contents, and usage data</a></h3><div class="gs_a"><a href="/citations?user=Kt1bjZoAAAAJ&amp;hl=en&amp;oi=sra">B Liu</a> - 2007 - books.google.com</div><div class="gs_rs">Web mining aims to discover useful information and knowledge from the Web hyperlink <br>structure, page contents, and usage data. Although Web mining uses many conventional <br>data mining techniques, it is not purely an application of traditional data mining due to the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3065834184951786639&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 715</a> <a href="/scholar?q=related:j-xMnvIHjCoJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3065834184951786639&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 27 versions</a> <a onclick="return gs_ocit(event,'j-xMnvIHjCoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md0', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md0" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:j-xMnvIHjCoJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=5530795097813886832&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://users.csc.tntech.edu/~weberle/Fall2008/CSC6910/Papers/posonly.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tntech.edu</span><span class="gs_ggsS">tntech.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1401920" class=yC2>Learning classifiers from only positive and unlabeled data</a></h3><div class="gs_a"><a href="/citations?user=im5aMngAAAAJ&amp;hl=en&amp;oi=sra">C Elkan</a>, K Noto - Proceeding of the 14th ACM SIGKDD international  &hellip;, 2008 - dl.acm.org</div><div class="gs_rs">Abstract The input to an algorithm that learns a binary classifier normally consists of two sets <br>of examples, where one set consists of positive examples of the concept to be learned, and <br>the other set consists of negative examples. However, it is often the case that the available <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6181348327120722288&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 89</a> <a href="/scholar?q=related:cFn8po2PyFUJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6181348327120722288&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 19 versions</a> <a onclick="return gs_ocit(event,'cFn8po2PyFUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4554167" class=yC4>Learning from positive and unlabeled examples: A survey</a></h3><div class="gs_a">B Zhang, W Zuo - Information Processing (ISIP), 2008  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper surveys the existing method of learning from positive and unlabeled <br>examples. We divide the existing methods into three families, and review the main <br>algorithms, respectively. The first Family of methods takes a two-step strategy, extracting <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12934406435340607941&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 16</a> <a href="/scholar?q=related:xeEAnx8-gLMJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12934406435340607941&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'xeEAnx8-gLMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://eprints.pascal-network.org/archive/00004475/01/scott09a.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from pascal-network.org</span><span class="gs_ggsS">pascal-network.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://eprints.pascal-network.org/archive/00004475/" class=yC5>Novelty detection: Unlabeled data definitely help</a></h3><div class="gs_a">C Scott, <a href="/citations?user=FOkAbQgAAAAJ&amp;hl=en&amp;oi=sra">G Blanchard</a> - 2009 - eprints.pascal-network.org</div><div class="gs_rs">Abstract In machine learning, one formulation of the novelty detection problem is to build a <br>detector based on a training sample consisting only on nominal data. The standard <br>(inductive) approach to this problem has been to declare novelties where the nominal <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5415830074552181179&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 12</a> <a href="/scholar?q=related:u2GPLcLkKEsJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5415830074552181179&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'u2GPLcLkKEsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://eprints.pascal-network.org/archive/00005893/02/blanchard10a.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from pascal-network.org</span><span class="gs_ggsS">pascal-network.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1953028" class=yC7>Semi-supervised novelty detection</a></h3><div class="gs_a"><a href="/citations?user=FOkAbQgAAAAJ&amp;hl=en&amp;oi=sra">G Blanchard</a>, G Lee, C Scott - The Journal of Machine Learning  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract A common setting for novelty detection assumes that labeled examples from the <br>nominal class are available, but that labeled examples of novelties are unavailable. The <br>standard (inductive) approach is to declare novelties where the nominal density is low, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6213055140349029744&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 16</a> <a href="/scholar?q=related:cC1rYrs0OVYJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6213055140349029744&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'cC1rYrs0OVYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md4', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md4" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:cC1rYrs0OVYJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=11739643663143622857&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://people.cs.vt.edu/~sanmay/papers/tcbb09.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from vt.edu</span><span class="gs_ggsS">vt.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5374367" class=yC9>Identifying relevant data for a biological database: Handcrafted rules versus machine learning</a></h3><div class="gs_a">AK Sehgal, S Das, K Noto, MK Saier&hellip; - &hellip; IEEE/ACM Transactions &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract With well over 1,000 specialized biological databases in use today, the task of <br>automatically identifying novel, relevant data for such databases is increasingly important. In <br>this paper, we describe practical machine learning approaches for identifying MEDLINE <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7944567868108659820&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 6</a> <a href="/scholar?q=related:bFyZSGLGQG4J:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7944567868108659820&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 17 versions</a> <a onclick="return gs_ocit(event,'bFyZSGLGQG4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://marco.pi.titech.ac.jp/~kong/mypaper/sriphaew09cool.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from titech.ac.jp</span><span class="gs_ggsS">titech.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/03M4V1M5631446M6.pdf" class=yCB>Cool blog classification from positive and unlabeled examples</a></h3><div class="gs_a">K Sriphaew, H Takamura, M Okumura - Advances in Knowledge Discovery &hellip;, 2009 - Springer</div><div class="gs_rs">Abstract. We address the problem of cool blog classification using only positive and <br>unlabeled examples. We propose an algorithm, called PUB, that exploits the information of <br>unlabeled data together with the positive examples to predict whether the unseen blogs <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15434972475341362738&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 3</a> <a href="/scholar?q=related:MlanNrAJNNYJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15434972475341362738&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'MlanNrAJNNYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://www.sc.ehu.es/ccwbayes/isg/administrator/components/com_jresearch/files/theses/borja.calvo.phd.dissertation.2008.pdf" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ehu.es</span><span class="gs_ggsS">ehu.es <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.sc.ehu.es/ccwbayes/isg/administrator/components/com_jresearch/files/theses/borja.calvo.phd.dissertation.2008.pdf" class=yCD>Positive unlabelled learning with applications in computational biology</a></h3><div class="gs_a">B Calvo - 2008 - sc.ehu.es</div><div class="gs_rs">Summary With the increasing amount of stored information, the use of data mining <br>techniques to extract useful knowledge from them has become a key issue in many <br>domains. Classifier induction algorithms are useful tools for this purpose as they allow us <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15520150911433506707&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 3</a> <a href="/scholar?q=related:k_9yUAanYtcJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15520150911433506707&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'k_9yUAanYtcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md7', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md7" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:k_9yUAanYtcJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a>  <a href="/scholar?q=info:k_9yUAanYtcJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=1204611380269982216&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://www.cs.sfu.ca/~ester/papers/WAIM-2010.UnlabeledData.final.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from sfu.ca</span><span class="gs_ggsS">sfu.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/U35H1368504L78V0.pdf" class=yCF>Semi-supervised learning from only positive and unlabeled data using entropy</a></h3><div class="gs_a">X Wang, Z Xu, C Sha, M Ester, A Zhou - Web-Age Information Management, 2010 - Springer</div><div class="gs_rs">The problem of classification from positive and unlabeled examples attracts much attention <br>currently. However, when the number of unlabeled negative examples is very small, the <br>effectiveness of former work has been decreased. This paper propose an effective <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15963085483643568529&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 3</a> <a href="/scholar?q=related:kQHF26tFiN0J:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15963085483643568529&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'kQHF26tFiN0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.152.4289&amp;rep=rep1&amp;type=pdf" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.152.4289&amp;rep=rep1&amp;type=pdf" class=yC11>Transductive anomaly detection</a></h3><div class="gs_a">C Scott, <a href="/citations?user=FOkAbQgAAAAJ&amp;hl=en&amp;oi=sra">G Blanchard</a> - 2008 - Citeseer</div><div class="gs_rs">Abstract One formulation of the anomaly detection problem is to build a detector based on a <br>training sample consisting only on nominal data. The standard approach to this problem has <br>been to declare anomalies where the nominal density is low, which reduces the problem <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16588085755813494875&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 1</a> <a href="/scholar?q=related:WwD7ghu4NOYJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16588085755813494875&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'WwD7ghu4NOYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md9', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md9" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:WwD7ghu4NOYJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://www.dcs.bbk.ac.uk/~DELL/publications/dellzhang_jdim2009.pdf" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from bbk.ac.uk</span><span class="gs_ggsS">bbk.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.dcs.bbk.ac.uk/~DELL/publications/dellzhang_jdim2009.pdf" class=yC13>Query-By-Multiple-Examples using Support Vector Machines</a></h3><div class="gs_a">D Zhang, <a href="/citations?user=8PCrLgwAAAAJ&amp;hl=en&amp;oi=sra">WS Lee</a> - Journal of Digital Information Management, 2009 - dcs.bbk.ac.uk</div><div class="gs_rs">ABSTRACT: We identify and explore an Information Retrieval paradigm called Query-By-<br>Multiple-Examples (QBME) where the information need is described not by a set of terms but <br>by a set of documents. Intuitive ideas for QBME include using the centroid of these <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11728149529685398098&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 1</a> <a href="/scholar?q=related:UhKQ3dvBwqIJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11728149529685398098&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'UhKQ3dvBwqIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md10', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md10" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:UhKQ3dvBwqIJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://www.dcs.bbk.ac.uk/~DELL/publications/dellzhang_icdim2008a.pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from bbk.ac.uk</span><span class="gs_ggsS">bbk.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4746761" class=yC15>Learning classifiers without negative examples: A reduction approach</a></h3><div class="gs_a">D Zhang, <a href="/citations?user=8PCrLgwAAAAJ&amp;hl=en&amp;oi=sra">WS Lee</a> - Digital Information Management, 2008.  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The problem of PU Learning, ie, learning classifiers with positive and unlabelled <br>examples (but not negative examples), is very important in information retrieval and data <br>mining. We address this problem through a novel approach: reducing it to the problem of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18389703398840834102&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=23">Cited by 3</a> <a href="/scholar?q=related:Npiz9M5ZNf8J:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18389703398840834102&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'Npiz9M5ZNf8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/PW15014TRH88TXH5.pdf" class=yC17>Partially Supervised Learning</a></h3><div class="gs_a">B Liu, <a href="/citations?user=8PCrLgwAAAAJ&amp;hl=en&amp;oi=sra">WS Lee</a> - Web Data Mining, 2011 - Springer</div><div class="gs_rs">In supervised learning, the learning algorithm uses labeled training examples from every <br>class to generate a classification function. One of the drawbacks of this classic paradigm is <br>that a large number of labeled examples are needed in order to learn accurately. Since <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:s5lCEXPGlAYJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'s5lCEXPGlAYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/X431U57305487237.pdf" class=yC18>Positive unlabeled learning for deriving protein interaction networks</a></h3><div class="gs_a">C KÄ±lÄ±Ã§, <a href="/citations?user=Ztz_N_gAAAAJ&amp;hl=en&amp;oi=sra">M Tan</a> - Network Modeling and Analysis in Health Informatics  &hellip;, 2012 - Springer</div><div class="gs_rs">Abstract Binary classification is the process of labeling the members of a given data set on <br>the basis of whether they have some property or not. To train a binary classifier, normally <br>one needs two sets of examples from each group, usually named as positive and negative <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:qYroKPkpeYMJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9473649441260473001&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'qYroKPkpeYMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://www.wias-berlin.de/preprint/1471/wias_preprints_1471.pdf" class=yC1A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from wias-berlin.de</span><span class="gs_ggsS">wias-berlin.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.wias-berlin.de/preprint/1471/wias_preprints_1471.pdf" class=yC19>WeierstraÃ-Institut</a></h3><div class="gs_a"><a href="/citations?user=FOkAbQgAAAAJ&amp;hl=en&amp;oi=sra">G Blanchard</a>, G Lee, C Scott - wias-berlin.de</div><div class="gs_rs">Abstract A common setting for novelty detection assumes that labeled examples from the <br>nominal class are available, but that labeled examples of novelties are unavailable. The <br>standard (inductive) approach is to declare novelties where the nominal density is low, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:-Ir4VzNrw8wJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14754754672459287288&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'-Ir4VzNrw8wJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md14', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md14" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:-Ir4VzNrw8wJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/7P6887M30R9G8L41.pdf" class=yC1B>Estimate Unlabeled-Data-Distribution for Semi-supervised PU Learning</a></h3><div class="gs_a">H Hu, C Sha, X Wang, A Zhou - Web Technologies and Applications, 2012 - Springer</div><div class="gs_rs">Traditional supervised classifiers use only labeled data (features/label pairs) as the training <br>set, while the unlabeled data is used as the testing set. In practice, it is often the case that the <br>labeled data is hard to obtain and the unlabeled data contains the instances that belong to <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:jwn7eb6enlYJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6241600674509556111&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'jwn7eb6enlYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><a href="http://mesharpe.metapress.com/index/4012260568301135.pdf" class=yC1C>Automatic Moderation of Online Discussion Sites</a></h3><div class="gs_a">JY Delort, B Arunasalam, <a href="/citations?user=KFordDAAAAAJ&amp;hl=en&amp;oi=sra">C Paris</a> - International Journal of Electronic  &hellip;, 2011 - ME Sharpe</div><div class="gs_rs">Online discussion sites are plagued with various types of unwanted content, such as spam <br>and obscene or malicious messages. Prevention and detection-based techniques have <br>been proposed to filter inappropriate content from online discussion sites. But, even <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:wV7afUmLs3oJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8841563641218752193&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'wV7afUmLs3oJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://jmlr.csail.mit.edu/proceedings/papers/v25/zhou12/zhou12.pdf" class=yC1E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://jmlr.csail.mit.edu/proceedings/papers/v25/zhou12/zhou12.pdf" class=yC1D>Multi-view Positive and Unlabeled Learning</a></h3><div class="gs_a">JT Zhou, <a href="/citations?user=P6WcnfkAAAAJ&amp;hl=en&amp;oi=sra">SJ Pan</a>, Q Mao, <a href="/citations?user=rJMOlVsAAAAJ&amp;hl=en&amp;oi=sra">IW Tsang</a> - jmlr.csail.mit.edu</div><div class="gs_rs">Abstract Learning with Positive and Unlabeled instances (PU learning) arises widely in <br>information retrieval applications. To address the unavailability issue of negative instances, <br>most existing PU learning approaches require to either identify a reliable set of negative <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'rv4On-krM6QJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md17', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md17" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:rv4On-krM6QJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Query-By-Multiple-Examples in Text Databases via Learning with Support Vector Machines</h3><div class="gs_a">D Zhang, WS Lee</div><div class="gs_fl"><a href="/scholar?q=related:-OVWoWqS99AJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'-OVWoWqS99AJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.tandfonline.com/doi/abs/10.1080/00207721.2011.627475" class=yC1F>Learning naive Bayes classifiers from positive and unlabelled examples with uncertainty</a></h3><div class="gs_a">J He, Y Zhang, X Li, <a href="/citations?user=EGx1iH0AAAAJ&amp;hl=en&amp;oi=sra">P Shi</a> - International Journal of Systems  &hellip;, 2012 - Taylor &amp; Francis</div><div class="gs_rs">Traditional classification algorithms require a large number of labelled examples from all the <br>predefined classes, which is generally difficult and time-consuming to obtain. Furthermore, <br>data uncertainty is prevalent in many real-world applications, such as sensor network, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:_E99sZ-WZycJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'_E99sZ-WZycJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/32m8kl75182h5hmp.pdf" class=yC20>Wrapper positive Bayesian network classifiers</a></h3><div class="gs_a">B Calvo, <a href="/citations?user=ogYjUPAAAAAJ&amp;hl=en&amp;oi=sra">I Inza</a>, <a href="/citations?user=9zrv6BMAAAAJ&amp;hl=en&amp;oi=sra">P LarraÃ±aga</a>, JA Lozano - Knowledge and Information  &hellip;, 2012 - Springer</div><div class="gs_rs">Abstract In the information retrieval framework, there are problems where the goal is to <br>recover objects of a particular class from big sets of unlabelled objects. In some of these <br>problems, only examples from the class we want to recover are available. For such <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:-r2RvjjH3coJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14618059012043816442&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'-r2RvjjH3coJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/UV22220532672172.pdf" class=yC21>Bayesian classifiers for positive unlabeled learning</a></h3><div class="gs_a">J He, Y Zhang, X Li, Y Wang - Web-Age Information Management, 2011 - Springer</div><div class="gs_rs">This paper studies the problem of Positive Unlabeled learning (PU learning), where positive <br>and unlabeled examples are used for training. Naive Bayes (NB) and Tree Augmented <br>Naive Bayes (TAN) have been extended to PU learning algorithms (PNB and PTAN). <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:UAmz7QKl2AoJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=781555967345232208&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'UAmz7QKl2AoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB22" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW22"><a href="http://www.di.unipi.it/~aorlandi/pdf/tesi-mag.pdf" class=yC23><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unipi.it</span><span class="gs_ggsS">unipi.it <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.di.unipi.it/~aorlandi/pdf/tesi-mag.pdf" class=yC22>METODI PER LA PERSONALIZZAZIONE DEL WEB CRAWLING</a></h3><div class="gs_a"><a href="/citations?user=gxWk5wYAAAAJ&amp;hl=en&amp;oi=sra">A ORLANDI</a> - di.unipi.it</div><div class="gs_rs">La crescente mole di informazione sparsa in rete e la conseguente necessitÃ  di creare dei <br>punti di accesso centrali alla stessa hanno spinto la comunitÃ  scientifica e le aziende ad <br>interessarsi ai motori di ricerca, oggi diventati ormai strumento di uso comune per ogni <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:waIYhy4BwBMJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'waIYhy4BwBMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md22', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md22" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:waIYhy4BwBMJ:scholar.google.com/&amp;hl=en&amp;num=23&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
