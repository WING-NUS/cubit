Total results = 10
<div class="gs_r" style="z-index:400"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397597000182" class=yC0>Noisy inference and oracles</a></h3><div class="gs_a">F Stephan - Theoretical Computer Science, 1997 - Elsevier</div><div class="gs_rs">The present paper deals with several variants of inductive inference from noisy data. The <br>notion of noise is based on the idea that the learner recieves a sequence of data elements <br>such that each correct element appears infinitely often and each incorrect element <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12324907220817005336&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 22</a> <a href="/scholar?q=related:GMtxMtHdCqsJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12324907220817005336&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'GMtxMtHdCqsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/F7357P1580T1575G.pdf" class=yC1>Noisy inference and oracles</a></h3><div class="gs_a">F Stephan - Algorithmic Learning Theory, 1995 - Springer</div><div class="gs_rs">A learner noisily infers a function or set, if every correct item is presented infinitely often <br>while in addition some incorrect data (noise) is presented a finite number of times. It is <br>shown that learning from a noisy informant is equal to finite learning with K-oracle from a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7409414712334555572&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 13</a> <a href="/scholar?q=related:tBlBkmyH02YJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/15/01/EN031725641.html?source=googlescholar" class="gs_nph" class=yC2>BL Direct</a> <a href="/scholar?cluster=7409414712334555572&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'tBlBkmyH02YJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www.comp.nus.edu.sg/~sanjay/paps/mulj.pdf" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/Y883313L70NM1731.pdf" class=yC3>Learning from multiple sources of inaccurate data</a></h3><div class="gs_a">G Baliga, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, A Sharma - Analogical and Inductive Inference, 1992 - Springer</div><div class="gs_rs">Most theoretical studies of inductive inference model a situation involving a machine M <br>learning its environment E on following lines. M, placed in E, receives data about E, and <br>simultaneously conjectures a sequence of hypotheses. M is said to learn E just in case the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14964936246632640499&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 8</a> <a href="/scholar?q=related:8-_nijoirs8J:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/19/2F/EN000326148.html?source=googlescholar" class="gs_nph" class=yC5>BL Direct</a> <a href="/scholar?cluster=14964936246632640499&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'8-_nijoirs8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.33.5664&amp;rep=rep1&amp;type=pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> A survey of inductive inference with an emphasis on queries</h3><div class="gs_a">W Gasarch, CH Smith - LECTURE NOTES IN PURE AND  &hellip;, 1997 - MARCEL DEKKER AG</div><div class="gs_fl"><a href="/scholar?cites=18265723380539879962&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 7</a> <a href="/scholar?q=related:GnKgfqPifP0J:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/42/0B/RN022346246.html?source=googlescholar" class="gs_nph" class=yC7>BL Direct</a> <a href="/scholar?cluster=18265723380539879962&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'GnKgfqPifP0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/F7Q6184682RG6200.pdf" class=yC8>On the strength of incremental learning</a></h3><div class="gs_a">S Lange, G Grieser - Algorithmic Learning Theory, 1999 - Springer</div><div class="gs_rs">This paper provides a systematic study of incremental learning from noise-free and from <br>noisy data, thereby distinguishing between learning from only positive data and from both <br>positive and negative data. Our study relies on the notion of noisy data introduced in [22]. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11071798720267559072&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 7</a> <a href="/scholar?q=related:oCAsckbuppkJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11071798720267559072&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'oCAsckbuppkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://epubs.siam.org/doi/pdf/10.1137/S0097539792239461" class=yC9>Learning from multiple sources of inaccurate data</a></h3><div class="gs_a">G Baliga, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, A Sharma - SIAM Journal on Computing, 1997 - SIAM</div><div class="gs_rs">Most theoretical models of inductive inference make the idealized assumption that the data <br>available to a learner is from a single and accurate source. The subject of inaccuracies in <br>data emanating from a single source has been addressed by several authors. The present <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7776508045410810585&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 6</a> <a href="/scholar?q=related:2bqtl92062sJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/39/1B/RN030135738.html?source=googlescholar" class="gs_nph" class=yCA>BL Direct</a> <a href="/scholar?cluster=7776508045410810585&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'2bqtl92062sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/mbhav1ap8ga0pu01.pdf" class=yCB>Language learning with a neighbor system</a></h3><div class="gs_a">Y Mukouchi, M Sato - Discovery Science, 2000 - Springer</div><div class="gs_rs">We consider inductive language learning from positive examples, some of which may be <br>incorrect. In the present paper, the error or incorrectness we consider is the one described <br>uniformly in terms of a distance over strings. Firstly, we introduce a notion of a recursively <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11152172449248372592&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 4</a> <a href="/scholar?q=related:cOdYf8F5xJoJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/36/5A/RN087987980.html?source=googlescholar" class="gs_nph" class=yCC>BL Direct</a> <a href="/scholar?cluster=11152172449248372592&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'cOdYf8F5xJoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.5444&amp;rep=rep1&amp;type=pdf" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.5444&amp;rep=rep1&amp;type=pdf" class=yCD>Iterative concept learning from noisy data</a></h3><div class="gs_a">S en Lange, G Grieser - Citeseer</div><div class="gs_rs">Abstract In the present paper, we study iterative learning of indexable concept classes from <br>noisy data. We distinguish between learning from positive data only and learning from <br>positive and negative data; synonymously, learning from text and informant, respectively. <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:hovRSwK6TgMJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=238332349321939846&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'hovRSwK6TgMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md7', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md7" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:hovRSwK6TgMJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/5RDJV0QCC3FKK17K.pdf" class=yCF>Refutable/inductive learning from neighbor examples and its application to decision trees over patterns</a></h3><div class="gs_a">M Sato, Y Mukouchi, M Terada - Progress in Discovery Science, 2002 - Springer</div><div class="gs_rs">The paper develops the theory of refutable/inductive learning as a foundation of discovery <br>science from examples. We consider refutable/inductive language learning from positive <br>examples, some of which may be incorrect. The error or incorrectness we consider is the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:zWgPdk1OTTQJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/3B/27/RN111502857.html?source=googlescholar" class="gs_nph" class=yC10>BL Direct</a> <a href="/scholar?cluster=3768754557779142861&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'zWgPdk1OTTQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.6756&amp;rep=rep1&amp;type=pdf" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.6756&amp;rep=rep1&amp;type=pdf" class=yC11>On the strength of incremental learning</a></h3><div class="gs_a">S en Lange, G Grieser - Citeseer</div><div class="gs_rs">Abstract. This paper provides a systematic study of incremental learning from noise-free and <br>from noisy data, thereby distinguishing between learning from only positive data and from <br>both positive and negative data. Our study relies on the notion of noisy data introduced in <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:wMdDg89ZrbwJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13595621597896755136&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'wMdDg89ZrbwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md9', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md9" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:wMdDg89ZrbwJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
