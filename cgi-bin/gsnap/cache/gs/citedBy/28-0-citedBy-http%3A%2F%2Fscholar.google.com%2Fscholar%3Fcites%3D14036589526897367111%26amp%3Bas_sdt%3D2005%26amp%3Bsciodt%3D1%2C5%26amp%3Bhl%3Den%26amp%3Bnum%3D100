Total results = 28
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://jjtok.io/papers/JNRSAS-2004.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from jjtok.io</span><span class="gs_ggsS">jjtok.io <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://jjtok.io/papers/JNRSAS-2004.pdf" class=yC0>Improving timbre similarity: How high is the sky?</a></h3><div class="gs_a"><a href="/citations?user=rMvx0LYAAAAJ&amp;hl=en&amp;oi=sra">F Pachet</a>, <a href="/citations?user=jnST06UAAAAJ&amp;hl=en&amp;oi=sra">JJ Aucouturier</a> - Journal of negative results in speech and audio  &hellip;, 2004 - jjtok.io</div><div class="gs_rs">AbstractâWe report on experiments done in an attempt to improve the performance of a <br>music similarity measure which we introduced in [2]. The technique aims at comparing music <br>titles on the basis of their global âtimbreâ, which has many applications in the field of Music <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8572439498205260541&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 285</a> <a href="/scholar?q=related:_WoNDU5s93YJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8572439498205260541&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'_WoNDU5s93YJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md0', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md0" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:_WoNDU5s93YJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="ftp://ftp.cse.ohio-state.edu/pub/tech-report/2005/TR61.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ohio-state.edu</span><span class="gs_ggsS">ohio-state.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4156205" class=yC2>Separation of singing voice from music accompaniment for monaural recordings</a></h3><div class="gs_a"><a href="/citations?user=OCQSEIsAAAAJ&amp;hl=en&amp;oi=sra">Y Li</a>, <a href="/citations?user=yO59sggAAAAJ&amp;hl=en&amp;oi=sra">DL Wang</a> - Audio, Speech, and Language Processing,  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Separating singing voice from music accompaniment is very useful in many <br>applications, such as lyrics recognition and alignment, singer identification, and music <br>information retrieval. Although speech separation has been extensively studied for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16877915460734066236&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 74</a> <a href="/scholar?q=related:PJ4gQrBmOuoJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/03/1B/RN211148698.html?source=googlescholar" class="gs_nph" class=yC4>BL Direct</a> <a href="/scholar?cluster=16877915460734066236&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'PJ4gQrBmOuoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www.ee.columbia.edu/~dpwe/ismir2004/CRFILES/paper183.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from columbia.edu</span><span class="gs_ggsS">columbia.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ee.columbia.edu/~dpwe/ismir2004/CRFILES/paper183.pdf" class=yC5>Automatic detection of vocal segments in popular songs</a></h3><div class="gs_a">TL Nwe, Y Wang - Proc. ISMIR, 2004 - ee.columbia.edu</div><div class="gs_rs">ABSTRACT This paper presents a technique for the automatic classification of vocal and <br>non-vocal regions in an acoustic musical signal. The proposed technique uses acoustic <br>features which are suitable to distinguish vocal and non-vocal signals. We employ the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1029789852324898212&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 38</a> <a href="/scholar?q=related:pKUgJWqMSg4J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1029789852324898212&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 24 versions</a> <a onclick="return gs_ocit(event,'pKUgJWqMSg4J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md2', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md2" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:pKUgJWqMSg4J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.139.5510&amp;rep=rep1&amp;type=pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.139.5510&amp;rep=rep1&amp;type=pdf" class=yC7>Separation of vocals from polyphonic audio recordings</a></h3><div class="gs_a"><a href="/citations?user=CSujHJ0AAAAJ&amp;hl=en&amp;oi=sra">S Vembu</a>, S Baumann - Proc. ISMIR, 2005 - Citeseer</div><div class="gs_rs">ABSTRACT Source separation techniques like independent component analysis and the <br>more recent non-negative matrix factorization are gaining widespread use for the monaural <br>separation of individual tracks present in a music sample. The underlying principle behind <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16995744993622094260&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 39</a> <a href="/scholar?q=related:tPH3PQYE3esJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16995744993622094260&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'tPH3PQYE3esJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md3', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md3" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:tPH3PQYE3esJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://www.comp.nus.edu.sg/~mohan/papers/music_struct_det.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1580435" class=yC9>Automatic structure detection for popular music</a></h3><div class="gs_a">NC Maddage - Multimedia, IEEE, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Our proposed approach detects music structures by looking at beat-space <br>segmentation, chords, singing-voice boundaries, and melody-and content-based similarity <br>regions. Experiments illustrate that the proposed approach is capable of extracting useful <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7556639789070752933&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 36</a> <a href="/scholar?q=related:pRwl89mT3mgJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/3D/1C/RN183745851.html?source=googlescholar" class="gs_nph" class=yCB>BL Direct</a> <a href="/scholar?cluster=7556639789070752933&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'pRwl89mT3mgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://www.comp.nus.edu.sg/~wangye/papers/1.Audio_and_Music_Analysis_and_Retrieval/2004_Singing_Voice_Detection_in_Popular_Music.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1027602" class=yCC>Singing voice detection in popular music</a></h3><div class="gs_a">TL Nwe, A Shenoy, Y Wang - Proceedings of the 12th annual ACM  &hellip;, 2004 - dl.acm.org</div><div class="gs_rs">Abstract We propose a novel technique for the automatic classification of vocal and non-<br>vocal regions in an acoustic musical signal. Our technique uses a combination of harmonic <br>content attenuation using higher level musical knowledge of key followed by sub-band <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3838002631248715374&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 34</a> <a href="/scholar?q=related:bh6Y-g5TQzUJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3838002631248715374&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 22 versions</a> <a onclick="return gs_ocit(event,'bh6Y-g5TQzUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5153305" class=yCE>On the improvement of singing voice separation for monaural recordings using the MIR-1K dataset</a></h3><div class="gs_a">CL Hsu, <a href="/citations?user=xPAxmk0AAAAJ&amp;hl=en&amp;oi=sra">JSR Jang</a> - Audio, Speech, and Language Processing, &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Monaural singing voice separation is an extremely challenging problem. While <br>efforts in pitch-based inference methods have led to considerable progress in voiced singing <br>voice separation, little attention has been paid to the incapability of such methods to <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8143162252476140354&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 32</a> <a href="/scholar?q=related:Qss1n-xSAnEJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8143162252476140354&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'Qss1n-xSAnEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://ohm.fing.edu.uy/publicaciones/2007/RH07/RH07.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from fing.edu.uy</span><span class="gs_ggsS">fing.edu.uy <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://ohm.fing.edu.uy/publicaciones/2007/RH07/RH07.pdf" class=yCF>Comparing audio descriptors for singing voice detection in music audio files</a></h3><div class="gs_a">M Rocamora, <a href="/citations?user=x4X0Ia8AAAAJ&amp;hl=en&amp;oi=sra">P Herrera</a> - &hellip;  on Computer Music, 11th. San Pablo,  &hellip;, 2007 - ohm.fing.edu.uy</div><div class="gs_rs">Abstract. Given the relevance of the singing voice in popular western music, a system able to <br>reliable identify those portions of a music audio file containing vocals would be very useful. <br>In this work, we explore already used descriptors to perform this task and compare the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4597348268454176119&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 23</a> <a href="/scholar?q=related:d-X3ceQPzT8J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4597348268454176119&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'d-X3ceQPzT8J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md7', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md7" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:d-X3ceQPzT8J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://www.mdpi.com/1999-4893/2/3/907/pdf" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mdpi.com</span><span class="gs_ggsS">mdpi.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.mdpi.com/1999-4893/2/3/907" class=yC11>Classification of echolocation calls from 14 species of bat by support vector machines and ensembles of neural networks</a></h3><div class="gs_a">RD Redgwell, JM Szewczak, <a href="/citations?user=26tnVuUAAAAJ&amp;hl=en&amp;oi=sra">G Jones</a>, S Parsons - Algorithms, 2009 - mdpi.com</div><div class="gs_rs">Abstract: Calls from 14 species of bat were classified to genus and species using <br>discriminant function analysis (DFA), support vector machines (SVM) and ensembles of <br>neural networks (ENN). Both SVMs and ENNs outperformed DFA for every species while <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15712656319005042460&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 12</a> <a href="/scholar?q=related:HKcXRKyRDtoJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15712656319005042460&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'HKcXRKyRDtoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/FF2RACE6AEM0G0TJ.pdf" class=yC13>Semantic region detection in acoustic music signals</a></h3><div class="gs_a">N Maddage, C Xu, A Shenoy, Y Wang - Advances in Multimedia  &hellip;, 2005 - Springer</div><div class="gs_rs">We propose a novel approach to detect semantic regions (pure vocals, pure instrumental <br>and instrumental mixed vocals) in acoustic music signals. The acoustic music signal is first <br>segmented at the beat level based on our proposed rhythm tracking algorithm. Then for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12750419578840592374&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 5</a> <a href="/scholar?q=related:9q_6ZQ2X8rAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/16/07/RN160207046.html?source=googlescholar" class="gs_nph" class=yC14>BL Direct</a> <a href="/scholar?cluster=12750419578840592374&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'9q_6ZQ2X8rAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://ismir2009.ismir.net/proceedings/PS4-22.pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ismir.net</span><span class="gs_ggsS">ismir.net <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://ismir2009.ismir.net/proceedings/PS4-22.pdf" class=yC15>An integrated approach to music boundary detection</a></h3><div class="gs_a">MY Su, <a href="/citations?user=OL-XGxcAAAAJ&amp;hl=en&amp;oi=sra">YH Yang</a>, YC Lin&hellip; - Proceedings of the 10th  &hellip;, 2009 - ismir2009.ismir.net</div><div class="gs_rs">ABSTRACT Music boundary detection is a fundamental step of music analysis and <br>summarization. Existing works use either unsupervised or supervised methodologies to <br>detect boundary. In this paper, we propose an integrated approach that takes advantage <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15104889617882105971&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 5</a> <a href="/scholar?q=related:c0hZDRRZn9EJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15104889617882105971&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'c0hZDRRZn9EJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md10', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md10" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:c0hZDRRZn9EJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://www.ee.iitb.ac.in/daplab/publications/international-conference/papers/VRPR_ICSLP09.pdf" class=yC17><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from iitb.ac.in</span><span class="gs_ggsS">iitb.ac.in <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Singing voice detection in polyphonic music using predominant pitch</h3><div class="gs_a">V Rao, S Ramakrishnan, P Rao - Proc. InterSpeech 2009, 2009</div><div class="gs_fl"><a href="/scholar?cites=15789716467748213682&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 5</a> <a href="/scholar?q=related:spNETHhXINsJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15789716467748213682&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'spNETHhXINsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://www.ee.iitb.ac.in/web/files/publications/RaoPS2008.pdf" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from iitb.ac.in</span><span class="gs_ggsS">iitb.ac.in <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ee.iitb.ac.in/web/files/publications/RaoPS2008.pdf" class=yC18>Singing voice detection in north indian classical music</a></h3><div class="gs_a">V Rao, S Ramakrishnan, P Rao - Proc. of the National Conference on  &hellip;, 2008 - ee.iitb.ac.in</div><div class="gs_rs">AbstractâSinging voice detection is essential for content-based applications such as those <br>involving melody extraction and singer identification. This article is concerned with the <br>accurate detection of singing voice phrases in north Indian classical vocal music. The <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16148304997457824986&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 3</a> <a href="/scholar?q=related:2owjetZNGuAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16148304997457824986&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'2owjetZNGuAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md12', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md12" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:2owjetZNGuAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://www.ee.iitb.ac.in/daplab/publications/international-conference/papers/PR_InvitedPaper_ncsipa09.pdf" class=yC1B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from iitb.ac.in</span><span class="gs_ggsS">iitb.ac.in <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ee.iitb.ac.in/daplab/publications/international-conference/papers/PR_InvitedPaper_ncsipa09.pdf" class=yC1A>Musical information extraction from the singing voice</a></h3><div class="gs_a">P Rao - Proc. National Conf. Signal &amp; Image Process, 2009 - ee.iitb.ac.in</div><div class="gs_rs">Abstract Music information retrieval is currently an active research area that addresses the <br>extraction of musically important information from audio signals, and the applications of such <br>information. The extracted information can be used for search and retrieval of music in <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16229214954739720671&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 3</a> <a href="/scholar?q=related:3-G36APBOeEJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16229214954739720671&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'3-G36APBOeEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md13', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md13" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:3-G36APBOeEJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4607654" class=yC1C>Using dtw based unsupervised segmentation to improve the vocal part detection in pop music</a></h3><div class="gs_a">L Xiao, J Zhou, T Zhang - Multimedia and Expo, 2008 IEEE  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Vocal part detection, which plays an important role in music information retrieval, is <br>still a tough task so far. Previous works focused on short time features, which cannot capture <br>some essential long term characteristics of singing. In this paper, we propose a Dynamic <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1816904981912120762&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 2</a> <a href="/scholar?q=related:um2CZXTxNhkJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'um2CZXTxNhkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://www.ee.iitb.ac.in/daplab/publications/vr-cg-pr-AMR-11.pdf" class=yC1E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from iitb.ac.in</span><span class="gs_ggsS">iitb.ac.in <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ee.iitb.ac.in/daplab/publications/vr-cg-pr-AMR-11.pdf" class=yC1D>Context-aware features for singing voice detection in polyphonic music</a></h3><div class="gs_a">V Rao, C Gupta, P Rao - Proc. of Adaptive Multimedia Retrieval, 2011 - ee.iitb.ac.in</div><div class="gs_rs">Abstract. The effectiveness of audio content analysis for music retrieval may be enhanced by <br>the use of available metadata. In the present work, observed differences in singing style and <br>instrumentation across genres are used to adapt acoustic features for the singing voice <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9915265364322959400&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 3</a> <a href="/scholar?q=related:KEA0xlAZmokJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9915265364322959400&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'KEA0xlAZmokJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md15', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md15" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:KEA0xlAZmokJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Singing Phoneme Class Detection In Polyphonic Music Recordings</h3><div class="gs_a">V Ourania - 2008 - magistrska naloga, Univerza  &hellip;</div><div class="gs_fl"><a href="/scholar?cites=11653457682537027000&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 1</a> <a href="/scholar?q=related:uJWqBAVmuaEJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11653457682537027000&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'uJWqBAVmuaEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://audiofingerprinting.googlecode.com/svn/trunk/Theory/NeuralMachinesForMusicRecognition.pdf" class=yC20><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from googlecode.com</span><span class="gs_ggsS">googlecode.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://audiofingerprinting.googlecode.com/svn/trunk/Theory/NeuralMachinesForMusicRecognition.pdf" class=yC1F>Neural machines for music recognition</a></h3><div class="gs_a"><a href="/citations?user=qSa64FYAAAAJ&amp;hl=en&amp;oi=sra">L Pape</a> - 2006 - audiofingerprinting.googlecode.com</div><div class="gs_rs">Abstract Since the early days of neural networks research, the focus has largely been aimed <br>at forward processing of information. A recently developed theory called pattern theory, <br>takes a different approach to solving pattern recognition problems. Rather than extracting <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11538384213454962400&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 1</a> <a href="/scholar?q=related:4D71JE-TIKAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11538384213454962400&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'4D71JE-TIKAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md17', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md17" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:4D71JE-TIKAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB18" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW18"><a href="http://institut17-1.kug.ac.at/fileadmin/media/iem/projects/2011/gampp_ti.pdf" class=yC22><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from kug.ac.at</span><span class="gs_ggsS">kug.ac.at <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://institut17-1.kug.ac.at/fileadmin/media/iem/projects/2011/gampp_ti.pdf" class=yC21>Evaluation of Robust Features for Singing Voice Detection</a></h3><div class="gs_a">P Gampp - institut17-1.kug.ac.at</div><div class="gs_rs">Abstract The detection of singing voice segments within music signals is an important object <br>of research in the field of music information retrieval, since it serves as an essential pre-<br>stage for applications like singer identification, lyrics recognition, singing melody <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:CMMZACBTsKIJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11722961226951148296&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'CMMZACBTsKIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md18', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md18" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:CMMZACBTsKIJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=huAzfJQhXDcC&amp;oi=fnd&amp;pg=PA99&amp;ots=_G5BM4g-li&amp;sig=36G2z5eAt4-5C_e0-IMJwuROluU" class=yC23>Content-Based Music Summarization and Classification</a></h3><div class="gs_a">JS Jin - Managing Multimedia Semantics, 2005 - books.google.com</div><div class="gs_rs">ABSTRACT This chapter aims to provide a comprehensive survey of the technical <br>achievements in the area of content-based music summarization and classification and to <br>present our recent achievements. In order to give a full picture of the current status, the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:rJdeESIOowoJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'rJdeESIOowoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB20" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW20"><a href="http://www-kd.iai.uni-bonn.de/pubattachments/336/da.pdf" class=yC25><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uni-bonn.de</span><span class="gs_ggsS">uni-bonn.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www-kd.iai.uni-bonn.de/pubattachments/336/da.pdf" class=yC24>Melody Separation from Polyphonic Audio Recordings</a></h3><div class="gs_a">S Vembu - 2005 - www-kd.iai.uni-bonn.de</div><div class="gs_rs">Abstract In the field of music information retrieval, query-by-humming is an interesting <br>application area in which humming sequences or melodies are matched with a database of <br>songs to come up with a list of indexed songs that are similar in melodic content to the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Wa_TF3qsUOoJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16884184643397726041&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'Wa_TF3qsUOoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md20', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md20" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Wa_TF3qsUOoJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> A project report submitted for the award of BSc Computer Science with Artificial Intelligence</h3><div class="gs_a">L Collard - 2007</div><div class="gs_fl"><a href="/scholar?q=related:dTdLIlVUU0oJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'dTdLIlVUU0oJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB22" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW22"><a href="http://mpac.ee.ntu.edu.tw/~yihsuan/pub/ISMIR09_segmentation.pdf" class=yC27><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntu.edu.tw</span><span class="gs_ggsS">ntu.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://mpac.ee.ntu.edu.tw/~yihsuan/pub/ISMIR09_segmentation.pdf" class=yC26>AN INTEGRATED APPROACH TO MUSIC BOUNDARY DETECTION</a></h3><div class="gs_a">S Min-Yian, <a href="/citations?user=OL-XGxcAAAAJ&amp;hl=en&amp;oi=sra">YH Yang</a>, YC Lin, H Chen - 2009 - mpac.ee.ntu.edu.tw</div><div class="gs_rs">ABSTRACT Music boundary detection is a fundamental step of music analysis and <br>summarization. Existing works either use unsupervised or supervised methods to detect <br>boundary. In this paper, we propose an integrated approach that takes advantage of both <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:R-mRR-dw3RgJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'R-mRR-dw3RgJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md22', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md22" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:R-mRR-dw3RgJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Monaural musical sound separation</h3><div class="gs_a"><a href="/citations?user=OCQSEIsAAAAJ&amp;hl=en&amp;oi=sra">Y Li</a> - 2008 - The Ohio State University</div><div class="gs_fl"><a href="/scholar?q=related:jpa0VTJdi4EJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9334657123423131278&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'jpa0VTJdi4EJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md23', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md23" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:jpa0VTJdi4EJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=14713022477718088856&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB24" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW24"><a href="http://www.ee.columbia.edu/~dpwe/e6820/proposals/felix.pdf" class=yC29><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from columbia.edu</span><span class="gs_ggsS">columbia.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ee.columbia.edu/~dpwe/e6820/proposals/felix.pdf" class=yC28>Identifying singing segments in music</a></h3><div class="gs_a">FS Garcia - ee.columbia.edu</div><div class="gs_rs">Page 1. Identifying singing segments in music Felix Sanchez Garcia Page 2. Objective â¢<br>Given a music sample, identify singing segments Page 3. Difficulties â¢ It is hard to<br>model singing voice, it differs from normal speech â Mixed <b>...</b> </div><div class="gs_fl"><a href="/scholar?q=related:_vPzlY0xKEAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4622999501671756798&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'_vPzlY0xKEAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md24', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md24" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:_vPzlY0xKEAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4797191" class=yC2A>An Effective Vocal/Non-vocal Segmentation Approach for Embedded Music Retrieve System on Mobile Phone</a></h3><div class="gs_a">H Tuo, H Li, K Lei - &hellip;  and Mobile Computing, 2009. CMC&#39;09. WRI &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract With the growing bodies of MP3 songs in Internet, content-based analysis plays an <br>important role for its retrieving and management. Due to most useful information is carried by <br>vocal portions, it is necessary to separate the vocal segments from music. This paper <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:44sDuDX6SGMJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7154243116705483747&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'44sDuDX6SGMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB26" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW26"><a href="http://ir.lib.szu.edu.cn:8080/bitstream/244041/2221/1/%E5%9F%BA%E4%BA%8E%E7%BD%AE%E4%BF%A1%E6%B5%8B%E5%BA%A6%E7%9A%84GMM%E6%A8%A1%E5%9E%8B%E9%80%82%E9%85%8D%E7%AE%97%E6%B3%95%E5%9C%A8%E9%9F%B3%E4%B9%90%E5%88%86%E5%89%B2%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8.pdf" class=yC2C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from szu.edu.cn</span><span class="gs_ggsS">szu.edu.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ir.lib.szu.edu.cn:8080/handle/244041/2221" class=yC2B>åºäºç½®ä¿¡æµåº¦ç GMM æ¨¡åééç®æ³å¨é³ä¹åå²ä¸­çåºç¨</a></h3><div class="gs_a">å¼ äºç£ï¼ éè½æï¼ æé - 2012 - ir.lib.szu.edu.cn</div><div class="gs_rs">æ¬ææåºäºä¸ç§åºäºç½®ä¿¡æµåº¦çèªéåºæ¨¡åééç®æ³ç¨äºé³ä¹åå². å¨ä¼ ç»çé³ä¹åå²ç®æ³åºç¡<br>ä¸, éè¿ç½®ä¿¡æµåº¦éæ©å¯é çæ°æ®è¿è¡æ¨¡åçå¨çº¿éé, è·å¾è·å¾åå²çé³ä¹ä¿¡å·æ´å¹éçå£°ä¹/<br>éå£°ä¹æ¨¡å, ä»èæé«é³ä¹åå²çåç¡®ç. ç¸å¯¹äºä¼ ç»çç®æ³, è¯¥ç®æ³å¨éè¯¯ç, èè­¦çåæ¼æ¥<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:52AkHppt1ccJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14399535892285120743&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'52AkHppt1ccJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB27" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW27"><a href="http://www.atiam.ircam.fr/Archives/Stages0708/Regnier.pdf" class=yC2E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ircam.fr</span><span class="gs_ggsS">ircam.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.atiam.ircam.fr/Archives/Stages0708/Regnier.pdf" class=yC2D>DÃ©tection de la voix chantÃ©e dans un morceau de musique</a></h3><div class="gs_a">L REGNIER - atiam.ircam.fr</div><div class="gs_rs">RÃ©sumÃ© De tous les Ã©lÃ©ments constitutifs d&#39;un morceau de musique, la voix est sans <br>conteste celui qui focalise le plus l&#39;attention de l&#39;auditeur. Ceci provient du fait que la voix est <br>porteuse d&#39;un message (le texte) et d&#39;une identitÃ© (celle du chanteur). Pour ces raisons, de <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:klX7IkhpWdMJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15229319373475501458&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'klX7IkhpWdMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md27', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md27" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:klX7IkhpWdMJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
