Total results = 37
<div class="gs_r" style="z-index:400"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1035721" class=yC0>The segmentation of news video into story units</a></h3><div class="gs_a">L Chaisorn, TS Chua, CH Lee - Multimedia and Expo, 2002.  &hellip;, 2002 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The segmentation of news video into single-story semantic units is a challenging <br>problem. This research proposes a two-level, multi-modal framework to tackle this problem. <br>The video is analyzed at the shot and story unit (or scene) levels using a variety of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16492627510664671647&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=37">Cited by 51</a> <a href="/scholar?q=related:n7EA2laV4eQJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16492627510664671647&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'n7EA2laV4eQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/JWWW03-lekha.pdf" class=yC2><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/VL11P38010523613.pdf" class=yC1>A multi-modal approach to story segmentation for news video</a></h3><div class="gs_a">L Chaisorn, TS Chua, CH Lee - World Wide Web, 2003 - Springer</div><div class="gs_rs">This research proposes a two-level, multi-modal framework to perform the segmentation and <br>classification of news video into single-story semantic units. The video is analyzed at the <br>shot and story unit (or scene) levels using a variety of features and techniques. At the shot <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6108549097289369038&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=37">Cited by 35</a> <a href="/scholar?q=related:zkX3HArtxVQJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/5E/44/RN130983315.html?source=googlescholar" class="gs_nph" class=yC3>BL Direct</a> <a href="/scholar?cluster=6108549097289369038&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'zkX3HArtxVQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/acm-tomccap06-xuhx.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1126007" class=yC4>Fusion of AV features and external information sources for event detection in team sports video</a></h3><div class="gs_a">H Xu, TS Chua - ACM Transactions on Multimedia Computing,  &hellip;, 2006 - dl.acm.org</div><div class="gs_rs">Abstract The use of AV features alone is insufficient to induce high-level semantics. This <br>article proposes a framework that utilizes both internal AV features and various types of <br>external information sources for event detection in team sports video. Three schemes are <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9085544146769579941&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=37">Cited by 27</a> <a href="/scholar?q=related:pY9Uo0NWFn4J:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9085544146769579941&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'pY9Uo0NWFn4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://lms.comp.nus.edu.sg/papers/media/2002/MTAP02~1.PDF" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/m2911q0732955g43.pdf" class=yC6>Stratification approach to modeling video</a></h3><div class="gs_a">TS Chua, L Chen, J Wang - Multimedia Tools and Applications, 2002 - Springer</div><div class="gs_rs">The explosive growth of audiovisual information in the last few years has made the <br>development of advanced video modeling and management tools an urgent task. In this <br>research, we investigate the use of stratification approach to model the contextual <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13358721049472749966&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=37">Cited by 23</a> <a href="/scholar?q=related:jlFbVwS2Y7kJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/3A/61/RN108177950.html?source=googlescholar" class="gs_nph" class=yC8>BL Direct</a> <a href="/scholar?cluster=13358721049472749966&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'jlFbVwS2Y7kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://www.comp.nus.edu.sg/~mohan/papers/logo_erase.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1035664" class=yC9>Erasing video logos based on image inpainting</a></h3><div class="gs_a">WQ Yan, MS Kankanhalli - Multimedia and Expo, 2002. ICME&#39; &hellip;, 2002 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract A video logo is usually a declaration of the video copyright. However it sometimes <br>causes visual discomfort due to the presence of multiple logos in videos that have been filed <br>and exchanged by different channels. We present an approach to erase logos from video <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8921315077717581294&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=37">Cited by 24</a> <a href="/scholar?q=related:7l2xyMvgznsJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8921315077717581294&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'7l2xyMvgznsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://dro.deakin.edu.au/eserv/DU:30023258/tjondronegoro-contentbased-2005.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from deakin.edu.au</span><span class="gs_ggsS">deakin.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1101362" class=yCB>Content-based video indexing for sports applications using integrated multi-modal approach</a></h3><div class="gs_a"><a href="/citations?user=_OblDDgAAAAJ&amp;hl=en&amp;oi=sra">D Tjondronegoro</a>, <a href="/citations?user=Vt5edEkAAAAJ&amp;hl=en&amp;oi=sra">YPP Chen</a>, B Pham - Proceedings of the 13th annual  &hellip;, 2005 - dl.acm.org</div><div class="gs_rs">Abstract To sustain an ongoing rapid growth of video information, there is an emerging <br>demand for a sophisticated content-based video indexing system. However, current video <br>indexing solutions are still immature and lack of any standard. This doctoral consists of a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6490305720990925273&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=37">Cited by 24</a> <a href="/scholar?q=related:2YFZh6oyEloJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6490305720990925273&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 18 versions</a> <a onclick="return gs_ocit(event,'2YFZh6oyEloJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md5', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md5" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:2YFZh6oyEloJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=15416151159179791011&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.199.6634&amp;rep=rep1&amp;type=pdf" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Pp3Xg-xg2CUC&amp;oi=fnd&amp;pg=PA95&amp;ots=PPpTE1avdk&amp;sig=MixirEbnt_Ln9TvcINKEcAleNXA" class=yCD>The segmentation and classification of story boundaries in news video</a></h3><div class="gs_a">L Chaisorn, TS Chua - Proceedings of the IFIP TC2/WG2, 2002 - books.google.com</div><div class="gs_rs">Abstract The segmentation and classification of news video into single-story semantic units <br>is a challenging problem. This research proposes a two-level, multi-modal framework to <br>tackle this problem. The video is analyzed at the shot and story unit (or scene) levels using <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14815142300848227144&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=37">Cited by 21</a> <a href="/scholar?q=related:SAPsum31mc0J:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14815142300848227144&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'SAPsum31mc0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://jan.nesvadba.info/cv/2004%20ICIP%20Face%20Detection%20in%20the%20Compressed%20Domain.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nesvadba.info</span><span class="gs_ggsS">nesvadba.info <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1421478" class=yCF>Face detection in the compressed domain</a></h3><div class="gs_a"><a href="/citations?user=ZRYS_nkAAAAJ&amp;hl=en&amp;oi=sra">P Fonseca</a>, J Nesvadha - Image Processing, 2004. ICIP&#39;04.  &hellip;, 2004 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Face detection is important in many algorithms in the areas of machine object <br>recognition and pattern recognition. The kaleidoscope of applications for face detection <br>extends across automatic image and home video content annotation, face-image <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5133308272577719596&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=37">Cited by 16</a> <a href="/scholar?q=related:LK2RLa0sPUcJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5133308272577719596&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'LK2RLa0sPUcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://asp.eurasipjournals.com/content/pdf/1687-6180-2006-059451.pdf" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from eurasipjournals.com</span><span class="gs_ggsS">eurasipjournals.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1288430" class=yC11>Face tracking in the compressed domain</a></h3><div class="gs_a"><a href="/citations?user=ZRYS_nkAAAAJ&amp;hl=en&amp;oi=sra">PM Fonseca</a>, J Nesvadba - EURASIP Journal on Applied Signal  &hellip;, 2006 - dl.acm.org</div><div class="gs_rs">Abstract A compressed domain generic object tracking algorithm offers, in combination with <br>a face detection algorithm, a low-computational-cost solution to the problem of detecting and <br>locating faces in frames of compressed video sequences (such as MPEG-1 or MPEG-2). <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12960354448024690239&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=37">Cited by 13</a> <a href="/scholar?q=related:P16qHbRt3LMJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/5D/62/RN191189174.html?source=googlescholar" class="gs_nph" class=yC13>BL Direct</a> <a href="/scholar?cluster=12960354448024690239&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'P16qHbRt3LMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://vireo.cs.cityu.edu.hk/wfeng/paper/pr08.pdf" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cityu.edu.hk</span><span class="gs_ggsS">cityu.edu.hk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://vireo.cs.cityu.edu.hk/wfeng/paper/pr08.pdf" class=yC14>Structuringlow-qualityvideotapedlecturesforcross-referencebrowsingbyvideotext analysis</a></h3><div class="gs_a">F Wanga, <a href="/citations?user=jk5DWVMAAAAJ&amp;hl=en&amp;oi=sra">CW Ngob</a>, TC Ponga - Pattern Recognition, 2008 - vireo.cs.cityu.edu.hk</div><div class="gs_rs">This paper presents an unified approach in analyzing and structuring the content of <br>videotaped lectures for distance learning applications. By structuring lecture videos, we can <br>support topic indexing and semantic querying of multimedia documents captured in the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9822635751327630528&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=37">Cited by 13</a> <a href="/scholar?q=related:wITvWywDUYgJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9822635751327630528&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'wITvWywDUYgJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md9', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md9" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:wITvWywDUYgJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://homepage.cs.latrobe.edu.au/ypchen/My_Papers_eCopies/tsmca-YChen-2046729-proof.pdf" class=yC17><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from latrobe.edu.au</span><span class="gs_ggsS">latrobe.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5467165" class=yC16>Knowledge-discounted event detection in sports video</a></h3><div class="gs_a"><a href="/citations?user=_OblDDgAAAAJ&amp;hl=en&amp;oi=sra">DW Tjondronegoro</a>, YPP Chen - Systems, Man and  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Automatic events annotation is an essential requirement for constructing an <br>effective sports video summary. Researchers worldwide have actively been seeking the <br>most robust and powerful solutions to detect and classify key events (or highlights) in <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9121841145964622892&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=37">Cited by 14</a> <a href="/scholar?q=related:LHTDUjFKl34J:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9121841145964622892&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'LHTDUjFKl34J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://www-nlpir.nist.gov/projects/tvpubs/tvpapers03/nus.partial.pdf" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nist.gov</span><span class="gs_ggsS">nist.gov <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www-nlpir.nist.gov/projects/tvpubs/tvpapers03/nus.partial.pdf" class=yC18>Two-level multi-modal framework for news story segmentation of large video corpus</a></h3><div class="gs_a">L Chaisorn, C Koh, Y Zhao, H Xu&hellip; - 12th Text Retrieval  &hellip;, 2003 - www-nlpir.nist.gov</div><div class="gs_rs">To tackle the problem of story segmentation, we proposed a two-level multi-modal <br>framework [Chaisorn et al. 2002]. First we analyze the video at the shot level using a variety <br>of low and high-level features, and classify the shots into pre-defined categories using <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14116296357896250010&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=37">Cited by 9</a> <a href="/scholar?q=related:muKLBL8o58MJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14116296357896250010&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'muKLBL8o58MJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md11', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md11" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:muKLBL8o58MJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1398372" class=yC1A>Face related features in consumer electronic (ce) device environments</a></h3><div class="gs_a">J Nesvadba, R Kleihorst, J Fan&hellip; - Systems, Man and  &hellip;, 2004 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The smart usage of the scattered processing power of consumer-electronics-device <br>networks permits analytical systems to be realized capable of generating semantically <br>meaningful meta information. A combination of&#39;service units&#39; such as face detection, face <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10551043303777695118&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=37">Cited by 8</a> <a href="/scholar?q=related:jvVuo_vVbJIJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10551043303777695118&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'jvVuo_vVbJIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=LAp_yx6oUIkC&amp;oi=fnd&amp;pg=PA288&amp;ots=4j9onZBwfQ&amp;sig=BLejWLL6IUCdmpZ4Ofnn9X7ix3k" class=yC1B>Motion activity based shot identification and closed caption detection for video structuring</a></h3><div class="gs_a"><a href="/citations?user=py1Cgn0AAAAJ&amp;hl=en&amp;oi=sra">DY Chen</a>, SJ Lin, SY Lee - Lecture notes in computer science, 2002 - books.google.com</div><div class="gs_rs">Abstract. In this paper, we propose a novel approach to generate the table of video content <br>based on shot description by motion activity and closed caption in MPEG-2 video streams. <br>Videos are segmented into shots by GOP-based approach and shot identification is used <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11721325254353372768&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=37">Cited by 7</a> <a href="/scholar?q=related:YEaMcjeDqqIJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/06/44/RN110086350.html?source=googlescholar" class="gs_nph" class=yC1C>BL Direct</a> <a href="/scholar?cluster=11721325254353372768&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'YEaMcjeDqqIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/2JPPMTJ8YW0ALBVL.pdf" class=yC1D>Fast text caption localization on video using visual rhythm</a></h3><div class="gs_a">S Chun, H Kim, K Jung-Rim, S Oh, S Sull - Recent Advances in Visual  &hellip;, 2002 - Springer</div><div class="gs_rs">In this paper, a fast DCT-based algorithm is proposed to efficiently locate text captions <br>embedded on specific areas in a video sequence through visual rhythm, which can be fast <br>constructed by sampling certain portions of a DC image sequence and temporally <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17403310426614969955&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=37">Cited by 5</a> <a href="/scholar?q=related:Y7Y8VqD6hPEJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/3B/48/RN110086325.html?source=googlescholar" class="gs_nph" class=yC1E>BL Direct</a> <a href="/scholar?cluster=17403310426614969955&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'Y7Y8VqD6hPEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://www.iis.sinica.edu.tw/page/jise/2006/200609_10.pdf" class=yC20><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from sinica.edu.tw</span><span class="gs_ggsS">sinica.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.iis.sinica.edu.tw/page/jise/2006/200609_10.pdf" class=yC1F>Automatic closed caption detection and filtering in MPEG videos for video structuring</a></h3><div class="gs_a"><a href="/citations?user=py1Cgn0AAAAJ&amp;hl=en&amp;oi=sra">DY Chen</a>, MH Hsiao, SY Lee - Journal of information science and  &hellip;, 2006 - iis.sinica.edu.tw</div><div class="gs_rs">Video structuring is the process of extracting temporal structural information of video <br>sequences and is a crucial step in video content analysis especially for sports videos. It <br>involves detecting temporal boundaries, identifying meaningful segments of a video and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=570677145891355041&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=37">Cited by 4</a> <a href="/scholar?q=related:oblJMtdz6wcJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/26/3B/RN216765976.html?source=googlescholar" class="gs_nph" class=yC21>BL Direct</a> <a href="/scholar?cluster=570677145891355041&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'oblJMtdz6wcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md15', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md15" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:oblJMtdz6wcJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.4.8364&amp;rep=rep1&amp;type=pdf" class=yC23><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.4.8364&amp;rep=rep1&amp;type=pdf" class=yC22>Detection of objects in video in contrast feature domain</a></h3><div class="gs_a">TS Chua, Y Zhao, Y Zhang - Proc. of IEEE Pacific-Rim Conf. on Multimedia &hellip;, 2000 - Citeseer</div><div class="gs_rs">ABSTRACT Recent advances in computing, networking and multimedia technologies have <br>brought about a surge in digital multimedia applications. In particular, there are great <br>interests to develop automated tools to manage the huge amount of digital video. To <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13224834987627220307&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=37">Cited by 3</a> <a href="/scholar?q=related:U42tYloNiLcJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13224834987627220307&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'U42tYloNiLcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md16', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md16" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:U42tYloNiLcJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Extracting Story Units in News Video</h3><div class="gs_a">L Chaisorn, TS Chua, CH Lee - Proceedings of IWAIT, 2003</div><div class="gs_fl"><a href="/scholar?cites=1474656682461943625&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=37">Cited by 2</a> <a href="/scholar?q=related:SdfMi3AIdxQJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1474656682461943625&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'SdfMi3AIdxQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/K47Q17N70W15034W.pdf" class=yC24>A model-based iterative method for caption extraction in compressed MPEG video</a></h3><div class="gs_a">D MÃ¡rquez, J BescÃ³s - Semantic Multimedia, 2007 - Springer</div><div class="gs_rs">We here describe a method for caption extraction that totally works in the MPEG compressed <br>domain. As opposed to other compressed domain methods; it does not need to refine their <br>results in the pixel domain. It consists of two phases: first, a selection of candidate frames <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=587801701967515103&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=37">Cited by 2</a> <a href="/scholar?q=related:380knIhKKAgJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/29/20/RN221530340.html?source=googlescholar" class="gs_nph" class=yC25>BL Direct</a> <a href="/scholar?cluster=587801701967515103&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'380knIhKKAgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/6M7N0X6BHTQXW0CT.pdf" class=yC26>Automatic closed caption detection and font size differentiation in MPEG video</a></h3><div class="gs_a">C Duan-Yu, H Ming-Ho, L Suh-Yin - Recent Advances in Visual Information &hellip;, 2002 - Springer</div><div class="gs_rs">In this paper, a novel approach of automatic closed caption detection and font size <br>differentiation among localized text regions in I-frames of MPEG videos is proposed. The <br>approach consists of five modules: video segmentation, shot selection, caption frame <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13601077830216784796&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=37">Cited by 1</a> <a href="/scholar?q=related:nBuDmDm8wLwJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/27/42/RN110086349.html?source=googlescholar" class="gs_nph" class=yC27>BL Direct</a> <a href="/scholar?cluster=13601077830216784796&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'nBuDmDm8wLwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB20" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW20"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.66.1122&amp;rep=rep1&amp;type=pdf" class=yC29><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/pn3430677t4406l4.pdf" class=yC28>A cross-modal approach for karaoke artifacts correction</a></h3><div class="gs_a">WQ Yan, MS Kankanhalli - Multimedia Tools and Applications, 2008 - Springer</div><div class="gs_rs">Abstract Karaoke singing is a popular form of entertainment in several parts of the world. <br>Since this genre of performance attracts amateurs, the singing often has artifacts related to <br>scale, tempo, and synchrony. We have developed an approach to correct these artifacts <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12356163693489506090&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=37">Cited by 1</a> <a href="/scholar?q=related:KkcF2WnpeasJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/19/4E/RN232981854.html?source=googlescholar" class="gs_nph" class=yC2A>BL Direct</a> <a href="/scholar?cluster=12356163693489506090&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'KkcF2WnpeasJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/95200x/200909/30369617.html" class=yC2B>å¿«éååç¡®çåè²è§é¢ææ¬æåæ¹æ³</a></h3><div class="gs_a">æ²ä»»éï¼ é»ç»åï¼ æ±ç¯æ - è®¡ç®æºå·¥ç¨, 2009 - cqvip.com</div><div class="gs_rs">éå¯¹å¤§å¤æ°è§é¢ææ¬è¾¹ç¼ä¸°å¯ä¸é¢è²åä¸, æ°´å¹³æåçç¹ç¹, éè¿åºäºderiche <br>è¾¹ç¼çæ¹æ³è¿éç¡®å®è§é¢å¾åä¸­å¯è½åå«ææ¬çåºå, ä½¿ç¨åºäºé¢è²çæ¹æ³ä»ä¸­æåç²¾ç¡®çäºå¼<br>ææ¬å¾å. å®éªç»æè¡¨æ, è¯¥ææ¬æåæ¹æ³éç¨äºèæ¯å¤æçè§é¢å¾å, ä¸ä¸åçº¯åºäºé¢è²ç<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11453741912838431624&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=37">Cited by 1</a> <a href="/scholar?q=related:iOO8z5Xd854J:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11453741912838431624&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'iOO8z5Xd854J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/4rtcbk421nq0ltrk.pdf" class=yC2C>Motion Activity Based Shot Identification and Closed Caption Detection for Video Structuring</a></h3><div class="gs_a">C Duan-Yu, L Shu-Jiuan, L Suh-Yin - Recent Advances in Visual  &hellip;, 2002 - Springer</div><div class="gs_rs">In this paper, we propose a novel approach to generate the table of video content based on <br>shot description by motion activity and closed caption in MPEG-2 video streams. Videos are <br>segmented into shots by GOP-based approach and shot identification is used to identify <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:eF3vBL0IylsJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'eF3vBL0IylsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB23" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW23"><a href="http://ethesys.isu.edu.tw/ETD-db/ETD-search/getfile?URN=etd-0820107-181954&amp;filename=etd-0820107-181954.pdf" class=yC2E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from isu.edu.tw</span><span class="gs_ggsS">isu.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ethesys.isu.edu.tw/ETD-db/ETD-search-c/view_etd?URN=etd-0820107-181954" class=yC2D>An algorithm of automatic image characters extraction</a></h3><div class="gs_a">CY Lin - 2007 - ethesys.isu.edu.tw</div><div class="gs_rs">Abstract We develop and improve an algorithm which can extract characters automatically in <br>image among continuous film. The algorithm of automatic image characters extraction can <br>extract characters information in image among continuous film, and store the character <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:SBZHHt7x3HMJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'SBZHHt7x3HMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB24" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW24"><a href="http://scholarbank.nus.sg/bitstream/handle/10635/16625/Phd_dissertation_HuangWeihua.pdf?sequence=1" class=yC30><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.sg</span><span class="gs_ggsS">nus.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://scholarbank.nus.sg/handle/10635/16625" class=yC2F>Scientific chart image recognition and interpretation</a></h3><div class="gs_a">H WEIHUA - 2008 - scholarbank.nus.sg</div><div class="gs_rs">This dissertation presents the research work on scientific chart image recognition and <br>interpretation, a relatively new area of document image analysis. Literature review is <br>conducted to summarize relevant research activities and point out their limitations that are <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:_43sNViI1mQJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7266144961252068863&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'_43sNViI1mQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/lh7413485m406rv4.pdf" class=yC31>Cross-Modal Approach for Karaoke Artifacts Correction</a></h3><div class="gs_a">WQ Yan, MS Kankanhalli - &hellip;  of Multimedia for Digital Entertainment and  &hellip;, 2009 - Springer</div><div class="gs_rs">In this chapter, we combine adaptive sampling in conjunction with video analogies (VA) to <br>correct the audio stream in the karaoke environment k= k (t): k (t)=(U (t), K (t)), t Ã (ts, te) Îº=\ <br>left {Îº (t):\ kappa (t)=\ left (U (t),\ K (t)\ right),\ t â\ left (t _ s,{t _ e\ right)\ right\} where ts and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:oYqzO5N08cYJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14335367264607636129&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'oYqzO5N08cYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/PM907273154185X1.pdf" class=yC32>Fast rotation-invariant video caption detection based on visual rhythm</a></h3><div class="gs_a">F Valio, <a href="/citations?user=kc-wB9QAAAAJ&amp;hl=en&amp;oi=sra">H Pedrini</a>, <a href="/citations?user=Qfothk4AAAAJ&amp;hl=en&amp;oi=sra">N Leite</a> - Progress in Pattern Recognition, Image  &hellip;, 2011 - Springer</div><div class="gs_rs">Text detection in images has been studied and improved for decades. There are many <br>works that extend the existing methods for analyzing videos, however, few of them create or <br>adapt approaches that consider inherent characteristics of videos, such as temporal <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:J2HGPP5qVvEJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17390204651311620391&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'J2HGPP5qVvEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB27" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW27"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/icme02-lekha.pdf" class=yC34><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/icme02-lekha.pdf" class=yC33>THE SEGMENTATION OF NEWS VIDEO INTO STORY UNITS</a></h3><div class="gs_a">LCTS Chua - 137.132.145.151</div><div class="gs_rs">The segmentation of news video into single-story semantic units is a challenging problem. <br>This research proposes a twolevel, multi-modal framework to tackle this problem. The video <br>is analyzed at the shot and story unit (or scene) levels using a variety of features and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:I0iaR7YY_H8J:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'I0iaR7YY_H8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB28" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW28"><a href="http://eprints.qut.edu.au/archive/00002199/01/PhDThesis_Tjondronegoro.pdf" class=yC36><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from qut.edu.au</span><span class="gs_ggsS">qut.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://eprints.qut.edu.au/archive/00002199" class=yC35>PhD Thesis:&quot; Content-based Video Indexing for Sports Applications using Multi-modal approach&quot;</a></h3><div class="gs_a"><a href="/citations?user=_OblDDgAAAAJ&amp;hl=en&amp;oi=sra">DW Tjondronegoro</a> - 2005 - eprints.qut.edu.au</div><div class="gs_rs">Triggered by technology innovations, there has been a huge increase in the utilization of <br>video, as one of the most preferred types of media due to its content richness, for many <br>significant applications. To sustain an ongoing rapid growth of video information, there is <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:k7wHTZYfh10J:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6739390097781144723&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'k7wHTZYfh10J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.freepatentsonline.com/EP1473658.html" class=yC37>Preprocessing device and method for recognizing image characters</a></h3><div class="gs_a">C Lim, H Kim, <a href="/citations?user=lP3XQWkAAAAJ&amp;hl=en&amp;oi=sra">J Seo</a>, N Kim, C Kim, J Park&hellip; - EP Patent  &hellip;, 2010 - freepatentsonline.com</div><div class="gs_rs">ZHONG Y ET AL:&quot; AUTOMATIC CAPTION LOCALIZATION IN COMPRESSED VIDEO&quot; IEEE <br>TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, IEEE <br>SERVICE CENTER, LOS ALAMITOS, CA, US, vol. 22, no. 4, April 2000 (2000-04), pages <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Jzn8W7reV0IJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Jzn8W7reV0IJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md29', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md29" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Jzn8W7reV0IJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB30" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW30"><a href="http://jan.nesvadba.info/cv/2004%20IEEE%20SMC%20Face%20Related%20Features%20In%20CEdevice%20Environments%20-%20copyright.pdf" class=yC39><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nesvadba.info</span><span class="gs_ggsS">nesvadba.info <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://jan.nesvadba.info/cv/2004%20IEEE%20SMC%20Face%20Related%20Features%20In%20CEdevice%20Environments%20-%20copyright.pdf" class=yC38>1.2 Connectivity in CE environments</a></h3><div class="gs_a">DB Meta - jan.nesvadba.info</div><div class="gs_rs">Currently, connectivity growth is even outstripping that of processing power and memory. CE <br>devices and PCs are inter-and broadband-connected, sharing information through local or <br>global networks with rapidly increasing bandwidth. Nowadays, as far as CE devices are <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:HJwBxbWvmusJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16977074940555664412&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'HJwBxbWvmusJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md30', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md30" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:HJwBxbWvmusJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB31" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW31"><a href="https://projectopenfarm.googlecode.com/files/OpenFARM%20Book.pdf" class=yC3B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from googlecode.com</span><span class="gs_ggsS">googlecode.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="https://projectopenfarm.googlecode.com/files/OpenFARM%20Book.pdf" class=yC3A>Open Framework for the Analysis of Rich Media MSc by Research in Software Engineering June 2011</a></h3><div class="gs_a">FMMF Martins - 2011 - projectopenfarm.googlecode.com</div><div class="gs_rs">Abstract This thesis describes the work undertaken to complete a two year programme of <br>study to investigate an âopen framework for the analysis of rich mediaâ(OpenFARM), under <br>the Knowledge Transfer Partnership (KTP) scheme.</div><div class="gs_fl"><a href="/scholar?q=related:1yjv1NqLG6gJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12113429394734655703&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'1yjv1NqLG6gJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md31', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md31" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:1yjv1NqLG6gJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB32" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW32"><a href="http://lms.comp.nus.edu.sg/papers/media/2002/icme02-lekha.pdf" class=yC3D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://lms.comp.nus.edu.sg/papers/media/2002/icme02-lekha.pdf" class=yC3C>THE SEGMENTATION OF NEWS VIDEO INTO STORY UNITS</a></h3><div class="gs_a">LCTSC Chin, H Lee - lms.comp.nus.edu.sg</div><div class="gs_rs">The effective management of the ever-increasing amount of broadcast news video is <br>essential to support a variety of useroriented functions, including the browsing, retrieval and <br>personalization of news video. One effective way to organize video is to segment it into <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:8pSS5jUvhfsJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18123944183970567410&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'8pSS5jUvhfsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:367"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB33" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW33"><a href="http://www.scholarbank.nus.edu.sg/bitstream/handle/10635/13136/Thesis_XU_Huaxin_HT016894E.pdf?sequence=1" class=yC3F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.scholarbank.nus.edu.sg/handle/10635/13136" class=yC3E>Integrated analysis of audiovisual signals and external information sources for event detection in team sports video</a></h3><div class="gs_a">H Xu - 2007 - scholarbank.nus.edu.sg</div><div class="gs_rs">Audiovisual signals and external information sources (news reports, live commentaries, Web <br>casts, etc.) are found to have complementary strengths for detecting events in sports video. <br>This thesis reports research on integrated analysis of them, focusing on tackling the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:M-BY-RAX2tkJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15697884812823552051&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'M-BY-RAX2tkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:366"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB34" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW34"><a href="http://www.ceaj.org/Jweb_gcyyy/EN/article/downloadArticleFile.do?attachType=PDF&amp;id=25488" class=yC41><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ceaj.org</span><span class="gs_ggsS">ceaj.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ceaj.org/Jweb_gcyyy/EN/article/downloadArticleFile.do?attachType=PDF&amp;id=25488" class=yC40>ä¸ç§æ°ç H. 264 è§é¢åºæ¯åæ¢æ£æµç®æ³</a></h3><div class="gs_a">åå²ä¸ï¼ é®ç§ç¦ - Computer Engineering and Applications, 2011 - ceaj.org</div><div class="gs_rs">æè¦: H. 264/AVC QCIF è§é¢åºæ¯åæ¢æ£æµæ¯è§é¢åºç¨ä¸­ä¸ä¸ªæå·æææ§çç ç©¶è¯¾é¢, <br>åªå©ç¨å®åä¿¡æ¯å¾é¾å¾å°æ»¡æçæ£æµææ, ä¸ºæ­¤æåºäºä¸ç§éç¨å¨æéå¼åAC ç¸ä¼¼åº¦çH. <br>264/AVC è§é¢åºæ¯åæ¢æ£æµç®æ³, èèç¼ç é¢æµæ¨¡å¼åDCT ç³»æ°ç­ä¿¡æ¯, æåºåºäºç¼ç æ¯ç¹æ°<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Hc0Nn2RBICcJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2819325267154947357&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'Hc0Nn2RBICcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md34', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md34" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Hc0Nn2RBICcJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:365"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB35" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW35"><a href="http://www.ecice06.com/EN/article/downloadArticleFile.do?attachType=PDF&amp;id=11918" class=yC43><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ecice06.com</span><span class="gs_ggsS">ecice06.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ecice06.com/EN/article/downloadArticleFile.do?attachType=PDF&amp;id=11918" class=yC42>åºäº PageRank ç®æ³æ¹è¿çåèèªå¨æºæ¨¡å</a></h3><div class="gs_a">å´å°å° - è®¡ç®æºå·¥ç¨, 2009 - ecice06.com</div><div class="gs_rs">æè¦: éå¯¹å¨çº¿é¶å®ä¸å¡ç³»ç»ä¸­ç¨æ·è¦è¿å¥è®¸å¤æ å³é¡µé¢æè½æ¾å°æéååçé®é¢, <br>ç«ç¹åºè½æ ¹æ®ç¾¤ä½ç¨æ·è´­ä¹°å´è¶£å¨æè°æ´ç½é¡µåé, å³ç«ç¹èªéåº. åç¨PageRank <br>ç®æ³å¯¹åèèªå¨æºæ¨¡åè¿è¡æ¹è¿, å®ç°ç«ç¹çèªéåºè°æ´. ä¸åæ¨¡åç¸æ¯, æ¹è¿æ¨¡åçæ¼åè§å<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:8Ezv5kwNNjQJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3762209162657746160&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'8Ezv5kwNNjQJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md35', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md35" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:8Ezv5kwNNjQJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:364"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB36" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW36"><a href="http://www.ceaj.org/Jweb_gcyyy/EN/article/downloadArticleFile.do?attachType=PDF&amp;id=25497" class=yC45><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ceaj.org</span><span class="gs_ggsS">ceaj.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ceaj.org/Jweb_gcyyy/EN/article/downloadArticleFile.do?attachType=PDF&amp;id=25497" class=yC44>Îµ-é»åå¹¶éç ç©¶ç´è§æ¨¡ç³ææçå®ç¾å·¥å·</a></h3><div class="gs_a">éç§ï¼ æä»¤å¼º - Computer Engineering and Applications, 2011 - ceaj.org</div><div class="gs_rs">æè¦: å¯¹D. Ãoker çÎµ-é»åç»æåLupiaÃ±ez çç´è§æ¨¡ç³ç½(æ»¤å­) çæ¶æçè®ºåäºè¿ä¸æ­¥æ¢è®¨, <br>è¯æäºÎµ-é»åå¹¶éç ç©¶ç´è§æ¨¡ç³ææçå®ç¾å·¥å·. å³é®è¯: é»å; ç´è§æ¨¡ç³ææ; ç´è§æ¨¡ç³ç½(æ»¤å­) <br>DOI: 10.3778/j. issn. 1002-8331.2011. 08.010 æç« ç¼å·: 1002-8331 (2011) 08-0030-03 <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:L4fR_1HaJuYJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16584182723557558063&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'L4fR_1HaJuYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md36', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md36" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:L4fR_1HaJuYJ:scholar.google.com/&amp;hl=en&amp;num=37&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
