Total results = 28
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.cse.cuhk.edu.hk/~king/PUB/TMM2010-Ma.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cuhk.edu.hk</span><span class="gs_ggsS">cuhk.edu.hk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5473143" class=yC0>Bridging the semantic gap between image contents and tags</a></h3><div class="gs_a"><a href="/citations?user=4spEfYgAAAAJ&amp;hl=en&amp;oi=sra">H Ma</a>, <a href="/citations?user=SC-WmzwAAAAJ&amp;hl=en&amp;oi=sra">J Zhu</a>, <a href="/citations?user=uQnBgK0AAAAJ&amp;hl=en&amp;oi=sra">MRT Lyu</a>, <a href="/citations?user=MXvC7tkAAAAJ&amp;hl=en&amp;oi=sra">I King</a> - Multimedia, IEEE Transactions  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract With the exponential growth of Web 2.0 applications, tags have been used <br>extensively to describe the image contents on the Web. Due to the noisy and sparse nature <br>in the human generated tags, how to understand and utilize these tags for image retrieval <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7863504538628971512&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 20</a> <a href="/scholar?q=related:-NumGrfHIG0J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7863504538628971512&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'-NumGrfHIG0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5733423" class=yC2>Effective semantic annotation by image-to-concept distribution model</a></h3><div class="gs_a">JH Su, CL Chou, <a href="/citations?user=kc6wqugAAAAJ&amp;hl=en&amp;oi=sra">CY Lin</a>&hellip; - &hellip; , IEEE Transactions on, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Image annotation based on visual features has been a difficult problem due to the <br>diverse associations that exist between visual features and human concepts. In this paper, <br>we propose a novel approach called Annotation by Image-to-Concept Distribution Model (<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2462913930046407351&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 4</a> <a href="/scholar?q=related:twLHmCsHLiIJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2462913930046407351&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'twLHmCsHLiIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://research.microsoft.com/en-us/people/xjwang/ieeep_arista.pdf" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from microsoft.com</span><span class="gs_ggsS">microsoft.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6210348" class=yC3>Duplicate-Search-Based Image Annotation Using Web-Scale Data</a></h3><div class="gs_a">XJ Wang, <a href="/citations?user=fIlGZToAAAAJ&amp;hl=en&amp;oi=sra">L Zhang</a>, WY Ma - Proceedings of the IEEE, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Easy photo-taking and photo-sharing today make image an increasingly important <br>type of media in people&#39;s everyday life, which arouses a growing demand for a practical <br>image understanding technique. Traditional computer vision or machine learning methods <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3720039134173134828&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 2</a> <a href="/scholar?q=related:7P_wBuI7oDMJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3720039134173134828&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'7P_wBuI7oDMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6135819" class=yC5>An Adaptive Recognition Model for Image Annotation</a></h3><div class="gs_a">Z Chen, H Fu, Z Chi, DD Feng - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, an adaptive recognition model (ARM) is proposed for image <br>annotation. The ARM consists of an adaptive classification network (CFN) and a nonlinear <br>correlation network (CLN). The adaptive CFN aims to annotate an image with keywords, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6588742578563758026&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 1</a> <a href="/scholar?q=related:yrfIb3fqb1sJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'yrfIb3fqb1sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6046648" class=yC6>Large-scale image annotation using prototype-based models</a></h3><div class="gs_a">SH Amiri, M Jamzad - Image and Signal Processing and  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Automatic image annotation is a challenging problem in the field of image retrieval. <br>Dealing with large databases makes the annotation problem more difficult and therefore an <br>effective approach is needed to manage such databases. In this work, an annotation <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11438911372152377621&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 1</a> <a href="/scholar?q=related:FZFRekktv54J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'FZFRekktv54J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0925231211006849" class=yC7>Scale invariant image matching using triplewise constraint and weighted voting</a></h3><div class="gs_a">Y Pang, M Shang, Y Yuan, J Pan - Neurocomputing, 2011 - Elsevier</div><div class="gs_rs">Due to limited computational resource, image matching on mobile phone places great <br>demand on efficiency and scale invariant. Though spectral matching (SM) with pairwisely <br>geometric constraints is widely used in matching, it is not efficient and scale invariant for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=40556142128859267&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 1</a> <a href="/scholar?q=related:gwgNrZgVkAAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=40556142128859267&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'gwgNrZgVkAAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/ZhaZJ_J03_Semantic-Gap-Oriented%20Active%20Learning%20for%20Multilable%20Image%20Annotation.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6111295" class=yC8>Semantic-Gap-Oriented Active Learning for Multilabel Image Annotation</a></h3><div class="gs_a"><a href="/citations?user=ByBLlEwAAAAJ&amp;hl=en&amp;oi=sra">J Tang</a>, ZJ Zha, D Tao, TS Chua - Image Processing, IEEE  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract User interaction is an effective way to handle the semantic gap problem in image <br>annotation. To minimize user effort in the interactions, many active learning methods were <br>proposed. These methods treat the semantic concepts individually or correlatively. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12951969610158265254&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 5</a> <a href="/scholar?q=related:plMj67yjvrMJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12951969610158265254&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'plMj67yjvrMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0925231212009022" class=yCA>Kai Jiang, Huagang Yin, Peng Wang, Nenghai Yu</a></h3><div class="gs_a"><a href="/citations?user=nz-Li8kAAAAJ&amp;hl=en&amp;oi=sra">K Jiang</a>, H Yin, P Wang, N Yu - Neurocomputing, 2013 - Elsevier</div><div class="gs_rs">Abstract This paper proposed a method that fully exploits contextual information of geo-<br>tagged web photos to recommend tourism attractions to a user according to his personal <br>interest and current time and location. The proposed method first detects tourism <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'47hWBsoEwdcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://www.jofcis.com/publishedpapers/2012_8_9_3859_3866.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from jofcis.com</span><span class="gs_ggsS">jofcis.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.jofcis.com/publishedpapers/2012_8_9_3859_3866.pdf" class=yCB>A Novel Image Representation Algorithm Based on RNAMC and Its Application to Medical Images</a></h3><div class="gs_a">Y ZHENG, Z LI, J ZHANG, J LIN, X MO&hellip; - Journal of Computational  &hellip;, 2012 - jofcis.com</div><div class="gs_rs">Abstract An efficient image representation can save space and facilitate the manipulation of <br>the acquired images. By controlling the ratio of the length and the width of a homogenous <br>block and using a diagonal-first search strategy, a novel image representation algorithm <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:iyszE4t1spYJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'iyszE4t1spYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md8', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md8" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:iyszE4t1spYJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="https://www.ideals.illinois.edu/bitstream/handle/2142/34426/Jin_Xin.pdf?sequence=1" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from illinois.edu</span><span class="gs_ggsS">illinois.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="https://www.ideals.illinois.edu/handle/2142/34426" class=yCD>Mining the relation and implication of user generated content in social media</a></h3><div class="gs_a">J Han, T Abdelzaher, <a href="/citations?user=YU-baPIAAAAJ&amp;hl=en&amp;oi=sra">C Zhai</a>, J Yu - 2012 - ideals.illinois.edu</div><div class="gs_rs">Abstract: The phenomenal success of social media sites, such as Facebook, Twitter, <br>LinkedIn, Flickr and YouTube, not only revolutionized the way people communicate and <br>think, but also revolutionized the way how corporations do business. During the current <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:BoPMGMJ5MckJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'BoPMGMJ5MckJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6081863" class=yCF>Reinforced Similarity Integration in Image-Rich Information Networks</a></h3><div class="gs_a">X Jin, <a href="/citations?user=CcbnBvgAAAAJ&amp;hl=en&amp;oi=sra">J Luo</a>, J Yu, G Wang, <a href="/citations?user=TYmV4V8AAAAJ&amp;hl=en&amp;oi=sra">D Joshi</a>, J Han - 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Social multimedia sharing and hosting websites, such as Flickr and Facebook, <br>contain billions of user-submitted images. Popular Internet commerce websites such as <br>Amazon. com are also furnished with tremendous amounts of product-related images. In <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13046109345638082360&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 1</a> <a href="/scholar?q=related:OGepH1QXDbUJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13046109345638082360&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'OGepH1QXDbUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5711740" class=yC10>A framework for high level semantic annotation using trusted object annotated dataset</a></h3><div class="gs_a">I Irfanullah, N Aslam, J Loo, M Loomes&hellip; - &hellip;  (ISSPIT), 2010 IEEE  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Dramatic expansion and eminence of the multimedia data from the last decades, <br>culminates to a trouble in managing, accessing and annotating the data. The high level <br>semantic annotation (HLS) of resources in general and multimedia resources in particular, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:w5jOLzP1vNcJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15545569613970315459&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'w5jOLzP1vNcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2324839" class=yC11>Multi-graph multi-instance learning for object-based image and video retrieval</a></h3><div class="gs_a">F Li, <a href="/citations?user=X2waN0MAAAAJ&amp;hl=en&amp;oi=sra">R Liu</a> - Proceedings of the 2nd ACM International Conference  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract Object-based image retrieval has been an active research topic in recent years, in <br>which a user is only interested in some object in the images. As one promising approach, <br>graph-based multi-instance learning has attracted many researchers. The existing <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Tz-2NjRUADYJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Tz-2NjRUADYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S092523121200906X" class=yC12>Hybrid Image Summarization by Hypergraph Partition</a></h3><div class="gs_a">M Li, C Zhao, <a href="/citations?user=ByBLlEwAAAAJ&amp;hl=en&amp;oi=sra">J Tang</a> - Neurocomputing, 2013 - Elsevier</div><div class="gs_rs">Abstract The objectiveof hybrid image summarization is selecting a few visual exemplars <br>and semantic exemplars of a large-scale image collection and organizing them to represent <br>the collection. In this paper, we present a framework for hybrid image summarization in <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'ldtgTpHIVcYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0925231212009058" class=yC13>Fusing inherent and external knowledge with nonlinear learning for cross-media retrieval</a></h3><div class="gs_a">H Zhang, Y Liu, Z Ma - Neurocomputing, 2013 - Elsevier</div><div class="gs_rs">Abstract Cross-media retrieval focuses on searching multimedia data of different modalities <br>with content-based methods. However, most of those methods are designed for multimedia <br>retrieval in single modality, such as image retrieval and audio retrieval. Though a few work <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'Mz5bT9bZMoEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://www.ieeeprojects.yavum.com/ieee2012basepaper/Learn%20to%20Personalized%20Image%20Search%20from%20the%20Photo%20Sharing%20Websites.pdf" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from yavum.com</span><span class="gs_ggsS">yavum.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6111487" class=yC14>Learn to Personalized Image Search From the Photo Sharing Websites</a></h3><div class="gs_a"><a href="/citations?user=u6ivSjgAAAAJ&amp;hl=en&amp;oi=sra">J Sang</a>, C Xu, D Lu - Multimedia, IEEE Transactions on, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Increasingly developed social sharing websites like Flickr and Youtube allow users <br>to create, share, annotate, and comment medias. The large-scale user-generated metadata <br>not only facilitate users in sharing and organizing multimedia content, but provide useful <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14042515156176223035&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 2</a> <a href="/scholar?q=related:OzvsVCIJ4cIJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14042515156176223035&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'OzvsVCIJ4cIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6092497" class=yC16>Query Difficulty Prediction for Web Image Search</a></h3><div class="gs_a">X Tian, Y Lu, <a href="/citations?user=cvgKxDQAAAAJ&amp;hl=en&amp;oi=sra">L Yang</a> - Multimedia, IEEE Transactions on, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Image search plays an important role in our daily life. Given a query, the image <br>search engine is to retrieve images related to it. However, different queries have different <br>search difficulty levels. For some queries, they are easy to be retrieved (the search engine <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:AD64Z0noKUEJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'AD64Z0noKUEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S1047320312000272" class=yC17>Visual attention modeling based on short-term environmental adaption</a></h3><div class="gs_a"><a href="/citations?user=KPMK3B4AAAAJ&amp;hl=en&amp;oi=sra">X Sun</a>, H Yao, <a href="/citations?user=lRSD7PQAAAAJ&amp;hl=en&amp;oi=sra">R Ji</a> - Journal of Visual Communication and Image  &hellip;, 2012 - Elsevier</div><div class="gs_rs">Abstract Visual attention modeling is crucial for interpreting the structure and functionality of <br>human vision system. A typical computational model of visual attention includes two basic <br>elements: visual representation and saliency measurement. Most existing models left two <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:m9FdbKhISpAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'m9FdbKhISpAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0165168412003738" class=yC18>Accurate off-line query expansion for large-scale mobile visual search</a></h3><div class="gs_a">K Gao, Y Zhang, D Zhang, S Lin - Signal Processing, 2012 - Elsevier</div><div class="gs_rs">Abstract Mobile visual search is a new class of applications that use images taken by <br>camera phone to initiate search queries. It is a very challenging task mainly because of <br>image affine transformations caused by viewpoints changes, and motion blur due to hand <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'jGqqcFaDOSwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0925231212009083" class=yC19>Jing Pan, Zhao Ma, Yanwei Pang, Yuan Yuan</a></h3><div class="gs_a">J Pan, Z Ma, Y Pang, Y Yuan - Neurocomputing, 2013 - Elsevier</div><div class="gs_rs">Abstract The input data of collaborative filtering, also known as recommendation system, are <br>usually sparse and noisy. In addition, in many cases the data are time-variant and have <br>obvious periodic property. In this paper, we take the two characteristics into account. To <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'u4EUgLBtfCcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0925231212003426" class=yC1A>Semi-supervised distance metric learning based on local linear regression for data clustering</a></h3><div class="gs_a">H Zhang, J Yu, <a href="/citations?user=rHagaaIAAAAJ&amp;hl=en&amp;oi=sra">M Wang</a>, Y Liu - Neurocomputing, 2012 - Elsevier</div><div class="gs_rs">Distance metric plays an important role in many machine learning tasks. The distance <br>between samples is mostly measured with a predefined metric, ignoring how the samples <br>distribute in the feature space and how the features are correlated. This paper proposes a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Nbwah0vMCV4J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6776171739116911669&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'Nbwah0vMCV4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/n21118436x784101.pdf" class=yC1B>Combining global and local matching of multiple features for precise item image retrieval</a></h3><div class="gs_a">H Li, X Wang, <a href="/citations?user=ByBLlEwAAAAJ&amp;hl=en&amp;oi=sra">J Tang</a>, C Zhao - Multimedia Systems - Springer</div><div class="gs_rs">Abstract With the fast-growing of online shopping services, there are millions even billions of <br>commercial item images available on the Internet. How to effectively leverage visual search <br>method to find the items of users&#39; interests is an important yet challenging task. Besides <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2778197965817864700&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 1</a> <a href="/scholar?q=related:_GFJlFQkjiYJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'_GFJlFQkjiYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0925231212009125" class=yC1C>Fuming Sun, Haojie Li, Xueming Wang</a></h3><div class="gs_a">F Sun, H Li, X Wang - Neurocomputing, 2013 - Elsevier</div><div class="gs_rs">Abstract As smart phone features dramatical performance, including faster processor, GPS <br>chip, and more advanced camera, etc, more and more people use it for photography. With <br>more photos stored on personal devices, there is a growing need of photo tools that can <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'vG-isodJ56UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/14n6w3452rwrhx4r.pdf" class=yC1D>Variants of dense descriptors and Zernike moments as features for accurate shape-based image retrieval</a></h3><div class="gs_a">A Goyal, E Walia - Signal, Image and Video Processing, 2012 - Springer</div><div class="gs_rs">Abstract Shape, being an important part of an object, has a special place in the field of <br>shape-based image retrieval (SBIR). To retrieve most appropriate images, various <br>descriptors are applied in SBIR like Zernike moments (ZMs), complex Zernike moments (<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ZX4ZuBGYcyEJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'ZX4ZuBGYcyEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/iel5/5326/6330018/06135819.pdf?arnumber=6135819" class=yC1E>Technical Correspondence</a></h3><div class="gs_a">Z Chen, H Fu, Z Chi, DD Feng - IEEE TRANSACTIONS ON  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">AbstractâIn this paper, an adaptive recognition model (ARM) is pro-posed for image <br>annotation. The ARM consists of an adaptive classification network (CFN) and a nonlinear <br>correlation network (CLN). The adaptive CFN aims to annotate an image with keywords, <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'dh0qxVAoz14J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S1047320312000387" class=yC1F>Image annotation by semi-supervised cross-domain learning with group sparsity</a></h3><div class="gs_a">Y Yuan, F Wu, <a href="/citations?user=VUN-9cQAAAAJ&amp;hl=en&amp;oi=sra">J Shao</a>, Y Zhuang - Journal of Visual Communication and  &hellip;, 2012 - Elsevier</div><div class="gs_rs">Abstract With the explosive growth of multimedia data in the web, multi-label image <br>annotation has been attracted more and more attention. Although the amount of available <br>data is large and growing, the number of labeled data is quite small. This paper proposes <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:99PNz5Umyn0J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'99PNz5Umyn0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0925231213000167" class=yC20>Hypergraph spectral hashing for image retrieval with heterogeneous social contexts</a></h3><div class="gs_a">Y Liu, J Shao, J Xiao, F Wu, Y Zhuang - Neurocomputing, 2013 - Elsevier</div><div class="gs_rs">Abstract The development of social media brings great challenges to image retrieval on both <br>efficiency and accuracy. In addition to achieving fast similarity search over large scale data, <br>it is very crucial to represent the complex and high-order relationships among the social <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'I52-4bBb7zsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0925231213000143" class=yC21>Liansheng Zhuang, Haoyuan Gao, Jiebo Luo, Zhouchen Lin</a></h3><div class="gs_a">L Zhuang, H Gao, <a href="/citations?user=CcbnBvgAAAAJ&amp;hl=en&amp;oi=sra">J Luo</a>, <a href="/citations?user=TanjFwoAAAAJ&amp;hl=en&amp;oi=sra">Z Lin</a> - Neurocomputing, 2013 - Elsevier</div><div class="gs_rs">Abstract Topic model is a popular tool for visual concept learning. Most topic models are <br>either unsupervised or fully supervised. In this paper, to take advantage of both limited <br>labeled training images and rich unlabeled images, we proposes a novel regularized <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'d3625usrxKwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
