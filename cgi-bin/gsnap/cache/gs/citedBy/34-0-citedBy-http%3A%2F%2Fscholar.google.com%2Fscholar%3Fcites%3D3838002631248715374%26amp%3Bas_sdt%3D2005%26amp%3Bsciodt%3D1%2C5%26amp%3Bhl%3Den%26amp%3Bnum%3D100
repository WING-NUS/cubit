Total results = 34
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://hal.inria.fr/docs/00/54/47/74/PDF/2007_IEEE_TASLP_OzerovEtAl_SingleChannelSourceSeparation.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from inria.fr</span><span class="gs_ggsS">inria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4244535" class=yC0>Adaptation of Bayesian models for single-channel source separation and its application to voice/music separation in popular songs</a></h3><div class="gs_a"><a href="/citations?user=LnV-0z0AAAAJ&amp;hl=en&amp;oi=sra">A Ozerov</a>, P Philippe, F Bimbot&hellip; - Audio, Speech, and  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Probabilistic approaches can offer satisfactory solutions to source separation with a <br>single channel, provided that the models of the sources match accurately the statistical <br>properties of the mixed signals. However, it is not always possible to train such models. To <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3148219667242123779&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 85</a> <a href="/scholar?q=related:A4LdfBu5sCsJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/50/02/RN211839556.html?source=googlescholar" class="gs_nph" class=yC2>BL Direct</a> <a href="/scholar?cluster=3148219667242123779&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'A4LdfBu5sCsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="ftp://ftp.cse.ohio-state.edu/pub/tech-report/2005/TR61.pdf" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ohio-state.edu</span><span class="gs_ggsS">ohio-state.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4156205" class=yC3>Separation of singing voice from music accompaniment for monaural recordings</a></h3><div class="gs_a"><a href="/citations?user=OCQSEIsAAAAJ&amp;hl=en&amp;oi=sra">Y Li</a>, <a href="/citations?user=yO59sggAAAAJ&amp;hl=en&amp;oi=sra">DL Wang</a> - Audio, Speech, and Language Processing,  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Separating singing voice from music accompaniment is very useful in many <br>applications, such as lyrics recognition and alignment, singer identification, and music <br>information retrieval. Although speech separation has been extensively studied for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16877915460734066236&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 74</a> <a href="/scholar?q=related:PJ4gQrBmOuoJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/03/1B/RN211148698.html?source=googlescholar" class="gs_nph" class=yC5>BL Direct</a> <a href="/scholar?cluster=16877915460734066236&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'PJ4gQrBmOuoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www.comp.nus.edu/~kanmy/dossier/papers/p1568934817-wang.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu</span><span class="gs_ggsS">nus.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1027576" class=yC6>LyricAlly: automatic synchronization of acoustic musical signals and textual lyrics</a></h3><div class="gs_a">Y Wang, <a href="/citations?user=aNVcd3EAAAAJ&amp;hl=en&amp;oi=sra">MY Kan</a>, TL Nwe, A Shenoy, J Yin - Proceedings of the 12th  &hellip;, 2004 - dl.acm.org</div><div class="gs_rs">Abstract We present a prototype that automatically aligns acoustic musical signals with their <br>corresponding textual lyrics, in a manner similar to manually-aligned karaoke. We tackle this <br>problem using a multimodal approach, where the appropriate pairing of audio and text <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10802878761400089986&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 61</a> <a href="/scholar?q=related:gj3dVP-I65UJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10802878761400089986&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 36 versions</a> <a onclick="return gs_ocit(event,'gj3dVP-I65UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1112857" class=yC8>Key, chord, and rhythm tracking of popular music recordings</a></h3><div class="gs_a">A Shenoy, Y Wang - Computer Music Journal, 2005 - dl.acm.org</div><div class="gs_rs">In this article, we propose a framework to analyze a musical audio signal (sampled from a <br>popular music CD) and determine its key, provide usable chord transcriptions, and obtain <br>the hierarchical rhythm structure representation comprising the quarternote, half-note, and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16290336487138294495&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 22</a> <a href="/scholar?q=related:33p2o7nmEuIJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/2E/0B/RN175256451.html?source=googlescholar" class="gs_nph" class=yC9>BL Direct</a> <a href="/scholar?cluster=16290336487138294495&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'33p2o7nmEuIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://ohm.fing.edu.uy/publicaciones/2007/RH07/RH07.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from fing.edu.uy</span><span class="gs_ggsS">fing.edu.uy <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://ohm.fing.edu.uy/publicaciones/2007/RH07/RH07.pdf" class=yCA>Comparing audio descriptors for singing voice detection in music audio files</a></h3><div class="gs_a">M Rocamora, <a href="/citations?user=x4X0Ia8AAAAJ&amp;hl=en&amp;oi=sra">P Herrera</a> - &hellip;  on Computer Music, 11th. San Pablo,  &hellip;, 2007 - ohm.fing.edu.uy</div><div class="gs_rs">Abstract. Given the relevance of the singing voice in popular western music, a system able to <br>reliable identify those portions of a music audio file containing vocals would be very useful. <br>In this work, we explore already used descriptors to perform this task and compare the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4597348268454176119&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 23</a> <a href="/scholar?q=related:d-X3ceQPzT8J:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4597348268454176119&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'d-X3ceQPzT8J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md4', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md4" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:d-X3ceQPzT8J:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.98.1526&amp;rep=rep1&amp;type=pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/j1h044n4v1767603.pdf" class=yCC>Automatic lyrics alignment for Cantonese popular music</a></h3><div class="gs_a">CH Wong, WM Szeto, KH Wong - Multimedia Systems, 2007 - Springer</div><div class="gs_rs">Abstract From lyrics-display on electronic music players and Karaoke videos to surtitles for <br>live Chinese opera performance, one feature is common to all these everyday functionalities <br>temporal: synchronization of the written text and its corresponding musical phrase. Our <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=782808755015182321&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 16</a> <a href="/scholar?q=related:8ee-SWoY3QoJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/5E/5A/RN202853430.html?source=googlescholar" class="gs_nph" class=yCE>BL Direct</a> <a href="/scholar?cluster=782808755015182321&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'8ee-SWoY3QoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md5', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md5" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:8ee-SWoY3QoJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=18158445423803726775&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://www.tsi.enst.fr/~grichard/Publications/Icassp08_ramona.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from enst.fr</span><span class="gs_ggsS">enst.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4518002" class=yCF>Vocal detection in music with support vector machines</a></h3><div class="gs_a">M Ramona, G Richard, B David - Acoustics, Speech and Signal  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We propose a statistical learning approach for the automatic detection of vocal <br>regions in a polyphonic musical signal. A support vector model, based on a large feature set, <br>is employed to discriminate accompanied singing voice from pure instrumental regions. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8183329524968948919&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 17</a> <a href="/scholar?q=related:t4S9h9gGkXEJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8183329524968948919&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'t4S9h9gGkXEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="https://www1.comp.nus.edu.sg/~wangye/papers/1.Audio_and_Music_Analysis_and_Retrieval/2005_Singing_Voice_Detection_for_Karaoke_Application.pdf" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=876255" class=yC11>Singing voice detection for karaoke application</a></h3><div class="gs_a">A Shenoy, Y Wu, Y Wang - Visual  &hellip;, 2005 - proceedings.spiedigitallibrary.org</div><div class="gs_rs">abstract We present a framework to detect the regions of singing voice in musical audio <br>signals. This work is oriented towards the development of a robust transcriber of lyrics for <br>karaoke applications. The technique leverages on a combination of low-level audio <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12185904537651465050&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 11</a> <a href="/scholar?q=related:WkuJAZ0HHakJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/3A/63/RN177222664.html?source=googlescholar" class="gs_nph" class=yC13>BL Direct</a> <a href="/scholar?cluster=12185904537651465050&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 17 versions</a> <a onclick="return gs_ocit(event,'WkuJAZ0HHakJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="https://piglet2.ee.columbia.edu/2008/papers/122.pdf" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from columbia.edu</span><span class="gs_ggsS">columbia.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.isca-speech.org/archive_open/archive_papers/sapa_2008/sap8_007.pdf" class=yC14>Singing voice detection using modulation frequency features</a></h3><div class="gs_a"><a href="/citations?user=Z2Jmcq0AAAAJ&amp;hl=en&amp;oi=sra">M Markaki</a>, A Holzapfel, Y Stylianou - Proc. SAPA, 2008 - isca-speech.org</div><div class="gs_rs">Abstract In this paper, a feature set derived from modulation spectra is applied to the task of <br>detecting singing voice in historical and recent recordings of Greek Rembetiko. A <br>generalization of SVD to tensors, Higher Order SVD (HOSVD), is applied to reduce the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11924636628357371507&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 9</a> <a href="/scholar?q=related:c1bahNXRfKUJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11924636628357371507&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'c1bahNXRfKUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://www.ee.iitb.ac.in/web/files/publications/RaoPS2008.pdf" class=yC17><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from iitb.ac.in</span><span class="gs_ggsS">iitb.ac.in <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ee.iitb.ac.in/web/files/publications/RaoPS2008.pdf" class=yC16>Singing voice detection in north indian classical music</a></h3><div class="gs_a">V Rao, S Ramakrishnan, P Rao - Proc. of the National Conference on  &hellip;, 2008 - ee.iitb.ac.in</div><div class="gs_rs">AbstractâSinging voice detection is essential for content-based applications such as those <br>involving melody extraction and singer identification. This article is concerned with the <br>accurate detection of singing voice phrases in north Indian classical vocal music. The <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16148304997457824986&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 3</a> <a href="/scholar?q=related:2owjetZNGuAJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16148304997457824986&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'2owjetZNGuAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md9', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md9" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:2owjetZNGuAJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://hal.archives-ouvertes.fr/docs/00/45/75/22/PDF/These_Helene_Lachambre.pdf" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://hal.archives-ouvertes.fr/tel-00457522/" class=yC18>CaractÃ©risation de l&#39;environnement musical dans les documents audiovisuels</a></h3><div class="gs_a">H Lachambre - 2009 - hal.archives-ouvertes.fr</div><div class="gs_rs">Depuis plusieurs dizaines d&#39;annÃ©es, l&#39;indexation par le contenu des documents <br>audiovisuels fait l&#39;objet de travaux de la part de nombreuses Ã©quipes de recherche:âLe mot <br>Â«audiovisuelÂ» fait rÃ©fÃ©rencea un contenu Â«multimÃ©diaÂ» qui regroupea la fois des donnÃ©es <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7844252019198893922&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 4</a> <a href="/scholar?q=related:Yp_9nKZh3GwJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7844252019198893922&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'Yp_9nKZh3GwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md10', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md10" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:Yp_9nKZh3GwJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=3531827526069817499&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Singing Phoneme Class Detection In Polyphonic Music Recordings</h3><div class="gs_a">V Ourania - 2008 - magistrska naloga, Univerza  &hellip;</div><div class="gs_fl"><a href="/scholar?cites=11653457682537027000&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 1</a> <a href="/scholar?q=related:uJWqBAVmuaEJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11653457682537027000&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'uJWqBAVmuaEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://www.dse.nl/~gijsg/AmbiSys-GeleijnseEtAl.pdf" class=yC1B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from dse.nl</span><span class="gs_ggsS">dse.nl <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1363164" class=yC1A>Enriching music with synchronized lyrics, images and colored lights</a></h3><div class="gs_a">G Geleijnse, D Sekulovski, <a href="/citations?user=OweuZLoAAAAJ&amp;hl=en&amp;oi=sra">J Korst</a>, S Pauws&hellip; - Proceedings of the 1st  &hellip;, 2008 - dl.acm.org</div><div class="gs_rs">Abstract We present a method to synchronize popular music with its lyrics at the stanza level. <br>First we apply an algorithm to segment audio content into harmonically similar and/or <br>contrasting progressions, ie the stanzas. We map the stanzas found to a sequence of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1472177553128121368&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 1</a> <a href="/scholar?q=related:GGSBRK85bhQJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1472177553128121368&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'GGSBRK85bhQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2072366" class=yC1C>MUSIZ: a generic framework for music resizing with stretching and cropping</a></h3><div class="gs_a">Z Liu, <a href="/citations?user=2cAqDukAAAAJ&amp;hl=en&amp;oi=sra">C Wang</a>, Y Bai, H Wang, J Wang - Proceedings of the 19th ACM  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract Content-aware music adaption, ie music resizing, in temporal constraints starts <br>drawing attention from multimedia communities because of the need of real-world scenarios, <br>eg animation production and radio advertisement production. The goal of music resizing is <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16365374490920703488&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 1</a> <a href="/scholar?q=related:AFaRW2R9HeMJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'AFaRW2R9HeMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/t3086h1747710650.pdf" class=yC1D>Impulsive Environment Sound Detection by Neural Classification of Spectrogram and Mel-Frequency Coefficient Images</a></h3><div class="gs_a">P Khunarsa, C Lursinsap, T Raicharoen - Advances in Neural Network  &hellip;, 2010 - Springer</div><div class="gs_rs">The problem of automatic detecting impulsive sounds such as human sound (screams, <br>shout), gun shots, machine gun, thunder, fire alarm, and car horn are useful for hearing <br>impairment person. In this paper, instead of filtering the frequency of each sound for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14750481687401604342&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 1</a> <a href="/scholar?q=related:9iR6e_E8tMwJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14750481687401604342&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'9iR6e_E8tMwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://www.ecmlpkdd2009.net/wp-content/uploads/2008/09/machine-learning-and-music.pdf#page=13" class=yC1F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ecmlpkdd2009.net</span><span class="gs_ggsS">ecmlpkdd2009.net <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ecmlpkdd2009.net/wp-content/uploads/2008/09/machine-learning-and-music.pdf#page=13" class=yC1E>Detecting key features in popular music: case studyâsinging voice detection</a></h3><div class="gs_a">R NÃ³brega, <a href="/citations?user=GYSlP0UAAAAJ&amp;hl=en&amp;oi=sra">S Cavaco</a> - Proc. of the Workshop on Machine  &hellip;, 2009 - ecmlpkdd2009.net</div><div class="gs_rs">Abstract. Detecting distinct features in modern pop music is an important problem that can <br>have significant applications in areas such as multimedia entertainment. They can be used, <br>for example, to give a visually coherent representation of the sound. We propose to <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=693533957868979666&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 1</a> <a href="/scholar?q=related:0oVzznXtnwkJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=693533957868979666&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'0oVzznXtnwkJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md15', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md15" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:0oVzznXtnwkJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://tel.archives-ouvertes.fr/docs/00/52/93/31/PDF/main.pdf" class=yC21><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://tel.archives-ouvertes.fr/pastel-00529331/" class=yC20>Classification automatique de flux radiophoniques par Machines Ã  Vecteurs de Support</a></h3><div class="gs_a">M Ramona - 2010 - tel.archives-ouvertes.fr</div><div class="gs_rs">1.1 Vers une radio numÃ©rique......................... 9 1.2 Applications de l&#39;indexation audio pour la <br>radio............ 10 1.3 Â«Qu&#39;est-ce que la musique?Â»...................... 11 1.4 Classification par <br>Machines Ã  Vecteurs de Support.......... 12 1.5 ProblÃ©matiques................................ 13 1.6 <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13344670493018324694&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=34">Cited by 1</a> <a href="/scholar?q=related:1n7-PBzLMbkJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13344670493018324694&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'1n7-PBzLMbkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://institut17-1.kug.ac.at/fileadmin/media/iem/projects/2011/gampp_ti.pdf" class=yC23><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from kug.ac.at</span><span class="gs_ggsS">kug.ac.at <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://institut17-1.kug.ac.at/fileadmin/media/iem/projects/2011/gampp_ti.pdf" class=yC22>Evaluation of Robust Features for Singing Voice Detection</a></h3><div class="gs_a">P Gampp - institut17-1.kug.ac.at</div><div class="gs_rs">Abstract The detection of singing voice segments within music signals is an important object <br>of research in the field of music information retrieval, since it serves as an essential pre-<br>stage for applications like singer identification, lyrics recognition, singing melody <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:CMMZACBTsKIJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11722961226951148296&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'CMMZACBTsKIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md17', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md17" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:CMMZACBTsKIJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB18" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW18"><a href="http://www-kd.iai.uni-bonn.de/pubattachments/336/da.pdf" class=yC25><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uni-bonn.de</span><span class="gs_ggsS">uni-bonn.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www-kd.iai.uni-bonn.de/pubattachments/336/da.pdf" class=yC24>Melody Separation from Polyphonic Audio Recordings</a></h3><div class="gs_a">S Vembu - 2005 - www-kd.iai.uni-bonn.de</div><div class="gs_rs">Abstract In the field of music information retrieval, query-by-humming is an interesting <br>application area in which humming sequences or melodies are matched with a database of <br>songs to come up with a list of indexed songs that are similar in melodic content to the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Wa_TF3qsUOoJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16884184643397726041&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'Wa_TF3qsUOoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md18', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md18" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Wa_TF3qsUOoJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/5017hhu836400623.pdf" class=yC26>Adaptive music resizing with stretching, cropping and insertion</a></h3><div class="gs_a">Z Liu, C Wang, J Wang, H Wang, Y Bai - Multimedia Systems - Springer</div><div class="gs_rs">Abstract Content-aware music adaption, ie music resizing, in temporal constraints starts <br>drawing attention from multimedia communities, because there are plenty of real-world <br>scenarios, eg animation production and radio advertisement production. The goal of <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:pgInTEFeqssJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'pgInTEFeqssJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Monaural musical sound separation</h3><div class="gs_a"><a href="/citations?user=OCQSEIsAAAAJ&amp;hl=en&amp;oi=sra">Y Li</a> - 2008 - The Ohio State University</div><div class="gs_fl"><a href="/scholar?q=related:jpa0VTJdi4EJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9334657123423131278&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'jpa0VTJdi4EJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md20', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md20" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:jpa0VTJdi4EJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=14713022477718088856&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6337096" class=yC27>Exploiting Semantic Content for Singing Voice Detection</a></h3><div class="gs_a">I Leonidas, <a href="/citations?user=aWKht5IAAAAJ&amp;hl=en&amp;oi=sra">JL Rouas</a> - Semantic Computing (ICSC), 2012 IEEE &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper we propose a method for singing voice detection in popular music <br>recordings. The method is based on statistical learning of spectral features extracted from <br>the audio tracks. In our method we use Mel Frequency Cepstrum Coefficients (MFCC) to <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'4hP8YZ9abnMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB22" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW22"><a href="http://tel.archives-ouvertes.fr/docs/00/68/74/75/PDF/these.pdf" class=yC29><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://tel.archives-ouvertes.fr/tel-00687475/" class=yC28>Localisation, caractÃ©risation et reconnaissance de voix chantÃ©es</a></h3><div class="gs_a">L Regnier - 2012 - tel.archives-ouvertes.fr</div><div class="gs_rs">Many auditors have a remarkable ability to identify the singer of a new song as long as they <br>have already heard some songs performed by the same singer. When the singer is <br>unfamiliar it is common for listeners to attempt to characterize the singer&#39;s voice by finding <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ObV6dGA6ysYJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14324325750750754105&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'ObV6dGA6ysYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB23" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW23"><a href="https://ccrma.stanford.edu/~kglee/pubs/klee-sppra09-final.pdf" class=yC2B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from stanford.edu</span><span class="gs_ggsS">stanford.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.actapress.com/PaperInfo.aspx?PaperID=38587&amp;reason=500" class=yC2A>Automatic Labeling of Training Data for Singing Voice Detection in Musical Audio</a></h3><div class="gs_a">K Lee, M Cremer - Proceedings of the 6th IASTED International  &hellip;, 2009 - actapress.com</div><div class="gs_rs">AUTOMATIC LABELING OF TRAINING DATA FOR SINGING VOICE DETECTION IN MUSICAL<br>AUDIO Kyogu Lee Media Technology Lab, Gracenote 2000 Powell Street, Emeryville, CA94608,<br>USA klee@gracenote.com Markus Cremer Media Technology Lab, Gracenote 2000 <b>...</b> </div><div class="gs_fl"><a href="/scholar?q=related:_npQe5m2DPoJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18017976979517635326&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'_npQe5m2DPoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB24" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW24"><a href="http://193.136.122.112/img/files/archivemodule/@random49f9c25b31ba0/1241105061_AudioProjectFinalReport.pdf" class=yC2D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 193.136.122.112</span><span class="gs_ggsS">193.136.122.112 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://193.136.122.112/img/files/archivemodule/@random49f9c25b31ba0/1241105061_AudioProjectFinalReport.pdf" class=yC2C>Detecting key features in popular music: case studyâvoice detection</a></h3><div class="gs_a">R NÃ³brega - 193.136.122.112</div><div class="gs_rs">ABSTRACT Detecting distinct features in modern pop music is an important problem that <br>can have significant applications in areas such as multimedia entertainment. They can be <br>used, for example, to give a visually coherent representation of the sound. The work <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:UN2lj_WqVtcJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15516777537805344080&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'UN2lj_WqVtcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md24', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md24" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:UN2lj_WqVtcJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB25" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW25"><a href="http://www.ee.columbia.edu/~dpwe/e6820/proposals/felix.pdf" class=yC2F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from columbia.edu</span><span class="gs_ggsS">columbia.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ee.columbia.edu/~dpwe/e6820/proposals/felix.pdf" class=yC2E>Identifying singing segments in music</a></h3><div class="gs_a">FS Garcia - ee.columbia.edu</div><div class="gs_rs">Page 1. Identifying singing segments in music Felix Sanchez Garcia Page 2. Objective â¢<br>Given a music sample, identify singing segments Page 3. Difficulties â¢ It is hard to<br>model singing voice, it differs from normal speech â Mixed <b>...</b> </div><div class="gs_fl"><a href="/scholar?q=related:_vPzlY0xKEAJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4622999501671756798&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'_vPzlY0xKEAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md25', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md25" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:_vPzlY0xKEAJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB26" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW26"><a href="http://hal.inria.fr/docs/00/68/74/75/PDF/these.pdf" class=yC31><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from inria.fr</span><span class="gs_ggsS">inria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://hal.inria.fr/docs/00/68/74/75/PDF/these.pdf" class=yC30>L&#39;UNIVERSITE PIERRE ET MARIE CURIE</a></h3><div class="gs_a">ML Regnier - hal.inria.fr</div><div class="gs_rs">Many auditors have a remarkable ability to identify the singer of a new song as long as they <br>have already heard some songs performed by the same singer. When the singer is <br>unfamiliar it is common for listeners to attempt to characterize the singer&#39;s voice by finding <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:0HDPonzwK1wJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'0HDPonzwK1wJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md26', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md26" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:0HDPonzwK1wJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB27" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW27"><a href="https://repository.library.georgetown.edu/bitstream/handle/10822/552965/henryMichael.pdf?sequence=1" class=yC33><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from georgetown.edu</span><span class="gs_ggsS">georgetown.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="https://repository.library.georgetown.edu/handle/10822/552965" class=yC32>Learning techniques for identifying vocal regions in music using the wavelet transformation version 1.0</a></h3><div class="gs_a">M Henry - 2012 - repository.library.georgetown.edu</div><div class="gs_rs">Abstract In this research I present a machine learning method for the automatic detection of <br>vocal regions in music. I employ the wavelet transformation to extract wavelet coefficients, <br>from which I build feature sets capable of constructing a model that can distinguish <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:PpPPvEB0KowJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10100012935726207806&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'PpPPvEB0KowJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md27', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md27" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:PpPPvEB0KowJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=12517843942992201336&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB28" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW28"><a href="http://hal.inria.fr/docs/00/75/99/23/PDF/2012_Ioannidis.pdf" class=yC35><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from inria.fr</span><span class="gs_ggsS">inria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://hal.inria.fr/hal-00759923/" class=yC34>Exploiting Semantic Content for Singing Voice Detection</a></h3><div class="gs_a">L Ioannidis, <a href="/citations?user=aWKht5IAAAAJ&amp;hl=en&amp;oi=sra">JL Rouas</a> - Sixth IEEE International Conference on  &hellip;, 2012 - hal.inria.fr</div><div class="gs_rs">RÃ©sumÃ©: In this paper we propose a method for singing voice detection in popular music <br>recordings. The method is based on statistical learning of spectral features extracted from <br>the audio tracks. In our method we use Mel Frequency Cepstrum Coefficients (MFCC) to <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'FPZe7YSBj14J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB29" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW29"><a href="ftp://ftp.irisa.fr/techreports/theses/2006/ozerov.ps.gz" class=yC37><span class="gs_ggsL"><span class=gs_ctg2>[PS]</span> from irisa.fr</span><span class="gs_ggsS">irisa.fr <span class=gs_ctg2>[PS]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PS]</span><span class="gs_ct2">[PS]</span></span> <a href="ftp://ftp.irisa.fr/techreports/theses/2006/ozerov.ps.gz" class=yC36>devant l&#39;UniversitÃ© de Rennes</a></h3><div class="gs_a">A Ozerov - irisa.fr</div><div class="gs_rs">RÃ©sumÃ© La sÃ©paration de sources avec un seul capteur est un probleme tres rÃ©cent, qui <br>attire de plus en plus d&#39;attention dans le monde scientifique. Cependant, il est loin d&#39;Ãªtre <br>rÃ©solu et, mÃªme plus, il ne peut pas Ãªtre rÃ©solu en toute gÃ©nÃ©ralitÃ©. La difficultÃ© principale <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:uf_1BBnHTmsJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7732336520513060793&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'uf_1BBnHTmsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md29', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md29" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:uf_1BBnHTmsJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB30" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW30"><a href="http://www.atiam.ircam.fr/Archives/Stages0708/Regnier.pdf" class=yC39><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ircam.fr</span><span class="gs_ggsS">ircam.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.atiam.ircam.fr/Archives/Stages0708/Regnier.pdf" class=yC38>DÃ©tection de la voix chantÃ©e dans un morceau de musique</a></h3><div class="gs_a">L REGNIER - atiam.ircam.fr</div><div class="gs_rs">RÃ©sumÃ© De tous les Ã©lÃ©ments constitutifs d&#39;un morceau de musique, la voix est sans <br>conteste celui qui focalise le plus l&#39;attention de l&#39;auditeur. Ceci provient du fait que la voix est <br>porteuse d&#39;un message (le texte) et d&#39;une identitÃ© (celle du chanteur). Pour ces raisons, de <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:klX7IkhpWdMJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15229319373475501458&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'klX7IkhpWdMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md30', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md30" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:klX7IkhpWdMJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB31" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW31"><a href="http://eprints.fri.uni-lj.si/1169/1/Strupeh_D._-UN.pdf" class=yC3B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uni-lj.si</span><span class="gs_ggsS">uni-lj.si <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://eprints.fri.uni-lj.si/1169/" class=yC3A>HASH (0xbb3b6ea0)</a></h3><div class="gs_a">D Strupeh - 2010 - eprints.fri.uni-lj.si</div><div class="gs_rs">Abstract In this thesis the automatic recognition of groups in singing recordings is presented. <br>The classification of audio recordings or their parts into defined classes is useful particularly <br>at large record sets that carry a variety of useful research information. The manual record <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:XUEGKlAM1qEJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'XUEGKlAM1qEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB32" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW32"><a href="http://hal.inria.fr/docs/00/56/48/66/PDF/ozerov_these.pdf" class=yC3D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from inria.fr</span><span class="gs_ggsS">inria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://hal.inria.fr/tel-00564866/" class=yC3C>Adaptation de modÃ¨les statistiques pour la sÃ©paration de sources mono-capteur Texte imprimÃ©: application Ã  la sÃ©paration voix/musique dans les chansons</a></h3><div class="gs_a"><a href="/citations?user=LnV-0z0AAAAJ&amp;hl=en&amp;oi=sra">A Ozerov</a> - 2006 - hal.inria.fr</div><div class="gs_rs">RÃ©sumÃ©: La sÃ©paration de sources avec un seul capteur est un problÃ¨me trÃ¨s rÃ©cent, qui <br>attire de plus en plus d&#39;attention dans le monde scientifique. Cependant, il est loin d&#39;Ãªtre <br>rÃ©solu et, mÃªme plus, il ne peut pas Ãªtre rÃ©solu en toute gÃ©nÃ©ralitÃ©. La difficultÃ© principale <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:IqQDpNdyi08J:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5731801221254325282&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'IqQDpNdyi08J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:367"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/95659x/200905/30314191.html" class=yC3E>åºäºé«æ¯æ··åæ¨¡åæµè¡é³ä¹ä¸­æ­å±é¨åçæºè½æ£æµ</a></h3><div class="gs_a">æä¸½å¨ï¼ å¶èï¼ èµµæ¬£ - å°åå¾®åè®¡ç®æºç³»ç», 2009 - cqvip.com</div><div class="gs_rs">ææå°æ£æµåºæµè¡é³ä¹ä¸­çæ­å±é¨åå¯¹å¨æµ·éæ°æ®åºä¸­è¿è¡é³ä¹æ£ç´¢, æµè§, å½ç±», <br>ä»¥åæå¾æååæ­å±å®¶è¯å«ç­æè¾å¤§çä»·å¼. æ¬æä½¿ç¨å¨è¯­é³ä¿¡å·å¤çä¸­å¹¿æ³ä½¿ç¨çåºäºæ¢å°<br>é¢ççåè°±ç³»æ°(MFCC) ä½ä¸ºè¯­é³ç¹å¾æ¥åææè¦å¤ççé³ä¹ä¿¡å·, å¹¶éç¨é«æ¯æ··åæ¨¡å(<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:10Pnsd-bS1QJ:scholar.google.com/&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6074119907503981527&amp;hl=en&amp;num=34&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'10Pnsd-bS1QJ')" href="#" class="gs_nph">Cite</a></div></div></div>
