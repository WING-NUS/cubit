Total results = 8
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://csce.uark.edu/~jgauch/library/Video/Yang.2003b.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uark.edu</span><span class="gs_ggsS">uark.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=957146" class=yC0>VideoQA: question answering on news video</a></h3><div class="gs_a">H Yang, L Chaisorn, Y Zhao, SY Neo&hellip; - Proceedings of the  &hellip;, 2003 - dl.acm.org</div><div class="gs_rs">Abstract When querying a news video archive, the users are interested in retrieving precise <br>answers in the form of a summary that best answers the query. However, current video <br>retrieval systems, including the search engines on the web, are designed to retrieve <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12408849427244413797&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 80</a> <a href="/scholar?q=related:ZXM2Js8WNawJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12408849427244413797&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 30 versions</a> <a onclick="return gs_ocit(event,'ZXM2Js8WNawJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.68.1833&amp;rep=rep1&amp;type=pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1321510" class=yC2>The role of documents vs. queries in extracting class attributes from text</a></h3><div class="gs_a">M PaÅca, <a href="/citations?user=wIujAJoAAAAJ&amp;hl=en&amp;oi=sra">B Van Durme</a>, N Garera - &hellip;  of the sixteenth ACM conference on  &hellip;, 2007 - dl.acm.org</div><div class="gs_rs">Abstract Challenging the implicit reliance on document collections, this paper discusses the <br>pros and cons of using query logs rather than document collections, as self-contained <br>sources of data in textual information extraction. The differences are quantified as part of a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1526992522191804532&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 22</a> <a href="/scholar?q=related:dJjry5v3MBUJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1526992522191804532&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 23 versions</a> <a onclick="return gs_ocit(event,'dJjry5v3MBUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/92817x/200511/20607117.html" class=yC4>èªå¨é®ç­ç³»ç»ä¸­çé®é¢çè§£ç ç©¶</a></h3><div class="gs_a">æ¹å¿å¨ï¼ æç¥æ¢ï¼ åææ¶ - è®¡ç®æºç§å­¦, 2006 - cqvip.com</div><div class="gs_rs">é®é¢çè§£æ¯é®ç­ç³»ç»çé¦è¦çåæå·¥ä½, åæçç»æå¯¹åé¢çå¤ç, ä»¥è³æ¾å°é®é¢çæ­£ç¡®ç­æ¡é½<br>æå¾å¤§çå½±å. æ¬æå°å¯¹å¸¸è§çé®é¢çè§£æ¹æ³è¿è¡æ¹è¿, ä»èä½¿ç³»ç»è½å¤è¾åç¡®å°åç­ç¨æ·ç<br>æé®. å®éªè¯ææ°çæ¹æ³å¯¹æé«ç³»ç»æ§è½ææ¾èä½ç¨, å°¤å¶éå¯¹æ§å¼º, ææè¡¨è¿°æ¸æ°çæé®, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13488205564966783777&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 6</a> <a href="/scholar?q=related:IctKbX-7L7sJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13488205564966783777&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'IctKbX-7L7sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://onlinelibrary.wiley.com/doi/10.1002/asi.20685/full" class=yC5>Questionâdriven segmentation of lecture speech text: Towards intelligent eâlearning systems</a></h3><div class="gs_a">M Lin, Z Zhang - Journal of the American Society for Information &hellip;, 2008 - Wiley Online Library</div><div class="gs_rs">Abstract Recently, lecture videos have been widely used in e-learning systems. Envisioning <br>intelligent e-learning systems, this article addresses the challenge of information seeking in <br>lecture videos by retrieving relevant video segments based on user queries, through <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13424008104015571376&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 1</a> <a href="/scholar?q=related:sCnQRT-oS7oJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/37/1A/RN221364026.html?source=googlescholar" class="gs_nph" class=yC6>BL Direct</a> <a href="/scholar?cluster=13424008104015571376&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'sCnQRT-oS7oJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://arizona.openrepository.com/arizona/bitstream/10150/193843/1/azu_etd_1730_sip1_m.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from openrepository.com</span><span class="gs_ggsS">openrepository.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://arizona.openrepository.com/arizona/handle/10150/193843" class=yC7>Automated Lecture Video Segmentation: Facilitate Content Browsing and Retrieval</a></h3><div class="gs_a">M Lin - 2006 - arizona.openrepository.com</div><div class="gs_rs">People often have difficulties finding specific information in video because of its linear and <br>unstructured nature. Segmenting long videos into small clips by topics and providing <br>browsing and search functionalities is beneficial for information searching. However, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10110024824933819945&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 1</a> <a href="/scholar?q=related:KaaPWAMGTowJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10110024824933819945&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'KaaPWAMGTowJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md4', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md4" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:KaaPWAMGTowJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=14262242278056286698&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://newdesign.aclweb.org/anthology/C/C10/C10-2149.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aclweb.org</span><span class="gs_ggsS">aclweb.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1944715" class=yC9>Automatic generation of semantic fields for annotating web images</a></h3><div class="gs_a">G Wang, TS Chua, <a href="/citations?user=jk5DWVMAAAAJ&amp;hl=en&amp;oi=sra">CW Ngo</a>, YC Wang - Proceedings of the 23rd  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract The overwhelming amounts of multimedia contents have triggered the need for <br>automatically detecting the semantic concepts within the media contents. With the <br>development of photo sharing websites such as Flickr, we are able to obtain millions of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16309016145247876043&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 1</a> <a href="/scholar?q=related:yzOcdcZDVeIJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16309016145247876043&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'yzOcdcZDVeIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4593805" class=yCB>A way of Chinese Question Analysis and its&#39; implement</a></h3><div class="gs_a">C Liu, Z Li - Intelligent Control and Automation, 2008. WCICA  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Question analysis is the primary task of question answering system. Performing <br>Interrogative phrase classification based on the chinese interrogative phrases and their <br>usages before parsing words can reduce the influence of the parsing errors to question <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6290273220691469327&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=8">Cited by 1</a> <a href="/scholar?q=related:D6R3uyqKS1cJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'D6R3uyqKS1cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://www.mirlab.org/conference_papers/International_Conference/ISCSLP%202006/pdfs/B60.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mirlab.org</span><span class="gs_ggsS">mirlab.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.isca-speech.org/archive_open/archive_papers/iscslp2006/B60.pdf" class=yCC>SpeechQoogle: An Open-Domain Question Answering System with Speech Interface</a></h3><div class="gs_a">G Hu, D Liu, Q Liu, R Wang - isca-speech.org</div><div class="gs_rs">Abstract. In this paper, we propose a new and valuable research task: opendomain question <br>answering system with speech interface, and first prototype (SpeechQoogle) is constructed <br>with three separated modules: speech recognition, question answering (QA) and speech <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:frmLUNMt_jEJ:scholar.google.com/&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3602367137555659134&amp;hl=en&amp;num=8&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'frmLUNMt_jEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
