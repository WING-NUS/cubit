Total results = 16
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.comp.nus.edu.sg/~tancl/publications/j2010/TCSVT4004-FinalPDF.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5585735" class=yC0>New Fourier-statistical features in RGB space for video text detection</a></h3><div class="gs_a">P Shivakumara, <a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>&hellip; - Circuits and Systems for  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose new Fourier-statistical features (FSF) in RGB space for <br>detecting text in video frames of unconstrained background, different fonts, different scripts, <br>and different font sizes. This paper consists of two parts namely automatic classification of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8338467067798852630&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16">Cited by 9</a> <a href="/scholar?q=related:FpRxe54vuHMJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8338467067798852630&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'FpRxe54vuHMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://vision.eecs.ucf.edu/papers/cvpr2011/WATER_CVPR2011.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ucf.edu</span><span class="gs_ggsS">ucf.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5995428" class=yC2>A two-stage reconstruction approach for seeing through water</a></h3><div class="gs_a"><a href="/citations?user=608EgncAAAAJ&amp;hl=en&amp;oi=sra">O Oreifej</a>, G Shu, T Pace, <a href="/citations?user=p8gsO3gAAAAJ&amp;hl=en&amp;oi=sra">M Shah</a> - Computer Vision and  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Several attempts have been lately proposed to tackle the problem of recovering the <br>original image of an underwater scene using a sequence distorted by water waves. The <br>main drawback of the state of the art [18] is that it heavily depends on modelling the waves<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8372730493210665176&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16">Cited by 4</a> <a href="/scholar?q=related:2CDn3wXqMXQJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8372730493210665176&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'2CDn3wXqMXQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www.icdar2011.org/fileup/PDF/4520b120.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from icdar2011.org</span><span class="gs_ggsS">icdar2011.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6065484" class=yC4>Edge-Based Features for Localization of Artificial Urdu Text in Video Images</a></h3><div class="gs_a">A Jamil, <a href="/citations?user=G4CYRhIAAAAJ&amp;hl=en&amp;oi=sra">I Siddiqi</a>, F Arif, A Raza - Document Analysis and  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Content-based video indexing and retrieval has become an interesting research <br>area with the tremendous growth in the amount of digital media. In addition to the audio-<br>visual content, text appearing in videos can serve as a powerful tool for semantic indexing <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=466618579049495806&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16">Cited by 4</a> <a href="/scholar?q=related:_rzXGSDDeQYJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=466618579049495806&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'_rzXGSDDeQYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://www-ee.ccny.cuny.edu/www/web/yltian/Publications/CBDAR2011_PostProceedings.PDF" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cuny.edu</span><span class="gs_ggsS">cuny.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/E157X3555V74M3JK.pdf" class=yC6>Assistive text reading from complex background for blind persons</a></h3><div class="gs_a">C Yi, <a href="/citations?user=aAWeB4wAAAAJ&amp;hl=en&amp;oi=sra">Y Tian</a> - Camera-Based Document Analysis and Recognition, 2012 - Springer</div><div class="gs_rs">In the paper, we propose a camera-based assistive system for visually impaired or blind <br>persons to read text from signage and objects that are held in the hand. The system is able <br>to read text from complex backgrounds and then communicate this information aurally. To <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15229765554693441120&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16">Cited by 4</a> <a href="/scholar?q=related:YIb7yxT_WtMJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15229765554693441120&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'YIb7yxT_WtMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5560063" class=yC8>Mash up of Breaking News and Contextual Web Information: A Novel Service for Connected Television</a></h3><div class="gs_a"><a href="/citations?user=ugI69q0AAAAJ&amp;hl=en&amp;oi=sra">T Chattopadhyay</a>, <a href="/citations?user=hkKS-xsAAAAJ&amp;hl=en&amp;oi=sra">A Pal</a>&hellip; - &hellip;  and Networks (ICCCN),  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The Connected TV can be described as an Internet enabled TV. In the current <br>paper we have proposed a system for connected TV that mash up the information from <br>internet and RSS feeds related to the breaking news aired over the TV. The proposed <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14225660364296598291&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16">Cited by 2</a> <a href="/scholar?q=related:E7NABbuya8UJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'E7NABbuya8UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320311000550" class=yC9>A novel mutual nearest neighbor based symmetry for text frame classification in video</a></h3><div class="gs_a">P Shivakumara, A Dutta, <a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">T Quy Phan</a>, C Lim Tan&hellip; - Pattern Recognition, 2011 - Elsevier</div><div class="gs_rs">In the field of multimedia retrieval in video, text frame classification is essential for text <br>detection, event detection, event boundary detection, etc. We propose a new text frame <br>classification method that introduces a combination of wavelet and median moment with k-<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11993170311716469446&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16">Cited by 2</a> <a href="/scholar?q=related:xvqeINtMcKYJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11993170311716469446&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'xvqeINtMcKYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5580484" class=yCA>Video text detection and localization based on localized generalization error model</a></h3><div class="gs_a">XH Ma, WWY Ng, PPK Chan&hellip; - Machine Learning and  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Texts in videos provide plenteous information for video analysis such as video <br>indexing, understanding and retrieval. We propose a neural network based method <br>detecting text in the video frames in this work. The proposed method consists of three <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14453146945092005100&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16">Cited by 2</a> <a href="/scholar?q=related:7Cy7DJLkk8gJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'7Cy7DJLkk8gJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6195336" class=yCB>Recent Advances in Video Based Document Processing: A Review</a></h3><div class="gs_a"><a href="/citations?user=JzinqNcAAAAJ&amp;hl=en&amp;oi=sra">N Sharma</a>, <a href="/citations?user=2_z_CogAAAAJ&amp;hl=en&amp;oi=sra">U Pal</a>, M Blumenstein - Document Analysis Systems &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Extraction and recognition of text present in video has become a very popular <br>research area in the last decade. Generally, text present in video frames is of different size, <br>orientation, style, etc. with complex backgrounds, noise, low resolution and contrast. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2870249651013170216&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16">Cited by 3</a> <a href="/scholar?q=related:KDRUsdks1ScJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2870249651013170216&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'KDRUsdks1ScJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/776215603u23x600.pdf" class=yCC>Detecting both superimposed and scene text with multiple languages and multiple alignments in video</a></h3><div class="gs_a">X Huang, H Ma, CX Ling, G Gao - Multimedia Tools and Applications, 2012 - Springer</div><div class="gs_rs">Abstract Video text often contains highly useful semantic information that can contribute <br>significantly to video retrieval and understanding. Video text can be classified into scene text <br>and superimposed text. Most of the previous methods detect superimposed or scene text <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:aJcOfW9_KYwJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'aJcOfW9_KYwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/F55628W47273P821.pdf" class=yCD>Using adaptive run length smoothing algorithm for accurate text localization in images</a></h3><div class="gs_a">M Rais, N Goussies, M Mejail - Progress in Pattern Recognition, Image  &hellip;, 2011 - Springer</div><div class="gs_rs">Text information in images and videos is frequently a key factor for information indexing and <br>retrieval systems. However, text detection in images is a difficult task since it is often <br>embedded in complex backgrounds. In this paper, we propose an accurate text detection <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:2QLGi382ooIJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9413146092591514329&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'2QLGi382ooIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0957417412004800" class=yCE>A robust video text detection approach using SVM</a></h3><div class="gs_a">YC Wei, <a href="/citations?user=9-S7q8UAAAAJ&amp;hl=en&amp;oi=sra">CH Lin</a> - Expert Systems with Applications, 2012 - Elsevier</div><div class="gs_rs">A new method for detecting text in video images is proposed in this article. Variations in <br>background complexity, font size and color, make detecting text regions in video images a <br>difficult task. A pyramidal scheme is utilized to solve these problems. First, two downsized <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:i6DLi_p9x8UJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14251498060877897867&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'i6DLi_p9x8UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://cdn.intechweb.org/pdfs/11406.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from intechweb.org</span><span class="gs_ggsS">intechweb.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://cdn.intechweb.org/pdfs/11406.pdf" class=yCF>Recognition of Characters from Streaming Videos</a></h3><div class="gs_a"><a href="/citations?user=ugI69q0AAAAJ&amp;hl=en&amp;oi=sra">T Chattopadhyay</a>, <a href="/citations?user=hkKS-xsAAAAJ&amp;hl=en&amp;oi=sra">A Pal</a>, <a href="/citations?user=TrdrjEQAAAAJ&amp;hl=en&amp;oi=sra">A Sinha</a> - cdn.intechweb.org</div><div class="gs_rs">Over the past few years, Video has become one of the prime source for recreation, be it <br>Television or Internet. Television brings a whole lot of professionally produced video content <br>(International or local, sports or educational, news or entertainment) to the home for the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10036602239941883215&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16">Cited by 1</a> <a href="/scholar?q=related:TzWgn48sSYsJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10036602239941883215&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'TzWgn48sSYsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md11', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md11" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:TzWgn48sSYsJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6405797" class=yC11>A Survey on Video Caption Extraction Technology</a></h3><div class="gs_a">Z Wang, L Yang, X Wu, Y Zhang - &hellip;  Information Networking and  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Video caption extraction has become a very popular research area in the last few <br>decades. Many reasons makes it a challenging task. A large number of techniques have <br>been proposed to address this problem. This paper reviews the progress in this area and <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'Q1IzsQRzLusJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.actapress.com/PDFViewer.aspx?paperId=451959" class=yC12>Gradient Difference Base Algorithm for Edge Detection for Localization of License Plates in Images</a></h3><div class="gs_a">C Nguyen, A Raheja - Robotics and Applications with Symposia 739 &hellip;, 2011 - actapress.com</div><div class="gs_rs">ABSTRACT This paper presents a novel morphological and gradient difference based <br>approach for locating vehicle license plates in natural background images. The proposed <br>algorithm uses a gradient difference method on grayscale license plate images (converted <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:VcaQ4xL6H98J:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16077844153770231381&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'VcaQ4xL6H98J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> New SVD-Statistical Features in RGB Space for Video Text Detection</h3><div class="gs_a">P Shivakumara, <a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a></div><div class="gs_fl"><a href="/scholar?q=related:IkKe89j4CdMJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'IkKe89j4CdMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.dbpia.co.kr/view/ar_view.asp?arid=1760617" class=yC13>ë ì´ë¸ë§ ê¸°ë²ê³¼ ë°ê¸°ê° ë³íì ê¸°ë°í ì»¬ë¬ììì ë¬¸ììì­ ì¶ì¶ ë°©ë²</a></h3><div class="gs_a">ì¡°ì§ì - íêµ­ì½íì¸ ííë¼ë¬¸ì§, 2011 - dbpia.co.kr</div><div class="gs_rs">&amp;nbsp; &amp;nbsp; ìì ìì¶ë ¥ ì¥ì¹ ì¬ì©ì´ ì¦ê°í¨ì ë°ë¼ ì»¬ë¬ìì ë´ ë¬¸ììì­ ì¶ì¶ì ì¤ìì± <br>ëí ëìì§ê³  ìë¤. ë³¸ ë¼ë¬¸ì ì´ë¬í ìì ë´ ë¬¸ììì­ì í¨ê³¼ì ì¼ë¡ ì¶ì¶íê¸° ìí´ ë ì´ë¸ë§ <br>ê¸°ë²ê³¼ íì ë¨ìì ë°ê¸°ê° ë³íì ê¸°ë°í ë¬¸ììì­ ì¶ì¶ ë°©ë²ì ì ìíë¤. ì ìíë ë°©ë²ì <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Vnf1caYt7qcJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Vnf1caYt7qcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
