Total results = 20
<div class="gs_r" style="z-index:400"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S1047320307000247" class=yC0>Video summarisation: A conceptual framework and survey of the state of the art</a></h3><div class="gs_a">AG Money, H Agius - Journal of Visual Communication and Image  &hellip;, 2008 - Elsevier</div><div class="gs_rs">Video summaries provide condensed and succinct representations of the content of a video <br>stream through a combination of still images, video segments, graphical representations and <br>textual descriptors. This paper presents a conceptual framework for video summarisation <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7380321859487654168&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=20">Cited by 129</a> <a href="/scholar?q=related:GOHP6qArbGYJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7380321859487654168&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'GOHP6qArbGYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://www.cs.nthu.edu.tw/~cthsu/papers/highlight_MM06.pdf" class=yC2><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nthu.edu.tw</span><span class="gs_ggsS">nthu.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1632043" class=yC1>Fusion of audio and motion information on HMM-based highlight extraction for baseball games</a></h3><div class="gs_a">CC Cheng, CT Hsu - Multimedia, IEEE Transactions on, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper aims to extract baseball game highlights based on audio-motion <br>integrated cues. In order to better describe different audio and motion characteristics in <br>baseball game highlights, we propose a novel representation method based on likelihood <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5524472719226896540&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=20">Cited by 42</a> <a href="/scholar?q=related:nADbEKveqkwJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/58/15/RN196047108.html?source=googlescholar" class="gs_nph" class=yC3>BL Direct</a> <a href="/scholar?cluster=5524472719226896540&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'nADbEKveqkwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.66.1178&amp;rep=rep1&amp;type=pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1076097" class=yC4>Automatic music video summarization based on audio-visual-text analysis and alignment</a></h3><div class="gs_a">C Xu, X Shao, NC Maddage&hellip; - Proceedings of the 28th  &hellip;, 2005 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we propose a novel approach for automatic music video <br>summarization based on audio-visual-text analysis and alignment. The music video is <br>separated into the music and video tracks. For the music track, the chorus is detected <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4445671957548823743&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=20">Cited by 17</a> <a href="/scholar?q=related:v_ScWRczsj0J:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4445671957548823743&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'v_ScWRczsj0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0306437905001250" class=yC6>The priority curve algorithm for video summarization</a></h3><div class="gs_a"><a href="/citations?user=s6zNFvAAAAAJ&amp;hl=en&amp;oi=sra">M Albanese</a>, M Fayzullin, <a href="/citations?user=LoUsybEAAAAJ&amp;hl=en&amp;oi=sra">A Picariello</a>&hellip; - Information Systems, 2006 - Elsevier</div><div class="gs_rs">In this paper, we introduce the concept of a priority curve associated with a video. We then <br>provide an algorithm that can use the priority curve to create a summary (of a desired length) <br>of any video. The summary thus created exhibits nice continuity properties and also <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1564161695970602083&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=20">Cited by 13</a> <a href="/scholar?q=related:Y6yZc8YEtRUJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1564161695970602083&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'Y6yZc8YEtRUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.4943&amp;rep=rep1&amp;type=pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1418832" class=yC7>A new approach to automatic music video summarization</a></h3><div class="gs_a">X Shao, C Xa, MS Kankanhalli - Image Processing, 2004. ICIP&#39; &hellip;, 2004 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract A new automatic summarization approach for music videos is presented. The <br>proposed method detects and recognizes lyric captions appearing commonly in karaoke <br>music videos and uses the captions to analyze music video structure and identify the most <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16663876692069623895&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=20">Cited by 11</a> <a href="/scholar?q=related:V6i4-4_7QecJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16663876692069623895&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'V6i4-4_7QecJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://www2.ifi.auf.org/personnel/Alain.Boucher/publis/cbmi2007-tmartin-aboucher-jmogier-mrossignol-ecastelli.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from auf.org</span><span class="gs_ggsS">auf.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4275076" class=yC9>Multimedia scenario extraction and content indexing for e-learning</a></h3><div class="gs_a">T Martin, <a href="/citations?user=bqmDokEAAAAJ&amp;hl=en&amp;oi=sra">A Boucher</a>, JM Ogier&hellip; - &hellip; , 2007. CBMI&#39;07.  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present the use of multimodal content analysis in the MARVEL <br>(multimodal analysis of recorded video for e-learning) project. In this project, we record <br>teachers giving their lectures in class and semi-automatically analyze the video-audio <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13561628763945541974&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=20">Cited by 2</a> <a href="/scholar?q=related:VqGxGoKVNLwJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13561628763945541974&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'VqGxGoKVNLwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/90131x/200602/21334132.html" class=yCB>åºäºæ ·æ¬çæµè¡æ­æ²å³é®æ®µåå²æ¹æ³</a></h3><div class="gs_a">å¼ ä¸å½¬ï¼ å¨æ°ï¼ è¾¹èç¥º - çµå­å­¦æ¥, 2006 - cqvip.com</div><div class="gs_rs">æµè¡æ­æ²çå³é®æ®µä¸ºæ­æ²ä¸­æè½æå¨äºº, ç»äººå°è±¡ææ·±å»çä¸ä¸ªå®æ´çæ®µ, å°å®åå²åºæ¥å¯ç¨äº<br>é³ä¹è¯å¬ååºäºåå®¹çé³ä¹åç±», æ£ç´¢, ç®¡ç. éè¿å¯¹äººå·¥æªåçæ ·æ¬è¿è¡åæ, <br>æ¬ææåºäºä¸ç§æµè¡æ­æ²å³é®æ®µèªå¨åå²æ¹æ³, å®éªç»æè¡¨æ, æ­¤æ¹æ³å¯ä»¥æ¯è¾åç¡®åææå°<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17489437690957351949&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=20">Cited by 4</a> <a href="/scholar?q=related:DUzXuur2tvIJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17489437690957351949&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'DUzXuur2tvIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://pastel.archives-ouvertes.fr/docs/00/50/05/79/PDF/thesis.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://pastel.archives-ouvertes.fr/pastel-00002805/" class=yCC>Transcription des signaux percussifs. Application Ã  l&#39;analyse de scÃ¨nes musicales audiovisuelles</a></h3><div class="gs_a"><a href="/citations?user=sHkl_ZgAAAAJ&amp;hl=en&amp;oi=sra">O Gillet</a> - 2007 - pastel.archives-ouvertes.fr</div><div class="gs_rs">Je tiens d&#39;aborda remercier mon directeur de these GaÃ«l Richard pour avoir su faire <br>converger mes motivations et intÃ©rÃªts personnels vers le domaine de l&#39;indexation audio, <br>jusqu&#39;au choix du sujet de cette these, vaste, riche, mais aussi parfois dÃ©routant. Il a sua <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8881040292480709146&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=20">Cited by 2</a> <a href="/scholar?q=related:GnI-nRfLP3sJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8881040292480709146&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'GnI-nRfLP3sJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md7', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md7" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:GnI-nRfLP3sJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=4373481126579171580&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.129.3606&amp;rep=rep1&amp;type=pdf" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.129.3606&amp;rep=rep1&amp;type=pdf" class=yCE>Multimodal interactions for multimedia content analysis</a></h3><div class="gs_a">T Martin, <a href="/citations?user=bqmDokEAAAAJ&amp;hl=en&amp;oi=sra">A Boucher</a>, JM Ogier - Proc. of ICTACS 2006, 2006 - Citeseer</div><div class="gs_rs">ABSTRACT In this paper, we are presenting a model for multimodal content analysis. We <br>are distinguishing between media and modality, which helps us to define and to <br>characterize 3 inter-modal relations. Then we are applying this model for recorded course <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7349675423972659117&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=20">Cited by 1</a> <a href="/scholar?q=related:rQ9PnNtK_2UJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7349675423972659117&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'rQ9PnNtK_2UJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md8', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md8" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:rQ9PnNtK_2UJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.fedoa.unina.it/577/" class=yC10>Extracting and summarizing information from large data repositories</a></h3><div class="gs_rs"><a href="https://support.google.com/websearch/bin/answer.py?answer=45449&hl=en">This site may harm your computer.</a></div><div class="gs_a"><a href="/citations?user=s6zNFvAAAAAJ&amp;hl=en&amp;oi=sra">M Albanese</a> - 2006 - fedoa.unina.it</div><div class="gs_rs">Information retrieval from large data repositories has become an important area of computer <br>science. Research in this field is highly encouraged by the ever-increasing rate with which <br>today&#39;s society is able to produce digital data. Unfortunately most of such data (eg video <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5189732247905998015&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=20">Cited by 2</a> <a href="/scholar?q=related:v5TTq_uhBUgJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5189732247905998015&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'v5TTq_uhBUgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://wpage.unina.it/malbanes/pdf/phd_thesis_albanese.pdf" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unina.it</span><span class="gs_ggsS">unina.it <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://wpage.unina.it/malbanes/pdf/phd_thesis_albanese.pdf" class=yC11>UNIVERSITA&#39;DEGLI STUDI DI NAPOLI FEDERICO II</a></h3><div class="gs_a">FLD REPOSITORIES - 2005 - wpage.unina.it</div><div class="gs_rs">Abstract Information retrieval from large data repositories has become an important area of <br>computer science. Research in this field is highly encouraged by the ever-increasing rate <br>with which today&#39;s society is able to produce digital data. Unfortunately most of such data (<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:cnqsXGGbwUwJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5530872659856620146&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'cnqsXGGbwUwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md10', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md10" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:cnqsXGGbwUwJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://137.132.14.55/bitstream/handle/10635/14402/thesis.pdf?sequence=1" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.14.55</span><span class="gs_ggsS">137.132.14.55 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://137.132.14.55/handle/10635/14402" class=yC13>Event detection in soccer video based on audio/visual keywords</a></h3><div class="gs_a">K YULIN - 2004 - 137.132.14.55</div><div class="gs_rs">In this thesis, we propose a multi-modal two-level event detection framework and <br>demonstrate it on soccer videos. We use a mid-level representation called Audio and Visual <br>Keyword (AVK) that can be learned and detected in video segments. AVKs are intended to <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:8u8rejdXeoUJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9618095849987633138&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'8u8rejdXeoUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.google.com/patents?hl=en&amp;lr=&amp;vid=USPAT8013229&amp;id=c0jtAQAAEBAJ&amp;oi=fnd&amp;printsec=abstract" class=yC15>Automatic creation of thumbnails for music videos</a></h3><div class="gs_a">C Xu - US Patent 8,013,229, 2011 - Google Patents</div><div class="gs_rs">There is provided a method for automatically creating a music video thumbnail (50) from a <br>music video signal (12). The music video signal is separated into a music signal (16) and a <br>video signal (18). The music signal is analysed by detecting similarity regions and the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:joE1fTcSfmEJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7025072498277712270&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'joE1fTcSfmEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4589983" class=yC16>Automatic summarization for popular songs</a></h3><div class="gs_a">M Guo, H Zhang - &hellip;  and Image Processing, 2008. ICALIP 2008.  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present an automatic summarization approach for popular songs. <br>The approach includes two stages. First, a rough summary of the song is extracted efficiently <br>by the energy information and the songpsilas structure, and then the segment boundaries <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:xauRgvb2uAoJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'xauRgvb2uAoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Lawn Tennis Video Summarization based on Audiovisual and Text Feature Analysis</h3><div class="gs_a">SS Kanade, PM Patil - International  &hellip;, 2012 - Foundation of Computer Science ( &hellip;</div><div class="gs_fl"><a href="/scholar?q=related:M6D9hdcBcokJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9903980555718729779&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'M6D9hdcBcokJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://psrcentre.org/images/extraimages/1211693.pdf" class=yC18><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psrcentre.org</span><span class="gs_ggsS">psrcentre.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://psrcentre.org/images/extraimages/1211693.pdf" class=yC17>Dominant Audio Energy Based Key Frame Extraction for Sports Video Summarization</a></h3><div class="gs_a">SS Kanade, PM Patil - psrcentre.org</div><div class="gs_rs">AbstractâIn this paper, a new approach for key frame extraction for sports video <br>summarization is presented. Our approach employs dominant value of shot volume and <br>energy. For the dominant value of each shot audio energy corresponding video key frame <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:frI2pSejxiEJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'frI2pSejxiEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md15', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md15" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:frI2pSejxiEJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> M. Albanese 2, C. Cesarano 2, M. Fayzullin 3, A. Picariello 2 and VS Subrahmanian 3</h3><div class="gs_a">B Furht - Springer</div><div class="gs_fl"><a href="/scholar?q=related:Vaioq0cRNecJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Vaioq0cRNecJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.actapress.com/PaperInfo.aspx?PaperID=32566&amp;reason=500" class=yC19>A fast algorithm for automatic key segment extraction for popular songs</a></h3><div class="gs_a">Y Zhang, J Zhou, X Wang - Signal Processing, Pattern Recognition,  &hellip;, 2008 - actapress.com</div><div class="gs_rs">A FAST ALGORITHM FOR AUTOMATIC KEY SEGMENT EXTRACTION FOR POPULAR SONGS<br>Yibin Zhang1 , Jie Zhou2 , Xia Wang1 1 Nokia research center, Beijing, China, 100013 2<br>Department of automation, tsinghua university, Beijing, China, 100084 Ext-yibin.1.zhang <b>...</b> </div><div class="gs_fl"><a href="/scholar?q=related:cn1HsRzOm7oJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13446567735073406322&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'cn1HsRzOm7oJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB18" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW18"><a href="http://hal.inria.fr/docs/00/50/05/79/PDF/thesis.pdf" class=yC1B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from inria.fr</span><span class="gs_ggsS">inria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://hal.inria.fr/docs/00/50/05/79/PDF/thesis.pdf" class=yC1A>Olivier Gillet</a></h3><div class="gs_a">MLG Rapporteur - hal.inria.fr</div><div class="gs_rs">Je tiens d&#39;aborda remercier mon directeur de these GaÃ«l Richard pour avoir su faire <br>converger mes motivations et intÃ©rÃªts personnels vers le domaine de l&#39;indexation audio, <br>jusqu&#39;au choix du sujet de cette these, vaste, riche, mais aussi parfois dÃ©routant. Il a sua <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'FOH6BXjkkdoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md18', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md18" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:FOH6BXjkkdoJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="http://www2.ifi.auf.org/personnel/Alain.Boucher/recherche/these-Thomas_Martin.pdf" class=yC1D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from auf.org</span><span class="gs_ggsS">auf.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www2.ifi.auf.org/personnel/Alain.Boucher/recherche/these-Thomas_Martin.pdf" class=yC1C>Vers une reconnaissance multimodale du texte et de la parole pour l&#39;analyse de documents vidÃ©os pÃ©dagogiques</a></h3><div class="gs_a">ED SPIA, T Martin - ifi.auf.org</div><div class="gs_rs">RÃ©sumÃ© Cette thÃ¨se s&#39; intÃ©resse Ã  la mise en Åuvre de mÃ©thodes de reconnaissance <br>multimodale du texte et de la parole dans des contenus audiovisuels. Elle se focalise en <br>particulier sur les enregistrements de cours prÃ©sentiels, dans lesquels est fait un usage <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:66HvmB7VNeYJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16588399129880666603&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'66HvmB7VNeYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md19', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md19" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:66HvmB7VNeYJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
