Total results = 17
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.comp.nus.edu.sg/~tancl/publications/j2010/TCSVT4004-FinalPDF.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5585735" class=yC0>New Fourier-statistical features in RGB space for video text detection</a></h3><div class="gs_a">P Shivakumara, <a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>&hellip; - Circuits and Systems for  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose new Fourier-statistical features (FSF) in RGB space for <br>detecting text in video frames of unconstrained background, different fonts, different scripts, <br>and different font sizes. This paper consists of two parts namely automatic classification of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8338467067798852630&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 9</a> <a href="/scholar?q=related:FpRxe54vuHMJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8338467067798852630&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'FpRxe54vuHMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5560063" class=yC2>Mash up of Breaking News and Contextual Web Information: A Novel Service for Connected Television</a></h3><div class="gs_a"><a href="/citations?user=ugI69q0AAAAJ&amp;hl=en&amp;oi=sra">T Chattopadhyay</a>, <a href="/citations?user=hkKS-xsAAAAJ&amp;hl=en&amp;oi=sra">A Pal</a>&hellip; - &hellip;  and Networks (ICCCN),  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The Connected TV can be described as an Internet enabled TV. In the current <br>paper we have proposed a system for connected TV that mash up the information from <br>internet and RSS feeds related to the breaking news aired over the TV. The proposed <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14225660364296598291&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 2</a> <a href="/scholar?q=related:E7NABbuya8UJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'E7NABbuya8UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320311000550" class=yC3>A novel mutual nearest neighbor based symmetry for text frame classification in video</a></h3><div class="gs_a">P Shivakumara, A Dutta, <a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">T Quy Phan</a>, C Lim Tan&hellip; - Pattern Recognition, 2011 - Elsevier</div><div class="gs_rs">In the field of multimedia retrieval in video, text frame classification is essential for text <br>detection, event detection, event boundary detection, etc. We propose a new text frame <br>classification method that introduces a combination of wavelet and median moment with k-<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11993170311716469446&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 2</a> <a href="/scholar?q=related:xvqeINtMcKYJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11993170311716469446&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'xvqeINtMcKYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6195336" class=yC4>Recent Advances in Video Based Document Processing: A Review</a></h3><div class="gs_a"><a href="/citations?user=JzinqNcAAAAJ&amp;hl=en&amp;oi=sra">N Sharma</a>, <a href="/citations?user=2_z_CogAAAAJ&amp;hl=en&amp;oi=sra">U Pal</a>, M Blumenstein - Document Analysis Systems &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Extraction and recognition of text present in video has become a very popular <br>research area in the last decade. Generally, text present in video frames is of different size, <br>orientation, style, etc. with complex backgrounds, noise, low resolution and contrast. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2870249651013170216&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 3</a> <a href="/scholar?q=related:KDRUsdks1ScJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2870249651013170216&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'KDRUsdks1ScJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://www.hpi.uni-potsdam.de/fileadmin/hpi/FG_ITS/papers/Web_3.0/2012_Yang_IWSSIP.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uni-potsdam.de</span><span class="gs_ggsS">uni-potsdam.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6208333" class=yC5>Text detection in video images using adaptive edge detection and stroke width verification</a></h3><div class="gs_a">H Yang, B Quehl, H Sack - Systems, Signals and Image  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Text displayed in a video provides important information about the video content. <br>Therefore, it can be utilized as a valuable source for indexing and retrieval in digital video <br>libraries. In this paper, we propose a novel approach for efficient automated text detection <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15691175128307394202&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:muY0z6RAwtkJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15691175128307394202&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'muY0z6RAwtkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://www.hpi.uni-potsdam.de/fileadmin/hpi/FG_ITS/papers/Web_3.0/2012_Yang_MTAB.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uni-potsdam.de</span><span class="gs_ggsS">uni-potsdam.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/V0835243406NUU73.pdf" class=yC7>A framework for improved video text detection and recognition</a></h3><div class="gs_a">H Yang, B Quehl, H Sack - Multimedia Tools and Applications, 2012 - Springer</div><div class="gs_rs">Abstract Text displayed in a video is an essential part for the high-level semantic information <br>of the video content. Therefore, video text can be used as a valuable source for automated <br>video indexing in digital video libraries. In this paper, we propose a workflow for video text <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'6cOYDKZn-KIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://www.jdl.ac.cn/doc/2011/20126281185432454_tmm2177646.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from jdl.ac.cn</span><span class="gs_ggsS">jdl.ac.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6092496" class=yC9>Robustly Extracting Captions in Videos Based on Stroke-Like Edges and Spatio-Temporal Analysis</a></h3><div class="gs_a">X Liu, W Wang - Multimedia, IEEE Transactions on, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents an effective and efficient approach to extracting captions from <br>videos. The robustness of our system comes from two aspects of contributions. First, we <br>propose a novel stroke-like edge detection method based on contours, which can <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ctmYDVS_r3QJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8408149397050284402&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'ctmYDVS_r3QJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://ijcsi.org/papers/IJCSI-8-5-3-225-234.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ijcsi.org</span><span class="gs_ggsS">ijcsi.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://ijcsi.org/papers/IJCSI-8-5-3-225-234.pdf" class=yCB>Robust Model for Text Extraction from Complex Video Inputs Based on SUSAN Contour Detection and Fuzzy C Means Clustering</a></h3><div class="gs_a">YS Kumaraswamy - ijcsi.org</div><div class="gs_rs">Abstract: The proposed system introduces a novel approach for extracting text effectively <br>from different types of complex video inputs. The valuable information within the text can be <br>deployed for text indexing and localization. The proposed system uses contour based <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:hNWbFBdJXOYJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16599222690059638148&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'hNWbFBdJXOYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md7', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md7" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:hNWbFBdJXOYJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://eprints.fri.uni-lj.si/1674/1/improved_eurocon_2011.pdf" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uni-lj.si</span><span class="gs_ggsS">uni-lj.si <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://eprints.fri.uni-lj.si/1674/" class=yCD>HASH (0xbbdf4148)</a></h3><div class="gs_a">A Ikica, P Peer - 2011 - eprints.fri.uni-lj.si</div><div class="gs_rs">Abstract Text detection in natural images has gained much attention in the last years as it is <br>a primary step towards fully autonomous text recognition. Understanding the visual text <br>content is of a vital importance in many applicative areas from the internet search engines <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:I45qGYyrVU0J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'I45qGYyrVU0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5967929" class=yCF>Effective and efficient video text extraction using key text points</a></h3><div class="gs_a">Z Li, G Liu, X Qian, D Guo, H Jiang - Image Processing, IET, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Text information contains important clues for video analysis, indexing and retrieval. <br>Effective and efficient text extraction has been a challenging and significant topic. Focusing <br>on this issue, this study proposes a video text extraction scheme using key text points (<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:KqO8LnLXeocJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9762352027689329450&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'KqO8LnLXeocJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://www.akgec.org/journals/jan-june%2012/10-San.pdf" class=yC11><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from akgec.org</span><span class="gs_ggsS">akgec.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.akgec.org/journals/jan-june%2012/10-San.pdf" class=yC10>A Survey of Image to Text Detection Methodology</a></h3><div class="gs_a">S Sharma, J Prakash - akgec.org</div><div class="gs_rs">Abstract--The automatic detection of text within a natural image is an important problem in <br>many applications. Text detection in natural images has gained much attention in the last <br>years as it is a primary step towards fully autonomous text recognition. It needs to be fast, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:huINMWCvEcUJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14200323927750599302&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'huINMWCvEcUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md10', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md10" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:huINMWCvEcUJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0957417412004800" class=yC12>A robust video text detection approach using SVM</a></h3><div class="gs_a">YC Wei, <a href="/citations?user=9-S7q8UAAAAJ&amp;hl=en&amp;oi=sra">CH Lin</a> - Expert Systems with Applications, 2012 - Elsevier</div><div class="gs_rs">A new method for detecting text in video images is proposed in this article. Variations in <br>background complexity, font size and color, make detecting text regions in video images a <br>difficult task. A pyramidal scheme is utilized to solve these problems. First, two downsized <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:i6DLi_p9x8UJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14251498060877897867&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'i6DLi_p9x8UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://cdn.intechweb.org/pdfs/11406.pdf" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from intechweb.org</span><span class="gs_ggsS">intechweb.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://cdn.intechweb.org/pdfs/11406.pdf" class=yC13>Recognition of Characters from Streaming Videos</a></h3><div class="gs_a"><a href="/citations?user=ugI69q0AAAAJ&amp;hl=en&amp;oi=sra">T Chattopadhyay</a>, <a href="/citations?user=hkKS-xsAAAAJ&amp;hl=en&amp;oi=sra">A Pal</a>, <a href="/citations?user=TrdrjEQAAAAJ&amp;hl=en&amp;oi=sra">A Sinha</a> - cdn.intechweb.org</div><div class="gs_rs">Over the past few years, Video has become one of the prime source for recreation, be it <br>Television or Internet. Television brings a whole lot of professionally produced video content <br>(International or local, sports or educational, news or entertainment) to the home for the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10036602239941883215&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:TzWgn48sSYsJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10036602239941883215&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'TzWgn48sSYsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md12', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md12" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:TzWgn48sSYsJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://islab.ulsan.ac.kr/files/announcement/366/improved_eurocon_2011[1].pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ulsan.ac.kr</span><span class="gs_ggsS">ulsan.ac.kr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5929289" class=yC15>An improved edge profile based method for text detection in images of natural scenes</a></h3><div class="gs_a">A Ikica, P Peer - &hellip; -International Conference on Computer as a  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Text detection in natural images has gained much attention in the last years as it is <br>a primary step towards fully autonomous text recognition. Understanding the visual text <br>content is of a vital importance in many applicative areas from the internet search engines <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Wc4IylVfmnYJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8546248064955371097&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'Wc4IylVfmnYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> New SVD-Statistical Features in RGB Space for Video Text Detection</h3><div class="gs_a">P Shivakumara, <a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a></div><div class="gs_fl"><a href="/scholar?q=related:IkKe89j4CdMJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'IkKe89j4CdMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.dbpia.co.kr/view/ar_view.asp?arid=1816155" class=yC17>A Novel Video Image Text Detection Method</a></h3><div class="gs_a">S Xu - KSII Transactions on Internet and Information Systems ( &hellip;, 2012 - dbpia.co.kr</div><div class="gs_rs">&amp;nbsp; &amp;nbsp; A novel and universal method of video image text detection is proposed. A <br>coarse-to-fine text detection method is implemented. Firstly, the spectral clustering (SC) <br>method is adopted to coarsely detect text regions based on the stationary wavelet <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:f4VYJ1w4OVcJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6285116723420497279&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'f4VYJ1w4OVcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/87339a/201010/35620975.html" class=yC18>ä¸ç§å¿«éç®åçå½©è²å¾åä¸­æå­å®ä½æ¹æ³</a></h3><div class="gs_a">å»ä½³ï¼ çäºé£ï¼ ççº¢æ¢ - çµèç¥è¯ä¸ææ¯: å­¦æ¯äº¤æµ, 2010 - cqvip.com</div><div class="gs_rs">å¾ååè§é¢ä¸­çææ¬åå«çéè¦çä¿¡æ¯. æåºäºä¸ç§å¯¹äºå½©è²å¾çææçææ¬æ£æµä¸å®ä½æ¹æ³. <br>è¯¥ç®æ³ä¸»è¦åºäºè§ç¹ååº. ææ¬åºåéå¸¸æçä¸°å¯çå¯éçè¾¹ç¼ä¸è§ç¹, å¨ææ¬åºåå¾å°å¼ºçç<br>ååºèå¨éææ¬åºåçååºè¾å¼±. è¿äºååºå¯¹ææ¬çæ£æµä¸å®ä½æä¾äºæç¨ççº¿ç´¢. é½å¼æ³ç<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11574927389889557204&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:1HJObyJnoqAJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11574927389889557204&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'1HJObyJnoqAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
