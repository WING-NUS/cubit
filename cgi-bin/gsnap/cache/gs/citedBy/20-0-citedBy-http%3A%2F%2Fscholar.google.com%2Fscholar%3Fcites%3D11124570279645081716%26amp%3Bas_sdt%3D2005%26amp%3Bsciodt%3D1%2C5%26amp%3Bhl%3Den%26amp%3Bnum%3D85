Total results = 20
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.comp.nus.edu.sg/~mohan/papers/fusion_survey.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/E31M71152774R630.pdf" class=yC0>Multimodal fusion for multimedia analysis: a survey</a></h3><div class="gs_a"><a href="/citations?user=2s3sftgAAAAJ&amp;hl=en&amp;oi=sra">PK Atrey</a>, <a href="/citations?user=Qq4AAT4AAAAJ&amp;hl=en&amp;oi=sra">MA Hossain</a>, <a href="/citations?user=VcOjgngAAAAJ&amp;hl=en&amp;oi=sra">A El Saddik</a>, MS Kankanhalli - Multimedia Systems, 2010 - Springer</div><div class="gs_rs">Abstract This survey aims at providing multimedia researchers with a state-of-the-art <br>overview of fusion strategies, which are used for combining multiple modalities in order to <br>accomplish various multimedia analysis tasks. The existing literature on multimodal fusion <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2303959858949282248&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=20">Cited by 65</a> <a href="/scholar?q=related:yFlu6UhP-R8J:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2303959858949282248&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'yFlu6UhP-R8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://eprints.ucl.ac.uk/12213/1/12213.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ucl.ac.uk</span><span class="gs_ggsS">ucl.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1703509" class=yC2>Experiential sampling on multiple data streams</a></h3><div class="gs_a">MS Kankanhalli, <a href="/citations?user=wIE1tY4AAAAJ&amp;hl=en&amp;oi=sra">J Wang</a>, R Jain - &hellip; , IEEE Transactions on, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Multimedia systems must deal with multiple data streams. Each data stream usually <br>contains significant volume of redundant noisy data. In many real-time applications, it is <br>essential to focus the computing resources on a relevant subset of data streams at any <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18208205894981513965&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=20">Cited by 9</a> <a href="/scholar?q=related:7fKLT8qKsPwJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/53/19/RN197726475.html?source=googlescholar" class="gs_nph" class=yC4>BL Direct</a> <a href="/scholar?cluster=18208205894981513965&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'7fKLT8qKsPwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www.acs.uwinnipeg.ca/pkatrey/papers/2008_TMM_ConfEvol.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uwinnipeg.ca</span><span class="gs_ggsS">uwinnipeg.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4668509" class=yC5>Confidence evolution in multimedia systems</a></h3><div class="gs_a"><a href="/citations?user=2s3sftgAAAAJ&amp;hl=en&amp;oi=sra">PK Atrey</a>, <a href="/citations?user=VcOjgngAAAAJ&amp;hl=en&amp;oi=sra">A El Saddik</a> - Multimedia, IEEE Transactions on, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Multimedia systems utilize multiple media streams, each of which have different <br>confidence levels in accomplishing various detection tasks. For example, in a multimedia <br>surveillance system, one would usually have higher confidence in an audio stream <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11717596756683693634&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=20">Cited by 7</a> <a href="/scholar?q=related:Qp5m7ypEnaIJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11717596756683693634&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'Qp5m7ypEnaIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://www.cecs.uci.edu/~papers/icme06/pdfs/0001809.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uci.edu</span><span class="gs_ggsS">uci.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4036973" class=yC7>Experiential sampling based foreground/background segmentation for video surveillance</a></h3><div class="gs_a"><a href="/citations?user=2s3sftgAAAAJ&amp;hl=en&amp;oi=sra">PK Atrey</a>, V Kumar, A Kumar&hellip; - Multimedia and Expo,  &hellip;, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Segmentation of foreground and background has been an important research <br>problem arising out of many applications including video surveillance. A method commonly <br>used for segmentation is&quot; background subtraction&quot; or thresholding the difference between <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6214500469372150399&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=20">Cited by 6</a> <a href="/scholar?q=related:f-JsRUBXPlYJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6214500469372150399&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'f-JsRUBXPlYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/N2N6326693361026.pdf" class=yC9>Experiential sampling for object detection in video</a></h3><div class="gs_a">P Anandathirtha, KR Ramakrishnan, SK Raja&hellip; - Multimedia Content  &hellip;, 2009 - Springer</div><div class="gs_rs">There are robust, supervised learning-based algorithms available for object detection in an <br>image. Object detection in videos can be performed by using such a detector on each frame <br>of the video sequence. This approach checks for the presence of an object around each <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5618277508970393821&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=20">Cited by 3</a> <a href="/scholar?q=related:3TC_o6Ah-E0J:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5618277508970393821&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'3TC_o6Ah-E0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.64.4317&amp;rep=rep1&amp;type=pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1198307" class=yCA>Multimedia simplification for optimized MMS synthesis</a></h3><div class="gs_a">WQ Yan, MS Kankanhalli - ACM Transactions on Multimedia Computing &hellip;, 2007 - dl.acm.org</div><div class="gs_rs">Abstract We propose a novel transcoding technique called multimedia simplification which is <br>based on experiential sampling. Multimedia simplification helps optimize the synthesis of <br>MMS (multimedia messaging service) messages for mobile phones. Transcoding is useful <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6272608690979916157&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=20">Cited by 3</a> <a href="/scholar?q=related:fcni6F7IDFcJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6272608690979916157&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'fcni6F7IDFcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4808845" class=yCC>A novel real time voice quality testing model for VoIP ambience environment in wireless LAN</a></h3><div class="gs_a">V Karthikeyan, N Malmurugan&hellip; - &hellip;  Systems and Networks  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This in this work, we propose a model for measuring and improving voice quality <br>under ambience environment for VoIP calls in wireless WLAN 802.11. Existing models such <br>as E-model, PESQ model and Adaptive model which address QoS in VoIP networking do <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16857848994557119692&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=20">Cited by 1</a> <a href="/scholar?q=related:zMzABVgc8-kJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16857848994557119692&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'zMzABVgc8-kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://www.jr.ietejournals.org/article.asp?issn=0377-2063;year=2009;volume=55;issue=5;spage=212;epage=217;aulast=Vaiapury" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from ietejournals.org</span><span class="gs_ggsS">ietejournals.org <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[HTML]</span><span class="gs_ct2">[HTML]</span></span> <a href="http://www.jr.ietejournals.org/article.asp?issn=0377-2063;year=2009;volume=55;issue=5;spage=212;epage=217;aulast=Vaiapury" class=yCD>Ambience-Based Voice Over Internet Protocol Quality Testing Model</a></h3><div class="gs_a"><a href="/citations?user=OSN_mDUAAAAJ&amp;hl=en&amp;oi=sra">K Vaiapury</a>, M Nagarajan, SK Jain - IETE Journal of Research, 2009 - jr.ietejournals.org</div><div class="gs_rs">Abstract In this paper, we explore a new voice quality management model under ambience <br>environment suitable for voice over internet protocol (VoIP) calls in wireless WLAN 802.11 <br>Linux environment. The system is based on a setup that assimilates environment noise <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=69930126643881795&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=20">Cited by 1</a> <a href="/scholar?q=related:Q-e0ZRRx-AAJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=69930126643881795&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'Q-e0ZRRx-AAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.151.5924&amp;rep=rep1&amp;type=pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4756090" class=yCF>Integrated Detect-Track Framework for Multi-view Face Detection in Video</a></h3><div class="gs_a">KR Anoop, P Anandathirtha&hellip; - &hellip;  Vision, Graphics &amp;  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract An Experiential sampling and Meanshift tracker based Multi-view face detection in <br>video is proposed in this paper. In this framework, instead of performing face detection at <br>every position in a frame, we determine certain key positions to run the multi-view face <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=381099718151897103&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=20">Cited by 1</a> <a href="/scholar?q=related:DwByrCzwSQUJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=381099718151897103&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'DwByrCzwSQUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.66.1122&amp;rep=rep1&amp;type=pdf" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/pn3430677t4406l4.pdf" class=yC11>A cross-modal approach for karaoke artifacts correction</a></h3><div class="gs_a">WQ Yan, MS Kankanhalli - Multimedia Tools and Applications, 2008 - Springer</div><div class="gs_rs">Abstract Karaoke singing is a popular form of entertainment in several parts of the world. <br>Since this genre of performance attracts amateurs, the singing often has artifacts related to <br>scale, tempo, and synchrony. We have developed an approach to correct these artifacts <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12356163693489506090&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=20">Cited by 1</a> <a href="/scholar?q=related:KkcF2WnpeasJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/19/4E/RN232981854.html?source=googlescholar" class="gs_nph" class=yC13>BL Direct</a> <a href="/scholar?cluster=12356163693489506090&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'KkcF2WnpeasJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/lh7413485m406rv4.pdf" class=yC14>Cross-Modal Approach for Karaoke Artifacts Correction</a></h3><div class="gs_a">WQ Yan, MS Kankanhalli - &hellip;  of Multimedia for Digital Entertainment and  &hellip;, 2009 - Springer</div><div class="gs_rs">In this chapter, we combine adaptive sampling in conjunction with video analogies (VA) to <br>correct the audio stream in the karaoke environment k= k (t): k (t)=(U (t), K (t)), t Ã (ts, te) Îº=\ <br>left {Îº (t):\ kappa (t)=\ left (U (t),\ K (t)\ right),\ t â\ left (t _ s,{t _ e\ right)\ right\} where ts and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:oYqzO5N08cYJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14335367264607636129&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'oYqzO5N08cYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Fundamentals of Media Security</h3><div class="gs_a">WQ Yan, J Weir - 2010 - WeiQi Yan, Jonathan Weir &amp; Ventus  &hellip;</div><div class="gs_fl"><a href="/scholar?q=related:AREtVtYBdcMJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14084165429751517441&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'AREtVtYBdcMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> STUDENTENSUPPORT. BE</h3><div class="gs_a">W YAN, J WEIR, LKS AUF</div><div class="gs_fl"><a href="/scholar?q=related:Dqk1jcCPctEJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15092283358437550350&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'Dqk1jcCPctEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> VENTUS. DK</h3><div class="gs_a">W YAN, J WEIR</div><div class="gs_fl"><a href="/scholar?q=related:nL_voShiBdEJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'nL_voShiBdEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://etheses.dur.ac.uk/552/2/Customer_Service_Retention_-_A_Behavioural_Perspective_of_the_UK_Mobile_Market.pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from dur.ac.uk</span><span class="gs_ggsS">dur.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://etheses.dur.ac.uk/552/" class=yC15>Customer Service RetentionâA Behavioural Perspective of the UK Mobile Market</a></h3><div class="gs_a">M ALSHURIDEH - 2010 - etheses.dur.ac.uk</div><div class="gs_rs">Abstract Customer retention is essential for firms in the service sector and will subsequently <br>receive a great deal of attention in the coming years. A large majority of firms are losing their <br>current customers at a significant rate. UK operators lose over a third of their subscribers <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13647610794706371312&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=20">Cited by 1</a> <a href="/scholar?q=related:8IJCq7UNZr0J:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13647610794706371312&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'8IJCq7UNZr0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ri"><h3 class="gs_rt"><a href="http://137.132.14.55/handle/10635/33304" class=yC17>Human Visual Perception, study and applications to understanding Images and Videos</a></h3><div class="gs_a"><a href="/citations?user=Cja9MMgAAAAJ&amp;hl=en&amp;oi=sra">H Katti</a> - 2011 - 137.132.14.55</div><div class="gs_rs">Assessing whether a photograph is interesting, or spotting people in conversation or <br>important objects in an images and videos, are visual tasks that we humans do effortlessly <br>and in a robust manner. In this thesis I first explore and quantify how humans distinguish <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:jna1s1LyMH0J:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9020976490639357582&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'jna1s1LyMH0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md15', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md15" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:jna1s1LyMH0J:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=leHMO02GL5cC&amp;oi=fnd&amp;pg=PA282&amp;ots=H6SUdfnXp0&amp;sig=v4vUeHJdLtMrnAaAf-nByi7h4LU" class=yC18>Teams in the Military</a></h3><div class="gs_a"><a href="/citations?user=Pv6vHP8AAAAJ&amp;hl=en&amp;oi=sra">ML Shuffler</a>, D Pavlas, E Salas - The Oxford Handbook of Military  &hellip;, 2012 - books.google.com</div><div class="gs_rs">Abstract Teams have long been considered critical to the organizational structure of the <br>military. The complex nature of military missions requires knowledge, skills, and abilities <br>beyond those ofa single individual, thus requiring the use of teams. Furthermore, the study <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:D2cKtuY5q9UJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15396463414155568911&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'D2cKtuY5q9UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> BOOKBOON. COM</h3><div class="gs_a">W YAN, J WEIR</div><div class="gs_fl"><a href="/scholar?q=related:ygZFwB_L5psJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11233889657752454858&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'ygZFwB_L5psJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/TJ7634160T0Q0478.pdf" class=yC19>Bayesian multimodal fusion in forensic applications</a></h3><div class="gs_a"><a href="/citations?user=HL9Yt8AAAAAJ&amp;hl=en&amp;oi=sra">V Fernandez Arguedas</a>, <a href="/citations?user=XR6C9BoAAAAJ&amp;hl=en&amp;oi=sra">Q Zhang</a>&hellip; - Computer VisionâECCV  &hellip;, 2012 - Springer</div><div class="gs_rs">The public location of CCTV cameras and their connexion with public safety demand high <br>robustness and reliability from surveillance systems. This paper focuses on the development <br>of a multimodal fusion technique which exploits the benefits of a Bayesian inference <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'RWILzLd68rUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> STUDENTENSUPPORT. NL</h3><div class="gs_a">W YAN, J WEIR</div><div class="gs_fl"><a href="/scholar?q=related:UN3X_foQH1oJ:scholar.google.com/&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6493927857878195536&amp;hl=en&amp;num=20&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'UN3X_foQH1oJ')" href="#" class="gs_nph">Cite</a></div></div></div>
