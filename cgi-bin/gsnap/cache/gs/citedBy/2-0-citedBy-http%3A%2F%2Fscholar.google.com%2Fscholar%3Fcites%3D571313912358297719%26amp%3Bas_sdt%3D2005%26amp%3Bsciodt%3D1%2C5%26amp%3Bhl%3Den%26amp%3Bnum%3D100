Total results = 2
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.juew.org/publication/upright_cvpr12.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from juew.org</span><span class="gs_ggsS">juew.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6247761" class=yC0>Automatic upright adjustment of photographs</a></h3><div class="gs_a">H Lee, <a href="/citations?user=B_FTboQAAAAJ&amp;hl=en&amp;oi=sra">E Shechtman</a>, <a href="/citations?user=Bt4uDWMAAAAJ&amp;hl=en&amp;oi=sra">J Wang</a>&hellip; - Computer Vision and  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Man-made structures often appear to be distorted in photos captured by casual <br>photographers, as the scene layout often conflicts with how it is expected by human <br>perception. In this paper we propose an automatic approach for straightening up slanted <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:H9l-J-ntTsYJ:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14289620253338949919&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'H9l-J-ntTsYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><a href="http://137.132.14.55/handle/10635/33304" class=yC2>Human Visual Perception, study and applications to understanding Images and Videos</a></h3><div class="gs_a"><a href="/citations?user=Cja9MMgAAAAJ&amp;hl=en&amp;oi=sra">H Katti</a> - 2011 - 137.132.14.55</div><div class="gs_rs">Assessing whether a photograph is interesting, or spotting people in conversation or <br>important objects in an images and videos, are visual tasks that we humans do effortlessly <br>and in a robust manner. In this thesis I first explore and quantify how humans distinguish <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:jna1s1LyMH0J:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9020976490639357582&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'jna1s1LyMH0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md1', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md1" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:jna1s1LyMH0J:scholar.google.com/&amp;hl=en&amp;num=2&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
