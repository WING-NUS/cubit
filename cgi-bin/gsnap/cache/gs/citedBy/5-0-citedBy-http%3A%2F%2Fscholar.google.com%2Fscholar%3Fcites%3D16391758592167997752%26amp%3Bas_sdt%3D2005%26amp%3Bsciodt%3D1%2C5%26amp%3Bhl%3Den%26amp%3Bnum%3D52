Total results = 5
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.science.uva.nl/research/publications/2012/LiITM2012/li_biconcept_tmm.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uva.nl</span><span class="gs_ggsS">uva.nl <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6175138" class=yC0>Harvesting social images for bi-concept search</a></h3><div class="gs_a"><a href="/citations?user=6m-ZQ1EAAAAJ&amp;hl=en&amp;oi=sra">X Li</a>, <a href="/citations?user=0uKdbscAAAAJ&amp;hl=en&amp;oi=sra">CGM Snoek</a>, <a href="/citations?user=pdu8f3sAAAAJ&amp;hl=en&amp;oi=sra">M Worring</a>&hellip; - &hellip; , IEEE Transactions on, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Searching for the co-occurrence of two visual concepts in unlabeled images is an <br>important step towards answering complex user queries. Traditional visual search methods <br>use combinations of the confidence scores of individual concept detectors to tackle such <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=20645694324272890&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5">Cited by 4</a> <a href="/scholar?q=related:-u5WTCZZSQAJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=20645694324272890&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'-u5WTCZZSQAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/video%20browser%20showdown%20by%20NUS.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/E531450682267J87.pdf" class=yC2>Video browser showdown by NUS</a></h3><div class="gs_a">J Yuan, H Luan, D Hou, H Zhang, YT Zheng&hellip; - Advances in Multimedia  &hellip;, 2012 - Springer</div><div class="gs_rs">The known item search task (KIS) aims to retrieve a unique video or video clip in the video <br>corpus. This paper presents a novel interactive video browsing system for KIS task. Our <br>system integrates visual content-based, text-based and concept-based search <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:oqS4HyKSSHIJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8234992593905689762&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'oqS4HyKSSHIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/fp019-nie-MM-2012.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/fp019-nie-MM-2012.pdf" class=yC4>Harvesting Visual Concepts for Image Search with Complex Queries</a></h3><div class="gs_a">L Nie, <a href="/citations?user=DNuiPHwAAAAJ&amp;hl=en&amp;oi=sra">S Yan</a>, <a href="/citations?user=rHagaaIAAAAJ&amp;hl=en&amp;oi=sra">M Wang</a>, <a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, TS Chua - 2012 - 137.132.145.151</div><div class="gs_rs">ABSTRACT The use of image reranking to boost retrieval performance has been found to be <br>successful for simple queries. It is, however, less effective for complex queries due to the <br>widened semantic gap. This paper presents a scheme to enhance web image reranking <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7073429921893258232&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5">Cited by 1</a> <a href="/scholar?q=related:-BMRjgnfKWIJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'-BMRjgnfKWIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md2', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md2" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:-BMRjgnfKWIJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/zhangAF.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/zhangAF.pdf" class=yC6>Attribute Feedback</a></h3><div class="gs_a">H Zhang, ZJ Zha, <a href="/citations?user=DNuiPHwAAAAJ&amp;hl=en&amp;oi=sra">S Yan</a>, J Bian, TS Chua - 2012 - 137.132.145.151</div><div class="gs_rs">ABSTRACT This work presents a new interactive Content Based Image Retrieval (CBIR) <br>scheme, termed Attribute Feedback (AF). Unlike traditional relevance feedback purely <br>founded on low-level visual features, the Attribute Feedback system shapes users&#39; <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:uiwKptSKrpUJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'uiwKptSKrpUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md3', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md3" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:uiwKptSKrpUJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://dare.uva.nl/document/355661" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uva.nl</span><span class="gs_ggsS">uva.nl <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dare.uva.nl/en/record/410580" class=yC8>Content-based visual search learned from social media</a></h3><div class="gs_a"><a href="/citations?user=6m-ZQ1EAAAAJ&amp;hl=en&amp;oi=sra">X Li</a> - 2012 - dare.uva.nl</div><div class="gs_rs">Abstract In een wereld waarin de hoeveelheid digitale afbeeldingen alsmaar groeit is het <br>belangrijk te kunnen zoeken op basis van beeldinhoud. Xirong Li liet zich inspireren door <br>sociale media en onderzocht de waarde van beelden met social tags voor visueel zoeken. <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:xTQX0HIOAtIJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15132673584198530245&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'xTQX0HIOAtIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
