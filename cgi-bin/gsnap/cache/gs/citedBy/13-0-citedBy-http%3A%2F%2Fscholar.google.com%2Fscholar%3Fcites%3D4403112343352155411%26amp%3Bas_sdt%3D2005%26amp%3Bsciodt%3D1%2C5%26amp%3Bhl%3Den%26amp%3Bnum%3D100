Total results = 13
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://vireo.cs.cityu.edu.hk/papers/mm10-songtan.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cityu.edu.hk</span><span class="gs_ggsS">cityu.edu.hk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1874159" class=yC0>Topical summarization of web videos by visual-text time-dependent alignment</a></h3><div class="gs_a">S Tan, HK Tan, <a href="/citations?user=jk5DWVMAAAAJ&amp;hl=en&amp;oi=sra">CW Ngo</a> - Proceedings of the international conference on &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract Search engines are used to return a long list of hundreds or even thousands of <br>videos in response to a query topic. Efficient navigation of videos becomes difficult and <br>users often need to painstakingly explore the search list for a gist of the search result. This <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7721399328803957791&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13">Cited by 7</a> <a href="/scholar?q=related:H6xMosfrJ2sJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7721399328803957791&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'H6xMosfrJ2sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://www.cs.clemson.edu/~jzwang/1201863/mm2011/p53-xie.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from clemson.edu</span><span class="gs_ggsS">clemson.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2072307" class=yC2>Visual memes in social media: tracking real-world news in youtube videos</a></h3><div class="gs_a"><a href="/citations?user=u0xUDSoAAAAJ&amp;hl=en&amp;oi=sra">L Xie</a>, <a href="/citations?user=Ade_7YoAAAAJ&amp;hl=en&amp;oi=sra">A Natsev</a>, JR Kender, M Hill&hellip; - Proceedings of the 19th  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract We propose visual memes, or frequently reposted short video segments, for <br>tracking large-scale video remix in social media. Visual memes are extracted by novel and <br>highly scalable detection algorithms that we develop, with over 96% precision and 80% <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14051881471954910360&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13">Cited by 9</a> <a href="/scholar?q=related:mPzDqb9PAsMJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14051881471954910360&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'mPzDqb9PAsMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://users.cecs.anu.edu.au/~xlx/papers/acmmm11-meme.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from anu.edu.au</span><span class="gs_ggsS">anu.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://users.cecs.anu.edu.au/~xlx/papers/acmmm11-meme.pdf" class=yC4>Visual memes in social media</a></h3><div class="gs_a"><a href="/citations?user=u0xUDSoAAAAJ&amp;hl=en&amp;oi=sra">L Xie</a>, <a href="/citations?user=Ade_7YoAAAAJ&amp;hl=en&amp;oi=sra">A Natsev</a>, JR Kender, M Hill&hellip; - Proceedings of the  &hellip;, 2011 - users.cecs.anu.edu.au</div><div class="gs_rs">ABSTRACT We propose visual memes, or frequently reposted short video segments, for <br>tracking large-scale video remix in social media. Visual memes are extracted by novel and <br>highly scalable detection algorithms that we develop, with over 96% precision and 80% <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17942621608993828837&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13">Cited by 2</a> <a href="/scholar?q=related:5S9TD0r_APkJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'5S9TD0r_APkJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md2', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md2" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:5S9TD0r_APkJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S016516841200151X" class=yC6>Rank canonical correlation analysis and its application in visual search reranking</a></h3><div class="gs_a">Z Ji, P Jing, Y Su, Y Pang - Signal Processing, 2012 - Elsevier</div><div class="gs_rs">Abstract Ranking relevance degree information is widely utilized in the ranking models of <br>information retrieval applications, such as text and multimedia retrieval, question answering, <br>and visual search reranking. However, existing feature dimensionality reduction methods <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15976973777985874063&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13">Cited by 4</a> <a href="/scholar?q=related:jyiUXgCdud0J:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'jyiUXgCdud0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2072044" class=yC7>Eventscapes: visualizing events over time with emotive facets</a></h3><div class="gs_a"><a href="/citations?user=kbcVlyAAAAAJ&amp;hl=en&amp;oi=sra">B Adams</a>, <a href="/citations?user=OtA9SwIAAAAJ&amp;hl=en&amp;oi=sra">D Phung</a>, <a href="/citations?user=AEkRUQcAAAAJ&amp;hl=en&amp;oi=sra">S Venkatesh</a> - Proceedings of the 19th ACM  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract The scale and dynamicity of social media, and interaction between traditional news <br>sources and online communities, has created challenges to information retrieval <br>approaches. Users may have no clear information need or be unable to express it in the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4257005770476263352&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13">Cited by 4</a> <a href="/scholar?q=related:uJcGlDHsEzsJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4257005770476263352&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'uJcGlDHsEzsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0925231212009046" class=yC8>Richang Hong, Linxie Tang, Jun Hu, Guanda Li, Jiang-Guo Jiang</a></h3><div class="gs_a"><a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, L Tang, J Hu, G Li, JG Jiang - Neurocomputing, 2013 - Elsevier</div><div class="gs_rs">Abstract We have witnessed the booming of contextual video advertising recent years. <br>However, those advertisement systems solely take the metadata into account, such as titles, <br>descriptions and tags. This kind of text-based contextual advertising reveals a number of <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'qWujGb64isAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6135507" class=yC9>Event Driven Web Video Summarization by Tag Localization and Key-Shot Identification</a></h3><div class="gs_a"><a href="/citations?user=rHagaaIAAAAJ&amp;hl=en&amp;oi=sra">M Wang</a>, <a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, G Li, ZJ Zha, <a href="/citations?user=DNuiPHwAAAAJ&amp;hl=en&amp;oi=sra">S Yan</a>&hellip; - &hellip; , IEEE Transactions on, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract With the explosive growth of web videos on the Internet, it becomes challenging to <br>efficiently browse hundreds or even thousands of videos. When searching an event query, <br>users are often bewildered by the vast quantity of web videos returned by search engines. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17159319909387631227&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=13">Cited by 6</a> <a href="/scholar?q=related:e3pWKosmIu4J:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'e3pWKosmIu4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://libque.cityu.edu.hk/bitstream/2031/6211/1/abstract.html" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cityu.edu.hk</span><span class="gs_ggsS">cityu.edu.hk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://libque.cityu.edu.hk/handle/2031/6211" class=yCA>Video hyperlinking for multimedia search</a></h3><div class="gs_a">HK Tan - 2010 - libque.cityu.edu.hk</div><div class="gs_rs">ï»¿ With the spread of Web 2.0, web videos have become prevalent online. There is a growing <br>need for effective modeling and organization of video data to facilitate browsing or retrieval. <br>Meanwhile, the modeling of web pages through hyperlink graph has seen tremendous <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:gk0oVGtrZrQJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12999195483169115522&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'gk0oVGtrZrQJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md7', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md7" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:gk0oVGtrZrQJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=16418393280767177700&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://vireo.cs.cityu.edu.hk/papers/mm11-tan.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cityu.edu.hk</span><span class="gs_ggsS">cityu.edu.hk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2072331" class=yCC>Cross media hyperlinking for search topic browsing</a></h3><div class="gs_a">S Tan, <a href="/citations?user=jk5DWVMAAAAJ&amp;hl=en&amp;oi=sra">CW Ngo</a>, HK Tan, L Pang - Proceedings of the 19th ACM  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract With the rapid growth of social media, there are plenty of information sources freely <br>available online for use. Nevertheless, how to synchronize and leverage these diverse forms <br>of information for multimedia applications remains a problem yet to be seriously studied. <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:uHuya3a24vIJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17501751721644424120&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'uHuya3a24vIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0165168412002204" class=yCE>Multimedia encyclopedia construction by mining web knowledge</a></h3><div class="gs_a"><a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, ZJ Zha, Y Gao, TS Chua, X Wu - Signal Processing, 2012 - Elsevier</div><div class="gs_rs">Abstract In recent years, we have witnessed the blooming of Web 2.0 content such as <br>Wikipedia, Flickr and YouTube, etc. How might we benefit from such rich media resources <br>available on the internet? This paper presents a novel concept called Mediapedia, a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:-PXgd9tRpOoJ:scholar.google.com/&amp;hl=en&amp;num=13&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'-PXgd9tRpOoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://www.jdl.ac.cn/doc/2011/20131111721081984_p781.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from jdl.ac.cn</span><span class="gs_ggsS">jdl.ac.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2396311" class=yCF>An effective multi-clue fusion approach for web video topic detection</a></h3><div class="gs_a">T Chen, C Liu, Q Huang - Proceedings of the 20th ACM international  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract The efficient organization and navigation of web videos in the topic level could <br>enhance the user experience and boost the user&#39;s understanding about the happened <br>events. Due to the potential application prospects, topic detection attracts increasing <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'DBS9sDw33okJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> A Cloud-based Collaborative Video Story Authoring and Sharing Platform</h3><div class="gs_a">C Wang, <a href="/citations?user=Y_Y3fVEAAAAJ&amp;hl=en&amp;oi=sra">R Ranjan</a>, <a href="/citations?user=y6m820wAAAAJ&amp;hl=en&amp;oi=sra">X Zhou</a>, <a href="/citations?user=PlZO-l8AAAAJ&amp;hl=en&amp;oi=sra">K Mitra</a>, S Saha, M Meng&hellip;</div><div class="gs_fl"><a onclick="return gs_ocit(event,'ZQ51-Rcr_p8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/91690x/201227/43276680.html" class=yC11>å¤è§é¢æè¦ææ¯: æ¹æ³, åºç¨åææ</a></h3><div class="gs_a">åä¸­ï¼ èè²æºï¼ åºå½¦ä¼ - è®¡ç®æºå·¥ç¨ä¸åºç¨, 2012 - cqvip.com</div><div class="gs_rs">å¤è§é¢æè¦ææ¯è¿å¹´æ¥åå°äºå½åå¤å­¦èçå¹¿æ³å³æ³¨, å®æ¯æéè¿å¯¹è§é¢ç»æååå®¹çåæ, <br>ä»å¤ä¸ªç¸å³è§é¢æä»¶ä¸­æååºææä¹çé¨å, å°å®ä»¬ä»¥ä¸å®æ¹å¼è¿è¡ç»å, å½¢æç®æ´ç, <br>è½å¤ååè¡¨ç°è¯­ä¹åå®¹çæ¦è¦, ç®çæ¯æä¾å¿«æ·çæµè§åæ¥è¯¢æå¡. ç®åè¯¥ææ¯è¿å¤äºèµ·æ­¥<b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'JlHoS-uMJQMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
