Total results = 21
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="https://www1.comp.nus.edu.sg/~wangye/papers/3.Applications_in_Edutainment_(e-Learning)/2005_Digital_Violin_Tutor-An_Integrated_System_for_Beginning_Violin_Learners.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1101353" class=yC0>Digital violin tutor: an integrated system for beginning violin learners</a></h3><div class="gs_a">J Yin, Y Wang, <a href="/citations?user=S9LHLKEAAAAJ&amp;hl=en&amp;oi=sra">D Hsu</a> - Proceedings of the 13th annual ACM  &hellip;, 2005 - dl.acm.org</div><div class="gs_rs">Abstract Prompt feedback is essential for beginning violin learners; however, most amateur <br>learners can only meet with teachers and receive feedback once or twice a week. To help <br>such learners, we have attempted an initial design of Digital Violin Tutor (DVT), an <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3396752607590408849&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21">Cited by 22</a> <a href="/scholar?q=related:keJO9X-wIy8J:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3396752607590408849&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'keJO9X-wIy8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://strum.googlecode.com/svn-history/r41/trunk/Research/CAMIT.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from googlecode.com</span><span class="gs_ggsS">googlecode.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1290156" class=yC2>Effective use of multimedia for computer-assisted musical instrument tutoring</a></h3><div class="gs_a"><a href="/citations?user=xCnDkXAAAAAJ&amp;hl=en&amp;oi=sra">G Percival</a>, Y Wang, <a href="/citations?user=yPgxxpwAAAAJ&amp;hl=en&amp;oi=sra">G Tzanetakis</a> - Proceedings of the international  &hellip;, 2007 - dl.acm.org</div><div class="gs_rs">Abstract This paper presents a survey of recent work in computer-assisted musical <br>instrumental tutoring and outlines several questions to consider when developing future <br>projects. In particular, we suggest that the area ingreatest need of computer assistance is <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=963958909237274801&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21">Cited by 18</a> <a href="/scholar?q=related:sSgpS4WrYA0J:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=963958909237274801&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 21 versions</a> <a onclick="return gs_ocit(event,'sSgpS4WrYA0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://winnie.kuis.kyoto-u.ac.jp/~kitahara/papers/d-thesis-kitahara.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from kyoto-u.ac.jp</span><span class="gs_ggsS">kyoto-u.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://winnie.kuis.kyoto-u.ac.jp/~kitahara/papers/d-thesis-kitahara.pdf" class=yC4>Computational musical instrument recognition and its application to content-based music information retrieval</a></h3><div class="gs_a">T Kitahara - &hellip;  PhD Thesis, Kyoto University, Kyoto, Japan.  &hellip;, 2007 - winnie.kuis.kyoto-u.ac.jp</div><div class="gs_rs">Abstract The current capability of computers to recognize auditory events is severely limited <br>when compared to human ability. Although computers can accurately recognize sounds that <br>are sufficiently close to those trained in advance and that occur without other sounds <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10175040816671476796&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21">Cited by 10</a> <a href="/scholar?q=related:PMzNjLYBNY0J:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10175040816671476796&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'PMzNjLYBNY0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md2', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md2" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:PMzNjLYBNY0J:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5356228" class=yC6>Music scene-adaptive harmonic dictionary for unsupervised note-event detection</a></h3><div class="gs_a">JJ Carabias-Orti, P Vera-Candeas&hellip; - Audio, Speech, and  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Harmonic decompositions are a powerful tool dealing with polyphonic music <br>signals in some potential applications such as music visualization, music transcription and <br>instrument recognition. The usefulness of a harmonic decomposition relies on the design <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1323416664502097094&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21">Cited by 8</a> <a href="/scholar?q=related:xtR60XG4XRIJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1323416664502097094&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'xtR60XG4XRIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://www.mistic.ece.uvic.ca/publications/2007_ismir_sitar.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uvic.ca</span><span class="gs_ggsS">uvic.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.mistic.ece.uvic.ca/publications/2007_ismir_sitar.pdf" class=yC7>Pedagogical transcription for multimodal sitar performance</a></h3><div class="gs_a">A Kapur, <a href="/citations?user=xCnDkXAAAAAJ&amp;hl=en&amp;oi=sra">G Percival</a>, <a href="/citations?user=Z-D1LQwAAAAJ&amp;hl=en&amp;oi=sra">M Lagrange</a>&hellip; - Proc. Int&#39;l Conf. Music  &hellip;, 2007 - mistic.ece.uvic.ca</div><div class="gs_rs">ABSTRACT Most automatic music transcription research is concerned with producing sheet <br>music from the audio signal alone. However, the audio data does not include certain <br>performance data which is vital for the preservation of instrument performance techniques <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2768606964165807622&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21">Cited by 6</a> <a href="/scholar?q=related:Bo7GfV0RbCYJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2768606964165807622&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'Bo7GfV0RbCYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md4', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md4" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Bo7GfV0RbCYJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://www.comp.nus.edu.sg/~wangye/papers/3.Applications_in_Edutainment_(e-Learning)/2008_Application_Specific_Music_Transcription_for_Tutoring.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4623948" class=yC9>Application-specific music transcription for tutoring</a></h3><div class="gs_a">Y Wang, B Zhang - Multimedia, IEEE, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Automatic music transcription (AMT) refers to the ability of computers to write note <br>information, such as the pitch, onset time, duration, and source of each sound, after listening <br>to the music. Our application scenario is computer-assisted, musical-instrument tutoring, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=176626421973561276&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21">Cited by 5</a> <a href="/scholar?q=related:vK-ug8uAcwIJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=176626421973561276&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 18 versions</a> <a onclick="return gs_ocit(event,'vK-ug8uAcwIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5303851" class=yCB>Multiple fundamental frequency estimation based on harmonic structure model</a></h3><div class="gs_a">L Shi, J Zhang, G Han - &hellip;  and Signal Processing, 2009. CISP&#39;09. &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Multiple-f0 estimation refers to the core part of music signal analysis. Although it has <br>been considerably developed, current techniques are still not accurate and robust. Partial <br>overlapping is one of the most difficult problem, all algorithms have troubles in processing <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13288984704287430916&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21">Cited by 2</a> <a href="/scholar?q=related:BNmmNC71a7gJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'BNmmNC71a7gJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://paper.ijcsns.org/07_book/200709/20070928.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ijcsns.org</span><span class="gs_ggsS">ijcsns.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://paper.ijcsns.org/07_book/200709/20070928.pdf" class=yCC>Analysis/Synthesis of Stringed Instrument Using Formant Structure</a></h3><div class="gs_a">K Yasuda, H Hama - IJCSNS, 2007 - paper.ijcsns.org</div><div class="gs_rs">Summary In this paper, timbre of stringed instrument is analyzed and the timbre sound is <br>synthesized. Timbre is familiar and looks well known, but it has been unknown even now <br>what an essential factor is. And it is the most important factor for human to distinguish <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7501502318734403470&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21">Cited by 2</a> <a href="/scholar?q=related:jufuPZ2wGmgJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7501502318734403470&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'jufuPZ2wGmgJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md7', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md7" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:jufuPZ2wGmgJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/94913x/200612/23426065.html" class=yCE>åºäºè°æ³¢ç»æä¿¡æ¯çèªå¨é³ä¹æ æ³¨æ¹æ³</a></h3><div class="gs_a">éè´µæ»¨ï¼ é©çºªåº - è®¡ç®æºç ç©¶ä¸åå±, 2007 - cqvip.com</div><div class="gs_rs">æ ¹æ®åç±»ä¹å¨é³è²ç¸ä¼¼çç¹ç¹, æåºäºä¸ç§åºäºè°æ³¢ç»æä¿¡æ¯çèªå¨é³ä¹æ æ³¨æ¹æ³. <br>è¯¥æ¹æ³äºåæåä¸ç±»ä¹å¨ä¸­æä¸ä»¶ä¹å¨çè°æ³¢ç»æä¿¡æ¯. æ ¹æ®è¾å¥ä¿¡å·éæ©åéçä¸è°åç³»æ°, <br>é¢çè¯¯å·®ç³»æ°, ç»åè°æ³¢ç»æä¿¡æ¯æé åç±»æªç¥ä¹å¨çååº¦è°±, ç¶åéç¨æªæ­å®å¨æå°äºä¹æ³<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5972430114963879139&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21">Cited by 2</a> <a href="/scholar?q=related:43RE2ItV4lIJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5972430114963879139&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'43RE2ItV4lIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4303965" class=yCF>Automatic Transcription Method for Polyphonic Music Based on Adaptive Comb Filter and Neural Network</a></h3><div class="gs_a">Z Guibin, L Sheng - Mechatronics and Automation, 2007. ICMA  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents a method to transcribe polyphonic music based on adaptive <br>comb filter and neural network. In the method, the input audio is firstly divided into snapshots <br>by a BP neural network, and then comb filters of different notes are used to calculate <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6085922523805208601&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21">Cited by 1</a> <a href="/scholar?q=related:GVD1cUqKdVQJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'GVD1cUqKdVQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.aes.org/e-lib/browse.cfm?conv=126&amp;papernum=7819" class=yC10>Estimating Instrument Spectral Envelopes for Polyphonic Music Transcription in a Music Scene-Adaptive Approach</a></h3><div class="gs_a">JJ Carabias-Orti, P Vera-Candeas, N Ruiz-Reyes&hellip; - Watermark, 2012 - aes.org</div><div class="gs_rs">We propose a method for estimating the spectral envelope pattern of musical instruments in <br>an musical scene-adaptive scheme, without having any prior knowledge about the real <br>transcription. A musical note is defined as stable when variations between its harmonic <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12055637877470136450&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=21">Cited by 1</a> <a href="/scholar?q=related:gghaq8Y6TqcJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12055637877470136450&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'gghaq8Y6TqcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://downloads.hindawi.com/journals/aaa/2012/302958.pdf" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hindawi.com</span><span class="gs_ggsS">hindawi.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.hindawi.com/journals/aaa/2012/302958/abs/" class=yC11>A Combined Mathematical Treatment for a Special Automatic Music Transcription System</a></h3><div class="gs_a">Y Guo, J Tang - Abstract and Applied Analysis, 2012 - hindawi.com</div><div class="gs_rs">This paper presents a combined mathematical treatment for a special automatic music <br>transcription system. This system is specially made for computer-synthesized music. The <br>combined mathematical treatment includes harmonic selection, matrix analysis, and <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'Xr5LCXrxUmUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md11', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md11" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Xr5LCXrxUmUJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> A Compositional Automatic Music Transcription System for Computer-synthesized Music</h3><div class="gs_a">G Yi</div><div class="gs_fl"><a href="/scholar?q=related:q7i8KOrlg_kJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'q7i8KOrlg_kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6060196" class=yC13>Study on accurate estimation of musical information in musical performance</a></h3><div class="gs_a">N Funakoshi, T Tanaka - SICE Annual Conference (SICE), 2011 &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Although the recent research in the field of Automatic music transcription has been <br>active, there are still outstanding problems. Amongst, we focused on note-length and aim to <br>estimate note-length exactly. In the past, Fourier or Wavelet transform are used to <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Sk7vLW1qpAsJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Sk7vLW1qpAsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.184.7941&amp;rep=rep1&amp;type=pdf" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.184.7941&amp;rep=rep1&amp;type=pdf" class=yC14>OVERLAPPED EVENT-NOTE SEPARATION BASED ON PARTIALS AMPLITUDE AND PHASE ESTIMATION FOR POLYPHONIC MUSIC TRANSCRIPTION</a></h3><div class="gs_a">JJ Carabias-Orti, P Vera-Candeas, N Ruiz-Reyes&hellip; - 2009 - Citeseer</div><div class="gs_rs">ABSTRACT We propose a discriminative model for polyphonic music transcription that deals <br>with the well-known overlapped partial problem by taking into account the instrument <br>envelope pattern for each note. The process to obtain the music scene-adaptive envelope <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:D9-LkvBnjdQJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15316012190705377039&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'D9-LkvBnjdQJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md14', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md14" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:D9-LkvBnjdQJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> 6FKRRORI &amp;RPSXWLQJ 1DWLRQDO8QLYHUVLW\ RI 6LQJDSRUH^\ LQMXQ ZDQJ\ HG\ KVX# FRPS QXV HGX VJ</h3><div class="gs_a">J Yin, Y Wang, D Hsu - 2005</div><div class="gs_fl"><a href="/scholar?q=related:SzZzqC4R6hQJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'SzZzqC4R6hQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5336070" class=yC16>Note Recognition of Polyphonic Music Based on Timbre Model</a></h3><div class="gs_a">L Shi, J Zhang, M Li - Intelligent Human-Machine Systems and  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Note recognition has been studied for many years, and current techniques are still <br>not accurate and robust. Partial overlapping is one of the most difficult problems, all <br>algorithms have trouble in processing the shared partial. In this paper, we analyze the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:U2Bm4q0oY_sJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18114366853507080275&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'U2Bm4q0oY_sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://rahati.mshdiau.ac.ir/docs/azizi-faez-rezaeeian-rahati-ICIC2009.pdf" class=yC18><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mshdiau.ac.ir</span><span class="gs_ggsS">mshdiau.ac.ir <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/9860642482586476.pdf" class=yC17>Automatic music transcription based on wavelet transform</a></h3><div class="gs_a">A Azizi, <a href="/citations?user=S_zHD0YAAAAJ&amp;hl=en&amp;oi=sra">K Faez</a>, A Delui, S Rahati - Emerging Intelligent Computing  &hellip;, 2009 - Springer</div><div class="gs_rs">Abstract. In this paper, we introduce a method which uses a note model and signal post <br>processing for a musical instrument to make a piece of music. one of the important issues in <br>note transcription is extraction of multiple pitches. Most of the examined methods face <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:a0Gc_4CXsmYJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7400143718023184747&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'a0Gc_4CXsmYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/95033x/201013/34734262.html" class=yC19>åºäºé³è²æ¨¡åçå¤åºé¢ä¼°è®¡æ¹æ³</a></h3><div class="gs_a">ç³ç«æ°ï¼ å¼ ä¿æ - è®¡ç®æºå·¥ç¨ä¸è®¾è®¡, 2010 - cqvip.com</div><div class="gs_rs">ä¸ºäºææè§£å³å¤è°é³ä¹æ³é³éå é®é¢, æåºäºä¸ç§åºäºé³è²æ¨¡åçå¤åºé¢ä¼°è®¡æ¹æ³. <br>åæäºé³è²çæ¶é¢ç¹å¾, æåºè¡°éåç»´æé¶æ®µçè°æ³¢ç»æç¨³å®å¯é , éååºé¢ä¼°è®¡. <br>æ ¹æ®è°æ³¢å¹éçåå¼ºåº¦ç­éåéåºé¢, éç¨é¢è°±è¿­ä»£å é¤çæ¹æ³ç¡®å®ç¡®ååºé¢. ä¾æ®æå°è°æ³¢<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:kNzoiv2TkN8J:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16109538584270789776&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'kNzoiv2TkN8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="http://rua.ua.es/dspace/bitstream/10045/18326/1/Tesis_Pertusa.pdf" class=yC1B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ua.es</span><span class="gs_ggsS">ua.es <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dialnet.unirioja.es/servlet/tesis?codigo=20907" class=yC1A>Computationally efficient methods for polyphonic music transcription</a></h3><div class="gs_a">A Pertusa-IbÃ¡Ã±ez - 2010 - dialnet.unirioja.es</div><div class="gs_rs">Resumen: Automatic music transcription is a music information retrieval (MIR) task which <br>involves many different disciplines, such as audio signal processing, machine learning, <br>computer science, psychoacoustics and music perception, music theory, and music <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:2JJri16MFxAJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1159549766765089496&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'2JJri16MFxAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md19', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md19" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:2JJri16MFxAJ:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB20" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW20"><a href="http://www.iit.upcomillas.es/pfc/resumenes/4c27a624eb042.pdf" class=yC1D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from upcomillas.es</span><span class="gs_ggsS">upcomillas.es <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.iit.upcomillas.es/pfc/resumenes/4c27a624eb042.pdf" class=yC1C>CODIFICACIÃN AUTOMÃTICA DE MELODÃAS Y APLICACIÃN DE TÃCNICAS DE CLUSTERING PARA EL ANÃLISIS DE ARCHIVOS DE AUDIO  &hellip;</a></h3><div class="gs_a">MMR Calvo - iit.upcomillas.es</div><div class="gs_rs">ABSTRACT Always was heard referenced to art that&quot; no accounting for taste is nothing in <br>writing&quot;, but when you study the popularity ratings of some songs, the conclusion is that <br>some composers and musicians have had an extraordinary ability to generate melodies <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:W-f1qAxPts8J:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14967237327405311835&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'W-f1qAxPts8J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md20', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md20" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:W-f1qAxPts8J:scholar.google.com/&amp;hl=en&amp;num=21&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
