Total results = 22
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://hal.archives-ouvertes.fr/docs/00/51/14/37/PDF/Papadopoulos_Chord_CBMI_2007.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4275055" class=yC0>Large-scale study of chord estimation algorithms based on chroma representation and HMM</a></h3><div class="gs_a">H Papadopoulos, G Peeters - Content-Based Multimedia  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper deals with the automatic estimation of chord progression over time of an <br>audio file. From the audio signal, a set of chroma vectors representing the pitch content of <br>the file over time is extracted. From these observations the chord progression is then <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=652762294204648197&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 59</a> <a href="/scholar?q=related:BUvWHNkTDwkJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=652762294204648197&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'BUvWHNkTDwkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://hal.archives-ouvertes.fr/docs/00/51/14/45/PDF/Papadopoulos_ChordDownbeat_ICASSP_2008.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4517561" class=yC2>Simultaneous estimation of chord progression and downbeats from an audio file</a></h3><div class="gs_a">H Papadopoulos, G Peeters - Acoustics, Speech and Signal  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Harmony and metrical structure are some of the most important attributes of <br>Western tonal music. In this paper, we present a new method for simultaneously estimating <br>the chord progression and the downbeats from an audio file. For this, we propose a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4277220996177333062&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 35</a> <a href="/scholar?q=related:Rgv-ltW9WzsJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4277220996177333062&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'Rgv-ltW9WzsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/G840778660242162.pdf" class=yC4>A probabilistic framework for audio-based tonal key and chord recognition</a></h3><div class="gs_a">B Catteau, JP Martens, M Leman - Advances in Data Analysis, 2007 - Springer</div><div class="gs_rs">A unified probabilistic framework for audio-based chord and tonal key recognition is <br>described and evaluated. The proposed framework embodies an acoustic observation <br>likelihood model and key &amp; chord transition models. It is shown how to conceive these <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11342088862696469192&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 15</a> <a href="/scholar?q=related:yPLvR7oxZ50J:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11342088862696469192&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'yPLvR7oxZ50J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="https://biblio.ugent.be/publication/967938/file/978931.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ugent.be</span><span class="gs_ggsS">ugent.be <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="https://biblio.ugent.be/publication/967938" class=yC5>Integrating musicological knowledge into a probabilistic framework for chord and key extraction</a></h3><div class="gs_a">J Pauwels, J Martens - 2010 - biblio.ugent.be</div><div class="gs_rs">abstract In this contribution a formerly developed probabilistic framework for the <br>simultaneous detection of chords and keys in polyphonic audio is further extended and <br>validated. The system behaviour is controlled by a small set of carefully defined free <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14217723233053415809&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 9</a> <a href="/scholar?q=related:gZn3pPN_T8UJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14217723233053415809&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'gZn3pPN_T8UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://wwwiti.cs.uni-magdeburg.de/~stober/publ/cbmi2008.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uni-magdeburg.de</span><span class="gs_ggsS">uni-magdeburg.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4564924" class=yC7>Enhancing chord classification through neighbourhood histograms</a></h3><div class="gs_a">J Reinhard, S Stober&hellip; - Content-Based Multimedia  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The chord progression of a song is an important high-level feature which enables <br>indexing as well as deeper analysis of musical recordings. Different approaches to chord <br>recognition have been suggested in the past. Though their performance increased, still <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10861208389787583936&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 7</a> <a href="/scholar?q=related:wAXIQHzDupYJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10861208389787583936&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'wAXIQHzDupYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://laurentoudre.fr/publis/OFG-IEEE-11.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from laurentoudre.fr</span><span class="gs_ggsS">laurentoudre.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5664772" class=yC9>Probabilistic template-based chord recognition</a></h3><div class="gs_a"><a href="/citations?user=aSXlodEAAAAJ&amp;hl=en&amp;oi=sra">L Oudre</a>, <a href="/citations?user=kAWEUq0AAAAJ&amp;hl=en&amp;oi=sra">C FÃ©votte</a>, Y Grenier - Audio, Speech, and Language  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper describes a probabilistic approach to template-based chord recognition <br>in music signals. The algorithm only takes chromagram data and a user-defined dictionary of <br>chord templates as input data. No training or musical information such as key, rhythm, or <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6789456638796096372&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 3</a> <a href="/scholar?q=related:dONbRdf-OF4J:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6789456638796096372&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'dONbRdf-OF4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://www.cs.fiu.edu/~lli003/Music/clu/5.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from fiu.edu</span><span class="gs_ggsS">fiu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=OHp3sRnZD-oC&amp;oi=fnd&amp;pg=PA319&amp;ots=oDOSrGgB95&amp;sig=sBWhBDxXRIXKa14TnKOuDPdbnKo" class=yCB>Clustering music recordings by their keys</a></h3><div class="gs_a">Y Liu, Y Wang, A Shenoy, WH Tsai&hellip; - Proceedings of the  &hellip;, 2008 - books.google.com</div><div class="gs_rs">ABSTRACT Music key, a high level feature of musical audio, is an effective tool for structural <br>analysis of musical works. This paper presents a novel unsupervised approach for clustering <br>music recordings by their keys. Based on chroma-based features extracted from acoustic <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16035653830951345082&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 3</a> <a href="/scholar?q=related:upv83jIWit4J:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16035653830951345082&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 24 versions</a> <a onclick="return gs_ocit(event,'upv83jIWit4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://hal.inria.fr/docs/00/54/89/52/PDF/Papadopoulos_Thesis.pdf" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from inria.fr</span><span class="gs_ggsS">inria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://hal.inria.fr/docs/00/54/89/52/PDF/Papadopoulos_Thesis.pdf" class=yCD>Joint estimation of musical content information from an audio signal</a></h3><div class="gs_a">H Papadopoulos - 2010 - hal.inria.fr</div><div class="gs_rs">RÃ©sumÃ© Dans cette these, nous nous intÃ©ressons au probleme de l&#39;extraction automatique <br>d&#39;informations de contenu d&#39;un signal audio de musique. La plupart des travaux existants <br>abordent ce probleme en considÃ©rant les attributs musicaux de maniere indÃ©pendante les <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5504565459161893914&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 4</a> <a href="/scholar?q=related:Gsw65B4lZEwJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Gsw65B4lZEwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md7', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md7" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Gsw65B4lZEwJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a>  <a href="/scholar?q=info:Gsw65B4lZEwJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=14696771562731948953&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://www.helene.lachambre.eu/files/lachambre_TASLP_2011.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from lachambre.eu</span><span class="gs_ggsS">lachambre.eu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5610710" class=yCF>Distinguishing monophonies from polyphonies using Weibull bivariate distributions</a></h3><div class="gs_a">H Lachambre, R AndrÃ©-Obrecht&hellip; - Audio, Speech, and  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In the context of music indexation, it would be useful to have a precise information <br>about the number of sources performing; a source is a solo voice or an isolated instrument <br>which produces a single note at any time. This correspondence discusses the automatic <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3132766224755721410&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 2</a> <a href="/scholar?q=related:wgTohkjSeSsJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3132766224755721410&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'wgTohkjSeSsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="https://biblio.ugent.be/publication/1944757/file/1944775.pdf" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ugent.be</span><span class="gs_ggsS">ugent.be <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6012146" class=yC11>Improving the key extraction performance of a simultaneous local key and chord estimation system</a></h3><div class="gs_a">J Pauwels, JP Martens, M Leman - Multimedia and Expo (ICME &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, significant improvements of a previously developed key and chord <br>extraction system are proposed. The major improvement is the introduction of a separate <br>acoustic model, designed to verify local key hypotheses. The conducted experimental <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17749672809303511912&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 2</a> <a href="/scholar?q=related:aBPy1WCBU_YJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17749672809303511912&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'aBPy1WCBU_YJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://hal.archives-ouvertes.fr/docs/00/45/75/22/PDF/These_Helene_Lachambre.pdf" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://hal.archives-ouvertes.fr/tel-00457522/" class=yC13>CaractÃ©risation de l&#39;environnement musical dans les documents audiovisuels</a></h3><div class="gs_a">H Lachambre - 2009 - hal.archives-ouvertes.fr</div><div class="gs_rs">Depuis plusieurs dizaines d&#39;annÃ©es, l&#39;indexation par le contenu des documents <br>audiovisuels fait l&#39;objet de travaux de la part de nombreuses Ã©quipes de recherche:âLe mot <br>Â«audiovisuelÂ» fait rÃ©fÃ©rencea un contenu Â«multimÃ©diaÂ» qui regroupea la fois des donnÃ©es <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7844252019198893922&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 4</a> <a href="/scholar?q=related:Yp_9nKZh3GwJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7844252019198893922&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'Yp_9nKZh3GwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md10', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md10" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:Yp_9nKZh3GwJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=3531827526069817499&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://www.comp.nus.edu.sg/~wangye/papers/1.Audio_and_Music_Analysis_and_Retrieval/2007_Pop_Music_Beat_Detection_in_the_Huffman_Coded_Domain.pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4284586" class=yC15>Pop music beat detection in the huffman coded domain</a></h3><div class="gs_a">J Zhu, Y Wang - Multimedia and Expo, 2007 IEEE International  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents a novel beat detector that operates in the Huffman coded <br>domain of a MP3 audio bitstream. We seek to answer two main questions. First, whether it is <br>possible to extract beats without even partial decoding of a MP3 audio. Second, how to <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7860314104567563746&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 1</a> <a href="/scholar?q=related:4gW-SQhyFW0J:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7860314104567563746&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'4gW-SQhyFW0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5685054" class=yC17>Design of an architecture for a MIDI based music e-tutor</a></h3><div class="gs_a">S Mammen, I Krishnamurthi - Audio Language and Image  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The main goal of our work is to develop a framework which can train students on <br>musical instruments. The student&#39;s musical instrument can be connected to the framework <br>through MIDI connection. The framework receives input both from the MIDI instrument and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1925494835263843165&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 1</a> <a href="/scholar?q=related:XSvA2Fm7uBoJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'XSvA2Fm7uBoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://www.music-ir.org/mirex/abstracts/2009/ACD_SS_mauch.pdf" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from music-ir.org</span><span class="gs_ggsS">music-ir.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.music-ir.org/mirex/abstracts/2009/ACD_SS_mauch.pdf" class=yC18>MIREX submissions for audio chord detection (no training) and structural segmentation</a></h3><div class="gs_a"><a href="/citations?user=_gfIN8AAAAAJ&amp;hl=en&amp;oi=sra">M Mauch</a>, K Noland, <a href="/citations?user=9GvyqXEAAAAJ&amp;hl=en&amp;oi=sra">S Dixon</a> - MIREX Submission Abstracts, 2009 - music-ir.org</div><div class="gs_rs">ABSTRACT This paper describes our approach to chord extraction from audio, a variant of <br>which was submitted to the 2009 MIREX Chord Detection Task (No Training), and achieved <br>the top ranking of 71.2%. The structural segmentation algorithm is a pre-processing step <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2699054119824505124&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=22">Cited by 1</a> <a href="/scholar?q=related:JLmx-Wv3dCUJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2699054119824505124&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'JLmx-Wv3dCUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md13', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md13" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:JLmx-Wv3dCUJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://wwwiti.cs.uni-magdeburg.de/~stober/publ/mtap2012adaptiveMIR.pdf" class=yC1B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uni-magdeburg.de</span><span class="gs_ggsS">uni-magdeburg.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/76x78554q0526132.pdf" class=yC1A>Adaptive music retrievalâa state of the art</a></h3><div class="gs_a">S Stober, <a href="/citations?user=LuMoBX0AAAAJ&amp;hl=en&amp;oi=sra">A NÃ¼rnberger</a> - Multimedia Tools and Applications, 2012 - Springer</div><div class="gs_rs">Abstract With the development of more and more sophisticated Music Information Retrieval <br>approaches, aspects of adaptivity are becoming an increasingly important research topic. <br>Even though, adaptive techniques have already found their way into Music Information <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:MvLbFPg5nPEJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17409853997172126258&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'MvLbFPg5nPEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://laurentoudre.fr/publis/OFG-MMSP-10.pdf" class=yC1D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from laurentoudre.fr</span><span class="gs_ggsS">laurentoudre.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5662016" class=yC1C>Probabilistic framework for template-based chord recognition</a></h3><div class="gs_a"><a href="/citations?user=aSXlodEAAAAJ&amp;hl=en&amp;oi=sra">L Oudre</a>, <a href="/citations?user=kAWEUq0AAAAJ&amp;hl=en&amp;oi=sra">C FÃ©votte</a>, Y Grenier - Multimedia Signal Processing ( &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper describes a method for chord recognition from audio signals. Our <br>method provides a coherent and relevant probabilistic framework for template-based <br>transcription. The only information needed for the transcription is the definition of the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:dnxlM2X4ymwJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7839351214929443958&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'dnxlM2X4ymwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://scholarbank.nus.sg/bitstream/handle/10635/13382/thesis_21_amendment_2.pdf?sequence=1" class=yC1F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.sg</span><span class="gs_ggsS">nus.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://scholarbank.nus.sg/handle/10635/13382" class=yC1E>REFINING MUSIC SIGNAL TO LYRIC TEXT SYNCHRONIZATION FROM LINE-LEVEL TO SYLLABLE-LEVEL BY CONSTRAINING DYNAMIC TIME WARPING  &hellip;</a></h3><div class="gs_a">D ISKANDAR - 2007 - scholarbank.nus.sg</div><div class="gs_rs">The problem we consider in this thesis is synchronization between lyric text and the <br>corresponding singing voice recording. We limit the singing to the pop genre to make the <br>problem manageable. The recordings we consider in this problem are those we can <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:q87ftenzmuwJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17049207524468706987&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'q87ftenzmuwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5571465" class=yC20>Design of an Architecture for</a></h3><div class="gs_a">S Mammen, I Krishnamurthi&hellip; - &hellip;  Computing (ICIIC), 2010  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The main goal of our work is to develop a framework which can train students on <br>musical instruments. The student&#39;s musical instrument can be connected to the framework <br>through MIDI connection. The framework receives input both from the MIDI instrument and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:T8Bj_VEd0CEJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2436479636388167759&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'T8Bj_VEd0CEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB18" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW18"><a href="http://laurentoudre.fr/publis/LO-PHDfr-10.pdf" class=yC22><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from laurentoudre.fr</span><span class="gs_ggsS">laurentoudre.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://laurentoudre.fr/publis/LO-PHDfr-10.pdf" class=yC21>Laurent OUDRE</a></h3><div class="gs_a">DE Rapporteurs, S Marchand - laurentoudre.fr</div><div class="gs_rs">Ce premier chapitre vise Ã  introduire les principales notions musicales nÃ©cessaires Ã  la <br>bonne comprÃ©hension du prÃ©sent document, mais aussi Ã  prÃ©ciser le contexte et les <br>principales applications de ce travail de thÃ¨se.</div><div class="gs_fl"><a href="/scholar?q=related:PPdVPuMCoxEJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1270862694875264828&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'PPdVPuMCoxEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md18', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md18" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:PPdVPuMCoxEJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="http://www.db-thueringen.de/servlets/DerivateServlet/Derivate-23720/ilm1-2011000164.pdf" class=yC24><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from db-thueringen.de</span><span class="gs_ggsS">db-thueringen.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.db-thueringen.de/servlets/DerivateServlet/Derivate-23720/ilm1-2011000164.pdf" class=yC23>Ein Beitrag zur tonraumbasierten Analyse und Synthese musikalischer Audiosignale</a></h3><div class="gs_a">IT Sporer, T KrÃ¤mer - db-thueringen.de</div><div class="gs_rs">Im ersten Teil, der die Kapitel 2 bis 6 enthÃ¤lt und von Gabriel Gatzsche verfasst wurde, erfolgt <br>die mathematisch-geometrische Beschreibung der TonalitÃ¤t auf verschiedenen hierarchischen <br>Ebenen angelehnt an Fred Lerdahls Tonal Pitch Space, David Gatzsches Kadenzkreis <b> ...</b> </div><div class="gs_fl"><a href="/scholar?q=related:KJPIThOZopUJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10782348766083584808&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'KJPIThOZopUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md19', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md19" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:KJPIThOZopUJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB20" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW20"><a href="http://tel.archives-ouvertes.fr/docs/00/54/28/40/PDF/These_fr_en.pdf" class=yC26><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://tel.archives-ouvertes.fr/pastel-00542840/" class=yC25>Reconnaissance d&#39;accords Ã  partir de signaux audio par l&#39;utilisation de gabarits thÃ©oriques</a></h3><div class="gs_a"><a href="/citations?user=aSXlodEAAAAJ&amp;hl=en&amp;oi=sra">L Oudre</a> - 2010 - tel.archives-ouvertes.fr</div><div class="gs_rs">RÃ©sumÃ© Cette thÃ¨se s&#39; inscrit dans le cadre du traitement du signal musical, en se focalisant <br>plus particuliÃ¨rement sur la transcription automatique de signaux audio en accords. En effet, <br>depuis une dizaine d&#39;annÃ©es, de nombreux travaux visent Ã  reprÃ©senter les signaux <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:afhmW5HEmVcJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6312292481319237737&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'afhmW5HEmVcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="http://tel.archives-ouvertes.fr/docs/00/54/89/52/PDF/Papadopoulos_Thesis.pdf" class=yC28><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://tel.archives-ouvertes.fr/tel-00548952/" class=yC27>Estimation conjointe d&#39;information de contenu musical d&#39;un signal audio</a></h3><div class="gs_a">H Papadopoulos - 2010 - tel.archives-ouvertes.fr</div><div class="gs_rs">RÃ©sumÃ© Dans cette these, nous nous intÃ©ressons au probleme de l&#39;extraction automatique <br>d&#39;informations de contenu d&#39;un signal audio de musique. La plupart des travaux existants <br>abordent ce probleme en considÃ©rant les attributs musicaux de maniere indÃ©pendante les <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:B-SObITZT2wJ:scholar.google.com/&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7804695842036573191&amp;hl=en&amp;num=22&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'B-SObITZT2wJ')" href="#" class="gs_nph">Cite</a></div></div></div>
