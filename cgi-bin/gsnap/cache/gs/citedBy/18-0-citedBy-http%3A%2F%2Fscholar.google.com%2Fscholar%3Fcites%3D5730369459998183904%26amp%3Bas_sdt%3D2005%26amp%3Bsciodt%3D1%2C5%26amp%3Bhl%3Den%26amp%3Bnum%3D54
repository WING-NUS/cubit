Total results = 18
<div class="gs_r" style="z-index:400"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/AM7558R84445558T.pdf" class=yC0>U-shaped, iterative, and iterative-with-counter learning</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, SE Moelius - Machine Learning, 2008 - Springer</div><div class="gs_rs">Abstract This paper solves an important problem left open in the literature by showing that U-<br>shapes are unnecessary in iterative learning from positive data. A U-shape occurs when a <br>learner first learns, then unlearns, and, finally, relearns, some target concept. Iterative <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3868849313996447409&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 13</a> <a href="/scholar?q=related:sZ5F-vPpsDUJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/14/04/RN231197058.html?source=googlescholar" class="gs_nph" class=yC1>BL Direct</a> <a href="/scholar?cluster=3868849313996447409&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'sZ5F-vPpsDUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0890540108000266" class=yC2>Learning in Friedberg numberings</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, F Stephan - Information and Computation, 2008 - Elsevier</div><div class="gs_rs">In this paper we consider learnability in some special numberings, such as Friedberg <br>numberings, which contain all the recursively enumerable languages, but have simpler <br>grammar equivalence problem compared to acceptable numberings. We show that every <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=243296875089145118&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 9</a> <a href="/scholar?q=related:Hq2mBjhdYAMJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=243296875089145118&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'Hq2mBjhdYAMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://colt2010.haifa.il.ibm.com/presentation/COLT10Talk-NUTechniques.pdf" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ibm.com</span><span class="gs_ggsS">ibm.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://colt2010.haifa.il.ibm.com/presentation/COLT10Talk-NUTechniques.pdf" class=yC3>Strongly non-U-shaped learning results by general techniques</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, T KÃ¶tzing - Proceedings of COLT (Conference on  &hellip;, 2010 - colt2010.haifa.il.ibm.com</div><div class="gs_rs">Let N={0, 1, 2,...}, the set of all natural numbers. A language is a set Lâ N. A presentation for <br>L is essentially an (infinite) listing T of all and only the elements of L. Such a T is called a text <br>for L. We numerically name programs or grammars in some standard general hypothesis <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16271890449647034039&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 9</a> <a href="/scholar?q=related:t15I2yZe0eEJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16271890449647034039&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'t15I2yZe0eEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md2', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md2" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:t15I2yZe0eEJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2613/1/TR11-07.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/D56708146217R601.pdf" class=yC5>Learning in Friedberg numberings</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, F Stephan - Algorithmic Learning Theory, 2007 - Springer</div><div class="gs_rs">In this paper we consider learnability in some special numberings, such as Friedberg <br>numberings, which contain all the recursively enumerable languages, but have simpler <br>grammar equivalence problem compared to acceptable numberings. We show that every <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12222878631934212208&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 6</a> <a href="/scholar?q=related:cLgmLVtjoKkJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/1F/45/RN216180780.html?source=googlescholar" class="gs_nph" class=yC7>BL Direct</a> <a href="/scholar?cluster=12222878631934212208&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 26 versions</a> <a onclick="return gs_ocit(event,'cLgmLVtjoKkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://www.cis.udel.edu/~moelius/publications/iteqnuit_mlj_preprint.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from udel.edu</span><span class="gs_ggsS">udel.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/K6565966X8828563.pdf" class=yC8>U-shaped, iterative, and iterative-with-counter learning</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, S Moelius - Learning Theory, 2007 - Springer</div><div class="gs_rs">This paper solves an important problem left open in the literature by showing that U-shapes <br>are unnecessary in iterative learning. A U-shape occurs when a learner first learns, then <br>unlearns, and, finally, relearns, some target concept. Iterative learning is a Gold-style <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13027096633014401606&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 5</a> <a href="/scholar?q=related:RrqCAV6LybQJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/30/40/RN210335558.html?source=googlescholar" class="gs_nph" class=yCA>BL Direct</a> <a href="/scholar?cluster=13027096633014401606&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'RrqCAV6LybQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://cs5235.userapi.com/u133638729/docs/e02780dda47c/Yoav_Freund_Algorithmic_Learning_Theory_19_conf.pdf#page=431" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from userapi.com</span><span class="gs_ggsS">userapi.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/1N4582H1226U0066.pdf" class=yCB>Optimal language learning</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, S Moelius - Algorithmic Learning Theory, 2008 - Springer</div><div class="gs_rs">Gold&#39;s original paper on inductive inference introduced a notion of an optimal learner. <br>Intuitively, a learner identifies a class of objects optimally iff there is no other learner that: <br>requires as little of each presentation of each object in the class in order to identify that <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4359389727217022240&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 7</a> <a href="/scholar?q=related:IPVBINypfzwJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4359389727217022240&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'IPVBINypfzwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://www.comp.nus.edu.sg/~sanjay/paps/hypdep.pdf" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0890540110002026" class=yCD>Hypothesis spaces for learning</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a> - Information and Computation, 2011 - Elsevier</div><div class="gs_rs">In this paper we survey some results in inductive inference showing how learnability of a <br>class of languages may depend on the hypothesis space chosen. Additionally, optimal <br>hypothesis spaces, usable for every learnable class, are considered. We also discuss <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12832226744634658204&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 5</a> <a href="/scholar?q=related:nE03dzw6FbIJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12832226744634658204&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'nE03dzw6FbIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/WW86604W658G5101.pdf" class=yCF>Solutions to open questions for non-U-shaped learning with memory limitations</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, T KÃ¶tzing - Algorithmic Learning Theory, 2010 - Springer</div><div class="gs_rs">A U-shape occurs when a learner first learns, then unlearns, and, finally, relearns, some <br>target concept. Within the framework of Inductive Inference, previous results have shown, for <br>example, that U-shapes are unnecessary for explanatory learning, but are necessary for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12332842702605565065&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 5</a> <a href="/scholar?q=related:ibyShxgPJ6sJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12332842702605565065&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'ibyShxgPJ6sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.108.2025&amp;rep=rep1&amp;type=pdf" class=yC11><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397509000620" class=yC10>Prescribed learning of re classes</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, F Stephan, N Ye - Theoretical Computer Science, 2009 - Elsevier</div><div class="gs_rs">This work extends studies of Angluin, Lange and Zeugmann on the dependence of learning <br>on the hypothesis space chosen for the language class in the case of learning uniformly <br>recursive language classes. The concepts of class-comprising (where the learner can <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4264170485848462433&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 3</a> <a href="/scholar?q=related:YdSz3nZgLTsJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4264170485848462433&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 20 versions</a> <a onclick="return gs_ocit(event,'YdSz3nZgLTsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/B827045M7662102M.pdf" class=yC12>Iterative learning from positive data and counters</a></h3><div class="gs_a">T KÃ¶tzing - Algorithmic Learning Theory, 2011 - Springer</div><div class="gs_rs">We analyze iterative learning in the limit from positive data with the additional information <br>provided by a counter. The simplest type of counter provides the current iteration number <br>(counting up from 0 to infinity), which is known to improve learning power over plain <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3496968209057278535&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 2</a> <a href="/scholar?q=related:R2qx8w66hzAJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3496968209057278535&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'R2qx8w66hzAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1903/1/tr51-05.pdf" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.comp.nus.edu.sg/dspace/handle/1900.100/1903" class=yC13>Memory-Limited U-Shaped Learning</a></h3><div class="gs_a">L CARLUCCI, <a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J CASE</a>, <a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S JAIN</a>, F STEPHAN - 2005 - dl.comp.nus.edu.sg</div><div class="gs_rs">Abstract: U-shaped learning is a learning behaviour in which the learner first learns <br>something, then unlearns it and finally relearns it. Such a behaviour, observed by <br>psychologists, for example, in the learning of past-tenses of English verbs, has been <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12730338166427747033&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 1</a> <a href="/scholar?q=related:2QKGOB0_q7AJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12730338166427747033&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'2QKGOB0_q7AJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2573/1/TRB9-07.pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://iospress.metapress.com/index/506U32192564M0H5.pdf" class=yC15>Prescribed learning of indexed families</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, F Stephan, Y Nan - Fundamenta Informaticae, 2008 - IOS Press</div><div class="gs_rs">This work extends studies of Angluin, Lange and Zeugmann on how learnability of a <br>language class depends on the hypothesis space used by the learner. While previous <br>studies mainly focused on the case where the learner chooses a particular hypothesis <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12875309711335374895&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 1</a> <a href="/scholar?q=related:L0BIVfdJrrIJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12875309711335374895&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 29 versions</a> <a onclick="return gs_ocit(event,'L0BIVfdJrrIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.145.8803&amp;rep=rep1&amp;type=pdf" class=yC18><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.145.8803&amp;rep=rep1&amp;type=pdf" class=yC17>Optimal language learning (expanded version)</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, SE Moelius - 2008 - Citeseer</div><div class="gs_rs">Abstract. Gold&#39;s original paper on inductive inference introduced a notion of an optimal <br>learner. Intuitively, a learner identifies a class of objects optimally iff there is no other learner <br>that: requires as little of each presentation of each object in the class in order to identify <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2574599541247357815&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 1</a> <a href="/scholar?q=related:d7PuVqTQuiMJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2574599541247357815&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'d7PuVqTQuiMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md12', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md12" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:d7PuVqTQuiMJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/12017035066353VR.pdf" class=yC19>Resource Restricted Computability Theoretic Learning: Illustrative Topics and Problems</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a> - Computation and Logic in the Real World, 2007 - Springer</div><div class="gs_rs">Computability theoretic learning theory (machine inductive inference) typically involves <br>learning programs for languages or functions from a stream of complete data about them <br>and, importantly, allows mind changes as to conjectured programs. This theory takes into <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:MIjRDNBNqiIJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/3B/42/RN210775594.html?source=googlescholar" class="gs_nph" class=yC1A>BL Direct</a> <a href="/scholar?cluster=2497894499293956144&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'MIjRDNBNqiIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0890540111001088" class=yC1B>Optimal language learning from positive data</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, SE Moelius - Information and Computation, 2011 - Elsevier</div><div class="gs_rs">GoldÊ¼s original paper on inductive inference introduced a notion of an optimal learner. <br>Intuitively, a learner identifies a class of objects optimally iff there is no other learner that: <br>requires as little of each presentation of each object in the class in order to identify that <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Lka8Q86r5ysJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3163686165639087662&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'Lka8Q86r5ysJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/812361171q2264pu.pdf" class=yC1C>Resource Restricted Computability Theoretic Learning: Illustrative Topics and Problems</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a> - Theory of Computing Systems, 2009 - Springer</div><div class="gs_rs">Abstract Computability theoretic learning theory (machine inductive inference) typically <br>involves learning programs for languages or functions from a stream of complete data about <br>them and, importantly, allows mind changes as to conjectured programs. This theory takes <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:cNGIg7j_YKkJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12205036158119891312&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'cNGIg7j_YKkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://www.eecis.udel.edu/~case/papers/pr2.pdf" class=yC1E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from udel.edu</span><span class="gs_ggsS">udel.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.eecis.udel.edu/~case/papers/pr2.pdf" class=yC1D>On the Necessity of U-Shaped Learning</a></h3><div class="gs_a">L Carlucci, <a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a> - eecis.udel.edu</div><div class="gs_rs">Abstract. A U-shaped curve in a cognitive-developmental trajectory refers to a three-step <br>process: good performance followed by bad performance followed by good performance <br>once again. U-shaped curves have been observed in a wide variety of cognitive-<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17336137048815070431&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'32wcjMtUlvAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md16', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md16" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:32wcjMtUlvAJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397512009310" class=yC1F>Memory-limited non-U-shaped learning with solved open problems</a></h3><div class="gs_a"><a href="/citations?user=lMV_QwEAAAAJ&amp;hl=en&amp;oi=sra">J Case</a>, T KÃ¶tzing - Theoretical Computer Science, 2012 - Elsevier</div><div class="gs_rs">Herein we also distinguish between semantic and syntactic U-shapes. We answer a number <br>of open questions in the prior literature as well as provide new results regarding syntactic <br>U-shapes. Importantly for cognitive science, we see more of a previously noticed pattern <b> ...</b> </div><div class="gs_fl"><a onclick="return gs_ocit(event,'zUS4nbYRNscJ')" href="#" class="gs_nph">Cite</a></div></div></div>
