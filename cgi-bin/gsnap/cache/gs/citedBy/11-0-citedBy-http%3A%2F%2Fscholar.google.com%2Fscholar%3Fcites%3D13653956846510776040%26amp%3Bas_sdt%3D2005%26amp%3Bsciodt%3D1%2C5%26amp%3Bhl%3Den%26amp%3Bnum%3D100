Total results = 11
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://repository.cmu.edu/cgi/viewcontent.cgi?article=1224&amp;context=hcii" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cmu.edu</span><span class="gs_ggsS">cmu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1125635" class=yC0>Cherish: smart digital photo frames for sharing social narratives at home</a></h3><div class="gs_a">J Kim, <a href="/citations?user=A-4JUL4AAAAJ&amp;hl=en&amp;oi=sra">J Zimmerman</a> - CHI&#39;06 extended abstracts on Human factors in  &hellip;, 2006 - dl.acm.org</div><div class="gs_rs">Abstract The introduction and rapid acceptance of digital cameras has fundamentally <br>changed the way people take and share images. When displaying and interacting with <br>images in the home, people still print out the photos as if they had been taken on a film <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3532538921143439412&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11">Cited by 32</a> <a href="/scholar?q=related:NBD_vW4ZBjEJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3532538921143439412&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'NBD_vW4ZBjEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://www.sandhaus-ol.de/wp-content/papercite-data/pdf/boll2007.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from sandhaus-ol.de</span><span class="gs_ggsS">sandhaus-ol.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/1257364T56U6157G.pdf" class=yC2>Metaxaâcontext-and content-driven metadata enhancement for personal photo books</a></h3><div class="gs_a"><a href="/citations?user=1vsF_kYAAAAJ&amp;hl=en&amp;oi=sra">S Boll</a>, P Sandhaus, <a href="/citations?user=LFTRuMEAAAAJ&amp;hl=en&amp;oi=sra">A Scherp</a>, S Thieme - Advances in multimedia  &hellip;, 2006 - Springer</div><div class="gs_rs">Making a photo book as a special gift to your beloved can be very time-consuming. One has <br>to carefully select and arrange the pictures nicely over the pages of a previously bought <br>photo book. In these days, photo finisher companies are able to directly print and bind a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13340395067208093925&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11">Cited by 16</a> <a href="/scholar?q=related:5dBPGKKaIrkJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13340395067208093925&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 17 versions</a> <a onclick="return gs_ocit(event,'5dBPGKKaIrkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/pt87804r8r721136.pdf" class=yC4>Semantic analysis and retrieval in personal and social photo collections</a></h3><div class="gs_a">P Sandhaus, <a href="/citations?user=1vsF_kYAAAAJ&amp;hl=en&amp;oi=sra">S Boll</a> - Multimedia Tools and Applications, 2011 - Springer</div><div class="gs_rs">Abstract Semantic understanding of images has been an important topic in the research <br>community for a long time as it is an important prerequisite to build meaningful retrieval <br>systems which are accessible by both users and automatic reasoning algorithms. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13896392617743481556&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11">Cited by 14</a> <a href="/scholar?q=related:1Pr1p3Xn2cAJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13896392617743481556&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'1Pr1p3Xn2cAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://144.206.159.178/ft/CONF/16408942/16408953.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 144.206.159.178</span><span class="gs_ggsS">144.206.159.178 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://spiedigitallibrary.org/data/Conferences/SPIEP/17627/68200C_1.pdf" class=yC5>Event-centric media management</a></h3><div class="gs_a">A Scherpa, S Agaramb, R Jainb - 2008 - spiedigitallibrary.org</div><div class="gs_rs">ABSTRACT The management of the vast amount of media assets captured at every day <br>events such as meetings, birthday parties, vacation, and conferences has become an <br>increasingly challenging problem. Today, most media management applications are <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10801831627491795646&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11">Cited by 10</a> <a href="/scholar?q=related:vmI6eKLQ55UJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10801831627491795646&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 19 versions</a> <a onclick="return gs_ocit(event,'vmI6eKLQ55UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://www.cmlab.csie.ntu.edu.tw/~chenhsiu/research/iscas2005_Oct4.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntu.edu.tw</span><span class="gs_ggsS">ntu.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1465186" class=yC7>A musical-driven video summarization system using content-aware mechanisms</a></h3><div class="gs_a">CH Huang, CH Wu, JH Kuo&hellip; - Circuits and Systems, 2005 &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose a music-driven summarization system for home videos <br>based on several content-aware mechanisms. Many audio and video features are employed <br>to help analyzing and synchronizing input audios and videos. The synchronization is <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12446914328682309027&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11">Cited by 7</a> <a href="/scholar?q=related:oyXUpqJSvKwJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/50/3C/RN173405143.html?source=googlescholar" class="gs_nph" class=yC9>BL Direct</a> <a href="/scholar?cluster=12446914328682309027&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'oyXUpqJSvKwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://www.dcc.unicamp.br/~oliveira/doc/MHCI2009_MAMI.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unicamp.br</span><span class="gs_ggsS">unicamp.br <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1613860" class=yCA>Text versus speech: a comparison of tagging input modalities for camera phones</a></h3><div class="gs_a"><a href="/citations?user=szEMs8MAAAAJ&amp;hl=en&amp;oi=sra">M Cherubini</a>, <a href="/citations?user=Sg0XkAsAAAAJ&amp;hl=en&amp;oi=sra">X Anguera</a>, N Oliver&hellip; - Proceedings of the 11th  &hellip;, 2009 - dl.acm.org</div><div class="gs_rs">Abstract Speech and typed text are two common input modalities for mobile phones. <br>However, little research has compared them in their ability to support annotation and <br>retrieval of digital pictures on mobile devices. In this paper, we report the results of a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6350233493441078125&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11">Cited by 6</a> <a href="/scholar?q=related:beNXobePIFgJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6350233493441078125&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'beNXobePIFgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://www.hindawi.com/journals/am/aip/592690/" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from hindawi.com</span><span class="gs_ggsS">hindawi.com <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1453719" class=yCC>On the design and exploitation of user&#39;s personal and public information for semantic personal digital photograph annotation</a></h3><div class="gs_a">S Sarin, T Nagahashi, T Miyosawa&hellip; - Advances in  &hellip;, 2008 - dl.acm.org</div><div class="gs_rs">Abstract Automating the process of semantic annotation of digital personal photographs is a <br>crucial step towards efficient and effective management of this increasingly high volume of <br>content. However, this is still a highly challenging task for the research community. This <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7015679221044812584&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=11">Cited by 3</a> <a href="/scholar?q=related:KBt3tBSzXGEJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7015679221044812584&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'KBt3tBSzXGEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Interface for EMME</h3><div class="gs_a">D Phong Vuong, R Jain - 2009</div><div class="gs_fl"><a href="/scholar?q=related:ZVlFPtKHFjoJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'ZVlFPtKHFjoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://www.penerbit.utm.my/bookchapterdoc/FSKSM/bookchapter_fsksm05.pdf#page=17" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from utm.my</span><span class="gs_ggsS">utm.my <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.penerbit.utm.my/bookchapterdoc/FSKSM/bookchapter_fsksm05.pdf#page=17" class=yCE>Bridging the personal digital photo annotation and retrieval gap in user oriented image query</a></h3><div class="gs_a"><a href="/citations?user=irGmToYAAAAJ&amp;hl=en&amp;oi=sra">NA Ismail</a>, SA Ramlan - Nor Azman Ismail Nur Zuraifah Syazrah  &hellip;, 2008 - penerbit.utm.my</div><div class="gs_rs">Photos can be in non-digital or digital form. Photos are valuable and historical things <br>because they are powerful in expressing the implicit storytelling other than to deliver visions <br>or ideas. Photos can be a role player in expressing their feelings. As a result, people now <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:9DfkUSYRBmcJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7423639892047181812&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'9DfkUSYRBmcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md8', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md8" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:9DfkUSYRBmcJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://yokoya.naist.jp/paper/datas/1057/civr2168-iwasaki.pdf" class=yC11><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from naist.jp</span><span class="gs_ggsS">naist.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1386381" class=yC10>Construction of extended geographical database based on photo shooting history</a></h3><div class="gs_a">K Iwasaki, M Kanbara, K Yamazawa&hellip; - Proceedings of the 2008  &hellip;, 2008 - dl.acm.org</div><div class="gs_rs">Abstract This study proposes an extended geographical database based on photo shooting <br>history to enable the suggestion of candidate captions to newly shot photos. The extended <br>geographical database consists of not only subject positions but also the likely shooting <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:s1RGUrNrToEJ:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9317503096999793843&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'s1RGUrNrToEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://www.ansgarscherp.net/publications/2006-BollSandhausScherpThieme-MIRAusDerPerspektiveEinesFotoalbums.pdf" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ansgarscherp.net</span><span class="gs_ggsS">ansgarscherp.net <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ansgarscherp.net/publications/2006-BollSandhausScherpThieme-MIRAusDerPerspektiveEinesFotoalbums.pdf" class=yC12>Ansichten eines Fotoalbums zu Multimedia Information Retrieval</a></h3><div class="gs_a">MIR Gebiet, DE wurden mit unserem Projektpartner - ansgarscherp.net</div><div class="gs_rs">Kurzfassung Nach einer Reise oder einer Feier mÃ¶chte man oft aus den aufgenommenen <br>Erlebnissen die schÃ¶nsten Momente heraussuchen und die Bilder zum Erlebnis in einem <br>Album einkleben. Allerdings sind die richtige Auswahl der Bilder und deren schÃ¶nes <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:8EgcYnrr1H0J:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9067130860668209392&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'8EgcYnrr1H0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md10', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md10" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:8EgcYnrr1H0J:scholar.google.com/&amp;hl=en&amp;num=11&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
