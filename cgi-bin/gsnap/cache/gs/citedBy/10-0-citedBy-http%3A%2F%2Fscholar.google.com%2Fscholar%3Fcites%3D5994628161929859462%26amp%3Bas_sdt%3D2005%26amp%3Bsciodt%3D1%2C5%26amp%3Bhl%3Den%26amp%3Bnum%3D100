Total results = 10
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://eprints.ucl.ac.uk/13464/1/13464.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ucl.ac.uk</span><span class="gs_ggsS">ucl.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1703508" class=yC0>Experiential sampling in multimedia systems</a></h3><div class="gs_a">MS Kankanhalli, <a href="/citations?user=wIE1tY4AAAAJ&amp;hl=en&amp;oi=sra">J Wang</a>, R Jain - &hellip; , IEEE Transactions on, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Multimedia systems must deal with multiple data streams. Each data stream usually <br>contains significant volume of redundant noisy data. In many real-time applications, it is <br>essential to focus the computing resources on a relevant subset of data streams at any <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11124570279645081716&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 20</a> <a href="/scholar?q=related:dPAclbppYpoJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/45/63/RN197726464.html?source=googlescholar" class="gs_nph" class=yC2>BL Direct</a> <a href="/scholar?cluster=11124570279645081716&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 22 versions</a> <a onclick="return gs_ocit(event,'dPAclbppYpoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://www.imaging.utk.edu/publications/papers/2008/acm-cs-bra.pdf" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from utk.edu</span><span class="gs_ggsS">utk.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1456657" class=yC3>Survey and analysis of multimodal sensor planning and integration for wide area surveillance</a></h3><div class="gs_a">BR Abidi, NR Aragam, Y Yao, MA Abidi - ACM Computing Surveys ( &hellip;, 2008 - dl.acm.org</div><div class="gs_rs">Abstract Although sensor planning in computer vision has been a subject of research for <br>over two decades, a vast majority of the research seems to concentrate on two particular <br>applications in a rather limited context of laboratory and industrial workbenches, namely <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4718587992432694438&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 18</a> <a href="/scholar?q=related:ptRfasfKe0EJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4718587992432694438&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'ptRfasfKe0EJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://opticalengineering.spiedigitallibrary.org/article.aspx?articleid=1089215%20" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from spiedigitallibrary.org</span><span class="gs_ggsS">spiedigitallibrary.org <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[HTML]</span><span class="gs_ct2">[HTML]</span></span> <a href="http://opticalengineering.spiedigitallibrary.org/article.aspx?articleid=1089215%20" class=yC5>Multiple-priority region-of-interest H. 264 video compression using constraint variable bitrate control for video surveillance</a></h3><div class="gs_a">CM Huang, CW Lin - Optical Engineering, 2009 - opticalengineering.spiedigitallibrary. &hellip;</div><div class="gs_rs">With the growth of digital video surveillance markets and requirements of high-quality <br>surveillance data, an efficient video compression technique that is suitable for surveillance <br>applications and is compatible with emerging coding standards (eg, H. 264) is required <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4770227864224665913&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 4</a> <a href="/scholar?q=related:ORHIAPhAM0IJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4770227864224665913&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'ORHIAPhAM0IJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md2', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md2" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:ORHIAPhAM0IJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="https://doc.novay.nl/dsweb/Get/Version-21777/Experiental%20Sampling%20for%20Monitoring.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from novay.nl</span><span class="gs_ggsS">novay.nl <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="https://doc.novay.nl/dsweb/Get/Version-21777/Experiental%20Sampling%20for%20Monitoring.pdf" class=yC7>Experiential Sampling for Monitoring</a></h3><div class="gs_a">WQYMS Kankanhalli, WJMJT Reinders - 2003 - doc.novay.nl</div><div class="gs_rs">ABSTRACT This demonstration presents a novel prototype of experiential sampling for <br>monitoring in a multi-camera setting. The system utilizes the experiential sampling technique <br>to compute the importance of each frame in multiple video streams, and selects the most <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:zlllQRWCoc0J:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14817267276828727758&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'zlllQRWCoc0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md3', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md3" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:zlllQRWCoc0J:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=982484.982497" class=yC9>Experiential sampling for monitoring</a></h3><div class="gs_a">WQ Yan, MS Kankanhalli, J Wang&hellip; - Proceedings of the 2003  &hellip;, 2003 - dl.acm.org</div><div class="gs_rs">Abstract This demonstration presents a novel prototype of experiential sampling for <br>monitoring in a multi-camera setting. The system utilizes the experiential sampling technique <br>to compute the importance of each frame in multiple video streams, and selects the most <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:VaVPYpYnYI0J:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10187185883960026453&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'VaVPYpYnYI0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6113506" class=yCA>A Framework of Heterogeneous Real-Time Video Surveillance Network Management System</a></h3><div class="gs_a">W Jinyi, Y Baoping - Information Technology, Computer  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Real-time video surveillance is valuable for ethology. In order to support the study <br>of Anser indicus&#39;s breeding period behavior, a real-time video surveillance network <br>management system must be constructed for scientists. Through requirements analysis, a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:2Rp6ag0SUhMJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1392195083641166553&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'2Rp6ag0SUhMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://www.comp.nus.edu.sg/~mohan/papers/mmas.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/ANUKC34M23G9MBJH.pdf" class=yCB>Multimedia analysis and synthesis</a></h3><div class="gs_a">M Kankanhalli - AI 2003: Advances in Artificial Intelligence, 2003 - Springer</div><div class="gs_rs">We describe novel approaches to multimedia analysis and synthesis problems. We first <br>present the experiential sampling technique which has the ability to focus on the analysis <br>task by making use of the contextual information. Sensor samples are used to gather <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:t5HWlg4ROjIJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/18/3A/RN141850840.html?source=googlescholar" class="gs_nph" class=yCD>BL Direct</a> <a href="/scholar?cluster=3619224004903473591&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'t5HWlg4ROjIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://r203-2.crt.ntust.edu.tw/www/index.php/JCIE/article/viewFile/1014/531" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntust.edu.tw</span><span class="gs_ggsS">ntust.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.tandfonline.com/doi/abs/10.1080/02533839.2009.9671527" class=yCE>IPSâICC an IPâsurveillance platform using interactive cameraâhandoff control</a></h3><div class="gs_a">CM Huang, CW Lin, CC Yang - Journal of the Chinese Institute of  &hellip;, 2009 - Taylor &amp; Francis</div><div class="gs_rs">Abstract In this paper, we develop an IPâsurveillance platform using interactive cameraâ<br>handoff control, which is called IPSâICC. In addition to fundamental teleâsurveillance <br>functions, emerging techniques of IPSâICC contain flexible surveillance description <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:5C3N9TC0Z6YJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11990750655272529380&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'5C3N9TC0Z6YJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://tech.nagaokaut.ac.jp/lecturenote/project/FLC(pricacy).pdf" class=yC11><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nagaokaut.ac.jp</span><span class="gs_ggsS">nagaokaut.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://tech.nagaokaut.ac.jp/lecturenote/project/FLC(pricacy).pdf" class=yC10>JPEG2000 ã«åºã¥ããã©ã¤ãã·ã¼ã«éæ®ããäººç©ã¢ãã¿ãªã³ã°ã·ã¹ãã </a></h3><div class="gs_a">é´æ¨è²´ä¹ï¼ å²©æ©æ¿å® - ç ç©¶ä¼è¬æ¼äºç¨¿, 2006 - tech.nagaokaut.ac.jp</div><div class="gs_rs">ããã¾ã æ¬å ±åã§ã¯, éå¸¸ã¯è¶ä½ãããã¬ã¼ãã®ãã¼ã¿éä¿¡ã§ ãã¢ã¦ã§ã¢ãã¹ã ãè¡¨ç¤ºã, <br>å¿è¦æã«ã¯è¿½å æå ±ããéä¿¡ãããã¨ã§ ãæ åã ãè¡¨ç¤ºã§ããæ°ããã¿ã¤ãã®æ åéä¿¡ã·ã¹ãã ã<br>ææ¡ãã.ãã¢ã¦ã§ã¢ãã¹ã ã¯äººã®å­å¨ãåããæå³ã, ããã ãã§ã¯äººç©ã®è©³ç´°ã¯ç¹å®ã§ãã ã<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:KDjZu3xnF2QJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7212347113682319400&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'KDjZu3xnF2QJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md8', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md8" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:KDjZu3xnF2QJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> <a href="http://ci.nii.ac.jp/naid/10019823250/" class=yC12>JPEG2000 ãæ´»ç¨ããã¢ã¦ã§ã¢ãã¹æ åéä¿¡ã·ã¹ãã </a></h3><div class="gs_a">ã¿ã³ã¹ãªã¤ãã³ã¹ãªã¨ã³ï¼ é´æ¨è²´ä¹ï¼ å²©æ©æ¿å® - ç»åé»å­å­¦ä¼èª= Imaging &amp;  &hellip;, 2007 - ci.nii.ac.jp</div><div class="gs_fl"><a href="/scholar?q=related:xAJT422XH1AJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5773499745533362884&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'xAJT422XH1AJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md9', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md9" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:xAJT422XH1AJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
