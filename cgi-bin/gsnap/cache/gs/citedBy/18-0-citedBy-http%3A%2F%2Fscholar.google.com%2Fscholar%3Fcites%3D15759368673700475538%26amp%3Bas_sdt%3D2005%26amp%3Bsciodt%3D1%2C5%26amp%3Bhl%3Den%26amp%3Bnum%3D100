Total results = 18
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://hal.archives-ouvertes.fr/docs/00/64/74/59/PDF/288r-rouanet.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6281349" class=yC0>A robotic game to evaluate interfaces used to show and teach visual objects to a robot in real world condition</a></h3><div class="gs_a">P Rouanet, F Danieau&hellip; - Human-Robot Interaction ( &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present a real world user study of 4 interfaces designed to teach <br>new visual objects to a social robot. This study was designed as a robotic game in order to <br>maintain the user&#39;s motivation during the whole experiment. Among the 4 interfaces 3 <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9838466836016497774&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 4</a> <a href="/scholar?q=related:boQ5_3VBiYgJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9838466836016497774&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'boQ5_3VBiYgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://c15x4fug.securesites.net/projects/snappy/HRI2010_Hashimoto.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from securesites.net</span><span class="gs_ggsS">securesites.net <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1734519" class=yC2>Photograph-based interaction for teaching object delivery tasks to robots</a></h3><div class="gs_a">S Hashimoto, A Ostanin, M Inami&hellip; - Proceedings of the 5th  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract Personal photographs are important media for communication in our daily lives. <br>People take photos to remember things about themselves and show them to others to share <br>the experience. We expect that a photograph can be useful tool for teaching a task to a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5844540996044252013&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 3</a> <a href="/scholar?q=related:beNs-BH7G1EJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5844540996044252013&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'beNs-BH7G1EJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www.designinterface.jp/en/projects/BlinkBot/BlinkBot.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from designinterface.jp</span><span class="gs_ggsS">designinterface.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1866238" class=yC4>Blinkbot: look at, blink and move</a></h3><div class="gs_a">P Mistry, K Ishii, M Inami, T Igarashi - Adjunct proceedings of the 23nd  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract In this paper we present BlinkBot-a hands free input interface to control and <br>command a robot. BlinkBot explores the natural modality of gaze and blink to direct a robot <br>to move an object from a location to another. The paper also explains detailed hardware <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4204127883264992201&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 2</a> <a href="/scholar?q=related:ySNTEAkQWDoJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4204127883264992201&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'ySNTEAkQWDoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="https://www.designinterface.jp/projects/Roboshop/Roboshop-CR.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from designinterface.jp</span><span class="gs_ggsS">designinterface.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1979035" class=yC6>Roboshop: multi-layered sketching interface for robot housework assignment and management</a></h3><div class="gs_a">K Liu, <a href="/citations?user=BJQ8tDsAAAAJ&amp;hl=en&amp;oi=sra">D Sakamoto</a>, M Inami, T Igarashi - Proceedings of the 2011 annual &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract As various home robots come into homes, the need for efficient robot task <br>management tools is arising. Current tools are designed for controlling individual robots <br>independently, so they are not ideally suitable for assigning coordinated action among <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1458459358119056180&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 2</a> <a href="/scholar?q=related:NNMHGA99PRQJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1458459358119056180&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'NNMHGA99PRQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2047259" class=yC8>Pub-point upon body: exploring eyes-free interaction and methods on an arm</a></h3><div class="gs_a">SY Lin, CH Su, KY Cheng, RH Liang, TH Kuo&hellip; - Proceedings of the 24th &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract This paper presents a novel interaction system, PUB (Point Upon Body), to explore <br>eyes-free interaction in a personal space by allowing users tapping on their own arms to be <br>provided with haptic feedback from their skin. Two user studies determine how users can <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7192083004828005830&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 5</a> <a href="/scholar?q=related:xrXlOWNpz2MJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'xrXlOWNpz2MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://hci.comp.nus.edu.sg/modules/2009f_documents/LFSX_final_Report.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://hci.comp.nus.edu.sg/modules/2009f_documents/LFSX_final_Report.pdf" class=yC9>Explore the Design Space of Using GWAP to Enhance Human Robot Interaction</a></h3><div class="gs_a">QKHTHY Bo - 2009 - hci.comp.nus.edu.sg</div><div class="gs_rs">Executive Summary Robots used in domestic services provide us a new context to explore <br>Human Robot Interaction (HRI). Previous researches have explored the design space of <br>explicitly and implicitly control robot by robot user. In this project, we are trying to expand <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:6VEOB4nYVZEJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10472514591560454633&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'6VEOB4nYVZEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md5', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md5" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:6VEOB4nYVZEJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://hal.inria.fr/docs/00/75/82/41/PDF/tro-2010-v10.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from inria.fr</span><span class="gs_ggsS">inria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6384810" class=yCB>The Impact of Human--Robot Interfaces on the Learning of Visual Objects</a></h3><div class="gs_a">P Rouanet, <a href="/citations?user=7mfRbX0AAAAJ&amp;hl=en&amp;oi=sra">PY Oudeyer</a>, F Danieau, <a href="/citations?user=Wzq_c20AAAAJ&amp;hl=en&amp;oi=sra">D Filliat</a> - 2013 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper studies the impact of interfaces, allowing nonexpert users to efficiently <br>and intuitively teach a robot to recognize new visual objects. We present challenges that <br>need to be addressed for real-world deployment of robots capable of learning new visual <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'VoEWSX8FKVoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6119727" class=yCD>Development of position recording system on structural surface using laser pointer</a></h3><div class="gs_a">H Seki, T Fukumura, Y Kamiya&hellip; - IECON 2011-37th Annual &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Surfaces of old structures are inspected by workers and the positions of the <br>damaged places are manually recorded for their maintenance. In order to lighten this work, <br>we propose a novel system to record position on structural surface by a laser pointer and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:-aAQTAE8X_cJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'-aAQTAE8X_cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://cdn.intechopen.com/pdfs/40261/InTech-Design_and_evaluation_of_cell_phone_pointing_interface_for_robot_control.pdf" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from intechopen.com</span><span class="gs_ggsS">intechopen.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://cdn.intechopen.com/pdfs/40261/InTech-Design_and_evaluation_of_cell_phone_pointing_interface_for_robot_control.pdf" class=yCE>Design and Evaluation of Cell Phone Pointing Interface for Robot Control</a></h3><div class="gs_a">S Koceski, N Koceska, I Kocev - Int J Adv Robotic Sy, 2012 - cdn.intechopen.com</div><div class="gs_rs">Abstract In this work a pointing interface based on human gestures using a mobile phone <br>accelerometer for interaction with robots is proposed. Through this interface the user can <br>sketch stroke gestures on a computer screen using the cell phone accelerometer to make <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'YqiEVvmAUZsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md8', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md8" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:YqiEVvmAUZsJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0020025512007852" class=yC10>Efficient Jitter Compensation Using Double Exponential Smoothing</a></h3><div class="gs_a">MG Chung, SK Kim - Information Sciences, 2012 - Elsevier</div><div class="gs_rs">This paper proposes a new jitter reduction scheme based on double exponential smoothing <br>(DES). We compare this DES-based method to jitter reduction methods based on the <br>Kalman filter (KF) and extended Kalman filter (EKF), two well-known methods of jitter <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'wyONh_OJh4cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6181591" class=yC11>Interactions with a line-follower: An interactive tabletop system with a markerless gesture interface for robot control</a></h3><div class="gs_a">T Fujiwara, Y Iwatani - Robotics and Biomimetics (ROBIO),  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract An interactive desktop system for robot control is presented in this paper. The <br>system consists of a digital desk, a markerless gesture interface and a line-follower. The <br>digital desk is a network system composed of a camera, a computer and a projector. Hand <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12757375476527414133&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 1</a> <a href="/scholar?q=related:dTuyiGdNC7EJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'dTuyiGdNC7EJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5976477" class=yC12>Sensors for Gesture Recognition Systems</a></h3><div class="gs_a">S Berman, H Stern - Systems, Man, and Cybernetics, Part C:  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract A gesture recognition system (GRS) is comprised of a gesture, gesture-capture <br>device (sensor), tracking algorithm (for motion capture), feature extraction, and classification <br>algorithm. With the impending movement toward natural communication with mechanical <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:dgpQkTYaMgUJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=374390540693670518&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'dgpQkTYaMgUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1959840" class=yC13>ClippingLight: a method for easy snapshots with projection viewfinder and tilt-based zoom control</a></h3><div class="gs_a">Y Kajiwara, K Tajimi, K Uemura, N Sakata&hellip; - Proceedings of the 2nd  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we present a novel method to take photos with a hand-held camera. <br>Cameras are being used for new purposes in our daily lives these days, such as to augment <br>human memory or scan visual markers (eg QR-codes) and opportunities to take <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16262366521776915537&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 1</a> <a href="/scholar?q=related:UcS3mTCIr-EJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'UcS3mTCIr-EJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://www.dominikschmidt.net/wp-content/uploads/2012/07/2012-Schmidt-D-PICOntrol.pdf" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from dominikschmidt.net</span><span class="gs_ggsS">dominikschmidt.net <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.dominikschmidt.net/wp-content/uploads/2012/07/2012-Schmidt-D-PICOntrol.pdf" class=yC14>PICOntrol: Using a Handheld Projector for Direct Control of Physical Devices through Visible Light</a></h3><div class="gs_a"><a href="/citations?user=IZOFEHwAAAAJ&amp;hl=en&amp;oi=sra">D Schmidt</a>, D Molyneaux, <a href="/citations?user=XprSyesAAAAJ&amp;hl=en&amp;oi=sra">X Cao</a> - 2012 - dominikschmidt.net</div><div class="gs_rs">ABSTRACT Today&#39;s environments are populated with a growing number of electric devices <br>which come in diverse form factors and provide a plethora of functions. However, rich <br>interaction with these devices can become challenging if they need be controlled from a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ZXTxpm0aHSsJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'ZXTxpm0aHSsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md13', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md13" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:ZXTxpm0aHSsJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://www.shengdongzhao.com/wp-content/uploads/2012/07/APCHI2012_cameraReady.pdf" class=yC17><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from shengdongzhao.com</span><span class="gs_ggsS">shengdongzhao.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/ft_gateway.cfm?id=2350076&amp;type=pdf" class=yC16>Robots in my contact list: Using social media platforms for human-robot interaction in domestic environment</a></h3><div class="gs_a">X Ma, X Yang, <a href="/citations?user=_I_s9LQAAAAJ&amp;hl=en&amp;oi=sra">S Zhao</a>, CW Fu, Z Lan, Y Pu - 2012 - dl.acm.org</div><div class="gs_rs">ABSTRACT This paper proposes to put domestic robots as buddies on our contact lists, <br>thereby extending the use of social media in interpersonal interaction further to human-robot <br>interaction (HRI). In detail, we present a robot management system that employs <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:peer7xKk6Y4J:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10297942424196736933&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'peer7xKk6Y4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://grouplab.cpsc.ucalgary.ca/grouplab/uploads/Publications/Publications/2011-TasksToRobots.Roman.pdf" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ucalgary.ca</span><span class="gs_ggsS">ucalgary.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6005235" class=yC18>An augmented reality system for teaching sequential tasks to a household robot</a></h3><div class="gs_a">R Fung, S Hashimoto, M Inami&hellip; - RO-MAN, 2011 IEEE, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We present a method of instructing a sequential task to a household robot using a <br>hand-held augmented reality device. The user decomposes a high-level goal such as <br>âprepare a drinkâ into steps such as delivering a mug under a kettle and pouring hot water <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:s8-Q_4Za3XkJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8781274384302133171&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'s8-Q_4Za3XkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://www.theses.fr/2012BOR14510/document" class=yC1B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from theses.fr</span><span class="gs_ggsS">theses.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.theses.fr/2012BOR14510/document" class=yC1A>Apprendre Ã  un robot Ã  reconnaÃ®tre des objets visuels nouveaux et Ã  les associer Ã  des mots nouveaux: le rÃ´le de l&#39;interface</a></h3><div class="gs_a">DFEEIP HdR, RGDARP HdR - theses.fr</div><div class="gs_rs">RÃ©sumÃ© Cette thÃ¨se s&#39; intÃ©resse au rÃ´le de l&#39;interface dans l&#39;interaction humain-robot pour <br>l&#39;apprentissage. Elle Ã©tudie comment une interface bien conÃ§ue peut aider les utilisateurs <br>non-experts Ã  guider l&#39;apprentissage social d&#39;un robot, notamment en facilitant les <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:kC4gkwAY5ScJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2874730327893356176&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'kC4gkwAY5ScJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md16', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md16" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:kC4gkwAY5ScJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://www-ui.is.s.u-tokyo.ac.jp/~takeo/papers/jrsj2010.pdf" class=yC1D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from u-tokyo.ac.jp</span><span class="gs_ggsS">u-tokyo.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www-ui.is.s.u-tokyo.ac.jp/~takeo/papers/jrsj2010.pdf" class=yC1C>ã­ãããã®ããã®ã¦ã¼ã¶ã¤ã³ã¿ãã§ã¼ã¹</a></h3><div class="gs_a">äºååµå¥å¤« - æ¥æ¬ã­ãããå­¦ä¼èª, 2010 - www-ui.is.su-tokyo.ac.jp</div><div class="gs_rs">1. ã¦ã¼ã¶ã¤ã³ã¿ãã§ã¼ã¹ã®å¿è¦æ§ iRobot ç¤¾ã®æé¤ã­ãããã«ä»£è¡¨ãããããã«ã­ããããå®éã«å®¶åº­<br>åã«å¥ã£ã¦ãã¦ãã, ããã«å°æ¥çã«ã¯, ASIMO ã HRP2 ã®ãããªãã¥ã¼ããã¤ããå®¶äºãæä¼ã£ã¦<br>ãããããã«ãªããã¨ãæå¾ããã¦ãã. ããã, ã©ããªã«é«åº¦ãªæ©è½ãæããã­ããããã§ããã¨ãã¦<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:E4SO0k5-gFsJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6593408731475510291&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'E4SO0k5-gFsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md17', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md17" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:E4SO0k5-gFsJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
