Total results = 29
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.comp.nus.edu.sg/~TANCL/publications/c2009/ICME09-VideoText-1069.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5202546" class=yC0>Video text detection based on filters and edge features</a></h3><div class="gs_a">P Shivakumara, <a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>&hellip; - Multimedia and Expo, 2009 &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Text detection plays a vital role in retrieving and browsing video data efficiently and <br>accurately. In this paper, we propose a method for detecting both graphics and scene text in <br>video images by proposing initial text block identification, text portion segmentation and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4212221655237374525&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=29">Cited by 17</a> <a href="/scholar?q=related:PbKhM0fRdDoJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4212221655237374525&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'PbKhM0fRdDoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="https://ftp.cse.ust.hk/~jamesk/papers/ivc10.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ust.hk</span><span class="gs_ggsS">ust.hk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0262885610000612" class=yC2>Text detection in images using sparse representation with discriminative dictionaries</a></h3><div class="gs_a">M Zhao, S Li, J Kwok - Image and Vision Computing, 2010 - Elsevier</div><div class="gs_rs">Text detection is important in the retrieval of texts from digital pictures, video databases and <br>webpages. However, it can be very challenging since the text is often embedded in a <br>complex background. In this paper, we propose a classification-based algorithm for text <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6425450223302338970&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=29">Cited by 18</a> <a href="/scholar?q=related:munjQe_IK1kJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6425450223302338970&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">All 19 versions</a> <a onclick="return gs_ocit(event,'munjQe_IK1kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://dx.plos.org/10.1371/journal.pone.0012983" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from plos.org</span><span class="gs_ggsS">plos.org <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[HTML]</span><span class="gs_ct2">[HTML]</span></span> <a href="http://dx.plos.org/10.1371/journal.pone.0012983" class=yC4>Automatic figure ranking and user interfacing for intelligent figure search</a></h3><div class="gs_a"><a href="/citations?user=TyXe64wAAAAJ&amp;hl=en&amp;oi=sra">H Yu</a>, <a href="/citations?user=g4uO4CgAAAAJ&amp;hl=en&amp;oi=sra">F Liu</a>, BP Ramesh - PloS one, 2010 - dx.plos.org</div><div class="gs_rs">Background Figures are important experimental results that are typically reported in full-text <br>bioscience articles. Bioscience researchers need to access figures to validate research facts <br>and to formulate or to test novel research hypotheses. On the other hand, the sheer <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17783232335272895305&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=29">Cited by 11</a> <a href="/scholar?q=related:SWMu3pa7yvYJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17783232335272895305&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'SWMu3pa7yvYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md2', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md2" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:SWMu3pa7yvYJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://www.icpr2010.org/pdfs/icpr2010_ThBT6.1.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from icpr2010.org</span><span class="gs_ggsS">icpr2010.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5597689" class=yC6>Text detection using edge gradient and graph spectrum</a></h3><div class="gs_a">J Zhang, <a href="/citations?user=EFB9ZuwAAAAJ&amp;hl=en&amp;oi=sra">R Kasturi</a> - Pattern Recognition (ICPR), 2010 20th  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose a new unsupervised text detection approach which is <br>based on Histogram of Oriented Gradient and Graph Spectrum. By investigating the <br>properties of text edges, the proposed approach first extracts text edges from an image <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14691831334724423341&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=29">Cited by 8</a> <a href="/scholar?q=related:rc4zHsLe48sJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14691831334724423341&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'rc4zHsLe48sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Graphics separation and skew correction for mobile captured documents and comparative analysis with existing methods</h3><div class="gs_a">HK Chethan, GH Kumar - International  &hellip;, 2010 - Foundation of Computer Science  &hellip;</div><div class="gs_fl"><a href="/scholar?cites=4217979830716334894&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=29">Cited by 5</a> <a href="/scholar?q=related:LgOc505GiToJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4217979830716334894&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'LgOc505GiToJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://spiedigitallibrary.org/data/Conferences/SPIEP/5400/762803_1.pdf" class=yC8>An Automatic System to Detect and Extract Text in Medical Images for De-identification</a></h3><div class="gs_a">Y Zhu11, PD Singh, K Siddiqui, M Gillam - Proc. of SPIE Vol, 2010 - spiedigitallibrary.org</div><div class="gs_rs">ABSTRACT Recently, there is an increasing need to share medical images for research <br>purpose. In order to respect and preserve patient privacy, most of the medical images are de-<br>identified with protected health information (PHI) before research sharing. Since manual <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10011839320689815110&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=29">Cited by 3</a> <a href="/scholar?q=related:Ri4BMtEy8YoJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10011839320689815110&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'Ri4BMtEy8YoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5560063" class=yC9>Mash up of Breaking News and Contextual Web Information: A Novel Service for Connected Television</a></h3><div class="gs_a"><a href="/citations?user=ugI69q0AAAAJ&amp;hl=en&amp;oi=sra">T Chattopadhyay</a>, <a href="/citations?user=hkKS-xsAAAAJ&amp;hl=en&amp;oi=sra">A Pal</a>&hellip; - &hellip;  and Networks (ICCCN),  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The Connected TV can be described as an Internet enabled TV. In the current <br>paper we have proposed a system for connected TV that mash up the information from <br>internet and RSS feeds related to the breaking news aired over the TV. The proposed <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14225660364296598291&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=29">Cited by 2</a> <a href="/scholar?q=related:E7NABbuya8UJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'E7NABbuya8UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5370396" class=yCA>Sparse Representation Classification for Image Text Detection</a></h3><div class="gs_a">M Zhao, S Li - &hellip;  Intelligence and Design, 2009. ISCID&#39;09.  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Text detection in images is important for the retrieval of text information from digital <br>graph, video databases and web sites. In this paper, a text detection method based on <br>sparse representation classification with discrimination dictionaries is presented, which <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11459773560308622351&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=29">Cited by 2</a> <a href="/scholar?q=related:D-SbLFZLCZ8J:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11459773560308622351&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'D-SbLFZLCZ8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> A Comparative Analysis of Different Edge Based Algorithms for Mobile/Camera Captured Images</h3><div class="gs_a">HK Chethan, GH Kumar - International  &hellip;, 2010 - Foundation of Computer Science  &hellip;</div><div class="gs_fl"><a href="/scholar?cites=2810998281669817847&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=29">Cited by 2</a> <a href="/scholar?q=related:97UpOwusAicJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2810998281669817847&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'97UpOwusAicJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://dx.plos.org/10.1371/journal.pone.0015338" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from plos.org</span><span class="gs_ggsS">plos.org <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[HTML]</span><span class="gs_ct2">[HTML]</span></span> <a href="http://dx.plos.org/10.1371/journal.pone.0015338" class=yCB>Figure text extraction in biomedical literature</a></h3><div class="gs_a">D Kim, <a href="/citations?user=TyXe64wAAAAJ&amp;hl=en&amp;oi=sra">H Yu</a> - PloS one, 2011 - dx.plos.org</div><div class="gs_rs">Background Figures are ubiquitous in biomedical full-text articles, and they represent <br>important biomedical knowledge. However, the sheer volume of biomedical publications has <br>made it necessary to develop computational approaches for accessing figures. Therefore, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4659183523311768599&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=29">Cited by 3</a> <a href="/scholar?q=related:F9RZorq-qEAJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4659183523311768599&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'F9RZorq-qEAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md9', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md9" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:F9RZorq-qEAJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5451808" class=yCD>Automatic text location from complex natural scene images</a></h3><div class="gs_a">M Kumar, G Lee - &hellip; ), 2010 The 2nd International Conference on, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The rapid growth in communication technology leads to an effective way of sharing <br>ideas and information in form of speech or image. Understanding this information from any <br>kind of images has become important. Text in a digital image contains important <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=279678214987172190&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=29">Cited by 2</a> <a href="/scholar?q=related:Xsm5z9qd4QMJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Xsm5z9qd4QMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5698320" class=yCE>Chinese Numeral Recognition Using Gabor and SVM</a></h3><div class="gs_a">T Jipeng, GH Kumar&hellip; - Emerging Trends in  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Handwritten character recognition has received extensive attention in academic <br>and production fields. The recognition system can be either on-line or off-line. Off-line <br>handwriting recognition is the subfield of Optical Character Recognition. In this paper, We <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9401089516922842482&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=29">Cited by 1</a> <a href="/scholar?q=related:cq3VRRthd4IJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9401089516922842482&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'cq3VRRthd4IJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5375747" class=yCF>A novel edge based method to extract text in camera captured images</a></h3><div class="gs_a">HK Chethan, G Hemantha Kumar&hellip; - &hellip; in Computing, Control &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Character recognition has been in importance for several decades. Lot of research <br>interest are now focused on applying pattern recognition and computer vision algorithms on <br>camera captured documents to retrieve information from the documents. This paper <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3567878108463333533&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=29">Cited by 1</a> <a href="/scholar?q=related:nYDZeDymgzEJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3567878108463333533&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'nYDZeDymgzEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5569311" class=yC10>A combined algorithm for video text extraction</a></h3><div class="gs_a">X Zhang, F Sun, L Gu - Fuzzy Systems and Knowledge  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Video text provides high-level semantic information. However, due to the complex <br>background in video, it is of great difficulty to extract text efficiently. Although many methods <br>hold assumptions on single feature, such as texture, connected areas etc., there are still <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6386362306775865430&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=29">Cited by 1</a> <a href="/scholar?q=related:VthRfq7qoFgJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'VthRfq7qoFgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S1007021411700049" class=yC11>Pulse Coupled Neural Network Edge-Based Algorithm for Image Text Locating</a></h3><div class="gs_a">X Zhang, F Sun - Tsinghua Science &amp; Technology, 2011 - Elsevier</div><div class="gs_rs">This paper presents a method for locating text based on a simplified pulse coupled neural <br>network (PCNN). The PCNN generates a firings map in a similar way to the human visual <br>system with non-linear image processing. The PCNN is used to segment the original <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14879130124548268288&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=29">Cited by 2</a> <a href="/scholar?q=related:AGGD6ANKfc4J:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14879130124548268288&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'AGGD6ANKfc4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.scientific.net/AMM.58-60.2528" class=yC12>Video-Tag Detection and Recognition</a></h3><div class="gs_a">LH Ye, HM Yin - Applied Mechanics and Materials, 2011 - Trans Tech Publ</div><div class="gs_rs">Abstract In this work, we present a video-tag detection and recognition method. According to <br>the duration of the video, choose an appropriate strategy to sample the frames. After the <br>candidate tag of every frame is computed, a median filter algorithm is employed to get the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:jiGWCWqzzOMJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16414692009867354510&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'jiGWCWqzzOMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://eprints.fri.uni-lj.si/1674/1/improved_eurocon_2011.pdf" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uni-lj.si</span><span class="gs_ggsS">uni-lj.si <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://eprints.fri.uni-lj.si/1674/" class=yC13>HASH (0xbbdf4148)</a></h3><div class="gs_a">A Ikica, P Peer - 2011 - eprints.fri.uni-lj.si</div><div class="gs_rs">Abstract Text detection in natural images has gained much attention in the last years as it is <br>a primary step towards fully autonomous text recognition. Understanding the visual text <br>content is of a vital importance in many applicative areas from the internet search engines <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:I45qGYyrVU0J:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'I45qGYyrVU0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/X012342057014785.pdf" class=yC15>Automatic Text Localization in Natural Scene Images</a></h3><div class="gs_a">A KozÅowski, P StrumiÅÅo - Image Processing and Communications  &hellip;, 2011 - Springer</div><div class="gs_rs">In this paper we present an approach to automatic localization of text in natural scene <br>images. Text which is embedded in a natural scene, eg in the street, shop or a bus stop, is <br>not available to visually impaired persons, therefore it is necessary to design systems for <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:UZpiJygm53cJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8639916364034906705&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'UZpiJygm53cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB18" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW18"><a href="http://www.akgec.org/journals/jan-june%2012/10-San.pdf" class=yC17><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from akgec.org</span><span class="gs_ggsS">akgec.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.akgec.org/journals/jan-june%2012/10-San.pdf" class=yC16>A Survey of Image to Text Detection Methodology</a></h3><div class="gs_a">S Sharma, J Prakash - akgec.org</div><div class="gs_rs">Abstract--The automatic detection of text within a natural image is an important problem in <br>many applications. Text detection in natural images has gained much attention in the last <br>years as it is a primary step towards fully autonomous text recognition. It needs to be fast, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:huINMWCvEcUJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14200323927750599302&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'huINMWCvEcUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md18', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md18" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:huINMWCvEcUJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S187705091000373X" class=yC18>Image dewarping and text extraction from mobile captured distinct documents</a></h3><div class="gs_a">HK Chethan, G Hemantha Kumar - Procedia Computer Science, 2010 - Elsevier</div><div class="gs_rs">Camera Based Document Analysis (CBDA) is an emerging field in computer vision and <br>pattern recognition. In recent days, cameras are moulded with several items of additional <br>equipment. Thus, they play a vital role in the replacement of scanners with hand-held <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:PtQgRa-ROdsJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'PtQgRa-ROdsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5659136" class=yC19>Text Location in Camera-Captured Guidepost Images</a></h3><div class="gs_a">Q Sun, Y Lu - Pattern Recognition (CCPR), 2010 Chinese  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract A method is proposed to locate text in camera-captured guidepost images. Firstly, <br>due to its advantage of smoothing the low contrast information, mean shift method is applied <br>to remove some complex background. In order to improve the time efficiency, we modify <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:sK6zZeyzHFoJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'sK6zZeyzHFoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ri"><h3 class="gs_rt"><a href="http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=1197861" class=yC1A>Obliterable of graphics and correction of skew using Hough transform for mobile captured documents</a></h3><div class="gs_a">HK Chethan, GH Kumar - &hellip; on Graphic and &hellip;, 2011 - proceedings.spiedigitallibrary.org</div><div class="gs_rs">abstract CBDA is an emerging field in Computer Vision and Pattern Recognition. In recent <br>technology camera are incorporated to several electronic equipments and are very <br>interesting and thus playing a vital role by replacing scanner with hand held imaging <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:5t7nndfjSJIJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10540925443067338470&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'5t7nndfjSJIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB22" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW22"><a href="http://cdn.intechweb.org/pdfs/11406.pdf" class=yC1C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from intechweb.org</span><span class="gs_ggsS">intechweb.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://cdn.intechweb.org/pdfs/11406.pdf" class=yC1B>Recognition of Characters from Streaming Videos</a></h3><div class="gs_a"><a href="/citations?user=ugI69q0AAAAJ&amp;hl=en&amp;oi=sra">T Chattopadhyay</a>, <a href="/citations?user=hkKS-xsAAAAJ&amp;hl=en&amp;oi=sra">A Pal</a>, <a href="/citations?user=TrdrjEQAAAAJ&amp;hl=en&amp;oi=sra">A Sinha</a> - cdn.intechweb.org</div><div class="gs_rs">Over the past few years, Video has become one of the prime source for recreation, be it <br>Television or Internet. Television brings a whole lot of professionally produced video content <br>(International or local, sports or educational, news or entertainment) to the home for the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10036602239941883215&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=29">Cited by 1</a> <a href="/scholar?q=related:TzWgn48sSYsJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10036602239941883215&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'TzWgn48sSYsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md22', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md22" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:TzWgn48sSYsJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> A Chinese Words Detection Method in Camera Based Images</h3><div class="gs_a">Q Chen, Y Zhou, K Chen, <a href="/citations?user=jKIoTVoAAAAJ&amp;hl=en&amp;oi=sra">L Song</a>, <a href="/citations?user=yDEavdMAAAAJ&amp;hl=en&amp;oi=sra">X Yang</a> - American Journal of Engineering and  &hellip;, 2011</div><div class="gs_fl"><a href="/scholar?q=related:IGoSrmDDaaEJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11631042332665735712&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'IGoSrmDDaaEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0925231211003341" class=yC1D>Chinese text location under complex background using Gabor filter and SVM</a></h3><div class="gs_a">J Yan, J Li, X Gao - Neurocomputing, 2011 - Elsevier</div><div class="gs_rs">For the Chinese text location under complex background, this paper presents a novel <br>method by combining Gabor filter and support vector machine (SVM). It bases on such a fact <br>that Chinese characters are composed of four kinds of strokes. By extracting four kinds of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13673583033528411609&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=29">Cited by 1</a> <a href="/scholar?q=related:2eVEwFJTwr0J:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13673583033528411609&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'2eVEwFJTwr0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB25" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW25"><a href="http://islab.ulsan.ac.kr/files/announcement/366/improved_eurocon_2011[1].pdf" class=yC1F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ulsan.ac.kr</span><span class="gs_ggsS">ulsan.ac.kr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5929289" class=yC1E>An improved edge profile based method for text detection in images of natural scenes</a></h3><div class="gs_a">A Ikica, P Peer - &hellip; -International Conference on Computer as a  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Text detection in natural images has gained much attention in the last years as it is <br>a primary step towards fully autonomous text recognition. Understanding the visual text <br>content is of a vital importance in many applicative areas from the internet search engines <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Wc4IylVfmnYJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8546248064955371097&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'Wc4IylVfmnYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1998142" class=yC20>A new video text detection method</a></h3><div class="gs_a">J Yuan, B Wei, W Lu, L Wang - &hellip;  of the 11th annual international ACM/ &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract Nowadays, digital libraries contain more and more videos in them, and how to <br>organize and retrieve those videos effectively has become very urgent. Text in videos is a <br>very meaningful clue for video semantic understanding, and it can be used for video <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15801890146759906708&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=29">Cited by 2</a> <a href="/scholar?q=related:lJVe0V2XS9sJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'lJVe0V2XS9sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/92337a/201106/37020079.html" class=yC21>è§é¢æ ç­¾æ£æµä¸è¯å«</a></h3><div class="gs_a">å¶å©å - å¶é ä¸èªå¨å, 2011 - cqvip.com</div><div class="gs_rs">æåºä¸ç§è§é¢æ ç­¾çæ£æµä¸è¯å«æ¹æ³. æ ¹æ®è§é¢é¿åº¦, éç¨ä¸åçç­ç¥è·å¾æ½æ ·å¸§; <br>å¯¹æ¯ä¸ªæ½æ ·å¸§è®¡ç®åéæ ç­¾; ç¶åå¯¹ææåéæ ç­¾è¿è¡ä¸æ¬¡ä¸­å¼æ»¤æ³¢, ç¡®å®æ ç­¾è¾¹ç; <br>æåå©ç¨ä¸ç§åºäºå¤å¸§èååæçæ¹æ³å®ç°è§é¢æ ç­¾çäºå¼å. å¯¹è·å¾çäºå¼åæ ç­¾, å¨ç¼©æ¾<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:50hdWacBQnsJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8881663233398491367&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'50hdWacBQnsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.dbpia.co.kr/Article/?arid=1483602&amp;arid=1483602" class=yC22>Text Extraction from Complex Natural Images</a></h3><div class="gs_a">GS Lee - International Journal of Contents, 2010 - dbpia.co.kr</div><div class="gs_rs">The rapid growth in communication technology has led to the development of effective ways <br>of sharing ideas and information in the form of speech and images. Understanding this <br>information has become an important research issue and drawn the attention of many <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:kOgXgAMBLrkJ:scholar.google.com/&amp;hl=en&amp;num=29&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'kOgXgAMBLrkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
