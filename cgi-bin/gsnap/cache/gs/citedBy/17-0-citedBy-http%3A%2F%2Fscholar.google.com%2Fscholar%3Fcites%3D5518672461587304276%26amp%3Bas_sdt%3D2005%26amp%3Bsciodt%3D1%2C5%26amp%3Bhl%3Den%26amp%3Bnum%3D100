Total results = 17
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://coitweb.uncc.edu/~jfan/mm2008.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uncc.edu</span><span class="gs_ggsS">uncc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4451166" class=yC0>Integrating concept ontology and multitask learning to achieve more effective classifier training for multilevel image annotation</a></h3><div class="gs_a">J Fan, Y Gao, H Luo - Image Processing, IEEE Transactions on, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we have developed a new scheme for achieving multilevel <br>annotations of large-scale images automatically. To achieve more sufficient representation <br>of various visual properties of the images, both the global visual features and the local <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10089230769397461508&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 72</a> <a href="/scholar?q=related:BHLgAu4lBIwJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/19/2C/RN224050690.html?source=googlescholar" class="gs_nph" class=yC2>BL Direct</a> <a href="/scholar?cluster=10089230769397461508&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'BHLgAu4lBIwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/acmmm07-shiruiOFF.PDF" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1291307" class=yC3>Enhancing image annotation by integrating concept ontology and text-based bayesian learning model</a></h3><div class="gs_a">R Shi, CH Lee, TS Chua - &hellip;  of the 15th international conference on  &hellip;, 2007 - dl.acm.org</div><div class="gs_rs">Abstract Automatic image annotation (AIA) has been a hot research topic in recent years <br>since it can be used to support concept-based image retrieval. However, most existing AIA <br>models depend heavily on the availability of a large number of labeled training samples, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6590943054411936780&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 16</a> <a href="/scholar?q=related:DDQNpcm7d1sJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6590943054411936780&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'DDQNpcm7d1sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://maroo.cs.umass.edu/pdf/MM-670.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from umass.edu</span><span class="gs_ggsS">umass.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1386407" class=yC5>A discrete direct retrieval model for image and video retrieval</a></h3><div class="gs_a">S Feng, <a href="/citations?user=_0aMq28AAAAJ&amp;hl=en&amp;oi=sra">R Manmatha</a> - Proceedings of the 2008 international conference &hellip;, 2008 - dl.acm.org</div><div class="gs_rs">Abstract This paper proposes a formal framework for image and video retrieval using <br>discrete Markov random fields (MRF). The training dataset consists of images with keywords <br>(regions are not labeled). The model is built using a discrete vocabulary of vector <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13142954357404023283&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 15</a> <a href="/scholar?q=related:8zk9jFonZbYJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13142954357404023283&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'8zk9jFonZbYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://oro.open.ac.uk/23503/1/p243-llorente.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from open.ac.uk</span><span class="gs_ggsS">open.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://oro.open.ac.uk/23503/" class=yC7>Image retrieval using Markov random fields and global image features</a></h3><div class="gs_a">A Llorente, <a href="/citations?user=_0aMq28AAAAJ&amp;hl=en&amp;oi=sra">R Manmatha</a>, <a href="/citations?user=oFU5A7sAAAAJ&amp;hl=en&amp;oi=sra">S RÃ¼ger</a> - 2010 - oro.open.ac.uk</div><div class="gs_rs">In this paper, we propose a direct image retrieval framework based on Markov Random <br>Fields (MRFs) that exploits the semantic context dependencies of the image. The novelty of <br>our approach lies in the use of different kernels in our non-parametric density estimation <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4684010266910249855&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 7</a> <a href="/scholar?q=related:f9N3U4XyAEEJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4684010266910249855&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'f9N3U4XyAEEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/MPW5334442398650.pdf" class=yC9>Image annotation techniques based on feature selection for class-pairs</a></h3><div class="gs_a">J Lu, R Li, Y Zhang, T Zhao, Z Lu - Knowledge and information systems, 2010 - Springer</div><div class="gs_rs">Abstract Image annotation technique can be formulated as a multi-class classification <br>problem, which can be solved by the ensemble of multiple class-pair classifiers. Support <br>vector machine (SVM) classifiers based on optimal class-pair feature subsets from the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15029018030087694819&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 3</a> <a href="/scholar?q=related:42lRbkXMkdAJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15029018030087694819&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'42lRbkXMkdAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/r45622h18626h060.pdf" class=yCA>New approach for hierarchical classifier training and multi-level image annotation</a></h3><div class="gs_a">J Fan, Y Gao, H Luo, <a href="/citations?user=7aEF5cQAAAAJ&amp;hl=en&amp;oi=sra">S Satoh</a> - Advances in Multimedia Modeling, 2008 - Springer</div><div class="gs_rs">In this paper, we have proposed a novel algorithm to achieve automatic multi-level image <br>annotation by incorporating concept ontology and multi-task learning for hierarchical image <br>classifier training. To achieve more reliable image classifier training in high-dimensional <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12577391995711321906&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 3</a> <a href="/scholar?q=related:Mvc22WHfi64J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/06/41/RN221721316.html?source=googlescholar" class="gs_nph" class=yCB>BL Direct</a> <a href="/scholar?cluster=12577391995711321906&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'Mvc22WHfi64J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://www.jos.org.cn/ch/reader/create_pdf.aspx?file_no=20080926" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from jos.org.cn</span><span class="gs_ggsS">jos.org.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.jos.org.cn/ch/reader/create_pdf.aspx?file_no=20080926" class=yCC>åºäºæ©å±çæè¯­è¨æ¨¡åçå¾åèªå¨æ æ³¨æ¹æ³</a></h3><div class="gs_a">çæ¢ï¼ å¨åä¸ï¼ å¼ åæï¼ è®¸çº¢æ¶ï¼ æ½ä¼¯ä¹ - è½¯ä»¶å­¦æ¥, 2008 - jos.org.cn</div><div class="gs_rs">æè¦: ä½¿ç¨æå¤§æå¹éç®æ³, ç»åç»è®¡å¹³æ»ææ¯, æåºå¾ååºåç¹å¾çææ¦çä¼°è®¡æ¹æ³, <br>å¹¶è¿ä¸æ­¥å¯¹è®­ç»éä¸­æ æ³¨è¯ä¹é´çè¯­ä¹ç¸å³æ§(correlation) è¿è¡åæä¸åº¦é, <br>ç»åºä¸ç§åºäºçææ¨¡åçå¾åæ æ³¨ç®æ³. ç®æ³ä½¿ç¨ææåºçåºäºæå¤§æå¹éçå¾åçææ¦ç<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9153994569094206867&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 4</a> <a href="/scholar?q=related:kxW3ho-FCX8J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9153994569094206867&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'kxW3ho-FCX8J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md6', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md6" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:kxW3ho-FCX8J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5070264" class=yCE>Ensemble of Two-class Classifiers for Image Annotation</a></h3><div class="gs_a">Y Li, J Lu, Y Zhang, R Li, W Xu - Education Technology and  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Image annotation can be formulated as a multi-class classification problem. A multi-<br>class classification problem can be solved by ensemble classifiers. We investigate the <br>ensemble of multiple two-class classifiers based on MPEG-7 standard. To get ride of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16102601352720502784&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 2</a> <a href="/scholar?q=related:AFChdJ3ud98J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16102601352720502784&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'AFChdJ3ud98J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://scholarbank.nus.edu/bitstream/handle/10635/13418/Thesis_Marchenko_Yelizaveta_PhDDegree.pdf?sequence=1" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu</span><span class="gs_ggsS">nus.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://scholarbank.nus.edu/handle/10635/13418" class=yCF>Ontology-based annotation of paintings with artistic concepts</a></h3><div class="gs_a">M YELIZAVETA - 2007 - scholarbank.nus.edu</div><div class="gs_rs">In this thesis, we focus on the automatic annotation of paintings with various artistic <br>concepts. These concepts originate from the several domain ontologies. In our work we <br>combine such domain knowledge with trasductive inference and demonstrate that the use <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=77623979425578235&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:-7y2F5nGEwEJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=77623979425578235&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'-7y2F5nGEwEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/P528W22657P61652.pdf" class=yC11>Semantic context based refinement for news video annotation</a></h3><div class="gs_a">Z Wang, G Guan, Y Qiu, L Zhuo, D Feng - Multimedia Tools and  &hellip;, 2012 - Springer</div><div class="gs_rs">Abstract Automatic video annotation is to bridge the semantic gap and facilitate concept <br>based video retrieval by detecting high level concepts from video data. Recently, utilizing <br>context information has emerged as an important direction in such domain. In this paper, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16356800356754641469&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:PdJXLkMH_-IJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'PdJXLkMH_-IJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5692630" class=yC12>Empirical study of multi-label classification methods for image annotation and retrieval</a></h3><div class="gs_a">G Nasierding, AZ Kouzani - Digital Image Computing:  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents an empirical study of multi-label classification methods, and <br>gives suggestions for multi-label classification that are effective for automatic image <br>annotation applications. The study shows that triple random ensemble multi-label <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5221583598824370166&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 4</a> <a href="/scholar?q=related:9q_uNJ7KdkgJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5221583598824370166&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'9q_uNJ7KdkgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://www.jos.org.cn/ch/reader/create_pdf.aspx?file_no=3658&amp;year_id=2010&amp;quarter_id=9&amp;falg=1" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from jos.org.cn</span><span class="gs_ggsS">jos.org.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.jos.org.cn/ch/reader/create_pdf.aspx?file_no=3658&amp;year_id=2010&amp;quarter_id=9&amp;falg=1" class=yC13>ä¸ç§èªéåºç Web å¾åè¯­ä¹èªå¨æ æ³¨æ¹æ³</a></h3><div class="gs_a">è®¸çº¢æ¶ï¼ å¨åä¸ï¼ åå®ï¼ æ½ä¼¯ä¹ - è½¯ä»¶å­¦æ¥, 2010 - jos.org.cn</div><div class="gs_rs">æè¦: æåºäºä¸ç§èªéåºçWeb å¾åè¯­ä¹èªå¨æ æ³¨æ¹æ³: é¦åå©ç¨Web æ ç­¾èµæºèªå¨è·åè®­ç»<br>æ°æ®; ç¶åéè¿å¸¦çº¦æçåæ®µæ©ç½å æåå½æ¨¡åå°å³èææ¬æéåå¸èªéåºå­¦ä¹ ååéªç¥è¯çº¦æ<br>ææºå°ç»åå¨ä¸èµ·, å®ç°Web å¾åè¯­ä¹çèªå¨æ æ³¨. å¨4 000 å¹ä»Web è·å¾çå¾åæ°æ®éä¸ç<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16395954804637883021&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 3</a> <a href="/scholar?q=related:jdrMewYiiuMJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16395954804637883021&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'jdrMewYiiuMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md11', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md11" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:jdrMewYiiuMJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://oro.open.ac.uk/25663/1/LlorenteThesis13122010.pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from open.ac.uk</span><span class="gs_ggsS">open.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://oro.open.ac.uk/25663/" class=yC15>Semantics and statistics for automated image annotation</a></h3><div class="gs_a">A Llorente - 2010 - oro.open.ac.uk</div><div class="gs_rs">Automated image annotation consists of a number of techniques that aim to find the <br>correlation between words and image features such as colour, shape, and texture to provide <br>correct annotation words to images. In particular, approaches based on Bayesian theory <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:XxpIA7-RgK0J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'XxpIA7-RgK0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="https://scholarbank.nus.edu.sg/bitstream/handle/10635/15994/SHIRUI_PHDThesis_BayesianLearningofConceptOntologyforAutomaticImageAnnotation.pdf?sequence=1" class=yC18><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="https://scholarbank.nus.edu.sg/handle/10635/15994" class=yC17>Bayesian learning of concept ontology for automatic image annotation</a></h3><div class="gs_a">RUI SHI - 2007 - scholarbank.nus.edu.sg</div><div class="gs_rs">Automatic image annotation (AIA) has been a hot research topic in recent years since it can <br>be used to support concept-based image retrieval. In the field of AIA, characterizing image <br>concepts by mixture models is one of the most effective techniques. However, mixture <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:hevhtMNxNoEJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9310754365002345349&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'hevhtMNxNoEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://vireo.cs.cityu.edu.hk/papers/mmm07.pdf" class=yC1A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cityu.edu.hk</span><span class="gs_ggsS">cityu.edu.hk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/y2u565162461h8np.pdf" class=yC19>Mining multiple visual appearances of semantics for image annotation</a></h3><div class="gs_a">HK Tan, <a href="/citations?user=jk5DWVMAAAAJ&amp;hl=en&amp;oi=sra">CW Ngo</a> - Advances in Multimedia Modeling, 2006 - Springer</div><div class="gs_rs">This paper investigates the problem of learning the visual semantics of keyword categories <br>for automatic image annotation. Supervised learning algorithms which learn only a single <br>concept point of a category are limited in their effectiveness for image annotation. We <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:-eejyOtioi8J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3432414630832760825&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'-eejyOtioi8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://www.aas.net.cn/qikan/manage/wenzhang/20120502.pdf" class=yC1C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aas.net.cn</span><span class="gs_ggsS">aas.net.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.aas.net.cn/qikan/manage/wenzhang/20120502.pdf" class=yC1B>å¾åè¯­ä¹èªå¨æ æ³¨åå¶ç²åº¦åææ¹æ³</a></h3><div class="gs_a">å¼ ç´ å°ï¼ é­å¹³ï¼ å¼ ç»§ç¦ï¼ è¡ç«å - èªå¨åå­¦æ¥, 2012 - aas.net.cn</div><div class="gs_rs">æè¦ç¼©å°å¾åä½å±è§è§ç¹å¾ä¸é«å±è¯­ä¹ä¹é´çé¸¿æ², ä»¥æé«å¾åè¯­ä¹èªå¨æ æ³¨çç²¾åº¦, <br>è¿èå¿«éæ»¡è¶³ç¨æ·æ£ç´¢å¾åçéæ±, ä¸ç´æ¯å¾åè¯­ä¹èªå¨æ æ³¨ç ç©¶çå³é®. ç²åº¦åææ¹æ³æ¯ä¸ç§<br>å±æ¬¡ç, éè¦çæ°æ®åææ¹æ³, ä¸ºå¤æé®é¢çæ±è§£æä¾äºæ°çæè·¯. å¾åçè§£ä¸åæçç²åº¦ä¸å<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18049918482269682896&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:0DxxIDoxfvoJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18049918482269682896&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'0DxxIDoxfvoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md15', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md15" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:0DxxIDoxfvoJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://www.jos.org.cn/ch/reader/download_pdf.aspx?file_no=3380&amp;year_id=2009&amp;quarter_id=9&amp;falg=1" class=yC1E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from jos.org.cn</span><span class="gs_ggsS">jos.org.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.jos.org.cn/ch/reader/download_pdf.aspx?file_no=3380&amp;year_id=2009&amp;quarter_id=9&amp;falg=1" class=yC1D>åºäºå¯å¤å«è¶å¹³é¢æ ççææ¨¡åå¾åæ æ³¨æ¹æ³</a></h3><div class="gs_a">çæ¢ï¼ å¨åä¸ï¼ è®¸çº¢æ¶ï¼ æ½ä¼¯ä¹ - Journal of Software, 2009 - jos.org.cn</div><div class="gs_rs">Page 1. ISSN 1000-9825, CODEN RUXUEW E-mail: jos@iscas.ac.cn Journal of<br>Software, Vol.20, No.9, September 2009, pp.2450â2461 http://www.jos.org.cn doi:<br>10.3724/SP.J.1001.2009.03380 Tel/Fax: +86-10-62562563 <b>...</b> </div><div class="gs_fl"><a href="/scholar?q=related:lP6mcxaGC38J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9154558098548391572&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'lP6mcxaGC38J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md16', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md16" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:lP6mcxaGC38J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
