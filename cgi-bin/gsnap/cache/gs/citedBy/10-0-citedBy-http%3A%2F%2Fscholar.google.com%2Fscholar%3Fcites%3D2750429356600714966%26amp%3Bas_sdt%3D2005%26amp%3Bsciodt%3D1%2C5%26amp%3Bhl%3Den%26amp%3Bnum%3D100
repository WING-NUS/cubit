Total results = 10
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.104.4752&amp;rep=rep1&amp;type=pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4118238" class=yC0>On the correlation of automatic audio and visual segmentations of music videos</a></h3><div class="gs_a"><a href="/citations?user=sHkl_ZgAAAAJ&amp;hl=en&amp;oi=sra">O Gillet</a>, S Essid, G Richard - Circuits and Systems for Video  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The study of the associations between audio and video content has numerous <br>important applications in the fields of information retrieval and multimedia content authoring. <br>In this work, we focus on music videos which exhibit a broad range of structural and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14760550731917802638&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 25</a> <a href="/scholar?q=related:jrwXma8C2MwJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/0D/5C/RN207335616.html?source=googlescholar" class="gs_nph" class=yC2>BL Direct</a> <a href="/scholar?cluster=14760550731917802638&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'jrwXma8C2MwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.140.3830&amp;rep=rep1&amp;type=pdf#page=176" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.140.3830&amp;rep=rep1&amp;type=pdf#page=176" class=yC3>Sonified motion flow fields as a means of musical expression</a></h3><div class="gs_a">JM Pelletier - Proceedings of the 2008 International Conference on  &hellip;, 2008 - Citeseer</div><div class="gs_rs">ABSTRACT This paper describes a generalized motion-based framework for the generation <br>of large musical control fields from imaging data. The framework is general in the sense that <br>it does not depend on a particular source of sensing data. Real-time images of stage <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13235620256619843705&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 9</a> <a href="/scholar?q=related:eVDKgX9errcJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13235620256619843705&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'eVDKgX9errcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md1', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md1" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:eVDKgX9errcJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="https://www.cs.sfu.ca/research/groups/VML/image_based_music/wu_icme08.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from sfu.ca</span><span class="gs_ggsS">sfu.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4607692" class=yC5>A study of image-based music composition</a></h3><div class="gs_a">X Wu, ZN Li - Multimedia and Expo, 2008 IEEE International  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Visual and auditory forms have some noticeable associations that can inspire <br>similar cognitive and aesthetical experiences. This paper presents a study on the <br>possibilities of applying low-level visual-auditory associations to music generation. A few <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4887410798348298274&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 5</a> <a href="/scholar?q=related:Imj1-jmS00MJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4887410798348298274&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'Imj1-jmS00MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1874024" class=yC7>Toward an automatically generated soundtrack from low-level cross-modal correlations for automotive scenarios</a></h3><div class="gs_a"><a href="/citations?user=LbgTPRwAAAAJ&amp;hl=en&amp;oi=sra">M Cristani</a>, A Pesarin, <a href="/citations?user=lKqYJ3AAAAAJ&amp;hl=en&amp;oi=sra">C Drioli</a>, <a href="/citations?user=yV3_PTkAAAAJ&amp;hl=en&amp;oi=sra">V Murino</a>&hellip; - Proceedings of the  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we propose a novel recommendation policy for driving scenarios. <br>While driving a car, listening to an audio track may enrich the atmosphere, conveying <br>emotions that let the driver sense a more arousing experience. Here, we are introducing a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17578300289213752476&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 3</a> <a href="/scholar?q=related:nGS7rfqq8vMJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17578300289213752476&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'nGS7rfqq8vMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6018882" class=yC8>A smart background music mixing algorithm for portable digital imaging devices</a></h3><div class="gs_a">JA Kang, CJ Chun, HK Kim, MB Kim&hellip; - &hellip; , IEEE Transactions on, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose a smart background music (BGM) mixing algorithm for <br>portable digital imaging devices to enable users to enjoy video content with BGM. The <br>proposed algorithm automatically adjusts the BGM output energy based on the activity <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13718122215091212436&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 2</a> <a href="/scholar?q=related:lBDoD3mPYL4J:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13718122215091212436&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'lBDoD3mPYL4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://pastel.archives-ouvertes.fr/docs/00/50/05/79/PDF/thesis.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://pastel.archives-ouvertes.fr/pastel-00002805/" class=yC9>Transcription des signaux percussifs. Application Ã  l&#39;analyse de scÃ¨nes musicales audiovisuelles</a></h3><div class="gs_a"><a href="/citations?user=sHkl_ZgAAAAJ&amp;hl=en&amp;oi=sra">O Gillet</a> - 2007 - pastel.archives-ouvertes.fr</div><div class="gs_rs">Je tiens d&#39;aborda remercier mon directeur de these GaÃ«l Richard pour avoir su faire <br>converger mes motivations et intÃ©rÃªts personnels vers le domaine de l&#39;indexation audio, <br>jusqu&#39;au choix du sujet de cette these, vaste, riche, mais aussi parfois dÃ©routant. Il a sua <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8881040292480709146&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 2</a> <a href="/scholar?q=related:GnI-nRfLP3sJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8881040292480709146&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'GnI-nRfLP3sJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md5', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md5" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:GnI-nRfLP3sJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=4373481126579171580&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Exploring Visual-Auditory Associations for Generating Music from Image</h3><div class="gs_a">X Wu, ZN Li - Proc. of ACM Multimedia, 2008</div><div class="gs_fl"><a href="/scholar?cites=17460516109534879362&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en">Cited by 1</a> <a href="/scholar?q=related:gt7PT-Q2UPIJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17460516109534879362&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'gt7PT-Q2UPIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://www.comp.nus.edu.sg/~mohan/papers/mmas.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/ANUKC34M23G9MBJH.pdf" class=yCB>Multimedia analysis and synthesis</a></h3><div class="gs_a">M Kankanhalli - AI 2003: Advances in Artificial Intelligence, 2003 - Springer</div><div class="gs_rs">We describe novel approaches to multimedia analysis and synthesis problems. We first <br>present the experiential sampling technique which has the ability to focus on the analysis <br>task by making use of the contextual information. Sensor samples are used to gather <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:t5HWlg4ROjIJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/18/3A/RN141850840.html?source=googlescholar" class="gs_nph" class=yCD>BL Direct</a> <a href="/scholar?cluster=3619224004903473591&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'t5HWlg4ROjIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://icserv.kjist.ac.kr/mis/publications/data/2008/IEEE_Consumer_Electronics_BBS%EC%97%85%EB%A1%9C%EB%93%9C%EC%9A%A9_%EC%98%A4%EC%9C%A0%EB%A6%AC.pdf" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from kjist.ac.kr</span><span class="gs_ggsS">kjist.ac.kr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/iel4/30/14980/x0059260.pdf" class=yCE>Consumer electronics</a></h3><div class="gs_a">CH Han, SG Kwon, BK Lee - ieeexplore.ieee.org</div><div class="gs_rs">The Consumer Electronics Society is an organization, within the framework of the IEEE, of <br>members, with technical interests in all facets ot consumer electronics products. All members <br>of the IEEE may join the Society and have the option of receiving the Transactions on <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:E1cslx9zWkgJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5213606098152216339&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'E1cslx9zWkgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://hal.inria.fr/docs/00/50/05/79/PDF/thesis.pdf" class=yC11><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from inria.fr</span><span class="gs_ggsS">inria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://hal.inria.fr/docs/00/50/05/79/PDF/thesis.pdf" class=yC10>Olivier Gillet</a></h3><div class="gs_a">MLG Rapporteur - hal.inria.fr</div><div class="gs_rs">Je tiens d&#39;aborda remercier mon directeur de these GaÃ«l Richard pour avoir su faire <br>converger mes motivations et intÃ©rÃªts personnels vers le domaine de l&#39;indexation audio, <br>jusqu&#39;au choix du sujet de cette these, vaste, riche, mais aussi parfois dÃ©routant. Il a sua <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'FOH6BXjkkdoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md9', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md9" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:FOH6BXjkkdoJ:scholar.google.com/&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
