Total results = 18
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.ldmc.buaa.edu.cn/download/data_mining/Content-Based%20Multimedia%20Information%20Retrieval.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from buaa.edu.cn</span><span class="gs_ggsS">buaa.edu.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1126005" class=yC0>Content-based multimedia information retrieval: State of the art and challenges</a></h3><div class="gs_a">MS Lew, <a href="/citations?user=fOmROdkAAAAJ&amp;hl=en&amp;oi=sra">N Sebe</a>, C Djeraba, R Jain - ACM Transactions on Multimedia  &hellip;, 2006 - dl.acm.org</div><div class="gs_rs">Abstract Extending beyond the boundaries of science, art, and culture, content-based <br>multimedia information retrieval provides new paradigms and methods for searching <br>through the myriad variety of media all over the world. This survey reviews 100&amp;plus; <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12559216584042821206&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 858</a> <a href="/scholar?q=related:VjYRDfFMS64J:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12559216584042821206&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 38 versions</a> <a onclick="return gs_ocit(event,'VjYRDfFMS64J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://jan.nesvadba.info/cv/2004%20ICIP%20Face%20Detection%20in%20the%20Compressed%20Domain.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nesvadba.info</span><span class="gs_ggsS">nesvadba.info <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1421478" class=yC2>Face detection in the compressed domain</a></h3><div class="gs_a"><a href="/citations?user=ZRYS_nkAAAAJ&amp;hl=en&amp;oi=sra">P Fonseca</a>, J Nesvadha - Image Processing, 2004. ICIP&#39;04.  &hellip;, 2004 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Face detection is important in many algorithms in the areas of machine object <br>recognition and pattern recognition. The kaleidoscope of applications for face detection <br>extends across automatic image and home video content annotation, face-image <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5133308272577719596&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 16</a> <a href="/scholar?q=related:LK2RLa0sPUcJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5133308272577719596&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'LK2RLa0sPUcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/acmmm02-wangjh.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=641055" class=yC4>A framework for video scene boundary detection</a></h3><div class="gs_a">J Wang, TS Chua - Proceedings of the tenth ACM international  &hellip;, 2002 - dl.acm.org</div><div class="gs_rs">Abstract Most current video retrieval systems use shot as the basis for information <br>organization and access. In cinematography, scene is the basic story unit that the directors <br>use to convey their ideas. This paper proposes a framework based on the concept of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2323743190817835309&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 17</a> <a href="/scholar?q=related:LQnuzR6YPyAJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2323743190817835309&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'LQnuzR6YPyAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/visual03.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/empenryggg0alg96.pdf" class=yC6>A cinematic-based framework for scene boundary detection in video</a></h3><div class="gs_a">J Wang, TS Chua - The Visual Computer, 2003 - Springer</div><div class="gs_rs">Most current video retrieval systems use shots as the basis for information organization and <br>access. In cinematography, scene is the basic story unit that the directors use to compose <br>and convey their ideas. This paper proposes a framework based on the concept of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16541083775778629801&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 6</a> <a href="/scholar?q=related:qShDPw68jeUJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/4B/32/RN137115916.html?source=googlescholar" class="gs_nph" class=yC8>BL Direct</a> <a href="/scholar?cluster=16541083775778629801&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'qShDPw68jeUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://cs.nju.edu.cn/ywguo/webs/paperdownload/Automatic_Foreground_Extraction_of_Head_Shoulder_Images.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nju.edu.cn</span><span class="gs_ggsS">nju.edu.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/R5517P81213222X6.pdf" class=yC9>Automatic foreground extraction of head shoulder images</a></h3><div class="gs_a">J Wang, Y Ying, Y Guo, Q Peng - Advances in Computer Graphics, 2006 - Springer</div><div class="gs_rs">Abstract. Most existing techniques of foreground extracting work only in interactive mode. <br>This paper introduces a novel algorithm of automatic foreground extraction for special <br>object, and verifies its effectiveness with head shoulder images. The main contribution of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13312797955036980175&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 5</a> <a href="/scholar?q=related:z6OGtDSPwLgJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/3E/45/RN191569956.html?source=googlescholar" class="gs_nph" class=yCB>BL Direct</a> <a href="/scholar?cluster=13312797955036980175&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'z6OGtDSPwLgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://lms.comp.nus.edu.sg/papers/media/2003/cgi03-zhaoyl.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1214462" class=yCC>Automatic tracking of face sequences in MPEG video</a></h3><div class="gs_a">Y Zhao, TS Chua - Computer Graphics International, 2003.  &hellip;, 2003 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Human faces are commonly found in video streams and provide useful information <br>for video content analysis. We present a robust face tracking system to extract multiple face <br>sequences from MPEG video without human intervention. Specifically, a view-based DCT-<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5933369710207850926&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 4</a> <a href="/scholar?q=related:rlkAqlCQV1IJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5933369710207850926&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'rlkAqlCQV1IJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=875852" class=yCE>Detecting faces in the wavelet compressed domain</a></h3><div class="gs_a">X Li, LS Shen - Visual Communications and  &hellip;, 2005 - proceedings.spiedigitallibrary.org</div><div class="gs_rs">abstract A novel technique that can implement face detection directly in the wavelet <br>compressed domain is presented in this paper. The algorithm takes the entropy decoding <br>and inverse quantized wavelet transform coefficients of JPEG2000 picture as input, and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9968459549363115076&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 3</a> <a href="/scholar?q=related:RJSjHSUVV4oJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/05/14/RN177222731.html?source=googlescholar" class="gs_nph" class=yCF>BL Direct</a> <a href="/scholar?cluster=9968459549363115076&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'RJSjHSUVV4oJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/90131x/200512/20901766.html" class=yC10>ä¸ç§åºäºå¤çº§æ¢¯åº¦è½éç¹å¾ç DCT åç¼©åäººè¸æ£æµç®æ³</a></h3><div class="gs_a">ææåï¼ ææåï¼ æ²å°èª - çµå­å­¦æ¥, 2006 - cqvip.com</div><div class="gs_rs">åç¼©åäººè¸æ£æµå¨å¾å/è§é¢ä¿¡æ¯å¤çä¸­å·æéè¦æä¹. æ¬ææåºäºä¸ç§åºäºå¤çº§æ¢¯åº¦è½éç¹å¾<br>çDCT (Discrete Cosine Transform) åç¼©åäººè¸æ£æµç®æ³. ä¾æ®DCT åç¼©å¾åè²å·®ä¿¡å·çç´æµ<br>ç³»æ°è¿è¡è¤è²åå², åå°æ£æµèå´. å¨åå²ä¸ºè¤è²çåºåæåå¤çº§æ¢¯åº¦è½éç¹å¾, å³å©ç¨ä¸å<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6447821056201842748&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 5</a> <a href="/scholar?q=related:POAxrhZDe1kJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6447821056201842748&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'POAxrhZDe1kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4284770" class=yC11>Anchorperson Shot Detection in MPEG Domain</a></h3><div class="gs_a">Z Ji, C Zhang, Y Su - Multimedia and Expo, 2007 IEEE  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, a refined ASD algorithm in MPEG compressed domain is proposed. <br>The new method is expected to outperform the existing strategies based on the following two <br>improvements. One is that an effective face detection method is introduced. It aims to <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2608984314382506197&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 2</a> <a href="/scholar?q=related:1dhVM2n5NCQJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2608984314382506197&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'1dhVM2n5NCQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://www.mirlab.org/conference_papers/International_Conference/ICICS_PCM%202003/PDFFILES/PAPERS/1A11P0911.pdf" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mirlab.org</span><span class="gs_ggsS">mirlab.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1292401" class=yC12>Information-integration approach to designing digital video albums</a></h3><div class="gs_a">C Madhwacharyula, W Jun, Y Weiqi, J Yi&hellip; - &hellip; , 2003 and Fourth  &hellip;, 2003 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present the architecture of the DVA (digital video album) system. <br>Information-integration is the key principle utilized in this system to allow for content-based <br>indexing, intuitive access and retrieval of digital video. Our implementation of the system <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4720112419584736435&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 1</a> <a href="/scholar?q=related:s_xBxTw1gUEJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4720112419584736435&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'s_xBxTw1gUEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://file.lw23.com/f/f7/f7f/f7f11c01-dee1-4402-944a-9d6f76cb89fb.pdf" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from lw23.com</span><span class="gs_ggsS">lw23.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://file.lw23.com/f/f7/f7f/f7f11c01-dee1-4402-944a-9d6f76cb89fb.pdf" class=yC14>åºäºå¤çº§æ¢¯åº¦è½éæè¿°çåç¼©åäººè¸æ£æµ</a></h3><div class="gs_a">ææåï¼ æ²å°èª - çµå­ä¸ä¿¡æ¯å­¦æ¥, 2005 - file.lw23.com</div><div class="gs_rs">æè¦: éå¯¹JPEG2000 å½©è²å¾å, æåºäºä¸ç§ç»åè¤è²åçº¹çä¿¡æ¯, ç´æ¥å¨å°æ³¢åç¼©åæä½çäººè¸<br>æ£æµæ¹æ³. è¯¥æ¹æ³æ3 å¤§ç¹ç¹: é¦å, æåºäºå°æ³¢åäººè¸æ¨¡å¼çå¤çº§æ¢¯åº¦è½éæè¿°, <br>å¨ææè¡¨å¾è¸é¨ç¹ç¹çåæ¶, å¯é¿åå¤æçåç¼©åå¾åç¼©æ¾æä½, é¦æ¬¡è¾å¥½å°è§£å³äºåç¼©åäºº<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15616598245366678296&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 1</a> <a href="/scholar?q=related:GMMRJ11NudgJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15616598245366678296&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'GMMRJ11NudgJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md10', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md10" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:GMMRJ11NudgJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Image and video processing in the compressed domain</h3><div class="gs_a">J Mukhopadhyay - 2011 - Chapman &amp; Hall</div><div class="gs_fl"><a href="/scholar?q=related:3bBAJFl-klkJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6454360137300750557&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'3bBAJFl-klkJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md11', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md11" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:3bBAJFl-klkJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=14399308448768267390&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=828045" class=yC16>Video shot classification with concept detection</a></h3><div class="gs_a">Z Ji, Y Su - International Symposium on  &hellip;, 2007 - proceedings.spiedigitallibrary.org</div><div class="gs_rs">abstract It is a challenging work to classify video shots into a predefined genre set according <br>to their semantic contents, which is helpful to video indexing, summarization and retrieval. <br>This research proposes a novel shot classification algorithm with concept detection for <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:nnCXtltYwrsJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/35/4B/RN223377322.html?source=googlescholar" class="gs_nph" class=yC17>BL Direct</a> <a href="/scholar?cluster=13529473381503037598&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'nnCXtltYwrsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> FRACTIONAL SCALING OF IMAGE AND VIDEO IN DCT DOMAIN</h3><div class="gs_a">YZMSK Tat, S Chua</div><div class="gs_fl"><a href="/scholar?q=related:j4oq39jjjDIJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3642536719232436879&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'j4oq39jjjDIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://scholarbank.nus.edu/bitstream/handle/10635/13633/Zhao_Yunlong_PhD_thesis.pdf?sequence=1" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu</span><span class="gs_ggsS">nus.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://scholarbank.nus.edu/handle/10635/13633" class=yC18>Automatic extraction and tracking of face sequences in MPEG video</a></h3><div class="gs_a">Z Yunlong - 2004 - scholarbank.nus.edu</div><div class="gs_rs">This PhD work focuses on the problem of extracting multiple face sequences from MPEG <br>video based on face detection and tracking. It aims to facilitate the strata-based digital video <br>modelling to achieve efficient video retrieval and browsing. The research includes the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:LWH47rNLYawJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12421292483445023021&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'LWH47rNLYawJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/82172x/201205/43423903.html" class=yC1A>åºäºåç¼©åçå¿«éäººè¸æ£æµæ¹æ³çéªè¯ä¸åæ</a></h3><div class="gs_a">çéºä¼ï¼ èµµå£«ä¼ï¼ ç°é - è­¦å¯ææ¯, 2012 - cqvip.com</div><div class="gs_rs">æçç»´æ®: å¸æ·ä½é¢; åå¼è®°å½; ä¸è½½è®°å½; æçæ¶è. è´­ç©è½¦; åå¼; å®¢æ. é¦é¡µ | æåå¤§å¨ | å¨çº¿åºç |<br>è®ºææ£æµ | å¨çº¿èè¯ | ä¼ä¸ææ¥é¦ | å­¦èç©ºé´ | å­¦æ¯æºæ | è®ºæåè¡¨ |. æ¨çä½ç½®ï¼ç½ç«é¦é¡µ &gt;<br>ãä¸­æç§ææåæ°æ®åºã &gt; å·¥ç¨ææ¯ &gt; èªå¨åè®¡ç®æº &gt; è®¡ç®æºåºç¨ &gt; æè¦. <b>...</b> </div><div class="gs_fl"><a onclick="return gs_ocit(event,'nTPKYnQucL8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://www.etti.utcluj.ro/download/498_Rezumat_te.pdf" class=yC1C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from utcluj.ro</span><span class="gs_ggsS">utcluj.ro <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.etti.utcluj.ro/download/498_Rezumat_te.pdf" class=yC1B>ContribuÅ£ii la prelucrarea neliniarÄ Åi adaptivÄ a imaginilor comprimate JPEG</a></h3><div class="gs_a">C ÅtiinÅ£ific, A VLAICU - etti.utcluj.ro</div><div class="gs_rs">Tematica abordatÄ Ã®n cadrul cercetÄrii doctorale este cea a prelucrÄrii direct Ã®n domeniul <br>comprimat a imaginilor digitale statice Åi a secvenÅ£elor video JPEG/MPEG. Acest domeniu <br>adreseazÄ, Ã®n principal, problema eficientizÄrii prelucrÄrii imaginilor prin eliminarea <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:sgLndJ9s_qMJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'sgLndJ9s_qMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md16', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md16" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:sgLndJ9s_qMJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://www.ms17.cn/uploadfile/b/uploadfile/20065/20065044.PDF" class=yC1E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ms17.cn</span><span class="gs_ggsS">ms17.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ms17.cn/uploadfile/b/uploadfile/20065/20065044.PDF" class=yC1D>åç¼©åäºèç½ä¿¡æ¯çæµè¿æ»¤ä»ªå³é®ææ¯ç ç©¶</a></h3><div class="gs_a">æ²å°èªï¼ çç´ ç - ç°ä»£ç§å­¦ä»ªå¨, 2006 - ms17.cn</div><div class="gs_rs">æè¦éå¯¹äºèç½ä¿¡æ¯çæµç®¡ççéæ±, æä»¬æåºåºäºåç¼©åçç½ç»ä¿¡æ¯çæµè¿æ»¤ä»ªçæ¦å¿µ, <br>å¹¶ä»åç¼©åçº¹çä¿¡æ¯çåç±», è½®å»æå, å­ç¬¦å®ä½, è¤è²åå², äººè¸æ£æµç­å ä¸ªæ¹é¢å¯¹å¶ææ¶åç<br>å³é®ææ¯è¿è¡äºå¹¿æ³æ·±å¥çç å®, æåºäºä¸ç³»åé«æçåç¼©åå¾åå¤çç®æ³, ä¸ºçæµè¿æ»¤ä»ªç<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:yIOnue2wICUJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2675332713726575560&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'yIOnue2wICUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md17', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md17" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:yIOnue2wICUJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
