Total results = 16
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.88.2127&amp;rep=rep1&amp;type=pdf#page=57" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.88.2127&amp;rep=rep1&amp;type=pdf#page=57" class=yC0>Object boundary detection for ontology-based image classification</a></h3><div class="gs_a">L Wang, L Khan, C Breen - &hellip;  of the Third International Workshop on  &hellip;, 2002 - Citeseer</div><div class="gs_rs">ABSTRACT Technology in the field of digital media generates huge amounts of non-textual <br>information, audio, video, and images, along with more familiar textual information. The <br>potential for exchange and retrieval of information is vast and daunting. The key problem <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9830117167266326327&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16">Cited by 10</a> <a href="/scholar?q=related:N-dgP3uXa4gJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9830117167266326327&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'N-dgP3uXa4gJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md0', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md0" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:N-dgP3uXa4gJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://tkuir.lib.tku.edu.tw/dspace/bitstream/987654321/37397/1/0769524893_p403-407.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tku.edu.tw</span><span class="gs_ggsS">tku.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1565861" class=yC2>Photo defect detection for image inpainting</a></h3><div class="gs_a">RC Chang, YL Sie, SM Chou&hellip; - Multimedia, Seventh  &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Image inpainting (or image completion) techniques use textural or structural <br>information to repair or fill damaged portion of a picture. However, most techniques request <br>a human to identify the portion to be inpainted. We developed a new mechanism which <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6063961611189593223&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16">Cited by 8</a> <a href="/scholar?q=related:h6SPBvWEJ1QJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6063961611189593223&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'h6SPBvWEJ1QJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1468-0394.2010.00543.x/full" class=yC4>Multiple scale neural architecture for enhancing regions in the colour image segmentation process</a></h3><div class="gs_a">FJ DÃ­azâPernas, M AntÃ³nâRodrÃ­guez&hellip; - Expert  &hellip;, 2011 - Wiley Online Library</div><div class="gs_rs">Abstract: A dynamic multi-scale neural model for enhancing regions and extracting contours <br>in the colour image segmentation process is proposed. This model combines colour and <br>textural information to coherently enhance images through the operation of two main <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12215015048476504292&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16">Cited by 4</a> <a href="/scholar?q=related:5DB--ndzhKkJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12215015048476504292&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'5DB--ndzhKkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.21.6206&amp;rep=rep1&amp;type=pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1048360" class=yC5>Object segmentation and tracking using video locales</a></h3><div class="gs_a">J Au, ZN Li, <a href="/citations?user=ZeJn22YAAAAJ&amp;hl=en&amp;oi=sra">MS Drew</a> - Pattern Recognition, 2002. Proceedings. &hellip;, 2002 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present a new technique based on feature localization for <br>segmenting and tracking objects in videos. A video locale is a sequence of image feature <br>locales that share similar features (color, texture, shape, and motion) in the spatio-<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5551954004115666989&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16">Cited by 3</a> <a href="/scholar?q=related:LTifUMCADE0J:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/15/2E/RN126684400.html?source=googlescholar" class="gs_nph" class=yC7>BL Direct</a> <a href="/scholar?cluster=5551954004115666989&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 42 versions</a> <a onclick="return gs_ocit(event,'LTifUMCADE0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md3', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md3" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:LTifUMCADE0J:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=1972484110528117767&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/A402U3703221PV17.pdf" class=yC8>A surface errors locator system for ancient culture preservation</a></h3><div class="gs_a">Y Yu, D Xu, C Chen, Y Yu, <a href="/citations?user=XWoUWRwAAAAJ&amp;hl=en&amp;oi=sra">L Zhao</a> - Digital Libraries: Achievements,  &hellip;, 2006 - Springer</div><div class="gs_rs">Abstract. We present a novel system to find the surface errors for preservation and <br>reappearance of cultural relic image better. Our approach firstly transforms images to HSL <br>color space in accord with human vision and deal with the lightness of color conveniently. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7200599994774640591&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16">Cited by 2</a> <a href="/scholar?q=related:z9c4eour7WMJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/3D/05/RN200038006.html?source=googlescholar" class="gs_nph" class=yC9>BL Direct</a> <a href="/scholar?cluster=7200599994774640591&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'z9c4eour7WMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/4vxl8tddfehtuq7t.pdf" class=yCA>Object detection for hierarchical image classification</a></h3><div class="gs_a">L Khan, L Wang - Mining Multimedia and Complex Data, 2003 - Springer</div><div class="gs_rs">Technology in the field of digital media generates huge amounts of non-textual information, <br>audio, video, and images, along with more familiar textual information. The potential for <br>exchange and retrieval of information is vast and daunting. The key problem in achieving <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18362285847561328722&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16">Cited by 1</a> <a href="/scholar?q=related:UlgT2LDx0_4J:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/1F/5C/RN139587429.html?source=googlescholar" class="gs_nph" class=yCB>BL Direct</a> <a href="/scholar?cluster=18362285847561328722&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'UlgT2LDx0_4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://congresos.cio.mx/3_enc_mujer/files/extensos/Sesion%202/S2-ING12.doc" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[DOC]</span> from cio.mx</span><span class="gs_ggsS">cio.mx <span class=gs_ctg2>[DOC]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[DOC]</span><span class="gs_ct2">[DOC]</span></span> <a href="http://congresos.cio.mx/3_enc_mujer/files/extensos/Sesion%202/S2-ING12.doc" class=yCC>SegmentaciÃ³n de imÃ¡genes naturales usando el espacio de color CIELab</a></h3><div class="gs_a">LS LÃ³pez-Conejo, <a href="/citations?user=9b6b7jYAAAAJ&amp;hl=en&amp;oi=sra">RE SÃ¡nchez-YÃ¡nez</a> - Universidad de Guanajuato,  &hellip; - congresos.cio.mx</div><div class="gs_rs">ResumEn Se evalÃºa la utilizaciÃ³n de componentes del espacio de color CIELab para la <br>segmentaciÃ³n de imÃ¡genes de ambientes no estructurados, como los observados en <br>paisajes naturales. Al inicio, se introduce al tema con una discusiÃ³n acerca del espacio <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14442663347103688900&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=16">Cited by 1</a> <a href="/scholar?q=related:xGirLsulbsgJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14442663347103688900&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'xGirLsulbsgJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md6', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md6" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:xGirLsulbsgJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://muvis.cs.tut.fi/Documents/Stefan_MscThesis.pdf" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tut.fi</span><span class="gs_ggsS">tut.fi <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://muvis.cs.tut.fi/Documents/Stefan_MscThesis.pdf" class=yCE>Region-based Multimedia Indexing and Retrieval Framework</a></h3><div class="gs_a">S UHLMANN - muvis.cs.tut.fi</div><div class="gs_rs">Page 1. TAMPERE UNIVERSITY OF TECHNOLOGY DEPARTMENT OF INFORMATION<br>TECHNOLOGY STEFAN UHLMANN Region-based Multimedia Indexing and Retrieval<br>Framework MASTER OF SCIENCE THESIS Subject approved in the Department <b>...</b> </div><div class="gs_fl"><a href="/scholar?q=related:I0mAABkc5kgJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'I0mAABkc5kgJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md7', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md7" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:I0mAABkc5kgJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://www.labplan.ufsc.br/congressos/wseas/papers/517-383.pdf" class=yC11><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ufsc.br</span><span class="gs_ggsS">ufsc.br <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.labplan.ufsc.br/congressos/wseas/papers/517-383.pdf" class=yC10>Automatic Blemish Detection for Image Restoration of Virtual Heritage Environments1</a></h3><div class="gs_a">Y Yu, D Xu, C Chen, Y Yu, <a href="/citations?user=XWoUWRwAAAAJ&amp;hl=en&amp;oi=sra">L Zhao</a> - Proceedings of the 6th WSEAS  &hellip;, 2006 - labplan.ufsc.br</div><div class="gs_rs">Abstract. This paper proposes a novel approach for the completion of natural scenery <br>images, which automatically detects the blemish region in the image for restoration. This <br>approach consists of two filtering steps and uses shape information to detect the blemish <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:utwJEdQOTDUJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3840460886221905082&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'utwJEdQOTDUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md8', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md8" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:utwJEdQOTDUJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/Q028L71024J41V50.pdf" class=yC12>Left Object Detection with Reduced False Positives in Real-Time</a></h3><div class="gs_a">A Piratla, M Das, J Surendran - Advances in Computing and Information  &hellip; - Springer</div><div class="gs_rs">Identifying unattended objects in public places efficiently, is one of the major thrust areas of <br>security. This paper proposes a real-time method to identify unattended or left objects in a <br>region of interest that is under surveillance. This is a simple pixel based method for object <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:2Vq9cXi3U5QJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'2Vq9cXi3U5QJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://www.brunel.nom.fr/publications/poster_ICME03_brunel_lionel.pdf" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from brunel.nom.fr</span><span class="gs_ggsS">brunel.nom.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1221311" class=yC13>Fast method of segmentation and indexing MPEG1-2 flow</a></h3><div class="gs_a">L Brunel, P Mathieu - Multimedia and Expo, 2003. ICME&#39;03.  &hellip;, 2003 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Multimedia data accessibility depends on a precise indexing, involving a <br>computational cost. This paper proposes a new fast method of segmentation and indexing in <br>order to fill out in an automatic way several MPEG7 [ISO/IEC, 1999] fields (eg camera and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:f5Bq6h85mssJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14671101545352433791&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 22 versions</a> <a onclick="return gs_ocit(event,'f5Bq6h85mssJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ci.nii.ac.jp/naid/110003671069/" class=yC15>ã­ãã¹ãç°æ¹æ§é åæé·ã«ãã 2 æ®µéç»åã»ã°ã¡ã³ãã¼ã·ã§ã³</a></h3><div class="gs_a">S Auethavekiat, K Aizawa - æ åæå ±ã¡ãã£ã¢å­¦ä¼èª: æ åæå ±ã¡ãã£ã¢, 2003 - ci.nii.ac.jp</div><div class="gs_rs">æé² Region growing is a widely used image-segmentation techniques. However, <br>oversegmentation and dependency on the starting point (seed) pose difficulties. We propose <br>an algorithm using the robust homogeneous criteria consisting of (1) intensity and (2) no <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:8oTFFTI5YGwJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7809304641136854258&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'8oTFFTI5YGwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md11', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md11" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:8oTFFTI5YGwJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://www.brunel.nom.fr/publications/GRETSI01_brunel_lionel.pdf" class=yC17><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from brunel.nom.fr</span><span class="gs_ggsS">brunel.nom.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.brunel.nom.fr/publications/GRETSI01_brunel_lionel.pdf" class=yC16>Lionel BRUNEL</a></h3><div class="gs_a">L Brunel, P Mathieu - 2009 - brunel.nom.fr</div><div class="gs_rs">AbstractâThe accessibility of the multimedia data dependents on a precise indexing, which <br>takes a lot of time. This paper proposes a new method to inform in an automatic way several <br>fields MPEG7 (for example, the movement of the camera and objects). We exploit the most <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:GXGJHgjYKJQJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10676020446065422617&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'GXGJHgjYKJQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://documents.irevues.inist.fr/bitstream/handle/2042/13450/PAPER360.pdf?seque.." class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from inist.fr</span><span class="gs_ggsS">inist.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://documents.irevues.inist.fr/handle/2042/13450" class=yC18>MÃ©thode rapide de segmentation et d&#39;indexation du flux MPEG1-2 par bloc DCT</a></h3><div class="gs_a">L Brunel, P Mathieu - 18Â° Colloque sur le traitement du  &hellip;, 2001 - documents.irevues.inist.fr</div><div class="gs_rs">L&#39;accessibilitÃ© des donnÃ©es multimÃ©dias est tributaire d&#39;une indexation prÃ©cise, ce qui <br>demande un temps trÃ¨s long. Cet article propose une nouvelle mÃ©thode pour renseigner de <br>faÃ§on automatique plusieurs champs MPEG7 (par exemple, le mouvement de la camÃ©ra <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Ra8gWE3qHzEJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3539805450048417605&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'Ra8gWE3qHzEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://hal-unice.archives-ouvertes.fr/docs/00/21/41/13/PDF/These_Brunel.pdf" class=yC1B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://hal-unice.archives-ouvertes.fr/docs/00/21/41/13/PDF/These_Brunel.pdf" class=yC1A>NICE-SOPHIA ANTIPOLIS</a></h3><div class="gs_a">L BRUNEL - hal-unice.archives-ouvertes.fr</div><div class="gs_rs">Je tiens Ã  remercier Monsieur le Professeur Michel Barlaud qui m&#39;a accueilli au sein de <br>l&#39;Ã©quipe CReATIVe3 dont il est le responsable. Je tiens Ã  le remercier chaleureusement <br>pour ses aides nombreuses, dont les aides financiÃ¨res, qui m&#39;ont permis de participer Ã  <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Mlg1WrytQzIJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3621929549814913074&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'Mlg1WrytQzIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md14', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md14" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Mlg1WrytQzIJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://tel.archives-ouvertes.fr/docs/00/21/41/13/PDF/These_Brunel.pdf" class=yC1D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://tel.archives-ouvertes.fr/tel-00214113/" class=yC1C>Indexation vidÃ©o par l&#39;analyse de codage</a></h3><div class="gs_a">L Brunel - 2004 - tel.archives-ouvertes.fr</div><div class="gs_rs">Je tiens Ã  remercier Monsieur le Professeur Michel Barlaud qui m&#39;a accueilli au sein de <br>l&#39;Ã©quipe CReATIVe3 dont il est le responsable. Je tiens Ã  le remercier chaleureusement <br>pour ses aides nombreuses, dont les aides financiÃ¨res, qui m&#39;ont permis de participer Ã  <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:C_Rq19-zS7IJ:scholar.google.com/&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12847560135977661451&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'C_Rq19-zS7IJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md15', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md15" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:C_Rq19-zS7IJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=16&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=7447051982679938982&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
