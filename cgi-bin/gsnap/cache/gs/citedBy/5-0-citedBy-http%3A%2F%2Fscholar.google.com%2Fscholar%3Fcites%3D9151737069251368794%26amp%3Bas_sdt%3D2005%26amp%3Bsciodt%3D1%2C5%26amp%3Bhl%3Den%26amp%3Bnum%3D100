Total results = 5
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.221.3757&amp;rep=rep1&amp;type=pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6163959" class=yC0>Regularized subspace Gaussian mixture models for cross-lingual speech recognition</a></h3><div class="gs_a">L Lu, A Ghoshal, <a href="/citations?user=hERDiOEAAAAJ&amp;hl=en&amp;oi=sra">S Renals</a> - Automatic Speech Recognition  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We investigate cross-lingual acoustic modelling for low resource languages using <br>the subspace Gaussian mixture model (SGMM). We assume the presence of acoustic <br>models trained on multiple source languages, and use the global subspace parameters <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8598284989798436351&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5">Cited by 3</a> <a href="/scholar?q=related:_02CfqQ-U3cJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8598284989798436351&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'_02CfqQ-U3cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://www.comp.nus.edu.sg/~li-bo/papers/is10_0526_adapt.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.comp.nus.edu.sg/~li-bo/papers/is10_0526_adapt.pdf" class=yC2>Comparison of Discriminative Input and Output Transformations for Speaker Adaptation in the Hybrid NN/HMM Systems</a></h3><div class="gs_a"><a href="/citations?user=SLgWQLEAAAAJ&amp;hl=en&amp;oi=sra">B Li</a>, <a href="/citations?user=jnU62sUAAAAJ&amp;hl=en&amp;oi=sra">KC Sim</a> - Eleventh Annual Conference of the International  &hellip;, 2010 - comp.nus.edu.sg</div><div class="gs_rs">Abstract Speaker variability is one of the major error sources for ASR systems. Speaker <br>adaptation estimates speaker specific models from the speaker independent ones to <br>minimize the mismatch between the training and testing conditions arisen from speaker <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1073705282869215385&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5">Cited by 1</a> <a href="/scholar?q=related:mUDhGkSR5g4J:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1073705282869215385&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'mUDhGkSR5g4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www.comp.nus.edu.sg/~wang86/Joey_files/papers/seq.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.comp.nus.edu.sg/~wang86/Joey_files/papers/seq.pdf" class=yC4>Sequential Classification Criteria for NNs in Automatic Speech Recognition</a></h3><div class="gs_a">W Guangsen, <a href="/citations?user=jnU62sUAAAAJ&amp;hl=en&amp;oi=sra">KC Sim</a> - 2011 - comp.nus.edu.sg</div><div class="gs_rs">Abstract Neural networks (NNs) are discriminative classifiers which have been successfully <br>integrated with hidden Markov models (HMMs), either in the hybrid NN/HMM or tandem <br>connectionist systems. Typically, the NNs are trained with the framebased cross-entropy <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13934189542361626647&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=5">Cited by 1</a> <a href="/scholar?q=related:F3ht8Y8vYMEJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13934189542361626647&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'F3ht8Y8vYMEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://www.comp.nus.edu.sg/~wang86/Joey_files/papers/smth.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.comp.nus.edu.sg/~wang86/Joey_files/papers/smth.pdf" class=yC6>Comparison of Smoothing Techniques for Robust Context Dependent Acoustic Modelling in Hybrid NN/HMM Systems</a></h3><div class="gs_a">W Guangsen, <a href="/citations?user=jnU62sUAAAAJ&amp;hl=en&amp;oi=sra">KC Sim</a> - 2011 - comp.nus.edu.sg</div><div class="gs_rs">Abstract Hybrid Neural Network/Hidden Markov Model (NN/HMM) systems have been found <br>to yield high quality phone recognition performance. One issue with modelling the Context <br>Dependent (CD) NN/HMM is the robust estimation of the NN parameters to reliably predict <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:fIHT4FxqRNUJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15367524775636468092&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'fIHT4FxqRNUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://homepages.inf.ed.ac.uk/llu/pdf/llu_2nd_year_report.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ed.ac.uk</span><span class="gs_ggsS">ed.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://homepages.inf.ed.ac.uk/llu/pdf/llu_2nd_year_report.pdf" class=yC8>Robust Estimation and Adaptation of Subspace Gaussian Mixture Models for Automatic Speech Recognition</a></h3><div class="gs_a">L Lu - 2011 - homepages.inf.ed.ac.uk</div><div class="gs_rs">Abstract In conventional hidden Markov model (HMM) based speech recognisers, the <br>emitting HMM states are modelled by Gaussian Mixture Models (GMMs), with parameters <br>been estimated directly from the training data. However, in Subspace Gaussian mixture <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:CucG9PBTuEUJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'CucG9PBTuEUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md4', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md4" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:CucG9PBTuEUJ:scholar.google.com/&amp;hl=en&amp;num=5&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
