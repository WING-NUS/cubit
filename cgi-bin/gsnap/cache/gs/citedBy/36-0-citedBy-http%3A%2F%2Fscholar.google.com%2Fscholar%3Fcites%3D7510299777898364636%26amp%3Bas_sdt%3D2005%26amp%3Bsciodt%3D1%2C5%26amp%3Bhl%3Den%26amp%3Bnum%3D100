Total results = 36
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.comp.nus.edu.sg/~TANCL/publications/j2011/TPAMI-2009-09-0621-Minor.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5557889" class=yC0>A Laplacian approach to multi-oriented text detection in video</a></h3><div class="gs_a">P Shivakumara, <a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>&hellip; - Pattern Analysis and  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose a method based on the Laplacian in the frequency <br>domain for video text detection. Unlike many other approaches which assume that text is <br>horizontally-oriented, our method is able to handle text of arbitrary orientation. The input <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18410909248866227790&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 32</a> <a href="/scholar?q=related:ThagqmqwgP8J:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18410909248866227790&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 21 versions</a> <a onclick="return gs_ocit(event,'ThagqmqwgP8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3337634/" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from nih.gov</span><span class="gs_ggsS">nih.gov <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5729827" class=yC2>Text string detection from natural scenes by structure-based partition and grouping</a></h3><div class="gs_a">C Yi, <a href="/citations?user=aAWeB4wAAAAJ&amp;hl=en&amp;oi=sra">YL Tian</a> - Image Processing, IEEE Transactions on, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Text information in natural scene images serves as important clues for many image-<br>based applications such as scene understanding, content-based image retrieval, assistive <br>navigation, and automatic geocoding. However, locating text from a complex background <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3016895145552734713&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 23</a> <a href="/scholar?q=related:-WlFkyYq3ikJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3016895145552734713&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'-WlFkyYq3ikJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www.comp.nus.edu.sg/~tancl/publications/j2010/TCSVT4004-FinalPDF.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5585735" class=yC4>New Fourier-statistical features in RGB space for video text detection</a></h3><div class="gs_a">P Shivakumara, <a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>&hellip; - Circuits and Systems for  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose new Fourier-statistical features (FSF) in RGB space for <br>detecting text in video frames of unconstrained background, different fonts, different scripts, <br>and different font sizes. This paper consists of two parts namely automatic classification of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8338467067798852630&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 9</a> <a href="/scholar?q=related:FpRxe54vuHMJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8338467067798852630&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'FpRxe54vuHMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://www.karatzas.co.uk/papers/ICDAR2011_Karatzas.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from karatzas.co.uk</span><span class="gs_ggsS">karatzas.co.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6065555" class=yC6>ICDAR 2011 Robust Reading Competition-Challenge 1: Reading Text in Born-Digital Images (Web and Email)</a></h3><div class="gs_a"><a href="/citations?user=xASEtrUAAAAJ&amp;hl=en&amp;oi=sra">D Karatzas</a>, SR Mestre, J Mas&hellip; - Document Analysis  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents the results of the first Challenge of ICDAR 2011 Robust <br>Reading Competition. Challenge 1 is focused on the extraction of text from born-digital <br>images, specifically from images found in Web pages and emails. The challenge was <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17121888137954988608&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 9</a> <a href="/scholar?q=related:QBLIuosqne0J:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17121888137954988608&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'QBLIuosqne0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://media-lab.engr.ccny.cuny.edu/Paper/2010/ICCHP10-ContexWayfinding.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cuny.edu</span><span class="gs_ggsS">cuny.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/260UUJ35LN4XV882.pdf" class=yC8>Improving computer vision-based indoor wayfinding for blind persons with context information</a></h3><div class="gs_a"><a href="/citations?user=aAWeB4wAAAAJ&amp;hl=en&amp;oi=sra">YL Tian</a>, C Yi, A Arditi - Computers Helping People with Special Needs, 2010 - Springer</div><div class="gs_rs">There are more than 161 million visually impaired people in the world today, of which 37 <br>million are blind. Camera-based computer vision systems have the potential to assist blind <br>persons to independently access unfamiliar buildings. Signs with text play a very <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=971803248158340552&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 5</a> <a href="/scholar?q=related:yHUMxueJfA0J:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=971803248158340552&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'yHUMxueJfA0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://www.comp.nus.edu.sg/~tancl/publications/c2010/ShivaTextDetection-407.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.comp.nus.edu.sg/~tancl/publications/c2010/ShivaTextDetection-407.pdf" class=yCA>New wavelet and color features for text detection in Video</a></h3><div class="gs_a">P Shivakumara, <a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - Proceedings of the 2010 20th  &hellip;, 2010 - comp.nus.edu.sg</div><div class="gs_rs">Abstract-Automatic text detection in video is an important task for efficient and accurate <br>indexing and retrieval of multimedia data such as events identification, events boundary <br>identification etc. This paper presents a new method comprising of wavelet decomposition <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6715471896415485265&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 4</a> <a href="/scholar?q=related:Ub32FBwmMl0J:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6715471896415485265&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'Ub32FBwmMl0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md5', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md5" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Ub32FBwmMl0J:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://www-ee.ccny.cuny.edu/www/web/yltian/Publications/ICDAR11-Yi-Tian.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cuny.edu</span><span class="gs_ggsS">cuny.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6065299" class=yCC>Text detection in natural scene images by stroke Gabor words</a></h3><div class="gs_a">C Yi, <a href="/citations?user=aAWeB4wAAAAJ&amp;hl=en&amp;oi=sra">Y Tian</a> - Document Analysis and Recognition (ICDAR),  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose a novel algorithm, based on stroke components and <br>descriptive Gabor filters, to detect text regions in natural scene images. Text characters and <br>strings are constructed by stroke components as basic units. Gabor filters are used to <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7318587465823172671&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 6</a> <a href="/scholar?q=related:PzgETobYkGUJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7318587465823172671&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'PzgETobYkGUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://www-ee.ccny.cuny.edu/www/web/yltian/Publications/CBDAR2011_PostProceedings.PDF" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cuny.edu</span><span class="gs_ggsS">cuny.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/E157X3555V74M3JK.pdf" class=yCE>Assistive text reading from complex background for blind persons</a></h3><div class="gs_a">C Yi, <a href="/citations?user=aAWeB4wAAAAJ&amp;hl=en&amp;oi=sra">Y Tian</a> - Camera-Based Document Analysis and Recognition, 2012 - Springer</div><div class="gs_rs">In the paper, we propose a camera-based assistive system for visually impaired or blind <br>persons to read text from signage and objects that are held in the hand. The system is able <br>to read text from complex backgrounds and then communicate this information aurally. To <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15229765554693441120&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 4</a> <a href="/scholar?q=related:YIb7yxT_WtMJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15229765554693441120&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'YIb7yxT_WtMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/Y338K1745U113M60.pdf" class=yC10>Statistical modeling for the detection, localization and extraction of text from heterogeneous textual images using combined feature scheme</a></h3><div class="gs_a">C Gopalan, D Manjula - Signal, Image and Video Processing, 2011 - Springer</div><div class="gs_rs">Abstract Discriminating between the text and non text regions of an image is a complex and <br>challenging task. In contrast to Caption text, Scene text can have any orientation and may be <br>distorted by the perspective projection. Moreover, it is often affected by variations in scene <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=27003132874885407&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 3</a> <a href="/scholar?q=related:H4nUzjTvXwAJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=27003132874885407&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'H4nUzjTvXwAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.180.5205&amp;rep=rep1&amp;type=pdf" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1815365" class=yC11>A skeleton-based method for multi-oriented video text detection</a></h3><div class="gs_a"><a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>, P Shivakumara, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - Proceedings of the 9th IAPR  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we propose a method based on the skeletonization operation for multi-<br>oriented video text detection. The first step uses our existing Laplacian-based method to <br>identify candidate text regions. In the second step, each region is classified as either a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3582318005138939334&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 3</a> <a href="/scholar?q=related:xt3K6D7ztjEJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3582318005138939334&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'xt3K6D7ztjEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320311000550" class=yC13>A novel mutual nearest neighbor based symmetry for text frame classification in video</a></h3><div class="gs_a">P Shivakumara, A Dutta, <a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">T Quy Phan</a>, C Lim Tan&hellip; - Pattern Recognition, 2011 - Elsevier</div><div class="gs_rs">In the field of multimedia retrieval in video, text frame classification is essential for text <br>detection, event detection, event boundary detection, etc. We propose a new text frame <br>classification method that introduces a combination of wavelet and median moment with k-<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11993170311716469446&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 2</a> <a href="/scholar?q=related:xvqeINtMcKYJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11993170311716469446&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'xvqeINtMcKYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1815395" class=yC14>An eigen value based approach for text detection in video</a></h3><div class="gs_a">DS Guru, S Manjunath, P Shivakumara&hellip; - Proceedings of the 9th  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, a novel approach for detection of text and non-text regions in video <br>frames is proposed. The proposed approach performs block wise eigen analysis on the <br>gradient image of the video frame. For each block of the gradient frame, the dominant <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10040391418189623075&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 3</a> <a href="/scholar?q=related:I68Sb8yiVosJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'I68Sb8yiVosJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5693594" class=yC15>A New method for Handwritten scene text detection in video</a></h3><div class="gs_a">P Shivakumara, A Dutta, <a href="/citations?user=2_z_CogAAAAJ&amp;hl=en&amp;oi=sra">U Pal</a>&hellip; - Frontiers in Handwriting  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract There are many video images where hand written text may appear. Therefore <br>handwritten scene text detection in video is essential and useful for many applications for <br>efficient indexing, retrieval etc. Also there are many video frames where text line may be <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6316640492045681897&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 2</a> <a href="/scholar?q=related:6UQ7fg83qVcJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6316640492045681897&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'6UQ7fg83qVcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1815366" class=yC16>A new wavelet-median-moment based method for multi-oriented video text detection</a></h3><div class="gs_a">P Shivakumara, A Dutta, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a>, <a href="/citations?user=2_z_CogAAAAJ&amp;hl=en&amp;oi=sra">U Pal</a> - Proceedings of the 9th IAPR  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we present a new method based on wavelet-median-moments and a <br>novel idea of angle projection for detecting multi-oriented text in video. The proposed <br>method uses wavelet decomposition first to obtain three high frequency sub-bands (LH, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3151128915057296173&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 3</a> <a href="/scholar?q=related:LcNzhw0PuysJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3151128915057296173&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'LcNzhw0PuysJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.scientific.net/AMM.58-60.2528" class=yC17>Video-Tag Detection and Recognition</a></h3><div class="gs_a">LH Ye, HM Yin - Applied Mechanics and Materials, 2011 - Trans Tech Publ</div><div class="gs_rs">Abstract In this work, we present a video-tag detection and recognition method. According to <br>the duration of the video, choose an appropriate strategy to sample the frames. After the <br>candidate tag of every frame is computed, a median filter algorithm is employed to get the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:jiGWCWqzzOMJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16414692009867354510&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'jiGWCWqzzOMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://ijcsi.org/papers/IJCSI-8-5-3-225-234.pdf" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ijcsi.org</span><span class="gs_ggsS">ijcsi.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://ijcsi.org/papers/IJCSI-8-5-3-225-234.pdf" class=yC18>Robust Model for Text Extraction from Complex Video Inputs Based on SUSAN Contour Detection and Fuzzy C Means Clustering</a></h3><div class="gs_a">YS Kumaraswamy - ijcsi.org</div><div class="gs_rs">Abstract: The proposed system introduces a novel approach for extracting text effectively <br>from different types of complex video inputs. The valuable information within the text can be <br>deployed for text indexing and localization. The proposed system uses contour based <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:hNWbFBdJXOYJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16599222690059638148&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'hNWbFBdJXOYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md15', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md15" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:hNWbFBdJXOYJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=tm22nivpJi4C&amp;oi=fnd&amp;pg=PA41&amp;ots=Esj4wMcMAQ&amp;sig=kCzvk-XxhTKH5suzfSDmRIk73aI" class=yC1A>An Application of K-Means Clustering for Improving Video Text Detection</a></h3><div class="gs_a">VNM Aradhya, MS Pavithra - Intelligent Informatics, 2013 - books.google.com</div><div class="gs_rs">Abstract. In the present work, we explore an extensive applications of Gabor filter and K-<br>means clustering algorithm in detection of text in an unconstrained complex background and <br>regular images. The system is a comprehensive of four stages: In the first stage, <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'9jmpKTeMBAoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://media-lab.engr.ccny.cuny.edu/cyi/publications/papers_web/assets-p325-yi.pdf" class=yC1C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cuny.edu</span><span class="gs_ggsS">cuny.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1878894" class=yC1B>Text locating in scene images for reading and navigation aids for visually impaired persons</a></h3><div class="gs_a">C Yi - Proceedings of the 12th international ACM  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract Many reading assistants and navigation systems have been designed specifically <br>for people who are blind or visually impaired, but text locating in scene image with complex <br>background has not yet been successfully addressed. In this paper, we propose a novel <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:z35ePaliI20J:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7864237853337616079&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'z35ePaliI20J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> A Skeleton-Based Method for Multi-Oriented Text Detection</h3><div class="gs_a">TQPPS Chew, L Tan</div><div class="gs_fl"><a href="/scholar?q=related:BA_BR6t5r-MJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16406465744084209412&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'BA_BR6t5r-MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S1877705812008727" class=yC1D>Novel Approach of Adaptive Thresholding Technique for Edge Detection in Videos</a></h3><div class="gs_a">D Samanta, G Sanyal - Procedia Engineering, 2012 - Elsevier</div><div class="gs_rs">Edge detection and motion estimation is one of the important aspect to analyzed the video. <br>In this paper an adaptive threshold generation technique is used to filter the edges from its <br>background from a video. We first propose an algorithm for detecting edges within video <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:q6PAcLvmhT4J:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'q6PAcLvmhT4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> An Eigen Based Approach for Text Detection in Video</h3><div class="gs_a">DS Guru, S a Manjunath, P Shivakumara, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a></div><div class="gs_fl"><a href="/scholar?q=related:58NidEcD8MgJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'58NidEcD8MgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="http://www-ee.ccny.cuny.edu/www/web/yltian/Publications/CVIU-Text.pdf" class=yC1F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cuny.edu</span><span class="gs_ggsS">cuny.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www-ee.ccny.cuny.edu/www/web/yltian/Publications/CVIU-Text.pdf" class=yC1E>Text Extraction from Scene Images by Character Appearance and Structure Modeling</a></h3><div class="gs_a">C Yi, <a href="/citations?user=aAWeB4wAAAAJ&amp;hl=en&amp;oi=sra">Y Tian</a> - Computer Vision and Image Understanding, 2012 - www-ee.ccny.cuny.edu</div><div class="gs_rs">Abstract In this paper, we propose a novel algorithm to detect text information from natural <br>scene images. Scene text classification and detection are still open research topics. Our <br>proposed algorithm is able to model both character appearance and structure to generate <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'tSKshEXi35gJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md21', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md21" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:tSKshEXi35gJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB22" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW22"><a href="http://ijcsit.com/docs/Volume%202/vol2issue5/ijcsit2011020554.pdf" class=yC21><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ijcsit.com</span><span class="gs_ggsS">ijcsit.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://ijcsit.com/docs/Volume%202/vol2issue5/ijcsit2011020554.pdf" class=yC20>A Novel Approach of Entropy based Adaptive Thresholding Technique for Video Edge Detection</a></h3><div class="gs_a">D Samanta, M Paul - Threshold (x, y) - ijcsit.com</div><div class="gs_rs">AbstractâMotion estimation and Edge detection are one of the bottlenecks in terms in image <br>processing and computer vision, particularly in the areas of feature detection and feature <br>extraction, to refer to algorithms which aim at identifying points in a digital image frames of <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:u8w4ilwN_MIJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14050119628596235451&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'u8w4ilwN_MIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md22', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md22" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:u8w4ilwN_MIJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0957417412004800" class=yC22>A robust video text detection approach using SVM</a></h3><div class="gs_a">YC Wei, <a href="/citations?user=9-S7q8UAAAAJ&amp;hl=en&amp;oi=sra">CH Lin</a> - Expert Systems with Applications, 2012 - Elsevier</div><div class="gs_rs">A new method for detecting text in video images is proposed in this article. Variations in <br>background complexity, font size and color, make detecting text regions in video images a <br>difficult task. A pyramidal scheme is utilized to solve these problems. First, two downsized <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:i6DLi_p9x8UJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14251498060877897867&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'i6DLi_p9x8UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB24" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW24"><a href="http://media-lab.engr.ccny.cuny.edu/xyang/papers/MVAP_Navigation.pdf" class=yC24><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cuny.edu</span><span class="gs_ggsS">cuny.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/L87KU3T806V81371.pdf" class=yC23>Toward a computer vision-based wayfinding aid for blind persons to access unfamiliar indoor environments</a></h3><div class="gs_a"><a href="/citations?user=aAWeB4wAAAAJ&amp;hl=en&amp;oi=sra">YL Tian</a>, <a href="/citations?user=yWsMg_gAAAAJ&amp;hl=en&amp;oi=sra">X Yang</a>, C Yi, A Arditi - Machine Vision and Applications, 2012 - Springer</div><div class="gs_rs">Abstract Independent travel is a well-known challenge for blind and visually impaired <br>persons. In this paper, we propose a proof-of-concept computer vision-based wayfinding aid <br>for blind people to independently access unfamiliar indoor environments. In order to find <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11997268116089564575&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 1</a> <a href="/scholar?q=related:n22jjsnbfqYJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11997268116089564575&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'n22jjsnbfqYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> A New Bayesian Classifier Approach to Text Detection in Video Frames</h3><div class="gs_a">RP Sreedhar, P Shivakumara, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - 2004</div><div class="gs_fl"><a href="/scholar?q=related:q1fckUBzW2sJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'q1fckUBzW2sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> A New Method based on Maximum Color Difference and Boundary Growing for Handwritten Video Scene Text Detection</h3><div class="gs_a">P Shivakumara, A Dutta, <a href="/citations?user=2_z_CogAAAAJ&amp;hl=en&amp;oi=sra">U Pal</a>, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a></div><div class="gs_fl"><a href="/scholar?q=related:moIOmZwVg4MJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'moIOmZwVg4MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/V71273607X676682.pdf" class=yC25>An Application of K-Means Clustering for Improving Video Text Detection</a></h3><div class="gs_a">VN Manjunath Aradhya, MS Pavithra - Intelligent Informatics - Springer</div><div class="gs_rs">In the present work, we explore an extensive applications of Gabor filter and K-means <br>clustering algorithm in detection of text in an unconstrained complex background and <br>regular images. The system is a comprehensive of four stages: In the first stage, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:F-XOpnFCe1QJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'F-XOpnFCe1QJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Automatic Multi-Oriented Video Text Detection Based on Text Representatives</h3><div class="gs_a">P Shivakumara, A Dutta, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a>, <a href="/citations?user=2_z_CogAAAAJ&amp;hl=en&amp;oi=sra">U Pal</a></div><div class="gs_fl"><a href="/scholar?q=related:3IvLwhrlViMJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2546474542424624092&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'3IvLwhrlViMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB29" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW29"><a href="http://www-ee.ccny.cuny.edu/www/web/yltian/Publications/TIP-Yi-2012.pdf" class=yC27><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cuny.edu</span><span class="gs_ggsS">cuny.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6200341" class=yC26>Localizing Text in Scene Images by Boundary Clustering, Stroke Segmentation, and String Fragment Classification</a></h3><div class="gs_a">C Yi, <a href="/citations?user=aAWeB4wAAAAJ&amp;hl=en&amp;oi=sra">YL Tian</a> - Image Processing, IEEE Transactions on, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose a novel framework to extract text regions from scene <br>images with complex backgrounds and multiple text appearances. This framework consists <br>of three main steps: boundary clustering (BC), stroke segmentation, and string fragment <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:QEshyprrNXMJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8301800538176047936&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'QEshyprrNXMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/6Q587377K6642628.pdf" class=yC28>A Robust Algorithm for Arabic Video Text Detection</a></h3><div class="gs_a">A Ahmad, A Alqutami, J Atoum - Proceedings of the 2011 2nd International &hellip;, 2012 - Springer</div><div class="gs_rs">In this paper, we propose an efficient Arabic text detection method based on the Laplacian <br>operator in the frequency domain. The zero crossing value is computed for each pixel in the <br>Laplacian-filtered image to found edges in four directions. K-means is then used to <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:PNY12gquFrUJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13048808331986458172&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'PNY12gquFrUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S2212017312003143" class=yC29>A Robust Multilingual Text Detection Approach Based on Transforms and Wavelet Entropy</a></h3><div class="gs_a">VN Aradhya, MS Pavithra, C Naveena - Procedia Technology, 2012 - Elsevier</div><div class="gs_rs">Abstract In the present work, we describe the study and performance of a robust text <br>detection method in color and regular images. The system employs two important stages: <br>Firstly the combination of wavelet transforms and gabor filter is applied to extract <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:znpa8w9zpd8J:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'znpa8w9zpd8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> New SVD-Statistical Features in RGB Space for Video Text Detection</h3><div class="gs_a">P Shivakumara, <a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a></div><div class="gs_fl"><a href="/scholar?q=related:IkKe89j4CdMJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'IkKe89j4CdMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:367"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB33" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW33"><a href="http://www.comp.nus.edu.sg/~TANCL/publications/j2012/Shiva-TCSVT12-Bayes-Page.pdf" class=yC2B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6196211" class=yC2A>Multioriented Video Scene Text Detection Through Bayesian Classification and Boundary Growing</a></h3><div class="gs_a">P Shivakumara, RP Sreedhar, <a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>&hellip; - Circuits and Systems &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Multioriented text detection in video frames is not as easy as detection of captions <br>or graphics or overlaid texts, which usually appears in the horizontal direction and has high <br>contrast compared to its background. Multioriented text generally refers to scene text that <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9097153869983721236&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=36">Cited by 1</a> <a href="/scholar?q=related:FCdz9z6VP34J:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9097153869983721236&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'FCdz9z6VP34J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:366"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/92337a/201106/37020079.html" class=yC2C>è§é¢æ ç­¾æ£æµä¸è¯å«</a></h3><div class="gs_a">å¶å©å - å¶é ä¸èªå¨å, 2011 - cqvip.com</div><div class="gs_rs">æåºä¸ç§è§é¢æ ç­¾çæ£æµä¸è¯å«æ¹æ³. æ ¹æ®è§é¢é¿åº¦, éç¨ä¸åçç­ç¥è·å¾æ½æ ·å¸§; <br>å¯¹æ¯ä¸ªæ½æ ·å¸§è®¡ç®åéæ ç­¾; ç¶åå¯¹ææåéæ ç­¾è¿è¡ä¸æ¬¡ä¸­å¼æ»¤æ³¢, ç¡®å®æ ç­¾è¾¹ç; <br>æåå©ç¨ä¸ç§åºäºå¤å¸§èååæçæ¹æ³å®ç°è§é¢æ ç­¾çäºå¼å. å¯¹è·å¾çäºå¼åæ ç­¾, å¨ç¼©æ¾<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:50hdWacBQnsJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8881663233398491367&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'50hdWacBQnsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:365"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB35" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW35"><a href="http://www.ecice06.com/EN/article/downloadArticleFile.do?attachType=PDF&amp;id=21755" class=yC2E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ecice06.com</span><span class="gs_ggsS">ecice06.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ecice06.com/EN/article/downloadArticleFile.do?attachType=PDF&amp;id=21755" class=yC2D>åºäºèªéåº LBP çè§é¢ææ¬æ£æµç®æ³</a></h3><div class="gs_a">æ±å®æ³¢ï¼ å¼ æ¥å¤ï¼ éç¢§å¨ - Computer Engineering, 2011 - ecice06.com</div><div class="gs_rs">æè¦: éå¯¹LBP ç®æ³èªéåºæ§å¼±åå¤æåº¦é«çé®é¢, æåºä¸ç§åºäºèªéåºLBP <br>ç®å­çè§é¢ææ¬æ£æµç®æ³. è¯¥ç®æ³å©ç¨å¨å±åå±é¨çåç´ ç°åº¦åå·®å³å®èªéåºéå¼å¤§å°, <br>è½æå¤§éåº¦å»é¤å¤æèæ¯, èªéåºæ§è¾å¼º. ç»åºåºäºè¿ä¼¼åçæ©æ¨¡ç®æ³æ¥è¦çå¤æ¹åç§å­çé¿<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:4lOrunB6IHoJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8800168296468665314&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'4lOrunB6IHoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md35', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md35" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:4lOrunB6IHoJ:scholar.google.com/&amp;hl=en&amp;num=36&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
