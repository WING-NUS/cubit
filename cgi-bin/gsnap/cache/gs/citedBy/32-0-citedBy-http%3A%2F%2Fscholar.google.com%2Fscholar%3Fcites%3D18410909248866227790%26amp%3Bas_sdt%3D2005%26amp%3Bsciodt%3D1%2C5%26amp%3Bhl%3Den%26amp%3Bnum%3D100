Total results = 32
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.stanford.edu/~dmchen/documents/ICIP2011_RobustTextDetection.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from stanford.edu</span><span class="gs_ggsS">stanford.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6116200" class=yC0>Robust text detection in natural images with edge-enhanced maximally stable extremal regions</a></h3><div class="gs_a"><a href="/citations?user=WghqyVMAAAAJ&amp;hl=en&amp;oi=sra">H Chen</a>, <a href="/citations?user=JdE_LFYAAAAJ&amp;hl=en&amp;oi=sra">SS Tsai</a>, <a href="/citations?user=OrgfKhAAAAAJ&amp;hl=en&amp;oi=sra">G Schroth</a>, <a href="/citations?user=VatsnGUAAAAJ&amp;hl=en&amp;oi=sra">DM Chen</a>&hellip; - &hellip;  (ICIP), 2011 18th  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Detecting text in natural images is an important prerequisite. In this paper, we <br>propose a novel text detection algorithm, which employs edge-enhanced Maximally Stable <br>Extremal Regions as basic letter candidates. These candidates are then filtered using <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8653879580759317318&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=32">Cited by 23</a> <a href="/scholar?q=related:Rlsq5KDBGHgJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8653879580759317318&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'Rlsq5KDBGHgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://www.icdar2011.org/fileup/PDF/4520b024.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from icdar2011.org</span><span class="gs_ggsS">icdar2011.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6065465" class=yC2>A gradient vector flow-based method for video character segmentation</a></h3><div class="gs_a"><a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>, P Shivakumara, <a href="/citations?user=ymlKC0EAAAAJ&amp;hl=en&amp;oi=sra">B Su</a>&hellip; - Document Analysis and  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose a method based on gradient vector flow for video <br>character segmentation. By formulating character segmentation as a minimum cost path <br>finding problem, the proposed method allows curved segmentation paths and thus it is <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17188779621951853069&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=32">Cited by 7</a> <a href="/scholar?q=related:DdLpAP_Piu4J:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17188779621951853069&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'DdLpAP_Piu4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6065493" class=yC4>A New Fourier-Moments Based Video Word and Character Extraction Method for Recognition</a></h3><div class="gs_a">D Rajendran, P Shivakumara, <a href="/citations?user=ymlKC0EAAAAJ&amp;hl=en&amp;oi=sra">B Su</a>&hellip; - Document Analysis  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents a new method based on Fourier and moments features to <br>extract words and characters from a video text line in any direction for recognition. Unlike <br>existing methods which output the entire text line to the ensuing recognition algorithm, the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17279574887212752174&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=32">Cited by 2</a> <a href="/scholar?q=related:Lp0TDs9hze8J:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17279574887212752174&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'Lp0TDs9hze8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5766755" class=yC5>A Low Complexity Sign Detection and Text Localization Method for Mobile Applications</a></h3><div class="gs_a">KL Bouman, G Abdollahian, M Boutin&hellip; - &hellip; , IEEE Transactions on, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We propose a low complexity method for sign detection and text localization in <br>natural images. This method is designed for mobile applications (eg, unmanned or <br>handheld devices) in which computational and energy resources are limited. No prior <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11501213600771041036&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=32">Cited by 5</a> <a href="/scholar?q=related:DGfZd9WEnJ8J:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11501213600771041036&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'DGfZd9WEnJ8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6065508" class=yC6>Video Script Identification based on Text Lines</a></h3><div class="gs_a"><a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>, P Shivakumara, Z Ding&hellip; - Document Analysis  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present a new method for video script identification which is <br>essential before choosing an appropriate OCR engine for identifying text lines when a video <br>frame contains more than one language. The input for script identification is the text lines <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5791387435508712030&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=32">Cited by 1</a> <a href="/scholar?q=related:XkIoQjAkX1AJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5791387435508712030&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'XkIoQjAkX1AJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6195338" class=yC7>A New Method for Arbitrarily-Oriented Text Detection in Video</a></h3><div class="gs_a"><a href="/citations?user=JzinqNcAAAAJ&amp;hl=en&amp;oi=sra">N Sharma</a>, P Shivakumara, <a href="/citations?user=2_z_CogAAAAJ&amp;hl=en&amp;oi=sra">U Pal</a>&hellip; - &hellip;  (DAS), 2012 10th  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Text detection in video frames plays a vital role in enhancing the performance of <br>information extraction systems because the text in video frames helps in indexing and <br>retrieving video efficiently and accurately. This paper presents a new method for arbitrarily<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9292900039434295505&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=32">Cited by 1</a> <a href="/scholar?q=related:0dixl1kD94AJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9292900039434295505&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'0dixl1kD94AJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6195336" class=yC8>Recent Advances in Video Based Document Processing: A Review</a></h3><div class="gs_a"><a href="/citations?user=JzinqNcAAAAJ&amp;hl=en&amp;oi=sra">N Sharma</a>, <a href="/citations?user=2_z_CogAAAAJ&amp;hl=en&amp;oi=sra">U Pal</a>, M Blumenstein - Document Analysis Systems &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Extraction and recognition of text present in video has become a very popular <br>research area in the last decade. Generally, text present in video frames is of different size, <br>orientation, style, etc. with complex backgrounds, noise, low resolution and contrast. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2870249651013170216&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=32">Cited by 3</a> <a href="/scholar?q=related:KDRUsdks1ScJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2870249651013170216&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'KDRUsdks1ScJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0167865512003042" class=yC9>Scene text detection using graph model built upon maximally stable extremal regions</a></h3><div class="gs_a">C Shi, C Wang, B Xiao, Y Zhang, S Gao - Pattern Recognition Letters, 2012 - Elsevier</div><div class="gs_rs">Scene text detection could be formulated as a bi-label (text and non-text regions) <br>segmentation problem. However, due to the high degree of intraclass variation of scene <br>characters as well as the limited number of training samples, single information source or <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17407688279980496252&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=32">Cited by 1</a> <a onclick="return gs_ocit(event,'fNX3wEKIlPEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6065290" class=yCA>Video Character Recognition through Hierarchical Classification</a></h3><div class="gs_a">P Shivakumara, <a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>, <a href="/citations?user=Fgqq-4kAAAAJ&amp;hl=en&amp;oi=sra">S Lu</a>&hellip; - Document Analysis and  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We present a new video character recognition method based on hierarchical <br>classification. In the first step, we propose a method for character segmentation of the text <br>line detected by the text detection method. The segmentation algorithm uses dynamic <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10234352400990604160&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=32">Cited by 2</a> <a href="/scholar?q=related:gAs250i5B44J:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10234352400990604160&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'gAs250i5B44J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://media.cs.tsinghua.edu.cn/~ahz/papers/final_dot_text_detection.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tsinghua.edu.cn</span><span class="gs_ggsS">tsinghua.edu.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6065349" class=yCB>Dot Text Detection Based on FAST Points</a></h3><div class="gs_a">Y Du, <a href="/citations?user=hhV6J6UAAAAJ&amp;hl=en&amp;oi=sra">H Ai</a>, S Lao - Document Analysis and Recognition ( &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose a method for dot text detection based on FAST points. <br>This problem is different from general scene text detection because of discontinuous text <br>stroke. Unlike many other methods which assume that text is horizontally oriented, our <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:KvNUF8ia64MJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9505861622671143722&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'KvNUF8ia64MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=tm22nivpJi4C&amp;oi=fnd&amp;pg=PA41&amp;ots=Esj4wMdRHN&amp;sig=F2DYsXgx4K_uRwlD7nhilbBftcw" class=yCD>An Application of K-Means Clustering for Improving Video Text Detection</a></h3><div class="gs_a">VNM Aradhya, MS Pavithra - Intelligent Informatics, 2013 - books.google.com</div><div class="gs_rs">Abstract. In the present work, we explore an extensive applications of Gabor filter and K-<br>means clustering algorithm in detection of text in an unconstrained complex background and <br>regular images. The system is a comprehensive of four stages: In the first stage, <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'9jmpKTeMBAoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> A New Gradient based Segmentation Method for Video text Recognition</h3><div class="gs_a">P Shivakumara, S Bhowmick, S Bolan, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a>, <a href="/citations?user=2_z_CogAAAAJ&amp;hl=en&amp;oi=sra">U Pal</a></div><div class="gs_fl"><a href="/scholar?q=related:5EE8L5Ldmk4J:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'5EE8L5Ldmk4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6292505" class=yCE>Text Localization, Extraction and Inpainting in Color Images</a></h3><div class="gs_a">M Khodadadi, A Behrad - ieeexplore.ieee.org</div><div class="gs_rs">Abstract: in this paper, we propose a new algorithm for subtitle text detection, extraction and <br>text inpainting in color images. The proposed algorithm includes three stages. In the first <br>stage, we localize text blocks to extract subtitles. We then extract the text characters <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:3klhNVanwtEJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'3klhNVanwtEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Wavelet and Angle Projection Boundary Growing based Method for Automatic Multi-Oriented Text Detection in Video Frames</h3><div class="gs_a">P Shivakumara, A Dutta, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a>, <a href="/citations?user=2_z_CogAAAAJ&amp;hl=en&amp;oi=sra">U Pal</a></div><div class="gs_fl"><a href="/scholar?q=related:GZ2HQD9f92sJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'GZ2HQD9f92sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://www.stanford.edu/~bgirod/pdfs/Tsai_ACCV2012.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from stanford.edu</span><span class="gs_ggsS">stanford.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.stanford.edu/~bgirod/pdfs/Tsai_ACCV2012.pdf" class=yCF>Design of a Text Detection System via Hypothesis Generation and Verification</a></h3><div class="gs_a"><a href="/citations?user=JdE_LFYAAAAJ&amp;hl=en&amp;oi=sra">SS Tsai</a>, <a href="/citations?user=e2H0s8EAAAAJ&amp;hl=en&amp;oi=sra">V Parameswaran</a>, <a href="/citations?user=kw3AHnIAAAAJ&amp;hl=en&amp;oi=sra">J Berclaz</a>, <a href="/citations?user=Kcf6bqAAAAAJ&amp;hl=en&amp;oi=sra">R Vedantham</a>&hellip; - stanford.edu</div><div class="gs_rs">Abstract. Text-detection is a well-established topic within the document recognition domain, <br>but detecting text in natural scenes has proved to be considerably harder due to the large <br>variability of text appearances, and due to dominating clutter. In this paper, we begin with <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'AMJfRdJcm9QJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md14', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md14" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:AMJfRdJcm9QJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/C5P3364R6NQM7106.pdf" class=yC11>Graph-Based detection of objects with regular regions</a></h3><div class="gs_a">C Shi, C Wang, B Xiao, Y Zhang - Intelligent Robotics and Applications, 2012 - Springer</div><div class="gs_rs">Most objects with regular regions could be detected as Maximally Stable Extremal Regions <br>(MSER)[20]. In this paper, We formulate object detection as a bi-label (object and non-object <br>regions) segmentation problem, and propose a graph-based object detection method <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'9DBWSE3_QfIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6195365" class=yC12>Graph-Based Background Suppression for Scene Text Detection</a></h3><div class="gs_a">C Shi, B Xiao, C Wang, Y Zhang - Document Analysis Systems  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Detecting text in video or natural scene image is quite challenging due to the <br>complex background, various fonts and illumination conditions. The preprocessing period, <br>which suppresses the nontext areas so as to highlight the text areas, is the basis for further <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:8o39UgBup1kJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6460253138157669874&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'8o39UgBup1kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://www.bmva.org/bmvc/2012/BMVC/paper063/paper063.pdf" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from bmva.org</span><span class="gs_ggsS">bmva.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.bmva.org/bmvc/2012/BMVC/paper063/paper063.pdf" class=yC13>Image Text Detection Using a Bandlet-Based Edge Detector and Stroke Width Transform</a></h3><div class="gs_a">A Mosleh, N Bouguila, AB Hamza - bmva.org</div><div class="gs_rs">Abstract In this paper, we propose a text detection method based on a feature vector <br>generated from connected components produced via the stroke width transform. Several <br>properties, such as variant directionality of gradient of text edges, high contrast with <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:dLXZYZAWaeQJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16458711122574947700&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'dLXZYZAWaeQJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md17', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md17" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:dLXZYZAWaeQJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/R623157476U83777.pdf" class=yC15>Text Location for Scene Image with Inherent Features</a></h3><div class="gs_a">Q Sun, Y Lu - Pattern Recognition, 2012 - Springer</div><div class="gs_rs">Locating the text from nature scene images is a challenge problem for computer, because <br>text is various. In this paper, the inherent characteristics of the text are employed to locate <br>the text from complicated background in the scene images. The edge map of the input <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:3qFQaXVJpXwJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'3qFQaXVJpXwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="http://arxiv.org/pdf/1301.2628" class=yC17><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arxiv.org</span><span class="gs_ggsS">arxiv.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://arxiv.org/abs/1301.2628" class=yC16>Robust Text Detection in Natural Scene Images</a></h3><div class="gs_a">XC Yin, X Yin, <a href="/citations?user=3l5B0joAAAAJ&amp;hl=en&amp;oi=sra">K Huang</a> - arXiv preprint arXiv:1301.2628, 2013 - arxiv.org</div><div class="gs_rs">Abstract: Text detection in natural scene images is an important prerequisite for many <br>content-based image analysis tasks. In this paper, we propose an accurate and robust <br>method for detecting texts in natural scene images. A fast and effective pruning algorithm <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'6cQmb_dwpZwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5949833" class=yC18>Strengthen accuracy of feature recognition via integration of ant colony detection and adaptive contour tracking</a></h3><div class="gs_a">Z Ye, H Mohamadian - Evolutionary Computation (CEC), 2011  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Reliable feature recognition is necessary in broad fields of computer vision and <br>image processing. Edges often act as primary artifacts of visual data. Edge detection is to <br>mark sharp changes of the intensity or brightness of digital images. Canny edge detection <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:AyVEkvZ105kJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'AyVEkvZ105kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.worldscientific.com/doi/abs/10.1142/S0218001412550105" class=yC19>MULTI-ORIENTED TEXT DETECTION IN SCENE IMAGES</a></h3><div class="gs_a">M BASAVANNA, P SHIVAKUMARA&hellip; - International Journal of  &hellip; - World Scientific</div><div class="gs_rs">With the increasing use of digital image capturing devices, such as digital cameras, mobile <br>phones, and PDAs, content based image analysis techniques are receiving intensive <br>attention in recent years. Among all the content in images, text information has inspired <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'19J2mYNM2hYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6031864" class=yC1A>Gradient-based video text localization algorithm with statistical analysis of text-like features</a></h3><div class="gs_a">CH Li, YL Huang, SY Chien - Consumer Electronics-Berlin ( &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Video processing techniques in most of the current display systems are performed <br>without considering the text information. The proposed algorithm aims to localize the text <br>regions for video processing. To derive the robust text-like features, a statistical analysis is <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:evAuoXluUWEJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'evAuoXluUWEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/V71273607X676682.pdf" class=yC1B>An Application of K-Means Clustering for Improving Video Text Detection</a></h3><div class="gs_a">VN Manjunath Aradhya, MS Pavithra - Intelligent Informatics - Springer</div><div class="gs_rs">In the present work, we explore an extensive applications of Gabor filter and K-means <br>clustering algorithm in detection of text in an unconstrained complex background and <br>regular images. The system is a comprehensive of four stages: In the first stage, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:F-XOpnFCe1QJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'F-XOpnFCe1QJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB24" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW24"><a href="http://www.comp.nus.edu.sg/~tancl/publications/c2012/DICTA_PID1141978.pdf" class=yC1D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.comp.nus.edu.sg/~tancl/publications/c2012/DICTA_PID1141978.pdf" class=yC1C>A New Method for Word Segmentation from Arbitrarily-Oriented Video Text Lines</a></h3><div class="gs_a"><a href="/citations?user=JzinqNcAAAAJ&amp;hl=en&amp;oi=sra">N Sharma</a>, P Shivakumara, <a href="/citations?user=2_z_CogAAAAJ&amp;hl=en&amp;oi=sra">U Pal</a>, M Blumenstein&hellip; - comp.nus.edu.sg</div><div class="gs_rs">AbstractâWord segmentation has become a research topic to improve OCR accuracy for <br>video text recognition, because a video text line suffers from arbitrary orientation, complex <br>background and low resolution. Therefore, for word segmentation from arbitrarily-oriented <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:hzXzqGHRI5QJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'hzXzqGHRI5QJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md24', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md24" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:hzXzqGHRI5QJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6195331" class=yC1E>New Spatial-Gradient-Features for Video Script Identification</a></h3><div class="gs_a">D Zhao, P Shivakumara, <a href="/citations?user=Fgqq-4kAAAAJ&amp;hl=en&amp;oi=sra">S Lu</a>&hellip; - &hellip;  Analysis Systems (DAS),  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present new features based on Spatial-Gradient-Features (SGF) at <br>block level for identifying six video scripts namely, Arabic, Chinese, English, Japanese, <br>Korean and Tamil. This works helps in enhancing the capability of the current OCR on <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ht1usu_4H2EJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6998586054331522438&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'ht1usu_4H2EJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/6Q587377K6642628.pdf" class=yC1F>A Robust Algorithm for Arabic Video Text Detection</a></h3><div class="gs_a">A Ahmad, A Alqutami, J Atoum - Proceedings of the 2011 2nd International &hellip;, 2012 - Springer</div><div class="gs_rs">In this paper, we propose an efficient Arabic text detection method based on the Laplacian <br>operator in the frequency domain. The zero crossing value is computed for each pixel in the <br>Laplacian-filtered image to found edges in four directions. K-means is then used to <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:PNY12gquFrUJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13048808331986458172&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'PNY12gquFrUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB27" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW27"><a href="http://www.comp.nus.edu.sg/~tancl/publications/c2012/ICPR-TextLocalization-8.docx" class=yC21><span class="gs_ggsL"><span class=gs_ctg2>[DOC]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[DOC]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[DOC]</span><span class="gs_ct2">[DOC]</span></span> <a href="http://www.comp.nus.edu.sg/~tancl/publications/c2012/ICPR-TextLocalization-8.docx" class=yC20>Wavelet-Gradient-Fusion for Video Text Binarization</a></h3><div class="gs_a">S Roy, P Shivakumara, PP Roy, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - comp.nus.edu.sg</div><div class="gs_rs">AbstractâAchieving good character recognition rate in video images is not as easy as <br>achieving the same from the scanned documents because of low resolution and complex <br>background in video images. In this paper, we propose a new method using fusion of <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:IB1v3ToAWhEJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1250312099371883808&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'IB1v3ToAWhEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md27', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md27" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:IB1v3ToAWhEJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB28" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW28"><a href="http://www.comp.nus.edu.sg/~tancl/publications/j2012/PR-RRT-R7.docx" class=yC23><span class="gs_ggsL"><span class=gs_ctg2>[DOC]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[DOC]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S003132031200324X" class=yC22>A Novel Ring Radius Transform for Video Character Reconstruction</a></h3><div class="gs_a">P Shivakumara, <a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>, S Bhowmick, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a>&hellip; - Pattern Recognition, 2012 - Elsevier</div><div class="gs_rs">Character recognition in video is a challenging task because low resolution and complex <br>background of video cause disconnections, loss of information, loss of shapes of the <br>characters etc. In this paper, we introduce a novel ring radius transform (RRT) and the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:wFrf8atNV0YJ:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5068605306521475776&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'wFrf8atNV0YJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB29" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW29"><a href="http://users.loni.ucla.edu/~ztu/publication/cvpr12_textdetection.pdf" class=yC25><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ucla.edu</span><span class="gs_ggsS">ucla.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6247787" class=yC24>Detecting texts of arbitrary orientations in natural images</a></h3><div class="gs_a"><a href="/citations?user=IpmnLFcAAAAJ&amp;hl=en&amp;oi=sra">C Yao</a>, <a href="/citations?user=UeltiQ4AAAAJ&amp;hl=en&amp;oi=sra">X Bai</a>, W Liu, <a href="/citations?user=XqLiBQMAAAAJ&amp;hl=en&amp;oi=sra">Y Ma</a>, <a href="/citations?user=9oz-dvgAAAAJ&amp;hl=en&amp;oi=sra">Z Tu</a> - Computer Vision and Pattern  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract With the increasing popularity of practical vision systems and smart phones, text <br>detection in natural scenes becomes a critical yet challenging task. Most existing methods <br>have focused on detecting horizontal or near-horizontal texts. In this paper, we propose a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4526897363741528163&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=32">Cited by 1</a> <a href="/scholar?q=related:Y1B39CrF0j4J:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4526897363741528163&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'Y1B39CrF0j4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB30" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW30"><a href="http://www.comp.nus.edu.sg/~TANCL/publications/j2012/Shiva-TCSVT12-Bayes-Page.pdf" class=yC27><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6196211" class=yC26>Multioriented Video Scene Text Detection Through Bayesian Classification and Boundary Growing</a></h3><div class="gs_a">P Shivakumara, RP Sreedhar, <a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>&hellip; - Circuits and Systems &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Multioriented text detection in video frames is not as easy as detection of captions <br>or graphics or overlaid texts, which usually appears in the horizontal direction and has high <br>contrast compared to its background. Multioriented text generally refers to scene text that <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9097153869983721236&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=32">Cited by 1</a> <a href="/scholar?q=related:FCdz9z6VP34J:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9097153869983721236&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'FCdz9z6VP34J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB31" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW31"><a href="http://www.airccse.org/journal/ijscai/papers/0812ijscai02.pdf" class=yC29><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from airccse.org</span><span class="gs_ggsS">airccse.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.airccse.org/journal/ijscai/papers/0812ijscai02.pdf" class=yC28>TEXT DETECTION AND EXTRACTION FROM VIDEOS USING ANN BASED NETWORK</a></h3><div class="gs_a">A Thilagavathy, K Aarthi, A Chilambuchelvan - airccse.org</div><div class="gs_rs">ABSTRACT With fast intensification of existing multimedia documents and mounting <br>demand for information indexing and retrieval, much endeavor has been done on extracting <br>the text from images and videos. The prime intention of the projected system is to spot and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:T0f--K9O_28J:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8070255574974875471&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'T0f--K9O_28J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md31', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md31" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:T0f--K9O_28J:scholar.google.com/&amp;hl=en&amp;num=32&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
