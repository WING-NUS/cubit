Total results = 43
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://staging.comp.nus.edu.sg/~tancl/publications/j2004/TKDE_2004_LuY.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1339266" class=yC0>Information retrieval in document image databases</a></h3><div class="gs_a">Y Lu, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - &hellip;  and Data Engineering, IEEE Transactions on, 2004 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract With the rising popularity and importance of document images as an information <br>source, information retrieval in document image databases has become a growing and <br>challenging problem. In this paper, we propose an approach with the capability of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18315018101739793021&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 39</a> <a href="/scholar?q=related:faoMKe0DLP4J:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/50/1F/RN157518999.html?source=googlescholar" class="gs_nph" class=yC2>BL Direct</a> <a href="/scholar?cluster=18315018101739793021&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 33 versions</a> <a onclick="return gs_ocit(event,'faoMKe0DLP4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://www.cvc.uab.es/icdar2009/papers/3725a331.pdf" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uab.es</span><span class="gs_ggsS">uab.es <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5277679" class=yC3>Keyword spotting in document images through word shape coding</a></h3><div class="gs_a">S Bai, L Li, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - &hellip; Analysis and Recognition, 2009. ICDAR&#39;09 &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract With large databases of document images available, a method for users to find <br>keywords in documents will be useful. One approach is to perform Optical Character <br>Recognition (OCR) on each document followed by indexing of the resulting text. However, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5594110284809541287&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 15</a> <a href="/scholar?q=related:p5ZuSKpFok0J:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5594110284809541287&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 20 versions</a> <a onclick="return gs_ocit(event,'p5ZuSKpFok0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www.tuat.jp/~nakagawa/pub/2009/pdf/ChengCheng_ICDAR200907.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tuat.jp</span><span class="gs_ggsS">tuat.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5277533" class=yC5>Improvements in keyword search japanese characters within handwritten digital ink</a></h3><div class="gs_a">C Cheng, B Zhu, X Chen&hellip; - Document Analysis and  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents a revised method for keyword search from handwritten digital <br>ink in comparison with the previous system. We adopt a search method using noise <br>reduction. Experiments on digital ink databases show that the revised method typically <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10040427822334487899&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 7</a> <a href="/scholar?q=related:Wy0yb-jDVosJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10040427822334487899&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'Wy0yb-jDVosJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/81l6v663305v4670.pdf" class=yC7>A survey of keyword spotting techniques for printed document images</a></h3><div class="gs_a">A Murugappan, B Ramachandran&hellip; - Artificial Intelligence  &hellip;, 2011 - Springer</div><div class="gs_rs">Abstract This paper attempts to provide a survey of the past researches on character based <br>as keyword based approaches used for retrieving information from document images. This <br>survey also provides insights into the strengths and weaknesses of current techniques, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4152659816115326052&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 6</a> <a href="/scholar?q=related:ZMyX3Bk2oTkJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4152659816115326052&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'ZMyX3Bk2oTkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://sites.google.com/site/zgfanfan/DocumentImageRetrievalwithLocalFeatu.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from google.com</span><span class="gs_ggsS">google.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5277676" class=yC8>Document image retrieval with local feature sequences</a></h3><div class="gs_a">J Li, ZG Fan, Y Wu, N Le - Document Analysis and Recognition &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In recent years, many document image retrieval algorithms have been proposed. <br>However, most of the current approaches either need good quality images or depend on the <br>page layout structure. This paper presents a fast, accurate and OCR-free image retrieval <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15593739359372885471&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 6</a> <a href="/scholar?q=related:371yA1QXaNgJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15593739359372885471&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'371yA1QXaNgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="https://posgrado.escom.ipn.mx/biblioteca/Text%20retrieval%20from%20early%20printed%20books.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ipn.mx</span><span class="gs_ggsS">ipn.mx <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/A855GL8845800346.pdf" class=yCA>Text retrieval from early printed books</a></h3><div class="gs_a">S Marinai - International journal on document analysis and  &hellip;, 2011 - Springer</div><div class="gs_rs">Abstract Retrieving text from early printed books is particularly difficult because in these <br>documents, the words are very close one to the other and, similarly to medieval manuscripts, <br>there is a large use of ligatures and abbreviations. To address these problems, we <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2897344057422586629&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 4</a> <a href="/scholar?q=related:BSPDxhFvNSgJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2897344057422586629&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'BSPDxhFvNSgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.184.7135&amp;rep=rep1&amp;type=pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.184.7135&amp;rep=rep1&amp;type=pdf" class=yCC>Document Image Retrieval: An Overview</a></h3><div class="gs_a"><a href="/citations?user=L5vYHPkAAAAJ&amp;hl=en&amp;oi=sra">MB Kokare</a>, MS Shirdhonkar - International Journal of Computer  &hellip;, 2010 - Citeseer</div><div class="gs_rs">ABSTRACT The economic feasibility of creating a large database of document image has <br>left a tremendous need for robust ways to access the information. Printed documents are <br>scanned for archiving or in an attempt to move towards a paperless office and are stored <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1340064328863007046&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 4</a> <a href="/scholar?q=related:RkENOmjdmBIJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1340064328863007046&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'RkENOmjdmBIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md6', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md6" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:RkENOmjdmBIJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://oaj.unsri.ac.id/files/wwwijcaonline/journal/number7/pxc387274.pdf" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unsri.ac.id</span><span class="gs_ggsS">unsri.ac.id <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Document Image Retrieval: An Overview</h3><div class="gs_a">MS Shirdhonkar, <a href="/citations?user=L5vYHPkAAAAJ&amp;hl=en&amp;oi=sra">MB Kokare</a> - International  &hellip;, 2010 - Foundation of Computer Science  &hellip;</div><div class="gs_fl"><a href="/scholar?cites=4818304879540611727&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 3</a> <a href="/scholar?q=related:j6qMbMIO3kIJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4818304879540611727&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'j6qMbMIO3kIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://www.lmt.ei.tum.de/forschung/publikationen/dateien/Schroth2011Exploitingtext-relatedfeaturesfor.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tum.de</span><span class="gs_ggsS">tum.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6123328" class=yCF>Exploiting text-related features for content-based image retrieval</a></h3><div class="gs_a"><a href="/citations?user=OrgfKhAAAAAJ&amp;hl=en&amp;oi=sra">G Schroth</a>, <a href="/citations?user=TenY_v0AAAAJ&amp;hl=en&amp;oi=sra">S Hilsenbeck</a>, <a href="/citations?user=_vdEqpwAAAAJ&amp;hl=en&amp;oi=sra">R Huitl</a>&hellip; - &hellip;  (ISM), 2011 IEEE  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Distinctive visual cues are of central importance for image retrieval applications, in <br>particular, in the context of visual location recognition. While in indoor environments typically <br>only few distinctive features can be found, outdoors dynamic objects and clutter <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2198795633221897273&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 4</a> <a href="/scholar?q=related:OQzfi_qwgx4J:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2198795633221897273&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'OQzfi_qwgx4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://icpr2010.org/pdfs/icpr2010_TuBCT9.35.pdf" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from icpr2010.org</span><span class="gs_ggsS">icpr2010.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5597262" class=yC11>Shape code based word-image matching for retrieval of Indian multi-lingual documents</a></h3><div class="gs_a">A Tarafdar, <a href="/citations?user=QMmbyQkAAAAJ&amp;hl=en&amp;oi=sra">R Mondal</a>, S Pal, <a href="/citations?user=2_z_CogAAAAJ&amp;hl=en&amp;oi=sra">U Pal</a>&hellip; - &hellip;  (ICPR), 2010 20th  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In the current scenario retrieving information from document images is a <br>challenging problem. In this paper we propose a shape code based word-image matching <br>(word-spotting) technique for retrieval of multilingual documents written in Indian <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16001967394304733812&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 2</a> <a href="/scholar?q=related:dLLqJJBoEt4J:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16001967394304733812&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'dLLqJJBoEt4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://dejanseo.com.au/research/google/37297.pdf" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from dejanseo.com.au</span><span class="gs_ggsS">dejanseo.com.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/D777W63674UX3R7Q.pdf" class=yC13>Discrete point based signatures and applications to document matching</a></h3><div class="gs_a">N Spasojevic, G Poncin, D Bloomberg - Image Analysis and Processingâ &hellip;, 2011 - Springer</div><div class="gs_rs">Document analysis often starts with robust signatures, for instance for document lookup from <br>low-quality photographs, or similarity analysis between scanned books. Signatures based <br>on OCR typically work well, but require good quality OCR, which is not always available <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15056960776992402576&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 3</a> <a href="/scholar?q=related:kCyfLQ0S9dAJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15056960776992402576&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'kCyfLQ0S9dAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://www.icdar2011.org/fileup/PDF/4520a678.pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from icdar2011.org</span><span class="gs_ggsS">icdar2011.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6065397" class=yC15>Word retrieval in historical document using character-primitives</a></h3><div class="gs_a">PP Roy, <a href="/citations?user=Id00xlIAAAAJ&amp;hl=en&amp;oi=sra">J Ramel</a>, N Ragot - Document Analysis and  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Word searching and indexing in historical document collections is a challenging <br>problem because, characters in these documents are often touching or broken due to <br>degradation/ageing effects. For efficient searching in such historical documents, this paper <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3602358528909654966&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 3</a> <a href="/scholar?q=related:tjtC9f4l_jEJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3602358528909654966&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'tjtC9f4l_jEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/0M1248728R303075.pdf" class=yC17>Digital Libraries and Document Image Retrieval Techniques: A Survey</a></h3><div class="gs_a">S Marinai, B Miotti, G Soda - Learning Structure and Schemas from  &hellip;, 2011 - Springer</div><div class="gs_rs">Nowadays, Digital Libraries have become a widely used service to store and share both <br>digital born documents and digital versions of works stored by traditional libraries. Document <br>images are intrinsically non-structured and the structure and semantic of the digitized <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11584587757996533051&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 1</a> <a href="/scholar?q=related:O-W4KDC5xKAJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11584587757996533051&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'O-W4KDC5xKAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/WV066034QQ01L263.pdf" class=yC18>Mathematical symbol indexing for digital libraries</a></h3><div class="gs_a">S Marinai, B Miotti, G Soda - Digital Libraries, 2010 - Springer</div><div class="gs_rs">In this paper we describe our recent research for mathematical symbol indexing and its <br>possible application in the Digital Library domain. The proposed approach represents <br>mathematical symbols by means of Shape Contexts (SC) description. Indexed symbols <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16678339709376805939&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 1</a> <a href="/scholar?q=related:MzyynJlddecJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16678339709376805939&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'MzyynJlddecJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://www.icdar2011.org/fileup/PDF/4520a683.pdf" class=yC1A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from icdar2011.org</span><span class="gs_ggsS">icdar2011.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6065398" class=yC19>An On-line Handwritten Text Search Method based on Directional Feature Matching</a></h3><div class="gs_a">P Luangvilay, B Zhu&hellip; - Document Analysis and  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we describe a method of retrieving on-line handwritten text based on <br>directional feature matching. Although text search into the character recognition candidate <br>lattice has been elaborated, the character recognition based approach does not support <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5402852292713956299&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 1</a> <a href="/scholar?q=related:y8Me4YjJ-koJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5402852292713956299&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'y8Me4YjJ-koJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://www.icdar2011.org/fileup/PDF/4520b200.pdf" class=yC1C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from icdar2011.org</span><span class="gs_ggsS">icdar2011.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6065500" class=yC1B>Document Image Indexing Using Edit Distance Based Hashing</a></h3><div class="gs_a">E Hassan, S Chaudhury&hellip; - Document Analysis and  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We present a novel word image based document indexing scheme by combination <br>of string matching and hashing. The word image representation is defined by string codes <br>obtained by unsupervised learning over graphical primitives. The indexing framework is <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:2XyPC70zjd8J:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16108588329209920729&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'2XyPC70zjd8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://etd.aau.edu.et/dspace/bitstream/123456789/3516/1/final%20edited1.pdf" class=yC1E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aau.edu.et</span><span class="gs_ggsS">aau.edu.et <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://etd.aau.edu.et/dspace/handle/123456789/3516" class=yC1D>FEATURE EXTRACTION AND MATCHING IN AMHARIC DOCUMENT IMAGE COLLECTIONS</a></h3><div class="gs_a">L ADANE - 2011 - etd.aau.edu.et</div><div class="gs_rs">Abstract: The ubiquity of digital computers and the boom of the Internet and World Wide Web <br>resulted in massive information explosion over the entire world. Different types of information <br>are uploaded in the Internet such as text documents, document images and other <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:3s5jD0QyDXEJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'3s5jD0QyDXEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://refbase.cvc.uab.es/files/DLP2012.pdf" class=yC20><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uab.es</span><span class="gs_ggsS">uab.es <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320312004359" class=yC1F>A symbol spotting approach in graphical documents by hashing serialized graphs</a></h3><div class="gs_a">A Dutta, <a href="/citations?user=92pWl-AAAAAJ&amp;hl=en&amp;oi=sra">J LladÃ³s</a>, <a href="/citations?user=2_z_CogAAAAJ&amp;hl=en&amp;oi=sra">U Pal</a> - Pattern Recognition, 2012 - Elsevier</div><div class="gs_rs">In this paper we propose a symbol spotting technique in graphical documents. Graphs are <br>used to represent the documents and a (sub) graph matching technique is used to detect the <br>symbols in them. We propose a graph serialization to reduce the usual computational <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'2ikpFVMJhKUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6195353" class=yC21>An efficient coarse-to-fine indexing technique for fast text retrieval in historical documents</a></h3><div class="gs_a">PP Roy, F Rayar, <a href="/citations?user=Id00xlIAAAAJ&amp;hl=en&amp;oi=sra">JY Ramel</a> - Document Analysis Systems ( &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present a fast text retrieval system to index and browse degraded <br>historical documents. The indexing and retrieval strategy is designed in a two level, coarse-<br>to-fine approach, to increase the speed of the retrieval process. During the indexing step, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17675416227519989303&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 1</a> <a href="/scholar?q=related:NwaBGmmxS_UJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17675416227519989303&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'NwaBGmmxS_UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="http://www.nailed-barnacle.co.uk/ocr/Dissertation.pdf" class=yC23><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nailed-barnacle.co.uk</span><span class="gs_ggsS">nailed-barnacle.co.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.nailed-barnacle.co.uk/ocr/Dissertation.pdf" class=yC22>The Text Contains its Own Lexicon: Extracting a Spelling Reference in the Presence of OCR Errors.</a></h3><div class="gs_a">DN Barnes - 2011 - nailed-barnacle.co.uk</div><div class="gs_rs">Page 1. The Text Contains its Own Lexicon: Extracting a Spelling Reference in the Presence<br>of OCR Errors. A dissertation submitted in partial fullfillment of the requirements for the Open<br>University&#39;s Master of Science Degree in Computing for Commerce and Industry By <b>...</b> </div><div class="gs_fl"><a href="/scholar?q=related:AgLSICkB57wJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'AgLSICkB57wJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md19', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md19" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:AgLSICkB57wJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6075200" class=yC24>Document image retrieval using signature as query</a></h3><div class="gs_a">MS Shirdhonkar, <a href="/citations?user=L5vYHPkAAAAJ&amp;hl=en&amp;oi=sra">MB Kokare</a> - Computer and Communication  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we presents a new approach to document image retrieval based on <br>signature. The database contains document images with English text combined with <br>headlines, ruling lines, logo, trade mark and signature. In searching a repository of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12882107587570054518&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 1</a> <a href="/scholar?q=related:djV6O5lwxrIJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'djV6O5lwxrIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5659448" class=yC25>Image Feature Based Method for Mail Retrieval</a></h3><div class="gs_a">Y Du, Y Lu - Pattern Recognition (CCPR), 2010 Chinese  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract A mail retrieval method based on image feature is an innovative approach by which <br>the postal department can realize the query of mail information. The paper chooses <br>envelope images with handwritten address characters as retrieval object. Through a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:OwF5PkDoDCQJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'OwF5PkDoDCQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB22" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW22"><a href="http://unibz.it/en/public/universitypress/publications/all/Documents/9788860460301.pdf#page=54" class=yC27><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unibz.it</span><span class="gs_ggsS">unibz.it <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://unibz.it/en/public/universitypress/publications/all/Documents/9788860460301.pdf#page=54" class=yC26>Tools for Document Image Retrieval in Digital Libraries: the AIDI System</a></h3><div class="gs_a">S Marinai, G Soda - Workshop on Advanced Technologies for Digital  &hellip;, 2009 - unibz.it</div><div class="gs_rs">In the last few years, Digital Libraries became one important application area for Document <br>Image Analysis and Recognition research [1]. In this field, a relevant line of research is <br>Document Image Retrieval (DIR) that aims at finding relevant documents relying on image <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:yOMQSS4ND9cJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15496619335250666440&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 17 versions</a> <a onclick="return gs_ocit(event,'yOMQSS4ND9cJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md22', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md22" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:yOMQSS4ND9cJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB23" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW23"><a href="http://www.tuat.jp/~nakagawa/pub/2010/pdf/Pasitthideth_CJKPR2010.pdf" class=yC29><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tuat.jp</span><span class="gs_ggsS">tuat.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.tuat.jp/~nakagawa/pub/2010/pdf/Pasitthideth_CJKPR2010.pdf" class=yC28>Text Search from Handwritten Digital Ink Using Directional Features</a></h3><div class="gs_a">P Luangvilay, B Zhu, M Nakagawa - tuat.jp</div><div class="gs_rs">Abstract This paper describes a method of retrieving handwritten text using directional <br>features. Text search from handwritten digital ink employing character recognition <br>technology has been developed. However, the character recognition based approach <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:fNphX1dCR54J:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11405157524368906876&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'fNphX1dCR54J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md23', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md23" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:fNphX1dCR54J:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6195369" class=yC2A>Effect of Text/Non-text Classification for Ink Search Employing String Recognition</a></h3><div class="gs_a">T Matsushita, C Cheng, Y Murata, B Zhu&hellip; - &hellip;  (DAS), 2012 10th  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents the effect of text/non-text classification for ink search which <br>employs string recognition. Pen or touch interfaces provides the benefit that users can write <br>text and draw figures without changing the device or mode, but line drawings are <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1946764662581962939&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 1</a> <a href="/scholar?q=related:uyh7biVMBBsJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1946764662581962939&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'uyh7biVMBBsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB25" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW25"><a href="http://www.waprogramming.com/papers/vol2-no5/(308-314)%20Content%20Based%20Document%20Image%20Retrieval%20with%20Support%20Vectors%20Clustering.pdf" class=yC2C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from waprogramming.com</span><span class="gs_ggsS">waprogramming.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.waprogramming.com/papers/vol2-no5/(308-314)%20Content%20Based%20Document%20Image%20Retrieval%20with%20Support%20Vectors%20Clustering.pdf" class=yC2B>Content Based Document Image Retrieval with Support Vectors Clustering</a></h3><div class="gs_a">M Habibi, R Azmi - 2011 - waprogramming.com</div><div class="gs_rs">Abstract: The goal of this paper is representing a suitable approach to content based <br>document image retrieval. in proposed algorithm a feature vector is extracted with wavelet <br>transform for sub-words. then based on this features, sub-words are clustered with support <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:FOBXeposYzkJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4135197924845412372&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'FOBXeposYzkJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md25', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md25" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:FOBXeposYzkJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB26" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW26"><a href="http://www.stanford.edu/~dmchen/documents/ISM2012_VisualTextFeatures.pdf" class=yC2E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from stanford.edu</span><span class="gs_ggsS">stanford.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.stanford.edu/~dmchen/documents/ISM2012_VisualTextFeatures.pdf" class=yC2D>Visual Text Features for Image Matching</a></h3><div class="gs_a"><a href="/citations?user=JdE_LFYAAAAJ&amp;hl=en&amp;oi=sra">SS Tsai</a>, <a href="/citations?user=WghqyVMAAAAJ&amp;hl=en&amp;oi=sra">H Chen</a>, <a href="/citations?user=VatsnGUAAAAJ&amp;hl=en&amp;oi=sra">D Chen</a>, <a href="/citations?user=e2H0s8EAAAAJ&amp;hl=en&amp;oi=sra">V Parameswaran</a>&hellip; - stanford.edu</div><div class="gs_rs">AbstractâWe present a new class of visual text features that are based on text in <br>cameraphone images. A robust text detection algorithm locates individual text lines and <br>feeds them to a recognition engine. From the recognized characters, we generate the <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'aWhPfWPDWFUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md26', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md26" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:aWhPfWPDWFUJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB27" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW27"><a href="http://www.icdar2011.org/fileup/PDF/4520a789.pdf" class=yC30><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from icdar2011.org</span><span class="gs_ggsS">icdar2011.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6065419" class=yC2F>Chinese Keyword Spotting Using Knowledge-Based Clustering</a></h3><div class="gs_a">Y Xia, K Wang, M Li - Document Analysis and Recognition ( &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Content-based document image retrieval is a new and promising research area. <br>Without OCR, document indexing directly based on image content is more general and <br>convenient. However content-based Chinese document retrieval is difficult for the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:4JGphFFD3c0J:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14834086765025399264&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'4JGphFFD3c0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6233763" class=yC31>Chinese document image retrieval based on recognition candidates</a></h3><div class="gs_a">X Jia, Y Xia, R Zhou, H Liang - Fuzzy Systems and Knowledge  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract For the sake of the low recognition rate for degraded Chinese document, the <br>retrieval performance is not good if directly based on OCR result. In this paper, an indexing <br>method with n-gram and recognition candidates is proposed to improve the performance <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:2HVIkKT416oJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'2HVIkKT416oJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6223602" class=yC32>Retrieval of degraded Chinese document based on fuzzy coding strategy</a></h3><div class="gs_a">X Yong, J Xu-Hui, W Kuan-Quan - Systems and Informatics ( &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract For the sake of the low recognition rate for degraded Chinese document, the <br>performance of retrieval is not good if directly based on OCR result. This paper presents a <br>new way to improve the performance of retrieval by fuzzy coding strategy. Lots of <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:QJhpleDcsEoJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'QJhpleDcsEoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.google.com/patents?hl=en&amp;lr=&amp;vid=USPAT8151186&amp;id=ANwLAgAAEBAJ&amp;oi=fnd&amp;printsec=abstract" class=yC33>Comparing text pages using image features based on word positions</a></h3><div class="gs_a">NL Spasojevic, G Poncin, DS Bloomberg - US Patent 8,151,186, 2012 - Google Patents</div><div class="gs_rs">A signature for a page of text is generated. The signature serves as an identifier of the text <br>page. Positions of words in a text page are determined. Positions of multiple second words <br>in the text page are determined relative to the position of a first word in the text page. A <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:8_NOlqnh924J:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7996107781907084275&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'8_NOlqnh924J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/658QL40574874006.pdf" class=yC34>Word shape descriptor-based document image indexing: a new DBH-based approach</a></h3><div class="gs_a">E Hassan, S Chaudhury, M Gopal - International Journal on Document  &hellip;, 2012 - Springer</div><div class="gs_rs">Abstract In this paper, we propose a novel feature representation for binary patterns by <br>exploiting the object shape information. Initial evaluation of the representation is performed <br>for Bengali and Gujarati script character classification. The extension of the representation <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10020897361449113578&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=43">Cited by 1</a> <a href="/scholar?q=related:6tfSpw5hEYsJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'6tfSpw5hEYsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB32" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW32"><a href="http://arxiv.org/pdf/1206.1291" class=yC36><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arxiv.org</span><span class="gs_ggsS">arxiv.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://arxiv.org/abs/1206.1291" class=yC35>Feature Weighting for Improving Document Image Retrieval System Performance</a></h3><div class="gs_a">M Keyvanpour, R Tavoli - arXiv preprint arXiv:1206.1291, 2012 - arxiv.org</div><div class="gs_rs">Abstract: Feature weighting is a technique used to approximate the optimal degree of <br>influence of individual features. This paper presents a feature weighting method for <br>Document Image Retrieval System (DIRS) based on keyword spotting. In this method, we <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:kseZuKEYxswJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14755508311991895954&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'kseZuKEYxswJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:367"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB33" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW33"><a href="http://www.dsi.unifi.it/~simone/Papers/CHAP_DIAR.pdf" class=yC38><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unifi.it</span><span class="gs_ggsS">unifi.it <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.dsi.unifi.it/~simone/Papers/CHAP_DIAR.pdf" class=yC37>Digital Libraries and Document Image Analysis Techniques: a Survey</a></h3><div class="gs_a">S Marinai, B Miotti, G Soda - dsi.unifi.it</div><div class="gs_rs">Abstract Nowadays, Digital Libraries have become a widely used service to store and share <br>both digital born documents and digital versions of works stored by traditional libraries. <br>Document images are intrinsically non-structured and the structure and semantic of the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:lafmvprbpaIJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'lafmvprbpaIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md33', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md33" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:lafmvprbpaIJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:366"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB34" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW34"><a href="http://ijcsi.org/papers/IJCSI-8-5-1-166-172.pdf" class=yC3A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ijcsi.org</span><span class="gs_ggsS">ijcsi.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.doaj.org/doaj?func=abstract&amp;id=893554" class=yC39>Farsi/Arabic Document Image Retrieval through Sub-Letter Shape Coding for mixed Farsi/Arabic and English text</a></h3><div class="gs_a">Z Bahmani, R Azmi - International Journal of Computer Science - doaj.org</div><div class="gs_rs">Abstract: A retrieval method for explicit recognition free Farsi/Arabic document is proposed in <br>this paper. The system can be used in mixed Farsi/Arabic and English text. The method <br>consists of Preprocessing, word and sub_word extraction, detection and cancelation of <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:3P_9yyNDPqwJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12411431444105002972&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'3P_9yyNDPqwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md34', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md34" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:3P_9yyNDPqwJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:365"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6166372" class=yC3B>Feature Combination in Kernel Space for Distance Based Image Hashing</a></h3><div class="gs_a">E Hassan, S Chaudhury&hellip; - &hellip; , IEEE Transactions on, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The paper presents a novel feature based indexing scheme for image collections. <br>The scheme presents the extension of distance based hashing to kernel space for <br>generating the indexing structure based on similarity in kernel space. The objective of the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:vHGVzgsUFOIJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16290667793049022908&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'vHGVzgsUFOIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:364"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.google.com/patents?hl=en&amp;lr=&amp;vid=USPAT8151187&amp;id=AdwLAgAAEBAJ&amp;oi=fnd&amp;printsec=abstract" class=yC3C>Comparing text pages using image features based on word positions</a></h3><div class="gs_a">NL Spasojevic, G Poncin, DS Bloomberg - US Patent 8,151,187, 2012 - Google Patents</div><div class="gs_rs">A signature for a page of text is generated. The signature serves as an identifier of the text <br>page. Positions of words in a text page are determined. Positions of multiple second words <br>in the text page are determined relative to the position of a first word in the text page. A <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:XFQJ4wsvLJEJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10460787762575004764&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'XFQJ4wsvLJEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:363"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB37" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW37"><a href="http://www.tuat.jp/~nakagawa/pub/2009/pdf/ChengCheng_CJKPR200911.pdf" class=yC3E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tuat.jp</span><span class="gs_ggsS">tuat.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5343975" class=yC3D>Ink Search Employing Japanese String Recognition</a></h3><div class="gs_a">C Cheng, B Zhu, M Nakagawa - Pattern Recognition, 2009.  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents a revised method for keyword search from Japanese <br>handwritten digital ink. We employ Japanese string recognition and produce a candidate <br>lattice. We search for a given keyword into the lattice so that we can search for the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:LwKL51TB8mQJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7274088918562832943&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'LwKL51TB8mQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:362"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB38" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW38"><a href="http://arxiv.org/pdf/1209.2274" class=yC40><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arxiv.org</span><span class="gs_ggsS">arxiv.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://arxiv.org/abs/1209.2274" class=yC3F>PCA-Based Relevance Feedback in Document Image Retrieval</a></h3><div class="gs_a">R Tavoli, F Mahmoudi - arXiv preprint arXiv:1209.2274, 2012 - arxiv.org</div><div class="gs_rs">Abstract: Research has been devoted in the past few years to relevance feedback as an <br>effective solution to improve performance of information retrieval systems. Relevance <br>feedback refers to an interactive process that helps to improve the retrieval performance. <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ebVF62a3zVIJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5966626733997536633&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'ebVF62a3zVIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:361"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB39" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW39"><a href="http://gradvibot.u-bourgogne.fr/thesis2011/9.UmerIftikhar-Ligature-Recognition.pdf" class=yC42><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from u-bourgogne.fr</span><span class="gs_ggsS">u-bourgogne.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://gradvibot.u-bourgogne.fr/thesis2011/9.UmerIftikhar-Ligature-Recognition.pdf" class=yC41>VIBOT Consortium</a></h3><div class="gs_a">U Iftikhar - gradvibot.u-bourgogne.fr</div><div class="gs_rs">Abstract Optical Character Recognition (OCR) is the process of converting a scanned <br>document image into an editable electronic representation. OCR is a major research field in <br>artificial intelligence. Decades of research in OCR has led to development of several <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:eW6J9dg2ZwcJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=533455386326953593&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'eW6J9dg2ZwcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md39', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md39" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:eW6J9dg2ZwcJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:360"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5658616" class=yC43>Keyword spotting in degraded document using mixed OCR and word shape coding</a></h3><div class="gs_a">Y Xia, G Quan, Y Xu, Y Sun - Intelligent Computing and  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents a new way for keyword spotting in degraded imaged <br>document. Two prevalent word indexing, OCR and word shape coding, are combined <br>compactly based on the recognition confidence evaluation. The basic procedures are as <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:UenR-dZTjzAJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'UenR-dZTjzAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:359"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Handwriting Recognition and Fast Retrieval for Hebrew Historical Manuscripts</h3><div class="gs_a">S Armon - 2011</div><div class="gs_fl"><a href="/scholar?q=related:8n6XEy7CwB0J:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'8n6XEy7CwB0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:358"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB42" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW42"><a href="http://frederic.rayar.free.fr/data/papers/CIFED2012%20-%20F.RAYAR%20-%20Paper.pdf" class=yC45><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from free.fr</span><span class="gs_ggsS">free.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://frederic.rayar.free.fr/data/papers/CIFED2012%20-%20F.RAYAR%20-%20Paper.pdf" class=yC44>Approche multi-niveaux pour la recherche de texte par l&#39;exemple dans les images de documents historiques</a></h3><div class="gs_a">FRPP RoyâJean, Y Ramel - frederic.rayar.free.fr</div><div class="gs_rs">RÃSUMÃ. Dans cet article, nous prÃ©sentons un systÃ¨me d&#39;indexation et de recherche par <br>l&#39;exemple dans les documents, adaptÃ© aux images de documents historiques dÃ©gradÃ©s. Les <br>textes prÃ©sents dans les documents sont encodÃ©s en sÃ©quences de primitives, provenant <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'HPoboiSeCIEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md42', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md42" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:HPoboiSeCIEJ:scholar.google.com/&amp;hl=en&amp;num=43&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
