Total results = 79
<div class="gs_r" style="z-index:400"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320305001251" class=yC0>A novel adaptive morphological approach for degraded character image segmentation</a></h3><div class="gs_a">S Nomura, K Yamanaka, O Katai, H Kawakami&hellip; - Pattern Recognition, 2005 - Elsevier</div><div class="gs_rs">This work proposes a novel adaptive approach for character segmentation and feature <br>vector extraction from seriously degraded images. An algorithm based on the histogram <br>automatically detects fragments and merges these fragments before segmenting the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16302261817994729971&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 62</a> <a href="/scholar?q=related:81n9GMBEPeIJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16302261817994729971&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'81n9GMBEPeIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="ftp://ftp.idiap.ch/pub/reports/2004/rr04-03.pdf" class=yC2><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from idiap.ch</span><span class="gs_ggsS">idiap.ch <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1524982" class=yC1>Noisy text categorization</a></h3><div class="gs_a"><a href="/citations?user=XOnfkHIAAAAJ&amp;hl=en&amp;oi=sra">A Vinciarelli</a> - Pattern Analysis and Machine Intelligence, IEEE  &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This work presents categorization experiments performed over noisy texts. By noisy, <br>we mean any text obtained through an extraction process (affected by errors) from media <br>other than digital texts (eg, transcriptions of speech recordings extracted with a recognition <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15519178137776715898&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 42</a> <a href="/scholar?q=related:engwzEoyX9cJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/51/50/RN179891437.html?source=googlescholar" class="gs_nph" class=yC3>BL Direct</a> <a href="/scholar?cluster=15519178137776715898&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 29 versions</a> <a onclick="return gs_ocit(event,'engwzEoyX9cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www.comp.nus.edu.sg/~tancl/publications/j2008/document%20annotation%20and%20retrieval%20(final%20manuscript).pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4492785" class=yC4>Document image retrieval through word shape coding</a></h3><div class="gs_a"><a href="/citations?user=Fgqq-4kAAAAJ&amp;hl=en&amp;oi=sra">S Lu</a>, L Li, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - Pattern Analysis and Machine Intelligence,  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents a document retrieval technique that is capable of searching <br>document images without optical character recognition (OCR). The proposed technique <br>retrieves document images by a new word shape coding scheme, which captures the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15535907822021277121&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 43</a> <a href="/scholar?q=related:wXXK8tmhmtcJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15535907822021277121&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'wXXK8tmhmtcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://staging.comp.nus.edu.sg/~tancl/publications/j2004/TKDE_2004_LuY.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1339266" class=yC6>Information retrieval in document image databases</a></h3><div class="gs_a">Y Lu, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - &hellip;  and Data Engineering, IEEE Transactions on, 2004 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract With the rising popularity and importance of document images as an information <br>source, information retrieval in document image databases has become a growing and <br>challenging problem. In this paper, we propose an approach with the capability of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18315018101739793021&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 39</a> <a href="/scholar?q=related:faoMKe0DLP4J:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/50/1F/RN157518999.html?source=googlescholar" class="gs_nph" class=yC8>BL Direct</a> <a href="/scholar?cluster=18315018101739793021&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 33 versions</a> <a onclick="return gs_ocit(event,'faoMKe0DLP4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://webloria.loria.fr/~tombre/icdar03-tombre.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from loria.fr</span><span class="gs_ggsS">loria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1227650" class=yC9>Graphics recognition-from re-engineering to retrieval</a></h3><div class="gs_a">K Tombre, <a href="/citations?user=aFZTrIEAAAAJ&amp;hl=en&amp;oi=sra">B Lamiroy</a> - Document Analysis and Recognition,  &hellip;, 2003 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we discuss how the focus in document analysis in graphics <br>recognition has moved from re-engineering problems to indexing and information retrieval. <br>After a few reviews of ongoing work on these topics, we propose some challenges for the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7951381707870458426&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 34</a> <a href="/scholar?q=related:OlIo-4j7WG4J:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7951381707870458426&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 20 versions</a> <a onclick="return gs_ocit(event,'OlIo-4j7WG4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1642655" class=yCB>Font adaptive word indexing of modern printed documents</a></h3><div class="gs_a">S Marinai, E Marino, G Soda - Pattern Analysis and Machine  &hellip;, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We propose an approach for the word-level indexing of modern printed documents <br>which are difficult to recognize using current OCR engines. By means of word-level <br>indexing, it is possible to retrieve the position of words in a document, enabling queries <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14725324179830551457&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 33</a> <a href="/scholar?q=related:oTNFzVLcWswJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/10/3B/RN196221394.html?source=googlescholar" class="gs_nph" class=yCC>BL Direct</a> <a href="/scholar?cluster=14725324179830551457&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'oTNFzVLcWswJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://staging.comp.nus.edu.sg/~tancl/publications/c2008/Shiva_Huang.pdf" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4669975" class=yCD>An efficient edge based technique for text detection in video frames</a></h3><div class="gs_a">P Shivakumara, W Huang&hellip; - &hellip;  Analysis Systems, 2008.  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Both graphic text and scene text detection in video images with complex <br>background and low resolution is still a challenging and interesting problem for researchers <br>in the field of image processing and computer vision. In this paper, we present a novel <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8855755282162914531&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 36</a> <a href="/scholar?q=related:4xQcY4L25XoJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8855755282162914531&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'4xQcY4L25XoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://www.dsi.unifi.it/~simone/Papers/ICDAR03a.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unifi.it</span><span class="gs_ggsS">unifi.it <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1227663" class=yCF>Indexing and retrieval of words in old documents</a></h3><div class="gs_a">S Marinai, E Marino, G Soda - Document Analysis and  &hellip;, 2003 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper describes a system for efficient indexing and retrieval of words in <br>collections of document images. The proposed method is based on two main principles: <br>unsupervised prototype clustering, and string encoding for efficient string matching. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14913525470838747041&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 31</a> <a href="/scholar?q=related:oW8VhmZ8984J:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14913525470838747041&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'oW8VhmZ8984J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4359308" class=yC11>Script and language identification in noisy and degraded document images</a></h3><div class="gs_a"><a href="/citations?user=Fgqq-4kAAAAJ&amp;hl=en&amp;oi=sra">L Shijian</a>, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - Pattern Analysis and Machine Intelligence,  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper reports an identification technique that detects scripts and languages of <br>noisy and degraded document images. In the proposed technique, scripts and languages <br>are identified through the document vectorization, which converts each document image <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1557928597142664402&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 28</a> <a href="/scholar?q=related:0nQcCs7fnhUJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/49/15/RN222908228.html?source=googlescholar" class="gs_nph" class=yC12>BL Direct</a> <a href="/scholar?cluster=1557928597142664402&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'0nQcCs7fnhUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://www.comp.nus.edu.sg/~tancl/publications/j2008/PR-LuTan-2007.pdf" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320307004669" class=yC13>Retrieval of machine-printed Latin documents through Word Shape Coding</a></h3><div class="gs_a"><a href="/citations?user=Fgqq-4kAAAAJ&amp;hl=en&amp;oi=sra">S Lu</a>, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - Pattern Recognition, 2008 - Elsevier</div><div class="gs_rs">This paper reports a document retrieval technique that retrieves machine-printed Latin-<br>based document images through word shape coding. Adopting the idea of image <br>annotation, a word shape coding scheme is proposed, which converts each word image <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5548075066167160378&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 23</a> <a href="/scholar?q=related:Om4YsuC4_kwJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5548075066167160378&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'Om4YsuC4_kwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/M616171186552871.pdf" class=yC15>Mobile Retriever: access to digital documents from their physical source</a></h3><div class="gs_a">X Liu, <a href="/citations?user=RoGOW9AAAAAJ&amp;hl=en&amp;oi=sra">D Doermann</a> - International Journal on Document Analysis and  &hellip;, 2008 - Springer</div><div class="gs_rs">Abstract In this paper, we describe an image based document retrieval system which runs <br>on camera enabled mobile devices.âMobile Retrieverâ aims to seamlessly link physical and <br>digital documents by allowing users to snap a picture of the text of a document and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7631993920592731933&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 17</a> <a href="/scholar?q=related:Hd_e5AhK6mkJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7631993920592731933&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'Hd_e5AhK6mkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://lib-repos.fun.ac.jp/dspace/bitstream/10445/3003/4/kterasaw_2007_02_icdar.pdf" class=yC17><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from fun.ac.jp</span><span class="gs_ggsS">fun.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4378678" class=yC16>Locality sensitive pseudo-code for document images</a></h3><div class="gs_a">K Terasawa, Y Tanaka - Document Analysis and Recognition,  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose a novel scheme for representing character string images <br>in the scanned document. We converted conventional multi-dimensional descriptors into <br>pseudo-codes which have a property that: if two vectors are near in the original space <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4406103475064879809&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 16</a> <a href="/scholar?q=related:wTrbGsSfJT0J:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4406103475064879809&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'wTrbGsSfJT0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.94.2049&amp;rep=rep1&amp;type=pdf" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.worldscientific.com/doi/abs/10.1142/S0218001404003137" class=yC18>Chinese word searching in imaged documents</a></h3><div class="gs_a">LU YUE, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">LIMTAN CHEW</a> - International Journal of Pattern  &hellip;, 2004 - World Scientific</div><div class="gs_rs">An approach to searching for user-specified words in imaged Chinese documents, without <br>the requirements of layout analysis and OCR processing of the entire documents, is <br>proposed in this paper. A small number of Chinese characters that cannot be successfully <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5282528325200680472&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 15</a> <a href="/scholar?q=related:GJaGE4ZPT0kJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/45/29/RN148356931.html?source=googlescholar" class="gs_nph" class=yC1A>BL Direct</a> <a href="/scholar?cluster=5282528325200680472&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'GJaGE4ZPT0kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://www.comp.nus.edu.sg/~TANCL/publications/c2004/DIAL-LuY.pdf" class=yC1C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1263247" class=yC1B>Retrieving imaged documents in digital libraries based on word image coding</a></h3><div class="gs_a">Y Lu, L Zhang, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - Document Image Analysis for Libraries &hellip;, 2004 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract A great number of documents are scanned and archived in the form of digital <br>images in digital libraries, to make them available and accessible in the Internet. Information <br>retrieval in these imaged documents has become a growing and challenging problem. For <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9993457208829613877&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 13</a> <a href="/scholar?q=related:NRdbQmLkr4oJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9993457208829613877&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 19 versions</a> <a onclick="return gs_ocit(event,'NRdbQmLkr4oJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://cvit.iiit.ac.in/papers/Million08Matching.pdf" class=yC1E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from iiit.ac.in</span><span class="gs_ggsS">iiit.ac.in <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/D76093176Q324226.pdf" class=yC1D>Matching word images for content-based retrieval from printed document images</a></h3><div class="gs_a">M Meshesha, <a href="/citations?user=U9dH-DoAAAAJ&amp;hl=en&amp;oi=sra">CV Jawahar</a> - &hellip; journal on document analysis and recognition, 2008 - Springer</div><div class="gs_rs">Abstract As large quantity of document images is getting archived by the digital libraries, <br>there is a need for an efficient search strategies to make them available as per users <br>information need. In this paper, we propose an effective word image matching scheme <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9745578603144312775&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 14</a> <a href="/scholar?q=related:x3cQ8xpAP4cJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9745578603144312775&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 19 versions</a> <a onclick="return gs_ocit(event,'x3cQ8xpAP4cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="ftp://coggsworth.cse.buffalo.edu/pub/tech-reports/2006-22.pdf" class=yC20><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from buffalo.edu</span><span class="gs_ggsS">buffalo.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/r1n853j667157q1g.pdf" class=yC1F>Automatic recognition of handwritten medical forms for search engines</a></h3><div class="gs_a">RJ Milewski, <a href="/citations?user=ruIgbscAAAAJ&amp;hl=en&amp;oi=sra">V Govindaraju</a>, <a href="/citations?user=U-KH6j4AAAAJ&amp;hl=en&amp;oi=sra">A Bhardwaj</a> - International journal on  &hellip;, 2009 - Springer</div><div class="gs_rs">Abstract A new paradigm, which models the relationships between handwriting and topic <br>categories, in the context of medical forms, is presented. The ultimate goals are:(1) a robust <br>method which categorizes medical forms into specified categories, and (2) the use of such <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4398567822512311335&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 11</a> <a href="/scholar?q=related:J0xPRSHaCj0J:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4398567822512311335&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 24 versions</a> <a onclick="return gs_ocit(event,'J0xPRSHaCj0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md15', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md15" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:J0xPRSHaCj0J:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=12367863921973043563&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://www.cis.pku.edu.cn/vision/Visual%26Robot/publication/doc/ICDAR05_Liu.pdf" class=yC22><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from pku.edu.cn</span><span class="gs_ggsS">pku.edu.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1575702" class=yC21>Document image retrieval based on density distribution feature and key block feature</a></h3><div class="gs_a">H Liu, S Feng, H Zha, X Liu - Document Analysis and  &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Document image retrieval is an important part of many document image processing <br>systems such as paperless office systems, digital libraries and so on. Its task is to help users <br>find out the most similar document images from a document image database. For <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9077747366827313218&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 10</a> <a href="/scholar?q=related:Qsh6WCKj-n0J:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9077747366827313218&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'Qsh6WCKj-n0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ADA478157" class=yC24><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from dtic.mil</span><span class="gs_ggsS">dtic.mil <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://oai.dtic.mil/oai/oai?verb=getRecord&amp;metadataPrefix=html&amp;identifier=ADA478157" class=yC23>A statistical approach to retrieving historical manuscript images without recognition</a></h3><div class="gs_a">TM Rath, <a href="/citations?user=FfjKDgwAAAAJ&amp;hl=en&amp;oi=sra">V Lavrenko</a>, <a href="/citations?user=_0aMq28AAAAJ&amp;hl=en&amp;oi=sra">R Manmatha</a> - 2003 - DTIC Document</div><div class="gs_rs">Abstract: Handwritten historical document collections in libraries and other areas are often of <br>interest to researchers, students, or the general public. Convenient access to such corpora <br>generally requires an index, which allows one to locate individual text units (pages, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16526728466694298132&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 10</a> <a href="/scholar?q=related:FFqmZPq7WuUJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16526728466694298132&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'FFqmZPq7WuUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md17', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md17" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:FFqmZPq7WuUJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=13905596791453437082&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4378692" class=yC25>Document images retrieval based on multiple features combination</a></h3><div class="gs_a">G Meng, N Zheng, Y Song&hellip; - Document Analysis and  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Retrieving the relevant document images from a great number of digitized pages <br>with different kinds of artificial variations and documents quality deteriorations caused by <br>scanning and printing is a meaningful and challenging problem. We attempt to deal with <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12882190408703700843&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 8</a> <a href="/scholar?q=related:a2-6h-y7xrIJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12882190408703700843&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'a2-6h-y7xrIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ri"><h3 class="gs_rt"><a href="http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=858081" class=yC26>Sequential neural network combination for degraded machine-printed character recognition</a></h3><div class="gs_a">A Namane, M Arezki&hellip; - Electronic  &hellip;, 2005 - proceedings.spiedigitallibrary.org</div><div class="gs_rs">abstract This paper presents an OCR method that combines Hopfield network with two layer <br>perceptron for degraded printed character recognition. Hopfield network stores 35 prototype <br>characters used as main classes. After the pre-processing, an image of a character is <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6036943507929713368&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 8</a> <a href="/scholar?q=related:2EpApyKIx1MJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6036943507929713368&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'2EpApyKIx1MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB20" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW20"><a href="http://www.dtic.mil/dtic/tr/fulltext/u2/a477913.pdf" class=yC28><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from dtic.mil</span><span class="gs_ggsS">dtic.mil <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://oai.dtic.mil/oai/oai?verb=getRecord&amp;metadataPrefix=html&amp;identifier=ADA477913" class=yC27>Retrieving historical manuscripts using shape</a></h3><div class="gs_a">TM Rath, <a href="/citations?user=FfjKDgwAAAAJ&amp;hl=en&amp;oi=sra">V Lavrenko</a>, <a href="/citations?user=_0aMq28AAAAJ&amp;hl=en&amp;oi=sra">R Manmatha</a> - 2003 - DTIC Document</div><div class="gs_rs">Abstract: Convenient access to handwritten historical document collections in libraries <br>generally requires an index, which allows one to locate individual text units (pages, <br>sentences, lines) that are relevant to a given query (usually provided as text). Currently, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13883784797649843718&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 9</a> <a href="/scholar?q=related:BjbjybYcrcAJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13883784797649843718&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'BjbjybYcrcAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md20', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md20" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:BjbjybYcrcAJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=7446437998253175441&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="http://www-dsi.ing.unifi.it/~simone/Papers/das06.pdf" class=yC2A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unifi.it</span><span class="gs_ggsS">unifi.it <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/P126844X56795K87.pdf" class=yC29>Efficient word retrieval by means of SOM clustering and PCA</a></h3><div class="gs_a">S Marinai, S Faini, E Marino, G Soda - Document Analysis Systems VII, 2006 - Springer</div><div class="gs_rs">We propose an approach for efficient word retrieval from printed documents belonging to <br>Digital Libraries. The approach combines word image clustering (based on Self Organizing <br>Maps, SOM) with Principal Component Analysis. The combination of these methods <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=59533132948930137&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 7</a> <a href="/scholar?q=related:WX7JqRGB0wAJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/50/41/RN183130570.html?source=googlescholar" class="gs_nph" class=yC2B>BL Direct</a> <a href="/scholar?cluster=59533132948930137&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'WX7JqRGB0wAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB22" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW22"><a href="http://www.comp.nus.edu.sg/~TANCL/publications/c2002/LuY-das2002.pdf" class=yC2D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/vc7jev8d3kg9rxn4.pdf" class=yC2C>Word searching in document images using word portion matching</a></h3><div class="gs_a">Y Lu, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">C Tan</a> - Document Analysis Systems V, 2002 - Springer</div><div class="gs_rs">An approach with the capability of searching a word portion in document images is <br>proposed in this paper, to facilitate the detection and location of the user-specified query <br>words. A feature string is synthesized according to the character sequence in the user-<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3647449478686784503&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 7</a> <a href="/scholar?q=related:9ztP0flXnjIJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/5F/4C/RN118897845.html?source=googlescholar" class="gs_nph" class=yC2E>BL Direct</a> <a href="/scholar?cluster=3647449478686784503&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 23 versions</a> <a onclick="return gs_ocit(event,'9ztP0flXnjIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB23" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW23"><a href="http://perso.telecom-paristech.fr/~cfaure/articles/cfaureSADPI07.pdf" class=yC30><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from telecom-paristech.fr</span><span class="gs_ggsS">telecom-paristech.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1283883" class=yC2F>Document image analysis for active reading</a></h3><div class="gs_a">C Faure, N Vincent - Proceedings of the 2007 international workshop on  &hellip;, 2007 - dl.acm.org</div><div class="gs_rs">Abstract A huge number of documents that were only available in libraries are now on the <br>web. The web access is a solution to protect the cultural heritage and to facilitate knowledge <br>transmission. Most of these documents are displayed as images of the original paper <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7520004362983683525&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 6</a> <a href="/scholar?q=related:xbUHHSBsXGgJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7520004362983683525&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'xbUHHSBsXGgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/81l6v663305v4670.pdf" class=yC31>A survey of keyword spotting techniques for printed document images</a></h3><div class="gs_a">A Murugappan, B Ramachandran&hellip; - Artificial Intelligence  &hellip;, 2011 - Springer</div><div class="gs_rs">Abstract This paper attempts to provide a survey of the past researches on character based <br>as keyword based approaches used for retrieving information from document images. This <br>survey also provides insights into the strengths and weaknesses of current techniques, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4152659816115326052&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 6</a> <a href="/scholar?q=related:ZMyX3Bk2oTkJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4152659816115326052&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'ZMyX3Bk2oTkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB25" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW25"><a href="http://orpheus.ee.duth.gr/download/papers/journals/A%20Document%20Image%20Retrieval%20System.pdf" class=yC33><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from duth.gr</span><span class="gs_ggsS">duth.gr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0952197610000771" class=yC32>A document image retrieval system</a></h3><div class="gs_a"><a href="/citations?user=GDAL3kUAAAAJ&amp;hl=en&amp;oi=sra">K Zagoris</a>, <a href="/citations?user=uJVGw7kAAAAJ&amp;hl=en&amp;oi=sra">K Ergina</a>, <a href="/citations?user=E8a90xYAAAAJ&amp;hl=en&amp;oi=sra">N Papamarkos</a> - Engineering Applications of Artificial  &hellip;, 2010 - Elsevier</div><div class="gs_rs">In this paper, a system is presented that locates words in document image archives. This <br>technique performs the word matching directly in the document images bypassing character <br>recognition and using word images as queries. First, it makes use of document image <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2217747457466046465&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 8</a> <a href="/scholar?q=related:ARjK-48Fxx4J:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2217747457466046465&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'ARjK-48Fxx4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB26" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW26"><a href="http://staging.comp.nus.edu.sg/~tancl/publications/c2007/lu-keywordspotting.pdf" class=yC35><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4377064" class=yC34>Keyword spotting and retrieval of document images captured by a digital camera</a></h3><div class="gs_a"><a href="/citations?user=Fgqq-4kAAAAJ&amp;hl=en&amp;oi=sra">S Lu</a>, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - &hellip;  Analysis and Recognition, 2007. ICDAR 2007.  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents a keyword spotting technique that locates keywords within <br>document images captured by a digital camera. In the proposed technique, the shape of <br>word images in perspective view is captured by using three perspective invariants, namely<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9924312720079342668&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 5</a> <a href="/scholar?q=related:TEw4cNY9uokJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9924312720079342668&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'TEw4cNY9uokJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4343120" class=yC36>Word indexing of ancient documents using fuzzy classification</a></h3><div class="gs_a">JMC Sousa, JM Gil, JRC Pinto - Fuzzy Systems, IEEE  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper proposes a fuzzy classification system to perform word indexing in <br>ancient printed documents. The indexing system receives a given word selected by an user. <br>The word is preprocessed using an aspect ratio filter, assuring that only interesting word <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1735762786213268696&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 6</a> <a href="/scholar?q=related:2IyVvg6rFhgJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/0A/20/RN218545542.html?source=googlescholar" class="gs_nph" class=yC37>BL Direct</a> <a href="/scholar?cluster=1735762786213268696&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'2IyVvg6rFhgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB28" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW28"><a href="http://dblab.mgt.ncu.edu.tw/%E6%95%99%E6%9D%90/2008%20DM/40.pdf" class=yC39><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ncu.edu.tw</span><span class="gs_ggsS">ncu.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0306457307002142" class=yC38>Text image matching without language model using a Hausdorff distance</a></h3><div class="gs_a">HJ Son, SH Kim, JS Kim - Information Processing &amp; Management, 2008 - Elsevier</div><div class="gs_rs">In this paper, we propose a text matching method for document image retrieval without any <br>language model. Two word images are first normalized to an appropriate size and image <br>features are extracted using the local crowdedness method. Similarity between the two <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15434266969461134930&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 5</a> <a href="/scholar?q=related:UpZG0wiIMdYJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15434266969461134930&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'UpZG0wiIMdYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB29" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW29"><a href="http://www-dsi.ing.unifi.it/~simone/Papers/ECDL07.pdf" class=yC3B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unifi.it</span><span class="gs_ggsS">unifi.it <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/u3w7614963g06756.pdf" class=yC3A>Exploring digital libraries with document image retrieval</a></h3><div class="gs_a">S Marinai, E Marino, G Soda - Research and Advanced Technology for  &hellip;, 2007 - Springer</div><div class="gs_rs">In this paper, we describe a system to perform Document Image Retrieval in Digital <br>Libraries. The system allows users to retrieve digitized pages on the basis of layout <br>similarities and to make textual searches on the documents without relying on OCR. The <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17450940246358170276&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 5</a> <a href="/scholar?q=related:pBq_7LExLvIJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/19/13/RN216317372.html?source=googlescholar" class="gs_nph" class=yC3C>BL Direct</a> <a href="/scholar?cluster=17450940246358170276&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'pBq_7LExLvIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB30" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW30"><a href="http://cvit.iiit.ac.in/thesis/millionPHD2008/millionThesis2008.pdf" class=yC3E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from iiit.ac.in</span><span class="gs_ggsS">iiit.ac.in <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://cvit.iiit.ac.in/thesis/millionPHD2008/millionThesis2008.pdf" class=yC3D>Recognition and Retrieval from Document Image Collections</a></h3><div class="gs_a">M Meshesha - 2006 - cvit.iiit.ac.in</div><div class="gs_rs">Abstract The present growth of digitization of books and manuscripts demands an immediate <br>solution to access them electronically. This will enable the archived valuable materials to be <br>searchable and usable by users in order to achieve their objectives. This requires <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6537078785522049211&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 5</a> <a href="/scholar?q=related:u6DIP4VeuFoJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'u6DIP4VeuFoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md30', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md30" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:u6DIP4VeuFoJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB31" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW31"><a href="http://pdf.aminer.org/000/264/689/keyword_spotting_on_korean_document_images_by_matching_the_keyword.pdf" class=yC40><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aminer.org</span><span class="gs_ggsS">aminer.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/f4r2514141401175.pdf" class=yC3F>Keyword spotting on Korean document images by matching the keyword image</a></h3><div class="gs_a">S Kim, S Park, C Jeong, J Kim, H Park&hellip; - &hellip;  Strategies and Sharing  &hellip;, 2005 - Springer</div><div class="gs_rs">In this paper, we propose a keyword spotting system for Korean document images and <br>compare the proposed system with an OCR-based document retrieval system. The system is <br>composed of character segmentation, feature extraction for the query keyword, and word-<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9534385331387069434&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 4</a> <a href="/scholar?q=related:-nMFjfHwUIQJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/5A/30/RN180451996.html?source=googlescholar" class="gs_nph" class=yC41>BL Direct</a> <a href="/scholar?cluster=9534385331387069434&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'-nMFjfHwUIQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1864500" class=yC42>Papercomp 2010: first international workshop on paper computing</a></h3><div class="gs_a"><a href="/citations?user=pZEf29QAAAAJ&amp;hl=en&amp;oi=sra">F Kaplan</a>, <a href="/citations?user=G1N5IrwAAAAJ&amp;hl=en&amp;oi=sra">P Jermann</a> - Proceedings of the 12th ACM international  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract Paper is not dead. Despite the progress of e-ink screens, smartphones and tablet <br>interfaces, printed paper stays a convenient, versatile and familiar support for reading and <br>writing. Books, magazines and other printed materials can now be connected to the digital <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15201133184885379662&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 4</a> <a href="/scholar?q=related:TtJ-tBdG9dIJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'TtJ-tBdG9dIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:367"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB33" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW33"><a href="https://posgrado.escom.ipn.mx/biblioteca/Text%20retrieval%20from%20early%20printed%20books.pdf" class=yC44><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ipn.mx</span><span class="gs_ggsS">ipn.mx <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/A855GL8845800346.pdf" class=yC43>Text retrieval from early printed books</a></h3><div class="gs_a">S Marinai - International journal on document analysis and  &hellip;, 2011 - Springer</div><div class="gs_rs">Abstract Retrieving text from early printed books is particularly difficult because in these <br>documents, the words are very close one to the other and, similarly to medieval manuscripts, <br>there is a large use of ligatures and abbreviations. To address these problems, we <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2897344057422586629&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 4</a> <a href="/scholar?q=related:BSPDxhFvNSgJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2897344057422586629&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'BSPDxhFvNSgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:366"><div class="gs_ri"><h3 class="gs_rt"><a href="http://inderscience.metapress.com/index/g04343p28gxv8m74.pdf" class=yC45>Feature string-based intelligent information retrieval from Tamil document images</a></h3><div class="gs_a">S Abirami, D Manjula - International Journal of Computer Applications  &hellip;, 2009 - Inderscience</div><div class="gs_rs">Information Retrieval (IR) in document images has become a growing and challenging <br>problem due to its rising popularity. This paper proposes a simple and effective method to <br>extract the text and perform intelligent IR from Tamil Document Images without Optical <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=808284528493685425&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 4</a> <a href="/scholar?q=related:sWpPBn-aNwsJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=808284528493685425&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'sWpPBn-aNwsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:365"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/7030541531486Q85.pdf" class=yC46>Impact of online handwriting recognition performance on text categorization</a></h3><div class="gs_a">S PeÃ±a Saldarriaga, C Viard-Gaudin&hellip; - International journal on  &hellip;, 2010 - Springer</div><div class="gs_rs">Abstract Today, there is an increasing demand of efficient archival and retrieval methods for <br>online handwritten data. For such tasks, text categorization is of particular interest. The <br>textual data available in online documents can be extracted through online handwriting <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5391203364612795899&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 3</a> <a href="/scholar?q=related:--2ic-Vm0UoJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5391203364612795899&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'--2ic-Vm0UoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:364"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB36" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW36"><a href="http://opticalengineering.spiedigitallibrary.org/article.aspx?articleid=1076893%20" class=yC48><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from spiedigitallibrary.org</span><span class="gs_ggsS">spiedigitallibrary.org <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[HTML]</span><span class="gs_ct2">[HTML]</span></span> <a href="http://opticalengineering.spiedigitallibrary.org/article.aspx?articleid=1076893%20" class=yC47>Hopfield-multilayer-perceptron serial combination for accurate degraded printed character recognition</a></h3><div class="gs_a">A Namane, A Guessoum&hellip; - Optical  &hellip;, 2006 - opticalengineering.spiedigitallibrary. &hellip;</div><div class="gs_rs">Abstract. Degraded printed character recognition is a hard and everpresent problem in <br>optical character recognition. Previous work has explored serial combination of multilayer <br>perceptron (MLP) and autoassociators networks for printed character recognition. The <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15941885261655450863&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 3</a> <a href="/scholar?q=related:7yQChy70PN0J:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/1F/01/RN196136760.html?source=googlescholar" class="gs_nph" class=yC49>BL Direct</a> <a href="/scholar?cluster=15941885261655450863&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'7yQChy70PN0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md36', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md36" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:7yQChy70PN0J:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:363"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB37" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW37"><a href="http://nlpr-web.ia.ac.cn/2010papers/kz/gh12.pdf" class=yC4B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ia.ac.cn</span><span class="gs_ggsS">ia.ac.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5512232" class=yC4A>License plate location based on adaboost</a></h3><div class="gs_a"><a href="/citations?user=WyYnBkEAAAAJ&amp;hl=en&amp;oi=sra">X Zhang</a>, P Shen, J Bai, J Lei, Y Hu&hellip; - &hellip;  (ICIA), 2010 IEEE  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract License plate locating has been the bottleneck of Automatic Vehicle Recognition <br>System. In order to improve the speed and accuracy of license plate locating, this paper <br>proposes a simple and practical method of license plate locating. This method uses the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10535263073969644421&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 3</a> <a href="/scholar?q=related:hSNAk_LFNJIJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10535263073969644421&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'hSNAk_LFNJIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:362"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB38" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW38"><a href="http://hal.archives-ouvertes.fr/docs/00/11/19/94/PDF/article_74f.pdf" class=yC4D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://hal.archives-ouvertes.fr/hal-00111994/" class=yC4C>Indexation de Documents Manuscrits Offline</a></h3><div class="gs_a"><a href="/citations?user=XOnfkHIAAAAJ&amp;hl=en&amp;oi=sra">A Vinciarelli</a> - &hellip; Colloque International Francophone sur l&#39;Ecrit &hellip;, 2006 - hal.archives-ouvertes.fr</div><div class="gs_rs">RÃ©sumÃ©: Les systÃ¨mes de reconnaissance automatique de l&#39;Ã©criture permettent de <br>transfomer des collections de documents manuscrits en archives de documents <br>numÃ©riques. L&#39;avantage n&#39;est pas tellement la rÃ©duction de l&#39;espace nÃ©cÃ©ssaire pour <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13809459667631753897&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 6</a> <a href="/scholar?q=related:qUpG7WYOpb8J:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13809459667631753897&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'qUpG7WYOpb8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:361"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/93758x/20093/30902188.0.html" class=yC4E>åºäº OCR ä¸è¯å½¢ç¶ç¼ç çè±ææ«æææ¡£æ£ç´¢</a></h3><div class="gs_a">å¤åï¼ æ´æ±ä¸ºï¼ èæåï¼ çæ¥æ - æ¨¡å¼è¯å«ä¸äººå·¥æºè½, 2009 - cqvip.com</div><div class="gs_rs">æè¦: åæå½åå¸¸ç¨çä¸¤ç±»æ«æææ¡£æ£ç´¢æ¹æ³: åºäºOCR ååºäºè¯å½¢ç¶ç¼ç çæ¹æ³. <br>æåºåºäºè¯å«ä¿¡åº¦å°ä¸¤ç§æ¹æ³è¿è¡ææºç»åçæè·¯. åºäºææ¡£æå­ç¹æ§åç¬ç»ç¹å¾, <br>è¿æåºä¸ç§è¯å½¢ç¶ç¼ç æ¹æ³, å¯¹å­ä½æè¾å¼ºçå®¹å¿æ§. éå¯¹åç§æ å¼æ¹æ³è¿è¡å³é®è¯æ£ç´¢å¯¹æ¯<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3141428776127416886&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 4</a> <a href="/scholar?q=related:NspD8NOYmCsJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3141428776127416886&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'NspD8NOYmCsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:360"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/96983x/20074/24841458.0.html" class=yC4F>ä¸ç§åºäºå³é®è¯çä¸­æææ¡£å¾åæ£ç´¢æ¹æ³</a></h3><div class="gs_a">é»ç¥¥æï¼ é«è¸ï¼ æ¨ä¸½è³ï¼ çé¹é¹ - ä¸­æä¿¡æ¯å­¦æ¥, 2007 - cqvip.com</div><div class="gs_rs">æè¦: æ¬ææåºäºä¸ç§åºäºå³é®è¯çä¸­æææ¡£å¾åæ£ç´¢æ¹æ³, è½å¨ä¸ç»OCR (Optical Character <br>Recognition) è¯å«çæåµä¸, ç´æ¥å©ç¨ä¸­æå­ç¬¦çå¾åç¹å¾è¿è¡å³é®è¯æ£ç´¢. <br>é¦åå°ææ¡£å¾ååå²æåä¸ªä¸­æå­ç¬¦å¾å, æ¥çå¯¹å­ç¬¦å¾åè¿è¡æ±å­ç¬ç»çç¹å¾æ°æ®æå, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8452016989588293914&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 3</a> <a href="/scholar?q=related:Ggn626uYS3UJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8452016989588293914&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'Ggn626uYS3UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:359"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB41" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW41"><a href="http://cv.jbnu.ac.kr/~isoh/data/%C1%A4%BA%B8%B0%FA%C7%D0%C8%B8%C1%F62001.hwp" class=yC51><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from jbnu.ac.kr</span><span class="gs_ggsS">jbnu.ac.kr <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.dbpia.co.kr/view/ar_view.asp?arid=607123" class=yC50>ë¬¸ì ìì ì²ë¦¬ ê¸°ì ê³¼ ëì§í¸ ëìê´</a></h3><div class="gs_a">ê³½í¬ê· - ì ë³´ê³¼ííì§, 2002 - dbpia.co.kr</div><div class="gs_rs">Page 1. 24 2002. 8. ì ë³´ê³¼ííì§ ì 20ê¶ ì 8í¸ D ë¬¸ì ìì ì²ë¦¬ ê¸°ì ê³¼ ëì§í¸ ëìê´ ì ë¶ëí%<br>ì¤ì¼ìÂ· ì ë¨ëíêµ ê¹ìíÂ· ìí´ëíêµ ì íìâ¥ íêµ­ê³¼íê¸°ì ì ê³½í¬ê· 1 . ì ë¡  J00 80 ì¸ë¥ì<br>ì§ììë¬¸ììë¬¸ìë¼ëííë¥¼íµí´ ì¤ë oTn 60 ì¸ì ì¶ì ëì´ ìë¤. <b>...</b> </div><div class="gs_fl"><a href="/scholar?cites=11186639748397628631&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 2</a> <a href="/scholar?q=related:13yB8ZTtPpsJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11186639748397628631&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'13yB8ZTtPpsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:358"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB42" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW42"><a href="http://www.scholarbank.nus.edu.sg/bitstream/handle/10635/14556/PhDThesis-LooPohKok.pdf?sequence=1" class=yC53><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.scholarbank.nus.edu.sg/handle/10635/14556" class=yC52>Document image processing using irregular pyramid structure</a></h3><div class="gs_a">LOOPOH KOK - 2005 - scholarbank.nus.edu.sg</div><div class="gs_rs">This thesis will present our research in the use of a new irregular pyramid structure in <br>document image processing. The focus is in the segmentation of textual components from <br>binary, gray scale and color document images with mixed texts/graphics. The thesis <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5958240527368237188&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 1</a> <a href="/scholar?q=related:hLAeCDHsr1IJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5958240527368237188&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'hLAeCDHsr1IJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:357"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB43" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW43"><a href="http://hal.inria.fr/docs/00/33/44/17/PDF/paper-36.pdf" class=yC55><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from inria.fr</span><span class="gs_ggsS">inria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://hal.inria.fr/hal-00334417/" class=yC54>Multiple classifier for degraded machine printed character recognition</a></h3><div class="gs_a">A Namane, P Meyrueis - &hellip; Colloque International Francophone sur l&#39;Ecrit &hellip;, 2008 - hal.inria.fr</div><div class="gs_rs">RÃ©sumÃ©: The general problem of optical character recognition (OCR) remains a <br>fundamental but not entirely solved issue in document analysis. In spite of significant <br>improvements in the area of optical character recognition, the recognition of degraded <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9957247360873772753&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 1</a> <a href="/scholar?q=related:0baTDbg_L4oJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9957247360873772753&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'0baTDbg_L4oJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:356"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5300831" class=yC56>Character Retrieval Based on the Improved Contour Feature and Texture Feature</a></h3><div class="gs_a">J Zhang, XL Huang, H Lv - Management and Service Science,  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In order to retrieve the character images but avoid the OCR system which is limited <br>in some application, a method for Chinese characters retrieval is presented in this paper. It <br>firstly extracts the improved contour feature of Chinese character images, which is used to <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11654625598369863974&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 1</a> <a href="/scholar?q=related:JpkCnTuMvaEJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'JpkCnTuMvaEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:355"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.stormingmedia.us/31/3197/A319774.html" class=yC57>Retrieving Historical Manuscripts Using Shape</a></h3><div class="gs_a"><a href="/citations?user=FfjKDgwAAAAJ&amp;hl=en&amp;oi=sra">V Lavrenko</a>, TM Rath, <a href="/citations?user=_0aMq28AAAAJ&amp;hl=en&amp;oi=sra">R Manmatha</a> - 2003 - stormingmedia.us</div><div class="gs_rs">Abstract: Convenient access to handwritten historical document collections in libraries <br>generally requires an index, which allows one to locate individual text units (pages, <br>sentences, lines) that are relevant to a given query (usually provided as text). Currently, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:yRN7B-An3SwJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'yRN7B-An3SwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:354"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB46" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW46"><a href="http://etd.aau.edu.et/dspace/bitstream/123456789/3516/1/final%20edited1.pdf" class=yC59><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aau.edu.et</span><span class="gs_ggsS">aau.edu.et <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://etd.aau.edu.et/dspace/handle/123456789/3516" class=yC58>FEATURE EXTRACTION AND MATCHING IN AMHARIC DOCUMENT IMAGE COLLECTIONS</a></h3><div class="gs_a">L ADANE - 2011 - etd.aau.edu.et</div><div class="gs_rs">Abstract: The ubiquity of digital computers and the boom of the Internet and World Wide Web <br>resulted in massive information explosion over the entire world. Different types of information <br>are uploaded in the Internet such as text documents, document images and other <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:3s5jD0QyDXEJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'3s5jD0QyDXEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:353"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Partial Word Image Matching and Its Applications to Document Image Retrieval</h3><div class="gs_a">Y Lu, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a></div><div class="gs_fl"><a href="/scholar?q=related:xACIEjuQ0jMJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3734205624431935684&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'xACIEjuQ0jMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:352"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB48" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW48"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.90.9185&amp;rep=rep1&amp;type=pdf" class=yC5B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.90.9185&amp;rep=rep1&amp;type=pdf" class=yC5A>A New Invariant Algorithm for Recognition of Alphabets of Multi-lingual Documents</a></h3><div class="gs_a">GH Kumar, P Shivakumara, S Noushath, VNM Aradhya - 2008 - Citeseer</div><div class="gs_rs">Abstract OCR is used to translate human readable characters into machine-readable codes <br>because it provides a solution for processing large volumes of data automatically in a large <br>variety of scientific and business applications. Thus OCR is an important component of <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:dYKrGRzd8i0J:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3310951788830229109&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'dYKrGRzd8i0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:351"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB49" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW49"><a href="http://staging.comp.nus.edu.sg/~tancl/publications/c2008/sigir2008.pdf" class=yC5D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1390496" class=yC5C>A word shape coding method for camera-based document images</a></h3><div class="gs_a">L Li, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - Proceedings of the 31st annual international ACM  &hellip;, 2008 - dl.acm.org</div><div class="gs_rs">Abstract This paper reports a word shape coding method to facilitate retrieval of camera-<br>based document images without OCR. Due to perspective distortion, many reported word <br>shape coding methods fail on camera-based images. In this paper, the problem is <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:-JdMLg6g1mwJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7842631783879055352&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'-JdMLg6g1mwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:350"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Script and Language Identification in Noisy and Degraded Document Images</h3><div class="gs_a">SLUCLIM TAN</div><div class="gs_fl"><a href="/scholar?q=related:kH2ULuYK-YYJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'kH2ULuYK-YYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:349"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB51" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW51"><a href="http://www.icdar2011.org/fileup/PDF/4520b379.pdf" class=yC5F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from icdar2011.org</span><span class="gs_ggsS">icdar2011.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6065536" class=yC5E>A Fast Appearance-Based Full-Text Search Method for Historical Newspaper Images</a></h3><div class="gs_a">K Terasawa, T Shima&hellip; - Document Analysis and  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents a fast appearance-based full-text search method for historical <br>newspaper images. Since historical newspapers differ from recent newspapers in image <br>quality, type fonts and language usages, optical character recognition (OCR) does not <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:eV_BZ-i1bGQJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7236358711055310713&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'eV_BZ-i1bGQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:348"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB52" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW52"><a href="http://kaitman.free.fr/article/thesis/04293683.pdf" class=yC61><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from free.fr</span><span class="gs_ggsS">free.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4293683" class=yC60>Profile Based Information Retrieval from Printed Document Images</a></h3><div class="gs_a">S Abirami, D Manjula - Computer Graphics, Imaging and  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper performs a profile based Information Retrieval from printed document <br>image collections. Keywords are valuable indexing tools and if they can be identified at the <br>image level, extensive computation during recognition will be avoided. Printed documents <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:JmPpbB-j6VsJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6623004082391573286&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'JmPpbB-j6VsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:347"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB53" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW53"><a href="http://lampsrv02.umiacs.umd.edu/pubs/TechReports/LAMP_151/LAMP_151.pdf" class=yC63><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from umd.edu</span><span class="gs_ggsS">umd.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://lampsrv02.umiacs.umd.edu/pubs/TechReports/LAMP_151/LAMP_151.pdf" class=yC62>LAMP-TR-151 November 2008 COMPUTER VISION AND IMAGE PROCESSING LARGE TECHNIQUES FOR MOBILE APPLICATIONS</a></h3><div class="gs_a">X Liu, <a href="/citations?user=RoGOW9AAAAAJ&amp;hl=en&amp;oi=sra">D Doermann</a> - lampsrv02.umiacs.umd.edu</div><div class="gs_rs">Abstract Camera phones have penetrated every corner of society and have become a focal <br>point for communications. In our research we extend the traditional use of such devices to <br>help bridge the gap between physical and digital worlds. Their combined image <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:xIYNbZmcz_sJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18144893606472550084&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'xIYNbZmcz_sJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md53', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md53" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:xIYNbZmcz_sJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:346"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB54" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW54"><a href="http://docsdrive.com/pdfs/medwelljournals/ajit/2006/996-1000.pdf" class=yC65><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from docsdrive.com</span><span class="gs_ggsS">docsdrive.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://docsdrive.com/pdfs/medwelljournals/ajit/2006/996-1000.pdf" class=yC64>Enabling Intelligent Information Retrieval from Tamil Document Images</a></h3><div class="gs_a">S Abirami, ZD Manjula - Asian J. Inform. Tech, 2006 - docsdrive.com</div><div class="gs_rs">Abstract: This study performs an efficient Information Retrieval from scanned Tamil <br>Document Images. Keywords are valuable indexing tools and if they can be identified at the <br>image level, extensive computation during recognition will be avoided. Printed documents <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:4WogcmrnN_UJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17669846107378707169&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'4WogcmrnN_UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:345"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB55" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW55"><a href="http://www.waprogramming.com/papers/vol2-no5/(308-314)%20Content%20Based%20Document%20Image%20Retrieval%20with%20Support%20Vectors%20Clustering.pdf" class=yC67><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from waprogramming.com</span><span class="gs_ggsS">waprogramming.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.waprogramming.com/papers/vol2-no5/(308-314)%20Content%20Based%20Document%20Image%20Retrieval%20with%20Support%20Vectors%20Clustering.pdf" class=yC66>Content Based Document Image Retrieval with Support Vectors Clustering</a></h3><div class="gs_a">M Habibi, R Azmi - 2011 - waprogramming.com</div><div class="gs_rs">Abstract: The goal of this paper is representing a suitable approach to content based <br>document image retrieval. in proposed algorithm a feature vector is extracted with wavelet <br>transform for sub-words. then based on this features, sub-words are clustered with support <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:FOBXeposYzkJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4135197924845412372&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'FOBXeposYzkJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md55', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md55" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:FOBXeposYzkJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:344"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB56" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW56"><a href="http://pc01.lib.ntust.edu.tw/ETD-db/ETD-search-c/getfile?URN=etd-0727109-160940&amp;filename=etd-0727109-160940.pdf" class=yC69><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntust.edu.tw</span><span class="gs_ggsS">ntust.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://pc01.lib.ntust.edu.tw/ETD-db/ETD-search/view_etd?URN=etd-0727109-160940" class=yC68>Form document retrieval with a partial form pattern</a></h3><div class="gs_a">K Li - 2009 - pc01.lib.ntust.edu.tw</div><div class="gs_rs">Abstract Using partial information retrieve that is a subject often encountered, and applies to <br>form document, it often needs complete information of form document to retrieve. When form <br>document remains partial information or has a specific structure of form type, our research <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:LByIfbB0ESEJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2382813979224841260&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'LByIfbB0ESEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:343"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB57" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW57"><a href="http://lampsrv02.umiacs.umd.edu/pubs/Papers/mobileretriever-ijdar/mobileretriever-ijdar.pdf" class=yC6B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from umd.edu</span><span class="gs_ggsS">umd.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://lampsrv02.umiacs.umd.edu/pubs/Papers/mobileretriever-ijdar/mobileretriever-ijdar.pdf" class=yC6A>Mobile Retriever</a></h3><div class="gs_a">X Liu, <a href="/citations?user=RoGOW9AAAAAJ&amp;hl=en&amp;oi=sra">D Doermann</a> - lampsrv02.umiacs.umd.edu</div><div class="gs_rs">Abstract In this paper we describe an image based document retrieval system which runs on <br>camera enabled mobile devices.âMobile Retrieverâ aims to seamlessly link physical and <br>digital documents by allowing users to snap a picture of the text of a document and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Qzc8gPFmvIUJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9636690490090600259&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'Qzc8gPFmvIUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md57', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md57" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Qzc8gPFmvIUJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:342"><div class="gs_ri"><h3 class="gs_rt"><a href="http://spie.org/x648.html?product_id=483240" class=yC6C>Approach to matching partial word image and its application to document image retrieval</a></h3><div class="gs_a">Y Lu, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a>, <a href="/citations?user=FwTHWZ4AAAAJ&amp;hl=en&amp;oi=sra">L Lin</a> - Optical Information Processing Technology: 16-18  &hellip;, 2002 - spie.org</div><div class="gs_rs">An approach with the capability of matching partial word image is proposed in this paper, to <br>facilitate the issues of document image retrieval, such as detection of user-specified query <br>words, and similarity measurement between documents. Each word image is represented <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:3bNsnOborRoJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1922448693121561565&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'3bNsnOborRoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md58', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md58" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:3bNsnOborRoJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:341"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/8012k07253200337.pdf" class=yC6D>Improved number plate character segmentation algorithm and its efficient FPGA implementation</a></h3><div class="gs_a">X Zhai, F Bensaali - Journal of Real-Time Image Processing, 2012 - Springer</div><div class="gs_rs">Abstract Character segmentation is an important stage in Automatic Number Plate <br>Recognition systems as good character separation leads to a high recognition rate. This <br>paper presents an improved character segmentation algorithm based on pixel projection <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15534255709896411070&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 1</a> <a href="/scholar?q=related:vod1nkPDlNcJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'vod1nkPDlNcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:340"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB60" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW60"><a href="http://arxiv.org/pdf/1206.1291" class=yC6F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arxiv.org</span><span class="gs_ggsS">arxiv.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://arxiv.org/abs/1206.1291" class=yC6E>Feature Weighting for Improving Document Image Retrieval System Performance</a></h3><div class="gs_a">M Keyvanpour, R Tavoli - arXiv preprint arXiv:1206.1291, 2012 - arxiv.org</div><div class="gs_rs">Abstract: Feature weighting is a technique used to approximate the optimal degree of <br>influence of individual features. This paper presents a feature weighting method for <br>Document Image Retrieval System (DIRS) based on keyword spotting. In this method, we <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:kseZuKEYxswJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14755508311991895954&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'kseZuKEYxswJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:339"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4555587" class=yC70>CSM-autossociators combination for degraded machine printed character recognition</a></h3><div class="gs_a">A Namane, N Khorissi, ZA Bensalama&hellip; - &hellip;  Processing and Its  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents an OCR method that combines the complementary similarity <br>measure (CSM) method with a set of autossociators for degraded character recognition. In <br>the serial combination, the first classifier must achieve lower errors and be very well suited <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:vY-wycipyHAJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'vY-wycipyHAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:338"><div class="gs_ri"><h3 class="gs_rt"><a href="http://jucs.org/jucs_17_1/the_use_of_latent/jucs_17_01_0064_0080_neto.pdf" class=yC71>The Use of Latent Semantic Indexing to Mitigate OCR Effects of Related Document Images</a></h3><div class="gs_a"><a href="/citations?user=_4UNe4EAAAAJ&amp;hl=en&amp;oi=sra">RF BulcÃ£o-Neto</a>, JA Camacho-Guerrero&hellip; - Journal of Universal  &hellip;, 2011 - jucs.org</div><div class="gs_rs">Abstract: Due to both the widespread and multipurpose use of document images and the <br>current availability of a high number of document images repositories, robust information <br>retrieval mechanisms and systems have been increasingly demanded. This paper <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:74blyq40nEkJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5304172386468595439&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'74blyq40nEkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:337"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB63" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW63"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.92.3369&amp;rep=rep1&amp;type=pdf" class=yC73><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.92.3369&amp;rep=rep1&amp;type=pdf" class=yC72>An Intelligent System for Exact Word Retrieval in Document Databases</a></h3><div class="gs_a">M Marikkannan, P Anandhakumar, A Kannan - Citeseer</div><div class="gs_rs">Abstract Automatic Information retrieval from document image databases is an important and <br>challenging task. The main challenges are font style, size and spacing between characters. <br>In order to meet the challenges, we propose a new technique for matching exact word <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:SRQdzllc0YwJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'SRQdzllc0YwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md63', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md63" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:SRQdzllc0YwJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:336"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB64" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW64"><a href="http://www.joics.com/publishedpapers/2013_10_1_247_256.pdf" class=yC75><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from joics.com</span><span class="gs_ggsS">joics.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.joics.com/publishedpapers/2013_10_1_247_256.pdf" class=yC74>Image Preprocessing and Feature Extraction Based on Real Estate Archives Retrieval</a></h3><div class="gs_a">J Guo, J Yu, F Yan - 2013 - joics.com</div><div class="gs_rs">Abstract Feature extraction is an important part of the document retrieval. The features of a <br>document are equivalent to the fingerprints of a document, which can be used to <br>characterize and retrieve a document. Document preprocessing and feature extraction <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'dPDw1RDyAMkJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md64', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md64" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:dPDw1RDyAMkJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:335"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB65" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW65"><a href="http://shodhganga.inflibnet.ac.in/dxml/bitstream/handle/1944/502/05cali_11.pdf?sequence=1" class=yC77><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from inflibnet.ac.in</span><span class="gs_ggsS">inflibnet.ac.in <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://shodhganga.inflibnet.ac.in/dxml/handle/1944/502" class=yC76>A New Contour Based Invariant Feature Extraction Approach for the Recognition of Multi-lingual Documents</a></h3><div class="gs_a">AVN Manjunath, KG Hemantha - 2005 - shodhganga.inflibnet.ac.in</div><div class="gs_rs">Now a day, developing a single OCR system for recognizing multi-lingual documents <br>becomes essential to enhance the ability and performance of the existing document analysis <br>system. Hence in this paper, we present a new technique based on contour detection and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:tvTr3ZesbWQJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7236629944517522614&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'tvTr3ZesbWQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:334"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB66" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW66"><a href="http://arxiv.org/pdf/1209.2274" class=yC79><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arxiv.org</span><span class="gs_ggsS">arxiv.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://arxiv.org/abs/1209.2274" class=yC78>PCA-Based Relevance Feedback in Document Image Retrieval</a></h3><div class="gs_a">R Tavoli, F Mahmoudi - arXiv preprint arXiv:1209.2274, 2012 - arxiv.org</div><div class="gs_rs">Abstract: Research has been devoted in the past few years to relevance feedback as an <br>effective solution to improve performance of information retrieval systems. Relevance <br>feedback refers to an interactive process that helps to improve the retrieval performance. <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ebVF62a3zVIJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5966626733997536633&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'ebVF62a3zVIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:333"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Image Registration for Digital Collation</h3><div class="gs_a">JW Waggoner, J Zhou, R Cream, <a href="/citations?user=eycXl_QAAAAJ&amp;hl=en&amp;oi=sra">S Wang</a></div><div class="gs_fl"><a href="/scholar?q=related:9-y9_k1xRMMJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'9-y9_k1xRMMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:332"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB68" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW68"><a href="http://file.lw23.com/2/2d/2db/2db2b650-7c6b-41fc-bf7d-ba37426d415b.pdf" class=yC7B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from lw23.com</span><span class="gs_ggsS">lw23.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://file.lw23.com/2/2d/2db/2db2b650-7c6b-41fc-bf7d-ba37426d415b.pdf" class=yC7A>ç§æ°é¢çæ¨¡ç³å­ç¬¦å¾ååå²èªéåºå½¢æå­¦æ¹æ³</a></h3><div class="gs_a">S Nomura, K Yamanaka, O Katai, H Kawakami&hellip; - file.lw23.com</div><div class="gs_rs">æè¦æ¬ææåºäºä¸ç§æ°é¢çå­ç¬¦åå²ä»¥åä»ä¸»è¦çæ¨¡ç³å¾åä¸­æåç¹å¾ç¢éçèªéåºæ¹æ³. <br>ç®æ³åºäºåå²åæ®µå­ç¬¦ä¹åèªå¨æ£æµçç¢çååå¹¶è¿äºç¢ççç´æ¹å¾æè¿°. <br>å¯¹äºéå å­ç¬¦çåå², å½¢æå­¦åçº§ç®æ³èªå¨ç¡®å®åèçº¿; å¯¹äºè¿æ¥å­ç¬¦çåå², å½¢æå­¦ç»åç®æ³<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:YIjfCl59XRcJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'YIjfCl59XRcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md68', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md68" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:YIjfCl59XRcJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:331"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB69" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW69"><a href="http://www.biblioteca.pucpr.br/tede/tde_arquivos/14/TDE-2009-06-09T153510Z-1189/Publico/Israel_Rios%20PPGIa.pdf" class=yC7D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from pucpr.br</span><span class="gs_ggsS">pucpr.br <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.biblioteca.pucpr.br/tede/tde_arquivos/14/TDE-2009-06-09T153510Z-1189/Publico/Israel_Rios%20PPGIa.pdf" class=yC7C>Busca por Palavras em Imagens de Documentos: Uma Abordagem Independente de OCR</a></h3><div class="gs_a">I RIOS - 2007 - biblioteca.pucpr.br</div><div class="gs_rs">Resumo Hoje em dia, hÃ¡ um grande volume de informaÃ§Ã£o disponÃ­vel na forma digital, seja <br>em grandes empresas seja em bibliotecas digitais. Grande parte dessa informaÃ§Ã£o Ã© <br>composta de imagens de documentos digitalizados. Devido ao grande volume, existe a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:aaqgMCP6wwMJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=271335431618996841&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'aaqgMCP6wwMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:330"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.dbpia.co.kr/view/ar_view.asp?arid=821724" class=yC7E>ë¬¸ìì¸ì ë¶ì¼ì ê¸°ê³íìµ ê¸°ë²</a></h3><div class="gs_a">ê¹ìí - ì ë³´ê³¼ííì§, 2007 - dbpia.co.kr</div><div class="gs_rs">ê¸°ê³íìµ (machine learning) ìê³ ë¦¬ì¦ ë±ì ê°ê´ì ì¼ì¤íë¼. ì¸ ë¬¸ìì¸ìì ì´ë¯¸ ì°ì¬ì§ <br>ë¬¸ìììì ì¹´ë©ë¡ ê³ ì°°íë¤ ì  2 ì ììë ë¬¸ìì¸ì ê¸°ì ì ì ìë¥¼. ë¼ ë° ì¤ìºëë¥¼ íµí´ <br>ìë ¥ë°ì ì¸ìíë ë°©ë²ì ë¨íì´í´ë³´ê³  ë¬¸ìì ìë ¥ ì¥ì¹ ëë ìë ¥ ë°©ìì ë°ë¼ë¬¸</div><div class="gs_fl"><a href="/scholar?q=related:LSnOV9GOtjgJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'LSnOV9GOtjgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:329"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/91690x/201012/33556470.html" class=yC7F>ç»¼åæå­åéæå­åºåç¹å¾çææ¡£å¾åæ£ç´¢</a></h3><div class="gs_a">å¼ ç° - è®¡ç®æºå·¥ç¨ä¸åºç¨, 2010 - cqvip.com</div><div class="gs_rs">æåºä¸ç§æ¹è¿çèªéåºæå­åºåæåç®æ³, å°ææ¡£å¾ååå²ææå­åºååéæå­åºå. <br>å¯¹æå­åºåæåè¿éå­ç¬¦é´ç©ºç½, è¿éå­ç¬¦é«åº¦åå®½åº¦ç­å±é¨ç¹å¾, ä»¥åä¹¦åæ ·å¼, <br>æ®µè½ç¹å¾ç­å¨å±ç¹å¾; å¯¹éæå­åºå, æåå³é®åç¹å¾. ç¶åå©ç¨æ£ç´¢ç®æ³å°æå­åºåç¹å¾åé<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2006898679886969195&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=79">Cited by 3</a> <a href="/scholar?q=related:a_ncYrfv2RsJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2006898679886969195&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'a_ncYrfv2RsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:328"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> åºäºå­ç¬¦å¯åº¦çè½¦çè¯å«æ¹æ³ç ç©¶</h3><div class="gs_a">èµµé¹ï¼ èµµä»²å­ - å¾®çµå­å­¦ä¸è®¡ç®æº, 2011</div><div class="gs_fl"><a href="/scholar?q=related:6n6pb2eoL_0J:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18243985777709645546&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'6n6pb2eoL_0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:327"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/92817x/200901/29209315.html" class=yC80>åºäºæ¨¡ç³éé¶å±åº¦ç¹å¾åè´´è¿åº¦çå¾½æ è¯å«</a></h3><div class="gs_a">çåï¼ é³å½¦éï¼ åç«æ± - è®¡ç®æºç§å­¦, 2009 - cqvip.com</div><div class="gs_rs">æ¨¡ç³ä¿¡æ¯çè®ºæ¯ä¸ç§åºäºæ¨¡ç³éçè®ºçä¿¡æ¯ç§å­¦, æ¨¡ç³éçè®ºå¨æ¨¡å¼è¯å«ä¸­è¡¨ç°åºå¾å¥½çæ§è½, <br>ä¸¤èç¸ç»åå½¢æäºæ¨¡ç³æ¨¡å¼è¯å«. éå¯¹å¾åæºè½å¤çä¸­å¯¹å¾½æ è¯å«çåºç¨éæ±, <br>æåºäºä¸ç§åºäºæ¨¡ç³éé¶å±åº¦ç¹å¾åè´´è¿åº¦çå¾½æ è¯å«ç®æ³. è¯¥ç®æ³éè¿æå¾½æ ç½æ ¼ç¹å¾æ å°<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:fwLbgJbzo0cJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5162237425629201023&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'fwLbgJbzo0cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:326"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/97264x/201007/34426857.html" class=yC81>åºäºæ¨¡æ¿å¹éå Tesseract çç¥¨æ®å½ç±»åç´¢å¼</a></h3><div class="gs_a">é±ç«å¯ï¼ çæå¹´ï¼ æ±å²ï¼ èå¹³ - è®¡ç®æºä¸ç°ä»£å, 2010 - cqvip.com</div><div class="gs_rs">ç°å¨å¤§éççº¸è´¨å­è¯é½éè¦éè¿æ«æå­å¥è®¡ç®æº, ä½å¦ä½å¯¹è¿äºå­è¯è¿è¡å½ç±»åæ£ç´¢æä¸ºä¸ä¸ª<br>ä¸»è¦é®é¢. éçOCR ææ¯çåå±, å·²æè½¯ä»¶äº§åè½å¤å®ææ«æä»¶çè¯å«åç®¡ç. <br>ä½å¨å¾å¤æåµä¸åªéå¯¹æ«æä»¶è¿è¡å½ç±»åå»ºç«ç´¢å¼, å¹¶ä¸éè¦å¯¹æ´å¼ ç¥¨æ®è¿è¡OCR è¯å«. æ¬æ<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:5kzMhERKRVcJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6288514112838978790&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'5kzMhERKRVcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:325"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB75" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW75"><a href="http://secure.ricoh.co.jp/about/company/technology/techreport/35/pdf/A3502.pdf" class=yC83><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ricoh.co.jp</span><span class="gs_ggsS">ricoh.co.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://secure.ricoh.co.jp/about/company/technology/techreport/35/pdf/A3502.pdf" class=yC82>ææ¸ç»åæ¤ç´¢</a></h3><div class="gs_a">å¾çè¼ï¼ ä¼æ±ç§å¤«ï¼ å¤§é»æ¶ä¹ - Ricoh technical report, 2009 - secure.ricoh.co.jp</div><div class="gs_rs">è¦ æ¨ãªãã£ã¹ææ¸ã®é»å­åãé²ãä¸­, ç»åãã¼ã¿ã®æ¤ç´¢ãã¼ãºãé«ã¾ã£ã¦ãã¦ãã. æ¬è«æã§ã¯, <br>åå®¹ãã¼ã¹ã®ç»åæ¤ç´¢ã®ããã®æ°ããææ³ãææ¡ãã. æãã¯ç»åãã¼ã¿ã®ç¹å¾´ãè¨å·åã, ãã¤ <br>1 æ¬¡ååãããã¨ã§, ãã­ã¹ãæ¤ç´¢ã¨åæ§ã®é«éãªç»åæ¤ç´¢ãå¯è½ã«ãã. ãã®ææ³ã§ã¯, å¯¾è±¡ã¨<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:VIcPmid35aUJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11954091797896988500&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'VIcPmid35aUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md75', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md75" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:VIcPmid35aUJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:324"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> <a href="http://www.cqvip.com/qk/87553a/201001/33327048.html" class=yC84>A novel license plate using HTD and recognition method VTD features</a></h3><div class="gs_a">ZXSPL Liangchao, WWBJZ Wenbo - ä¸­å½å·¥ç¨ç§å­¦: è±æç, 2010 - cqvip.com</div><div class="gs_rs">é¦é¡µ; æåå¤§å¨; ç¥è¯ç¤¾åº; å­¦èç©ºé´; å­¦æ¯æºæ; ä¸é¢å¯¼è¯»; ä¼è®®å±è§; æè²å¹è®­; ç»å½ æ³¨å åå¼ä¸­å¿<br>å®¢æä¸­å¿. ç»´æ®èµè®¯ ä¸­ææåÂ·ä¸ä¸æç« . ç»´æ®ä¸ä¸æ£ç´¢. å·¥ç¨ææ¯ &gt;&gt; èªå¨åè®¡ç®æº &gt;&gt; è®¡ç®æºåºç¨ &gt;&gt;<br>æè¦. A novel license plate using HTD and recognition method VTD features. è¯è®ºæ¨è <b>...</b> </div><div class="gs_fl"><a href="/scholar?q=related:qH7R7BBBqaMJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'qH7R7BBBqaMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:323"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/95216x/200601/22352171.html" class=yC85>ä¸ç§æ°é¢çæ¨¡ç³å­ç¬¦å¾ååå²èªéåºå½¢æå­¦æ¹æ³</a></h3><div class="gs_a">SNK Yamanakaï¼ è«ç¥ - å¾è±¡è¯å«ä¸èªå¨å, 2006 - cqvip.com</div><div class="gs_rs">æ¬ææåºäºä¸ç§æ°é¢çå­ç¬¦åå²ä»¥åä»ä¸»è¦çæ¨¡ç³å¾åä¸­æåç¹å¾ç¢éçèªéåºæ¹æ³. <br>ç®æ³åºäºåå²åæ®µå­ç¬¦ä¹åèªå¨æ£æµçç¢çååå¹¶è¿äºç¢ççç´æ¹å¾æè¿°. <br>å¯¹äºéå å­ç¬¦çåå², å½¢æå­¦åçº§ç®æ³èªå¨ç¡®å®åèçº¿; å¯¹äºè¿æ¥å­ç¬¦çåå², å½¢æå­¦ç»åç®æ³<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:W3Ip9BIaRvUJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'W3Ip9BIaRvUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:322"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB78" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW78"><a href="http://124.16.154.79/infotech/CN/abstract/abstract3188.shtml" class=yC87><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from 124.16.154.79</span><span class="gs_ggsS">124.16.154.79 <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[HTML]</span><span class="gs_ct2">[HTML]</span></span> <a href="http://124.16.154.79/infotech/CN/abstract/abstract3188.shtml" class=yC86>æ°å­ææ¬èµæä¿®å¤ä¸­çå­ç¬¦åå²æ³ååºç¨</a></h3><div class="gs_a">çæå² - ç°ä»£å¾ä¹¦ææ¥ææ¯, 2010 - 124.16.154.79</div><div class="gs_rs">æè¦: ç ç©¶æ°å­ææ¬èµæä¿®å¤æ¨¡å, æåºåºäºæå½±é¢åå²ååºäºå­ç¬¦è¿éæ§äºæ¬¡åå²ç»åçæ¹æ³, <br>å®ç°å¯¹è±ææ°å­ææ¡£ä¸­åºæ¬è±æå­ç¬¦çåç¡®åå², å¹¶éè¿å®éªéªè¯è¯¥æ¹æ³çæææ§åå®ç¨æ§. <br>è¯¥æ¹æ³å·æå¾å¼ºçå¯æ©å±æ§, ä¹å¯ç¨äºä¸­æåå­çåå².</div><div class="gs_fl"><a href="/scholar?q=related:re_S_ChmWOQJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16454013564824514477&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'re_S_ChmWOQJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md78', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md78" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:re_S_ChmWOQJ:scholar.google.com/&amp;hl=en&amp;num=79&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
