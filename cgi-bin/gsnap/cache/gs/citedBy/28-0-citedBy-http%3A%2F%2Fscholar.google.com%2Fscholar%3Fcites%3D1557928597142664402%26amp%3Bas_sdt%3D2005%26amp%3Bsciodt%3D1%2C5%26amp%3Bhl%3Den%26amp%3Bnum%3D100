Total results = 28
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.comp.nus.edu.sg/~tancl/publications/j2008/document%20annotation%20and%20retrieval%20(final%20manuscript).pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4492785" class=yC0>Document image retrieval through word shape coding</a></h3><div class="gs_a"><a href="/citations?user=Fgqq-4kAAAAJ&amp;hl=en&amp;oi=sra">S Lu</a>, L Li, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - Pattern Analysis and Machine Intelligence,  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents a document retrieval technique that is capable of searching <br>document images without optical character recognition (OCR). The proposed technique <br>retrieves document images by a new word shape coding scheme, which captures the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15535907822021277121&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 43</a> <a href="/scholar?q=related:wXXK8tmhmtcJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15535907822021277121&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'wXXK8tmhmtcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://staging.comp.nus.edu.sg/~tancl/publications/j2004/TKDE_2004_LuY.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1339266" class=yC2>Information retrieval in document image databases</a></h3><div class="gs_a">Y Lu, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - &hellip;  and Data Engineering, IEEE Transactions on, 2004 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract With the rising popularity and importance of document images as an information <br>source, information retrieval in document image databases has become a growing and <br>challenging problem. In this paper, we propose an approach with the capability of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18315018101739793021&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 39</a> <a href="/scholar?q=related:faoMKe0DLP4J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/50/1F/RN157518999.html?source=googlescholar" class="gs_nph" class=yC4>BL Direct</a> <a href="/scholar?cluster=18315018101739793021&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 33 versions</a> <a onclick="return gs_ocit(event,'faoMKe0DLP4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://staging.comp.nus.edu.sg/~tancl/publications/c2008/Shiva_Huang.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4669975" class=yC5>An efficient edge based technique for text detection in video frames</a></h3><div class="gs_a">P Shivakumara, W Huang&hellip; - &hellip;  Analysis Systems, 2008.  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Both graphic text and scene text detection in video images with complex <br>background and low resolution is still a challenging and interesting problem for researchers <br>in the field of image processing and computer vision. In this paper, we present a novel <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8855755282162914531&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 36</a> <a href="/scholar?q=related:4xQcY4L25XoJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8855755282162914531&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'4xQcY4L25XoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://www.comp.nus.edu.sg/~tancl/publications/j2008/PR-LuTan-2007.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320307004669" class=yC7>Retrieval of machine-printed Latin documents through Word Shape Coding</a></h3><div class="gs_a"><a href="/citations?user=Fgqq-4kAAAAJ&amp;hl=en&amp;oi=sra">S Lu</a>, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - Pattern Recognition, 2008 - Elsevier</div><div class="gs_rs">This paper reports a document retrieval technique that retrieves machine-printed Latin-<br>based document images through word shape coding. Adopting the idea of image <br>annotation, a word shape coding scheme is proposed, which converts each word image <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5548075066167160378&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 23</a> <a href="/scholar?q=related:Om4YsuC4_kwJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5548075066167160378&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'Om4YsuC4_kwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://arxiv.org/pdf/0806.1446" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arxiv.org</span><span class="gs_ggsS">arxiv.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4761069" class=yC9>Fastwavelet-based visual classification</a></h3><div class="gs_a">G Yuyu, <a href="/citations?user=TcREpMQAAAAJ&amp;hl=en&amp;oi=sra">JJ Slotine</a> - Pattern Recognition, 2008. ICPR 2008.  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We investigate a biologically motivated approach to fast visual classification, <br>directly inspired by the recent work [13]. Specifically, trading-off biological accuracy for <br>computational efficiency, we explore using standard wavelet transforms and patch <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8312914970747933803&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 11</a> <a href="/scholar?q=related:axR1Rx9oXXMJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8312914970747933803&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'axR1Rx9oXXMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://lampsrv02.umiacs.umd.edu/pubs/Papers/Zhu_ICFHR2008/Zhu_ICFHR2008.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from umd.edu</span><span class="gs_ggsS">umd.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://lampsrv02.umiacs.umd.edu/pubs/Papers/Zhu_ICFHR2008/Zhu_ICFHR2008.pdf" class=yCB>Unconstrained language identification using a shape codebook</a></h3><div class="gs_a">G Zhu, X Yu, <a href="/citations?user=JOvBjKMAAAAJ&amp;hl=en&amp;oi=sra">Y Li</a>, <a href="/citations?user=RoGOW9AAAAAJ&amp;hl=en&amp;oi=sra">D Doermann</a> - The 11th International &hellip;, 2008 - lampsrv02.umiacs.umd.edu</div><div class="gs_rs">Abstract We propose a novel approach to language identification in document images <br>containing handwriting and machine printed text using image descriptors constructed from a <br>codebook of shape features. We encode local text structures using scale and rotation <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14315984342074184511&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 7</a> <a href="/scholar?q=related:P9Ni5-iXrMYJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14315984342074184511&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'P9Ni5-iXrMYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md5', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md5" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:P9Ni5-iXrMYJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://figment.cse.usf.edu/~sfefilat/data/papers/ThAT8.33.pdf" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from usf.edu</span><span class="gs_ggsS">usf.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4761176" class=yCD>Unsupervised categorization of heterogeneous text images based on fractals</a></h3><div class="gs_a">B Khelifi, <a href="/citations?user=iOwiu44AAAAJ&amp;hl=en&amp;oi=sra">N Zaghden</a>, MA Alimi&hellip; - &hellip;  Recognition, 2008. ICPR &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper deals about text extraction from heterogeneous documents for <br>categorizing documents and indexing tasks. The purpose of this work is to find similar text <br>regions basing on their fonts. First text regions are extracted, and then font matching is <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9243424458711907706&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 5</a> <a href="/scholar?q=related:ej2uSZI9R4AJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9243424458711907706&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'ej2uSZI9R4AJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://www.umiacs.umd.edu/~zhugy/HandwritingLanguageID_PR2009.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from umd.edu</span><span class="gs_ggsS">umd.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320308005323" class=yCF>Language identification for handwritten document images using a shape codebook</a></h3><div class="gs_a">G Zhu, X Yu, <a href="/citations?user=JOvBjKMAAAAJ&amp;hl=en&amp;oi=sra">Y Li</a>, <a href="/citations?user=RoGOW9AAAAAJ&amp;hl=en&amp;oi=sra">D Doermann</a> - Pattern Recognition, 2009 - Elsevier</div><div class="gs_rs">Language identification for handwritten document images is an open document analysis <br>problem. In this paper, we propose a novel approach to language identification for <br>documents containing mixture of handwritten and machine printed text using image <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=594897776421046110&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 4</a> <a href="/scholar?q=related:Xgc_MWCAQQgJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=594897776421046110&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'Xgc_MWCAQQgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://users.cecs.anu.edu.au/~yili/publication/ContentRecognition_ECCV2008.pdf" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from anu.edu.au</span><span class="gs_ggsS">anu.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/132316841322g102.pdf" class=yC11>Learning visual shape lexicon for document image content recognition</a></h3><div class="gs_a">G Zhu, X Yu, <a href="/citations?user=JOvBjKMAAAAJ&amp;hl=en&amp;oi=sra">Y Li</a>, <a href="/citations?user=RoGOW9AAAAAJ&amp;hl=en&amp;oi=sra">D Doermann</a> - Computer VisionâECCV 2008, 2008 - Springer</div><div class="gs_rs">Developing effective content recognition methods for diverse imagery continues to <br>challenge computer vision researchers. We present a new approach for document image <br>content categorization using a lexicon of shape features. Each lexical word corresponds to <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8327417146706421199&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 3</a> <a href="/scholar?q=related:z-XuPcbtkHMJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8327417146706421199&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'z-XuPcbtkHMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://174.142.16.66/csc/manuscript/Journals/IJIP/volume4/Issue1/IJIP-116.pdf" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 174.142.16.66</span><span class="gs_ggsS">174.142.16.66 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://174.142.16.66/csc/manuscript/Journals/IJIP/volume4/Issue1/IJIP-116.pdf" class=yC13>Wavelet Packet Based Texture Features for Automatic Script Identification</a></h3><div class="gs_a">MC Padma, PA Vijaya - International Journal of Image Processing, 2010 - 174.142.16.66</div><div class="gs_rs">Abstract In a multi script environment, an archive of documents printed in different scripts is <br>in practice. For automatic processing of such documents through Optical Character <br>Recognition (OCR), it is necessary to identify the script type of the document. In this paper, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4806302721690623526&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 4</a> <a href="/scholar?q=related:Jt5cSdxqs0IJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4806302721690623526&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'Jt5cSdxqs0IJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md9', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md9" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Jt5cSdxqs0IJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.183.6204&amp;rep=rep1&amp;type=pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1568294" class=yC15>Word-Wise Thai and Roman Script Identification</a></h3><div class="gs_a">S Chanda, <a href="/citations?user=2_z_CogAAAAJ&amp;hl=en&amp;oi=sra">U Pal</a>, OR Terrades - ACM Transactions on Asian Language  &hellip;, 2009 - dl.acm.org</div><div class="gs_rs">Abstract In some Thai documents, a single text line of a printed document page may contain <br>words of both Thai and Roman scripts. For the Optical Character Recognition (OCR) of such <br>a document page it is better to identify, at first, Thai and Roman script portions and then to <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3600115645428115470&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 4</a> <a href="/scholar?q=related:DqgR9Bou9jEJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3600115645428115470&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'DqgR9Bou9jEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5588751" class=yC17>Texture feature-based language identification using wavelet-domain BDIP, BVLC, and NRMA features</a></h3><div class="gs_a">WS Lee, NC Kim, IH Jang - Machine Learning for Signal  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose a texture feature-based language identification using <br>wavelet-domain BDIP (block difference of inverse probabilities), BVLC (block variance of <br>local correlation coefficients), and NRMA (normalized magnitude) features. The proposed <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16424180593148593189&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 3</a> <a href="/scholar?q=related:JYR8_Tpp7uMJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'JYR8_Tpp7uMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://pdf.aminer.org/000/312/513/multi_font_script_identification_using_texture_based_features.pdf" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aminer.org</span><span class="gs_ggsS">aminer.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4761838" class=yC18>Fractal-based system for Arabic/Latin, printed/handwritten script identification</a></h3><div class="gs_a">S Ben Moussa, A Zahour&hellip; - &hellip; , 2008. ICPR 2008.  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present multilingual automatic identification of Arabic and Latin in <br>both handwritten and printed script. The proposed scheme is based, Firstly, on <br>morphological transform of line text images, secondly on fractal analysis features of both (i<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4087943401586809012&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 2</a> <a href="/scholar?q=related:tNh7ad1KuzgJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4087943401586809012&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'tNh7ad1KuzgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://onlinelibrary.wiley.com/doi/10.1002/ima.20215/abstract" class=yC1A>Subspace models for document script and language identification</a></h3><div class="gs_a"><a href="/citations?user=iRBbGQQAAAAJ&amp;hl=en&amp;oi=sra">TN Vikram</a>, KC Gowda - International Journal of Imaging  &hellip;, 2010 - Wiley Online Library</div><div class="gs_rs">Abstract In this article, we explore the suitability of subspace models like 2DPCA [Yang et al., <br>IEEE Trans Pattern Anal Machine Intelligence 26 (2004), 131â137], 2DFLD [Yang et al., <br>Pattern Recogn 38 (2005), 1125â1129], etc. for document script and language <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7338872097734044412&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 1</a> <a href="/scholar?q=related:_Kp2NUrp2GUJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7338872097734044412&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'_Kp2NUrp2GUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6065508" class=yC1B>Video Script Identification based on Text Lines</a></h3><div class="gs_a"><a href="/citations?user=wAGVhRkAAAAJ&amp;hl=en&amp;oi=sra">TQ Phan</a>, P Shivakumara, Z Ding&hellip; - Document Analysis  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present a new method for video script identification which is <br>essential before choosing an appropriate OCR engine for identifying text lines when a video <br>frame contains more than one language. The input for script identification is the text lines <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5791387435508712030&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 1</a> <a href="/scholar?q=related:XkIoQjAkX1AJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5791387435508712030&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'XkIoQjAkX1AJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ri"><h3 class="gs_rt"><a href="http://inderscience.metapress.com/index/8H16622712528180.pdf" class=yC1C>Local features-based script recognition from printed bilingual document images</a></h3><div class="gs_a">S Abirami, D Manjula - International Journal of Computer Applications  &hellip;, 2010 - Inderscience</div><div class="gs_rs">Classification and identification of language in a biscript document is one of the important <br>steps in the design of an OCR system for successful analysis and recognition. This paper <br>presents architecture for script recognition of bilingual document images (Tamil, English), <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:GzbmGFeOnsIJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14023802794409342491&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'GzbmGFeOnsIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://staging.comp.nus.edu.sg/~tancl/publications/j2010/manuscript.pdf" class=yC1E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/120q6034l05q180r.pdf" class=yC1D>Identification of scripts and orientations of degraded document images</a></h3><div class="gs_a"><a href="/citations?user=Fgqq-4kAAAAJ&amp;hl=en&amp;oi=sra">S Lu</a>, L Li, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - Pattern Analysis &amp; Applications, 2010 - Springer</div><div class="gs_rs">Abstract Document scripts and document orientations are important information for the <br>document digitalization. Prior work has been reported to identify document scripts and <br>document orientations, whereas most reported methods are very sensitive to document <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:tYLSRp1-SkIJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4776769568742998709&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'tYLSRp1-SkIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6011878" class=yC1F>Texture feature-based language identification using Gabor and MDLC features</a></h3><div class="gs_a">IH Jang, NC Kim, MH Park - Multimedia and Expo (ICME), 2011 &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose a texture feature-based language identification using <br>Gabor and MDLC (multi-lag directional local correlation) features. In the proposed method, <br>for a test image, Gabor magnitude images are first obtained by Gabor transform and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Vw4DTu44pdAJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15034485527208463959&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'Vw4DTu44pdAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/H4240328788754HU.pdf" class=yC20>Word Level Script Identification of Text in Low Resolution Images of Display Boards Using Wavelet Features</a></h3><div class="gs_a">SA Angadi, MM Kodabagi - &hellip;  of International Conference on Advances in  &hellip; - Springer</div><div class="gs_rs">Automated systems for understanding low resolution images of display boards are <br>facilitating several new applications such as blind assistants, tour guide systems, location <br>aware systems and many more. Script identification at character/word level is one of the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:BuZciFIviAkJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'BuZciFIviAkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="http://www.caa.tuwien.ac.at/cvl/research/tr/pdf/tr2.pdf" class=yC22><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tuwien.ac.at</span><span class="gs_ggsS">tuwien.ac.at <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.caa.tuwien.ac.at/cvl/research/tr/pdf/tr2.pdf" class=yC21>On the Combination of Spatial and Spectral Features for Image Restoration</a></h3><div class="gs_a">M Lettner, R Sablatnig - 2010 - caa.tuwien.ac.at</div><div class="gs_rs">Abstract The application of multispectral imaging is a well known method for the analysis <br>and digitization of decayed manuscripts. The main advantage in analyzing multiple spectral <br>ranges, including the ultraviolet and infrared range, is the additional information which is <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:iPfQiYg26dYJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15485968753745786760&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'iPfQiYg26dYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md19', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md19" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:iPfQiYg26dYJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ijidcs.org/issues/v2n1/ijidcs-14-109-119.pdf" class=yC23>Design and Development of a Script Recognition Tool for Indian Document Images</a></h3><div class="gs_rs"><a href="https://support.google.com/websearch/bin/answer.py?answer=45449&hl=en">This site may harm your computer.</a></div><div class="gs_a">S Sharmila, S Abirami, S Murukappan, R Bhaskaran - International Journal - ijidcs.org</div><div class="gs_rs">AbstractâIdentification of scripts from multi-script document is one of the important steps in <br>the design of an OCR system for successful analysis and recognition. Most optical character <br>recognition (OCR) systems can recognize at most a few scripts. But for large archives of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5444593029727666865&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=28">Cited by 1</a> <a href="/scholar?q=related:sUJ8i4MUj0sJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5444593029727666865&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'sUJ8i4MUj0sJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md20', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md20" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:sUJ8i4MUj0sJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="http://144.206.159.178/FT/CONF/16427826/16427860.pdf" class=yC25><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 144.206.159.178</span><span class="gs_ggsS">144.206.159.178 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://proceedings.spiedigitallibrary.org/data/Conferences/SPIEP/17609/72470Z_1.pdf" class=yC24>Script Identification of Handwritten Images</a></h3><div class="gs_a"><a href="/citations?user=U-KH6j4AAAAJ&amp;hl=en&amp;oi=sra">A Bhardwaj</a>, H Cao&hellip; - &hellip;  of SPIE, the  &hellip;, 2009 - proceedings.spiedigitallibrary.org</div><div class="gs_rs">ABSTRACT This paper describes a system for script identification of handwritten word <br>images. The system is divided into two main phases, training and testing. The training phase <br>performs a moment based feature extraction on the training word images and generates <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:jtPgk72Dbi8J:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3417814017473827726&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'jtPgk72Dbi8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB22" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW22"><a href="http://etd.aau.edu.et/dspace/bitstream/123456789/4134/1/final_revised6.pdf" class=yC27><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aau.edu.et</span><span class="gs_ggsS">aau.edu.et <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://etd.aau.edu.et/dspace/handle/123456789/4134" class=yC26>SCHOOL OF GRADUATE STUDIES SCHOOL OF INFORMATION SCIENCE</a></h3><div class="gs_a">A SAMUEL - 2012 - etd.aau.edu.et</div><div class="gs_rs">Abstract: Computer technology enabled humans to process, store, retrieve and disseminate <br>information with much flexibility and ease. As a result of this, vast amount of information is <br>being digitized. Currently, digital libraries are digitizing printed documents in order to offer <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'MWZ5l1XjdvQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB23" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW23"><a href="http://www.cvc.uab.es/icdar2009/papers/3725b191.pdf" class=yC29><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uab.es</span><span class="gs_ggsS">uab.es <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5277617" class=yC28>Separate Chinese Character and English Character by Cascade Classifier and Feature Selection</a></h3><div class="gs_a">Y Zhu, J Sun, A Minagawa, Y Hotta&hellip; - Document Analysis and  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The separation of Chinese character and English character is helpful for OCR <br>technique. In this paper, a multi-level cascade classifier combined with feature selection is <br>constructed to identify Chinese character and English character based on individual <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:yMuTnU-YTAUJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=381847536133196744&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'yMuTnU-YTAUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB24" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW24"><a href="http://www.icpr2010.org/pdfs/icpr2010_WeBT6.3.pdf" class=yC2B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from icpr2010.org</span><span class="gs_ggsS">icpr2010.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5597017" class=yC2A>Script IdentificationâA Han and Roman Script Perspective</a></h3><div class="gs_a">S Chanda, <a href="/citations?user=2_z_CogAAAAJ&amp;hl=en&amp;oi=sra">U Pal</a>, <a href="/citations?user=9RDx_xwAAAAJ&amp;hl=en&amp;oi=sra">K Franke</a>&hellip; - Pattern Recognition (ICPR &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract All Han-based scripts (Chinese, Japanese, and Korean) possess similar visual <br>characteristics. Hence system development for identification of Chinese, Japanese and <br>Korean scripts from a single document page is quite challenging. It is noted that a Han-<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:jGFsq0pYWhcJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1682754488503132556&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'jGFsq0pYWhcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6195331" class=yC2C>New Spatial-Gradient-Features for Video Script Identification</a></h3><div class="gs_a">D Zhao, P Shivakumara, <a href="/citations?user=Fgqq-4kAAAAJ&amp;hl=en&amp;oi=sra">S Lu</a>&hellip; - &hellip;  Analysis Systems (DAS),  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present new features based on Spatial-Gradient-Features (SGF) at <br>block level for identifying six video scripts namely, Arabic, Chinese, English, Japanese, <br>Korean and Tamil. This works helps in enhancing the capability of the current OCR on <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ht1usu_4H2EJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6998586054331522438&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'ht1usu_4H2EJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Image Registration for Digital Collation</h3><div class="gs_a">JW Waggoner, J Zhou, R Cream, <a href="/citations?user=eycXl_QAAAAJ&amp;hl=en&amp;oi=sra">S Wang</a></div><div class="gs_fl"><a href="/scholar?q=related:9-y9_k1xRMMJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'9-y9_k1xRMMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.dbpia.co.kr/Article/?arid=1665370&amp;arid=1665370" class=yC2D>Gabor í¹ì§ê³¼ ì¨ì´ë¸ë  ìì­ì BDIP ì BVLC í¹ì§ì ì´ì©í ì§ê° í¹ì§ ê¸°ë° ì¸ì´ ì¸ì</a></h3><div class="gs_a">ê¹ë¨ì²  - é»å­å·¥å­¸æï¥æèª, 2011 - dbpia.co.kr</div><div class="gs_rs">ë³¸ ë¼ë¬¸ììë Gabor í¹ì§ê³¼ ì¨ì´ë¸ë  ìì­ì BDIP ì BVLC í¹ì§ì ì´ì©í ì§ê° í¹ì§ ê¸°ë° <br>ì¸ì´ ì¸ì ë°©ë²ì ì ìíë¤. ì ìë ë°©ë²ììë ë¨¼ì  ìí ììì Gabor ë³íê³¼ ì¨ì´ë¸ë  <br>ë³íì ì ì©íë¤. ì¨ì´ë¸ë  ìì­ì ìì¸ ëì­ìë Donoho ì ì°ì­ì¹íë¥¼ ì ì©íì¬ ì¡ìì <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:zOAfngNzF2wJ:scholar.google.com/&amp;hl=en&amp;num=28&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'zOAfngNzF2wJ')" href="#" class="gs_nph">Cite</a></div></div></div>
