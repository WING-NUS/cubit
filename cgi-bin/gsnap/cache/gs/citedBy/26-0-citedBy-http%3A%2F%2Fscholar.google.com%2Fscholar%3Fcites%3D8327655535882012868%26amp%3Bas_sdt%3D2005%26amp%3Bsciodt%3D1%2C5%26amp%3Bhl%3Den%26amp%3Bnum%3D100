Total results = 26
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://pdf.aminer.org/000/502/603/content_based_music_structure_analysis_with_applications_to_music_semantics.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aminer.org</span><span class="gs_ggsS">aminer.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1027549" class=yC0>Content-based music structure analysis with applications to music semantics understanding</a></h3><div class="gs_a">NC Maddage, C Xu, MS Kankanhalli&hellip; - Proceedings of the 12th  &hellip;, 2004 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we present a novel approach for music structure analysis. A new <br>segmentation method, beat space segmentation, is proposed and used for music chord <br>detection and vocal/instrumental boundary detection. The wrongly detected chords in the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5128485784761225038&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 102</a> <a href="/scholar?q=related:Tk9VPKYKLEcJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5128485784761225038&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'Tk9VPKYKLEcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://www.comp.nus.edu/~kanmy/dossier/papers/p1568934817-wang.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu</span><span class="gs_ggsS">nus.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1027576" class=yC2>LyricAlly: automatic synchronization of acoustic musical signals and textual lyrics</a></h3><div class="gs_a">Y Wang, <a href="/citations?user=aNVcd3EAAAAJ&amp;hl=en&amp;oi=sra">MY Kan</a>, TL Nwe, A Shenoy, J Yin - Proceedings of the 12th  &hellip;, 2004 - dl.acm.org</div><div class="gs_rs">Abstract We present a prototype that automatically aligns acoustic musical signals with their <br>corresponding textual lyrics, in a manner similar to manually-aligned karaoke. We tackle this <br>problem using a multimodal approach, where the appropriate pairing of audio and text <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10802878761400089986&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 61</a> <a href="/scholar?q=related:gj3dVP-I65UJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10802878761400089986&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 36 versions</a> <a onclick="return gs_ocit(event,'gj3dVP-I65UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www.comp.nus.edu.sg/~mohan/papers/music_struct_det.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1580435" class=yC4>Automatic structure detection for popular music</a></h3><div class="gs_a">NC Maddage - Multimedia, IEEE, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Our proposed approach detects music structures by looking at beat-space <br>segmentation, chords, singing-voice boundaries, and melody-and content-based similarity <br>regions. Experiments illustrate that the proposed approach is capable of extracting useful <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7556639789070752933&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 36</a> <a href="/scholar?q=related:pRwl89mT3mgJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/3D/1C/RN183745851.html?source=googlescholar" class="gs_nph" class=yC6>BL Direct</a> <a href="/scholar?cluster=7556639789070752933&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'pRwl89mT3mgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://www.comp.nus.edu.sg/~wangye/papers/1.Audio_and_Music_Analysis_and_Retrieval/2004_Singing_Voice_Detection_in_Popular_Music.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1027602" class=yC7>Singing voice detection in popular music</a></h3><div class="gs_a">TL Nwe, A Shenoy, Y Wang - Proceedings of the 12th annual ACM  &hellip;, 2004 - dl.acm.org</div><div class="gs_rs">Abstract We propose a novel technique for the automatic classification of vocal and non-<br>vocal regions in an acoustic musical signal. Our technique uses a combination of harmonic <br>content attenuation using higher level musical knowledge of key followed by sub-band <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3838002631248715374&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 34</a> <a href="/scholar?q=related:bh6Y-g5TQzUJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3838002631248715374&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 22 versions</a> <a onclick="return gs_ocit(event,'bh6Y-g5TQzUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1385971" class=yC9>Music key detection for musical audio</a></h3><div class="gs_a">Y Zhu, MS Kankanhalli, S Gao - &hellip;  Modelling Conference, 2005.  &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The key or the scale information of a piece of music provides important clues on its <br>high level musical content, like harmonic and melodic context, which can be useful for music <br>classification, retrieval or further content analysis. Researchers have previously <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7434925632944995437&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 30</a> <a href="/scholar?q=related:bfwho3gpLmcJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7434925632944995437&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'bfwho3gpLmcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1632042" class=yCA>Precise pitch profile feature extraction from musical audio for key detection</a></h3><div class="gs_a">Y Zhu, MS Kankanhalli - Multimedia, IEEE Transactions on, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The majority of pieces of music, including classical and popular music, are <br>composed using music scales, such as keys. The key or the scale information of a piece <br>provides important clues on its high level musical content, like harmonic and melodic <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1730195481115303665&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 26</a> <a href="/scholar?q=related:8R7dg5_jAhgJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/4E/2F/RN196047096.html?source=googlescholar" class="gs_nph" class=yCB>BL Direct</a> <a href="/scholar?cluster=1730195481115303665&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'8R7dg5_jAhgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.119.3200&amp;rep=rep1&amp;type=pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4432643" class=yCC>LyricAlly: Automatic synchronization of textual lyrics to acoustic music signals</a></h3><div class="gs_a"><a href="/citations?user=aNVcd3EAAAAJ&amp;hl=en&amp;oi=sra">MY Kan</a>, Y Wang, D Iskandar, TL New&hellip; - Audio, Speech, and  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We present LyricAlly, a prototype that automatically aligns acoustic musical signals <br>with their corresponding textual lyrics, in a manner similar to manually-aligned karaoke. We <br>tackle this problem based on a multimodal approach, using an appropriate pairing of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6994750038097962320&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 27</a> <a href="/scholar?q=related:UKV6kRlYEmEJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/47/0A/RN222855432.html?source=googlescholar" class="gs_nph" class=yCE>BL Direct</a> <a href="/scholar?cluster=6994750038097962320&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'UKV6kRlYEmEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1112857" class=yCF>Key, chord, and rhythm tracking of popular music recordings</a></h3><div class="gs_a">A Shenoy, Y Wang - Computer Music Journal, 2005 - dl.acm.org</div><div class="gs_rs">In this article, we propose a framework to analyze a musical audio signal (sampled from a <br>popular music CD) and determine its key, provide usable chord transcriptions, and obtain <br>the hierarchical rhythm structure representation comprising the quarternote, half-note, and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16290336487138294495&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 22</a> <a href="/scholar?q=related:33p2o7nmEuIJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/2E/0B/RN175256451.html?source=googlescholar" class="gs_nph" class=yC10>BL Direct</a> <a href="/scholar?cluster=16290336487138294495&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'33p2o7nmEuIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://ispl.korea.ac.kr/conference/ICASSP2007/pdfs/0200481.pdf" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from korea.ac.kr</span><span class="gs_ggsS">korea.ac.kr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4217450" class=yC11>Pitch detection in polyphonic music using instrument tone models</a></h3><div class="gs_a"><a href="/citations?user=OCQSEIsAAAAJ&amp;hl=en&amp;oi=sra">Y Li</a>, <a href="/citations?user=yO59sggAAAAJ&amp;hl=en&amp;oi=sra">DL Wang</a> - &hellip;  Speech and Signal Processing, 2007. ICASSP &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We propose a hidden Markov model (HMM) based system to detect the pitch of an <br>instrument in polyphonic music using an instrument tone model. Our system calculates at <br>every time frame the salience of a pitch hypothesis based on the magnitudes of harmonics <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2571832681359691472&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 21</a> <a href="/scholar?q=related:0E4vkjL8sCMJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2571832681359691472&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'0E4vkjL8sCMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="https://www1.comp.nus.edu.sg/~wangye/papers/1.Audio_and_Music_Analysis_and_Retrieval/2005_Singing_Voice_Detection_for_Karaoke_Application.pdf" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=876255" class=yC13>Singing voice detection for karaoke application</a></h3><div class="gs_a">A Shenoy, Y Wu, Y Wang - Visual  &hellip;, 2005 - proceedings.spiedigitallibrary.org</div><div class="gs_rs">abstract We present a framework to detect the regions of singing voice in musical audio <br>signals. This work is oriented towards the development of a robust transcriber of lyrics for <br>karaoke applications. The technique leverages on a combination of low-level audio <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12185904537651465050&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 11</a> <a href="/scholar?q=related:WkuJAZ0HHakJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/3A/63/RN177222664.html?source=googlescholar" class="gs_nph" class=yC15>BL Direct</a> <a href="/scholar?cluster=12185904537651465050&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 17 versions</a> <a onclick="return gs_ocit(event,'WkuJAZ0HHakJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://wwwiti.cs.uni-magdeburg.de/~stober/publ/cbmi2008.pdf" class=yC17><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uni-magdeburg.de</span><span class="gs_ggsS">uni-magdeburg.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4564924" class=yC16>Enhancing chord classification through neighbourhood histograms</a></h3><div class="gs_a">J Reinhard, S Stober&hellip; - Content-Based Multimedia  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The chord progression of a song is an important high-level feature which enables <br>indexing as well as deeper analysis of musical recordings. Different approaches to chord <br>recognition have been suggested in the past. Though their performance increased, still <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10861208389787583936&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 7</a> <a href="/scholar?q=related:wAXIQHzDupYJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10861208389787583936&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'wAXIQHzDupYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://www.laurentoudre.fr/publis/OGF-IEEE-11.pdf" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from laurentoudre.fr</span><span class="gs_ggsS">laurentoudre.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5742981" class=yC18>Chord recognition by fitting rescaled chroma vectors to chord templates</a></h3><div class="gs_a"><a href="/citations?user=aSXlodEAAAAJ&amp;hl=en&amp;oi=sra">L Oudre</a>, Y Grenier, <a href="/citations?user=kAWEUq0AAAAJ&amp;hl=en&amp;oi=sra">C FÃ©votte</a> - Audio, Speech, and Language  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose a simple and fast method for chord recognition in music <br>signals. We extract a chromagram from the signal which transcribes the harmonic content of <br>the piece over time. We introduce a set of chord templates taking into account one or more <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17014428265094300295&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 7</a> <a href="/scholar?q=related:h8JPXVxkH-wJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17014428265094300295&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'h8JPXVxkH-wJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.mitpressjournals.org/doi/abs/10.1162/comj.2008.32.1.71" class=yC1A>Complexity-scalable beat detection with MP3 audio bitstreams</a></h3><div class="gs_a">J Zhu, Y Wang - Computer Music Journal, 2008 - MIT Press</div><div class="gs_rs">72 Computer Music Journal greatly limits their application, because it is not easy to obtain <br>complete MIDI representations of real-world acoustic signals. Such models suffer from the <br>scaling-up problem (Kitano 1993). Recent systems work with PCM audio bitstreams. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15871359328518311526&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 4</a> <a href="/scholar?q=related:Zo7qHjhlQtwJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/50/35/RN225441503.html?source=googlescholar" class="gs_nph" class=yC1B>BL Direct</a> <a href="/scholar?cluster=15871359328518311526&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'Zo7qHjhlQtwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/r8w711w22m350441.pdf" class=yC1C>Extracting the key from music</a></h3><div class="gs_a">S Pauws - Intelligent Algorithms in Ambient and Biomedical  &hellip;, 2006 - Springer</div><div class="gs_rs">Abstract Extracting a sense of key from music audio is indispensable for various unequalled <br>end-user applications dealing with music playback. This chapter presents an audio key <br>extraction algorithm that is based on models of human auditory perception and music <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5609843230841316976&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 4</a> <a href="/scholar?q=related:cCbtO7Iq2k0J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'cCbtO7Iq2k0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="https://qmro.qmul.ac.uk/xmlui/bitstream/handle/123456789/534/HARTETowardsAutomatic2010.pdf?sequence=1" class=yC1E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from qmul.ac.uk</span><span class="gs_ggsS">qmul.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="https://qmro.qmul.ac.uk/xmlui/handle/123456789/534" class=yC1D>Towards automatic extraction of harmony information from music signals</a></h3><div class="gs_a"><a href="/citations?user=KUW54BsAAAAJ&amp;hl=en&amp;oi=sra">C Harte</a> - 2010 - qmro.qmul.ac.uk</div><div class="gs_rs">In this thesis we address the subject of automatic extraction of harmony information from <br>audio recordings. We focus on chord symbol recognition and methods for evaluating <br>algorithms designed to perform that task. We present a novel six-dimensional model for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16895747196309534705&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 3</a> <a href="/scholar?q=related:8ffUuo7AeeoJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16895747196309534705&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'8ffUuo7AeeoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://hal.inria.fr/docs/00/54/89/52/PDF/Papadopoulos_Thesis.pdf" class=yC20><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from inria.fr</span><span class="gs_ggsS">inria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://hal.inria.fr/docs/00/54/89/52/PDF/Papadopoulos_Thesis.pdf" class=yC1F>Joint estimation of musical content information from an audio signal</a></h3><div class="gs_a">H Papadopoulos - 2010 - hal.inria.fr</div><div class="gs_rs">RÃ©sumÃ© Dans cette these, nous nous intÃ©ressons au probleme de l&#39;extraction automatique <br>d&#39;informations de contenu d&#39;un signal audio de musique. La plupart des travaux existants <br>abordent ce probleme en considÃ©rant les attributs musicaux de maniere indÃ©pendante les <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5504565459161893914&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 4</a> <a href="/scholar?q=related:Gsw65B4lZEwJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Gsw65B4lZEwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md15', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md15" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Gsw65B4lZEwJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a>  <a href="/scholar?q=info:Gsw65B4lZEwJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=14696771562731948953&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Scalar theory and knowledge discovery in the recording industry</h3><div class="gs_a"><a href="/citations?user=MclvcTIAAAAJ&amp;hl=en&amp;oi=sra">R Lewis</a> - The Twenty Second International Conference on  &hellip;, 2008</div><div class="gs_fl"><a href="/scholar?cites=3778067034053930096&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 1</a> <a href="/scholar?q=related:cOxlTvNjbjQJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3778067034053930096&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'cOxlTvNjbjQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.tandfonline.com/doi/abs/10.1080/09298215.2011.618543" class=yC21>Music Theoretic and Perception-based Features for Audio Key Determination</a></h3><div class="gs_a"><a href="/citations?user=TxKNCSoAAAAJ&amp;hl=en&amp;oi=sra">B Schuller</a>, B Gollan - Journal of New Music Research, 2012 - Taylor &amp; Francis</div><div class="gs_rs">Abstract The musical key of a piece is the fundamental knowledge for many Music <br>Information Retrieval tasks as automatic transcription, chord detection or automatic play list <br>generation. To this end, novel features are proposed and evaluated on the basis of <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:k9rwCjMcUIoJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9966496980923374227&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'k9rwCjMcUIoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB18" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW18"><a href="http://hal.archives-ouvertes.fr/docs/00/65/57/81/PDF/PapadopoulosPeeters_LcalKey_IEEE_2011.pdf" class=yC23><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6074928" class=yC22>Local Key Estimation from an Audio Signal Relying on Harmonic and Metrical Structures</a></h3><div class="gs_a">H Papadopoulos, G Peeters - Audio, Speech, and Language  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present a method for estimating the progression of musical key <br>from an audio signal. We address the problem of local key finding by investigating the <br>possible combination and extension of different previously proposed approaches for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6634530592485010227&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=26">Cited by 1</a> <a href="/scholar?q=related:M-uHMGyWElwJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6634530592485010227&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'M-uHMGyWElwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="http://w.comp.nus.edu/undergraduates/undergraduates/urop_papers/LuongMinhThang_U056889M.pdf" class=yC25><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu</span><span class="gs_ggsS">nus.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://w.comp.nus.edu/undergraduates/undergraduates/urop_papers/LuongMinhThang_U056889M.pdf" class=yC24>A repetition-based framework for lyric alignment in popular songs</a></h3><div class="gs_a">LM Thang, KANM Yen - National University of Singapore  &hellip;, 2007 - w.comp.nus.edu</div><div class="gs_rs">ABSTRACT We examine the problem of automatically aligning acoustic musical audio and <br>textual lyric in popular songs. Existing works have tackled the problem using <br>computationally-expensive audio processing techniques, resulting in solutions unsuitable <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:1_WYP4tF_fMJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17581284984694044119&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 27 versions</a> <a onclick="return gs_ocit(event,'1_WYP4tF_fMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md19', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md19" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:1_WYP4tF_fMJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/FT671731J0403662.pdf" class=yC26>A Survey of Music Structure Analysis Techniques for Music Applications</a></h3><div class="gs_a">N Maddage, <a href="/citations?user=z8_x7C8AAAAJ&amp;hl=en&amp;oi=sra">H Li</a>, M Kankanhalli - Recent Advances in Multimedia Signal  &hellip;, 2009 - Springer</div><div class="gs_rs">Music carries multilayer information which forms different structures. The information <br>embedded in the music can be categorized into time information, harmony/melody, music <br>regions, music similarities, song structures and music semantics. In this chapter, we first <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:3vo8SvZRZuUJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16529989600559299294&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'3vo8SvZRZuUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Singing Voice Detection in Western Popular Music</h3><div class="gs_a">W Yuansheng</div><div class="gs_fl"><a href="/scholar?q=related:dx-cdoqIEO4J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'dx-cdoqIEO4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6012032" class=yC27>Solo to a capella conversion-Synthesizing vocal harmony from lead vocals</a></h3><div class="gs_a">PY Chan, M Dong, SW Lee&hellip; - Multimedia and Expo ( &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents our work in the automatic synthesis of vocal harmony. Existing <br>innovations either allow for dissonances (ie non-harmonious or clashing intervals) at various <br>locations or require some musical ability of the user. We have developed a method that is <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:fU1lqjRY0l8J:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6904678161932701053&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'fU1lqjRY0l8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB23" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW23"><a href="http://laurentoudre.fr/publis/LO-PHDfr-10.pdf" class=yC29><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from laurentoudre.fr</span><span class="gs_ggsS">laurentoudre.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://laurentoudre.fr/publis/LO-PHDfr-10.pdf" class=yC28>Laurent OUDRE</a></h3><div class="gs_a">DE Rapporteurs, S Marchand - laurentoudre.fr</div><div class="gs_rs">Ce premier chapitre vise Ã  introduire les principales notions musicales nÃ©cessaires Ã  la <br>bonne comprÃ©hension du prÃ©sent document, mais aussi Ã  prÃ©ciser le contexte et les <br>principales applications de ce travail de thÃ¨se.</div><div class="gs_fl"><a href="/scholar?q=related:PPdVPuMCoxEJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1270862694875264828&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'PPdVPuMCoxEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md23', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md23" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:PPdVPuMCoxEJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB24" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW24"><a href="http://tel.archives-ouvertes.fr/docs/00/54/28/40/PDF/These_fr_en.pdf" class=yC2B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://tel.archives-ouvertes.fr/pastel-00542840/" class=yC2A>Reconnaissance d&#39;accords Ã  partir de signaux audio par l&#39;utilisation de gabarits thÃ©oriques</a></h3><div class="gs_a"><a href="/citations?user=aSXlodEAAAAJ&amp;hl=en&amp;oi=sra">L Oudre</a> - 2010 - tel.archives-ouvertes.fr</div><div class="gs_rs">RÃ©sumÃ© Cette thÃ¨se s&#39; inscrit dans le cadre du traitement du signal musical, en se focalisant <br>plus particuliÃ¨rement sur la transcription automatique de signaux audio en accords. En effet, <br>depuis une dizaine d&#39;annÃ©es, de nombreux travaux visent Ã  reprÃ©senter les signaux <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:afhmW5HEmVcJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6312292481319237737&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'afhmW5HEmVcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB25" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW25"><a href="http://tel.archives-ouvertes.fr/docs/00/54/89/52/PDF/Papadopoulos_Thesis.pdf" class=yC2D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://tel.archives-ouvertes.fr/tel-00548952/" class=yC2C>Estimation conjointe d&#39;information de contenu musical d&#39;un signal audio</a></h3><div class="gs_a">H Papadopoulos - 2010 - tel.archives-ouvertes.fr</div><div class="gs_rs">RÃ©sumÃ© Dans cette these, nous nous intÃ©ressons au probleme de l&#39;extraction automatique <br>d&#39;informations de contenu d&#39;un signal audio de musique. La plupart des travaux existants <br>abordent ce probleme en considÃ©rant les attributs musicaux de maniere indÃ©pendante les <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:B-SObITZT2wJ:scholar.google.com/&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7804695842036573191&amp;hl=en&amp;num=26&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'B-SObITZT2wJ')" href="#" class="gs_nph">Cite</a></div></div></div>
