Total results = 14
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://siddiqi.com/sajid/papers/ramos-siddiqi-etal.audioclassify.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from siddiqi.com</span><span class="gs_ggsS">siddiqi.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5495605" class=yC0>Automatic state discovery for unstructured audio scene classification</a></h3><div class="gs_a">J Ramos, S Siddiqi, A Dubrawski&hellip; - &hellip;  Speech and Signal  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper we present a novel scheme for unstructured audio scene classification <br>that possesses three highly desirable and powerful features: autonomy, scalability, and <br>robustness. Our scheme is based on our recently introduced machine learning algorithm <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7583873426922224927&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14">Cited by 4</a> <a href="/scholar?q=related:Hz05YbNUP2kJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7583873426922224927&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'Hz05YbNUP2kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://ismir2009.ismir.net/proceedings/OS9-5.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ismir.net</span><span class="gs_ggsS">ismir.net <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://ismir2009.ismir.net/proceedings/OS9-5.pdf" class=yC2>Music and geography: Content description of musical audio from different parts of the world</a></h3><div class="gs_a"><a href="/citations?user=09PV4lsAAAAJ&amp;hl=en&amp;oi=sra">E GÃ³mez</a>, M Haro, <a href="/citations?user=x4X0Ia8AAAAJ&amp;hl=en&amp;oi=sra">P Herrera</a> - Proc. of ISMIR, 2009 - ismir2009.ismir.net</div><div class="gs_rs">ABSTRACT This paper analyses how audio features related to different musical facets can <br>be useful for the comparative analysis and classification of music from diverse parts of the <br>world. The music collection under study gathers around 6,000 pieces, including traditional <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11996787996217229706&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14">Cited by 3</a> <a href="/scholar?q=related:isEy8B4nfaYJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11996787996217229706&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'isEy8B4nfaYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md1', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md1" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:isEy8B4nfaYJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www.music.mcgill.ca/~ich/classes/mumt621_09/presentations/germain/Final_Project_Report.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mcgill.ca</span><span class="gs_ggsS">mcgill.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.music.mcgill.ca/~ich/classes/mumt621_09/presentations/germain/Final_Project_Report.pdf" class=yC4>The wavelet transform Applications in Music Information Retrieval</a></h3><div class="gs_a">F Germain - McGill University, Canada, December, 2009 - music.mcgill.ca</div><div class="gs_rs">Abstract In this report, we present an overview of existing literature about wavelet-based <br>approaches in music information retrieval (MIR). Indeed, we wants to analyze the <br>possibilities of this novel and popular transform in this particular field. in a first time, we <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12074347272232052878&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14">Cited by 2</a> <a href="/scholar?q=related:jigZGN-ykKcJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12074347272232052878&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'jigZGN-ykKcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md2', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md2" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:jigZGN-ykKcJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://www.comp.nus.edu.sg/~wangye/papers/2.Applications_in_e-Health/2010_A_Music_Search_Engine_for_Therapeutic_Gait_Training.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1874037" class=yC6>A music search engine for therapeutic gait training</a></h3><div class="gs_a"><a href="/citations?user=TF8WdBMAAAAJ&amp;hl=en&amp;oi=sra">Z Li</a>, Q Xiang, J Hockman, J Yang, Y Yi&hellip; - Proceedings of the  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract A music retrieval system is introduced that incorporate tempo, cultural, and beat <br>strength features to help music therapists provide appropriate music for gait training for <br>Parkinson&#39;s patients. Unlike current methods available to music therapists (eg, personal <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15726831979121291272&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14">Cited by 3</a> <a href="/scholar?q=related:CDDHVVzuQNoJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15726831979121291272&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'CDDHVVzuQNoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ADA515929" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from dtic.mil</span><span class="gs_ggsS">dtic.mil <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://oai.dtic.mil/oai/oai?verb=getRecord&amp;metadataPrefix=html&amp;identifier=ADA515929" class=yC8>Learning Latent Variable and Predictive Models of Dynamical Systems</a></h3><div class="gs_a">SM Siddiqi - 2009 - DTIC Document</div><div class="gs_rs">Abstract: In this thesis we propose novel learning algorithms that address the issues of <br>model selection, local minima and instability in learning latent variable models. We show <br>that certain&#39;predictive&#39;latent variable model learning methods bridge the gap between <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18373489670929809201&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14">Cited by 2</a> <a href="/scholar?q=related:MX8UQIK_-_4J:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18373489670929809201&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'MX8UQIK_-_4J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md4', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md4" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:MX8UQIK_-_4J:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=13616896268779128428&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://lsas2008.dke-research.de/conftool/uploads/158/10-Sturm20121212.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from dke-research.de</span><span class="gs_ggsS">dke-research.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://lsas2008.dke-research.de/conftool/uploads/158/10-Sturm20121212.pdf" class=yCA>A survey of evaluation in music genre recognition</a></h3><div class="gs_a"><a href="/citations?user=KdeYIvMAAAAJ&amp;hl=en&amp;oi=sra">BL Sturm</a> - Proc. Adaptive Multimedia Retrieval.  &hellip;, 2012 - lsas2008.dke-research.de</div><div class="gs_rs">Abstract. Much work is focused upon music genre recognition (MGR) from audio recordings, <br>symbolic data, and other modalities. While reviews have been written of some of this work <br>before, no survey has been made of the approaches to evaluating approaches to MGR. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4253992352053677712&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14">Cited by 1</a> <a onclick="return gs_ocit(event,'kE5jbYE3CTsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md5', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md5" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:kE5jbYE3CTsJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Web Music Indexing and Search</h3><div class="gs_a">L Lu, Z Li</div><div class="gs_fl"><a href="/scholar?q=related:r9qlLF4oNbMJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'r9qlLF4oNbMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2160791" class=yCC>Traditional and folk melody classifier on culture style using Markov models and neural networks</a></h3><div class="gs_a"><a href="/citations?user=p0B3Nv0AAAAJ&amp;hl=en&amp;oi=sra">C Karunatilake</a>, S Nishimura, M Osano - Proceedings of the 2012 Joint  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract Music plays a vital role in any culture despite whether it is primary or modern and it <br>is a good indicator reflecting the nature of the culture where it has been produced. Music <br>traditions were developed even in the pre-historic periods when people did not have a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:AB-hS3XCY6AJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'AB-hS3XCY6AJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://nomislui.net/resources/Paper/2010-AES.pdf" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nomislui.net</span><span class="gs_ggsS">nomislui.net <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.aes.org/e-lib/browse.cfm?elib=15744" class=yCD>Retargeting Expressive Musical Style from Classical Music Recordings Using a Support Vector Machine</a></h3><div class="gs_a">S Lui, A Horner, C So - Watermark, 2012 - aes.org</div><div class="gs_rs">A method for transferring the expressive musical nuances of real recordings to a MIDI <br>synthesized version was successfully demonstrated. Three features (dynamics, tempo, and <br>articulation) were extracted from the recordings and then applied to the MIDI note list in <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:KYuKWFEzljUJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3861330154987621161&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'KYuKWFEzljUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://www.ee.iitb.ac.in/web/files/publications/VidwansPJan2012.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from iitb.ac.in</span><span class="gs_ggsS">iitb.ac.in <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ee.iitb.ac.in/web/files/publications/VidwansPJan2012.pdf" class=yCF>Identifying Indian Classical Music Styles using Melodic Contours</a></h3><div class="gs_a">A Vidwans, P Rao - ee.iitb.ac.in</div><div class="gs_rs">Abstract A prominent categorization of Indian classical music is the Hindustani and Carnatic <br>traditions. The distinction is geographical with the two styles having evolved under distinctly <br>different historical and cultural influences. Both styles are grounded in the melodic and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4027195861526768183&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=14">Cited by 2</a> <a href="/scholar?q=related:N-o5j0x54zcJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4027195861526768183&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'N-o5j0x54zcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md9', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md9" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:N-o5j0x54zcJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2095679" class=yC11>Artist filtering for non-western music classification</a></h3><div class="gs_a">A Kruspe, H Lukashevich, J AbeÃer - &hellip; of the 6th Audio Mostly Conference &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract The&quot; album effect&quot; is a known phenomenon in musical artist and genre recognition. <br>Classification results are often better when songs from the same album are used in the <br>training and evaluation data sets. Supposedly, this effect is caused by the production <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ZIgzlvMbfdMJ:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'ZIgzlvMbfdMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2396458" class=yC12>A domain-specific music search engine for gait training</a></h3><div class="gs_a"><a href="/citations?user=TF8WdBMAAAAJ&amp;hl=en&amp;oi=sra">Z Li</a>, Y Wang - Proceedings of the 20th ACM international conference  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract This paper demonstrates a domain-specific music retrieval system to help music <br>therapists find appropriate music for Parkinson&#39;s disease patients in their gait training. <br>Different from existing music search engines, this system incorporates multiple music <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'xZQtttjMjvQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://mtg.upf.edu/system/files/publications/Carlos-Vaquero-Master-Thesis-2012.pdf" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from upf.edu</span><span class="gs_ggsS">upf.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://mtg.upf.edu/system/files/publications/Carlos-Vaquero-Master-Thesis-2012.pdf" class=yC13>Improving the description of instrumental sounds by using ontologies and automatic content analysis</a></h3><div class="gs_a">CV Patricio - 2012 - mtg.upf.edu</div><div class="gs_rs">Abstract Browsing sound collections in a social database is a complex task when no <br>uniformity in the classification of the sounds and tags is applied; the relation between tag <br>concepts and sounds can vary extremely from one user to another, as well as the types of <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'wYmh7WF17u4J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md12', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md12" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:wYmh7WF17u4J:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://www.ee.iitb.ac.in/web/files/publications/VidwansPCJul2012.pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from iitb.ac.in</span><span class="gs_ggsS">iitb.ac.in <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ee.iitb.ac.in/web/files/publications/VidwansPCJul2012.pdf" class=yC15>CLASSIFICATION OF INDIAN CLASSICAL VOCAL STYLES FROM MELODIC CONTOURS</a></h3><div class="gs_a">A Vidwans, KK Ganguli, P Rao - 2012 - ee.iitb.ac.in</div><div class="gs_rs">ABSTRACT A prominent categorization of Indian classical music is the Hindustani and <br>Carnatic traditions, the two styles having evolved under distinctly different historical and <br>cultural influences. Both styles are grounded in the melodic and rhythmic framework of <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'qrz4-cKETN8J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md13', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md13" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:qrz4-cKETN8J:scholar.google.com/&amp;hl=en&amp;num=14&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
