Total results = 18
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://lms.comp.nus.edu.sg/papers/media/2010/mmm10-richang.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/925p41335j22184n.pdf" class=yC0>Mediapedia: Mining web knowledge to construct multimedia encyclopedia</a></h3><div class="gs_a"><a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, <a href="/citations?user=ByBLlEwAAAAJ&amp;hl=en&amp;oi=sra">J Tang</a>, ZJ Zha, <a href="/citations?user=0UkdiUT1ooUC&amp;hl=en&amp;oi=sra">Z Luo</a>, TS Chua - Advances in Multimedia  &hellip;, 2010 - Springer</div><div class="gs_rs">Abstract. In recent years, we have witnessed the blooming of Web 2.0 content such as <br>Wikipedia, Flickr and YouTube, etc. How might we benefit from such rich media resources <br>available on the internet? This paper presents a novel concept called Mediapedia, a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14978197780089934046&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 13</a> <a href="/scholar?q=related:3hDO6YU_3c8J:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14978197780089934046&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'3hDO6YU_3c8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://jcst.ict.ac.cn:8080/jcst/EN/article/downloadArticleFile.do?attachType=PDF&amp;id=9279" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ict.ac.cn</span><span class="gs_ggsS">ict.ac.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/0447K520N3X14646.pdf" class=yC2>Multiple Hypergraph Clustering of Web Images by MiningWord2Image Correlations</a></h3><div class="gs_a">F Wu, <a href="/citations?user=t4283loAAAAJ&amp;hl=en&amp;oi=sra">YH Han</a>, YT Zhuang - Journal of Computer Science and Technology, 2010 - Springer</div><div class="gs_rs">Abstract In this paper, we consider the problem of clustering Web images by mining <br>correlations between images and their corresponding words. Since Web images always <br>come with associated text, the corresponding textual tags of Web images are used as a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1291442843372348819&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 2</a> <a href="/scholar?q=related:k-Xtdmwg7BEJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1291442843372348819&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'k-Xtdmwg7BEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://lms.comp.nus.edu.sg/papers/media/2010/mmm10-guangda.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/16032402R4608815.pdf" class=yC4>Learning cooking techniques from youtube</a></h3><div class="gs_a">G Li, <a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, YT Zheng, <a href="/citations?user=DNuiPHwAAAAJ&amp;hl=en&amp;oi=sra">S Yan</a>, TS Chua - Advances in Multimedia  &hellip;, 2010 - Springer</div><div class="gs_rs">Abstract. Cooking is a human activity with sophisticated process. Underlying the multitude of <br>culinary recipes, there exist a set of fundamental and general cooking techniques, such as <br>cutting, braising, slicing, and sauntering, etc. These skills are hard to learn through <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2877317809657764576&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 3</a> <a href="/scholar?q=related:4FqOnk1J7icJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2877317809657764576&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'4FqOnk1J7icJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/M008556045V15WV1.pdf" class=yC6>A non-parametric visual-sense model of imagesâextending the cluster hypothesis beyond text</a></h3><div class="gs_a">KW Wan, <a href="/citations?user=G0hdDqYAAAAJ&amp;hl=en&amp;oi=sra">AH Tan</a>, JH Lim, <a href="/citations?user=Eeolw80AAAAJ&amp;hl=en&amp;oi=sra">LT Chia</a> - Multimedia Tools and Applications, 2012 - Springer</div><div class="gs_rs">Abstract The main challenge of a search engine is to find information that are relevant and <br>appropriate. However, this can become difficult when queries are issued using ambiguous <br>words. Rijsbergen first hypothesized a clustering approach for web pages wherein closely <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4881264009028995147&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 1</a> <a href="/scholar?q=related:S4gSEcG7vUMJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4881264009028995147&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'S4gSEcG7vUMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.aaai.org/ocs/index.php/WS/AAAIW12/paper/download/5335/5621" class=yC7>Collecting Representative Pictures for Words: A Human Computation Approach based on Draw Something Game</a></h3><div class="gs_a"><a href="/citations?user=JFUlA8cAAAAJ&amp;hl=en&amp;oi=sra">J Wang</a>, B Yu - Workshops at the Twenty-Sixth AAAI Conference on  &hellip;, 2012 - aaai.org</div><div class="gs_rs">Abstract This poster proposes a human computation approach to collecting representative <br>pictures for words so that the collected pictures can efficiently and effectively convey the <br>meaning of the words or concepts. A large collection of representative pictures can be <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:zrtXFMubpDQJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3793328082674760654&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'zrtXFMubpDQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://users.cis.fiu.edu/~lli003/pub/multimedia.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from fiu.edu</span><span class="gs_ggsS">fiu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/T3H5145346124054.pdf" class=yC8>A multimedia information fusion framework for web image categorization</a></h3><div class="gs_a">W Lu, <a href="/citations?user=b8sYKJIAAAAJ&amp;hl=en&amp;oi=sra">L Li</a>, J Li, <a href="/citations?user=_SuhcLEAAAAJ&amp;hl=en&amp;oi=sra">T Li</a>, H Zhang, J Guo - Multimedia Tools and Applications, 2012 - Springer</div><div class="gs_rs">Abstract With the rapid development of technologies for fast Internet access and the <br>popularization of digital cameras, an enormous number of digital images are posted and <br>shared online everyday. Web images are usually organized by topic and are often <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:_zQ_Kin3fcoJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14591090123924780287&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'_zQ_Kin3fcoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://ftp.cs.wisc.edu/computer-vision/repository/PDF/rosin.2011.tr1692.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from wisc.edu</span><span class="gs_ggsS">wisc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://ftp.cs.wisc.edu/computer-vision/repository/PDF/rosin.2011.tr1692.pdf" class=yCA>Department</a></h3><div class="gs_a">J Rosin, <a href="/citations?user=q7Z3lx0AAAAJ&amp;hl=en&amp;oi=sra">A Goldberg</a>, <a href="/citations?user=hqTu-QcAAAAJ&amp;hl=en&amp;oi=sra">X Zhu</a>, <a href="/citations?user=VizsSmEAAAAJ&amp;hl=en&amp;oi=sra">C Dyer</a> - 2011 - cs.wisc.edu</div><div class="gs_rs">Abstract Pictorial communication systems use synthesized pictures, rather than text, to <br>communicate with users. Because such systems depend on images to convey meanings, it <br>is critical to understand how a human user perceives the image meaning (sense). This <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ww4YPtabGFsJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6564167801359568579&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'ww4YPtabGFsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md6', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md6" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:ww4YPtabGFsJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S092523121200906X" class=yCC>Hybrid Image Summarization by Hypergraph Partition</a></h3><div class="gs_a">M Li, C Zhao, <a href="/citations?user=ByBLlEwAAAAJ&amp;hl=en&amp;oi=sra">J Tang</a> - Neurocomputing, 2013 - Elsevier</div><div class="gs_rs">Abstract The objectiveof hybrid image summarization is selecting a few visual exemplars <br>and semantic exemplars of a large-scale image collection and organizing them to represent <br>the collection. In this paper, we present a framework for hybrid image summarization in <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'ldtgTpHIVcYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/470T3394G5101W71.pdf" class=yCD>Video Reference: A Video Question Answering Engine</a></h3><div class="gs_a"><a href="/citations?user=bOKmjf8AAAAJ&amp;hl=en&amp;oi=sra">L Gao</a>, G Li, YT Zheng, <a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, TS Chua - Advances in Multimedia  &hellip;, 2010 - Springer</div><div class="gs_rs">Community-based question answering systems have become very popular for providing <br>answers to a wide variety ofâ how-toâ questions. However, most such systems present only <br>textual answers. In many cases, users would prefer visual answers such as videos which <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:5A7YdD9KBhIJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1298807178946678500&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'5A7YdD9KBhIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0165168412002204" class=yCE>Multimedia encyclopedia construction by mining web knowledge</a></h3><div class="gs_a"><a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, ZJ Zha, Y Gao, TS Chua, X Wu - Signal Processing, 2012 - Elsevier</div><div class="gs_rs">Abstract In recent years, we have witnessed the blooming of Web 2.0 content such as <br>Wikipedia, Flickr and YouTube, etc. How might we benefit from such rich media resources <br>available on the internet? This paper presents a novel concept called Mediapedia, a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:-PXgd9tRpOoJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'-PXgd9tRpOoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://pages.cs.wisc.edu/~jerryzhu/pub/kpic.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from wisc.edu</span><span class="gs_ggsS">wisc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://pages.cs.wisc.edu/~jerryzhu/pub/kpic.pdf" class=yCF>A Bayesian Model for Image Sense Ambiguity in Pictorial Communication Systems</a></h3><div class="gs_a">J Rosin, <a href="/citations?user=q7Z3lx0AAAAJ&amp;hl=en&amp;oi=sra">AB Goldberg</a>, <a href="/citations?user=hqTu-QcAAAAJ&amp;hl=en&amp;oi=sra">X Zhu</a>, <a href="/citations?user=VizsSmEAAAAJ&amp;hl=en&amp;oi=sra">C Dyer</a> - pages.cs.wisc.edu</div><div class="gs_rs">Abstract Pictorial communication systems use synthesized pictures, rather than text, to <br>communicate with users. Because such systems depend on images to convey meanings, it <br>is critical to understand how a human user perceives the image meaning (sense). This <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:3wGleNCmGs0J:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'3wGleNCmGs0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md10', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md10" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:3wGleNCmGs0J:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3540454/" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from nih.gov</span><span class="gs_ggsS">nih.gov <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[HTML]</span><span class="gs_ct2">[HTML]</span></span> <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3540454/" class=yC11>Automated Illustration of Patients Instructions</a></h3><div class="gs_a">D Bui, C Nakamura, BE Bray&hellip; - AMIA Annual  &hellip;, 2012 - ncbi.nlm.nih.gov</div><div class="gs_rs">Abstract A picture can be a powerful communication tool. However, creating pictures to <br>illustrate patient instructions can be a costly and time-consuming task. Building on our prior <br>research in this area, we developed a computer application that automatically converts <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'0aeCj2QzKYAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/n21118436x784101.pdf" class=yC13>Combining global and local matching of multiple features for precise item image retrieval</a></h3><div class="gs_a">H Li, X Wang, <a href="/citations?user=ByBLlEwAAAAJ&amp;hl=en&amp;oi=sra">J Tang</a>, C Zhao - Multimedia Systems - Springer</div><div class="gs_rs">Abstract With the fast-growing of online shopping services, there are millions even billions of <br>commercial item images available on the Internet. How to effectively leverage visual search <br>method to find the items of users&#39; interests is an important yet challenging task. Besides <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2778197965817864700&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 1</a> <a href="/scholar?q=related:_GFJlFQkjiYJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'_GFJlFQkjiYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://www.minds.wisconsin.edu/bitstream/handle/1793/60740/TR1692.pdf?sequence=1" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from wisconsin.edu</span><span class="gs_ggsS">wisconsin.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.minds.wisconsin.edu/handle/1793/60740" class=yC14>Date Mar 15, 2012</a></h3><div class="gs_a">J Rosin, <a href="/citations?user=q7Z3lx0AAAAJ&amp;hl=en&amp;oi=sra">AB Goldberg</a>, <a href="/citations?user=hqTu-QcAAAAJ&amp;hl=en&amp;oi=sra">X Zhu</a>, <a href="/citations?user=VizsSmEAAAAJ&amp;hl=en&amp;oi=sra">C Dyer</a> - 2012 - minds.wisconsin.edu</div><div class="gs_rs">Abstract Pictorial communication systems use synthesized pictures, rather than text, to <br>communicate with users. Because such systems depend on images to convey meanings, it <br>is critical to understand how a human user perceives the image meaning (sense). This <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:E5zBn4m8g7AJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12719217071901219859&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'E5zBn4m8g7AJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://people.cs.umass.edu/~jbing/paper/Online%20Image%20Classifier%20Learning%20for%20Google%20Image%20Search%20Improvement.pdf" class=yC17><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from umass.edu</span><span class="gs_ggsS">umass.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5948971" class=yC16>Online image classifier learning for Google image search improvement</a></h3><div class="gs_a">Y Wan, X Liu, J Bing, Y Chen - Information and Automation ( &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper proposes a content based method to improve image search results from <br>Google search engine. The images returned by Google are used to learn a statistical binary <br>classifier for measuring their relevance to the query. The learning process includes three <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:yz5mo7_ZnUgJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5232577759177752267&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'yz5mo7_ZnUgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ri"><h3 class="gs_rt"><a href="http://137.132.14.55/handle/10635/33304" class=yC18>Human Visual Perception, study and applications to understanding Images and Videos</a></h3><div class="gs_a"><a href="/citations?user=Cja9MMgAAAAJ&amp;hl=en&amp;oi=sra">H Katti</a> - 2011 - 137.132.14.55</div><div class="gs_rs">Assessing whether a photograph is interesting, or spotting people in conversation or <br>important objects in an images and videos, are visual tasks that we humans do effortlessly <br>and in a robust manner. In this thesis I first explore and quantify how humans distinguish <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:jna1s1LyMH0J:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9020976490639357582&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'jna1s1LyMH0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md15', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md15" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:jna1s1LyMH0J:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> <a href="http://www.cqvip.com/qk/85226x/201004/34470251.html" class=yC19>Multiple Hypergraph Clustering of Web Images by Mining Word2Image Correlations</a></h3><div class="gs_a">å´é£ï¼ é©äºæ´ªï¼ åºè¶æº - è®¡ç®æºç§å­¦ææ¯å­¦æ¥: è±æç, 2010 - cqvip.com</div><div class="gs_rs">æçç»´æ®: æçå¸æ·; æçæ¶èå¤¹; æçä½å; æçç²¾éè¾. è´­ç©è½¦; åå¼ä¸­å¿; å®¢æä¸­å¿. é¦é¡µ |<br>ç¥è¯ç»çºªäºº | æåå¤§å¨ | å­¦èç©ºé´ | å­¦æ¯æºæ | ç­ç¹ä¸é¢ | å­¦æ¯è®ºå | è®ºæåè¡¨ |<br>EIåISTPä¼è®® | å½éä¼è®® | æè²å¹è®­. é«çº§æç´¢ | ä¸ä¸æ£ç´¢ | æåæç¨¿. <b>...</b> </div><div class="gs_fl"><a href="/scholar?q=related:tEkLDyVicDYJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'tEkLDyVicDYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://koost.eveel.ru/science/AICT12.pdf" class=yC1B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from eveel.ru</span><span class="gs_ggsS">eveel.ru <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://koost.eveel.ru/science/AICT12.pdf" class=yC1A>ÐÑÐ¸Ð¼ÐµÐ½ÐµÐ½Ð¸Ðµ Ð¾Ð½ÑÐ¾Ð»Ð¾Ð³Ð¸Ð¸ Ð¿ÑÐ¸ ÑÐ¸Ð½ÑÐµÐ·Ðµ Ð¸Ð·Ð¾Ð±ÑÐ°Ð¶ÐµÐ½Ð¸Ñ Ð¿Ð¾ ÑÐµÐºÑÑÑ</a></h3><div class="gs_a">Ð Ð£ÑÑÐ°Ð»Ð¾Ð², Ð ÐÑÐ´ÑÑÐ²ÑÐµÐ² - 2012 - koost.eveel.ru</div><div class="gs_rs">ÐÐ½Ð½Ð¾ÑÐ°ÑÐ¸Ñ Ð ÑÑÐ°ÑÑÐµ Ð¿ÑÐµÐ´ÑÑÐ°Ð²Ð»ÐµÐ½ Ð¿Ð¾Ð´ÑÐ¾Ð´ Ðº Ð¿ÑÐ¸Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ Ð¾Ð½ÑÐ¾Ð»Ð¾Ð³Ð¸Ð¸ Ñ ÑÐµÐ»ÑÑ <br>Ð¾ÑÐ³Ð°Ð½Ð¸Ð·Ð°ÑÐ¸Ð¸ Ð¸Ð½ÑÐ¾ÑÐ¼Ð°ÑÐ¸Ð¾Ð½Ð½ÑÑ ÑÐµÑÑÑÑÐ¾Ð² Ð² ÑÐ¸ÑÑÐµÐ¼Ð°Ñ ÑÐ¸Ð½ÑÐµÐ·Ð° Ð¸Ð·Ð¾Ð±ÑÐ°Ð¶ÐµÐ½Ð¸Ñ Ð¿Ð¾ ÑÐµÐºÑÑÑ. <br>ÐÑÐ¿Ð¾Ð»ÑÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¾Ð½ÑÐ¾Ð»Ð¾Ð³Ð¸Ð¸ Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÐµÑ ÑÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°ÑÑ ÑÐ»Ð°Ð±ÑÑ ÑÐ²ÑÐ·Ð½Ð¾ÑÑÑ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½ÑÐ¾Ð² <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:8BSt0-WprEwJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5524977647440696560&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'8BSt0-WprEwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md17', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md17" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:8BSt0-WprEwJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
