Total results = 17
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www-alg.ist.hokudai.ac.jp/~thomas/publications/tcs08lzz.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hokudai.ac.jp</span><span class="gs_ggsS">hokudai.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397508001503" class=yC0>Learning indexed families of recursive languages from positive data: A survey</a></h3><div class="gs_a">S Lange, T Zeugmann, <a href="/citations?user=gkUY7QMAAAAJ&amp;hl=en&amp;oi=sra">S Zilles</a> - Theoretical Computer Science, 2008 - Elsevier</div><div class="gs_rs">In the past 40 years, research on inductive inference has developed along different lines, eg, <br>in the formalizations used, and in the classes of target concepts considered. One common <br>root of many of these formalizations is Gold&#39;s model of identification in the limit. This model <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11257453027040786320&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 39</a> <a href="/scholar?q=related:kHdpMOKBOpwJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11257453027040786320&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'kHdpMOKBOpwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.7.7311&amp;rep=rep1&amp;type=pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/TPQLB4Q0AWXYP3CN.pdf" class=yC2>A random sampling technique for training support vector machines</a></h3><div class="gs_a">J BalcÃ¡zar, Y Dai, O Watanabe - Algorithmic Learning Theory, 2001 - Springer</div><div class="gs_rs">Random sampling techniques have been developed for combinatorial optimization <br>problems. In this note, we report an application of one of these techniques for training <br>support vector machines (more precisely, primal-form maximal-margin classifiers) that <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4632482772689315381&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 37</a> <a href="/scholar?q=related:NWZDroniSUAJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/00/52/RN105608937.html?source=googlescholar" class="gs_nph" class=yC4>BL Direct</a> <a href="/scholar?cluster=4632482772689315381&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'NWZDroniSUAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://mind-change-bayes-net.googlecode.com/svn/branches/mclc.pdf" class=yC6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from googlecode.com</span><span class="gs_ggsS">googlecode.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0890540106000253" class=yC5>Mind change efficient learning</a></h3><div class="gs_a"><a href="/citations?user=fIxBU34AAAAJ&amp;hl=en&amp;oi=sra">W Luo</a>, O Schulte - Information and Computation, 2006 - Elsevier</div><div class="gs_rs">This paper studies efficient learning with respect to mind changes. Our starting point is the <br>idea that a learner that is efficient with respect to mind changes minimizes mind changes not <br>only globally in the entire learning problem, but also locally in subproblems after receiving <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14247247022051085877&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 12</a> <a href="/scholar?q=related:Nc6YcK5juMUJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14247247022051085877&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'Nc6YcK5juMUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0890540109001631" class=yC7>Topological properties of concept spaces (full version)</a></h3><div class="gs_a">M Brecht, A Yamamoto - Information and Computation, 2010 - Elsevier</div><div class="gs_rs">Based on the observation that the category of concept spaces with the positive information <br>topology is equivalent to the category of countably based T0 topological spaces, we <br>investigate further connections between the learning in the limit model of inductive <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3441739284640441290&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 3</a> <a href="/scholar?q=related:yiOA7qSDwy8J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3441739284640441290&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'yiOA7qSDwy8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://www.comp.nus.edu.sg/~sanjay/paps/intrinsur.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://iospress.metapress.com/index/TRRD110H759Y5W0B.pdf" class=yC8>The intrinsic complexity of learning: A survey</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a> - Fundamenta Informaticae, 2003 - IOS Press</div><div class="gs_rs">The theory of learning in the limit has been a focus of study by several researchers over the <br>last three decades. There have been several suggestions on how to measure the complexity <br>or hardness of learning. In this paper we survey the work done in one specific such <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1714095764473764975&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 2</a> <a href="/scholar?q=related:b9x1IASxyRcJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/37/56/RN141711373.html?source=googlescholar" class="gs_nph" class=yCA>BL Direct</a> <a href="/scholar?cluster=1714095764473764975&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'b9x1IASxyRcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.137.6190&amp;rep=rep1&amp;type=pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://epubs.siam.org/doi/abs/10.1137/070700577" class=yCB>Mitotic classes in inductive inference</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, F Stephan - SIAM Journal on Computing, 2008 - SIAM</div><div class="gs_rs">For the natural notion of splitting classes into two disjoint subclasses via a recursive <br>classifier working on texts, the question of how these splittings can look in the case of <br>learnable classes is addressed. Here the strength of the classes is compared using the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5975477938293324016&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 2</a> <a href="/scholar?q=related:8Dgog4Yp7VIJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5975477938293324016&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 24 versions</a> <a onclick="return gs_ocit(event,'8Dgog4Yp7VIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://webdocs.cs.ualberta.ca/~zilles/zilles03uniform.pdf" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ualberta.ca</span><span class="gs_ggsS">ualberta.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/QCKQQRTHHQ5K217C.pdf" class=yCD>Intrinsic complexity of uniform learning</a></h3><div class="gs_a"><a href="/citations?user=gkUY7QMAAAAJ&amp;hl=en&amp;oi=sra">S Zilles</a> - Algorithmic Learning Theory, 2003 - Springer</div><div class="gs_rs">Inductive inference is concerned with algorithmic learning of recursive functions. In the <br>model of learning in the limit a learner successful for a class of recursive functions must <br>eventually find a program for any function in the class from a gradually growing sequence <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6827755080938735900&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:HMm4NBIPwV4J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/5D/5B/RN139774897.html?source=googlescholar" class="gs_nph" class=yCF>BL Direct</a> <a href="/scholar?cluster=6827755080938735900&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'HMm4NBIPwV4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://cs5235.userapi.com/u133638729/docs/e02780dda47c/Yoav_Freund_Algorithmic_Learning_Theory_19_conf.pdf#page=386" class=yC11><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from userapi.com</span><span class="gs_ggsS">userapi.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/n3r64276x24l10v0.pdf" class=yC10>Topological Properties of Concept Spaces</a></h3><div class="gs_a">M de Brecht, A Yamamoto - Algorithmic Learning Theory, 2008 - Springer</div><div class="gs_rs">Based on the observation that the category of concept spaces with the positive information <br>topology is equivalent to the category of countably based T 0 topological spaces, we <br>investigate further connections between the learning in the limit model of inductive <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15041411694562322013&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:XSbLTj7UvdAJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15041411694562322013&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'XSbLTj7UvdAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="https://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/2569/1/TRB8-07.pdf" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/u584873247003656.pdf" class=yC12>Mitotic classes</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, F Stephan - Learning Theory, 2007 - Springer</div><div class="gs_rs">For the natural notion of splitting classes into two disjoint subclasses via a recursive <br>classifier working on texts, the question is addressed how these splittings can look in the <br>case of learnable classes. Here the strength of the classes is compared using the strong <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9199306675380504428&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:bEfvZa6Aqn8J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/0A/11/RN210335582.html?source=googlescholar" class="gs_nph" class=yC14>BL Direct</a> <a href="/scholar?cluster=9199306675380504428&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'bEfvZa6Aqn8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://cs5824.userapi.com/u11728334/docs/be3e0641bab1/David_Helmbold_Computational_Learning_Theory_14.pdf#page=185" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from userapi.com</span><span class="gs_ggsS">userapi.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/80x7h9xc6ju9crv4.pdf" class=yC15>Intrinsic complexity of learning geometrical concepts from positive data</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, E Kinber - Computational Learning Theory, 2001 - Springer</div><div class="gs_rs">Intrinsic complexity is used to measure complexity of learning areas limited by broken-<br>straight lines (called open semi-hulls) 1 and intersections of such areas. Any strategy <br>learning such geometrical concept can be viewed as a sequence of primitive basic <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14392061916281264977&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:UVtfeQ_guscJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/0C/3F/RN099833786.html?source=googlescholar" class="gs_nph" class=yC17>BL Direct</a> <a href="/scholar?cluster=14392061916281264977&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'UVtfeQ_guscJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://www.comp.nus.edu.sg/~sanjay/paps/kalapp.pdf" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/et9pbxuppma6j9j0.pdf" class=yC18>Learning languages in a union</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, Y Ng, T Tay - Algorithmic Learning Theory, 2001 - Springer</div><div class="gs_rs">In inductive inference, a machine is given words in a language and the machine is said to <br>identify the language if it correctly names the language. In this paper we study classes of <br>languages where the unions of up to a fixed number (n say) of languages from the class <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10657766068813191332&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:pFjStsX955MJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/4E/19/RN105609012.html?source=googlescholar" class="gs_nph" class=yC1A>BL Direct</a> <a href="/scholar?cluster=10657766068813191332&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'pFjStsX955MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="ftp://142.58.111.31/fas-info/ftp/ftp/pub/cs/theses/2007/WeiLuoPhD.pdf" class=yC1C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 142.58.111.31</span><span class="gs_ggsS">142.58.111.31 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="ftp://142.58.111.31/fas-info/ftp/ftp/pub/cs/theses/2007/WeiLuoPhD.pdf" class=yC1B>Mind change optimal learning: theory and applications</a></h3><div class="gs_a"><a href="/citations?user=fIxBU34AAAAJ&amp;hl=en&amp;oi=sra">W Luo</a> - 2007 - 142.58.111.31</div><div class="gs_rs">Abstract Learning theories play a significant role to machine learning as computability and <br>complexity theories to software engineering. Gold&#39;s language learning paradigm is one <br>cornerstone of modern learning theories. The aim of this thesis is to establish an inductive <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11533246138184030721&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:AdqaxUFSDqAJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11533246138184030721&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 34 versions</a> <a onclick="return gs_ocit(event,'AdqaxUFSDqAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md11', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md11" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:AdqaxUFSDqAJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a>  <a href="/scholar?q=info:AdqaxUFSDqAJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=14678773570696185909&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://www.comp.nus.edu.sg/~sanjay/paps/geometry.pdf" class=yC1E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0022000003000679" class=yC1D>Intrinsic complexity of learning geometrical concepts from positive data</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">S Jain</a>, E Kinber - Journal of Computer and System Sciences, 2003 - Elsevier</div><div class="gs_rs">Intrinsic complexity is used to measure the complexity of learning areas limited by broken-<br>straight lines (called open semi-hulls) and intersections of such areas. Any strategy learning <br>such geometrical concepts can be viewed as a sequence of primitive basic strategies. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1986744246918380383&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:X_seyV1VkhsJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1986744246918380383&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'X_seyV1VkhsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://www2.cs.uregina.ca/~zilles/zilles06intrinsic.pdf" class=yC20><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uregina.ca</span><span class="gs_ggsS">uregina.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0304397506004890" class=yC1F>An approach to intrinsic complexity of uniform learning</a></h3><div class="gs_a"><a href="/citations?user=gkUY7QMAAAAJ&amp;hl=en&amp;oi=sra">S Zilles</a> - Theoretical computer science, 2006 - Elsevier</div><div class="gs_rs">Inductive inference is concerned with algorithmic learning of recursive functions. In the <br>model of learning in the limit a learner successful for a class of recursive functions must <br>eventually find a program for any function in the class from a gradually growing sequence <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6053165535829796857&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=17">Cited by 1</a> <a href="/scholar?q=related:-afF2fspAVQJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6053165535829796857&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'-afF2fspAVQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTR/tcstr_07_31/tcstr_07_31.pdf" class=yC22><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hokudai.ac.jp</span><span class="gs_ggsS">hokudai.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www-alg.ist.hokudai.ac.jp/~thomas/TCSTR/tcstr_07_31/tcstr_07_31.pdf" class=yC21>TCS Technical Report</a></h3><div class="gs_a">S Lange, T Zeugmann, <a href="/citations?user=gkUY7QMAAAAJ&amp;hl=en&amp;oi=sra">S Zilles</a> - 2007 - www-alg.ist.hokudai.ac.jp</div><div class="gs_rs">Abstract In the past 40 years, research on inductive inference has developed along different <br>lines, concerning different formalizations of learning models and in particular of target <br>concepts for learning. One common root of many of these is Gold&#39;s model of identification <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:uMhVpfJ4388J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14978823869208840376&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'uMhVpfJ4388J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md14', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md14" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:uMhVpfJ4388J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://dl.comp.nus.edu.sg/dspace/bitstream/1900.100/1400/1/report.pdf" class=yC24><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.comp.nus.edu.sg/dspace/handle/1900.100/1400" class=yC23>On intrinsic complexity of learning geometrical concepts from texts</a></h3><div class="gs_a"><a href="/citations?user=9oNh1Z0AAAAJ&amp;hl=en&amp;oi=sra">J Sanjay</a>, E KINBER - 1999 - dl.comp.nus.edu.sg</div><div class="gs_rs">Abstract: The goal of this paper is to quantify complexity of algorithmic learning of <br>geometrical concepts from growing finite segments. The geometrical concepts we consider <br>are variants of open-hulls. We use intrinsic complexity as our complexity measure. The <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:DAWdzjlgDVIJ:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5912487687203128588&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'DAWdzjlgDVIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://users.dsic.upv.es/workshops/icgi2010/slides/Li.pdf" class=yC26><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from upv.es</span><span class="gs_ggsS">upv.es <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/K463H6036PH8678U.pdf" class=yC25>Splitting of learnable classes</a></h3><div class="gs_a">H Li, F Stephan - Grammatical Inference: Theoretical Results and  &hellip;, 2010 - Springer</div><div class="gs_rs">A class LL is called mitotic if it admits a splitting L 0, L 1 L _0, L _1 such that L, L 0, L 1 L, L <br>_0, L _1 are all equivalent with respect to a certain reducibility. Such a splitting might be <br>called a symmetric splitting. In this paper we investigate the possibility of constructing a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:cV405y-RMO8J:scholar.google.com/&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17235435408875347569&amp;hl=en&amp;num=17&amp;as_sdt=0,5&amp;sciodt=0,5">All 19 versions</a> <a onclick="return gs_ocit(event,'cV405y-RMO8J')" href="#" class="gs_nph">Cite</a></div></div></div>
