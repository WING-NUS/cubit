Total results = 152
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Publications_files/pomcp.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ucl.ac.uk</span><span class="gs_ggsS">ucl.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Publications_files/pomcp.pdf" class=yC0>Monte-Carlo planning in large POMDPs</a></h3><div class="gs_a">D Silver, J Veness - &hellip;  in Neural Information Processing Systems (NIPS), 2010 - cs.ucl.ac.uk</div><div class="gs_rs">Abstract This paper introduces a Monte-Carlo algorithm for online planning in large <br>POMDPs. The algorithm combines a Monte-Carlo update of the agent&#39;s belief state with a <br>Monte-Carlo tree search from the current belief state. The new algorithm, POMCP, has two <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3076708823025822549&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 55</a> <a href="/scholar?q=related:VavDmV-qsioJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3076708823025822549&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'VavDmV-qsioJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md0', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md0" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:VavDmV-qsioJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://typesetter.ucoz.com/_ld/0/1_2Dq.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ucoz.com</span><span class="gs_ggsS">ucoz.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ijr.sagepub.com/content/29/8/1053.short" class=yC2>Planning under uncertainty for robotic tasks with mixed observability</a></h3><div class="gs_a">SCW Ong, <a href="/citations?user=wZy6aw0AAAAJ&amp;hl=en&amp;oi=sra">SW Png</a>, <a href="/citations?user=S9LHLKEAAAAJ&amp;hl=en&amp;oi=sra">D Hsu</a>, <a href="/citations?user=8PCrLgwAAAAJ&amp;hl=en&amp;oi=sra">WS Lee</a> - The International Journal of  &hellip;, 2010 - ijr.sagepub.com</div><div class="gs_rs">Abstract Partially observable Markov decision processes (POMDPs) provide a principled, <br>general framework for robot motion planning in uncertain and dynamic environments. They <br>have been applied to various robotic tasks. However, solving POMDPs exactly is <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6039740786761352353&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 48</a> <a href="/scholar?q=related:oURZ4j540VMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6039740786761352353&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 23 versions</a> <a onclick="return gs_ocit(event,'oURZ4j540VMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://goldberg.berkeley.edu/pubs/LQG-MP-IJRR-June-2011.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from berkeley.edu</span><span class="gs_ggsS">berkeley.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ijr.sagepub.com/content/30/7/895.short" class=yC4>LQG-MP: Optimized path planning for robots with motion uncertainty and imperfect state information</a></h3><div class="gs_a"><a href="/citations?user=VjsNXysAAAAJ&amp;hl=en&amp;oi=sra">J Van Den Berg</a>, <a href="/citations?user=vtwH6GkAAAAJ&amp;hl=en&amp;oi=sra">P Abbeel</a>&hellip; - The International Journal of &hellip;, 2011 - ijr.sagepub.com</div><div class="gs_rs">Abstract In this paper we present LQG-MP (linear-quadratic Gaussian motion planning), a <br>new approach to robot motion planning that takes into account the sensors and the <br>controller that will be used during the execution of the robot&#39;s path. LQG-MP is based on <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15519288972405251019&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 33</a> <a href="/scholar?q=related:yxvafhiXX9cJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15519288972405251019&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 25 versions</a> <a onclick="return gs_ocit(event,'yxvafhiXX9cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://bigbird.comp.nus.edu.sg/~hannakur/papers/ijrr10_migs.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ijr.sagepub.com/content/30/3/308.short" class=yC6>Motion planning under uncertainty for robotic tasks with long time horizons</a></h3><div class="gs_a"><a href="/citations?user=JkjFXbAAAAAJ&amp;hl=en&amp;oi=sra">H Kurniawati</a>, Y Du, <a href="/citations?user=S9LHLKEAAAAJ&amp;hl=en&amp;oi=sra">D Hsu</a>, <a href="/citations?user=8PCrLgwAAAAJ&amp;hl=en&amp;oi=sra">WS Lee</a> - The International Journal of  &hellip;, 2011 - ijr.sagepub.com</div><div class="gs_rs">Abstract Motion planning with imperfect state information is a crucial capability for <br>autonomous robots to operate reliably in uncertain and dynamic environments. Partially <br>observable Markov decision processes (POMDPs) provide a principled general <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11769708948916864549&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 25</a> <a href="/scholar?q=related:JQbtMe5nVqMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11769708948916864549&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 36 versions</a> <a onclick="return gs_ocit(event,'JQbtMe5nVqMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://www.ri.cmu.edu/pub_files/2010/5/HollingerICRA10.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cmu.edu</span><span class="gs_ggsS">cmu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5509175" class=yC8>Multi-robot coordination with periodic connectivity</a></h3><div class="gs_a"><a href="/citations?user=0SQP4bwAAAAJ&amp;hl=en&amp;oi=sra">G Hollinger</a>, <a href="/citations?user=IxCZDBQAAAAJ&amp;hl=en&amp;oi=sra">S Singh</a> - Robotics and Automation (ICRA), 2010  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We consider the problem of multi-robot coordination subject to constraints on the <br>configuration. Specifically, we examine the case in which a mobile network of robots must <br>search, survey, or cover an environment while remaining connected. While many <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9167041911864230398&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 20</a> <a href="/scholar?q=related:_gHJvQzgN38J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9167041911864230398&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'_gHJvQzgN38J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="https://www.comp.nus.edu.sg/~hannakur/papers/wafr08_bounded.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/P157284H216JU768.pdf" class=yCA>Bounded uncertainty roadmaps for path planning</a></h3><div class="gs_a">L Guibas, <a href="/citations?user=S9LHLKEAAAAJ&amp;hl=en&amp;oi=sra">D Hsu</a>, <a href="/citations?user=JkjFXbAAAAAJ&amp;hl=en&amp;oi=sra">H Kurniawati</a>, E Rehman - Algorithmic Foundation of  &hellip;, 2009 - Springer</div><div class="gs_rs">Motion planning under uncertainty is an important problem in robotics. Although probabilistic <br>sampling is highly successful for motion planning of robots with many degrees of freedom, <br>sampling-based algorithms typically ignore uncertainty during planning. We introduce the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6003579417438000778&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 19</a> <a href="/scholar?q=related:ihY9_av_UFMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6003579417438000778&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 19 versions</a> <a onclick="return gs_ocit(event,'ihY9_av_UFMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://www.ncbi.nlm.nih.gov/pmc/articles/pmc2998859/" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from nih.gov</span><span class="gs_ggsS">nih.gov <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[HTML]</span><span class="gs_ct2">[HTML]</span></span> <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/pmc2998859/" class=yCC>Decision making under uncertainty: a neural model based on partially observable Markov decision processes</a></h3><div class="gs_a">RPN Rao - Frontiers in Computational Neuroscience, 2010 - ncbi.nlm.nih.gov</div><div class="gs_rs">Abstract A fundamental problem faced by animals is learning to select actions based on <br>noisy sensory information and incomplete knowledge of the world. It has been suggested <br>that the brain engages in Bayesian inference during perception but how such probabilistic <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5998708463507842251&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 18</a> <a href="/scholar?q=related:y6SDppCxP1MJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5998708463507842251&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'y6SDppCxP1MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://groups.csail.mit.edu/rrg/papers/aaai10-rh.pdf" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI10/paper/viewFile/1900/2154" class=yCE>PUMA: Planning under uncertainty with macro-actions</a></h3><div class="gs_a">R He, E Brunskill, <a href="/citations?user=aM3i_9oAAAAJ&amp;hl=en&amp;oi=sra">N Roy</a> - Proc. AAAI Conf. on Artificial Intelligence, 2010 - aaai.org</div><div class="gs_rs">Abstract Planning in large, partially observable domains is challenging, especially when a <br>long-horizon lookahead is necessary to obtain a good policy. Traditional POMDP planners <br>that plan a different potential action for each future observation can be prohibitively <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11862474141850541&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 17</a> <a href="/scholar?q=related:rdthfdskKgAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11862474141850541&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'rdthfdskKgAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://jmlr.csail.mit.edu/papers/volume12/choi11a/choi11a.pdf" class=yC11><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.aaai.org/ocs/index.php/IJCAI/IJCAI-09/paper/download/405/935" class=yC10>Inverse reinforcement learning in partially observable environments</a></h3><div class="gs_a">J Choi, KE Kim - Proceedings of the 21st international jont conference  &hellip;, 2009 - aaai.org</div><div class="gs_rs">Abstract Inverse reinforcement learning (IRL) is the problem of recovering the underlying <br>reward function from the behaviour of an expert. Most of the existing algorithms for IRL <br>assume that the expert&#39;s environment is modeled as a Markov decision process (MDP), <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3015363590429052093&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 16</a> <a href="/scholar?q=related:vYwrnDW52CkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3015363590429052093&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 20 versions</a> <a onclick="return gs_ocit(event,'vYwrnDW52CkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://iweb.tntech.edu/rqiu/publications/Cognitive%20Radio%20for%20Smart%20Grid.pdf" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tntech.edu</span><span class="gs_ggsS">tntech.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5971793" class=yC12>Cognitive radio network for the Smart Grid: Experimental system architecture, control algorithms, security, and Microgrid testbed</a></h3><div class="gs_a"><a href="/citations?user=FTLNXX8AAAAJ&amp;hl=en&amp;oi=sra">RC Qiu</a>, Z Hu, Z Chen, N Guo&hellip; - Smart Grid, IEEE  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper systematically investigates the novel idea of applying the next <br>generation wireless technology, cognitive radio network, for the smart grid. In particular, <br>system architecture, algorithms, and hardware testbed are studied. A microgrid testbed <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16387576634219203359&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 18</a> <a href="/scholar?q=related:H4sgrB9ebOMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16387576634219203359&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'H4sgrB9ebOMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.153.8052&amp;rep=rep1&amp;type=pdf" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.153.8052&amp;rep=rep1&amp;type=pdf" class=yC14>Robust belief-based execution of manipulation programs</a></h3><div class="gs_a"><a href="/citations?user=jdUSh80AAAAJ&amp;hl=en&amp;oi=sra">K Hsiao</a>, <a href="/citations?user=gQOKAggAAAAJ&amp;hl=en&amp;oi=sra">T Lozano-PÃ©rez</a>, LP Kaelbling - Eighth Intl. Workshop on the  &hellip;, 2008 - Citeseer</div><div class="gs_rs">Abstract: We describe a simple approach for executing manipulation programs in the <br>presence of significant, but bounded, uncertainty. The key idea is to maintain a belief-state <br>(a probability distribution over world states) and to execute fixed trajectories relative to the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5935375096188985223&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 13</a> <a href="/scholar?q=related:h18L-TOwXlIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5935375096188985223&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'h18L-TOwXlIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md10', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md10" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:h18L-TOwXlIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://www.mdpi.com/1424-8220/9/8/6530/htm" class=yC17><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from mdpi.com</span><span class="gs_ggsS">mdpi.com <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[HTML]</span><span class="gs_ct2">[HTML]</span></span> <a href="http://www.mdpi.com/1424-8220/9/8/6530/htm" class=yC16>A unified multi-functional dynamic spectrum access framework: tutorial, theory and multi-GHz wideband testbed</a></h3><div class="gs_a"><a href="/citations?user=FTLNXX8AAAAJ&amp;hl=en&amp;oi=sra">R Qiu</a>, N Guo, H Li, Z Wu, V Chakravarthy, Y Song&hellip; - Sensors, 2009 - mdpi.com</div><div class="gs_rs">Abstract: Dynamic spectrum access is a must-have ingredient for future sensors that are <br>ideally cognitive. The goal of this paper is a tutorial treatment of wideband cognitive radio <br>and radarâa convergence of (1) algorithms survey,(2) hardware platforms survey,(3) <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13788919413515355132&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 12</a> <a href="/scholar?q=related:_AMSVyYVXL8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13788919413515355132&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'_AMSVyYVXL8J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md11', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md11" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:_AMSVyYVXL8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ADA513420" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from dtic.mil</span><span class="gs_ggsS">dtic.mil <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://oai.dtic.mil/oai/oai?verb=getRecord&amp;metadataPrefix=html&amp;identifier=ADA513420" class=yC18>Model-based optimization of airborne collision avoidance logic</a></h3><div class="gs_a">MJ Kochenderfer, JP Chryssanthacopoulos&hellip; - 2010 - DTIC Document</div><div class="gs_rs">Abstract: The Traffic Alert and Collision Avoidance System (TCAS) is designed to reduce the <br>risk of mid-air collisions by providing resolution advisories to pilots. The current version of <br>the collision avoidance logic was hand-crafted over the course of many years and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15797407663673245730&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 10</a> <a href="/scholar?q=related:IgBHZZKqO9sJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15797407663673245730&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'IgBHZZKqO9sJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md12', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md12" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:IgBHZZKqO9sJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=6591483613894220326&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://gamesstudio.org/chek/wp-content/uploads/2011/02/TanAndCheng_aiide09.pdf" class=yC1B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from gamesstudio.org</span><span class="gs_ggsS">gamesstudio.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.aaai.org/ocs/index.php/AIIDE/AIIDE09/paper/viewFile/781/1082" class=yC1A>IMPLANT: An integrated MDP and POMDP learning agent for adaptive games</a></h3><div class="gs_a">CT Tan, <a href="/citations?user=LTYYmeQAAAAJ&amp;hl=en&amp;oi=sra">H Cheng</a> - Proceedings of The Artificial Intelligence and  &hellip;, 2009 - aaai.org</div><div class="gs_rs">Abstract This paper proposes an Integrated MDP and POMDP Learning AgeNT (IMPLANT) <br>architecture for adaptation in modern games. The modern game world basically involves a <br>human player acting in a virtual environment, which implies that the problem can be <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11562601647491951696&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 10</a> <a href="/scholar?q=related:UKwa5u-cdqAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11562601647491951696&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'UKwa5u-cdqAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://dspace.mit.edu/openaccess-disseminate/1721.1/61341" class=yC1D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dspace.mit.edu/handle/1721.1/61341" class=yC1C>Collision avoidance for unmanned aircraft using Markov decision processes</a></h3><div class="gs_a"><a href="/citations?user=4b2I74MAAAAJ&amp;hl=en&amp;oi=sra">S Temizer</a>, MJ Kochenderfer, LP Kaelbling&hellip; - 2010 - dspace.mit.edu</div><div class="gs_rs">Before unmanned aircraft can fly safely in civil airspace, robust airborne collision avoidance <br>systems must be developed. Instead of hand-crafting a collision avoidance algorithm for <br>every combination of sensor and aircraft con guration, we investigate the automatic <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3668851976713193092&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 10</a> <a href="/scholar?q=related:hMZ6NW9h6jIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3668851976713193092&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'hMZ6NW9h6jIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://www.cs.indiana.edu/~hauserk/papers/wafr2010-belieftrees.pdf" class=yC1F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from indiana.edu</span><span class="gs_ggsS">indiana.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/A1M77VW670511520.pdf" class=yC1E>Randomized belief-space replanning in partially-observable continuous spaces</a></h3><div class="gs_a">K Hauser - Algorithmic Foundations of Robotics IX, 2011 - Springer</div><div class="gs_rs">We present a sample-based replanning strategy for driving partially-observable, high-<br>dimensional robotic systems to a desired goal. At each time step, it uses forward simulation <br>of randomly-sampled open-loop controls to construct a belief-space search tree rooted at <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4164534646307328160&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 7</a> <a href="/scholar?q=related:oJD0NzJmyzkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4164534646307328160&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'oJD0NzJmyzkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://dspace.mit.edu/bitstream/handle/1721.1/54226/601707491.pdf?sequence=1" class=yC21><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/Q7P4533X028U7278.pdf" class=yC20>Aircraft collision avoidance using Monte Carlo real-time belief space search</a></h3><div class="gs_a">TB Wolf, MJ Kochenderfer - Journal of Intelligent &amp; Robotic Systems, 2011 - Springer</div><div class="gs_rs">Abstract The aircraft collision avoidance problem can be formulated using a decision-<br>theoretic planning framework where the optimal behavior requires balancing the competing <br>objectives of avoiding collision and adhering to a flight plan. Due to noise in the sensor <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15245094463839629569&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 8</a> <a href="/scholar?q=related:AXFvlKR0kdMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15245094463839629569&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'AXFvlKR0kdMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md16', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md16" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:AXFvlKR0kdMJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=1131411034071163641&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://dspace.mit.edu/openaccess-disseminate/1721.1/64741" class=yC23><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.aaai.org/Papers/JAIR/Vol40/JAIR-4014.pdf" class=yC22>Efficient planning under uncertainty with macro-actions</a></h3><div class="gs_a">R He, E Brunskill, <a href="/citations?user=aM3i_9oAAAAJ&amp;hl=en&amp;oi=sra">N Roy</a> - Journal of Artificial Intelligence Research, 2011 - aaai.org</div><div class="gs_rs">Abstract Deciding how to act in partially observable environments remains an active area of <br>research. Identifying good sequences of decisions is particularly challenging when good <br>control performance requires planning multiple steps into the future in domains with many <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4908626222938205989&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 9</a> <a href="/scholar?q=related:JS9m8YrxHkQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4908626222938205989&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'JS9m8YrxHkQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/p3366g21n2862818.pdf" class=yC24>A sampling hyperbelief optimization technique for stochastic systems</a></h3><div class="gs_a">J Davidson, <a href="/citations?user=-JPZ21IAAAAJ&amp;hl=en&amp;oi=sra">S Hutchinson</a> - Algorithmic Foundation of Robotics VIII, 2009 - Springer</div><div class="gs_rs">Uncertainty plays a dramatic role not only on the quality of the optimal solution of POMDP <br>system, but also on the computational complexity of finding the optimal solution, with a worst <br>case running time that is exponential in the length of the time horizon for the exact solution<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3213896025248320588&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 6</a> <a href="/scholar?q=related:TEz3MWgNmiwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3213896025248320588&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'TEz3MWgNmiwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="http://cmsassets.comp.nus.edu.sg/~leews/publications/wafr10.pdf" class=yC26><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/T354565W23354206.pdf" class=yC25>Monte Carlo value iteration for continuous-state POMDPs</a></h3><div class="gs_a"><a href="/citations?user=ho595lUAAAAJ&amp;hl=en&amp;oi=sra">H Bai</a>, <a href="/citations?user=S9LHLKEAAAAJ&amp;hl=en&amp;oi=sra">D Hsu</a>, <a href="/citations?user=8PCrLgwAAAAJ&amp;hl=en&amp;oi=sra">W Lee</a>, V Ngo - Algorithmic Foundations of Robotics IX, 2011 - Springer</div><div class="gs_rs">Partially observable Markov decision processes (POMDPs) have been successfully applied <br>to various robot motion planning tasks under uncertainty. However, most existing POMDP <br>algorithms assume a discrete state space, while the natural state space of a robot is often <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5253360281358716420&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 7</a> <a href="/scholar?q=related:BE6Ip1ev50gJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5253360281358716420&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 18 versions</a> <a onclick="return gs_ocit(event,'BE6Ip1ev50gJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB20" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW20"><a href="http://www.ll.mit.edu/mission/aviation/publications/publication-files/atc-reports/Kochenderfer_2011_ATC-371_WW-21458.pdf" class=yC28><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ll.mit.edu/mission/aviation/publications/publication-files/atc-reports/Kochenderfer_2011_ATC-371_WW-21458.pdf" class=yC27>Robust airborne collision avoidance through dynamic programming</a></h3><div class="gs_a">MJ Kochenderfer, JP Chryssanthacopoulos - Massachusetts Institute of  &hellip;, 2011 - ll.mit.edu</div><div class="gs_rs">EXECUTIVE SUMMARY The Traffic Alert and Collision Avoidance System (TCAS), currently <br>mandated on all large transport aircraft, has been shown to significantly reduce the risk of <br>mid-air collision. TCAS uses an on-board radar to monitor the local air traffic and logic to <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7542939766815863642&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 7</a> <a href="/scholar?q=related:WjM688DnrWgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7542939766815863642&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'WjM688DnrWgJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md20', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md20" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:WjM688DnrWgJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="http://dspace.mit.edu/bitstream/handle/1721.1/65856/MIT-CSAIL-TR-2011-039.pdf" class=yC2A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dspace.mit.edu/handle/1721.1/65856" class=yC29>A hypothesis-based algorithm for planning and control in non-Gaussian belief spaces</a></h3><div class="gs_a"><a href="/citations?user=Z4Y5S2oAAAAJ&amp;hl=en&amp;oi=sra">R Platt Jr</a>, L Kaelbling, <a href="/citations?user=gQOKAggAAAAJ&amp;hl=en&amp;oi=sra">T Lozano-Perez</a>, <a href="/citations?user=nxNkEiYAAAAJ&amp;hl=en&amp;oi=sra">R Tedrake</a> - 2011 - dspace.mit.edu</div><div class="gs_rs">We consider the partially observable control problem where it is potentially necessary to <br>perform complex information-gathering operations in order to localize state. One approach <br>to solving these problems is to create plans in belief-space, the space of probability <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9396763354234799403&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 5</a> <a href="/scholar?q=related:K8WSB3wCaIIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9396763354234799403&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'K8WSB3wCaIIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB22" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW22"><a href="http://dspace.mit.edu/bitstream/handle/1721.1/55115/591541776.pdf?sequence=1" class=yC2C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dspace.mit.edu/handle/1721.1/55115" class=yC2B>Relatively robust grasping</a></h3><div class="gs_a"><a href="/citations?user=jdUSh80AAAAJ&amp;hl=en&amp;oi=sra">K Hsiao</a> - 2009 - dspace.mit.edu</div><div class="gs_rs">This thesis presents an approach for grasping objects robustly under significant positional <br>uncertainty. In the field of robot manipulation there has been a great deal of work on how to <br>grasp objects stably, and in the field of robot motion planning there has been a great deal <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12533200004355665756&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 5</a> <a href="/scholar?q=related:XC-LDgDf7q0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12533200004355665756&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'XC-LDgDf7q0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md22', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md22" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:XC-LDgDf7q0J:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=9884503664486690376&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB23" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW23"><a href="http://www.isrr-2011.org/ISRR-2011/Program_files/Papers/Platt-ISRR-2011.pdf" class=yC2E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from isrr-2011.org</span><span class="gs_ggsS">isrr-2011.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.isrr-2011.org/ISRR-2011/Program_files/Papers/Platt-ISRR-2011.pdf" class=yC2D>Simultaneous localization and grasping as a belief space control problem</a></h3><div class="gs_a"><a href="/citations?user=Z4Y5S2oAAAAJ&amp;hl=en&amp;oi=sra">R Platt</a>, L Kaelbling, <a href="/citations?user=gQOKAggAAAAJ&amp;hl=en&amp;oi=sra">T Lozano-Perez</a>&hellip; - &hellip;  Symposium on Robotics  &hellip;, 2011 - isrr-2011.org</div><div class="gs_rs">Abstract Most approaches to grasp planning assume that the configurations of the object to <br>be grasped and any potential obstacles are known perfectly. As a result, implementations of <br>these âperfect informationâ approaches to grasp synthesis are necessarily preceded by a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16877513933415329556&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 7</a> <a href="/scholar?q=related:FC_tZID5OOoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16877513933415329556&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'FC_tZID5OOoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md23', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md23" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:FC_tZID5OOoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB24" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW24"><a href="http://hal.archives-ouvertes.fr/docs/00/53/55/59/PDF/ictai10.pdf" class=yC30><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5671411" class=yC2F>A closer look at MOMDPs</a></h3><div class="gs_a"><a href="/citations?user=52foGUkAAAAJ&amp;hl=en&amp;oi=sra">M Araya-LÃ³pez</a>, V Thomas, O Buffet&hellip; - Tools with Artificial  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The difficulties encountered in sequential decision-making problems under <br>uncertainty are often linked to the large size of the state space. Exploiting the structure of the <br>problem, for example by employing a factored representation, is usually an efficient <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1277154956140805618&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 5</a> <a href="/scholar?q=related:8v3me6pduREJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1277154956140805618&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'8v3me6pduREJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB25" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW25"><a href="http://www-cvr.ai.uiuc.edu/~scandido/pdf/sal_candido_icra2011.pdf" class=yC32><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uiuc.edu</span><span class="gs_ggsS">uiuc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5979695" class=yC31>Minimum uncertainty robot navigation using information-guided POMDP planning</a></h3><div class="gs_a"><a href="/citations?user=BDgbhmEAAAAJ&amp;hl=en&amp;oi=sra">S Candido</a>, <a href="/citations?user=-JPZ21IAAAAJ&amp;hl=en&amp;oi=sra">S Hutchinson</a> - Robotics and Automation (ICRA),  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract A ubiquitous problem in robotics is determining policies that move robots with <br>uncertain process and observation models (partially-observed state systems) to a goal <br>configuration while avoiding collision. We propose a new method to solve this minimum <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17409271983792917511&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 5</a> <a href="/scholar?q=related:BwwjiKEomvEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17409271983792917511&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'BwwjiKEomvEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB26" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW26"><a href="http://hal.inria.fr/docs/00/54/67/55/PDF/article.pdf" class=yC34><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from inria.fr</span><span class="gs_ggsS">inria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://hal.inria.fr/docs/00/54/67/55/PDF/article.pdf" class=yC33>A POMDP extension with belief-dependent rewards</a></h3><div class="gs_a"><a href="/citations?user=52foGUkAAAAJ&amp;hl=en&amp;oi=sra">M Araya-LÃ³pez</a>, O Buffet, V Thomas&hellip; - &hellip;  Systems-NIPS 2010, 2010 - hal.inria.fr</div><div class="gs_rs">RÃ©sumÃ©: Partially Observable Markov Decision Processes (POMDPs) model sequential <br>decision-making problems under uncertainty and partial observability. Unfortunately, some <br>problems cannot be modeled with state-dependent reward functions, eg, problems whose <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12540356156557511759&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 5</a> <a href="/scholar?q=related:T0x-lHtLCK4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12540356156557511759&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'T0x-lHtLCK4J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md26', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md26" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:T0x-lHtLCK4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB27" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW27"><a href="http://robert.kaplow.ca/thesis.pdf" class=yC36><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from kaplow.ca</span><span class="gs_ggsS">kaplow.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://robert.kaplow.ca/thesis.pdf" class=yC35>Point-based POMDP solvers: Survey and comparative analysis</a></h3><div class="gs_a">R Kaplow - 2010 - robert.kaplow.ca</div><div class="gs_rs">ABSTRACT Planning under uncertainty is an increasingly important research field, and it is <br>clear that the design of robust and scalable algorithms which consider uncertainty is key to <br>the development of effective autonomous and semi-autonomous systems. Partially <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18061490535889683366&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 6</a> <a href="/scholar?q=related:psPI0fJNp_oJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18061490535889683366&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'psPI0fJNp_oJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md27', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md27" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:psPI0fJNp_oJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a>  <a href="/scholar?q=info:psPI0fJNp_oJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=14909593051845351539&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB28" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW28"><a href="http://msl.cs.uiuc.edu/~lavalle/gto11/paper.pdf" class=yC38><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uiuc.edu</span><span class="gs_ggsS">uiuc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://msl.cs.uiuc.edu/~lavalle/gto11/paper.pdf" class=yC37>Sensing and filtering: A tutorial based on preimages and information spaces</a></h3><div class="gs_a"><a href="/citations?user=72e5VYEAAAAJ&amp;hl=en&amp;oi=sra">SM LaValle</a> - Foundations and Trends in Robotics, 2012 - msl.cs.uiuc.edu</div><div class="gs_rs">Abstract This tutorial presents a fresh perspective on sensing uncertainty and filtering with <br>the intention of understanding what information is minimally needed to achieve a specified <br>task. The guiding principle is not to sense, represent, and encode more than is necessary. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14061754654288730659&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 4</a> <a href="/scholar?q=related:I1qTD1tjJcMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14061754654288730659&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'I1qTD1tjJcMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md28', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md28" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:I1qTD1tjJcMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB29" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW29"><a href="http://users.isr.ist.utl.pt/~mtjspaan/pub/Spaan10icra.pdf" class=yC3A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from utl.pt</span><span class="gs_ggsS">utl.pt <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5509614" class=yC39>Multirobot coordination by auctioning POMDPs</a></h3><div class="gs_a">MTJ Spaan, N GonÃ§alves&hellip; - Robotics and Automation ( &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We consider the problem of task assignment and execution in multirobot systems, <br>by proposing a procedure for bid estimation in auction protocols. Auctions are of interest to <br>multirobot systems because they provide a flexible way to coordinate the assignment of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6995255570934926899&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 5</a> <a href="/scholar?q=related:Mw6mGuEjFGEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6995255570934926899&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'Mw6mGuEjFGEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB30" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW30"><a href="http://arxiv.org/pdf/1203.3538" class=yC3C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arxiv.org</span><span class="gs_ggsS">arxiv.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://arxiv.org/abs/1203.3538" class=yC3B>RAPID: A reachable anytime planner for imprecisely-sensed domains</a></h3><div class="gs_a">E Brunskill, S Russell - arXiv preprint arXiv:1203.3538, 2012 - arxiv.org</div><div class="gs_rs">Abstract: Despite the intractability of generic optimal partially observable Markov decision <br>process planning, there exist important problems that have highly structured models. <br>Previous researchers have used this insight to construct more efficient algorithms for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4916460467327051720&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 5</a> <a href="/scholar?q=related:yKdHG7_GOkQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4916460467327051720&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 21 versions</a> <a onclick="return gs_ocit(event,'yKdHG7_GOkQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB31" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW31"><a href="http://robotics.cs.unc.edu/publications/Patil2011_RSS.pdf" class=yC3E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from unc.edu</span><span class="gs_ggsS">unc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Ziy81kH3KfUC&amp;oi=fnd&amp;pg=PA241&amp;ots=ZYezt13j_Y&amp;sig=v5TnN8tnzEoc-ENclz8zansWMJc" class=yC3D>Motion planning under uncertainty in highly deformable environments</a></h3><div class="gs_a"><a href="/citations?user=zhUgtnAAAAAJ&amp;hl=en&amp;oi=sra">S Patil</a>, <a href="/citations?user=VjsNXysAAAAJ&amp;hl=en&amp;oi=sra">J van den Berg</a>, R Alterovitz - Robotics: Science and  &hellip;, 2012 - books.google.com</div><div class="gs_rs">AbstractâMany tasks in robot-assisted surgery, food handling, manufacturing, and other <br>applications require planning and controlling the motions of manipulators or other devices <br>that must interact with highly deformable objects. We present a unified approach for <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5654394003229212765&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 6</a> <a href="/scholar?q=related:XYCTPmNxeE4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5654394003229212765&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'XYCTPmNxeE4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB32" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW32"><a href="http://www-cvr.ai.uiuc.edu/~seth/ResPages/pdfs/icra10a.pdf" class=yC40><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uiuc.edu</span><span class="gs_ggsS">uiuc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5509494" class=yC3F>Exploiting domain knowledge in planning for uncertain robot systems modeled as POMDPs</a></h3><div class="gs_a"><a href="/citations?user=BDgbhmEAAAAJ&amp;hl=en&amp;oi=sra">S Candido</a>, J Davidson&hellip; - Robotics and Automation ( &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We propose a planning algorithm that allows user-supplied domain knowledge to <br>be exploited in the synthesis of information feedback policies for systems modeled as <br>partially observable Markov decision processes (POMDPs). POMDP models, which are <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1908798138939759472&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 4</a> <a href="/scholar?q=related:cFtuS8tpfRoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1908798138939759472&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'cFtuS8tpfRoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:367"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5209523" class=yC41>Robotic assistance with attitude: A mobility agent for motor function rehabilitation and ambulation support</a></h3><div class="gs_a">JV Miro, V Osswald, M Patel&hellip; - &hellip;  Robotics, 2009. ICORR &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents the design of an intelligent walking aid for the frail and elderly <br>as well as for patients who are recovering from surgical procedures, in order to enhance <br>safer mobility for these study populations. The device augments a conventional rolling <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15897986752158941921&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 4</a> <a href="/scholar?q=related:4cJMTrj-oNwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'4cJMTrj-oNwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:366"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB34" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW34"><a href="http://www.robots.ox.ac.uk/~posnerhi/Publications/PlanningToPerceive_icaps11.pdf" class=yC43><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ox.ac.uk</span><span class="gs_ggsS">ox.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.aaai.org/ocs/index.php/ICAPS/ICAPS11/paper/download/2707@misc/3177" class=yC42>Planning to perceive: Exploiting mobility for robust object detection</a></h3><div class="gs_a">J Velez, G Hemann, A Huang, I Posner, <a href="/citations?user=aM3i_9oAAAAJ&amp;hl=en&amp;oi=sra">N Roy</a> - Proc. ICAPS, 2011 - aaai.org</div><div class="gs_rs">Abstract Consider the task of a mobile robot autonomously navigating through an <br>environment while detecting and mapping objects of interest using a noisy object detector. <br>The robot must reach its destination in a timely manner, but is rewarded for correctly <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4034186770410820977&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 7</a> <a href="/scholar?q=related:cdXqX35P_DcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4034186770410820977&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'cdXqX35P_DcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:365"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB35" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW35"><a href="https://www1.comp.nus.edu.sg/~leews/publications/rss11.pdf" class=yC45><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Ziy81kH3KfUC&amp;oi=fnd&amp;pg=PA1&amp;ots=ZYezt13j_Y&amp;sig=J4m2E1WJo-E_2qhzqzLe9SAY-Fg" class=yC44>Unmanned aircraft collision avoidance using continuous-state POMDPs</a></h3><div class="gs_a"><a href="/citations?user=ho595lUAAAAJ&amp;hl=en&amp;oi=sra">H Bai</a>, <a href="/citations?user=S9LHLKEAAAAJ&amp;hl=en&amp;oi=sra">D Hsu</a>, MJ Kochenderfer&hellip; - Robotics: Science and  &hellip;, 2012 - books.google.com</div><div class="gs_rs">AbstractâAn effective collision avoidance system for unmanned aircraft will enable them to <br>fly in civil airspace and greatly expand their applications. One promising approach is to <br>model aircraft collision avoidance as a partially observable Markov decision process (<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4705016597772573552&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 5</a> <a href="/scholar?q=related:cBuN3KqTS0EJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4705016597772573552&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 14 versions</a> <a onclick="return gs_ocit(event,'cBuN3KqTS0EJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:364"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB36" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW36"><a href="http://swing.adm.ri.cmu.edu/pub_files/2009/5/HollingerICRA09.pdf" class=yC47><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cmu.edu</span><span class="gs_ggsS">cmu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5152305" class=yC46>Combining search and action for mobile robots</a></h3><div class="gs_a"><a href="/citations?user=0SQP4bwAAAAJ&amp;hl=en&amp;oi=sra">G Hollinger</a>, D Ferguson, <a href="/citations?user=RCi98EAAAAAJ&amp;hl=en&amp;oi=sra">S Srinivasa</a>&hellip; - &hellip;  and Automation, 2009 &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We explore the interconnection between search and action in the context of mobile <br>robotics. The task of searching for an object and then performing some action with that <br>object is important in many applications. Of particular interest to us is the idea of a robot <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2179212018307577975&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 5</a> <a href="/scholar?q=related:dzh84cgdPh4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2179212018307577975&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'dzh84cgdPh4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:363"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB37" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW37"><a href="http://www.cs.mcgill.ca/~spng/spng_masterthesis.pdf" class=yC49><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mcgill.ca</span><span class="gs_ggsS">mcgill.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5946754" class=yC48>Bayesian reinforcement learning for POMDP-based dialogue systems</a></h3><div class="gs_a"><a href="/citations?user=wZy6aw0AAAAJ&amp;hl=en&amp;oi=sra">SW Png</a>, <a href="/citations?user=CEt6_mMAAAAJ&amp;hl=en&amp;oi=sra">J Pineau</a> - Acoustics, Speech and Signal Processing ( &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Spoken dialogue systems are gaining popularity with improvements in speech <br>recognition technologies. Dialogue systems can be modeled effectively using POMDPs, <br>achieving improvements in robustness. However, past research on POMDPs-based <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6622246875075919245&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 5</a> <a href="/scholar?q=related:jT3XW3Ly5lsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6622246875075919245&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'jT3XW3Ly5lsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:362"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB38" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW38"><a href="http://www.frc.ri.cmu.edu/~gholling/thesis/HollingerThesis.pdf" class=yC4B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cmu.edu</span><span class="gs_ggsS">cmu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.frc.ri.cmu.edu/~gholling/thesis/HollingerThesis.pdf" class=yC4A>Search in the physical world</a></h3><div class="gs_a"><a href="/citations?user=0SQP4bwAAAAJ&amp;hl=en&amp;oi=sra">GA Hollinger</a> - 2010 - frc.ri.cmu.edu</div><div class="gs_rs">Abstract This thesis examines search in the physical world, which differs significantly from <br>the searches in the digital world that we perform every day on our computers. When <br>searching the internet, for instance, success is a matter of informed indexing that allows <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9551550893529257650&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 4</a> <a href="/scholar?q=related:slbgbu7sjYQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9551550893529257650&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'slbgbu7sjYQJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md38', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md38" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:slbgbu7sjYQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a>  <a href="/scholar?q=info:slbgbu7sjYQJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=14017187488309340715&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:361"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB39" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW39"><a href="http://hal.inria.fr/docs/00/60/74/03/PDF/secart11.pdf" class=yC4D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from inria.fr</span><span class="gs_ggsS">inria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://hal.inria.fr/inria-00607403/" class=yC4C>Penetration Testing== POMDP Solving?</a></h3><div class="gs_a">C Sarraute, O Buffet, <a href="/citations?user=NR6qg_UAAAAJ&amp;hl=en&amp;oi=sra">J Hoffmann</a> - Workshop on Intelligent Security ( &hellip;, 2011 - hal.inria.fr</div><div class="gs_rs">RÃ©sumÃ©: Penetration Testing is a methodology for assessing network security, by <br>generating and executing possible attacks. Doing so automatically allows for regular and <br>systematic testing without a prohibitive amount of human labor. A key question then is how <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3527640617790674016&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 3</a> <a href="/scholar?q=related:YBSnnnOy9DAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3527640617790674016&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'YBSnnnOy9DAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:360"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB40" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW40"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.221.8852&amp;rep=rep1&amp;type=pdf#page=314" class=yC4F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2132923" class=yC4E>Multi-policy dialogue management</a></h3><div class="gs_a"><a href="/citations?user=LcLqSYIAAAAJ&amp;hl=en&amp;oi=sra">P Lison</a> - Proceedings of the SIGDIAL 2011 Conference, 2011 - dl.acm.org</div><div class="gs_rs">Abstract We present a new approach to dialogue management based on the use of multiple, <br>inter-connected policies. Instead of capturing the complexity of the interaction in a single <br>large policy, the dialogue manager operates with a collection of small local policies <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16433657030177144602&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 4</a> <a href="/scholar?q=related:Gj9P7P8TEOQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16433657030177144602&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 17 versions</a> <a onclick="return gs_ocit(event,'Gj9P7P8TEOQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:359"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB41" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW41"><a href="http://www.cs.mcgill.ca/~spng/publications/icaps10.pdf" class=yC51><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mcgill.ca</span><span class="gs_ggsS">mcgill.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.cs.mcgill.ca/~spng/publications/icaps10.pdf" class=yC50>A POMDP approach to robot motion planning under uncertainty</a></h3><div class="gs_a">A IN - cs.mcgill.ca</div><div class="gs_rs">Abstract Motion planning in uncertain and dynamic environments is critical for reliable <br>operation of autonomous robots. Partially observable Markov decision processes (POMDPs) <br>provide a principled general framework for such planning tasks and have been <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4281760151563061329&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 3</a> <a href="/scholar?q=related:UchWDyzeazsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4281760151563061329&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'UchWDyzeazsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md41', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md41" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:UchWDyzeazsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:358"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB42" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW42"><a href="http://msl.cs.uiuc.edu/~lavalle/papers/Lav11.pdf" class=yC53><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uiuc.edu</span><span class="gs_ggsS">uiuc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dx.doi.org/10.1561/2300000004" class=yC52>Sensing and filtering: A fresh perspective based on preimages and information spaces</a></h3><div class="gs_a"><a href="/citations?user=72e5VYEAAAAJ&amp;hl=en&amp;oi=sra">SM LaValle</a> - Foundations and Trends in Robotics, 2010 - dx.doi.org</div><div class="gs_rs">Abstract This paper presents an unusual perspective on sensing uncertainty and filtering <br>with the intention of understanding what information is minimally needed to achieve a <br>specified task. Information itself is modeled using information space concepts, which <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15953239761730695035&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 2</a> <a href="/scholar?q=related:e2-YFgpLZd0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15953239761730695035&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'e2-YFgpLZd0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:357"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB43" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW43"><a href="http://hal.inria.fr/docs/00/52/94/98/PDF/RR-7433.pdf" class=yC55><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from inria.fr</span><span class="gs_ggsS">inria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://hal.inria.fr/inria-00529498/" class=yC54>A POMDP Extension with Belief-dependent Rewards (Extended Version)</a></h3><div class="gs_a"><a href="/citations?user=52foGUkAAAAJ&amp;hl=en&amp;oi=sra">M Araya-LÃ³pez</a>, O Buffet, V Thomas, <a href="/citations?user=NjZluukAAAAJ&amp;hl=en&amp;oi=sra">F Charpillet</a> - 2010 - hal.inria.fr</div><div class="gs_rs">RÃ©sumÃ©: Partially Observable Markov Decision Processes (POMDPs) model sequential <br>decision-making problems under uncertainty and partial observability. Unfortunately, some <br>problems cannot be modeled with state-dependent reward functions, eg, problems whose <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15985691259048919373&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 2</a> <a href="/scholar?q=related:TYGtGIGV2N0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15985691259048919373&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'TYGtGIGV2N0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:356"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.worldscientific.com/doi/abs/10.1142/S0219843610002179" class=yC56>Task-Oriented Probabilistic Active Vision</a></h3><div class="gs_a">P GUERRERO, <a href="/citations?user=U0XHBs8AAAAJ&amp;hl=en&amp;oi=sra">J RUIZ-DEL-SOLAR</a>&hellip; - &hellip;  Journal of Humanoid  &hellip;, 2010 - World Scientific</div><div class="gs_rs">In this work, an explicitly task-oriented approach to the active vision problem is presented. <br>The system tries to reduce the most relevant components of the uncertainty in the world <br>model, for the task the robot is currently performing. It is task oriented in the sense that it <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16565306549197619410&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 2</a> <a href="/scholar?q=related:0kBgLIrK4-UJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16565306549197619410&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'0kBgLIrK4-UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:355"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB45" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW45"><a href="http://dspace.mit.edu/bitstream/handle/1721.1/64487/727063332.pdf?sequence=1" class=yC58><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dspace.mit.edu/handle/1721.1/64487" class=yC57>Planning under uncertainty for dynamic collision avoidance</a></h3><div class="gs_a"><a href="/citations?user=4b2I74MAAAAJ&amp;hl=en&amp;oi=sra">S Temizer</a> - 2011 - dspace.mit.edu</div><div class="gs_rs">We approach dynamic collision avoidance problem from the perspective of designing <br>collision avoidance systems for unmanned aerial vehicles. Before unmanned aircraft can fly <br>safely in civil airspace, robust airborne collision avoidance systems must be developed. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16640102387310719042&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 3</a> <a href="/scholar?q=related:QvDITfWE7eYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16640102387310719042&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'QvDITfWE7eYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md45', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md45" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:QvDITfWE7eYJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=16819422701663093285&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:354"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB46" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW46"><a href="http://acl.eldoc.ub.rug.nl/mirror/W/W10/W10-4337.pdf" class=yC5A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from rug.nl</span><span class="gs_ggsS">rug.nl <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1944542" class=yC59>Investigating clarification strategies in a hybrid POMDP dialog manager</a></h3><div class="gs_a">S Varges, S Quarteroni, <a href="/citations?user=k9pXsKoAAAAJ&amp;hl=en&amp;oi=sra">G Riccardi</a>&hellip; - Proceedings of the 11th  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract We investigate the clarification strategies exhibited by a hybrid POMDP dialog <br>manager based on data obtained from a phone-based user study. The dialog manager <br>combines task structures with a number of POMDP policies each optimized for obtaining <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=440948333708803712&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 2</a> <a href="/scholar?q=related:gH4DWyyQHgYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=440948333708803712&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'gH4DWyyQHgYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:353"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5652268" class=yC5B>Programming by demonstration of probabilistic decision making on a multi-modal service robot</a></h3><div class="gs_a">SR Schmidt-Rohr, M LoÌsch, R JaÌkel&hellip; - Intelligent Robots and &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper we propose a process which is able to generate abstract service robot <br>mission representations, utilized during execution for autonomous, probabilistic decision <br>making, by observing human demonstrations. The observation process is based on the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6833552141415603356&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 3</a> <a href="/scholar?q=related:nNwvh3en1V4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'nNwvh3en1V4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:352"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB48" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW48"><a href="http://arl.cs.utah.edu/pubs/ICRA2012-1.pdf" class=yC5D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from utah.edu</span><span class="gs_ggsS">utah.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6224648" class=yC5C>LQG-obstacles: Feedback control with collision avoidance for mobile robots with motion and sensing uncertainty</a></h3><div class="gs_a"><a href="/citations?user=VjsNXysAAAAJ&amp;hl=en&amp;oi=sra">J van den Berg</a>, D Wilkie, <a href="/citations?user=aVg7BRwAAAAJ&amp;hl=en&amp;oi=sra">SJ Guy</a>&hellip; - &hellip;  (ICRA), 2012 IEEE  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents LQG-Obstacles, a new concept that combines linear-quadratic <br>feedback control of mobile robots with guaranteed avoidance of collisions with obstacles. <br>Our approach generalizes the concept of Velocity Obstacles [3] to any robotic system with <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4639961015035609020&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 3</a> <a href="/scholar?q=related:vL_bqPVzZEAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4639961015035609020&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'vL_bqPVzZEAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:351"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB49" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW49"><a href="http://arxiv.org/pdf/1202.5544" class=yC5F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arxiv.org</span><span class="gs_ggsS">arxiv.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6225158" class=yC5E>An incremental sampling-based algorithm for stochastic optimal control</a></h3><div class="gs_a">VA Huynh, <a href="/citations?user=Vu-Zb7EAAAAJ&amp;hl=en&amp;oi=sra">S Karaman</a>, <a href="/citations?user=8JGG3KcAAAAJ&amp;hl=en&amp;oi=sra">E Frazzoli</a> - Robotics and Automation ( &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we consider a class of continuous-time, continuous-space stochastic <br>optimal control problems. Building upon recent advances in Markov chain approximation <br>methods and sampling-based algorithms for deterministic path planning, we propose a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13641623997165191231&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 2</a> <a href="/scholar?q=related:P8B5vr_IUL0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13641623997165191231&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'P8B5vr_IUL0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:350"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB50" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW50"><a href="http://www.cs.cmu.edu/~./ebrun/brunskillPhD.pdf" class=yC61><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cmu.edu</span><span class="gs_ggsS">cmu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.cs.cmu.edu/~./ebrun/brunskillPhD.pdf" class=yC60>Compact parametric models for efficient sequential decision making in high-dimensional, uncertain domains</a></h3><div class="gs_a">EP Brunskill - 2009 - cs.cmu.edu</div><div class="gs_rs">Abstract Within artificial intelligence and robotics there is considerable interest in how a <br>single agent can autonomously make sequential decisions in large, high-dimensional, <br>uncertain domains. This thesis presents decision-making algorithms for maximizing the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1175372084797979417&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:GTtLCa_CTxAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1175372084797979417&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'GTtLCa_CTxAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md50', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md50" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:GTtLCa_CTxAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a>  <a href="/scholar?q=info:GTtLCa_CTxAJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=16659333588186523576&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:349"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB51" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW51"><a href="http://junction.stanford.edu/~lall/publications/tpmdp.pdf" class=yC63><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from stanford.edu</span><span class="gs_ggsS">stanford.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.aaai.org/ocs/index.php/SSS/SSS10/paper/download/1137/1420" class=yC62>An Exact Dynamic Programming Solution for a Decentralized Two-Player Markov Decision Process</a></h3><div class="gs_a">J Wu, <a href="/citations?user=C-LkdokAAAAJ&amp;hl=en&amp;oi=sra">S Lall</a> - Proceedings of the AAAI Spring Symposium Series, 2010 - aaai.org</div><div class="gs_rs">Abstract We present an exact dynamic programming solution for a finite-horizon <br>decentralized two-player Markov decision process, where player 1 only has access to its <br>own states, while player 2 has access to both player&#39;s states but cannot affect player 1&#39;s <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18196481062827485816&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:eGr0Fx7jhvwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18196481062827485816&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'eGr0Fx7jhvwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:348"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB52" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW52"><a href="http://www.wrighteagle.org/en/research/pomdppublication/zcsimpar2010.pdf" class=yC65><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from wrighteagle.org</span><span class="gs_ggsS">wrighteagle.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/DJ61P5304196208V.pdf" class=yC64>Accelerating point-based pomdp algorithms via greedy strategies</a></h3><div class="gs_a">Z Zhang, X Chen - &hellip; , Modeling, and Programming for Autonomous Robots, 2010 - Springer</div><div class="gs_rs">Many planning tasks of autonomous robots can be modeled as partially observable Markov <br>decision process (POMDP) problems. Point-based algorithms are well-known algorithms for <br>solving large-scale POMDP problems. Several leading point-based algorithms eschew <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3719528136869522041&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:eaotMiJrnjMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3719528136869522041&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'eaotMiJrnjMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:347"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB53" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW53"><a href="http://books.nips.cc/papers/files/nips24/NIPS2011_1435.pdf" class=yC67><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nips.cc</span><span class="gs_ggsS">nips.cc <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://books.nips.cc/papers/files/nips24/NIPS2011_1435.pdf" class=yC66>Periodic finite state controllers for efficient POMDP and DEC-POMDP planning</a></h3><div class="gs_a">J Pajarinen, <a href="/citations?user=WFYU6DkAAAAJ&amp;hl=en&amp;oi=sra">J Peltonen</a> - Proc. of the 25th Annual Conf. on Neural  &hellip;, 2011 - books.nips.cc</div><div class="gs_rs">Abstract Applications such as robot control and wireless communication require planning <br>under uncertainty. Partially observable Markov decision processes (POMDPs) plan policies <br>for single agents under uncertainty and their decentralized versions (DEC-POMDPs) find <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8912111488899823908&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:JDmNRi4urnsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8912111488899823908&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'JDmNRi4urnsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md53', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md53" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:JDmNRi4urnsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:346"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB54" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW54"><a href="http://home.ustc.edu.cn/~zzz/download/ZhangLittmanChen-AAAI2012.pdf" class=yC69><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ustc.edu.cn</span><span class="gs_ggsS">ustc.edu.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/download/4906/5343" class=yC68>Covering Number as a Complexity Measure for POMDP Planning and Learning</a></h3><div class="gs_a">Z Zhang, <a href="/citations?user=Jj00ksMAAAAJ&amp;hl=en&amp;oi=sra">M Littman</a>, X Chen - Proceedings of the Twenty-Sixth AAAI  &hellip;, 2012 - aaai.org</div><div class="gs_rs">Abstract Finding a meaningful way of characterizing the difficulty of partially observable <br>Markov decision processes (POMDPs) is a core theoretical problem in POMDP research. <br>State-space size is often used as a proxy for POMDP difficulty, but it is a weak metric at <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2484594352663288298&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:6tlvWWYNeyIJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2484594352663288298&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'6tlvWWYNeyIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:345"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB55" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW55"><a href="http://dspace.mit.edu/bitstream/handle/1721.1/59660/668106876.pdf?sequence=1" class=yC6B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dspace.mit.edu/handle/1721.1/59660" class=yC6A>Semi-conditional planners for efficient planning under uncertainty with macro-actions</a></h3><div class="gs_a">R He - 2010 - dspace.mit.edu</div><div class="gs_rs">Planning in large, partially observable domains is challenging, especially when good <br>performance requires considering situations far in the future. Existing planners typically <br>construct a policy by performing fully conditional planning, where each future action is <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12047082318634271891&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:k8QVZorVL6cJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12047082318634271891&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'k8QVZorVL6cJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md55', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md55" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:k8QVZorVL6cJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=3921413992834698397&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:344"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB56" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW56"><a href="http://lis.csail.mit.edu/pubs/macindoe-aiide12.pdf" class=yC6D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.aaai.org/ocs/index.php/AIIDE/AIIDE12/paper/download/5461/5694" class=yC6C>Pomcop: Belief space planning for sidekicks in cooperative games</a></h3><div class="gs_a">O Macindoe, LP Kaelbling, <a href="/citations?user=gQOKAggAAAAJ&amp;hl=en&amp;oi=sra">T Lozano-PÃ©rez</a> - Eighth Artificial Intelligence  &hellip;, 2012 - aaai.org</div><div class="gs_rs">Abstract We present POMCoP, a system for online planning in collaborative domains that <br>reasons about how its actions will affect its understanding of human intentions, and <br>demonstrate its use in building sidekicks for cooperative games. POM-CoP plans in belief <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18243231705850303765&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a onclick="return gs_ocit(event,'FdVZZpT6LP0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:343"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB57" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW57"><a href="http://iweb.tntech.edu/rqiu/publications/2009_mar_sensors.pdf" class=yC6F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tntech.edu</span><span class="gs_ggsS">tntech.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://iweb.tntech.edu/rqiu/publications/2009_mar_sensors.pdf" class=yC6E>A Unified Framework for Cognitive Radio, Cognitive Radar, and Electronic WarfareâTutorial, Theory, and Multi-GHz Wideband Testbed</a></h3><div class="gs_a"><a href="/citations?user=FTLNXX8AAAAJ&amp;hl=en&amp;oi=sra">R Qiu</a>, N Guo, H Li, Z Wu, V Chakravarthy, Y Song&hellip; - Sensors, 2009 - iweb.tntech.edu</div><div class="gs_rs">Abstract: Dynamic spectrum access is a must-have ingredient for future sensors that are <br>ideally cognitive. The goal of this paper is a tutorial treatment of wideband cognitive radio <br>and radarâa convergence.(1) Algorithms survey;(2) Hardware Platforms survey;(3) <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12510033918689942019&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:Axqaa5GRnK0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Axqaa5GRnK0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md57', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md57" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Axqaa5GRnK0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:342"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB58" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW58"><a href="http://arl.cs.utah.edu/pubs/AAAI2012.pdf" class=yC71><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from utah.edu</span><span class="gs_ggsS">utah.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/viewPDFInterstitial/5159/5340" class=yC70>Efficient approximate value iteration for continuous Gaussian POMDPs</a></h3><div class="gs_a"><a href="/citations?user=VjsNXysAAAAJ&amp;hl=en&amp;oi=sra">J van den Berg</a>, <a href="/citations?user=zhUgtnAAAAAJ&amp;hl=en&amp;oi=sra">S Patil</a>, R Alterovitz - 26th AAAI conference on artificial  &hellip;, 2012 - aaai.org</div><div class="gs_rs">Abstract We introduce a highly efficient method for solving continuous partially-observable <br>Markov decision processes (POMDPs) in which beliefs can be modeled using Gaussian <br>distributions over the state space. Our method enables fast solutions to sequential <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14130097962501276761&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:WQRcgDsxGMQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14130097962501276761&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'WQRcgDsxGMQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:341"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB59" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW59"><a href="http://www.cs.uwaterloo.ca/~ppoupart/publications/gapMin/gap-camera-ready.pdf" class=yC73><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uwaterloo.ca</span><span class="gs_ggsS">uwaterloo.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.aaai.org/ocs/index.php/ICAPS/ICAPS11/paper/download/2702/3152" class=yC72>Closing the gap: Improved bounds on optimal POMDP solutions</a></h3><div class="gs_a">P Poupart, KE Kim, D Kim - &hellip; on Automated Planning and Scheduling (ICAPS &hellip;, 2011 - aaai.org</div><div class="gs_rs">Abstract POMDP algorithms have made significant progress in recent years by allowing <br>practitioners to find good solutions to increasingly large problems. Most approaches <br>(including point-based and policy iteration techniques) operate by refining a lower bound <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16849784847886438581&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 5</a> <a href="/scholar?q=related:tdAHkAt21ukJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16849784847886438581&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'tdAHkAt21ukJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:340"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB60" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW60"><a href="http://ipc-2011-aim.googlecode.com/svn-history/r65/trunk/aim2011.pdf" class=yC75><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from googlecode.com</span><span class="gs_ggsS">googlecode.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://ipc-2011-aim.googlecode.com/svn-history/r65/trunk/aim2011.pdf" class=yC74>A Survey of the Seventh International Planning Competition</a></h3><div class="gs_a"><a href="/citations?user=EArg5moAAAAJ&amp;hl=en&amp;oi=sra">ACA Coles</a>, AGOSJ CarlosLinaresLÃ³pez, <a href="/citations?user=kB8UPNIAAAAJ&amp;hl=en&amp;oi=sra">S Sanner</a>&hellip; - 2011 - ipc-2011-aim.googlecode.com</div><div class="gs_rs">Abstract In this article we review the 2011 International Planning Competition. We give an <br>overview of the history of the competition, discussing how it has developed since its first <br>edition in 1998. The 2011 competition was run in three main separate tracks: the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7213603322233683251&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 4</a> <a href="/scholar?q=related:M_1QlADeG2QJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7213603322233683251&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'M_1QlADeG2QJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md60', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md60" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:M_1QlADeG2QJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:339"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB61" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW61"><a href="https://www.cs.indiana.edu/~hauserk/papers/permis09-decision-theoretic.pdf" class=yC77><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from indiana.edu</span><span class="gs_ggsS">indiana.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1865964" class=yC76>A decision-theoretic formalism for belief-optimal reasoning</a></h3><div class="gs_a">K Hauser - Proceedings of the 9th Workshop on Performance  &hellip;, 2009 - dl.acm.org</div><div class="gs_rs">Abstract Intelligent systems must often reason with partial or corrupted information, due to <br>noisy sensors, limited representation capabilities, and inherent problem complexity. <br>Gathering new information and reasoning with existing information comes at a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10682676878619593738&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:CkxmmAV-QJQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10682676878619593738&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'CkxmmAV-QJQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:338"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6088640" class=yC78>A knowledge base for learning probabilistic decision making from human demonstrations by a multimodal service robot</a></h3><div class="gs_a">SR Schmidt-Rohr, G Dirschl&hellip; - &hellip;  (ICAR), 2011 15th  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents a description logic based system to store and retrieve <br>knowledge used in models for autonomous probabilistic decision making by multimodal <br>service robots. These models are mainly generated by observation and analysis of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4391341034937085765&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:RW8Fq2ct8TwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'RW8Fq2ct8TwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:337"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB63" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW63"><a href="http://people.csail.mit.edu/tlp/publications/ICRA12_1775_FI.pdf" class=yC7A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6225223" class=yC79>Non-gaussian belief space planning: Correctness and complexity</a></h3><div class="gs_a"><a href="/citations?user=Z4Y5S2oAAAAJ&amp;hl=en&amp;oi=sra">R Platt</a>, L Kaelbling, <a href="/citations?user=gQOKAggAAAAJ&amp;hl=en&amp;oi=sra">T Lozano-Perez</a>&hellip; - &hellip;  and Automation (ICRA &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We consider the partially observable control problem where it is potentially <br>necessary to perform complex information-gathering operations in order to localize state. <br>One approach to solving these problems is to create plans in belief-space, the space of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=827695223843977028&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 3</a> <a href="/scholar?q=related:RPeBt2uQfAsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=827695223843977028&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'RPeBt2uQfAsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:336"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB64" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW64"><a href="http://dspace.mit.edu/bitstream/handle/1721.1/45281/311815419.pdf?sequence=1" class=yC7C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dspace.mit.edu/handle/1721.1/45281" class=yC7B>Combining local and global optimization for planning and control in information space</a></h3><div class="gs_a">VA Huynh - 2008 - dspace.mit.edu</div><div class="gs_rs">This thesis presents a novel algorithm, called the parametric optimized belief roadmap <br>(POBRM), to address the problem of planning a trajectory for controlling a robot with <br>imperfect state information under uncertainty. This question is formulated abstractly as a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15639341821933963150&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:jsdIuYYaCtkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15639341821933963150&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'jsdIuYYaCtkJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md64', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md64" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:jsdIuYYaCtkJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=5915650665446391385&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:335"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB65" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW65"><a href="http://www.bgu.ac.il/~shanigu/Publications/PointBasedSurvey.pdf" class=yC7E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from bgu.ac.il</span><span class="gs_ggsS">bgu.ac.il <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/8675533181296q51.pdf" class=yC7D>A survey of point-based POMDP solvers</a></h3><div class="gs_a"><a href="/citations?user=F2JS3YIAAAAJ&amp;hl=en&amp;oi=sra">G Shani</a>, <a href="/citations?user=CEt6_mMAAAAJ&amp;hl=en&amp;oi=sra">J Pineau</a>, R Kaplow - Autonomous Agents and Multi-Agent  &hellip;, 2012 - Springer</div><div class="gs_rs">Abstract The past decade has seen a significant breakthrough in research on solving <br>partially observable Markov decision processes (POMDPs). Where past solvers could not <br>scale beyond perhaps a dozen states, modern solvers can handle complex domains with <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13447824339711406310&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 5</a> <a href="/scholar?q=related:5rBZwvxEoLoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13447824339711406310&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'5rBZwvxEoLoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:334"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5598670" class=yC7F>Learning flexible, multi-modal human-robot interaction by observing human-human-interaction</a></h3><div class="gs_a">SR Schmidt-Rohr, M Losch, R Dillmann - RO-MAN, 2010 IEEE, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper presents a technique to learn flexible action selection in autonomous, <br>multi-modal human-robot interaction (HRI) from observing multi-modal human-human <br>interaction (HHI). A model is generated using the proposed technique with symbolic states <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14084359662930042638&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:Dh_JxX2ydcMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Dh_JxX2ydcMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:333"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6407655" class=yC80>POMDP-Based Statistical Spoken Dialog Systems: A Review</a></h3><div class="gs_a">S Young, <a href="/citations?user=yDSBDJoAAAAJ&amp;hl=en&amp;oi=sra">M GaÅ¡iÄ</a>, B Thomson, <a href="/citations?user=CcLxiyMAAAAJ&amp;hl=en&amp;oi=sra">JD Williams</a> - 2013 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Statistical dialog systems (SDSs) are motivated by the need for a data-driven <br>framework that reduces the cost of laboriously handcrafting complex dialog managers and <br>that provides robustness against the errors created by speech recognizers operating in <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5814687832889998252&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a onclick="return gs_ocit(event,'rLsxx8brsVAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:332"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB68" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW68"><a href="http://www.mmk.ei.tum.de/publ/pdf/09/09sch23.pdf" class=yC82><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tum.de</span><span class="gs_ggsS">tum.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.mmk.ei.tum.de/publ/pdf/09/09sch23.pdf" class=yC81>Using Graphical Models for Mixed-Initiative Dialog Management Systems with Realtime Policies</a></h3><div class="gs_a">S SchwÃ¤rzler, S Maier, J Schenk, F Wallhoff&hellip; - Proceedings of the  &hellip;, 2009 - mmk.ei.tum.de</div><div class="gs_rs">Abstract In this paper, we present a novel approach for dialog modeling, which extends the <br>idea underlying the partially observable Markov Decision Processes (POMDPs), ie it allows <br>for calculating the dialog policy in real-time and thereby increases the system flexibility. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11275321438331762570&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:incc5Bv9eZwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11275321438331762570&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'incc5Bv9eZwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:331"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB69" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW69"><a href="http://vault.willowgarage.com/wgdata1/vol1/muu11/WS-F-12-17.pdf" class=yC84><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from willowgarage.com</span><span class="gs_ggsS">willowgarage.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://vault.willowgarage.com/wgdata1/vol1/muu11/WS-F-12-17.pdf" class=yC83>Simultaneous localization and grasping using belief space planning</a></h3><div class="gs_a"><a href="/citations?user=Z4Y5S2oAAAAJ&amp;hl=en&amp;oi=sra">R Platt</a>, L Kaelbling, <a href="/citations?user=gQOKAggAAAAJ&amp;hl=en&amp;oi=sra">T Lozano-Perez</a>&hellip; - In Proceedings of the &hellip;, 2011 - vault.willowgarage.com</div><div class="gs_rs">AbstractâMost approaches to grasp planning assume that the configurations of the object to <br>be grasped and any potential obstacles are known perfectly. As a result, implementations of <br>these âperfect informationâ approaches to grasp synthesis are necessarily preceded by a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2424290372801219062&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:9kk35z_PpCEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'9kk35z_PpCEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md69', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md69" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:9kk35z_PpCEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:330"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB70" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW70"><a href="http://arxiv.org/pdf/1203.1177" class=yC86><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arxiv.org</span><span class="gs_ggsS">arxiv.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://arxiv.org/abs/1203.1177" class=yC85>Control of Probabilistic Systems under Dynamic, Partially Known Environments with Temporal Logic Specifications</a></h3><div class="gs_a">T Wongpiromsarn, <a href="/citations?user=8JGG3KcAAAAJ&amp;hl=en&amp;oi=sra">E Frazzoli</a> - arXiv preprint arXiv:1203.1177, 2012 - arxiv.org</div><div class="gs_rs">Abstract: We consider the synthesis of control policies for probabilistic systems, modeled by <br>Markov decision processes, operating in partially known environments with temporal logic <br>specifications. The environment is modeled by a set of Markov chains. Each Markov chain <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12465846872046108779&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:awC56K6V_6wJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12465846872046108779&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'awC56K6V_6wJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:329"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB71" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW71"><a href="http://anytime.cs.umass.edu/~camato/msdm2010/MSDM10.pdf#page=56" class=yC88><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from umass.edu</span><span class="gs_ggsS">umass.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://anytime.cs.umass.edu/~camato/msdm2010/MSDM10.pdf#page=56" class=yC87>Multi-robot planning under uncertainty with communication: a case study</a></h3><div class="gs_a">JV Messias, MTJ Spaan&hellip; - Fifth Workshop on Multi- &hellip;, 2010 - anytime.cs.umass.edu</div><div class="gs_rs">ABSTRACT Although Dec-POMDP techniques can be useful to modeling a wide range of <br>problems, their practical application is limited by the inherent computational complexity of <br>the algorithms currently available to solve such models. The application of these <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16271209302599636570&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:WpZ786byzuEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16271209302599636570&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'WpZ786byzuEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md71', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md71" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:WpZ786byzuEJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:328"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB72" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW72"><a href="http://rms.ae.illinois.edu/papers/De-Pablo2010.pdf" class=yC8A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from illinois.edu</span><span class="gs_ggsS">illinois.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://rms.ae.illinois.edu/papers/De-Pablo2010.pdf" class=yC89>An optimal solution to the linear search problem for a robot with dynamics</a></h3><div class="gs_a">IR De Pablo, A Becker, T Bretl - Intelligent Robots and Systems ( &hellip;, 2010 - rms.ae.illinois.edu</div><div class="gs_rs">AbstractâIn this paper we derive the control policy that minimizes the total expected time for <br>a point mass with bounded acceleration, starting from the origin at rest, to find and return to <br>an unknown target that is distributed uniformly on the unit interval. We apply our result to <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5643579987307960820&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:9Jn-9BgGUk4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5643579987307960820&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'9Jn-9BgGUk4J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md72', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md72" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:9Jn-9BgGUk4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:327"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB73" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW73"><a href="http://web.mit.edu/tirtha/Public/www/research/IntentionAware/wafr12iamp.pdf" class=yC8C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://web.mit.edu/tirtha/Public/www/research/IntentionAware/wafr12iamp.pdf" class=yC8B>Intention aware motion planning</a></h3><div class="gs_a">T Bandyopadhyay, KS Won, <a href="/citations?user=8JGG3KcAAAAJ&amp;hl=en&amp;oi=sra">E Frazzoli</a>, <a href="/citations?user=S9LHLKEAAAAJ&amp;hl=en&amp;oi=sra">D Hsu</a>&hellip; - &hellip;  Foundations of Robotics &hellip;, 2012 - mit.edu</div><div class="gs_rs">Abstract As robots venture into new application domains as autonomous vehicles on the <br>road or as domestic helpers at home, they must recognize human intentions and behaviors <br>in order to operate effectively. This paper investigates a new class of motion planning <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5034716446994528123&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a onclick="return gs_ocit(event,'e_fs9-7n3kUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md73', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md73" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:e_fs9-7n3kUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:326"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB74" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW74"><a href="http://dspace.mit.edu/bitstream/handle/1721.1/68405/768426659.pdf?sequence=1" class=yC8E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dspace.mit.edu/handle/1721.1/68405" class=yC8D>Planning under uncertainty and constraints for teams of autonomous agents</a></h3><div class="gs_a">A Undurti - 2011 - dspace.mit.edu</div><div class="gs_rs">One of the main advantages of unmanned, autonomous vehicles is their potential use in <br>dangerous situations, such as victim search and rescue in the aftermath of an urban <br>disaster. Unmanned vehicles can complement human first responders by performing tasks <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:dXD5BdBVRG4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7945569994530189429&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'dXD5BdBVRG4J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md74', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md74" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:dXD5BdBVRG4J:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=17337088546851882296&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:325"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB75" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW75"><a href="http://www.cecm.usp.br/~felipeh/planning_uncertanty_stockmkt.pdf" class=yC90><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from usp.br</span><span class="gs_ggsS">usp.br <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/G116427655848391.pdf" class=yC8F>Planning under the uncertainty of the technical analysis of stock markets</a></h3><div class="gs_a">A Baffa, A Ciarlini - Advances in Artificial IntelligenceâIBERAMIA 2010, 2010 - Springer</div><div class="gs_rs">The stock market can be considered a nondeterministic and partially observable domain, <br>because investors never know all information that affects prices and the result of an <br>investment is always uncertain. Technical Analysis methods demand only data that are <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:A-UgCPNi3MYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14329436910339024131&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'A-UgCPNi3MYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:324"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB76" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW76"><a href="https://uwspace.uwaterloo.ca/bitstream/10012/7222/1/Koltunova_Veronika.pdf" class=yC92><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uwaterloo.ca</span><span class="gs_ggsS">uwaterloo.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="https://uwspace.uwaterloo.ca/handle/10012/7222" class=yC91>Active Sensing for Partially Observable Markov Decision Processes</a></h3><div class="gs_a">V Koltunova - 2012 - uwspace.uwaterloo.ca</div><div class="gs_rs">Abstract: Context information on a smart phone can be used to tailor applications for specific <br>situations (eg provide tailored routing advice based on location, gas prices and traffic). <br>However, typical context-aware smart phone applications use very limited context <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'k7kNDXHnoq4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:323"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB77" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW77"><a href="http://www.st.ewi.tudelft.nl/~mtjspaan/pub/Spaan12pomdp.pdf" class=yC94><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tudelft.nl</span><span class="gs_ggsS">tudelft.nl <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/P57322T4638124N6.pdf" class=yC93>Partially observable Markov decision processes</a></h3><div class="gs_a">MTJ Spaan - Reinforcement Learning, 2012 - Springer</div><div class="gs_rs">For reinforcement learning in environments in which an agent has access to a reliable state <br>signal, methods based on the Markov decision process (MDP) have had many successes. In <br>many problem domains, however, an agent suffers from limited sensing capabilities that <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7220221289098934755&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:43l0EAJhM2QJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7220221289098934755&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'43l0EAJhM2QJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:322"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB78" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW78"><a href="http://auai.org/uai2012/papers/29.pdf" class=yC96><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from auai.org</span><span class="gs_ggsS">auai.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://auai.org/uai2012/papers/29.pdf" class=yC95>FHHOP: A Factored Hybrid Heuristic Online Planning Algorithm for Large POMDPs</a></h3><div class="gs_a">Z Zhang, X Chen - auai.org</div><div class="gs_rs">Abstract Planning in partially observable Markov decision processes (POMDPs) remains a <br>challenging topic in the artificial intelligence community, in spite of recent impressive <br>progress in approximation techniques. Previous research has indicated that online <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:zk2zEQ6xjEoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5371863129530781134&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'zk2zEQ6xjEoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md78', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md78" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:zk2zEQ6xjEoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:321"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB79" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW79"><a href="http://arxiv.org/pdf/1206.6449" class=yC98><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arxiv.org</span><span class="gs_ggsS">arxiv.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://arxiv.org/abs/1206.6449" class=yC97>Monte Carlo Bayesian Reinforcement Learning</a></h3><div class="gs_a"><a href="/citations?user=pEVxacwAAAAJ&amp;hl=en&amp;oi=sra">Y Wang</a>, KS Won, <a href="/citations?user=S9LHLKEAAAAJ&amp;hl=en&amp;oi=sra">D Hsu</a>, <a href="/citations?user=8PCrLgwAAAAJ&amp;hl=en&amp;oi=sra">WS Lee</a> - arXiv preprint arXiv:1206.6449, 2012 - arxiv.org</div><div class="gs_rs">Abstract: Bayesian reinforcement learning (BRL) encodes prior knowledge of the world in a <br>model and represents uncertainty in model parameters by maintaining a probability <br>distribution over them. This paper presents Monte Carlo BRL (MC-BRL), a simple and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5025651300568941452&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:jENkFzuzvkUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5025651300568941452&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 24 versions</a> <a onclick="return gs_ocit(event,'jENkFzuzvkUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:320"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB80" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW80"><a href="http://www.math.ryerson.ca/~pralat/papers/COV_ICRA.pdf" class=yC9A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ryerson.ca</span><span class="gs_ggsS">ryerson.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.math.ryerson.ca/~pralat/papers/COV_ICRA.pdf" class=yC99>The Role of Visibility in the Cops-Robber Game and Robotic Pursuit/Evasion</a></h3><div class="gs_a"><a href="/citations?user=AiqUHA8AAAAJ&amp;hl=en&amp;oi=sra">A Kehagias</a>, D Mitsche, <a href="/citations?user=8BUZITkAAAAJ&amp;hl=en&amp;oi=sra">P PraÅat</a> - math.ryerson.ca</div><div class="gs_rs">AbstractâThe cops-and-robber (CR) game has been used in mobile robotics as a <br>discretized model of pursuit/evasion problems. The âclassicalâ CR version is a perfect <br>information game: the cop&#39;s (pursuer&#39;s) location is always known to the robber (evader) <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:-7LlGOMac0UJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'-7LlGOMac0UJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md80', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md80" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:-7LlGOMac0UJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:319"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB81" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW81"><a href="http://www.loria.fr/~buffet/papiers/aaai12-b.pdf" class=yC9C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from loria.fr</span><span class="gs_ggsS">loria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/viewFile/4996/5338" class=yC9B>POMDPs Make Better Hackers: Accounting for Uncertainty in Penetration Testing</a></h3><div class="gs_a">C Sarraute, O Buffet, <a href="/citations?user=NR6qg_UAAAAJ&amp;hl=en&amp;oi=sra">J Hoffmann</a> - Twenty-Sixth AAAI Conference on  &hellip;, 2012 - aaai.org</div><div class="gs_rs">Abstract Penetration Testing is a methodology for assessing network security, by generating <br>and executing possible hacking attacks. Doing so automatically allows for regular and <br>systematic testing. A key question is how to generate the attacks. This is naturally <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=279647176509296322&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:wg5HGqCB4QMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=279647176509296322&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'wg5HGqCB4QMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:318"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB82" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW82"><a href="https://www2.lirmm.fr/lirmm/interne/BIBLI/CDROM/ROB/2012/IROS_2012/data/papers/1303.pdf" class=yC9E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from lirmm.fr</span><span class="gs_ggsS">lirmm.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6386011" class=yC9D>POMDP approach to robotized clothes separation</a></h3><div class="gs_a">P MonsÃ³, <a href="/citations?user=-ndXYyoAAAAJ&amp;hl=en&amp;oi=sra">G Alenya</a>, <a href="/citations?user=zXsQ3CkAAAAJ&amp;hl=en&amp;oi=sra">C Torras</a> - Intelligent Robots and Systems ( &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Rigid object manipulation with robots has mainly relied on precise, expensive <br>models and deterministic sequences. Given the great complexity of accurately modeling <br>deformable objects, their manipulation seems to call for a rather different approach. This <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'FhqnHFjPHFgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:317"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB83" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW83"><a href="http://www.ling.uni-potsdam.de/~varges/icassp11/icassp2011.pdf" class=yCA0><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uni-potsdam.de</span><span class="gs_ggsS">uni-potsdam.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5947627" class=yC9F>POMDP concept policies and task structures for hybrid dialog management</a></h3><div class="gs_a">S Varges, <a href="/citations?user=k9pXsKoAAAAJ&amp;hl=en&amp;oi=sra">G Riccardi</a>, S Quarteroni&hellip; - Acoustics, Speech and &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We address several challenges for applying statistical dialog managers based on <br>Partially Observable Markov Models to real world problems: to deal with large numbers of <br>concepts, we use individual POMDP policies for each concept. To control the use of the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11478082400150323234&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 2</a> <a href="/scholar?q=related:IoCfIyFXSp8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11478082400150323234&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'IoCfIyFXSp8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:316"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB84" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW84"><a href="http://www.researchgate.net/publication/233868800_Adaptive_Point-Based_Value_Iteration_for_Continuous_States_POMDP_in_Goal-Directed_Imitation_Learning/file/79e4150ca57178b3a6.pdf" class=yCA2><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from researchgate.net</span><span class="gs_ggsS">researchgate.net <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.researchgate.net/publication/233868800_Adaptive_Point-Based_Value_Iteration_for_Continuous_States_POMDP_in_Goal-Directed_Imitation_Learning/file/79e4150ca57178b3a6.pdf" class=yCA1>Adaptive Point-Based Value Iteration for Continuous States POMDP in Goal-Directed Imitation Learning</a></h3><div class="gs_a">FA Pratama, H Lee, G Lee, NY Chong - researchgate.net</div><div class="gs_rs">Abstract-In motion planning and robot navigation, continuous domain would be the natural <br>way of representation of state space. However, discretization is needed in order to deal with <br>continuous state space. Results precision depends on the discretization, which leads to a <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'KwlcJrYINQwJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md84', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md84" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:KwlcJrYINQwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:315"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB85" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW85"><a href="http://userpage.fu-berlin.de/tlang/pub/11-poupart-lang-toussaint-ECML.pdf" class=yCA4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from fu-berlin.de</span><span class="gs_ggsS">fu-berlin.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/Y3Q086232638U540.pdf" class=yCA3>Analyzing and escaping local optima in planning as inference for partially observable domains</a></h3><div class="gs_a">P Poupart, T Lang, <a href="/citations?user=t2X4Mg8AAAAJ&amp;hl=en&amp;oi=sra">M Toussaint</a> - Machine Learning and Knowledge  &hellip;, 2011 - Springer</div><div class="gs_rs">Planning as inference recently emerged as a versatile approach to decision-theoretic <br>planning and reinforcement learning for single and multi-agent systems in fully and partially <br>observable domains with discrete and continuous variables. Since planning as inference <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:eC8AK5vg43EJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8206649903045160824&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'eC8AK5vg43EJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:314"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB86" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW86"><a href="http://archimede.bibl.ulaval.ca/archimede/fichiers/27534/27534.pdf" class=yCA6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ulaval.ca</span><span class="gs_ggsS">ulaval.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://archimede.bibl.ulaval.ca/archimede/fichiers/27534/27534.pdf" class=yCA5>Predictive Representations For Sequential Decision Making Under Uncertainty</a></h3><div class="gs_a"><a href="/citations?user=8AF3RCsAAAAJ&amp;hl=en&amp;oi=sra">A Boularias</a> - 2010 - archimede.bibl.ulaval.ca</div><div class="gs_rs">Abstract The problem of making decisions is ubiquitous in life. This problem becomes even <br>more complex when the decisions should be made sequentially. In fact, the execution of an <br>action at a given time leads to a change in the environment of the problem, and this <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18116718542604450179&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:g7mrK4eDa_sJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18116718542604450179&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'g7mrK4eDa_sJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md86', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md86" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:g7mrK4eDa_sJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a>  <a href="/scholar?q=info:g7mrK4eDa_sJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=1371672971999793996&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:313"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB87" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW87"><a href="http://web-app.usc.edu/soc/syllabus/20111/30343.pdf" class=yCA8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from usc.edu</span><span class="gs_ggsS">usc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://web-app.usc.edu/soc/syllabus/20111/30343.pdf" class=yCA7>Sequential Decision Making in Robotics</a></h3><div class="gs_a"><a href="/citations?user=0SQP4bwAAAAJ&amp;hl=en&amp;oi=sra">G Hollinger</a>, <a href="/citations?user=lRUi-A8AAAAJ&amp;hl=en&amp;oi=sra">G Sukhatme</a> - 2011 - web-app.usc.edu</div><div class="gs_rs">This course will examine sequential decision making in robotics with a focus on information <br>gathering, path planning, and related optimization problems. We will discuss both <br>fundamental background material as well as cutting edge research in the following areas: <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:nzNUMDsYGqkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'nzNUMDsYGqkJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md87', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md87" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:nzNUMDsYGqkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:312"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB88" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW88"><a href="http://arl.cs.utah.edu/pubs/ICRA2012-2.pdf" class=yCAA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from utah.edu</span><span class="gs_ggsS">utah.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://arl.cs.utah.edu/pubs/ICRA2012-2.pdf" class=yCA9>Estimating Probability of Collision for Safe Planning under Gaussian Motion and Sensing Uncertainty</a></h3><div class="gs_a"><a href="/citations?user=zhUgtnAAAAAJ&amp;hl=en&amp;oi=sra">S Patil</a>, <a href="/citations?user=VjsNXysAAAAJ&amp;hl=en&amp;oi=sra">J van den Berg</a>, R Alterovitz - arl.cs.utah.edu</div><div class="gs_rs">AbstractâWe present a fast, analytical method for estimating the probability of collision of a <br>motion plan for a mobile robot operating under the assumptions of Gaussian motion and <br>sensing uncertainty. Estimating the probability of collision is an integral step in many <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:7XppNTCtO4oJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'7XppNTCtO4oJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md88', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md88" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:7XppNTCtO4oJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:311"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB89" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW89"><a href="https://www.ideals.illinois.edu/bitstream/handle/2142/34400/Davidson_James.pdf?sequence=1" class=yCAC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from illinois.edu</span><span class="gs_ggsS">illinois.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="https://www.ideals.illinois.edu/handle/2142/34400" class=yCAB>Exploiting insensitivity in stochastic systems to learn approximately optimal policies</a></h3><div class="gs_a"><a href="/citations?user=-JPZ21IAAAAJ&amp;hl=en&amp;oi=sra">S Hutchinson</a>, E Amir, M Raginsky, E Zhou - 2012 - ideals.illinois.edu</div><div class="gs_rs">Abstract: How does uncertainty affect a robot when attempting to generate a control policy to <br>achieve some objective? How sensitive is the obtained control policy to perturbations? <br>These are the central questions addressed in this dissertation. For most real-world robotic <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:W4uwNc16GnAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'W4uwNc16GnAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:310"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB90" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW90"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.154.3336&amp;rep=rep1&amp;type=pdf" class=yCAE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.154.3336&amp;rep=rep1&amp;type=pdf" class=yCAD>Decision Theoretic Execution Strategies for Modularized Problem Solvers</a></h3><div class="gs_a">K Hauser, J Latombe - 2010 - Citeseer</div><div class="gs_rs">SUMMARY Large-scale problem solving algorithms will prove to be critical in implementing <br>the long-term vision of cyberphysical systems (CPS). Such algorithms will be highly <br>modularized--that is, they will use subroutines implemented behind abstract interfaces. A <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:fjgFORSicNcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15524086123285788798&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'fjgFORSicNcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md90', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md90" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:fjgFORSicNcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:309"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB91" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW91"><a href="http://repositories.tdl.org/ttu-ir/bitstream/handle/2346/47031/BORERA-DISSERTATION.pdf?sequence=1" class=yCB0><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tdl.org</span><span class="gs_ggsS">tdl.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://repositories.tdl.org/ttu-ir/handle/2346/47031" class=yCAF>Applying Partially Observable Markov Decision Processes to Anesthesia Control: A Simulated Study.</a></h3><div class="gs_a">EC Borera - 2012 - repositories.tdl.org</div><div class="gs_rs">To have a better controller, this research applies Partially Observable Markov Decision <br>Process (POMDP) framework to achieve better drug delivery policy, even when there is <br>incomplete information about a patients&#39; current states during a general anesthesia. In this <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'HINaOttXQcgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:308"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB92" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW92"><a href="http://dspace.mit.edu/bitstream/handle/1721.1/71529/MIT-CSAIL-TR-2012-019.pdf?sequence=1" class=yCB2><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dspace.mit.edu/handle/1721.1/71529" class=yCB1>Integrated robot task and motion planning in belief space</a></h3><div class="gs_a">LP Kaelbling, <a href="/citations?user=gQOKAggAAAAJ&amp;hl=en&amp;oi=sra">T Lozano-Perez</a> - 2012 - dspace.mit.edu</div><div class="gs_rs">In this paper, we describe an integrated strategy for planning, perception, state-estimation <br>and action in complex mobile manipulation domains. The strategy is based on planning in <br>the belief space of probability distribution over states. Our planning approach is based on <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:RbBRPRYG8K4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12605582049597829189&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'RbBRPRYG8K4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:307"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Region Enhanced Neural Q-learning in Partially Observable Markov Decision Processes</h3><div class="gs_a">T Kooi - Order - University of Groningen. Faculty of  &hellip;</div><div class="gs_fl"><a href="/scholar?q=related:MRkGRDW8UNQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15298934871138113841&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'MRkGRDW8UNQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:306"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB94" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW94"><a href="http://pratikac.scripts.mit.edu/wordpress/wp-content/uploads/sm_thesis.pdf" class=yCB4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mit.edu</span><span class="gs_ggsS">mit.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://pratikac.scripts.mit.edu/wordpress/wp-content/uploads/sm_thesis.pdf" class=yCB3>Incremental Sampling based Algorithms for State Estimation</a></h3><div class="gs_a"><a href="/citations?user=c_z5hWEAAAAJ&amp;hl=en&amp;oi=sra">P Chaudhari</a> - 2012 - pratikac.scripts.mit.edu</div><div class="gs_rs">Abstract Perception is a crucial aspect of the operation of autonomous vehicles. With a <br>multitude of different sources of sensor data, it becomes important to have algorithms which <br>can process the available information quickly and provide a timely solution. Also, an <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:f5rvRhEXgL8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13799054621235190399&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'f5rvRhEXgL8J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md94', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md94" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:f5rvRhEXgL8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:305"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB95" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW95"><a href="http://learnlab.uta.edu/fakoor/files/2012/01/Final_Thesis.pdf" class=yCB6><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uta.edu</span><span class="gs_ggsS">uta.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://learnlab.uta.edu/fakoor/files/2012/01/Final_Thesis.pdf" class=yCB5>REDUCING THE COMPLEXITY OF REINFORCEMENT LEARNING IN POMDPS BY DECOMPOSITION INTO DECISION AND PERCEPTUAL PROCESSES</a></h3><div class="gs_a">R FAKOOR - 2012 - learnlab.uta.edu</div><div class="gs_rs">Markov Decision Processes (MDPs) and Partially Observable Markov Decision Processes <br>(POMDPs) are very powerful and general frameworks to model decision and decision <br>learning tasks in a wide range of problem domains. As a result, they are widely used in <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'PXbIR4JATYcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md95', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md95" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:PXbIR4JATYcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:304"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB96" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW96"><a href="http://152.2.131.244/~sachin/papers/Patil-ICRA2012.pdf" class=yCB8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 152.2.131.244</span><span class="gs_ggsS">152.2.131.244 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6224727" class=yCB7>Estimating probability of collision for safe motion planning under Gaussian motion and sensing uncertainty</a></h3><div class="gs_a"><a href="/citations?user=zhUgtnAAAAAJ&amp;hl=en&amp;oi=sra">S Patil</a>, <a href="/citations?user=VjsNXysAAAAJ&amp;hl=en&amp;oi=sra">J van den Berg</a>&hellip; - Robotics and Automation ( &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We present a fast, analytical method for estimating the probability of collision of a <br>motion plan for a mobile robot operating under the assumptions of Gaussian motion and <br>sensing uncertainty. Estimating the probability of collision is an integral step in many <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:phfPSwMmX04J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5647274253344511910&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'phfPSwMmX04J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:303"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB97" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW97"><a href="http://www.webscience.org.br/wiki/images/0/02/Baffa_ciarlini_sac_2010.pdf" class=yCBA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from webscience.org.br</span><span class="gs_ggsS">webscience.org.br <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1774585" class=yCB9>Modeling POMDPs for generating and simulating stock investment policies</a></h3><div class="gs_a">ACE Baffa, AEM Ciarlini - Proceedings of the 2010 ACM Symposium on  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract Analysts and investors use Technical Analysis tools to create charts and price <br>indicators that help them in decision making. Chart patterns and indicators are not <br>deterministic and even analysts may have different interpretations, depending on their <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:FjJKUlB5hXsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8900653624452592150&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'FjJKUlB5hXsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:302"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB98" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW98"><a href="http://www.cs.mcgill.ca/~spng/undergraduate_thesis.pdf" class=yCBC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mcgill.ca</span><span class="gs_ggsS">mcgill.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.cs.mcgill.ca/~spng/undergraduate_thesis.pdf" class=yCBB>Factored POMDPs with Mixed Observability</a></h3><div class="gs_a">PS Wei - cs.mcgill.ca</div><div class="gs_rs">Abstract POMDPs (Partially Observable Markov Decision Processes) provide a principled <br>mathematical framework for planning and decision making under uncertainty. It is widely <br>used to model many kinds of real-world problems. However, solving POMDPs with a large <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:vZ_cVj_Din8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'vZ_cVj_Din8J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md98', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md98" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:vZ_cVj_Din8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:301"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB99" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW99"><a href="https://www-new.comp.nus.edu.sg/~leews/publications/nips2011.pdf" class=yCBE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="https://www-new.comp.nus.edu.sg/~leews/publications/nips2011.pdf" class=yCBD>Monte Carlo Value Iteration with Macro-Actions</a></h3><div class="gs_a">ZW Lim, <a href="/citations?user=S9LHLKEAAAAJ&amp;hl=en&amp;oi=sra">D Hsu</a>, <a href="/citations?user=8PCrLgwAAAAJ&amp;hl=en&amp;oi=sra">WS Lee</a> - www-new.comp.nus.edu.sg</div><div class="gs_rs">Abstract POMDP planning faces two major computational challenges: large state spaces <br>and long planning horizons. The recently introduced Monte Carlo Value Iteration (MCVI) can <br>tackle POMDPs with very large discrete state spaces or continuous state spaces, but its <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5079403010652539591&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:x4r-WCCqfUYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5079403010652539591&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'x4r-WCCqfUYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md99', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md99" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:x4r-WCCqfUYJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
