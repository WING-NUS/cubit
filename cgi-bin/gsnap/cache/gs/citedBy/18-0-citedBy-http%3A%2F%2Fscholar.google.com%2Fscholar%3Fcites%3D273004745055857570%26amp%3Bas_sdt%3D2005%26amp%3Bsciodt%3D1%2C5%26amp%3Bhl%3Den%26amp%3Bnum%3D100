Total results = 18
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.viplab.cs.nott.ac.uk/publications/Papers/TPAMI_10.7.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nott.ac.uk</span><span class="gs_ggsS">nott.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5639019" class=yC0>A hybrid probabilistic model for unified collaborative and content-based image tagging</a></h3><div class="gs_a">N Zhou, <a href="/citations?user=e42JkYIAAAAJ&amp;hl=en&amp;oi=sra">WK Cheung</a>, <a href="/citations?user=pHkKtyMAAAAJ&amp;hl=en&amp;oi=sra">G Qiu</a>&hellip; - Pattern Analysis and  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The increasing availability of large quantities of user contributed images with labels <br>has provided opportunities to develop automatic tools to tag images to facilitate image <br>search and retrieval. In this paper, we present a novel hybrid probabilistic model (HPM) <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11387811574683480230&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 13</a> <a href="/scholar?q=related:pjAXvkqiCZ4J:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11387811574683480230&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'pjAXvkqiCZ4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://vireo.cs.cityu.edu.hk/papers/yuxiang_cvpr10.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cityu.edu.hk</span><span class="gs_ggsS">cityu.edu.hk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5540015" class=yC2>Semantic context modeling with maximal margin conditional random fields for automatic image annotation</a></h3><div class="gs_a"><a href="/citations?user=9cZUlEYAAAAJ&amp;hl=en&amp;oi=sra">Y Xiang</a>, <a href="/citations?user=QUrLihYAAAAJ&amp;hl=en&amp;oi=sra">X Zhou</a>, <a href="/citations?user=eZnL8b8AAAAJ&amp;hl=en&amp;oi=sra">Z Liu</a>, TS Chua&hellip; - Computer Vision and  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Context modeling for Vision Recognition and Automatic Image Annotation (AIA) has <br>attracted increasing attentions in recent years. For various contextual information and <br>resources, semantic context has been exploited in AIA and brings promising results. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10697190947606539551&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 11</a> <a href="/scholar?q=related:H62cnn0OdJQJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10697190947606539551&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'H62cnn0OdJQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://oro.open.ac.uk/23503/1/p243-llorente.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from open.ac.uk</span><span class="gs_ggsS">open.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://oro.open.ac.uk/23503/" class=yC4>Image retrieval using Markov random fields and global image features</a></h3><div class="gs_a">A Llorente, <a href="/citations?user=_0aMq28AAAAJ&amp;hl=en&amp;oi=sra">R Manmatha</a>, <a href="/citations?user=oFU5A7sAAAAJ&amp;hl=en&amp;oi=sra">S RÃ¼ger</a> - 2010 - oro.open.ac.uk</div><div class="gs_rs">In this paper, we propose a direct image retrieval framework based on Markov Random <br>Fields (MRFs) that exploits the semantic context dependencies of the image. The novelty of <br>our approach lies in the use of different kernels in our non-parametric density estimation <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4684010266910249855&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 7</a> <a href="/scholar?q=related:f9N3U4XyAEEJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4684010266910249855&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'f9N3U4XyAEEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://vipl.ict.ac.cn/sites/default/files/papers/files/2010_ACMMM_zpwu_Vicept_%20Link%20Visual%20Features%20to%20Concepts%20for%20Large-scale%20Image%20Understanding.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ict.ac.cn</span><span class="gs_ggsS">ict.ac.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1874059" class=yC6>Vicept: link visual features to concepts for large-scale image understanding</a></h3><div class="gs_a">Z Wu, <a href="/citations?user=4Rvn-ykAAAAJ&amp;hl=en&amp;oi=sra">S Jiang</a>, L Li, P Cui, Q Huang&hellip; - Proceedings of the  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract On noticing the paradox of visual polysemia and concept poly-morphism, this paper <br>proposes a new perspective called&quot; Vicept&quot; to associate elementary visual features and <br>cognitive concepts. Firstly, a carefully prepared large image dataset and associate <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15314954435448674535&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 6</a> <a href="/scholar?q=related:5xg2vOqlidQJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15314954435448674535&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'5xg2vOqlidQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/R141W2PMT86473P7.pdf" class=yC8>Tagging image by merging multiple features in a integrated manner</a></h3><div class="gs_a">X Zhang, Z Li, W Chao - Journal of Intelligent Information Systems, 2012 - Springer</div><div class="gs_rs">Abstract Image tagging is a task that automatically assigns the query image with semantic <br>keywords called tags, which significantly facilitates image search and organization. Since <br>tags and image visual content are represented in different feature space, how to merge <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4024339810954317437&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 2</a> <a href="/scholar?q=related:fQ5ld7xT2TcJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4024339810954317437&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'fQ5ld7xT2TcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://people.cs.clemson.edu/~jzwang/1301863/mm2012/p499-lu.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from clemson.edu</span><span class="gs_ggsS">clemson.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2393418" class=yC9>Image annotation by semantic sparse recoding of visual content</a></h3><div class="gs_a"><a href="/citations?user=OUXS8doAAAAJ&amp;hl=en&amp;oi=sra">Z Lu</a>, Y Peng - Proceedings of the 20th ACM international conference  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract This paper presents a new semantic sparse recoding method to generate more <br>descriptive and robust representation of visual content for image annotation. Although the <br>visual bag-of-words (BOW) representation has been reported to achieve promising results <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3967404799588172502&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 1</a> <a onclick="return gs_ocit(event,'1gKiH6UNDzcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/07786125454R1JK4.pdf" class=yCB>Fire detection in color images using Markov random fields</a></h3><div class="gs_a">D Van Hamme, P Veelaert, W Philips&hellip; - Advanced Concepts for  &hellip;, 2010 - Springer</div><div class="gs_rs">Automatic video-based fire detection can greatly reduce fire alert delay in large industrial <br>and commercial sites, at a minimal cost, by using the existing CCTV camera network. Most <br>traditional computer vision methods for fire detection model the temporal dynamics of the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17184785010921214450&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 1</a> <a href="/scholar?q=related:8pFqJeuefO4J:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17184785010921214450&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'8pFqJeuefO4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://www.db.fudan.edu.cn/mdb/upload/2011/10/PCM_140-14185044.pdf" class=yCD><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from fudan.edu.cn</span><span class="gs_ggsS">fudan.edu.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/AMG5934524254431.pdf" class=yCC>Learning contextual metrics for automatic image annotation</a></h3><div class="gs_a"><a href="/citations?user=eZnL8b8AAAAJ&amp;hl=en&amp;oi=sra">Z Liu</a>, <a href="/citations?user=QUrLihYAAAAJ&amp;hl=en&amp;oi=sra">X Zhou</a>, <a href="/citations?user=9cZUlEYAAAAJ&amp;hl=en&amp;oi=sra">Y Xiang</a>, YT Zheng - Advances in Multimedia Information  &hellip;, 2010 - Springer</div><div class="gs_rs">The semantic contextual information is shown to be an important resource for improving the <br>scene and image recognition, but is seldom explored in the literature of previous distance <br>metric learning (DML) for images. In this work, we present a novel Contextual Metric <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2535595501741016715&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 1</a> <a href="/scholar?q=related:iwZat6w-MCMJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2535595501741016715&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'iwZat6w-MCMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://oro.open.ac.uk/25663/1/LlorenteThesis13122010.pdf" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from open.ac.uk</span><span class="gs_ggsS">open.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://oro.open.ac.uk/25663/" class=yCE>Semantics and statistics for automated image annotation</a></h3><div class="gs_a">A Llorente - 2010 - oro.open.ac.uk</div><div class="gs_rs">Automated image annotation consists of a number of techniques that aim to find the <br>correlation between words and image features such as colour, shape, and texture to provide <br>correct annotation words to images. In particular, approaches based on Bayesian theory <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:XxpIA7-RgK0J:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'XxpIA7-RgK0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2382380" class=yC10>Tag ranking by propagating relevance over tag and image graphs</a></h3><div class="gs_a">M Li, <a href="/citations?user=ByBLlEwAAAAJ&amp;hl=en&amp;oi=sra">J Tang</a>, H Li, C Zhao - &hellip;  of the 4th International Conference on  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we explore the problem of tag ranking by propagating relevance over <br>community-contributed images and their associated tags. To rank the tags more accurately, <br>we propose a novel tag ranking scheme through a two-stage graph-based relevance <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'edO4DW-1rSsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://www.hindawi.com/isrn/ai/2012/376804/" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from hindawi.com</span><span class="gs_ggsS">hindawi.com <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[HTML]</span><span class="gs_ct2">[HTML]</span></span> <a href="http://www.hindawi.com/isrn/ai/2012/376804/" class=yC11>Bag-of-Words Representation in Image Annotation: A Review</a></h3><div class="gs_a">CF Tsai - ISRN Artificial Intelligence, 2012 - hindawi.com</div><div class="gs_rs">Content-based image retrieval (CBIR) systems require users to query images by their low-<br>level visual content; this not only makes it hard for users to formulate queries, but also can <br>lead to unsatisfied retrieval results. To this end, image annotation was proposed. The aim <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'uTXtKetKoCkJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md10', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md10" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:uTXtKetKoCkJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://inderscience.metapress.com/index/F681174TL7473015.pdf" class=yC13>Cross-media retrieval: state-of-the-art and open issues</a></h3><div class="gs_a">J Liu, C Xu, H Lu - International Journal of Multimedia Intelligence and  &hellip;, 2010 - Inderscience</div><div class="gs_rs">Cross-media retrieval is able to provide retrieval results with similar semantics but different <br>media to the query. Since cross-media retrieval complements currently popular text/content-<br>based retrieval which provides retrieval results with the same media to the query, it <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:3ha4PHVMgPsJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'3ha4PHVMgPsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0165168412001661" class=yC14>Social Image Tagging Using Graph-based Reinforcement on Multi-type Interrelated Objects</a></h3><div class="gs_a">X Zhang, X Zhao, Z Li, J Xia, R Jain, W Chao - Signal Processing, 2012 - Elsevier</div><div class="gs_rs">Abstract Social image tagging is becoming increasingly popular with the development of <br>social website, where images are annotated with arbitrary keywords called tags. Most of <br>present image tagging approaches are mainly based on the visual similarity or mapping <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10188512964859572982&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 1</a> <a href="/scholar?q=related:9rLqe4_eZI0J:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'9rLqe4_eZI0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://www.db.fudan.edu.cn/mdb/upload/2011/10/cvpr2010-14182428.pdf" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from fudan.edu.cn</span><span class="gs_ggsS">fudan.edu.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.db.fudan.edu.cn/mdb/upload/2011/10/cvpr2010-14182428.pdf" class=yC15>Semantic Context Modeling with Maximal Margin Conditional Random Fields for Automatic Image Annotation</a></h3><div class="gs_a">YXXZZ Liu, F Unviersity, TS Chua, <a href="/citations?user=jk5DWVMAAAAJ&amp;hl=en&amp;oi=sra">CW Ngo</a> - db.fudan.edu.cn</div><div class="gs_rs">Abstract Context modeling for Vision Recognition and Automatic Image Annotation (AIA) has <br>attracted increasing attentions in recent years. For various contextual information and <br>resources, semantic context has been exploited in AIA and brings promising results. <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:c_Icv5sykAgJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=617048793457422963&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'c_Icv5sykAgJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md13', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md13" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:c_Icv5sykAgJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/31530021T2516P44.pdf" class=yC17>Hierarchical Markov Random Fields with Irregular Pyramids for Improving Image Annotation</a></h3><div class="gs_a">A Morales-GonzÃ¡lez, E GarcÃ­a-Reyes&hellip; - Advances in Artificial  &hellip;, 2012 - Springer</div><div class="gs_rs">Image segmentation and Automatic Image Annotation (AIA) are two important areas that still <br>impose challenging problems. Addressing both problems simultaneously may improve their <br>results since they are interdependent. In this paper we give a step ahead in that direction <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'yXTgxM0oo9AJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://researchweb.iiit.ac.in/~yashaswi.verma/eccv12/vj_eccv12.pdf" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from iiit.ac.in</span><span class="gs_ggsS">iiit.ac.in <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://researchweb.iiit.ac.in/~yashaswi.verma/eccv12/vj_eccv12.pdf" class=yC18>Image Annotation Using Metric Learning in Semantic Neighbourhoods</a></h3><div class="gs_a">Y Verma, <a href="/citations?user=U9dH-DoAAAAJ&amp;hl=en&amp;oi=sra">CV Jawahar</a> - researchweb.iiit.ac.in</div><div class="gs_rs">Abstract. Automatic image annotation aims at predicting a set of textual labels for an image <br>that describe its semantics. These are usually taken from an annotation vocabulary of few <br>hundred labels. Because of the large vocabulary, there is a high variance in the number of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8287957244326208111&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=18">Cited by 1</a> <a href="/scholar?q=related:b2KwxTO9BHMJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'b2KwxTO9BHMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md15', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md15" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:b2KwxTO9BHMJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://homepage.fudan.edu.cn/xdzhou/files/2012/11/eccv2012-zhou.pdf" class=yC1B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from fudan.edu.cn</span><span class="gs_ggsS">fudan.edu.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/F17328344142J823.pdf" class=yC1A>Labeling images by integrating sparse multiple distance learning and semantic context modeling</a></h3><div class="gs_a">C Ji, <a href="/citations?user=QUrLihYAAAAJ&amp;hl=en&amp;oi=sra">X Zhou</a>, L Lin, W Yang - Computer VisionâECCV 2012, 2012 - Springer</div><div class="gs_rs">Recent progress on Automatic Image Annotation (AIA) is achieved by either exploiting low <br>level visual features or high level semantic context. Integrating these two paradigms to <br>further leverage the performance of AIA is promising. However, very few previous works <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'Qt3o2BUoBqoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0167865512000906" class=yC1C>An annotation rule extraction algorithm for image retrieval</a></h3><div class="gs_a">Z Chen, J Hou, D Zhang, X Qin - Pattern Recognition Letters, 2012 - Elsevier</div><div class="gs_rs">Automatic image annotation can be used to facilitate semantic search in large image <br>databases. However, retrieval performance of the existing annotation schemes is far from <br>the users&#39; expectation. In this paper, we propose a novel method to automatically annotate <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:Zm_k65Pv5EUJ:scholar.google.com/&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5036413701903904614&amp;hl=en&amp;num=18&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'Zm_k65Pv5EUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
