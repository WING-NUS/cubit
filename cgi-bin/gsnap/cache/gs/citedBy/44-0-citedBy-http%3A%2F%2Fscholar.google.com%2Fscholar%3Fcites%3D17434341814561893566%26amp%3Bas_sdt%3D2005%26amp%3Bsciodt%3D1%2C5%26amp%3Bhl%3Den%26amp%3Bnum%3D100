Total results = 44
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.ldmc.buaa.edu.cn/download/data_mining/A%20survey%20of%20content-based%20image%20retrieval%20with%20high-level%20semantics%20.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from buaa.edu.cn</span><span class="gs_ggsS">buaa.edu.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320306002184" class=yC0>A survey of content-based image retrieval with high-level semantics</a></h3><div class="gs_a">Y Liu, D Zhang, G Lu, WY Ma - Pattern Recognition, 2007 - Elsevier</div><div class="gs_rs">In order to improve the retrieval accuracy of content-based image retrieval systems, research <br>focus has been shifted from designing sophisticated low-level feature extraction algorithms <br>to reducing the &#39;semantic gap&#39;between the visual features and the richness of human <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7879404000356825275&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 576</a> <a href="/scholar?q=related:u3gPAzFEWW0J:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7879404000356825275&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 19 versions</a> <a onclick="return gs_ocit(event,'u3gPAzFEWW0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://lms.comp.nus.edu.sg/papers/media/2004/acmmm04-feng.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1027527.1027748" class=yC2>A bootstrapping framework for annotating and retrieving WWW images</a></h3><div class="gs_a">H Feng, R Shi, TS Chua - Proceedings of the 12th annual ACM  &hellip;, 2004 - dl.acm.org</div><div class="gs_rs">Abstract Most current image retrieval systems and commercial search engines use mainly <br>text annotations to index and retrieve WWW images. This research explores the use of <br>machine learning approaches to automatically annotate WWW images based on a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13909887808073208556&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 87</a> <a href="/scholar?q=related:7JK9gUPZCcEJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13909887808073208556&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'7JK9gUPZCcEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/trecvid04.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/trecvid04.pdf" class=yC4>TRECVID 2004 search and feature extraction task by NUS PRIS</a></h3><div class="gs_a">TS Chua, SY Neo, KY Li, G Wang, R Shi&hellip; - Proceedings of the  &hellip;, 2004 - 137.132.145.151</div><div class="gs_rs">ABSTRACT This paper describes the details of our systems for feature extraction and search <br>tasks of TRECVID-2004. For feature extraction, we emphasize the use of visual auto-concept <br>annotation technique, with the fusion of text and specialized detectors, to induce concepts <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4598184418179278710&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 60</a> <a href="/scholar?q=related:dudPuV0I0D8J:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4598184418179278710&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'dudPuV0I0D8J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md2', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md2" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:dudPuV0I0D8J:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://www-nlpir.nist.gov/projects/tvpubs/tv5.papers/nus.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nist.gov</span><span class="gs_ggsS">nist.gov <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www-nlpir.nist.gov/projects/tvpubs/tv5.papers/nus.pdf" class=yC6>Trecvid 2005 by nus pris</a></h3><div class="gs_a">TS Chua, SY Neo, HK Goh, <a href="/citations?user=9Be5CtEAAAAJ&amp;hl=en&amp;oi=sra">M Zhao</a>, Y Xiao&hellip; - NIST TRECVID- &hellip;, 2005 - www-nlpir.nist.gov</div><div class="gs_rs">ABSTRACT We participated in the high-level feature extraction and search task for <br>TRECVID 2005. For the high-level feature extraction task, we make use of the available <br>collaborative annotation results for training, and develop 2 methods to perform automated <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6139068261712169763&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 39</a> <a href="/scholar?q=related:I4s6zw5aMlUJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6139068261712169763&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'I4s6zw5aMlUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md3', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md3" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:I4s6zw5aMlUJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://www.benthamscience.com/cseng/samples/cseng1-1/Tsai.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from benthamscience.com</span><span class="gs_ggsS">benthamscience.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.benthamscience.com/cseng/samples/cseng1-1/Tsai.pdf" class=yC8>Automatically annotating images with keywords: A review of image annotation systems</a></h3><div class="gs_a">CF Tsai, C Hung - Recent Patents on Computer Science, 2008 - benthamscience.com</div><div class="gs_rs">Abstract: The explosive growth of image data leads to the research and development of <br>Content-Based Image Retrieval (CBIR) systems. CBIR systems extract and retrieve images <br>by their low-level features, such as color, texture, and shape. However, these visual <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9686744838602593986&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 40</a> <a href="/scholar?q=related:wpbBrhs7boYJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'wpbBrhs7boYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md4', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md4" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:wpbBrhs7boYJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1027605" class=yCA>A semi-naive bayesian method incorporating clustering with pair-wise constraints for auto image annotation</a></h3><div class="gs_a">W Jin, R Shi, TS Chua - Proceedings of the 12th annual ACM  &hellip;, 2004 - dl.acm.org</div><div class="gs_rs">Abstract We propose a novel approach for auto image annotation. In our approach, we first <br>perform the segmentation of images into regions, followed by clustering of regions, before <br>learning the relationship between concepts and region clusters using the set of training <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=991618827994373287&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 25</a> <a href="/scholar?q=related:p5wx-xHwwg0J:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=991618827994373287&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'p5wx-xHwwg0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/mmm05-shirui.pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1386009" class=yCB>A novel approach to auto image annotation based on pairwise constrained clustering and semi-naÃ¯ve Bayesian model</a></h3><div class="gs_a">S Rui, W Jin, TS Chua - &hellip; , 2005. MMM 2005. Proceedings of the  &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Automatic image annotation has been intensively studied for content-based image <br>retrieval recently. In this paper, we propose a novel approach for this task. Our approach first <br>performs the segmentation of images into regions, followed by the clustering of regions, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9087402978884673670&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 20</a> <a href="/scholar?q=related:hmA_t9zwHH4J:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9087402978884673670&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'hmA_t9zwHH4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320311002391" class=yCD>A review on automatic image annotation techniques</a></h3><div class="gs_a">D Zhang, MM Islam, G Lu - Pattern Recognition, 2012 - Elsevier</div><div class="gs_rs">Nowadays, more and more images are available. However, to find a required image for an <br>ordinary user is a challenging task. Large amount of researches on image retrieval have <br>been carried out in the past two decades. Traditionally, research in this area focuses on <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13853996943203153734&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 27</a> <a href="/scholar?q=related:Rrf4dtFIQ8AJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13853996943203153734&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'Rrf4dtFIQ8AJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S1047320308001302" class=yCE>Embedded lattices tree: An efficient indexing scheme for content based retrieval on image databases</a></h3><div class="gs_a">M Mejdoub, L Fonteles, C BenAmar&hellip; - Journal of Visual  &hellip;, 2009 - Elsevier</div><div class="gs_rs">One of the challenges in the development of a content-based multimedia indexing and <br>retrieval application is to achieve an efficient indexing scheme. To retrieve a particular <br>image from a large scale image database, users can be frustrated by the long query times. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16000577430751826410&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 9</a> <a href="/scholar?q=related:6lEYCWZ4Dd4J:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16000577430751826410&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'6lEYCWZ4Dd4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4054657" class=yCF>Segmentation of dental radiographs using a swarm intelligence approach</a></h3><div class="gs_a">F Keshtkar, W Gueaieb - Electrical and Computer Engineering,  &hellip;, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract One of the most complex tasks in digital image processing is image segmentation. <br>This paper proposes a novel image segmentation algorithm that uses a biologically inspired <br>technique based on swarm intelligence and a cellular automata model. The proposed <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17101410910132977377&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 8</a> <a href="/scholar?q=related:4T53mJ1qVO0J:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'4T53mJ1qVO0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5617668" class=yC10>Gaze movement inference for implicit image annotation</a></h3><div class="gs_a">SN Hajimirza, <a href="/citations?user=cyiYJhMAAAAJ&amp;hl=en&amp;oi=sra">E Izquierdo</a> - Image Analysis for Multimedia  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract An innovative semi-automatic image annotation system is enriched with the <br>feedbacks of user&#39;s eyes. This system implicitly exploits the competence of human mind and <br>it utilizes the computational power of the computers in order to achieve a pervasive and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=361215064966366720&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 5</a> <a href="/scholar?q=related:AAbXEjBLAwUJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'AAbXEjBLAwUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> <a href="http://ethos.bl.uk/OrderDetails.do?uin=uk.bl.ethos.416515" class=yC11>Automatically annotating images with keywords</a></h3><div class="gs_a">CF Tsai - 2005 - ethos.bl.uk</div><div class="gs_fl"><a href="/scholar?cites=16821213023628335420&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 4</a> <a href="/scholar?q=related:PJmKVB_0cOkJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16821213023628335420&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'PJmKVB_0cOkJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md11', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md11" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:PJmKVB_0cOkJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://www.csjournals.com/IJEE/PDF%202-1/6.pdf" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from csjournals.com</span><span class="gs_ggsS">csjournals.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.csjournals.com/IJEE/PDF%202-1/6.pdf" class=yC12>Content Retrieval From XRAY Images Using Color &amp; Texture Features</a></h3><div class="gs_a">B Singh, B Mazumdar - Methodology, 2010 - csjournals.com</div><div class="gs_rs">Abstract: The National Library of Medicine (NLM) maintains an archive of approximately <br>17,000 digitized x-ray images and accompanying data collected in the second National <br>Health and Nutrition Examination Survey (NHANES II). The problem of content-based <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6255381555198433793&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 4</a> <a href="/scholar?q=related:ARoizGGUz1YJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'ARoizGGUz1YJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md12', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md12" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:ARoizGGUz1YJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://ukpmc.ac.uk/articles/PMC3150552" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from ukpmc.ac.uk</span><span class="gs_ggsS">ukpmc.ac.uk <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0306457310001020" class=yC14>A query expansion framework in image retrieval domain based on local and global analysis</a></h3><div class="gs_a"><a href="/citations?user=Qf_Uf5AAAAAJ&amp;hl=en&amp;oi=sra">MM Rahman</a>, SK Antani, GR Thoma - Information processing &amp;  &hellip;, 2011 - Elsevier</div><div class="gs_rs">We present an image retrieval framework based on automatic query expansion in a concept <br>feature space by generalizing the vector space model of information retrieval. In this <br>framework, images are represented by vectors of weighted concepts similar to the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2746468225289261610&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 3</a> <a href="/scholar?q=related:KpJDq0xqHSYJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2746468225289261610&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'KpJDq0xqHSYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5331422" class=yC16>A comparative study of global and local feature representations in image database categorization</a></h3><div class="gs_a">CF Tsai, WC Lin - INC, IMS and IDC, 2009. NCM&#39;09. Fifth  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Content-based image retrieval systems can automatically extract visual content of <br>images which allow users to query images by their low-level features (such as color and <br>texture). However, users usually prefer querying images based on high-level concepts <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18360591800043035331&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 4</a> <a href="/scholar?q=related:w9qDq_bszf4J:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18360591800043035331&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'w9qDq_bszf4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4529997" class=yC17>Semantic strategic satellite image retrieval</a></h3><div class="gs_a">W Messaoudi, IR Farah&hellip; - &hellip; : From Theory to  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Large amounts of spatial data are becoming available today due to the rapid <br>development of remote sensing techniques. Several retrieval systems are proposed to <br>retrieve necessary, interested and effective information such as key-word based image <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3858362321688573193&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 2</a> <a href="/scholar?q=related:CbX_zhaoizUJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'CbX_zhaoizUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://hal.archives-ouvertes.fr/docs/00/46/59/60/PDF/These_ED_0366-370_-_Najlae_IDRISSI_-_2008.pdf" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://hal.archives-ouvertes.fr/tel-00465960/" class=yC18>La navigation dans les bases d&#39;images: prise en compte des attributs de texture</a></h3><div class="gs_a">N Idrissi - 2008 - hal.archives-ouvertes.fr</div><div class="gs_rs">RÃ©sumÃ© Ce travail de recherche entre dans le cadre des systÃ¨mes de recherche d&#39;images <br>par le contenu, en particulier la recherche par la texture. Le but de ce travail est de permettre <br>Ã  l&#39;utilisateur de naviguer dans de grande base de donnÃ©es d&#39;images sans formulation de <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5345067601461757147&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 2</a> <a href="/scholar?q=related:28STBap-LUoJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5345067601461757147&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'28STBap-LUoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1948017" class=yC1A>Wavelet based information for retrieval and classification of mammographic images</a></h3><div class="gs_a">BK Singh, JS Parihar, P Pal - &hellip;  of the 2011 International Conference on  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract Feature extraction, retrieval and classification of mammographic images are <br>important issues in development of disease diagnostic expert system [DDES]. In this paper <br>we investigate and make comparative analysis of wavelet based CBIR features which may <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3184005959842886855&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 1</a> <a href="/scholar?q=related:x3QpB43cLywJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'x3QpB43cLywJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB18" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW18"><a href="http://scholarbank.nus.edu/bitstream/handle/10635/13418/Thesis_Marchenko_Yelizaveta_PhDDegree.pdf?sequence=1" class=yC1C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu</span><span class="gs_ggsS">nus.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://scholarbank.nus.edu/handle/10635/13418" class=yC1B>Ontology-based annotation of paintings with artistic concepts</a></h3><div class="gs_a">M YELIZAVETA - 2007 - scholarbank.nus.edu</div><div class="gs_rs">In this thesis, we focus on the automatic annotation of paintings with various artistic <br>concepts. These concepts originate from the several domain ontologies. In our work we <br>combine such domain knowledge with trasductive inference and demonstrate that the use <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=77623979425578235&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 1</a> <a href="/scholar?q=related:-7y2F5nGEwEJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=77623979425578235&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'-7y2F5nGEwEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5656878" class=yC1D>Content Based Retrieval of X-ray Images Using Fusion of Spectral Texture and Shape Descriptors</a></h3><div class="gs_a">BK Singh, GR Sinha, B Mazumdar&hellip; - Advances in Recent  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper content based image retrieval of x-ray images using fusion of spectral <br>&amp; shape features is discussed. Texture analysis and shape description are two of the key <br>parts of image content description. Most of the existing descriptors are usually either <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14092057033051978252&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 1</a> <a href="/scholar?q=related:DLqbaTULkcMJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14092057033051978252&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'DLqbaTULkcMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB20" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW20"><a href="http://archive.nlm.nih.gov/pubs/pubPDFs/MMBIA_30.pdf" class=yC1F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nih.gov</span><span class="gs_ggsS">nih.gov <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5543452" class=yC1E>Local concept-based medical image retrieval with correlation-enhanced similarity matching based on global analysis</a></h3><div class="gs_a"><a href="/citations?user=Qf_Uf5AAAAAJ&amp;hl=en&amp;oi=sra">MM Rahman</a>, SK Antani&hellip; - Computer Vision and  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract A correlation-enhanced similarity matching framework for medical image retrieval is <br>presented in a local concept-based feature space. In this framework, images are presented <br>by vectors of concepts that comprise of local color and texture patches of image regions in <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11481061910574180667&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 2</a> <a href="/scholar?q=related:O6kKePrsVJ8J:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11481061910574180667&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'O6kKePrsVJ8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="http://sourcedb.ict.cas.cn/cn/ictthesis/200907/P020090722623054116238.pdf" class=yC21><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cas.cn</span><span class="gs_ggsS">cas.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4371021" class=yC20>A neural network approach for bridging the semantic gap in texture image retrieval</a></h3><div class="gs_a">Q Li, Z Shi, S Luo - Neural Networks, 2007. IJCNN 2007.  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract One of the big challenges faced by content-based image retrieval (CBIR) is <br>the&#39;semantic gap&#39;between the visual features and the richness of human semantics for <br>image content. We put forward a neural network approach to extract the image fuzzy <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17325895012846905071&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 1</a> <a href="/scholar?q=related:76ZzuLfxcfAJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17325895012846905071&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'76ZzuLfxcfAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5420188" class=yC22>Hybrid semantic retrieval= User-community Profiling+ Domain Knowledge+ Content-based retrieval</a></h3><div class="gs_a"><a href="/citations?user=D1LEg-YAAAAJ&amp;hl=en&amp;oi=sra">Q Li</a>, H Xie, W Chen, L Yu - Pervasive Computing (JCPC), 2009 &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The paradigm of Content-based retrieval (CBR) with query-by-example (QBE) has <br>been prevailing in multimedia applications and systems. While the CRB/QBE approach is <br>easy to use from the end-user&#39;s perspective, it is not always possible for a user to prepare/<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3152671806225051401&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 1</a> <a href="/scholar?q=related:Ce9u302KwCsJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'Ce9u302KwCsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.scientific.net/AMR.159.638" class=yC23>A Content-Based Image Retrieval System with Image Semantic</a></h3><div class="gs_a">Y Ma, LM Zhang, JX Ma - Advanced Materials Research, 2011 - Trans Tech Publ</div><div class="gs_rs">Abstract With the development of information technology and multimedia technology, more <br>and more images appear and have become a part of our daily life. Efficient image searching, <br>storing, retrieval and browsing tools are in high need in various domains, including face <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7032115159893096116&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 1</a> <a href="/scholar?q=related:tDYR7XoXl2EJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'tDYR7XoXl2EJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ri"><h3 class="gs_rt"><a href="http://inderscience.metapress.com/index/T2G580UG34QGT72L.pdf" class=yC24>Knowledgeâbased image segmentation using swarm intelligence techniques</a></h3><div class="gs_a">F Keshtkar, W Gueaieb, <a href="/citations?user=vfdlPAEAAAAJ&amp;hl=en&amp;oi=sra">M Masud</a> - International Journal of Innovative  &hellip;, 2012 - Inderscience</div><div class="gs_rs">Intelligent techniques such as swarm intelligence techniques rarely have been used for <br>image segmentation or boundary detection. The limited increasing number of agents in the <br>environment and how to find efficiently the right threshold in an image, develop a flexible <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:fpivD4Z5N-MJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16372688587024472190&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'fpivD4Z5N-MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4389634" class=yC25>High-Level Semantic Based Image Characterization Using Artificial Neural Networks</a></h3><div class="gs_a">EF Ribeiro, CAZ Barcelos&hellip; - Intelligent Systems Design &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Low-level attributes such as color, shape and texture generally fail in describing the <br>high-level semantic concepts. This work presents, through the formation of a high-level <br>characteristics vector, the representation of the subjective knowledge used by humans for <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:fXOsRG6MoWsJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7755634438535148413&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'fXOsRG6MoWsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB26" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW26"><a href="http://www.scholarbank.nus.edu.sg/bitstream/handle/10635/14783/thesis_body%20(huamin).pdf?sequence=2" class=yC27><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.scholarbank.nus.edu.sg/handle/10635/14783" class=yC26>Auto-annotation of multimedia contents: Theory and application</a></h3><div class="gs_a">F HUAMIN - 2005 - scholarbank.nus.edu.sg</div><div class="gs_rs">In this thesis, we propose a learning-based framework for auto-annotation of multimedia <br>contents. The framework is open and is designed to incorporate different base learners, <br>including the single-view machine learning (traditional) and the bootstrapping approaches<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:3raxSNrVELEJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12758932877839808222&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'3raxSNrVELEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB27" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW27"><a href="http://libque.cityu.edu.hk/bitstream/2031/6202/1/abstract.html" class=yC29><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cityu.edu.hk</span><span class="gs_ggsS">cityu.edu.hk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://libque.cityu.edu.hk/handle/2031/6202" class=yC28>Community-based multimedia information retrieval in peer-to-peer networks</a></h3><div class="gs_a">W Chen - 2009 - libque.cityu.edu.hk</div><div class="gs_rs">ï»¿ With the rapid development of information technology, multimedia applications have been <br>widely used in people&#39;s daily lives. The need of developing effective and efficient multimedia <br>information retrieval technologies has been identified in recent years. Due to the large <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:pDOBZzf3WZgJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10978077384024077220&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'pDOBZzf3WZgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB28" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW28"><a href="http://cdn.intechweb.org/pdfs/13298.pdf" class=yC2B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from intechweb.org</span><span class="gs_ggsS">intechweb.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://cdn.intechweb.org/pdfs/13298.pdf" class=yC2A>Image Search in a Visual Concept Feature Space with SOM-Based Clustering and Modified Inverted Indexing</a></h3><div class="gs_a"><a href="/citations?user=Qf_Uf5AAAAAJ&amp;hl=en&amp;oi=sra">MM Rahman</a> - cdn.intechweb.org</div><div class="gs_rs">The exponential growth of image data has created a compelling need for innovative tools for <br>managing, retrieving, and visualizing images from large collection. The low storage cost of <br>computer hardware, availability of digital devices, high bandwidth communication facilities <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:NPfNZ5z-8NIJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15199928690085328692&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'NPfNZ5z-8NIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md28', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md28" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:NPfNZ5z-8NIJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> ANN based Classifier System for Digital Mammographic Images</h3><div class="gs_a">BK Singh, A Yadav, S Singh - International  &hellip;, 2011 - &hellip;  of Computer Applications, 244 5 th  &hellip;</div><div class="gs_fl"><a href="/scholar?q=related:rVySeiqSsq0J:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12516227025558723757&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'rVySeiqSsq0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB30" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW30"><a href="http://www.cim.mcgill.ca/~levine/KyleThesis.pdf" class=yC2D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mcgill.ca</span><span class="gs_ggsS">mcgill.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.cim.mcgill.ca/~levine/KyleThesis.pdf" class=yC2C>Improving Image Classification by Co-training with Multi-modal Features</a></h3><div class="gs_a">K Weston - 2011 - cim.mcgill.ca</div><div class="gs_rs">ABSTRACT We explore the use of co-training to improve the performance of image <br>classification in the setting where multiple classifiers are used and several types of features <br>are available. Features are assigned to classifiers in an optimal manner using hierarchical <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ekq8hO9TSQIJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=164755149564955258&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'ekq8hO9TSQIJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md30', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md30" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:ekq8hO9TSQIJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB31" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW31"><a href="http://www.comp.nus.edu.sg/~hkiani/GRP_FinalVersion.pdf" class=yC2F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.comp.nus.edu.sg/~hkiani/GRP_FinalVersion.pdf" class=yC2E>Graduate Research Paper</a></h3><div class="gs_a">HK Galoogahi - 2011 - comp.nus.edu.sg</div><div class="gs_rs">Abstract One of the long-term goals of computational vision is to be able to understand the <br>world through visual images. This general challenging task involves a number of vision <br>tasks such as object recognition, image segmentation, classification and reasoning about <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:uyr7mPZN2xQJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'uyr7mPZN2xQJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md31', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md31" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:uyr7mPZN2xQJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB32" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW32"><a href="http://perso.ecp.fr/~bannourh/files/AAI.pdf" class=yC31><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ecp.fr</span><span class="gs_ggsS">ecp.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.tandfonline.com/doi/abs/10.1080/08839514.2010.514194" class=yC30>IMIOL: A System for Indexing Images by Their Semantic Content Based On Possibilistic Fuzzy Clustering and Adaptive Resonance Theory Neural Networks Learning</a></h3><div class="gs_a">LB Romdhane, <a href="/citations?user=MmLut9EAAAAJ&amp;hl=en&amp;oi=sra">H Bannour</a>, B Ayeb - Applied Artificial Intelligence, 2010 - Taylor &amp; Francis</div><div class="gs_rs">Image databases are becoming large and of potential use in many areas, including medical <br>diagnosis, astronomy, and the Web. These images, if analyzed, can reveal useful and <br>potential information. Image indexing is the process of extracting and modeling the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:TB5JoE0PbaUJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11920200614795615820&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'TB5JoE0PbaUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:367"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB33" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW33"><a href="https://scholarbank.nus.edu.sg/bitstream/handle/10635/15994/SHIRUI_PHDThesis_BayesianLearningofConceptOntologyforAutomaticImageAnnotation.pdf?sequence=1" class=yC33><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="https://scholarbank.nus.edu.sg/handle/10635/15994" class=yC32>Bayesian learning of concept ontology for automatic image annotation</a></h3><div class="gs_a">RUI SHI - 2007 - scholarbank.nus.edu.sg</div><div class="gs_rs">Automatic image annotation (AIA) has been a hot research topic in recent years since it can <br>be used to support concept-based image retrieval. In the field of AIA, characterizing image <br>concepts by mixture models is one of the most effective techniques. However, mixture <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:hevhtMNxNoEJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9310754365002345349&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'hevhtMNxNoEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:366"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.scientific.net/AMR.268-270.1427" class=yC34>Research on High-Level Semantic Image Retrieval</a></h3><div class="gs_a">CY Ri, M Yao - Advanced Materials Research, 2011 - Trans Tech Publ</div><div class="gs_rs">Abstract This paper presented the key problems to shorten âsemantic gapâ between low-<br>level visual features and high-level semantic features to implement high-level semantic <br>image retrieval. First, introduced ontology based semantic image description and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:vG9HvpBDzscJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'vG9HvpBDzscJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:365"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB35" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW35"><a href="http://upcommons.upc.edu/pfc/bitstream/2099.1/7724/1/MasterThesisMehdi.pdf" class=yC36><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from upc.edu</span><span class="gs_ggsS">upc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://upcommons.upc.edu/handle/2099.1/7724" class=yC35>Contextual Bag-Of-Visual-Words and ECOC-Rank for Retrieval and Multi-class Object Recognition</a></h3><div class="gs_a"><a href="/citations?user=c646VbAAAAAJ&amp;hl=en&amp;oi=sra">M Mirza-Mohammadi</a> - 2009 - upcommons.upc.edu</div><div class="gs_rs">Multi-class object categorization is an important line of research in Computer Vision and <br>Pattern Recognition fields. An artificial intelligent system is able to interact with its <br>environment if it is able to distinguish among a set of cases, instances, situations, objects, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:n9rbxLvb19AJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15048738279389911711&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'n9rbxLvb19AJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:364"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB36" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW36"><a href="http://webspace.qmul.ac.uk/mproulx/HajimirzaProulxIzquierdo2012.pdf" class=yC38><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from qmul.ac.uk</span><span class="gs_ggsS">qmul.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6145688" class=yC37>Reading Users&#39; Minds From Their Eyes: A Method for Implicit Image Annotation</a></h3><div class="gs_a">SN Hajimirza, MJ Proulx&hellip; - &hellip; , IEEE Transactions on, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper explores the possible solutions for image annotation and retrieval by <br>implicitly monitoring user attention via eye-tracking. Features are extracted from the gaze <br>trajectory of users examining sets of images to provide implicit information on the target <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8168924472133234978&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=44">Cited by 1</a> <a href="/scholar?q=related:IjF_zobZXXEJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8168924472133234978&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'IjF_zobZXXEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:363"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Mammographic Image Enhancement, Classification and Retrieval using Color, Statistical and Spectral Analysis</h3><div class="gs_a">KS Bikesh - International Journal of Computer  &hellip;, 2011 - Foundation of Computer Science ( &hellip;</div><div class="gs_fl"><a href="/scholar?q=related:MJqN3tKq4f8J:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18438206172085197360&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'MJqN3tKq4f8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:362"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB38" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW38"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/book04-chuats.pdf" class=yC3A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/1324717R67U00675.pdf" class=yC39>A Scalable Bootstrapping Framework for Auto-Annotation of Large Image Collections</a></h3><div class="gs_a">TS Chua, H Feng - Intelligent Multimedia Processing with Soft Computing, 2005 - Springer</div><div class="gs_rs">Image annotation aims to assign semantic concepts to images based on their visual <br>contents. It has received much attention recently as huge dynamic collections of <br>images/videos become available on the Web. Most recent approaches employ supervised <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:yeMT7QgHwSoJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/3D/45/RN157975788.html?source=googlescholar" class="gs_nph" class=yC3B>BL Direct</a> <a href="/scholar?cluster=3080751355016766409&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'yeMT7QgHwSoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:361"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB39" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW39"><a href="http://www.nbuv.gov.ua/Portal/natural/Sunz/2007_3/Kinosh.pdf" class=yC3D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nbuv.gov.ua</span><span class="gs_ggsS">nbuv.gov.ua <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.nbuv.gov.ua/Portal/natural/Sunz/2007_3/Kinosh.pdf" class=yC3C>ÐÐÐÐÐÐ ÐÐÐ¢ÐÐÐÐ ÐÐÐÐ¡ÐÐ Ð ÐÐÐÐÐÐÐ¦ÐÐ¯Ð¥ ÐÐÐÐÐ ÐÐÐÐÐÐ</a></h3><div class="gs_a">ÐÐ ÐÐ¸Ð½Ð¾ÑÐµÐ½ÐºÐ¾, ÐÐ ÐÑÑÑÑÐ¸Ð½ - nbuv.gov.ua</div><div class="gs_rs">Ð¡ÐµÐ¹ÑÐ°Ñ ÑÐ¶Ðµ Ð½ÐµÐ²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ Ð¿ÐµÑÐµÐ¾ÑÐµÐ½Ð¸ÑÑ Ð·Ð½Ð°ÑÐ¸Ð¼Ð¾ÑÑÑ Ð¸ Ð² ÑÐ¾ Ð¶Ðµ Ð²ÑÐµÐ¼Ñ Ð¿Ð¾Ð²ÑÐµÐ´Ð½ÐµÐ²Ð½Ð¾ÑÑÑ <br>Ð¸ÑÐ¿Ð¾Ð»ÑÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¼ÑÐ»ÑÑÐ¸Ð¼ÐµÐ´Ð¸Ð° Ð´Ð°Ð½Ð½ÑÑ. Ð¡ Ð²Ð¾Ð·Ð½Ð¸ÐºÐ½Ð¾Ð²ÐµÐ½Ð¸ÐµÐ¼ ÑÐ¸ÑÑÐ¾Ð²ÑÑ ÐºÐ°Ð¼ÐµÑ Ð¸ <br>ÑÐ¾ÑÐ¾Ð°Ð¿Ð¿Ð°ÑÐ°ÑÐ¾Ð², ÑÐ°Ð·Ð²Ð¸ÑÐ¸ÐµÐ¼ ÐºÐ¾Ð¼Ð¿ÑÑÑÐµÑÐ¾Ð² ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¸Ð½Ð´Ð¸Ð²Ð¸Ð´ÑÐ°Ð»ÑÐ½ÑÑ ÐºÐ¾Ð»Ð»ÐµÐºÑÐ¸Ð¹ Ð²Ð¸Ð´ÐµÐ¾ <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:OrHVLiyWV78J:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'OrHVLiyWV78J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md39', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md39" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:OrHVLiyWV78J:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:360"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB40" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW40"><a href="http://ethesys.lib.cyut.edu.tw/ETD-db/ETD-search/getfile?URN=etd-0628107-151251&amp;filename=etd-0628107-151251.pdf" class=yC3F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cyut.edu.tw</span><span class="gs_ggsS">cyut.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ethesys.lib.cyut.edu.tw/ETD-db/ETD-search/view_etd?URN=etd-0628107-151251" class=yC3E>Semantic Consumer Image Retrieval System Based on Multi-layer Color Features</a></h3><div class="gs_a">YL Yin - 2007 - ethesys.lib.cyut.edu.tw</div><div class="gs_rs">Abstract In recent years, digital photography has been gradually replacing traditional film <br>photography into the mainstream imaging methods. Due to the convenience of digital <br>photography, the average consumer may also possess a staggering amount of digital <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:S1zgX3G2MdwJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'S1zgX3G2MdwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:359"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB41" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW41"><a href="http://ethesys.lib.cyut.edu.tw/ETD-db/ETD-search-c/getfile?URN=etd-0113110-035740&amp;filename=etd-0113110-035740.pdf" class=yC41><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from cyut.edu.tw</span><span class="gs_ggsS">cyut.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ethesys.lib.cyut.edu.tw/ETD-db/ETD-search/view_etd?URN=etd-0113110-035740" class=yC40>An Image Retrieval for Three-dimensional Trademark</a></h3><div class="gs_a">Y Chang - 2009 - ethesys.lib.cyut.edu.tw</div><div class="gs_rs">Abstract Nowadays the quantity and the variety of registered trademarks rise rapidly, <br>whether it is at domestic or international. In our thesis, we proposed an image retrieval <br>method for three-dimensional trademark. How to rapidly search and classify the trademark <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:qOM6c2VT6WsJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'qOM6c2VT6WsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:358"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB42" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW42"><a href="http://hal.archives-ouvertes.fr/docs/00/66/65/31/PDF/thesis.pdf" class=yC43><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://hal.archives-ouvertes.fr/tel-00666531/" class=yC42>Une reprÃ©sentation visuelle avancÃ©e pour l&#39;apprentissage sÃ©mantique dans les bases d&#39;images</a></h3><div class="gs_a">I El Sayad - 2011 - hal.archives-ouvertes.fr</div><div class="gs_rs">RÃ©sumÃ© Avec l&#39;augmentation exponentielle de nombre d&#39;images disponibles sur Internet, le <br>besoin en outils efficaces d&#39;indexation et de recherche d&#39;images est devenu important. Dans <br>cette these, nous nous baserons sur le contenu visuel des images comme source <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:0iRtduNlN_sJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18102049254857843922&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'0iRtduNlN_sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:357"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB43" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW43"><a href="http://www.facom.ufu.br/posgrad/WD1/eduardo.pdf" class=yC45><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ufu.br</span><span class="gs_ggsS">ufu.br <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.facom.ufu.br/posgrad/WD1/eduardo.pdf" class=yC44>CaracterizaÃ§ ao de Imagens via Redes Neurais Artificiais</a></h3><div class="gs_a">EF Ribeiro - facom.ufu.br</div><div class="gs_rs">Resumo. Sistemas de RecuperaÃ§ ao de Imagens Baseada em ConteÃºdo (CBIR) se utilizam <br>da hipÃ³tese de correspondÃªncia de uma dada imagem a outra a partir de seus atributos <br>como cor, forma e textura. PorÃ©m, tais atributos geralmente falham em descrever <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:LQq7xrVTRHAJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'LQq7xrVTRHAJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md43', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md43" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:LQq7xrVTRHAJ:scholar.google.com/&amp;hl=en&amp;num=44&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
