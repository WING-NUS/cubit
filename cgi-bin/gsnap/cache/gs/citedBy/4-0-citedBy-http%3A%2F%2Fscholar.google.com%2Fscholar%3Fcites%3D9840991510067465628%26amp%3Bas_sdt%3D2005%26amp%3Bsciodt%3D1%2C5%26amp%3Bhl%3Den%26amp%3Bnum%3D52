Total results = 4
<div class="gs_r" style="z-index:400"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6373727" class=yC0>View-Based Discriminative Probabilistic Modeling for 3D Object Retrieval and Recognition</a></h3><div class="gs_a">M Wang, Y Gao, K Lu, <a href="/citations?user=uOJH_AEAAAAJ&amp;hl=en&amp;oi=sra">Y Rui</a> - 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In view-based 3D object retrieval and recognition, each object is described by <br>multiple views and a central problem is how to estimate the distance between two objects. <br>Most conventional methods integrate the distances of view pairs across two objects as an <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'sIPpWxvttnQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://dx.plos.org/10.1371/journal.pone.0047041" class=yC2><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from plos.org</span><span class="gs_ggsS">plos.org <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[HTML]</span><span class="gs_ct2">[HTML]</span></span> <a href="http://dx.plos.org/10.1371/journal.pone.0047041" class=yC1>Dynamic 3D Scene Depth Reconstruction via Optical Flow Field Rectification</a></h3><div class="gs_a">Y Yang, Q Liu, <a href="/citations?user=lRSD7PQAAAAJ&amp;hl=en&amp;oi=sra">R Ji</a>, Y Gao - PloS one, 2012 - dx.plos.org</div><div class="gs_rs">In this paper, we propose a depth propagation scheme based on optical flow field <br>rectification towards more accurate depth reconstruction. In depth reconstruction, the <br>occlusions and low-textural regions easily result in optical flow field errors, which lead <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'PWh2ZSNOuyMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md1', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md1" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:PWh2ZSNOuyMJ:scholar.google.com/&amp;hl=en&amp;num=4&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0165168412003738" class=yC3>Accurate off-line query expansion for large-scale mobile visual search</a></h3><div class="gs_a">K Gao, Y Zhang, D Zhang, S Lin - Signal Processing, 2012 - Elsevier</div><div class="gs_rs">Abstract Mobile visual search is a new class of applications that use images taken by <br>camera phone to initiate search queries. It is a very challenging task mainly because of <br>image affine transformations caused by viewpoints changes, and motion blur due to hand <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'jGqqcFaDOSwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/ft_gateway.cfm?id=2379797&amp;ftid=1324199&amp;dwn=1" class=yC4>In-Video Product Annotation with Web Information Mining</a></h3><div class="gs_a">G LI, Z LU, TATS CHUA - dl.acm.org</div><div class="gs_rs">Product annotation in videos is of great importance for video browsing, search, and <br>advertisement. However, most of the existing automatic video annotation research focuses <br>on the annotation of high-level concepts, such as events, scenes, and object categories. <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'L9eb5au8VsYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
