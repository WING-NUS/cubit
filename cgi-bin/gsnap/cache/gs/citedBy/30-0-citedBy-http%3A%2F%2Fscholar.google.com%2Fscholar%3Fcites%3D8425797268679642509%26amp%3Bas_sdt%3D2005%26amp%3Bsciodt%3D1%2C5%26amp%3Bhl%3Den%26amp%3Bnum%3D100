Total results = 30
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://www.comp.nus.edu.sg/~subolan/files/DAS_Binarization.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1815351" class=yC0>Binarization of historical document images using the local maximum and minimum</a></h3><div class="gs_a"><a href="/citations?user=ymlKC0EAAAAJ&amp;hl=en&amp;oi=sra">B Su</a>, <a href="/citations?user=Fgqq-4kAAAAJ&amp;hl=en&amp;oi=sra">S Lu</a>, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - Proceedings of the 9th IAPR International  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract This paper presents a new document image binarization technique that segments <br>the text from badly degraded historical document images. The proposed technique makes <br>use of the image contrast that is defined by the local image maximum and minimum. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13085893819197236154&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=30">Cited by 38</a> <a href="/scholar?q=related:uiO7tRhvmrUJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13085893819197236154&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'uiO7tRhvmrUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://www.comp.nus.edu/~subolan/files/IJDAR_2010.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu</span><span class="gs_ggsS">nus.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/R61316267330550M.pdf" class=yC2>Document image binarization using background estimation and stroke edges</a></h3><div class="gs_a"><a href="/citations?user=Fgqq-4kAAAAJ&amp;hl=en&amp;oi=sra">S Lu</a>, <a href="/citations?user=ymlKC0EAAAAJ&amp;hl=en&amp;oi=sra">B Su</a>, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - International journal on document analysis and  &hellip;, 2010 - Springer</div><div class="gs_rs">Abstract Document images often suffer from different types of degradation that renders the <br>document image binarization a challenging task. This paper presents a document image <br>binarization technique that segments the text from badly degraded document images <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13797077206185585563&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=30">Cited by 28</a> <a href="/scholar?q=related:m6tUdZ4Qeb8J:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13797077206185585563&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'m6tUdZ4Qeb8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320309004208" class=yC4>Transition pixel: A concept for binarization based on edge detection and gray-intensity histograms</a></h3><div class="gs_a"><a href="/citations?user=lgosrgEAAAAJ&amp;hl=en&amp;oi=sra">MA RamÃ­rez-OrtegÃ³n</a>, E Tapia, LL RamÃ­rez-RamÃ­rez&hellip; - Pattern Recognition, 2010 - Elsevier</div><div class="gs_rs">This paper introduces a novel binarization method based on the concept of transition pixel, a <br>generalization of edge pixels. Such pixels are characterized by extreme transition values <br>computed using pixel-intensity differences in a small neighborhood. We show how to <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17684705625238161871&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=30">Cited by 11</a> <a href="/scholar?q=related:z0msjRGybPUJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17684705625238161871&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'z0msjRGybPUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.opticsinfobase.org/oe/fulltext.cfm?uri=oe-17-26-23880" class=yC5>Retrospective correction of nonuniform illumination on bi-level images</a></h3><div class="gs_a">H Lee, J Kim - Optics express, 2009 - opticsinfobase.org</div><div class="gs_rs">Abstract We propose a novel method for correcting the effect of nonuniform illumination on a <br>bi-level image. The proposed method is based on a penalized nonlinear least squares <br>objective function that measures the binariness of an image and the roughness of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15839721226705597899&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=30">Cited by 7</a> <a href="/scholar?q=related:y3UAg4j-0dsJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15839721226705597899&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'y3UAg4j-0dsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5349338" class=yC6>A novel hybrid algorithm for binarization of badly illuminated document images</a></h3><div class="gs_a">M Valizadeh, N Armanfard, M Komeili&hellip; - &hellip; , 2009. CSICC 2009.  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present a novel hybrid algorithm for binarization of badly <br>illuminated document images. This algorithm locally enhances the document image and <br>makes the gray levels of text and background pixels separable. Afterward a simple global <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12301414963619047395&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=30">Cited by 7</a> <a href="/scholar?q=related:4ycw1btnt6oJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'4ycw1btnt6oJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://www.icdar2011.org/fileup/PDF/4520b205.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from icdar2011.org</span><span class="gs_ggsS">icdar2011.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6065501" class=yC7>New binarization approach based on text block extraction</a></h3><div class="gs_a">I Ben Messaoud, H Amiri, <a href="/citations?user=8EnK8jsAAAAJ&amp;hl=en&amp;oi=sra">H El Abed</a>&hellip; - Document Analysis  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Document analysis and recognition systems include, usually, several levels, <br>annotation, preprocessing, segmentation, feature extraction, classification and post-<br>processing. Each level may be dependent on or independent from the other levels. The <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5457395637685141297&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=30">Cited by 10</a> <a href="/scholar?q=related:MT_9_mqQvEsJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5457395637685141297&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'MT_9_mqQvEsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5583364" class=yC9>A novel image binarization method using hybrid thresholding</a></h3><div class="gs_a">TY Kuo, YY Lai, YC Lo - Multimedia and Expo (ICME), 2010  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we proposed a simple yet effective image binarization method to work <br>with various kinds of images, such as images with the color bleeding characters, or with non-<br>uniform background exposed to poor ambient light, and so forth. Our approach is based <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4047692680153005710&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=30">Cited by 7</a> <a href="/scholar?q=related:jv53CAxLLDgJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4047692680153005710&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'jv53CAxLLDgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="ftp://78.38.77.30/cee/y.baleghi/Digital%20Image%20Processing/Papers/Shading%20Extraction%20and%20Correction%20for%20scanned%20book%20images.pdf" class=yCB><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 78.38.77.30</span><span class="gs_ggsS">78.38.77.30 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4682549" class=yCA>Shading extraction and correction for scanned book images</a></h3><div class="gs_a">G Meng, N Zheng, S Du, Y Song&hellip; - &hellip; Processing Letters, IEEE, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract When one scans document pages from a bound book, shading artifacts are <br>commonly occurred in the book spine area. In this letter, we propose a general-purpose <br>method for image shading correction based on an assumption that the reflectance function <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18117024635323828313&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=30">Cited by 5</a> <a href="/scholar?q=related:WUh67-qZbPsJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18117024635323828313&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'WUh67-qZbPsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320311005140" class=yCC>AdOtsu: An adaptive and parameterless generalization of Otsu&#39;s method for document image binarization</a></h3><div class="gs_a"><a href="/citations?user=Z8HHAskAAAAJ&amp;hl=en&amp;oi=sra">R Farrahi Moghaddam</a>, <a href="/citations?user=oG89PhIAAAAJ&amp;hl=en&amp;oi=sra">M Cheriet</a> - Pattern Recognition, 2011 - Elsevier</div><div class="gs_rs">Adaptive binarization methods play a central role in document image processing. In this <br>work, an adaptive and parameterless generalization of Otsu&#39;s method is presented. The <br>adaptiveness is obtained by combining grid-based modeling and the estimated <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17100158607411759020&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=30">Cited by 7</a> <a href="/scholar?q=related:rMedJaf3T-0J:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17100158607411759020&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'rMedJaf3T-0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://www.di.ufpe.br/~cabm/visao/artigos/Binarization%20of%20degraded%20document%20image%20based%20on%20feature%20space%20partitioning%20and%20classification.pdf" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ufpe.br</span><span class="gs_ggsS">ufpe.br <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/453W00214557L280.pdf" class=yCD>Binarization of degraded document image based on feature space partitioning and classification</a></h3><div class="gs_a">M Valizadeh, <a href="/citations?user=FiD6uO8AAAAJ&amp;hl=en&amp;oi=sra">E Kabir</a> - International journal on document analysis and  &hellip;, 2010 - Springer</div><div class="gs_rs">Abstract In this paper, we propose a new algorithm for the binarization of degraded <br>document images. We map the image into a 2D feature space in which the text and <br>background pixels are separable, and then we partition this feature space into small <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=16547544016485198566&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=30">Cited by 6</a> <a href="/scholar?q=related:5qq9P5yvpOUJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16547544016485198566&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'5qq9P5yvpOUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://www.math.tau.ac.il/~turkel/imagepapers/binarization.pdf" class=yC10><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tau.ac.il</span><span class="gs_ggsS">tau.ac.il <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.math.tau.ac.il/~turkel/imagepapers/binarization.pdf" class=yCF>A new method for shading removal and binarization of documents acquired with portable digital cameras</a></h3><div class="gs_a">DM Oliveira, <a href="/citations?user=jR-40QMAAAAJ&amp;hl=en&amp;oi=sra">RD Lins</a> - &hellip;  of Third International Workshop on Camera- &hellip;, 2009 - math.tau.ac.il</div><div class="gs_rs">Abstract Photo documents, documents digitized with portable digital cameras, often are <br>affected by non-uniform shading. This paper proposes a new method to remove the shade of <br>document images captured with digital cameras followed by a new binarization algorithm. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14072441406166227881&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=30">Cited by 4</a> <a href="/scholar?q=related:qVsJYeZaS8MJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14072441406166227881&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'qVsJYeZaS8MJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md10', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md10" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:qVsJYeZaS8MJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://www.cse.iitb.ac.in/~sharat/icvgip.org/icvgip2010/papers/14.peng.249.pdf" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from iitb.ac.in</span><span class="gs_ggsS">iitb.ac.in <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1924569" class=yC11>Markov random field based binarization for hand-held devices captured document images</a></h3><div class="gs_a"><a href="/citations?user=0MipCn8AAAAJ&amp;hl=en&amp;oi=sra">X Peng</a>, <a href="/citations?user=BPEF3ZwAAAAJ&amp;hl=en&amp;oi=sra">S Setlur</a>, <a href="/citations?user=ruIgbscAAAAJ&amp;hl=en&amp;oi=sra">V Govindaraju</a>&hellip; - Proceedings of the Seventh &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, a novel Markov random fields (MRF) based binarization algorithm is <br>proposed to segment foreground text from document images captured using hand-held <br>devices (such as cell-phone or digital camera). In the MRF based framework, an edge <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11099761999840101608&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=30">Cited by 4</a> <a href="/scholar?q=related:6ETZ07pGCpoJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11099761999840101608&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'6ETZ07pGCpoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://www.visionopen.com/members/pengxujun/publications/xujun_drr2011.pdf" class=yC14><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from visionopen.com</span><span class="gs_ggsS">visionopen.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://proceedings.spiedigitallibrary.org/data/Conferences/SPIEP/2687/78740R_1.pdf" class=yC13>Binarization of camera-captured document using A MAP approach</a></h3><div class="gs_a"><a href="/citations?user=0MipCn8AAAAJ&amp;hl=en&amp;oi=sra">X Peng</a>, <a href="/citations?user=BPEF3ZwAAAAJ&amp;hl=en&amp;oi=sra">S Setlur</a>, <a href="/citations?user=ruIgbscAAAAJ&amp;hl=en&amp;oi=sra">V Govindaraju</a>&hellip; - Proc. of SPIE- &hellip;, 2011 - proceedings.spiedigitallibrary.org</div><div class="gs_rs">ABSTRACT Document binarization is one of the initial and critical steps for many document <br>analysis systems. Nowadays, with the success and popularity of hand-held devices, large <br>efforts are motivated to convert documents into digital format by using hand-held cameras. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=465550462029696999&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=30">Cited by 2</a> <a href="/scholar?q=related:549Muq33dQYJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=465550462029696999&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'549Muq33dQYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/95033x/200913/31022418.html" class=yC15>ææ¡£å¾åäºå¼åç®æ³ VFCM</a></h3><div class="gs_a">ç«¥ç«éï¼ éä¾ï¼ ä»æç²ï¼ æ®µå»ºå - è®¡ç®æºå·¥ç¨ä¸è®¾è®¡, 2009 - cqvip.com</div><div class="gs_rs">ä¸ºäºæé«åºäºæææ¹å¼çææ¡£å¾åçäºå¼åææ, éä½åå­¦å­ç¬¦è¯å«(optical character <br>recognition, OCR) ç³»ç»çæå­è¯å«éè¯¯ç, æåºäºä¸ç§å¨å±éå¼ä¸å±é¨éå¼ç¸ç»åçäºå¼å<br>ç®æ³ââVFCM. è¯¥ç®æ³ä½¿ç¨æå¤§æ¹å·®æ¯æ¹æ³äº§çå¨å±éå¼, ä½¿ç¨FCM (FuzzyC-Means) èç±»<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8216124701832975572&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=30">Cited by 3</a> <a href="/scholar?q=related:1BQRq-KJBXIJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8216124701832975572&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'1BQRq-KJBXIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="http://www.comp.nus.edu.sg/~TANCL/publications/c2011/SuBolan-ICDAR2011.pdf" class=yC17><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6065269" class=yC16>Combination of Document Image Binarization Techniques</a></h3><div class="gs_a"><a href="/citations?user=ymlKC0EAAAAJ&amp;hl=en&amp;oi=sra">B Su</a>, <a href="/citations?user=Fgqq-4kAAAAJ&amp;hl=en&amp;oi=sra">S Lu</a>, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - Document Analysis and Recognition ( &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Document image binarization has been studied for decades, and many practical <br>binarization techniques have been proposed for different kinds of document images. <br>However, many state-of-the-art methods are particularly suitable for the document images <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11180123808708768245&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=30">Cited by 8</a> <a href="/scholar?q=related:9TH5gl7HJ5sJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11180123808708768245&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'9TH5gl7HJ5sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6320858" class=yC18>Partitioning of feature space by iterative classification for degraded document image binarisation</a></h3><div class="gs_a">M Valizadeh, <a href="/citations?user=FiD6uO8AAAAJ&amp;hl=en&amp;oi=sra">E Kabir</a> - Image Processing, IET, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Proper partitioning of feature space into text and background regions is very <br>important in document image binarisation. This study presents an iterative classification <br>algorithm that efficiently partitions a two-dimensional feature space into text and <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'nCHfCrf5TBMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://www.ijetae.com/files/Volume2Issue11/IJETAE_1112_73.pdf" class=yC1A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ijetae.com</span><span class="gs_ggsS">ijetae.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ijetae.com/files/Volume2Issue11/IJETAE_1112_73.pdf" class=yC19>Variational Background Modeling Using Grid Point Sampling for Document Image Binarization</a></h3><div class="gs_a">J Bharathi, PC Reddy - ijetae.com</div><div class="gs_rs">AbstractâHistorical and degraded documents have varying background due to poor and <br>uneven illumination, ageing of paper etc. Global thresholding methods give poor <br>binarization results for these documents. Local binarization methods which are adaptive <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'oDPcE5In304J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md16', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md16" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:oDPcE5In304J:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/ln44130577848762.pdf" class=yC1B>An adaptive water flow model for binarization of degraded document images</a></h3><div class="gs_a">M Valizadeh, <a href="/citations?user=FiD6uO8AAAAJ&amp;hl=en&amp;oi=sra">E Kabir</a> - International Journal on Document Analysis and  &hellip;, 2012 - Springer</div><div class="gs_rs">Abstract In this paper, we present an adaptive water flow model for the binarization of <br>degraded document images. We regard an image surface as a three-dimensional terrain <br>and pour water on it. The water finds the valleys and fills them. Our algorithm controls the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8800636522935848017&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=30">Cited by 1</a> <a href="/scholar?q=related:UYzrMkokInoJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'UYzrMkokInoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Restoration of Degraded Historical Document Image</h3><div class="gs_a">B Gangamma, S Murthy, AV Singh - Journal of Emerging Trends in Computing and  &hellip;, 2012</div><div class="gs_fl"><a href="/scholar?q=related:l5SbOR9mguAJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16177605095764759703&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'l5SbOR9mguAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S1051200412000826" class=yC1C>Efficient illumination compensation techniquies for text images</a></h3><div class="gs_a">KN Chen, CH Chen, CC Chang - Digital Signal Processing, 2012 - Elsevier</div><div class="gs_rs">With the great advantages of digitization, more and more documents are being transformed <br>into digital representations. Most content digitization of documents is performed by scanners <br>or digital cameras. However, the transformation might degrade the image quality caused <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:4c8tQK61t8cJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14391170894291390433&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'4c8tQK61t8cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB20" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW20"><a href="http://www.icdar2011.org/fileup/PDF/4520a172.pdf" class=yC1E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from icdar2011.org</span><span class="gs_ggsS">icdar2011.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6065298" class=yC1D>Novel data representation for text extraction from multispectral historical document images</a></h3><div class="gs_a"><a href="/citations?user=EYp499kAAAAJ&amp;hl=en&amp;oi=sra">R Hedjam</a>, <a href="/citations?user=oG89PhIAAAAJ&amp;hl=en&amp;oi=sra">M Cheriet</a> - Document Analysis and Recognition ( &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The extraction and analysis of useful information from old document images is very <br>important into cultural heritage preservation. In advanced research, where the goal is to <br>separate the foreground (in general, text) from the background, image restoration and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:GYIkjki11tIJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15192529716207976985&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'GYIkjki11tIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="http://www.cse.buffalo.edu/faculty/shambhu/documents/pdf/acm-2011/thesis-xpeng.pdf" class=yC20><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from buffalo.edu</span><span class="gs_ggsS">buffalo.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.cse.buffalo.edu/faculty/shambhu/documents/pdf/acm-2011/thesis-xpeng.pdf" class=yC1F>Probabilistic random field based method for annotated machine printed documents preprocessing</a></h3><div class="gs_a"><a href="/citations?user=0MipCn8AAAAJ&amp;hl=en&amp;oi=sra">X Peng</a> - 2010 - cse.buffalo.edu</div><div class="gs_rs">Abstract Today, the convenience of search, both on the personal computer hard disk and on <br>the web, is essentially limited to machine-printed text documents and images because of the <br>poor accuracy of handwriting recognizers. The proposed research will advance the state-<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:k36pk5XUlvEJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17408335148539805331&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'k36pk5XUlvEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md21', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md21" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:k36pk5XUlvEJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a>  <a href="/scholar?q=info:k36pk5XUlvEJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=15785504530690994636&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB22" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW22"><a href="http://137.132.14.55/bitstream/handle/10635/35862/ThesisSuBolan.pdf?sequence=1" class=yC22><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.14.55</span><span class="gs_ggsS">137.132.14.55 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://137.132.14.55/handle/10635/35862" class=yC21>Document image enhancement</a></h3><div class="gs_a">S Bolan - 2012 - 137.132.14.55</div><div class="gs_rs">Document image enhancing aims to improve the document image quality, which not only <br>enhance human perception, but also facilitate the subsequent automated image processing. <br>Document image enhancing is a difficult problem, because: 1) The information it aims to <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'C06fsFOaSNsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/ft_gateway.cfm?id=2037359&amp;type=pdf" class=yC23>Combining statistical and geometrical classifiers for text extraction in multispectral document images</a></h3><div class="gs_a"><a href="/citations?user=EYp499kAAAAJ&amp;hl=en&amp;oi=sra">R Hedjam</a>, <a href="/citations?user=oG89PhIAAAAJ&amp;hl=en&amp;oi=sra">M Cheriet</a> - Proceedings of the 2011 Workshop on Historical  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract Extraction of the original text from historical document images is very important in <br>the preservation of cultural heritage. In recent decades, many image processing techniques <br>have been developed to separate the main text from the document image background, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:4Q10tn_vbTgJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4066169370386370017&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'4Q10tn_vbTgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6361405" class=yC24>Non-parametric Illumination Correction for Scanned Document Images via Convex Hulls</a></h3><div class="gs_a">G Meng, <a href="/citations?user=0ggsACEAAAAJ&amp;hl=en&amp;oi=sra">S Xiang</a>, N Zheng, C Pan - 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract A scanned image of an opened book page often suffers from various scanning <br>artifacts known as scanning shading and dark borders noises. These artifacts will degrade <br>the qualities of the scanned images and cause many problems to the subsequent process <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'iY0xt38rowEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB25" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW25"><a href="http://www.stanford.edu/class/ee368/Project_11/Proposals/Jou_Ni_Su_Android_Graph_Reader.pdf" class=yC26><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from stanford.edu</span><span class="gs_ggsS">stanford.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.stanford.edu/class/ee368/Project_11/Proposals/Jou_Ni_Su_Android_Graph_Reader.pdf" class=yC25>EE368 Project Proposal: Android Graph Reader</a></h3><div class="gs_a">T Jou, W Ni, J Su - 2011 - stanford.edu</div><div class="gs_rs">The target users of our system are students who need to read data off graphs in textbooks <br>and printed notes. Making this system available on the Android platform will improve the <br>accessibility of this technology, especially in comparison to existing computer-âbased <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:CODVu-nwPLgJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'CODVu-nwPLgJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md25', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md25" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:CODVu-nwPLgJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/l63646h100w7j912.pdf" class=yC27>Illumination Compensation for Document Images Using Local-Global Block Analysis</a></h3><div class="gs_a">M Azmi, M Iqbal Saripan, R Azmir&hellip; - Visual Informatics: Bridging &hellip;, 2009 - Springer</div><div class="gs_rs">Abstract. This paper presents the illumination compensation technique for document images <br>using local-global block analysis. Imbalance illumination will affect the performance of <br>classification and segmentation process because the darker regions conceal the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=759438341163285987&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=30">Cited by 1</a> <a href="/scholar?q=related:433ZySURigoJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=759438341163285987&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'433ZySURigoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/95033x/200913/31022425.html" class=yC28>åºäº DT-CWT çæ°å­æ°´å°ç®æ³</a></h3><div class="gs_a">å´å¾é¾ï¼ é»æå¹ - è®¡ç®æºå·¥ç¨ä¸è®¾è®¡, 2009 - cqvip.com</div><div class="gs_rs">ä¸ºäºå®ç°æ°å­å¾åççæä¿æ¤, è®¾è®¡äºä¸ç§åºäºåæ å¤å°æ³¢åæ¢çæå ä½æ»å»çæ°å­æ°´å°ç®æ³: <br>å¯¹æ°´å°å¾åè¿è¡ä¸çº§åæ å¤å°æ³¢åæ¢, æåç¹å¾å¹¶æå¼ä¸ºç¹å¾ç©éµ, å¹¶ä¸å®ä¹äºä¸ç§æ°çè·ç¦»<br>åéç¨äºç¸ä¼¼æ§åº¦é, ä½¿ç¨ç¹å¾ç©éµå¯¹é­åå ä½æ»å»çå¾åè¿è¡åæ°ä¼°è®¡. å®éªç»æè¡¨æ, è¯¥<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:0hwxJAy2JGsJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7720495824482933970&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'0hwxJAy2JGsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB28" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW28"><a href="http://ir.ntut.edu.tw/ir/retrieve/55259/ntut-97-95318007-1.pdf" class=yC2A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntut.edu.tw</span><span class="gs_ggsS">ntut.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://ir.ntut.edu.tw/ir/retrieve/55259/ntut-97-95318007-1.pdf" class=yC29>é»æ©å·¥ç¨ç³»ç¢©å£«ç­ç¢©å£«å­¸ä½ï¥æ</a></h3><div class="gs_a">é¾æ¿ç·ï¼ å¨è³å¦ - ir.ntut.edu.tw</div><div class="gs_rs">Page 1. é»æ©å·¥ç¨ç³»ç¢©å£«ç­ ç¢©å£«å­¸ä½ï¥æ ç¹é«å£ä¾é»ç§æå» æ¥å°æéåæåå¶ é¢¨éªè©ä¼° Ground<br>Fault Analysis and Risk Assessments for the High-Tech Industrial Plants Supplied by VHV<br>Distribution System ç ç©¶çï¼é¾æ¿ç· æå°ææï¼å¨è³å¦ ä¸­è¯æ°åä¹åä¸ï¦ï§æ Page 2. i æè¦ <b>...</b> </div><div class="gs_fl"><a onclick="return gs_ocit(event,'2cf3Sf0qtZYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB29" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW29"><a href="http://www.arocmag.com/ch/reader/create_pdf.aspx?file_no=10090703&amp;flag=1&amp;journal_id=arocmag" class=yC2C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arocmag.com</span><span class="gs_ggsS">arocmag.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.arocmag.com/ch/reader/create_pdf.aspx?file_no=10090703&amp;flag=1&amp;journal_id=arocmag" class=yC2B>ä¸ç§éå¯¹è¾åä¹¦ç±æ«æå¾åçäºå¼åæ¹æ³</a></h3><div class="gs_a">å¼ ä¼ï¼ åå¿å - è®¡ç®æºåºç¨ç ç©¶, 2011 - arocmag.com</div><div class="gs_rs">æè¦: å¯¹è¾åçä¹¦ç±è¿è¡æ«ææ¶, ç±äºä¸­ç¼é¾ä»¥åå¹³, å¸¸ä½¿æ«æåçå¾ååºç°é»è¾¹, <br>å èéç¨å¸¸è§çç®æ³å¯¹å¶è¿è¡éå¼åç»æå¾ä¸çæ³, è¿èä¸¥éå½±åå°æå­è¯å«çææ. <br>éå¯¹è¿ä¸é®é¢, æåºäºä¸ç§åºäºçº¹çåæçå¾åäºå¼åæ¹æ³. è¯¥æ¹æ³å¨å¨æéå¼çåºç¡ä¸, éè¿<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:0yOk3mmKc0sJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5436841362477818835&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'0yOk3mmKc0sJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md29', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md29" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:0yOk3mmKc0sJ:scholar.google.com/&amp;hl=en&amp;num=30&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
