Total results = 65
<div class="gs_r" style="z-index:400"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0167865504002466" class=yC0>A new Hausdorff distance for image matching</a></h3><div class="gs_a">C Zhao, W Shi, Y Deng - Pattern Recognition Letters, 2005 - Elsevier</div><div class="gs_rs">Object matching in two-dimensional images has been an important topic in computer vision, <br>object recognition, and image analysis. The Hausdorff distance plays an important role in <br>image matching. In order to deal with image matching problems in random noisy <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14120979449344642958&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 67</a> <a href="/scholar?q=related:jk_HNv7L98MJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14120979449344642958&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'jk_HNv7L98MJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.77.3430&amp;rep=rep1&amp;type=pdf" class=yC2><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/46P924JG64407X71.pdf" class=yC1>Keyword-guided word spotting in historical printed documents using synthetic data and user feedback</a></h3><div class="gs_a">T Konidaris, <a href="/citations?user=0bNXadoAAAAJ&amp;hl=en&amp;oi=sra">B Gatos</a>, K Ntzios, <a href="/citations?user=lCVokogAAAAJ&amp;hl=en&amp;oi=sra">I Pratikakis</a>&hellip; - International Journal on  &hellip;, 2007 - Springer</div><div class="gs_rs">Abstract In this paper, we propose a novel technique for word spotting in historical printed <br>documents combining synthetic data and user feedback. Our aim is to search for keywords <br>typed by the user in a large collection of digitized printed historical documents. The <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18159797742008130699&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 59</a> <a href="/scholar?q=related:i9xV5dSPBPwJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/42/11/RN206182774.html?source=googlescholar" class="gs_nph" class=yC3>BL Direct</a> <a href="/scholar?cluster=18159797742008130699&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'i9xV5dSPBPwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://staging.comp.nus.edu.sg/~tancl/publications/j2004/TKDE_2004_LuY.pdf" class=yC5><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1339266" class=yC4>Information retrieval in document image databases</a></h3><div class="gs_a">Y Lu, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - &hellip;  and Data Engineering, IEEE Transactions on, 2004 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract With the rising popularity and importance of document images as an information <br>source, information retrieval in document image databases has become a growing and <br>challenging problem. In this paper, we propose an approach with the capability of <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18315018101739793021&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 39</a> <a href="/scholar?q=related:faoMKe0DLP4J:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/50/1F/RN157518999.html?source=googlescholar" class="gs_nph" class=yC6>BL Direct</a> <a href="/scholar?cluster=18315018101739793021&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 33 versions</a> <a onclick="return gs_ocit(event,'faoMKe0DLP4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://users.iit.demokritos.gr/~bgat/ICDAR2005_KeywordSearch.pdf" class=yC8><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from demokritos.gr</span><span class="gs_ggsS">demokritos.gr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1575509" class=yC7>A segmentation-free approach for keyword search in historical typewritten documents</a></h3><div class="gs_a"><a href="/citations?user=0bNXadoAAAAJ&amp;hl=en&amp;oi=sra">B Gatos</a>, T Konidaris, K Ntzios&hellip; - Document Analysis  &hellip;, 2005 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose a novel segmentation-free approach for keyword search <br>in historical typewritten documents combining image preprocessing, synthetic data creation, <br>word spotting and user feedback technologies. Our aim is to search for keywords typed by <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12049564886214827114&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 36</a> <a href="/scholar?q=related:atzaNGynOKcJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12049564886214827114&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'atzaNGynOKcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB4" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW4"><a href="http://pixel-shaker.fr/wp-content/uploads/publications/Baudrier2008.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from pixel-shaker.fr</span><span class="gs_ggsS">pixel-shaker.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320307003287" class=yC9>Binary-image comparison with local-dissimilarity quantification</a></h3><div class="gs_a"><a href="/citations?user=ZFkMdjUAAAAJ&amp;hl=en&amp;oi=sra">Ã Baudrier</a>, F Nicolier, G Millon, S Ruan - Pattern Recognition, 2008 - Elsevier</div><div class="gs_rs">In this paper, we present a method for binary image comparison. For binary images, intensity <br>information is poor and shape extraction is often difficult. Therefore binary images have to be <br>compared without using feature extraction. Due to the fact that different scene patterns can <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6906001158270479844&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 26</a> <a href="/scholar?q=related:5O0lwXYL118J:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6906001158270479844&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'5O0lwXYL118J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.94.2049&amp;rep=rep1&amp;type=pdf" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.worldscientific.com/doi/abs/10.1142/S0218001404003137" class=yCB>Chinese word searching in imaged documents</a></h3><div class="gs_a">LU YUE, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">LIMTAN CHEW</a> - International Journal of Pattern  &hellip;, 2004 - World Scientific</div><div class="gs_rs">An approach to searching for user-specified words in imaged Chinese documents, without <br>the requirements of layout analysis and OCR processing of the entire documents, is <br>proposed in this paper. A small number of Chinese characters that cannot be successfully <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5282528325200680472&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 15</a> <a href="/scholar?q=related:GJaGE4ZPT0kJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/45/29/RN148356931.html?source=googlescholar" class="gs_nph" class=yCD>BL Direct</a> <a href="/scholar?cluster=5282528325200680472&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 16 versions</a> <a onclick="return gs_ocit(event,'GJaGE4ZPT0kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.158.7218&amp;rep=rep1&amp;type=pdf" class=yCF><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0262885609002005" class=yCE>Segmentation of historical machine-printed documents using Adaptive Run Length Smoothing and skeleton segmentation paths</a></h3><div class="gs_a">N Nikolaou, M Makridis, <a href="/citations?user=0bNXadoAAAAJ&amp;hl=en&amp;oi=sra">B Gatos</a>&hellip; - Image and Vision  &hellip;, 2010 - Elsevier</div><div class="gs_rs">In this paper, we strive towards the development of efficient techniques in order to segment <br>document pages resulting from the digitization of historical machine-printed sources. This <br>kind of documents often suffer from low quality and local skew, several degradations due <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18108289858968782422&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 21</a> <a href="/scholar?q=related:VoakVa-RTfsJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18108289858968782422&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'VoakVa-RTfsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://hal.archives-ouvertes.fr/docs/00/10/43/02/PDF/cr1061193216313.pdf" class=yC11><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://hal.archives-ouvertes.fr/inria-00104302/" class=yC10>Efficient off-line cursive handwriting word recognition</a></h3><div class="gs_a"><a href="/citations?user=0bNXadoAAAAJ&amp;hl=en&amp;oi=sra">B Gatos</a>, <a href="/citations?user=lCVokogAAAAJ&amp;hl=en&amp;oi=sra">I Pratikakis</a>, AL Kesidis&hellip; - &hellip;  on Frontiers in  &hellip;, 2006 - hal.archives-ouvertes.fr</div><div class="gs_rs">Abstract In this paper, we present an off-line cursive word handwriting recognition <br>methodology. This is based on a novel combination of two different modes of word image <br>normalization and robust hybrid feature extraction. Word image normalization is <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17559080809236560482&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 12</a> <a href="/scholar?q=related:YnrsyPZirvMJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17559080809236560482&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 13 versions</a> <a onclick="return gs_ocit(event,'YnrsyPZirvMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://iit.demokritos.gr/~bgat/icpr06.pdf" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from demokritos.gr</span><span class="gs_ggsS">demokritos.gr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1699375" class=yC12>Hybrid off-line cursive handwriting word recognition</a></h3><div class="gs_a"><a href="/citations?user=0bNXadoAAAAJ&amp;hl=en&amp;oi=sra">B Gatos</a>, <a href="/citations?user=lCVokogAAAAJ&amp;hl=en&amp;oi=sra">I Pratikakis</a>&hellip; - Pattern Recognition, 2006.  &hellip;, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present an off-line cursive word handwriting recognition <br>methodology. This is based on an additive fusion resulted after a novel combination of two <br>different modes of word image normalization and robust hybrid feature extraction. We <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7569620525195122129&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 9</a> <a href="/scholar?q=related:0dXCGMOxDGkJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=7569620525195122129&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'0dXCGMOxDGkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://iit.demokritos.gr/~bgat/Icdar2007_AnEfficientWordSegm.pdf" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from demokritos.gr</span><span class="gs_ggsS">demokritos.gr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4378699" class=yC14>An efficient word segmentation technique for historical and degraded machine-printed documents</a></h3><div class="gs_a">M Makridis, N Nikolaou, <a href="/citations?user=0bNXadoAAAAJ&amp;hl=en&amp;oi=sra">B Gatos</a> - Document Analysis and  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Word segmentation is a crucial step for segmentation-free document analysis <br>systems and is used for creating an index based on word matching. In this paper, we <br>propose a novel methodology for word segmentation in historical and degraded machine-<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=689822893645160159&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 11</a> <a href="/scholar?q=related:396mVUS-kgkJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=689822893645160159&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'396mVUS-kgkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://hal.archives-ouvertes.fr/docs/00/38/53/23/PDF/GRECLNCSV2.pdf" class=yC17><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/JW5WQ218R7251K15.pdf" class=yC16>A non-symmetrical method of image local-difference comparison for ancient impressions dating</a></h3><div class="gs_a"><a href="/citations?user=ZFkMdjUAAAAJ&amp;hl=en&amp;oi=sra">Ã Baudrier</a>, N Girard, JM Ogier - Graphics Recognition. Recent Advances  &hellip;, 2008 - Springer</div><div class="gs_rs">In this article, we focus on the dating of images (impressions, ornamental letters) printed <br>starting from the same stamp. This difficult task needs a good observation of the differences <br>between the compared images. We present a method, based on a local adaptation of the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=42601259346050043&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 9</a> <a href="/scholar?q=related:-ztOop5ZlwAJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=42601259346050043&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'-ztOop5ZlwAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB11" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW11"><a href="http://www.comp.nus.edu.sg/~TANCL/publications/c2002/LuY-das2002.pdf" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/vc7jev8d3kg9rxn4.pdf" class=yC18>Word searching in document images using word portion matching</a></h3><div class="gs_a">Y Lu, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">C Tan</a> - Document Analysis Systems V, 2002 - Springer</div><div class="gs_rs">An approach with the capability of searching a word portion in document images is <br>proposed in this paper, to facilitate the detection and location of the user-specified query <br>words. A feature string is synthesized according to the character sequence in the user-<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3647449478686784503&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 7</a> <a href="/scholar?q=related:9ztP0flXnjIJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/5F/4C/RN118897845.html?source=googlescholar" class="gs_nph" class=yC1A>BL Direct</a> <a href="/scholar?cluster=3647449478686784503&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 23 versions</a> <a onclick="return gs_ocit(event,'9ztP0flXnjIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB12" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW12"><a href="http://etienne.baudrier.free.fr/Baudrier_ISJ07.pdf" class=yC1C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from free.fr</span><span class="gs_ggsS">free.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.ingentaconnect.com/content/maney/isj/2007/00000055/00000003/art00005" class=yC1B>Hausdorff distance-based multiresolution maps applied to image similarity measure</a></h3><div class="gs_a"><a href="/citations?user=ZFkMdjUAAAAJ&amp;hl=en&amp;oi=sra">E Baudrier</a>, G Millon, F Nicolier&hellip; - &hellip;  Science Journal, The, 2007 - ingentaconnect.com</div><div class="gs_rs">Abstract: Image comparison is widely used in image processing. For binary images that are <br>not composed of a single shape, a local comparison can be interesting because the features <br>are usually poor (colour) or difficult to extract (texture, forms). Thus a new binary image <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15259524146260032305&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 7</a> <a href="/scholar?q=related:MTtT01y4xNMJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/43/3C/RN215450910.html?source=googlescholar" class="gs_nph" class=yC1D>BL Direct</a> <a href="/scholar?cluster=15259524146260032305&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'MTtT01y4xNMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB13" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW13"><a href="http://www.kzyjc.net:8080/EN/article/downloadArticleFile.do?attachType=PDF&amp;id=9282" class=yC1F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from kzyjc.net</span><span class="gs_ggsS">kzyjc.net <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.kzyjc.net:8080/EN/article/downloadArticleFile.do?attachType=PDF&amp;id=9282" class=yC1E>å æ Hausdorff è·ç¦»ç®æ³å¨ SAR/INS æ¯è±¡å¹éä¸­çåºç¨ [J]</a></h3><div class="gs_a">å·éªé£ï¼ åå»ºä¸ï¼ çæºï¼ é¢å¹¿å - æ§å¶ä¸å³ç­, 2006 - kzyjc.net</div><div class="gs_rs">æè¦: æåºäºä¸ç§åºäºç¹å¾å¾ååæ¯ç¹æåçå æH au sdo rff è·ç¦»å¾åå¹éç®æ³, <br>å¹¶ç»åºäºç¸åºçæå¼æ±è§£å¬å¼. ä¸ºæ»¡è¶³æ¯è±¡å¹éå¯¼èªç³»ç»å®æ¶æ§çè¦æ±, ç»åºäºç»åå¤ççé¢<br>å¤çæ¹æ³, åå°äºç¹å¾æä»¶çåä½åº¦, æé«äºå¹éæç´¢çå¿«éæ§. åæ¶, åºäºç»ååæååºç<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=449021397306207385&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 16</a> <a href="/scholar?q=related:mWz88pQ-OwYJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=449021397306207385&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'mWz88pQ-OwYJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md13', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md13" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:mWz88pQ-OwYJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB14" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW14"><a href="https://web.cs.umass.edu/publication/docs/2004/UM-CS-2004-071.pdf" class=yC21><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from umass.edu</span><span class="gs_ggsS">umass.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="https://web.cs.umass.edu/publication/docs/2004/UM-CS-2004-071.pdf" class=yC20>On Hausdorff Distance Measures</a></h3><div class="gs_a">MD Shapiro, <a href="/citations?user=EmmO7LcAAAAJ&amp;hl=en&amp;oi=sra">MB Blaschko</a> - Computer Vision Laboratory University of &hellip;, 2004 - cs.umass.edu</div><div class="gs_rs">ABSTRACT A number of Hausdorff-based algorithms have been proposed for finding <br>objects in images. We evaluate different measures and argue that the Hausdorff Average <br>distance measure outperforms other variants for model detection. This method has <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6515998162331563298&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 6</a> <a href="/scholar?q=related:IvXeLs55bVoJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6515998162331563298&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'IvXeLs55bVoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md14', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md14" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:IvXeLs55bVoJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB15" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW15"><a href="http://orpheus.ee.duth.gr/download/papers/conferences/WEB%20DOCUMENT%20IMAGE%20RETRIEVAL%20SYSTEM%20BASED%20ON%20WORD%20SPOTTING.pdf" class=yC23><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from duth.gr</span><span class="gs_ggsS">duth.gr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4106570" class=yC22>Web document image retrieval system based on word spotting</a></h3><div class="gs_a"><a href="/citations?user=GDAL3kUAAAAJ&amp;hl=en&amp;oi=sra">K Zagoris</a>, <a href="/citations?user=E8a90xYAAAAJ&amp;hl=en&amp;oi=sra">N Papamarkos</a>&hellip; - Image Processing, 2006  &hellip;, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Nowadays, the huge non-indexing quantities of image archives (especially <br>document images) require the development of intelligent tools for their retrieval with <br>convenience comparable of the texts search engines. The proposed technique addresses <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1092700314464260339&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 6</a> <a href="/scholar?q=related:85CZiSUNKg8J:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=1092700314464260339&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'85CZiSUNKg8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/81l6v663305v4670.pdf" class=yC24>A survey of keyword spotting techniques for printed document images</a></h3><div class="gs_a">A Murugappan, B Ramachandran&hellip; - Artificial Intelligence  &hellip;, 2011 - Springer</div><div class="gs_rs">Abstract This paper attempts to provide a survey of the past researches on character based <br>as keyword based approaches used for retrieving information from document images. This <br>survey also provides insights into the strengths and weaknesses of current techniques, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4152659816115326052&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 6</a> <a href="/scholar?q=related:ZMyX3Bk2oTkJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4152659816115326052&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'ZMyX3Bk2oTkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://www.aas.net.cn/qikan/manage/wenzhang/070702.pdf" class=yC26><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aas.net.cn</span><span class="gs_ggsS">aas.net.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.aas.net.cn/qikan/manage/wenzhang/070702.pdf" class=yC25>åºäºåæ¯ç¹å¾ç¹çå¯¼èªç¨å®æ¶å¾åå¹éç®æ³</a></h3><div class="gs_a">å·éªé£ï¼ åå»ºä¸ï¼ çæº - èªå¨åå­¦æ¥, 2007 - aas.net.cn</div><div class="gs_rs">æè¦ä¸ºäºæ»¡è¶³æ¯è±¡å¹éè¾å©å¯¼èªç³»ç»éè¦åæ¶è·åé£è¡å¨ä½ç½®åèªååå·®çéè¦, <br>æåºäºä¸ç§åºäºåæ¯ç¹å¾ç¹æåçå¾åå¹éç®æ³. ä¼ ç»çå¾åå¹éç®æ³éè¦å¨å±æç´¢å¹éç¹å¾ç¹<br>, èæ¶å·¨å¤§, èåªæååæ¯ç¹å¾ç¹æ¥å¹éè½æ»¡è¶³å¯¼èªç³»ç»å®æ¶æ§çè¦æ±. å¨å¹éç®æ³æ¹é¢, æåº<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9663325403171237720&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 16</a> <a href="/scholar?q=related:WK8HdUEHG4YJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9663325403171237720&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'WK8HdUEHG4YJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md17', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md17" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:WK8HdUEHG4YJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/gww5jqp4xvxwrcpm.pdf" class=yC27>Top-down likelihood word image generation model for holistic word recognition</a></h3><div class="gs_a">E Ishidera, <a href="/citations?user=Jz8DDVAAAAAJ&amp;hl=en&amp;oi=sra">S Lucas</a>, A Downton - Document Analysis Systems V, 2002 - Springer</div><div class="gs_rs">This paper describes a new top-down word image generation model for word recognition. <br>This model can generate a word image with a likelihood based on linguistic knowledge, <br>segmentation and character image. In the recognition process, first, the model generates <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3886369100370273978&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 5</a> <a href="/scholar?q=related:uuafHRso7zUJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/18/13/RN118897584.html?source=googlescholar" class="gs_nph" class=yC28>BL Direct</a> <a href="/scholar?cluster=3886369100370273978&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'uuafHRso7zUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB19" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW19"><a href="http://www.eshukan.com/upfiles/jwz/20120518225413637.pdf" class=yC2A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from eshukan.com</span><span class="gs_ggsS">eshukan.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.eshukan.com/upfiles/jwz/20120518225413637.pdf" class=yC29>åºäº JMF çè·¨å¹³å°è§é¢ç¹æ­ç³»ç»çè®¾è®¡ä¸å®ç°</a></h3><div class="gs_a">å¨è´µè³ï¼ æ¹è´µæ - è®¡ç®æºåºç¨ç ç©¶, 2007 - eshukan.com</div><div class="gs_rs">æè¦: å©ç¨Java åªä½æ¡æ¶(JMF) å¼åçè§é¢ç¹æ­ç³»ç»å·æå¼åç®å, è·¨å¹³å°, æä¾QoS <br>ä¿è¯åäº¤äºæ§å¥½ç­ä¼ç¹, å·æå¹¿æ³çåºç¨åæ¯. ä»ç»äºJMF åºç¨ç¼ç¨æ¥å£çç¹ç¹åç»æ, <br>éè¿°äºåºäºJMF å¼åçè·¨å¹³å°çè§é¢ç¹æ­ç³»ç»çæ´ä½ç»æè®¾è®¡, å¹¶è¯¦ç»ä»ç»äºåºäºRTP ç<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2165219698747802907&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 11</a> <a href="/scholar?q=related:G4WKHNhnDB4J:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2165219698747802907&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'G4WKHNhnDB4J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md19', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md19" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:G4WKHNhnDB4J:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB20" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW20"><a href="http://iit.demokritos.gr/~bgat/p55-kesidis.pdf" class=yC2C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from demokritos.gr</span><span class="gs_ggsS">demokritos.gr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1568307" class=yC2B>Accessing the content of greek historical documents</a></h3><div class="gs_a">A Kesidis, E Galiotou, <a href="/citations?user=0bNXadoAAAAJ&amp;hl=en&amp;oi=sra">B Gatos</a>&hellip; - Proceedings of The  &hellip;, 2009 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we propose an alternative method for accessing the content of Greek <br>historical documents printed during the 17th and 18th centuries by searching words directly <br>in digitized documents based on word spotting, without the use of an optical character <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17072784143240431704&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 4</a> <a href="/scholar?q=related:WIjECLm27uwJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17072784143240431704&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'WIjECLm27uwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB21" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW21"><a href="http://nguyendangbinh.org/Proceedings/ICPR/2006/DATA/C02_0319.PDF" class=yC2E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nguyendangbinh.org</span><span class="gs_ggsS">nguyendangbinh.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1699505" class=yC2D>A fast binary-image comparison method with local-dissimilarity quantification</a></h3><div class="gs_a"><a href="/citations?user=ZFkMdjUAAAAJ&amp;hl=en&amp;oi=sra">E Baudrier</a>, G Millon, F Nicolier&hellip; - &hellip;  Recognition, 2006. ICPR &hellip;, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Image similarity measure is widely used in image processing. For binary images <br>that are not composed of a single shape, a local comparison is interesting but the features <br>are usually poor (color) or difficult to extract (texture, forms). We present a new binary <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=3222260220693778079&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 4</a> <a href="/scholar?q=related:nw5TNJnEtywJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3222260220693778079&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'nw5TNJnEtywJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0165011409004072" class=yC2F>The Hausdorff fuzzy quasi-metric</a></h3><div class="gs_a">J RodrÃ­guez-LÃ³pez, S Romaguera&hellip; - Fuzzy Sets and  &hellip;, 2010 - Elsevier</div><div class="gs_rs">Removing the condition of symmetry in the notion of a fuzzy (pseudo) metric, in Kramosil and <br>Michalek&#39;s sense, one has the notion of a fuzzy quasi-(pseudo-) metric. Then for each fuzzy <br>quasi-pseudo-metric on a set X we construct a fuzzy quasi-pseudo-metric on the collection <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=18221873163707586559&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 6</a> <a href="/scholar?q=related:_5cDSRkZ4fwJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18221873163707586559&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'_5cDSRkZ4fwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB23" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW23"><a href="http://www.primaresearch.org/ICDAR2003/Papers/0085_491_lu_y.pdf" class=yC31><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from primaresearch.org</span><span class="gs_ggsS">primaresearch.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1227709" class=yC30>Word searching in CCITT group 4 compressed document images</a></h3><div class="gs_a">Y Lu, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a> - Document Analysis and Recognition, 2003.  &hellip;, 2003 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present a compressed pattern matching method for searching user <br>queried words in the CCITT Group 4 compressed document images, without <br>decompressing. The feature pixels composed of black changing elements and white <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6433486858895235955&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 4</a> <a href="/scholar?q=related:cxuYSzZWSFkJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6433486858895235955&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 26 versions</a> <a onclick="return gs_ocit(event,'cxuYSzZWSFkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB24" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW24"><a href="http://www.mirlab.org/conference_papers/International_Conference/ICME%202004/html/papers/P39231.pdf" class=yC33><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mirlab.org</span><span class="gs_ggsS">mirlab.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1394651" class=yC32>A method and user interface for instructional video indexing via recognition of handwritten table-of-contents words</a></h3><div class="gs_a">L Tang, JR Kender - Multimedia and Expo, 2004. ICME&#39;04.  &hellip;, 2004 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Efficient indexing and retrieval of digital videos are important needs within <br>instructional video databases. We construct a word-based video index by spotting words <br>taken from the table of contents (TOC) of the textbooks for the course given in the video. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9794075290042761368&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 4</a> <a href="/scholar?q=related:mABuxpWL64cJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9794075290042761368&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'mABuxpWL64cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ri"><h3 class="gs_rt"><a href="http://inderscience.metapress.com/index/g04343p28gxv8m74.pdf" class=yC34>Feature string-based intelligent information retrieval from Tamil document images</a></h3><div class="gs_a">S Abirami, D Manjula - International Journal of Computer Applications  &hellip;, 2009 - Inderscience</div><div class="gs_rs">Information Retrieval (IR) in document images has become a growing and challenging <br>problem due to its rising popularity. This paper proposes a simple and effective method to <br>extract the text and perform intelligent IR from Tamil Document Images without Optical <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=808284528493685425&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 4</a> <a href="/scholar?q=related:sWpPBn-aNwsJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=808284528493685425&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'sWpPBn-aNwsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB26" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW26"><a href="http://www.whxb.pku.edu.cn/CN/article/downloadArticleFile.do?attachType=PDF&amp;id=25842" class=yC36><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from pku.edu.cn</span><span class="gs_ggsS">pku.edu.cn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.whxb.pku.edu.cn/CN/article/downloadArticleFile.do?attachType=PDF&amp;id=25842" class=yC35>æ¿ååæ£å°ç ç©¶å¤©è±ç²èç½çèéè¿ç¨</a></h3><div class="gs_a">å´ä¿å¼ºï¼ é©¬æå¥ï¼ å´å¥ - 1995 - whxb.pku.edu.cn</div><div class="gs_rs">æååæååå°¤è¢éææ¯æ©çå¤©å·¦å»¿äºèªä¸»æ°´å¸¦æä¸ä¸åéåº¦K5CN åªå¢åä¸­çæé¼»è¿æ¡Â· K <br>å£C åæ½å å¥ææé«å¤©è±å»¿ä¸»æ°´é¥æ±ä¸­çæçµä½³Â· KSC åæçå£«ånÂ· 5m@ O1 ä¸&quot; 1 æ¶, <br>å¤©è±æ¯å¸¦è¯è¼æ, ç¨ä¸»Â· æ§ç¡ä¸­å¤©äº¢æ­å³åååå¹²ä¸è¯å¥ ä»²å¯ç§æ´»å¼å­å¨Â· ç§é¼»ä»¶ä¸»è±ä¸ç±å°1 <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8827558137621833156&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 5</a> <a href="/scholar?q=related:xOUOE1vJgXoJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8827558137621833156&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'xOUOE1vJgXoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/95624x/200802/26690094.html" class=yC37>åºäºéä¼ ç®æ³çå¯¼èªå®æ¶å¾åå¹éç®æ³</a></h3><div class="gs_a">å·éªé£ï¼ åå»ºä¸ï¼ çæº - éä¿¡å­¦æ¥, 2008 - cqvip.com</div><div class="gs_rs">ç±äºä¸è¬å¾åå¹éç®æ³åéç¨å¨å±æç´¢æ³, èæ¶è¾å¤§, ä¸ºæ»¡è¶³æ¯è±¡å¹éè¾å©å¯¼èªç³»ç»å®æ¶æ§ç<br>è¦æ±, æåºäºä¸ç§å°éä¼ ç®æ³åå æHausdorff è·ç¦»ç®æ³ç¸ç»åçå¾åå¹éç®æ³, <br>å©ç¨éä¼ ç®æ³çééåæç´¢æºå¶, è¿éæ¶æå°å¨å±è¿ä¼¼æä¼è§£, æé«äºå¹éæç´¢çå¿«éæ§. åæ¶<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5070655966400128649&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 6</a> <a href="/scholar?q=related:iaZ-Z7yWXkYJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5070655966400128649&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'iaZ-Z7yWXkYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB28" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW28"><a href="http://nguyendangbinh.org/Proceedings/ICPR/2002/DATA/08_2P_30.PDF" class=yC39><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nguyendangbinh.org</span><span class="gs_ggsS">nguyendangbinh.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1047822" class=yC38>Likelihood word image generation model for word recognition</a></h3><div class="gs_a">E Ishidera, SM Lucast&hellip; - Pattern Recognition, 2002. &hellip;, 2002 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper describes a new word image generation model for word recognition. <br>This model can generate a word image with likelihood based on linguistic knowledge, <br>segmentation and character image. In the recognition process, first, the model generates <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8847265714100339052&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 2</a> <a href="/scholar?q=related:bIFxykrNx3oJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/3B/39/RN126130156.html?source=googlescholar" class="gs_nph" class=yC3A>BL Direct</a> <a href="/scholar?cluster=8847265714100339052&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'bIFxykrNx3oJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB29" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW29"><a href="http://www.arocmag.com/ch/reader/create_pdf.aspx?file_no=200704052&amp;flag=1&amp;journal_id=arocmag" class=yC3C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arocmag.com</span><span class="gs_ggsS">arocmag.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.arocmag.com/ch/reader/create_pdf.aspx?file_no=200704052&amp;flag=1&amp;journal_id=arocmag" class=yC3B>åºäºæ¹è¿çå æ Hausdorff è·ç¦»çå¾åå¹é</a></h3><div class="gs_a">èæ°åï¼ åå²³ - è®¡ç®æºåºç¨ç ç©¶, 2007 - arocmag.com</div><div class="gs_rs">æè¦: æåºäºä¸ç§æ¹è¿çå æHausdorff è·ç¦», å¹¶å°å¶åºç¨äºå­ç¬¦å¾åçå¹é. <br>è¯¥æ¹æ³æ ¹æ®å­ç¬¦å¾åçç»æç¹å¾å¯¹å­ç¬¦ä¸ååºåè®¾ç½®ä¸åçæé. å®è·µè¡¨æè¯¥æ¹æ³æ¹åäºå¾å<br>å¹éææ. å³é®è¯: ç¸ä¼¼æ§åº¦é; Hausdorff è·ç¦»; å¾åå¹éä¸­å¾åç±»å·: TP391. 41 æç®æ å¿ç : <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11609818948822846506&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 3</a> <a href="/scholar?q=related:Kkwvj9JcHqEJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11609818948822846506&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'Kkwvj9JcHqEJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md29', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md29" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:Kkwvj9JcHqEJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB30" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW30"><a href="http://tel.archives-ouvertes.fr/docs/00/05/84/25/PDF/TheseEBaudrier2005.pdf" class=yC3E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://tel.archives-ouvertes.fr/tel-00011570/" class=yC3D>Comparaison d&#39;images binaires reposant sur une mesure locale des dissimilaritÃ©s. Application Ã  la classification.</a></h3><div class="gs_a"><a href="/citations?user=ZFkMdjUAAAAJ&amp;hl=en&amp;oi=sra">E Baudrier</a> - 2005 - tel.archives-ouvertes.fr</div><div class="gs_rs">Lors de la comparaison de deux images, il n&#39;est pas toujours nÃ©cessaire de comparer <br>l&#39;ensemble des Ã©lÃ©ments prÃ©sents dans les images. Par exemple, si la comparaison porte <br>sur les traits grossiers de l&#39;image, il n&#39;est pas utile de conserver une haute dÃ©finition pour l&#39;<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12627266598230521198&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 3</a> <a href="/scholar?q=related:bnWvpxEQPa8J:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12627266598230521198&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'bnWvpxEQPa8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/96983x/20074/24841458.0.html" class=yC3F>ä¸ç§åºäºå³é®è¯çä¸­æææ¡£å¾åæ£ç´¢æ¹æ³</a></h3><div class="gs_a">é»ç¥¥æï¼ é«è¸ï¼ æ¨ä¸½è³ï¼ çé¹é¹ - ä¸­æä¿¡æ¯å­¦æ¥, 2007 - cqvip.com</div><div class="gs_rs">æè¦: æ¬ææåºäºä¸ç§åºäºå³é®è¯çä¸­æææ¡£å¾åæ£ç´¢æ¹æ³, è½å¨ä¸ç»OCR (Optical Character <br>Recognition) è¯å«çæåµä¸, ç´æ¥å©ç¨ä¸­æå­ç¬¦çå¾åç¹å¾è¿è¡å³é®è¯æ£ç´¢. <br>é¦åå°ææ¡£å¾ååå²æåä¸ªä¸­æå­ç¬¦å¾å, æ¥çå¯¹å­ç¬¦å¾åè¿è¡æ±å­ç¬ç»çç¹å¾æ°æ®æå, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8452016989588293914&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 3</a> <a href="/scholar?q=related:Ggn626uYS3UJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8452016989588293914&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'Ggn626uYS3UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5262808" class=yC40>The hausdorff distance template matching algorithm based on kalman filter for target tracking</a></h3><div class="gs_a">F Chang, Z Chen, W Wang&hellip; - Automation and Logistics,  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The Hausdorff distance template matching algorithm is one of the most popular <br>algorithms recently for its robustness to the noise and the occlusion. But if the binary image <br>that has lots of edge pixel points, this algorithm needs a long time to calculate the distance <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6911926017343428891&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 2</a> <a href="/scholar?q=related:GxmJgRcY7F8J:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'GxmJgRcY7F8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:367"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB33" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW33"><a href="http://users.iit.demokritos.gr/~bgat/ICDAR2011_WordRec.pdf" class=yC42><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from demokritos.gr</span><span class="gs_ggsS">demokritos.gr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6065482" class=yC41>Efficient Word Recognition Using a Pixel-Based Dissimilarity Measure</a></h3><div class="gs_a">S Colutto, <a href="/citations?user=0bNXadoAAAAJ&amp;hl=en&amp;oi=sra">B Gatos</a> - Document Analysis and Recognition ( &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose a word recognition methodology based on a novel size-<br>normalization and a pixel-based image dissimilarity measure. As a first step, we apply a new <br>size-normalization technique using baseline estimation. Starting from those size-<b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17946539090594797758&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 1</a> <a href="/scholar?q=related:vpiQ0jfqDvkJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17946539090594797758&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'vpiQ0jfqDvkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:366"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Partial Word Image Matching and Its Applications to Document Image Retrieval</h3><div class="gs_a">Y Lu, <a href="/citations?user=nmFSOaEAAAAJ&amp;hl=en&amp;oi=sra">CL Tan</a></div><div class="gs_fl"><a href="/scholar?q=related:xACIEjuQ0jMJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3734205624431935684&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'xACIEjuQ0jMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:365"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6082896" class=yC43>A novel automatic track identification algorithm based on LTS-Hausdorff distance</a></h3><div class="gs_a">Y Xi-Hui, W Jian, C Bai-gen&hellip; - &hellip;  Systems (ITSC), 2011 14th &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Train locating information is very important for train control system, how to achieve <br>automatic identification of train track occupancy using GNSS simply in some railway sections <br>without track circuits has been a crucial problem. Hausdorff distance can be used to <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:E4OJMBjZA8kJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'E4OJMBjZA8kJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:364"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S1007570410003576" class=yC44>Study on an improved Hausdorff distance for multi-sensor image matching</a></h3><div class="gs_a">J Wu, Z Jing, Z Wu, Y Feng, G Xiao - Communications in Nonlinear Science &hellip;, 2012 - Elsevier</div><div class="gs_rs">A new modifying Hausdorff distance image matching algorithm was proposed in this paper. <br>After the corners of two images was extracted using Harris corner detector, a kind of <br>Hausdorff distance integrating points set coincidence numbers was presented to aim at <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:zvneQFaPDIoJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9947483277572897230&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'zvneQFaPDIoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:363"><div class="gs_ri"><h3 class="gs_rt"><a href="http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=1266186" class=yC45>Multisensor image registration using modified Hausdorff distance matrix metrics</a></h3><div class="gs_a">Q Li, G Qu, X Zhao, Q Yu - Seventh  &hellip;, 2011 - proceedings.spiedigitallibrary.org</div><div class="gs_rs">abstract As to multi-sensor image registration, a novel algorithm for registration synthetic <br>aperture radar (SAR) image to Optical image based on Weight Hausdorff Distance Matrix <br>(WHDM) Metric is proposed in the paper. In the proposed method, edge feature is used for <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:iMKjRXypluMJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16399481444325638792&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'iMKjRXypluMJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md37', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md37" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:iMKjRXypluMJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">Cached</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:362"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB38" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW38"><a href="http://eprints.nbu.bg/310/1/Sjc077.pdf" class=yC47><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nbu.bg</span><span class="gs_ggsS">nbu.bg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://eprints.nbu.bg/310/" class=yC46>Hausdorff distances for searching in binary text images</a></h3><div class="gs_a">A Andreev, N Kirov - Serdica: Journal of Computing, 2009 - eprints.nbu.bg</div><div class="gs_rs">Hausdorff distance (HD) seems the most efficient instrument for measuring how far two <br>compact non-empty subsets of a metric space are from each other. This paper considers the <br>possibilities provided by HD and some of its modifications used recently by many authors <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:_KbRVOE2jnoJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8831056260738688764&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'_KbRVOE2jnoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:361"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB39" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW39"><a href="http://algoval.essex.ac.uk/rep/eiki/ieee03.pdf" class=yC49><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from essex.ac.uk</span><span class="gs_ggsS">essex.ac.uk <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://algoval.essex.ac.uk/rep/eiki/ieee03.pdf" class=yC48>Likelihood Word Image Generation Model for Holistic Word Recognition</a></h3><div class="gs_a">E Ishidera, <a href="/citations?user=Jz8DDVAAAAAJ&amp;hl=en&amp;oi=sra">SM Lucas</a>, AC Downton - algoval.essex.ac.uk</div><div class="gs_rs">Abstract This paper describes a new top-down word image generation model for word <br>recognition. This model can generate a word image with a likelihood based on linguistic <br>knowledge, segmentation and character image. In the recognition process, first, the model <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:84PbWKL27k0J:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5615696962513503219&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'84PbWKL27k0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md39', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md39" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:84PbWKL27k0J:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:360"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0167865508002699" class=yC4A>Weak inclusions and digital spaces</a></h3><div class="gs_a">GD Maio, J RodrÃ­guez-LÃ³pez&hellip; - Pattern Recognition  &hellip;, 2009 - Elsevier</div><div class="gs_rs">The aim of this paper is to establish a new mathematical model for digital spaces. We <br>introduce the concept of weak inclusion. We will show that every digital space can be <br>considered as a space endowed with a weak inclusion. This structure generates a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:r_kDZWJsGZoJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11104025526116022703&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'r_kDZWJsGZoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:359"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB41" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW41"><a href="http://kaitman.free.fr/article/thesis/04293683.pdf" class=yC4C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from free.fr</span><span class="gs_ggsS">free.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4293683" class=yC4B>Profile Based Information Retrieval from Printed Document Images</a></h3><div class="gs_a">S Abirami, D Manjula - Computer Graphics, Imaging and  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper performs a profile based Information Retrieval from printed document <br>image collections. Keywords are valuable indexing tools and if they can be identified at the <br>image level, extensive computation during recognition will be avoided. Printed documents <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:JmPpbB-j6VsJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6623004082391573286&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'JmPpbB-j6VsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:358"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB42" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW42"><a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2830282/" class=yC4E><span class="gs_ggsL"><span class=gs_ctg2>[HTML]</span> from nih.gov</span><span class="gs_ggsS">nih.gov <span class=gs_ctg2>[HTML]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S089561110900130X" class=yC4D>Three-dimensional coupled-object segmentation using symmetry and tissue type information</a></h3><div class="gs_a">PB Bijari, <a href="/citations?user=Y7iC2bcAAAAJ&amp;hl=en&amp;oi=sra">A Akhondi-Asl</a>, <a href="/citations?user=Lc1LZWIAAAAJ&amp;hl=en&amp;oi=sra">H Soltanian-Zadeh</a> - &hellip;  Medical Imaging and  &hellip;, 2010 - Elsevier</div><div class="gs_rs">This paper presents an automatic method for segmentation of brain structures using their <br>symmetry and tissue type information. The proposed method generates segmented <br>structures that have homogenous tissues. It benefits from general symmetry of the brain <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:WDpgepk3ZkAJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4640457598374525528&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'WDpgepk3ZkAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:357"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB43" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW43"><a href="http://www.riunet.upv.es/bitstream/handle/10251/5769/tesisUPV3061.pdf?sequence=1" class=yC50><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from upv.es</span><span class="gs_ggsS">upv.es <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.riunet.upv.es/handle/10251/5769" class=yC4F>Semi-lipschitz functions, best approximation, and fuzzy quasi-metric hyperspaces.</a></h3><div class="gs_a">J SÃNCHEZ ÃLVAREZ - 2009 - riunet.upv.es</div><div class="gs_rs">En los Ãºltimos aÃ±os se ha desarrollado una teorÃ­a matemÃ¡tica que permite generalizar <br>algunas teorÃ­as matemÃ¡ticas clÃ¡sicas: hiperespacios, espacios de funciones, topologÃ­a <br>algebraica, etc. Este hecho viene motivado, en parte, por ciertos problemas de anÃ¡lisis <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:tU7QfrMqtnUJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8482013898614001333&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'tU7QfrMqtnUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:356"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB44" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW44"><a href="http://web2py.iiit.ac.in/research_centres/publications/download/inproceedings.pdf.83cb97826e2a38a1.52616d616e3130546f77617264732e706466.pdf" class=yC52><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from iiit.ac.in</span><span class="gs_ggsS">iiit.ac.in <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1815377" class=yC51>Towards more effective distance functions for word image matching</a></h3><div class="gs_a">R Jain, <a href="/citations?user=U9dH-DoAAAAJ&amp;hl=en&amp;oi=sra">CV Jawahar</a> - Proceedings of the 9th IAPR International  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract Matching word images has many applications in document recognition and retrieval <br>systems. Dynamic Time Warping (DTW) is popularly used to estimate the similarity between <br>word images. Word images are represented as sequences of feature vectors, and the cost <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ug0gg4g6HZEJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10456578267814038970&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'ug0gg4g6HZEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:355"><div class="gs_ri"><h3 class="gs_rt"><a href="http://link.aip.org/link/?APCPCS/1479/864/1" class=yC53>A note on the Hausdorff KM-fuzzy metric</a></h3><div class="gs_a">S Macario, M Sanchis - AIP Conference Proceedings, 2012 - link.aip.org</div><div class="gs_rs">We provide an easy formula for the Hausdorff fuzzy metric (in the sense of Kramosil and <br>Michalek) in the hyperspace [script K](X) of all nonempty compact subsets of a KM-fuzzy <br>metric space (X, M,â). To be precise, we show that the function and if t&gt; 0 defines a KM-<b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'Tbihg1Vr4g0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:354"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Precipitation Nowcasting</h3><div class="gs_a">CM Vossers - 2008</div><div class="gs_fl"><a href="/scholar?q=related:nwDJv2uuSdIJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'nwDJv2uuSdIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:353"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6342150" class=yC54>Research of Similarity Measures for Scene Matching Algorithm</a></h3><div class="gs_a">Z Xia, X Yang, F Meng, S Wang - Engineering and Technology ( &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Similarity measure is the most basic and important element of scene matching <br>algorithm. In this paper, the similarity measures for scene matching are summarized. <br>According to the requirements of scene matching system, the performances of mean <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'AHmAxIK13doJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:352"><div class="gs_ri"><h3 class="gs_rt"><a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=oDwpAvytHEUC&amp;oi=fnd&amp;pg=PA222&amp;ots=PNsfJvjyqr&amp;sig=tAsRBmIoOfyGKwlEdKevOTtUULI" class=yC55>On the Hausdorff Fuzzy Quasi-Metric and Computational Sciences</a></h3><div class="gs_a">J Rodriguez-Lopez, S Rornaguera&hellip; - &hellip;  E-Conference of  &hellip; - books.google.com</div><div class="gs_rs">Abstract: Motivated by its applications to patter recognition, we introduce and study the <br>notion of Hausdorff fuzzy quasi-metric in the sense of Kramosil and Michalek We will <br>develop some of its properties as well as some applications. Keywords: Fuzzy <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'Zq9tx0_5OKsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:351"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB49" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW49"><a href="http://www.researchgate.net/publication/234060965_SRT_12001_Rev_EV/file/79e4150ebd87dd1d25.pdf" class=yC57><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from researchgate.net</span><span class="gs_ggsS">researchgate.net <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://onlinelibrary.wiley.com/doi/10.1111/srt.12001/full" class=yC56>Gray Hausdorff distance measure for medical image comparison in dermatology: Evaluation of treatment effectiveness by image similarity</a></h3><div class="gs_a">P Spyridonos, G Gaitanis, ID Bassukas&hellip; - Skin Research and  &hellip;, 2012 - Wiley Online Library</div><div class="gs_rs">Objectives To quantify, by means of an image similarity metric, the degree of stabilization of <br>an expanding skin disease, and to identify the situation of &#39;no further change&#39;of the skin <br>condition of the patient, providing thus the physician with an early, objective measure of <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'Cf_lzTsROeEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:350"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB50" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW50"><a href="http://www.ceti.gr/~chamzas/chamzas_pdfs/publications/20061010_ICIP.pdf" class=yC59><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ceti.gr</span><span class="gs_ggsS">ceti.gr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ceti.gr/~chamzas/chamzas_pdfs/publications/20061010_ICIP.pdf" class=yC58>Democritus University of Thrace 67100 Xanthi, Greece, papamark (ee. duth. gr</a></h3><div class="gs_a"><a href="/citations?user=GDAL3kUAAAAJ&amp;hl=en&amp;oi=sra">K Zagoris</a>, <a href="/citations?user=E8a90xYAAAAJ&amp;hl=en&amp;oi=sra">N Papamarkos</a>, C Chamzas - ceti.gr</div><div class="gs_rs">ABSTRACT Nowadays, the huge non-indexing quantities of image archives (especially <br>document images) require the development of intelligent tools for their retrieval with <br>convenience comparable of the texts search engines. The proposed technique addresses <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:5OAn0WmGKDsJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4262804836344914148&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'5OAn0WmGKDsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md50', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md50" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:5OAn0WmGKDsJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:349"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB51" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW51"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.99.3561&amp;rep=rep1&amp;type=pdf" class=yC5B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.99.3561&amp;rep=rep1&amp;type=pdf" class=yC5A>Wavelets and word image matching</a></h3><div class="gs_a">E Kelevedjiev, A Andreev - Review of the national center for digitization, 2006 - Citeseer</div><div class="gs_rs">Abstract: An approach to word image matching (WIM) based on wavelet transform (WT) is <br>examined. A detailed computer experiments was carried out with respect to the type of <br>wavelet filters, types of the wavelet bases used, the best suited frequency band and <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:qhUb2HW5r-wJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17055054229663323562&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'qhUb2HW5r-wJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md51', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md51" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:qhUb2HW5r-wJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:348"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5430251" class=yC5C>Computation of discrete FrÃ©chet distance using CNN</a></h3><div class="gs_a">S Yoon, HM Yoo, SH Yang&hellip; - &hellip;  Nanoscale Networks and  &hellip;, 2010 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The discrete Frechet distance basically measures the similarity of two curves <br>considering their paths as well as distances of all discrete points on two curves. The present <br>algorithms to compute the discrete Frechet distance between two curves have very high <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:jGFH4_9Ei7sJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'jGFH4_9Ei7sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:347"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB53" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW53"><a href="http://iit.demokritos.gr/~bgat/setn2006.pdf" class=yC5E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from demokritos.gr</span><span class="gs_ggsS">demokritos.gr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/W118R16242388LR2.pdf" class=yC5D>A holistic methodology for keyword search in historical typewritten documents</a></h3><div class="gs_a"><a href="/citations?user=0bNXadoAAAAJ&amp;hl=en&amp;oi=sra">B Gatos</a>, T Konidaris, <a href="/citations?user=lCVokogAAAAJ&amp;hl=en&amp;oi=sra">I Pratikakis</a>&hellip; - Advances in Artificial  &hellip;, 2006 - Springer</div><div class="gs_rs">Abstract. In this paper, we propose a novel holistic methodology for keyword search in <br>historical typewritten documents combining synthetic data and user&#39;s feedback. The holistic <br>approach treats the word as a single entity and entails the recognition of the whole word <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:aQny47gVlpIJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/44/1C/RN188845458.html?source=googlescholar" class="gs_nph" class=yC5F>BL Direct</a> <a href="/scholar?cluster=10562653859886532969&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'aQny47gVlpIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:346"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4530002" class=yC60>Indexing by recognition approach for printed Arabic documents images</a></h3><div class="gs_a">MA Klaa, S Touj, NE Ben Amara - &hellip;  Technologies: From Theory  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract We propose in this paper an indexing by recognition approach applied to Arabic <br>printed documents images archives. Indeed, our goal is to restore the set of the images <br>susceptible to contain the key word or all the key words introduced by the user as a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:UuOV5QTNgPwJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'UuOV5QTNgPwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:345"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB55" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW55"><a href="http://poseidon.csd.auth.gr/papers/PUBLISHED/JOURNAL/pdf/Tsapanos11a.pdf" class=yC62><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from auth.gr</span><span class="gs_ggsS">auth.gr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0031320311004791" class=yC61>Shape matching using a binary search tree structure of weak classifiers</a></h3><div class="gs_a">N Tsapanos, <a href="/citations?user=4stOS3YAAAAJ&amp;hl=en&amp;oi=sra">A Tefas</a>, N Nikolaidis, <a href="/citations?user=lWmGADwAAAAJ&amp;hl=en&amp;oi=sra">I Pitas</a> - Pattern Recognition, 2011 - Elsevier</div><div class="gs_rs">In this paper, a novel algorithm for shape matching based on the Hausdorff distance and a <br>binary search tree data structure is proposed. The shapes are stored in a binary search tree <br>that can be traversed according to a Hausdorff-like similarity measure that allows us to <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12579282988498367520&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=65">Cited by 2</a> <a href="/scholar?q=related:IDSP6jqXkq4J:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12579282988498367520&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'IDSP6jqXkq4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:344"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Semantic content analysis and user interfaces for instructional video indexing</h3><div class="gs_a">L Tang - 2006 - Columbia University</div><div class="gs_fl"><a href="/scholar?q=related:DDLe6g1HMwoJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=735009289292100108&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'DDLe6g1HMwoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md56', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md56" class="gs_md_wn" style="display:none">  <a href="/scholar?q=info:DDLe6g1HMwoJ:scholar.google.com/&amp;output=instlink&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5&amp;scillfp=12114457881055637379&amp;oi=llo" class="gs_md_li">Library Search</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:343"><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctu"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> Semantic Content Analysis for Instructional Videos Via Text and Handwriting Spotting</h3><div class="gs_a">L Tang</div><div class="gs_fl"><a href="/scholar?q=related:MCyr9IKdFw4J:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'MCyr9IKdFw4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:342"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB58" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW58"><a href="http://www.ceaj.org/Jweb_gcyyy/EN/article/downloadArticleFile.do?attachType=PDF&amp;id=27844" class=yC64><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ceaj.org</span><span class="gs_ggsS">ceaj.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.ceaj.org/Jweb_gcyyy/EN/article/downloadArticleFile.do?attachType=PDF&amp;id=27844" class=yC63>2 ç§åå¤è½®å»å æçäººè³æ£æµç®æ³</a></h3><div class="gs_a">é·æ¾æ³½ï¼ å§çº¢é©ï¼ é½æï¼ ééé³ - Computer Engineering and Applications, 2009 - ceaj.org</div><div class="gs_rs">æè¦: ä¸ºäºæé«äººè³æ£æµä¸­å¾åå¹éçç²¾ç¡®æ§, æåºå¯¹åå¤è³è½®å»å æ, å¹¶å©ç¨Hausdorff <br>è·ç¦»è¿è¡äººè³æ£æµçç®æ³, å¨ä¼ ç»çHausdorff è·ç¦»å¹éä¸­, å¾åå¦æååªå£°å¹²æ°æè¾¹ç¼ä¸è¿ç»­ç­<br>æåµ, æ£æµç»æä¸çæ³, å æ­¤ä¸ºä½¿æ£æµä½ç½®æ´å æ¥è¿å¤è³è½®å», éè¦å¼ºè°å¤è³è½®å»çä½ç¨, è¿<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:wHfgYLZWSJUJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'wHfgYLZWSJUJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md58', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md58" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:wHfgYLZWSJUJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:341"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB59" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW59"><a href="http://hal.inria.fr/docs/00/11/35/95/PDF/000Corps.pdf" class=yC66><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from inria.fr</span><span class="gs_ggsS">inria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://hal.inria.fr/hal-00113595/" class=yC65>Une mÃ©thode de comparaison d&#39;images binaires quantifiant les dissimilaritÃ©s locales Application Ã  la classification d&#39;impressions anciennes</a></h3><div class="gs_a"><a href="/citations?user=ZFkMdjUAAAAJ&amp;hl=en&amp;oi=sra">E Baudrier</a>, G Millon, F Nicolier, S Ruan - &hellip;  Francophone sur l&#39;Ecrit et le  &hellip;, 2006 - hal.inria.fr</div><div class="gs_rs">RÃ©sumÃ©: La comparaison d&#39;images est largement utilisÃ©es en traitement d&#39;image. Pour les <br>images binaires qui ne sont pas composÃ©es de simples formes, une comparaison locale <br>peut Ãªtre intÃ©ressante car l&#39;extraction de formes est souvent dÃ©licate et les attributs <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:74iSYnA3xToJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4234851980441454831&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'74iSYnA3xToJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:340"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/91690x/200930/31892558.html" class=yC67>ä¸ç§åå¤è½®å»å æçäººè³æ£æµç®æ³</a></h3><div class="gs_a">é·æ¾æ³½ï¼ å§çº¢é©ï¼ é½æï¼ ééé³ - è®¡ç®æºå·¥ç¨ä¸åºç¨, 2009 - cqvip.com</div><div class="gs_rs">ä¸ºäºæé«äººè³æ£æµä¸­å¾åå¹éçç²¾ç¡®æ§, æåºå¯¹åå¤è³è½®å»å æ, å¹¶å©ç¨Hausdorff <br>è·ç¦»è¿è¡äººè³æ£æµçç®æ³. å¨ä¼ ç»çHausdorff è·ç¦»å¹éä¸­, å¾åå¦æååªå£°å¹²æ°æè¾¹ç¼ä¸è¿ç»­ç­<br>æåµ, æ£æµç»æä¸çæ³. å æ­¤ä¸ºä½¿æ£æµä½ç½®æ´å æ¥è¿å¤è³è½®å», éè¦å¼ºè°å¤è³è½®å»çä½ç¨, è¿<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:hrF2nw1df78J:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'hrF2nw1df78J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:339"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.dbpia.co.kr/view/ar_view.asp?arid=1618404" class=yC68>Hand Gesture Recognition Using Neural Network</a></h3><div class="gs_a">EJ Lee - 2007 ëë ì¶ê³íì ë°íë¼ë¬¸ì§, 582~ 585 ìª½ (ì´ 4 ìª½), 2007 - dbpia.co.kr</div><div class="gs_rs">In this paper, we present an algorithm which detects human hand by skin color information <br>in YCbCr and HIS color model. And for confirming special human hand we use circle rate of <br>region to detect hand region because human hand have complex edge than other region, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:lmRHxkheBRkJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'lmRHxkheBRkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:338"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB62" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW62"><a href="http://etienne.baudrier.free.fr/cifed06Baudrier.pdf" class=yC6A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from free.fr</span><span class="gs_ggsS">free.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://etienne.baudrier.free.fr/cifed06Baudrier.pdf" class=yC69>Une mÃ©thode de comparison d&#39;images binaires quantifiant les dissimilaritÃ©s locales Application Ã  la classification d&#39;impressions anciennes</a></h3><div class="gs_a">ÃBGMF Nicolier, S Ruan - etienne.baudrier.free.fr</div><div class="gs_rs">RÃ©sumÃ©: La comparaison d&#39;images est largement utilisÃ©es en traitement d&#39;image. Pour les <br>images binaires qui ne sont pas composÃ©es de simples formes, une comparaison locale <br>peut Ãªtre intÃ©ressante car l&#39;extraction de formes est souvent dÃ©licate et les attributs <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:CW1e8SuHGFgJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6347972297581554953&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'CW1e8SuHGFgJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md62', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md62" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:CW1e8SuHGFgJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:337"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.cqvip.com/qk/90752a/201006/36604486.html" class=yC6B>åè½¦è½¨éå ç¨èªå¨è¯å«ç®æ³</a></h3><div class="gs_a">è¡ä¼¯æ ¹ï¼ ä¸¥ç»è¾ï¼ çåï¼ ä¸å®ä¼ - äº¤éè¿è¾å·¥ç¨å­¦æ¥, 2011 - cqvip.com</div><div class="gs_rs">ä¸ºè§£å³åè½¦å¨éå²åå¹³è¡è¡éåºæ®µçè½¨éå ç¨èªå¨è¯å«é®é¢, åºäºLTS-Hausdorff è·ç¦», ç»åDS <br>è¯æ®çè®º, æåºäºä¸ç§æ°çåè½¦è½¨éå ç¨èªå¨è¯å«ç®æ³, å»ºç«äºå¯ç¨äºåè½¦è½¨éå ç¨èªå¨è¯å«ç<br>è½¨éLTS-Hausdorff è·ç¦»åèæ¨¡æ¿, åæäºLTS-Hausdorff è·ç¦»çè®¡ç®è¿ç¨åè½¨éå ç¨èªå¨<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:t0zY8l4z70AJ:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4679015020755438775&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'t0zY8l4z70AJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:336"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB64" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW64"><a href="http://www.setit.rnu.tn/last_edition/setit2009/Image%20and%20Video/52.pdf" class=yC6D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from setit.rnu.tn</span><span class="gs_ggsS">setit.rnu.tn <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.setit.rnu.tn/last_edition/setit2009/Image%20and%20Video/52.pdf" class=yC6C>Module d&#39;Indexation par Reconnaissance des Images de Documents Arabes ImprimÃ©s</a></h3><div class="gs_a">MA KLAA, T Soufien, NEBEN AMARA - setit.rnu.tn</div><div class="gs_rs">RÃ©sumÃ©: Nous proposons dans ce papier un module d&#39;indexation des images de <br>documents arabes imprimÃ©s par reconnaissance. En effet, la tendance actuelle est <br>d&#39;augmenter et de diversifier les tests sur le module d&#39;indexation que nous avons <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:3QH08vIMKg0J:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'3QH08vIMKg0J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md64', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md64" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:3QH08vIMKg0J:scholar.google.com/&amp;hl=en&amp;num=65&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
