<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB100" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW100"><a href="http://137.132.145.151/lms/sites/default/files/publication-attachments/tour-pattern-TIST-final.pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 137.132.145.151</span><span class="gs_ggsS">137.132.145.151 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2168770" class=yC0>Mining Travel Patterns from Geotagged Photos</a></h3><div class="gs_a">YT Zheng, ZJ Zha, TS Chua - ACM Transactions on Intelligent Systems  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract Recently, the phenomenal advent of photo-sharing services, such as Flickr and <br>Panoramio, have led to volumous community-contributed photos with text tags, timestamps, <br>and geographic references on the Internet. The photos, together with their time-and geo-<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:KJZndCcP9wwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=934232109833754152&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'KJZndCcP9wwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB101" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW101"><a href="http://pages.cs.wisc.edu/~mlenz/socialtourism/social_tourism.pdf" class=yC3><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from wisc.edu</span><span class="gs_ggsS">wisc.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://pages.cs.wisc.edu/~mlenz/socialtourism/social_tourism.pdf" class=yC2>Social Tourism Using Photos</a></h3><div class="gs_a">M Lenz - pages.cs.wisc.edu</div><div class="gs_rs">Abstract Mobile phones are frequently used to determine one&#39;s location and navigation <br>directions, and they can also provide a platform for connecting tourists with each other. This <br>paper proposes a system that uses a set of geotagged photos to automatically compute <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:AmUod8qSTt4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'AmUod8qSTt4J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md101', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md101" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:AmUod8qSTt4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0165168412002204" class=yC4>Multimedia encyclopedia construction by mining web knowledge</a></h3><div class="gs_a"><a href="/citations?user=-ReoUxUAAAAJ&amp;hl=en&amp;oi=sra">R Hong</a>, ZJ Zha, Y Gao, TS Chua, X Wu - Signal Processing, 2012 - Elsevier</div><div class="gs_rs">Abstract In recent years, we have witnessed the blooming of Web 2.0 content such as <br>Wikipedia, Flickr and YouTube, etc. How might we benefit from such rich media resources <br>available on the internet? This paper presents a novel concept called Mediapedia, a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:-PXgd9tRpOoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'-PXgd9tRpOoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5992597" class=yC5>From Web Mining to Social Multimedia Mining</a></h3><div class="gs_a">G Lappas - Advances in Social Networks Analysis and Mining ( &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Web mining is a well established field with many applications. Over the last years <br>we experience a vast and rapidly growing amount of multimedia content that becomes <br>available online. Web 2.0 and online social networks have dramatically influenced the <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13388176403906102811&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:GwYXeYFbzLkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13388176403906102811&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'GwYXeYFbzLkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB104" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW104"><a href="http://www.cs.utoronto.ca/~jasper/videos2places.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from utoronto.ca</span><span class="gs_ggsS">utoronto.ca <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6137466" class=yC6>From Videos to Places: Geolocating the World&#39;s Videos</a></h3><div class="gs_a">J Snoek, <a href="/citations?user=fKBmhcUAAAAJ&amp;hl=en&amp;oi=sra">L Sbaiz</a>, <a href="/citations?user=2EaTkYEAAAAJ&amp;hl=en&amp;oi=sra">H Aradhye</a> - Data Mining Workshops (ICDMW &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper explores the problem of large-scale automatic video geolocation. A <br>methodology is developed to infer the location at which videos from Anonymized. com were <br>recorded using video content and various additional signals. Specifically, multiple binary <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:q-oZfxSli-cJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16684610751974468267&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'q-oZfxSli-cJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB105" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW105"><a href="http://bird1.murase.m.is.nagoya-u.ac.jp/publications/967-pdf.pdf" class=yC9><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nagoya-u.ac.jp</span><span class="gs_ggsS">nagoya-u.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/X765615805824638.pdf" class=yC8>Construction of a Local Attraction Map According to Social Visual Attention</a></h3><div class="gs_a"><a href="/citations?user=8PXJm98AAAAJ&amp;hl=en&amp;oi=sra">I Ide</a>, J Wang, M Noda, <a href="/citations?user=ne-WQc4AAAAJ&amp;hl=en&amp;oi=sra">T Takahashi</a>, D Deguchi&hellip; - &hellip; : Systems and Services, 2012 - Springer</div><div class="gs_rs">Social media on the Internet where millions of people share their personal experiences, can <br>be considered as an information source that implies people&#39;s implicit and/or explicit visual <br>attentions. Especially, when the attentions of many people around a specific geographic <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:vxcljEe9opcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10926503760945813439&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'vxcljEe9opcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0923596512001099" class=yCA>Learning from mobile contexts to minimize the mobile location search latency</a></h3><div class="gs_a">LY Duan, <a href="/citations?user=lRSD7PQAAAAJ&amp;hl=en&amp;oi=sra">R Ji</a>, J Chen, H Yao, <a href="/citations?user=knvEK4AAAAAJ&amp;hl=en&amp;oi=sra">T Huang</a>&hellip; - Signal Processing: Image  &hellip;, 2012 - Elsevier</div><div class="gs_rs">Abstract We propose to learn an extremely compact visual descriptor from the mobile <br>contexts towards low bit rate mobile location search. Our scheme combines location related <br>side information from the mobile devices to adaptively supervise the compact visual <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ar9yjU24qIcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'ar9yjU24qIcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB107" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW107"><a href="http://www.tapironline.no/last-ned/348" class=yCC><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from tapironline.no</span><span class="gs_ggsS">tapironline.no <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://www.tapironline.no/last-ned/348" class=yCB>Towards calibration-free geo-localization of stationary outdoor webcams</a></h3><div class="gs_a"><a href="/citations?user=N9OuegkAAAAJ&amp;hl=en&amp;oi=sra">FE Sandnes</a> - Norsk informatikkonferanse (NIK), 2010 - tapironline.no</div><div class="gs_rs">Abstract This study proposes two strategies for determining the approximate geographical <br>location of outdoor webcams based on time-series comprising regularly sampled images. <br>The strategies require an accurate account of universal time and the date to be known, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:QwJalivFragJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12154587760339583555&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'QwJalivFragJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md107', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md107" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:QwJalivFragJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1992057" class=yCD>Landmark recognition in VISITO: VIsual Support to Interactive TOurism in Tuscany</a></h3><div class="gs_a">G Amato, P Bolettieri, <a href="/citations?user=4Vr1dSQAAAAJ&amp;hl=en&amp;oi=sra">F Falchi</a> - Proceedings of the 1st ACM International  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract We present the VIsual Support to Interactive TOurism in Tuscany (VISITO Tuscany) <br>project which offers an interactive guide for tourists visiting cities of art accessible via <br>smartphones. The peculiarity of the system is that user interaction is mainly obtained by <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:W0SPl3P4MYkJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'W0SPl3P4MYkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6116033" class=yCE>A discriminative learning technique for mobile landmark recognition</a></h3><div class="gs_a"><a href="/citations?user=w3OoFL0AAAAJ&amp;hl=en&amp;oi=sra">T Chen</a>, <a href="/citations?user=nr86m98AAAAJ&amp;hl=en&amp;oi=sra">KH Yap</a>, <a href="/citations?user=MYREIH0AAAAJ&amp;hl=en&amp;oi=sra">LP Chau</a> - Image Processing (ICIP), 2011  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract This paper proposes a discriminative learning bags-of-words (BoW) approach for <br>mobile landmark recognition at patch and image levels. Conventional methods often treat <br>the local patches and images equally important for recognition and do not differentiate <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:BJV-mRSyhPUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'BJV-mRSyhPUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.sciencedirect.com/science/article/pii/S0925231212001683" class=yCF>Looking into the world on Google Maps with view direction estimated photos</a></h3><div class="gs_a">H Li, <a href="/citations?user=ByBLlEwAAAAJ&amp;hl=en&amp;oi=sra">J Tang</a>, Y Wang, B Liu - Neurocomputing, 2012 - Elsevier</div><div class="gs_rs">In this paper, we present a novel system, named ViewFocus, to explore the world on Google <br>Maps by leveraging and mining the large amount of user-uploaded geo-tagged photos. <br>Compared with current available online geolocation-oriented photo exploring websites, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:ZBmNnXzfdnwJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8968601434267130212&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'ZBmNnXzfdnwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5972551" class=yC10>Detecting the long-tail of Points of Interest in tagged photo collections</a></h3><div class="gs_a">C Zigkolis, <a href="/citations?user=GuhyORoAAAAJ&amp;hl=en&amp;oi=sra">S Papadopoulos</a>&hellip; - &hellip;  (CBMI), 2011 9th  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The paper tackles the problem of matching the photos of a tagged photo collection <br>to a list of âlong-tailâ Points Of Interest (PoIs), that is PoIs that are not very popular and thus <br>not well represented in the photo collection. Despite the significance of improving âlong-<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:6ABEnrHG4eoJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'6ABEnrHG4eoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB112" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW112"><a href="http://dspace.thapar.edu:8080/dspace/bitstream/10266/1394/1/ashish_800932005.pdf" class=yC12><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from thapar.edu</span><span class="gs_ggsS">thapar.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dspace.thapar.edu:8080/dspace/handle/10266/1394" class=yC11>Image Retrieval using SURF Features</a></h3><div class="gs_a">A Kumar, <a href="/citations?user=pidH2oYAAAAJ&amp;hl=en&amp;oi=sra">S Batra</a> - 2011 - dspace.thapar.edu</div><div class="gs_rs">Abstract: Modern technology has made image capturing cameras ubiquitous and increased <br>accessibility to the Internet and Internet based services and soaring popularity of social <br>networking sites for sharing pictures has resulted in large amount of images being shared <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4453157700150589391&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 1</a> <a href="/scholar?q=related:z3dFnlXLzD0J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'z3dFnlXLzD0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6166619" class=yC13>Geolocation based image annotation</a></h3><div class="gs_a">A Shimada, H Nagahara, R Taniguchi&hellip; - &hellip;  (ACPR), 2011 First  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The growth of photo-sharing website such as Flickr and Picasa enables us to <br>access the billions of images easily. Recent years, many researchers leverage such photo-<br>sharing site to tackle the image annotation problem. The aim of the image annotation is to <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:wt1Qno36lkMJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'wt1Qno36lkMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/X54532872628U566.pdf" class=yC14>Architectural Style Classification of Domes</a></h3><div class="gs_a">G Shalunts, <a href="/citations?user=3SzlfM0AAAAJ&amp;hl=en&amp;oi=sra">Y Haxhimusa</a>, R Sablatnig - Advances in Visual Computing, 2012 - Springer</div><div class="gs_rs">Domes are architectural structural elements characteristic for ecclesiastical and secular <br>monumental buildings, like churches, basilicas, mosques, capitols and city halls. In the <br>scope of building facade architectural style classification the current paper addresses the <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:gx9hq4WZtXQJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'gx9hq4WZtXQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB115" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW115"><a href="http://www.ojs.academypublisher.com/index.php/jsw/article/viewFile/jsw0704749756/4720" class=yC16><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from academypublisher.com</span><span class="gs_ggsS">academypublisher.com <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.ojs.academypublisher.com/index.php/jsw/article/view/jsw0704749756" class=yC15>Mining Large-Scale Social Images with Rich Metadata and Its Application</a></h3><div class="gs_a">Z Liu, H Yan, H Han - Journal of Software, 2012 - ojs.academypublisher.com</div><div class="gs_rs">Abstract In this paper, we study on how to automatically mine landmarks from large-scale <br>social images with rich metadata. Firstly, location name is submitted to social image <br>community, and then related social images with rich metadata are obtained. Afterwards, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:450FraFjn3oJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8835890539967913443&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'450FraFjn3oJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB116" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW116"><a href="http://madm.dfki.de/_media/theses/sebastian_thesis.pdf" class=yC18><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from dfki.de</span><span class="gs_ggsS">dfki.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://madm.dfki.de/_media/theses/sebastian_thesis.pdf" class=yC17>Evaluation of Parameter Influence and Dimensionality Reduction for CBIR Systems using Local Features, TF-IDF and Inverted Files</a></h3><div class="gs_a">S Palacio - 2010 - madm.dfki.de</div><div class="gs_rs">2 Background Theory 5 2.1 Image Features................................. 5 2.2 Local <br>Features................................. 7 2.3 Invariant Features............................... 7 2.4 Distance <br>Measures............................... 8 2.5 Theory and Algorithms............................ 9 2.5. 1 <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:DhkWrd7WCPsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18088944155208587534&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'DhkWrd7WCPsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md116', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md116" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:DhkWrd7WCPsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB117" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW117"><a href="http://infoscience.epfl.ch/record/149446/files/article.pdf?version=1" class=yC1A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from epfl.ch</span><span class="gs_ggsS">epfl.ch <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://spiedigitallibrary.org/proceeding.aspx?articleid=754647" class=yC19>Propagation of geotags based on object duplicate detection</a></h3><div class="gs_a">P Vajda, I Ivanov, JS Lee, L Goldmann&hellip; - SPIE Optical  &hellip;, 2010 - spiedigitallibrary.org</div><div class="gs_rs">abstract In this paper, we consider the use of object duplicate detection for the propagation <br>of geotags from a small set of images with location names (IPTC) to a large set of non-<br>tagged images. The motivation behind this idea is that images of individual locations <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:0OYwr0VCzOAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16198394826804225744&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'0OYwr0VCzOAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB118" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW118"><a href="http://gvv.mpi-inf.mpg.de/files/ECCV2012/MainPaper.pdf" class=yC1C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mpg.de</span><span class="gs_ggsS">mpg.de <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://gvv.mpi-inf.mpg.de/files/ECCV2012/MainPaper.pdf" class=yC1B>Match Graph Construction for Large Image Databases</a></h3><div class="gs_a">KI Kim, J Tompkin, M Theobald, J Kautz, <a href="/citations?user=eIWg8NMAAAAJ&amp;hl=en&amp;oi=sra">C Theobalt</a> - gvv.mpi-inf.mpg.de</div><div class="gs_rs">Abstract. How best to efficiently establish correspondence among a large set of images or <br>video frames is an interesting unanswered question. For large databases, the high <br>computational cost of performing pair-wise image matching is a major problem. However, <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:mtTrr6ttDcsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=14631471348554912922&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'mtTrr6ttDcsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md118', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md118" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:mtTrr6ttDcsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/268N7170565GP005.pdf" class=yC1D>Segmentation of Building Facade Domes</a></h3><div class="gs_a">G Shalunts, <a href="/citations?user=3SzlfM0AAAAJ&amp;hl=en&amp;oi=sra">Y Haxhimusa</a>, R Sablatnig - Progress in Pattern Recognition,  &hellip;, 2012 - Springer</div><div class="gs_rs">Domes are architectural structural elements typical for ecclesiastical and secular grand <br>buildings, like churches, mosques, palaces, capitols and city halls. The current paper targets <br>the problem of segmentation of domes within the framework of architectural style <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:7L49t-rmgA8J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'7L49t-rmgA8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB120" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW120"><a href="http://arxiv.org/pdf/1207.7244" class=yC1F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from arxiv.org</span><span class="gs_ggsS">arxiv.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://arxiv.org/abs/1207.7244" class=yC1E>Visual Vocabulary Learning and Its Application to 3D and Mobile Visual Search</a></h3><div class="gs_a">L Cao - arXiv preprint arXiv:1207.7244, 2012 - arxiv.org</div><div class="gs_rs">Abstract: In this technical report, we review related works and recent trends in visual <br>vocabulary based web image search, object recognition, mobile visual search, and 3D <br>object retrieval. Especial focuses would be also given for the recent trends in supervised/<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:E6aIwLQgnuAJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=16185410071512524307&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'E6aIwLQgnuAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB121" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW121"><a href="http://doras.dcu.ie/16134/1/Investigation_of_Image_Models_for_Landmark_Classification.pdf" class=yC21><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from dcu.ie</span><span class="gs_ggsS">dcu.ie <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5381705" class=yC20>Investigation of Image Models for Landmark Classification</a></h3><div class="gs_a">M Hughes, <a href="/citations?user=YJuN_H8AAAAJ&amp;hl=en&amp;oi=sra">GJF Jones</a>&hellip; - &hellip;  Media Adaptation and  &hellip;, 2009 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract One commonly used approach to scene localization and landmark recognition is to <br>match an input image against a large annotated database of images using local image <br>features. However problems exist with these approaches relating to memory constraints <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:h0nqxEILyksJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5461189879539583367&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'h0nqxEILyksJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/RMWM742188X2556H.pdf" class=yC22>Size Matters: Exhaustive Geometric Verification for Image Retrieval Accepted for ECCV 2012</a></h3><div class="gs_a"><a href="/citations?user=2cn46OkAAAAJ&amp;hl=en&amp;oi=sra">H StewÃ©nius</a>, S Gunderson, J Pilet - Computer VisionâECCV 2012, 2012 - Springer</div><div class="gs_rs">The overreaching goals in large-scale image retrieval are bigger, better and cheaper. For <br>systems based on local features we show how to get both efficient geometric verification of <br>every match and unprecedented speed for the low sparsity situation. Large-scale systems <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'XyO3yvIBo34J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2396472" class=yC23>Searching for diversified landmarks by photo</a></h3><div class="gs_a">J Ye, J Chen, Z Chen, Y Zhu, S Bao, Z Su&hellip; - Proceedings of the 20th  &hellip;, 2012 - dl.acm.org</div><div class="gs_rs">Abstract This demo focuses on the problem of searching for diversified landmarks with <br>photos as input. More particularly, we propose a system called DLMSearch that allows a <br>user to upload a photo as a query and searches for a diverse set of relevant landmarks in <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'ucxjzun46U8J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB124" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW124"><a href="http://cs229.stanford.edu/proj2009/ZhangWang.pdf" class=yC25><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from stanford.edu</span><span class="gs_ggsS">stanford.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://cs229.stanford.edu/proj2009/ZhangWang.pdf" class=yC24>Automatic Ranking of Images on the Web</a></h3><div class="gs_a">HH Zhang, Z Wang - cs229.stanford.edu</div><div class="gs_rs">Abstract We propose a new way to automatically find representative images of a specified <br>object category. Given a large collection of images returned by a web search for an object <br>category, our approach learns the similarities among images without any user help. We <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:m3i_z_4Wb0MJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4859127806618990747&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'m3i_z_4Wb0MJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md124', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md124" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:m3i_z_4Wb0MJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2037688" class=yC26>Mining flickr landmarks by modeling reconstruction sparsity</a></h3><div class="gs_a"><a href="/citations?user=lRSD7PQAAAAJ&amp;hl=en&amp;oi=sra">R Ji</a>, Y Gao, B Zhong, H Yao, <a href="/citations?user=61b6eYkAAAAJ&amp;hl=en&amp;oi=sra">Q Tian</a> - ACM Transactions on Multimedia  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract In recent years, there have been ever-growing geographical tagged photos on the <br>community Web sites such as Flickr. Discovering touristic landmarks from these photos can <br>help us to make better sense of our visual world. In this article, we report our work on <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=10285706148000429334&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=100">Cited by 3</a> <a href="/scholar?q=related:FvWd3z4rvo4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=10285706148000429334&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'FvWd3z4rvo4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB126" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW126"><a href="https://oda.hio.no/jspui/bitstream/10642/514/2/543487post.pdf" class=yC28><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from hio.no</span><span class="gs_ggsS">hio.no <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/K807K33285G4T0P5.pdf" class=yC27>An energy efficient localization strategy for outdoor objects based on intelligent light-intensity sampling</a></h3><div class="gs_a"><a href="/citations?user=N9OuegkAAAAJ&amp;hl=en&amp;oi=sra">F Sandnes</a> - Ubiquitous Intelligence and Computing, 2010 - Springer</div><div class="gs_rs">A simple and low cost strategy for implementing pervasive objects that identify and track <br>their own geographical location is proposed. The strategy, which is not reliant on any GIS <br>infrastructure such as GPS, is realized using an electronic artifact with a built in clock, a <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:TYbx6CXNTHsJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8884701727600772685&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'TYbx6CXNTHsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6305823" class=yC29>Location-Based Large-Scale Landmark Image Recognition Scheme for Mobile Devices</a></h3><div class="gs_a">D Kim, E Hwang, S Rho - Mobile, Ubiquitous, and Intelligent  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose a location-based large-scale landmark image recognition <br>scheme for mobile devices such as smart phones. To achieve this goal, we collected <br>landmark images all around the world, which were available on the web. For each <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:uj7I7VUWq_EJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'uj7I7VUWq_EJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB128" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW128"><a href="http://scholarbank.nus.edu/bitstream/handle/10635/31626/ZhangDX.pdf?sequence=1" class=yC2B><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu</span><span class="gs_ggsS">nus.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://scholarbank.nus.edu/handle/10635/31626" class=yC2A>Efficient location-based spatial keyword query processing</a></h3><div class="gs_a">Z DONGXIANG - 2011 - scholarbank.nus.edu</div><div class="gs_rs">The emergence of Web $2.0 $ applications, including social networking sites, wikipedia and <br>multimedia sharing sites, has changed the way of how information is generated and shared. <br>Among these applications, map mashup is a popular and convenient means for data <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:2jHk8pyZ734J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9146698267581755866&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'2jHk8pyZ734J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.scientific.net/AMM.182-183.854" class=yC2C>Mobile Tour Planning Using Landmark Photo Matching and Intelligent Character Recognition</a></h3><div class="gs_a">CM Huang, WH Liao, SC Chen - Applied Mechanics and Materials, 2012 - Trans Tech Publ</div><div class="gs_rs">Abstract The functionalities of smart phones have extended from basic voice communication <br>to gaming, multimedia entertainment, information retrieval and location-based services. In <br>this paper, we attempt to design a mobile application to assist visitors to have better <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:bDTr96ETOLUJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13058208705930802284&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'bDTr96ETOLUJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB130" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW130"><a href="http://img.cs.uec.ac.jp/pub/conf10/110317kawakubo_3.pdf" class=yC2E><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uec.ac.jp</span><span class="gs_ggsS">uec.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://img.cs.uec.ac.jp/pub/conf10/110317kawakubo_3.pdf" class=yC2D>å°åå¥ä»£è¡¨ç»åãç¨ããåèªæ¦å¿µã®å°åæ§ã®åæ</a></h3><div class="gs_a">å·ä¹ä¿ç§æï¼ æ³äºåå¸ - æå ±å¦çå­¦ä¼ç ç©¶å ±å. CVIM,[ã³ã³ãã¥ã¼ã¿ &hellip;, 2011 - img.cs.uec.ac.jp</div><div class="gs_rs">æ¬è«æã§ã¯, åèªæ¦å¿µã«å¯¾å¿ããè¦è¦ã®å°åæ§ãåæããããã«, å°åå¥ä»£è¡¨ç»åã®é¸åºã¨åæã<br>è¡ãææ³ãææ¡ãã. ææ¡ææ³ã§ã¯, ã¾ã, åèªæ¦å¿µã«é¢ããä»£è¡¨ä½ç½®æå ±ä»ãç»åã®éåãç¨æ<br>ã, Mean-Shift æ³ã«ãã£ã¦åèªæ¦å¿µã«é¢é£ããä½ç½®åº§æ¨ãè¤æ°æ±ºå®ãã. ããã¦ç»åã®ä½ç½®æå ±<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:RC2Biv2Cmy4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=3358421972596895044&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'RC2Biv2Cmy4J')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md130', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md130" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:RC2Biv2Cmy4J:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:369"><div class="gs_ri"><h3 class="gs_rt"><a href="http://japanlinkcenter.org/JST.JSTAGE/iieej/39.924?from=Google" class=yC2F>6-12 ç»åãã¼ã¿ãã¼ã¹</a></h3><div class="gs_a">å¤ç°æè£ï¼ å è¤ä¿ä¸ - ç»åé»å­å­¦ä¼èª, 2010 - J-STAGE</div><div class="gs_rs">ç»åãã¼ã¿ãã¼ã¹ã»ç»åæ¤ç´¢ã¯,ãç»åããæ½åºãããç¹å¾´éãã­ã¼ã¨ãã¦ç»åãç®¡çã, <br>ãããæ¤ç´¢ããææ³ã ã¨,ãç»åã«ä»ä¸ãããä»å çãªæå ±ãã­ã¼ã¨ãã¦ç»åãç®¡çã, <br>ãããæ¤ç´¢ããææ³ã ãåºç¤æè¡ã¨ãã¦ãã, ãã®ä¸¡èããã¾ãèåãããã¨, ã¤ã¾ã, ã¤ã³ã¿ã¼ãã£<b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:mTyj5VH0RKcJ:scholar.google.com/&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12053027135332498585&amp;hl=en&amp;num=100&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'mTyj5VH0RKcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:368"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB132" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW132"><a href="http://repository.osakafu-u.ac.jp/dspace/bitstream/10466/12625/1/2012900005.pdf" class=yC31><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from osakafu-u.ac.jp</span><span class="gs_ggsS">osakafu-u.ac.jp <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[CITATION]</span><span class="gs_ct2">[C]</span></span> <a href="http://repository.osakafu-u.ac.jp/dspace/handle/10466/12625" class=yC30>å±æç¹å¾´éãç¨ããç¹å®ç©ä½èªè­ã«é¢ããç ç©¶</a></h3><div class="gs_a">äºä¸åæ - 2011 - repository.osakafu-u.ac.jp</div><div class="gs_rs">è¿å¹´, ãã¸ã¿ã«ã«ã¡ã©ãã¹ãã¼ããã©ã³ç­ã®æºå¸¯ç«¯æ«ãèè¥ç·å¥³ãåããã«, å¤ãã®äººãã«æ®åãã¦ã<br>ã¦ãã. ã¾ã, ãã®ãããªæºå¸¯ç«¯æ«æ©å¨ã®é«æ§è½åãèãã, ç¹ã«ãããã«ä»ä¸ããã¦ããã«ã¡ã©æ©è½<br>ã®æ§è½ã«ã¯ç®ãè¦å¼µããã®ããã. ä¾ãã°, ç¾å¨éçºããã¦ããæºå¸¯ç«¯æ«ã®ã»ã¨ãã©ã«ã¯, é¡æ¤åº<b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'qjOG_yqCULkJ')" href="#" class="gs_nph">Cite</a></div></div></div>
