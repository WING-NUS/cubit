Total results = 31
<div class="gs_r" style="z-index:400"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB0" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW0"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.104.4752&amp;rep=rep1&amp;type=pdf" class=yC1><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4118238" class=yC0>On the correlation of automatic audio and visual segmentations of music videos</a></h3><div class="gs_a"><a href="/citations?user=sHkl_ZgAAAAJ&amp;hl=en&amp;oi=sra">O Gillet</a>, S Essid, G Richard - Circuits and Systems for Video  &hellip;, 2007 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract The study of the associations between audio and video content has numerous <br>important applications in the fields of information retrieval and multimedia content authoring. <br>In this work, we focus on music videos which exhibit a broad range of structural and <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=14760550731917802638&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=31">Cited by 25</a> <a href="/scholar?q=related:jrwXma8C2MwJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/0D/5C/RN207335616.html?source=googlescholar" class="gs_nph" class=yC2>BL Direct</a> <a href="/scholar?cluster=14760550731917802638&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'jrwXma8C2MwJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:399"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB1" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW1"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.106.3642&amp;rep=rep1&amp;type=pdf" class=yC4><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/W09173015722J471.pdf" class=yC3>Emotion-based music visualization using photos</a></h3><div class="gs_a">CH Chen, <a href="/citations?user=5BeBtpgAAAAJ&amp;hl=en&amp;oi=sra">MF Weng</a>, SK Jeng, <a href="/citations?user=uSS3FwQAAAAJ&amp;hl=en&amp;oi=sra">YY Chuang</a> - Advances in Multimedia  &hellip;, 2008 - Springer</div><div class="gs_rs">Music players for personal computers are often featured with music visualization by <br>generating animated patterns according to the music&#39;s low-level features such as loudness <br>and spectrum. This paper proposes an emotion-based music player which synchronizes <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13030620209166866559&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=31">Cited by 15</a> <a href="/scholar?q=related:f9hqggoQ1rQJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/53/23/RN221721607.html?source=googlescholar" class="gs_nph" class=yC5>BL Direct</a> <a href="/scholar?cluster=13030620209166866559&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'f9hqggoQ1rQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:398"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB2" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW2"><a href="http://www.computing.edu.au/~svetha/publications/2008/journals/venkatesh_etal_pieee08.pdf" class=yC7><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from computing.edu.au</span><span class="gs_ggsS">computing.edu.au <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4472088" class=yC6>âYou Tube and I FindââPersonalizing Multimedia Content Access</a></h3><div class="gs_a"><a href="/citations?user=AEkRUQcAAAAJ&amp;hl=en&amp;oi=sra">S Venkatesh</a>, <a href="/citations?user=kbcVlyAAAAAJ&amp;hl=en&amp;oi=sra">B Adams</a>, <a href="/citations?user=OtA9SwIAAAAJ&amp;hl=en&amp;oi=sra">D Phung</a>, C Dorai&hellip; - Proceedings of the  &hellip;, 2008 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Recent growth in broadband access and proliferation of small personal devices that <br>capture images and videos has led to explosive growth of multimedia content available <br>everywhere-from personal disks to the Web. While digital media capture and upload has <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13000714320977884714&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=31">Cited by 15</a> <a href="/scholar?q=related:KnY4UMvQa7QJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/1B/14/RN226708502.html?source=googlescholar" class="gs_nph" class=yC8>BL Direct</a> <a href="/scholar?cluster=13000714320977884714&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'KnY4UMvQa7QJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:397"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB3" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW3"><a href="http://csce.uark.edu/~jgauch/library/Video/Achanta.2006.pdf" class=yCA><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from uark.edu</span><span class="gs_ggsS">uark.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1580433" class=yC9>Modeling intent for home video repurposing</a></h3><div class="gs_a"><a href="/citations?user=lc2HaZwAAAAJ&amp;hl=en&amp;oi=sra">RSV Achanta</a>, WQ Yan, MS Kankanhalli - Multimedia, IEEE, 2006 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Amateur home videos rarely convey intent effectively, primarily because of the <br>limitations of conventional consumer-quality video cameras and the difficulties of video <br>postprocessing. The authors describe a general approach for video-intent delivery based <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4206118216265038784&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=31">Cited by 13</a> <a href="/scholar?q=related:wPvGkzsiXzoJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/4F/49/RN183745838.html?source=googlescholar" class="gs_nph" class=yCB>BL Direct</a> <a href="/scholar?cluster=4206118216265038784&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 15 versions</a> <a onclick="return gs_ocit(event,'wPvGkzsiXzoJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:396"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1542096" class=yCC>Multimedia content personalization based on peer-level annotation</a></h3><div class="gs_a">MG Manzato, DB Coimbra, <a href="/citations?user=6lc68RgAAAAJ&amp;hl=en&amp;oi=sra">R Goularte</a> - Proceedings of the seventh  &hellip;, 2009 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we propose an architecture which supports metadata extraction by <br>exploring interaction mechanisms among users and content. The interaction activity <br>addressed in this work is related to peer-level annotation, where any user acts as author, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=1154790190464088485&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=31">Cited by 12</a> <a href="/scholar?q=related:pbm3VI-jBhAJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'pbm3VI-jBhAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:395"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB5" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW5"><a href="http://140.112.31.113/Publication%5Cconference%5C2008%5CAesthetics-based%20Automatic%20Home%20Video%20Skimming%20System.pdf" class=yCE><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from 140.112.31.113</span><span class="gs_ggsS">140.112.31.113 <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/818h87586v081k61.pdf" class=yCD>Aesthetics-based automatic home video skimming system</a></h3><div class="gs_a">WT Peng, YH Chiang, <a href="/citations?user=DcltNjQAAAAJ&amp;hl=en&amp;oi=sra">WT Chu</a>, WJ Huang&hellip; - Advances in Multimedia  &hellip;, 2008 - Springer</div><div class="gs_rs">In this paper, we propose an automatic home video skimming system based on media <br>aesthetics. Unlike other similar works, the proposed system considers video editing theory <br>and realizes the idea of computational media aesthetics. Given a home video and a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13232195404645601060&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=31">Cited by 10</a> <a href="/scholar?q=related:JA91BJ0zorcJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/0E/2E/RN221721444.html?source=googlescholar" class="gs_nph" class=yCF>BL Direct</a> <a href="/scholar?cluster=13232195404645601060&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 9 versions</a> <a onclick="return gs_ocit(event,'JA91BJ0zorcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:394"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB6" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW6"><a href="http://www.mirlab.org/conference_papers/International_Conference/ICICS_PCM%202003/PDFFILES/Papers/3B17P0682.PDF" class=yC11><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mirlab.org</span><span class="gs_ggsS">mirlab.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1292728" class=yC10>Music synthesis for home videos: an analogy based approach</a></h3><div class="gs_a">M Nayak, SH Srinivasan&hellip; - &hellip;  and Signal Processing,  &hellip;, 2003 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract There have been efforts in the recent years to make home videos look more <br>interesting and pleasing to viewers by mixing it with music. Most of the existing software <br>enables the user to add music of his preference. It assumes that the user has enough <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=2750429356600714966&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=31">Cited by 10</a> <a href="/scholar?q=related:1ub9a-18KyYJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=2750429356600714966&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'1ub9a-18KyYJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:393"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB7" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW7"><a href="http://ippr112.csie.ntu.edu.tw/sandbox/groups/publications/wiki/d199a/attachments/a3dbe/TMM2131638.pdf" class=yC13><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntu.edu.tw</span><span class="gs_ggsS">ntu.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5737794" class=yC12>Editing by viewing: automatic home video summarization by viewing behavior analysis</a></h3><div class="gs_a">WT Peng, <a href="/citations?user=DcltNjQAAAAJ&amp;hl=en&amp;oi=sra">WT Chu</a>, CH Chang, CN Chou&hellip; - Multimedia, IEEE  &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we propose the Interest Meter (IM), a system making the computer <br>conscious of user&#39;s reactions to measure user&#39;s interest and thus use it to conduct video <br>summarization. The IM takes account of users&#39; spontaneous reactions when they view <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=9339437170398883141&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=31">Cited by 11</a> <a href="/scholar?q=related:RW20v59YnIEJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9339437170398883141&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'RW20v59YnIEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:392"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB8" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW8"><a href="http://visualcomputing.yonsei.ac.kr/papers/2009/musicvideo_Yoon.pdf" class=yC15><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from yonsei.ac.kr</span><span class="gs_ggsS">yonsei.ac.kr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/T80K1H2V1K6R0LV2.pdf" class=yC14>Automated music video generation using multi-level feature-based segmentation</a></h3><div class="gs_a">JC Yoon, IK Lee, S Byun - &hellip;  of Multimedia for Digital Entertainment and Arts, 2009 - Springer</div><div class="gs_rs">The expansion of the home video market has created a requirement for video editing tools to <br>allow ordinary people to assemble videos from short clips. However, professional skills are <br>still necessary to create a music video, which requires a stream to be synchronized with <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=6080057098628019183&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=31">Cited by 9</a> <a href="/scholar?q=related:77PQubezYFQJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=6080057098628019183&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 10 versions</a> <a onclick="return gs_ocit(event,'77PQubezYFQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:391"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB9" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW9"><a href="http://ntur.lib.ntu.edu.tw/retrieve/171962/02.pdf" class=yC17><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntu.edu.tw</span><span class="gs_ggsS">ntu.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/U515027117122802.pdf" class=yC16>A user experience model for home video summarization</a></h3><div class="gs_a">WT Peng, WJ Huang, <a href="/citations?user=DcltNjQAAAAJ&amp;hl=en&amp;oi=sra">WT Chu</a>, CN Chou&hellip; - Advances in Multimedia  &hellip;, 2009 - Springer</div><div class="gs_rs">In this paper, we propose a novel system for automatically summarizing home videos based <br>on a user experience model. The user experience model takes account of user&#39;s <br>spontaneous behaviors when viewing videos. Based on users&#39; reaction when viewing <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17308652769603131641&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=31">Cited by 8</a> <a href="/scholar?q=related:-ZjGIP2vNPAJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17308652769603131641&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 11 versions</a> <a onclick="return gs_ocit(event,'-ZjGIP2vNPAJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:390"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB10" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW10"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.102.2127&amp;rep=rep1&amp;type=pdf" class=yC19><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/U512Q5X0081517M1.pdf" class=yC18>Analogies based video editing</a></h3><div class="gs_a">WQ Yan, MS Kankanhalli, <a href="/citations?user=wIE1tY4AAAAJ&amp;hl=en&amp;oi=sra">J Wang</a> - Multimedia Systems, 2005 - Springer</div><div class="gs_rs">A well-produced video always creates a strong impression on the viewer. However, due to <br>the limitations of the camera, the ambient conditions or the skills of the videographer, the <br>quality of captured videos sometimes falls short of one&#39;s expectations. On the other hand, <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=13469578948090295803&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=31">Cited by 4</a> <a href="/scholar?q=related:-3UAO7CO7boJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/33/03/RN180039385.html?source=googlescholar" class="gs_nph" class=yC1A>BL Direct</a> <a href="/scholar?cluster=13469578948090295803&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 7 versions</a> <a onclick="return gs_ocit(event,'-3UAO7CO7boJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:389"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1874024" class=yC1B>Toward an automatically generated soundtrack from low-level cross-modal correlations for automotive scenarios</a></h3><div class="gs_a"><a href="/citations?user=LbgTPRwAAAAJ&amp;hl=en&amp;oi=sra">M Cristani</a>, A Pesarin, <a href="/citations?user=lKqYJ3AAAAAJ&amp;hl=en&amp;oi=sra">C Drioli</a>, <a href="/citations?user=yV3_PTkAAAAJ&amp;hl=en&amp;oi=sra">V Murino</a>&hellip; - Proceedings of the  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract In this paper, we propose a novel recommendation policy for driving scenarios. <br>While driving a car, listening to an audio track may enrich the atmosphere, conveying <br>emotions that let the driver sense a more arousing experience. Here, we are introducing a <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=17578300289213752476&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=31">Cited by 3</a> <a href="/scholar?q=related:nGS7rfqq8vMJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=17578300289213752476&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 2 versions</a> <a onclick="return gs_ocit(event,'nGS7rfqq8vMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:388"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.google.com/patents?hl=en&amp;lr=&amp;vid=USPATAPP11094887&amp;id=khWUAAAAEBAJ&amp;oi=fnd&amp;printsec=abstract" class=yC1C>Projector/printer for displaying or printing of documents</a></h3><div class="gs_a"><a href="/citations?user=ENKbH8AAAAAJ&amp;hl=en&amp;oi=sra">D Lee</a>, <a href="/citations?user=Ce7SL8AAAAAJ&amp;hl=en&amp;oi=sra">JJ Hull</a>, B Erol, J Graham - US Patent App. 11/094,887, 2005 - Google Patents</div><div class="gs_rs">A combined projector/printer that can receive data in a printer format or a projector format, <br>and then either generate a displayable image, a printed document or both. In the case that <br>the input data is not in a video format but rather in a print format, the projector system is <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=5127013382660639678&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=31">Cited by 3</a> <a href="/scholar?q=related:vksp6IHPJkcJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=5127013382660639678&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'vksp6IHPJkcJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:387"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.google.com/patents?hl=en&amp;lr=&amp;vid=USPAT7747655&amp;id=fxbVAAAAEBAJ&amp;oi=fnd&amp;printsec=abstract" class=yC1D>Printable representations for time-based media</a></h3><div class="gs_a"><a href="/citations?user=Ce7SL8AAAAAJ&amp;hl=en&amp;oi=sra">JJ Hull</a>, J Graham, PE Hart - US Patent 7,747,655, 2010 - Google Patents</div><div class="gs_rs">The system of the present invention allows a user to generate a representation of time-<br>based media. The system of the present invention includes a feature extraction module for <br>extracting features from media content. For example, the feature extraction module can <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=11665545116587670471&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=31">Cited by 3</a> <a href="/scholar?q=related:xzuAEXpX5KEJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=11665545116587670471&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'xzuAEXpX5KEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:386"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.google.com/patents?hl=en&amp;lr=&amp;vid=USPAT7861169&amp;id=80fwAAAAEBAJ&amp;oi=fnd&amp;printsec=abstract" class=yC1E>Multimedia print driver dialog interfaces</a></h3><div class="gs_a"><a href="/citations?user=Ce7SL8AAAAAJ&amp;hl=en&amp;oi=sra">JJ Hull</a>, J Graham, PE Hart, K Piersol - US Patent 7,861,169, 2010 - Google Patents</div><div class="gs_rs">The system of the present invention includes a media-printing interface that allows users to <br>interact with a multimedia transformation process and format multimedia data to generate a <br>representation of multimedia data. The present invention provides a user interface that <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=12958485394861224892&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=31">Cited by 2</a> <a href="/scholar?q=related:vHPKQ8_J1bMJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12958485394861224892&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'vHPKQ8_J1bMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:385"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/Q611775538H607V7.pdf" class=yC1F>Example-based video remixing</a></h3><div class="gs_a">N Nitta, N Babaguchi - Multimedia Tools and Applications, 2011 - Springer</div><div class="gs_rs">Abstract A video remix is generally created by arranging selected video clips and combining <br>them with other media streams such as audio clips and video transition effects. This paper <br>proposes a system for semi-automatically creating video remixes of good expressive <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=15417949971467559414&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=31">Cited by 3</a> <a href="/scholar?q=related:9mERrs-P99UJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=15417949971467559414&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 6 versions</a> <a onclick="return gs_ocit(event,'9mERrs-P99UJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:384"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB16" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW16"><a href="http://pastel.archives-ouvertes.fr/docs/00/50/05/79/PDF/thesis.pdf" class=yC21><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from archives-ouvertes.fr</span><span class="gs_ggsS">archives-ouvertes.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://pastel.archives-ouvertes.fr/pastel-00002805/" class=yC20>Transcription des signaux percussifs. Application Ã  l&#39;analyse de scÃ¨nes musicales audiovisuelles</a></h3><div class="gs_a"><a href="/citations?user=sHkl_ZgAAAAJ&amp;hl=en&amp;oi=sra">O Gillet</a> - 2007 - pastel.archives-ouvertes.fr</div><div class="gs_rs">Je tiens d&#39;aborda remercier mon directeur de these GaÃ«l Richard pour avoir su faire <br>converger mes motivations et intÃ©rÃªts personnels vers le domaine de l&#39;indexation audio, <br>jusqu&#39;au choix du sujet de cette these, vaste, riche, mais aussi parfois dÃ©routant. Il a sua <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8881040292480709146&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=31">Cited by 2</a> <a href="/scholar?q=related:GnI-nRfLP3sJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8881040292480709146&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'GnI-nRfLP3sJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:383"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB17" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW17"><a href="http://www.cmlab.csie.ntu.edu.tw/~pullpull/papers/Film%20Narrative%20Exploration%20Through%20Analyzing%20Aesthetic%20Elements.pdf" class=yC23><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntu.edu.tw</span><span class="gs_ggsS">ntu.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/D4725V6504171524.pdf" class=yC22>Film narrative exploration through the analysis of aesthetic elements</a></h3><div class="gs_a">CW Wang, <a href="/citations?user=i12lzxgAAAAJ&amp;hl=en&amp;oi=sra">WH Cheng</a>, JC Chen, SS Yang&hellip; - Advances in Multimedia  &hellip;, 2006 - Springer</div><div class="gs_rs">In this paper, we propose a novel method for performing high-level narrative structure <br>extraction of films. Our objective is to utilize the knowledge of film production for analyzing <br>and extracting the structure of films. This is achieved by combining visual and aural cues <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8905894883605991300&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=31">Cited by 1</a> <a href="/scholar?q=related:hM9NEDYYmHsJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/37/1A/RN201272256.html?source=googlescholar" class="gs_nph" class=yC24>BL Direct</a> <a href="/scholar?cluster=8905894883605991300&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'hM9NEDYYmHsJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:382"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB18" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW18"><a href="http://visualcomputing.yonsei.ac.kr/papers/2006/iwicpas_yoon.pdf" class=yC26><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from yonsei.ac.kr</span><span class="gs_ggsS">yonsei.ac.kr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/D243415P346L322X.pdf" class=yC25>Feature-based synchronization of video and background music</a></h3><div class="gs_a">JC Yoon, IK Lee, HC Lee - Advances in Machine Vision, Image Processing &hellip;, 2006 - Springer</div><div class="gs_rs">We synchronize background music with a video by changing the timing of music, an <br>approach that minimizes the damage to music data. Starting from a MIDI file and video data, <br>feature points are extracted from both sources, paired, and then synchronized using <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=7919821297352619743&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=31">Cited by 1</a> <a href="/scholar?q=related:37ZGSYLb6G0J:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/5E/35/RN194735910.html?source=googlescholar" class="gs_nph" class=yC27>BL Direct</a> <a href="/scholar?cluster=7919821297352619743&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'37ZGSYLb6G0J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:381"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.google.com/patents?hl=en&amp;lr=&amp;vid=USPAT7864352&amp;id=vTDxAAAAEBAJ&amp;oi=fnd&amp;printsec=abstract" class=yC28>Printer with multimedia server</a></h3><div class="gs_a"><a href="/citations?user=Ce7SL8AAAAAJ&amp;hl=en&amp;oi=sra">JJ Hull</a>, J Graham, PE Hart, KW Piersol - US Patent 7,864,352, 2011 - Google Patents</div><div class="gs_rs">A printer with an embedded multimedia server is described that includes a processor <br>primarily allocated for print control and another processor for executing a multimedia server <br>for interfacing with hardware and/or software interfaces for various forms of media. <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=8385227030404851011&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=31">Cited by 1</a> <a href="/scholar?q=related:Q-VIrI5PXnQJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=8385227030404851011&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'Q-VIrI5PXnQJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:380"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB20" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW20"><a href="http://www.mirlab.org/conference_papers/International_Conference/ICICS_PCM%202003/PDFFILES/PAPERS/1A11P0911.pdf" class=yC2A><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from mirlab.org</span><span class="gs_ggsS">mirlab.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1292401" class=yC29>Information-integration approach to designing digital video albums</a></h3><div class="gs_a">C Madhwacharyula, W Jun, Y Weiqi, J Yi&hellip; - &hellip; , 2003 and Fourth  &hellip;, 2003 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present the architecture of the DVA (digital video album) system. <br>Information-integration is the key principle utilized in this system to allow for content-based <br>indexing, intuitive access and retrieval of digital video. Our implementation of the system <b> ...</b></div><div class="gs_fl"><a href="/scholar?cites=4720112419584736435&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en&amp;num=31">Cited by 1</a> <a href="/scholar?q=related:s_xBxTw1gUEJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4720112419584736435&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 12 versions</a> <a onclick="return gs_ocit(event,'s_xBxTw1gUEJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:379"><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6012080" class=yC2B>Example-based video remixing for home videos</a></h3><div class="gs_a">N Nitta, N Babaguchi - Multimedia and Expo (ICME), 2011 IEEE &hellip;, 2011 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract Video remixes are generally created by sequentially arranging selected video clips <br>and combining them with other media streams such as audio clips. In this paper, an example-<br>based approach is adopted for semi-automatically creating video remixes of good <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:zFfsDsOfSr4J:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=13711947675600705484&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'zFfsDsOfSr4J')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:378"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB22" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW22"><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.58.7697&amp;rep=rep1&amp;type=pdf" class=yC2D><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from psu.edu</span><span class="gs_ggsS">psu.edu <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.58.7697&amp;rep=rep1&amp;type=pdf" class=yC2C>Analogies Based Video Editing</a></h3><div class="gs_a">MS Kankanhalli - Citeseer</div><div class="gs_rs">Abstract A well-produced video always creates a strong impression on the viewer. However <br>due to the limitations of the camera, the ambient conditions or the skills of the videographer, <br>the quality of captured videos sometimes falls short of one&#39;s expectations. On the other <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:kBtpFa3WfAcJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=539542094254513040&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'kBtpFa3WfAcJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md22', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md22" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:kBtpFa3WfAcJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:377"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB23" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW23"><a href="http://visualcomputing.yonsei.ac.kr/papers/domestic/kcgs2006_yoon.pdf" class=yC2F><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from yonsei.ac.kr</span><span class="gs_ggsS">yonsei.ac.kr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://visualcomputing.yonsei.ac.kr/papers/domestic/kcgs2006_yoon.pdf" class=yC2E>ËÃ02 Ã±Â¥Â® Ã³Ã²dÃ´feg ÃÃï£¿ Ãhik j) l ÃÃ²Ä±ËCâ. mn j) lp orq ââ° tsvuÆÃ®wxy ËÃ0 ÃÃï£¿ hi Ã35XâÂ©â¥ Âµ {z|} Ãï£¿~!#% $âY nÃÃÂ¥Â© V Ã Ã Ã Ã ââ° ÃÃrÃÃ orq ââ° tÃ¡Ã Ã¤ Ã¢ Â«Â» ÃÃ &hellip;</a></h3><div class="gs_a">JC Yoond, IK Lee - visualcomputing.yonsei.ac.kr</div><div class="gs_rs">â Â¢Â°Â£â¢ Â§ÃÂ¶Â® Â© &quot;!Â® #$%Â¢&amp; (&#39;0)213)5 46 7Ã89A@CBDF EGI H PQS RUTVX WUYa` TVcbedX fghiUpqs <br>rutwvyxDÃ Ã)ÃÃÃÃÃÃ¡ Ã  <b> ...</b> Scene Conserved Music Video Generation Using the Multi-Level <br>Segmentation  <b> ...</b> Jong-Chul Yoond ,In-Kwon Lee p  <b> ...</b> âw Â«EÂ»â¦Ã ÃÃÃ¹ Å ÅÃÃ¢âââYâ <b> ...</b> </div><div class="gs_fl"><a href="/scholar?q=related:JP4AITN7_gsJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=864263638028975652&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'JP4AITN7_gsJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md23', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md23" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:JP4AITN7_gsJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:376"><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=2072371" class=yC30>Example-based video remixing support system</a></h3><div class="gs_a">N Nitta, N Babaguchi - Proceedings of the 19th ACM international  &hellip;, 2011 - dl.acm.org</div><div class="gs_rs">Abstract Video remixes are generally created by sequentially arranging selected video clips <br>and mixing them with other media streams such as audio clips and transition effects. <br>Especially, mixing music clips often effectively improves the expressive quality of video <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:zN0SOZ_P-lMJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a onclick="return gs_ocit(event,'zN0SOZ_P-lMJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:375"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB25" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW25"><a href="http://www.cmlab.csie.ntu.edu.tw/~zenic/Download/ICME2012/Conference/data/4711a985.pdf" class=yC32><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ntu.edu.tw</span><span class="gs_ggsS">ntu.edu.tw <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6298531" class=yC31>A Synaesthetic Approach for Image Slideshow Generation</a></h3><div class="gs_a">Y Xiang, MS Kankanhalli - Multimedia and Expo (ICME), 2012  &hellip;, 2012 - ieeexplore.ieee.org</div><div class="gs_rs">Abstract In this paper, we present a novel automatic image slideshow system that explores a <br>new medium between images and music. It can be regarded as a new image selection and <br>slideshow composition criterion. Based on the idea of``hearing colors, seeing sounds&quot; <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:r508TLR6NKgJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=12120447411952590255&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'r508TLR6NKgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:374"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB26" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW26"><a href="http://avarts.ionio.gr/~floros/pubs/AudioMostly%202010%20Paper.pdf" class=yC34><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from ionio.gr</span><span class="gs_ggsS">ionio.gr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://dl.acm.org/citation.cfm?id=1859803" class=yC33>Binaural mixing using gestural control interaction</a></h3><div class="gs_a">N Grigoriou, <a href="/citations?user=mb7ezlMAAAAJ&amp;hl=en&amp;oi=sra">A Floros</a>, K Drossos - Proceedings of the 5th Audio Mostly  &hellip;, 2010 - dl.acm.org</div><div class="gs_rs">Abstract In this work a novel audio binaural mixing platform is presented which employs <br>advanced gestural-based interaction techniques for controlling the mixing parameters. State-<br>of-the-art binaural technology algorithms are used for producing the final two-channel <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:GKLvg_KW1zgJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=4095908354456527384&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 3 versions</a> <a onclick="return gs_ocit(event,'GKLvg_KW1zgJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:373"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB27" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW27"><a href="http://www.comp.nus.edu.sg/~mohan/papers/mmas.pdf" class=yC36><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from nus.edu.sg</span><span class="gs_ggsS">nus.edu.sg <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.springerlink.com/index/ANUKC34M23G9MBJH.pdf" class=yC35>Multimedia analysis and synthesis</a></h3><div class="gs_a">M Kankanhalli - AI 2003: Advances in Artificial Intelligence, 2003 - Springer</div><div class="gs_rs">We describe novel approaches to multimedia analysis and synthesis problems. We first <br>present the experiential sampling technique which has the ability to focus on the analysis <br>task by making use of the contextual information. Sensor samples are used to gather <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:t5HWlg4ROjIJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="http://direct.bl.uk/research/18/3A/RN141850840.html?source=googlescholar" class="gs_nph" class=yC37>BL Direct</a> <a href="/scholar?cluster=3619224004903473591&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 8 versions</a> <a onclick="return gs_ocit(event,'t5HWlg4ROjIJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:372"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB28" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW28"><a href="http://pdf.aminer.org/000/246/882/new_trends_in_multimedia_systems_introduction.pdf" class=yC39><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from aminer.org</span><span class="gs_ggsS">aminer.org <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://pdf.aminer.org/000/246/882/new_trends_in_multimedia_systems_introduction.pdf" class=yC38>Emerging Trends in Multimedia Systems</a></h3><div class="gs_a">MS Kankanhalli - 2004 - pdf.aminer.org</div><div class="gs_rs">There has been a steadily growing interest in multimedia systems research over the last <br>decade. While there was initially a lot of activity in a few popular areas like video-on-<br>demand, video segmentation and content-based image retrieval, the range and depth of <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:r_LOmvN-q_wJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=18206785503314768559&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 4 versions</a> <a onclick="return gs_ocit(event,'r_LOmvN-q_wJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md28', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md28" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:r_LOmvN-q_wJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
<div class="gs_r" style="z-index:371"><div class="gs_ri"><h3 class="gs_rt"><a href="http://www.google.com/patents?hl=en&amp;lr=&amp;vid=USPAT8077341&amp;id=FJ7_AQAAEBAJ&amp;oi=fnd&amp;printsec=abstract" class=yC3A>Printer with audio or video receiver, recorder, and real-time content-based processing logic</a></h3><div class="gs_a"><a href="/citations?user=Ce7SL8AAAAAJ&amp;hl=en&amp;oi=sra">JJ Hull</a>, J Graham, PE Hart - US Patent 8,077,341, 2011 - Google Patents</div><div class="gs_rs">A system and method for monitoring events from a media stream and triggering an action in <br>response to detected events. The action is preferably based on information relating to the <br>event received by the system. The system can generate a paper document that reflects <b> ...</b></div><div class="gs_fl"><a href="/scholar?q=related:MJQVs5kbm4YJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">Related articles</a> <a href="/scholar?cluster=9699376569420977200&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5">All 5 versions</a> <a onclick="return gs_ocit(event,'MJQVs5kbm4YJ')" href="#" class="gs_nph">Cite</a></div></div></div>
<div class="gs_r" style="z-index:370"><div class="gs_ggs gs_fl"><button type="button" id="gs_ggsB30" class="gs_btnFI gs_in_ib gs_btn_half"><span class="gs_wr"><span class="gs_bg"></span><span class="gs_lbl"></span><span class="gs_ico"></span></span></button><div class="gs_md_wp" id="gs_ggsW30"><a href="http://hal.inria.fr/docs/00/50/05/79/PDF/thesis.pdf" class=yC3C><span class="gs_ggsL"><span class=gs_ctg2>[PDF]</span> from inria.fr</span><span class="gs_ggsS">inria.fr <span class=gs_ctg2>[PDF]</span></span></a></div></div><div class="gs_ri"><h3 class="gs_rt"><span class="gs_ctc"><span class="gs_ct1">[PDF]</span><span class="gs_ct2">[PDF]</span></span> <a href="http://hal.inria.fr/docs/00/50/05/79/PDF/thesis.pdf" class=yC3B>Olivier Gillet</a></h3><div class="gs_a">MLG Rapporteur - hal.inria.fr</div><div class="gs_rs">Je tiens d&#39;aborda remercier mon directeur de these GaÃ«l Richard pour avoir su faire <br>converger mes motivations et intÃ©rÃªts personnels vers le domaine de l&#39;indexation audio, <br>jusqu&#39;au choix du sujet de cette these, vaste, riche, mais aussi parfois dÃ©routant. Il a sua <b> ...</b></div><div class="gs_fl"><a onclick="return gs_ocit(event,'FOH6BXjkkdoJ')" href="#" class="gs_nph">Cite</a> <div class="gs_rm_dd gs_nph"><a href="#" class="gs_rm_l" onclick="return gs_md_opn('gs_rm_md30', event)">More<span class="gs_ico"></span></a><div id="gs_rm_md30" class="gs_md_wn" style="display:none"><a href="http://scholar.googleusercontent.com/scholar?q=cache:FOH6BXjkkdoJ:scholar.google.com/&amp;hl=en&amp;num=31&amp;as_sdt=0,5&amp;sciodt=0,5" class="gs_md_li">View as HTML</a></div>  </div>  </div></div></div>
